{"data": {"doi": "10.1109/tvcg.2014.2346318", "title": "ViSlang: A System for Interpreted Domain-Specific Languages for Scientific Visualization", "year": "2014", "conferenceName": "SciVis", "authors": "Peter Rautek;Stefan Bruckner;M. Eduard Gr\u00f6ller;Markus Hadwiger", "citationCount": "14", "affiliation": "Rautek, P (Corresponding Author), KAUST, Thuwal, Saudi Arabia. Rautek, Peter; Hadwiger, Markus, KAUST, Thuwal, Saudi Arabia. Bruckner, Stefan, Univ Bergen, N-5020 Bergen, Norway. Groeller, M. Eduard, Vienna Univ Technol, Vienna, Austria. Groeller, M. Eduard, VrVis Res Ctr, Vienna, Austria.", "countries": "Norway;Arabia;Austria", "abstract": "Researchers from many domains use scientific visualization in their daily practice. Existing implementations of algorithms usually come with a graphical user interface (high-level interface), or as software library or source code (low-level interface). In this paper we present a system that integrates domain-specific languages (DSLs) and facilitates the creation of new DSLs. DSLs provide an effective interface for domain scientists avoiding the difficulties involved with low-level interfaces and at the same time offering more flexibility than high-level interfaces. We describe the design and implementation of ViSlang, an interpreted language specifically tailored for scientific visualization. A major contribution of our design is the extensibility of the ViSlang language. Novel DSLs that are tailored to the problems of the domain can be created and integrated into ViSlang. We show that our approach can be added to existing user interfaces to increase the flexibility for expert users on demand, but at the same time does not interfere with the user experience of novice users. To demonstrate the flexibility of our approach we present new DSLs for volume processing, querying and visualization. We report the implementation effort for new DSLs and compare our approach with Matlab and Python implementations in terms of run-time performance.", "keywords": "Domain-specific languages, Volume visualization, Volume visualization framework", "link": "http://dx.doi.org/10.1109/TVCG.2014.2346318", "refList": ["10.1109/38.31462", "10.1145/1411203.1411256", "10.1109/ldav.2011.6092321", "10.1109/visual.2004.95", "10.1007/978-3-540-92995-6\\_3", "10.1109/tvcg.2009.25", "10.1145/1122501.1122505", "10.1109/visual.2005.1532788", "10.1109/tvcg.2011.185", "10.1109/tvcg.2009.58", "10.1145/2345156.2254079", "10.1109/visual.1992.235202", "10.1109/tvcg.2008.184", "10.1145/2185520.2185528", "10.1111/j.1467-8659.2011.01952.x", "10.1049/cp:20030538", "10.1109/mcg.2009.130", "10.1016/j.parco.2007.09.001", "10.1109/tvcg.2009.174", "10.1145/352029.352035", "10.1109/ipdps.2011.385"], "wos": 1, "children": [{"doi": "10.1109/tvcg.2015.2467449", "title": "Diderot: a Domain-Specific Language for Portable Parallel Scientific Visualization and Image Analysis", "year": "2015", "conferenceName": "SciVis", "authors": "Gordon L. Kindlmann;Charisee Chiw;Nicholas Seltzer;Lamont Samuels;John H. Reppy", "citationCount": "17", "affiliation": "Kindlmann, G (Corresponding Author), Univ Chicago, Dept Comp Sci, Chicago, IL 60637 USA. Kindlmann, Gordon; Chiw, Charisee; Seltzer, Nicholas; Samuels, Lamont; Reppy, John, Univ Chicago, Dept Comp Sci, Chicago, IL 60637 USA.", "countries": "USA", "abstract": "Many algorithms for scientific visualization and image analysis are rooted in the world of continuous scalar, vector, and tensor fields, but are programmed in low-level languages and libraries that obscure their mathematical foundations. Diderot is a parallel domain-specific language that is designed to bridge this semantic gap by providing the programmer with a high-level, mathematical programming notation that allows direct expression of mathematical concepts in code. Furthermore, Diderot provides parallel performance that takes advantage of modern multicore processors and GPUs. The high-level notation allows a concise and natural expression of the algorithms and the parallelism allows efficient execution on real-world datasets.", "keywords": "Domain specific language, portable parallel programming, scientific visualization, tensor fields", "link": "http://dx.doi.org/10.1109/TVCG.2015.2467449", "refList": ["10.2514/3.25224", "10.1145/1118890.1118892", "10.1109/tvcg.2011.185", "10.1145/2345156.2254079", "10.2140/pjm.1966.16.1", "10.1016/j.jmr.2011.09.022", "10.1109/tvcg.2012.240", "10.1109/visual.1999.809896", "10.1109/tvcg.2014.2346318", "10.1016/b978-012387582-2/50038-1", "10.1109/tpami.1986.4767851", "10.1016/s0022-5096(00)00023-5", "10.1145/2185520.2185528", "10.1145/361002.361007", "10.1111/j.1467-8659.2011.01952.x", "10.1109/visual.1998.745290", "10.1109/tvcg.2008.163", "10.1145/79173.79181", "10.1109/mcg.2009.130", "10.1016/s0898-1221(02)00210-9", "10.1109/smi.2005.41", "10.1109/2945.597800", "10.1109/visual.2003.1250414", "10.1016/s0022-0000(73)80033-9", "10.1109/tvcg.2008.148", "10.1109/78.193221", "10.1145/1932682.1869527", "10.1016/j.parco.2007.09.001", "10.1109/tvcg.2009.174", "10.1109/tvcg.2007.70534", "10.1109/tvcg.2014.2346322", "10.1109/38.511", "10.1145/352029.352035"], "wos": 1, "children": [{"doi": "10.1109/tvcg.2018.2864841", "title": "A Declarative Grammar of Flexible Volume Visualization Pipelines", "year": "2018", "conferenceName": "SciVis", "authors": "Min Shih;Charles Rozhon;Kwan-Liu Ma", "citationCount": "1", "affiliation": "Shih, M (Corresponding Author), Univ Calif Davis, Davis, CA 95616 USA. Shih, Min; Rozhon, Charles; Ma, Kwan-Liu, Univ Calif Davis, Davis, CA 95616 USA.", "countries": "USA", "abstract": "This paper presents a declarative grammar for conveniently and effectively specifying advanced volume visualizations. Existing methods for creating volume visualizations either lack the flexibility to specify sophisticated visualizations or are difficult to use for those unfamiliar with volume rendering implementation and parameterization. Our design provides the ability to quickly create expressive visualizations without knowledge of the volume rendering implementation. It attempts to capture aspects of those difficult but powerful methods while remaining flexible and easy to use. As a proof of concept, our current implementation of the grammar allows users to combine multiple data variables in various ways and define transfer functions for diverse input data. The grammar also has the ability to describe advanced shading effects and create animations. We demonstrate the power and flexibility of our approach using multiple practical volume visualizations.", "keywords": "Volume visualization,direct volume rendering,declarative specification,multivariate/multimodal volume data,animation", "link": "http://dx.doi.org/10.1109/TVCG.2018.2864841", "refList": ["10.1109/38.31462", "10.1007/978-0-387-98141-3\\_1", "10.1109/visual.1992.235219", "10.1109/visual.2004.95", "10.1080/14685240802376389", "10.1109/tvcg.2015.2467449", "10.1109/visual.2005.1532788", "10.1109/tvcg.2011.185", "10.1145/2345156.2254079", "10.1109/scivis.2015.7429514", "10.1109/tvcg.2014.2346318", "10.1111/j.1467-8659.2011.01952.x", "10.2312/vissym/eurovis07/115-122", "10.1109/tvcg.2002.1021579", "10.1109/mcg.2009.130", "10.1109/tvcg.2015.2467091", "10.1109/tvcg.2007.70555", "10.1111/j.1467-8659.2007.01095.x", "10.1016/j.parco.2007.09.001", "10.1109/tvcg.2009.174", "10.1109/tvcg.2007.70534", "10.1109/tvcg.2016.2599041", "10.1109/tvcg.2014.2346322", "10.1109/mcg.2008.96", "10.1109/tvcg.2009.189", "10.1109/ipdps.2011.385", "10.1109/tvcg.2016.2599030"], "wos": 1, "children": [], "len": 1}, {"doi": "10.1109/tvcg.2018.2864848", "title": "Shared-Memory Parallel Computation of Morse-Smale Complexes with Improved Accuracy", "year": "2018", "conferenceName": "SciVis", "authors": "Attila Gyulassy;Peer-Timo Bremer;Valerio Pascucci", "citationCount": "5", "affiliation": "Gyulassy, A (Corresponding Author), Univ Utah, SCI Inst, Salt Lake City, UT 84112 USA. Gyulassy, Attila; Pascucci, Valerio, Univ Utah, SCI Inst, Salt Lake City, UT 84112 USA. Bremer, Peer-Timo, Lawrence Livermore Natl Lab, Livermore, CA USA.", "countries": "USA", "abstract": "Topological techniques have proven to be a powerful tool in the analysis and visualization of large-scale scientific data. In particular, the Morse-Smale complex and its various components provide a rich framework for robust feature definition and computation. Consequently, there now exist a number of approaches to compute Morse-Smale complexes for large-scale data in parallel. However, existing techniques are based on discrete concepts which produce the correct topological structure but are known to introduce grid artifacts in the resulting geometry. Here, we present a new approach that combines parallel streamline computation with combinatorial methods to construct a high-quality discrete Morse-Smale complex. In addition to being invariant to the orientation of the underlying grid, this algorithm allows users to selectively build a subset of features using high-quality geometry. In particular, a user may specifically select which ascending/descending manifolds are reconstructed with improved accuracy, focusing computational effort where it matters for subsequent analysis. This approach computes Morse-Smale complexes for larger data than previously feasible with significant speedups. We demonstrate and validate our approach using several examples from a variety of different scientific domains, and evaluate the performance of our method.", "keywords": "Morse complex,Parallel Computation,Topology,Accurate Geometry", "link": "http://dx.doi.org/10.1109/TVCG.2018.2864848", "refList": ["10.1002/jcc.25181", "10.1007/s00454-003-2926-5", "10.1109/tpami.2011.95", "10.1109/tvcg.2010.235", "10.1007/s00454-002-2885-2", "10.1109/tvcg.2006.57", "10.1109/tvcg.2015.2467449", "10.1016/j.cagd.2012.03.017", "10.1145/777792.777846", "10.1109/tvcg.2008.110", "10.1109/tvcg.2007.70603", "10.1109/tvcg.2004.3", "10.1109/tvcg.2006.186", "10.1109/ldav.2016.7874333", "10.1021/jp981794v", "10.1016/j.jsc.2016.03.006", "10.1109/tvcg.2011.249", "10.1109/tvcg.2012.209", "10.1109/ldav.2016.7874312", "10.1080/14786445908642760", "10.1109/sc.2014.88", "10.1109/tvcg.2009.69", "10.1109/tvcg.2014.2346434", "10.1111/j.1365-2966.2011.18394.x"], "wos": 1, "children": [{"doi": "10.1109/tvcg.2019.2934620", "title": "High-throughput feature extraction for measuring attributes of deforming open-cell foams", "year": "2019", "conferenceName": "SciVis", "authors": "Steve Petruzza;Attila Gyulassy;Samuel Leventhal;John J. Baglino;Michael Czabaj;Ashley D. Spear;Valerio Pascucci", "citationCount": "1", "affiliation": "Petruzza, S (Corresponding Author), Univ Utah, SCI Inst, Salt Lake City, UT 84112 USA. Petruzza, Steve; Gyulassy, Attila; Leventhal, Samuel; Pascucci, Valerio, Univ Utah, SCI Inst, Salt Lake City, UT 84112 USA. Baglino, John J.; Czabaj, Michael; Spear, Ashley D., Univ Utah, Dept Mech Engn, Salt Lake City, UT 84112 USA.", "countries": "USA", "abstract": "Metallic open-cell foams are promising structural materials with applications in multifunctional systems such as biomedical implants, energy absorbers in impact, noise mitigation, and batteries. There is a high demand for means to understand and correlate the design space of material performance metrics to the material structure in terms of attributes such as density, ligament and node properties, void sizes, and alignments. Currently, X-ray Computed Tomography (CT) scans of these materials are segmented either manually or with skeletonization approaches that may not accurately model the variety of shapes present in nodes and ligaments, especially irregularities that arise from manufacturing, image artifacts, or deterioration due to compression. In this paper, we present a new workflow for analysis of open-cell foams that combines a new density measurement to identify nodal structures, and topological approaches to identify ligament structures between them. Additionally, we provide automated measurement of foam properties. We demonstrate stable extraction of features and time-tracking in an image sequence of a foam being compressed. Our approach allows researchers to study larger and more complex foams than could previously be segmented only manually, and enables the high-throughput analysis needed to predict future foam performance.", "keywords": "Topological analysis,foam,features extraction,feature tracking", "link": "http://dx.doi.org/10.1109/TVCG.2019.2934620", "refList": ["10.1179/175355510x12744412709403", "10.1002/jcc.25181", "10.1111/j.1365-2818.1981.tb01197.x", "10.3758/s13414-017-1457-8", "10.2312/sgp/sgp06/143-152", "10.1002/(sici)1527-2648(200004)2:4", "10.1016/j.solener.2010.04.022", "10.1016/s0079-6425(00)00002-5", "10.1016/0031-3203(84)90057-8", "10.1109/smi.2003.1199609", "10.1016/j.ijheatmasstransfer.2015.01.052", "10.1109/tvcg.2006.57", "10.1016/s1005-0302(12)60016-4", "10.1016/s0031-3203(98)00082-x", "10.1142/s0218654308001154", "10.1145/997817.997872", "10.1109/2945.795212", "10.1016/s0266-3538(03)00276-8", "10.1016/j.mspro.2014.07.604", "10.1111/j.1365-2818.1992.tb04302.x", "10.1109/2945.942688", "10.1109/tvcg.2007.70603", "10.1557/mrs2003.83", "10.1016/j.matdes.2013.10.027", "10.1109/tvcg.2015.2467432", "10.1109/pccga.2000.883951", "10.1016/0167-8655(95)00034-e", "10.1016/j.cej.2015.09.014", "10.1109/visual.1998.745288", "10.1109/ldav.2015.7348066", "10.1117/12.198601", "10.1109/tvcg.2009.69", "10.1007/pl00013399", "10.1109/2945.597796", "10.1016/j.jmatprotec.2013.12.004", "10.1109/34.329007", "10.1016/s0079-6425(98)00004-8", "10.1103/physrevd.71.077102", "10.1038/nmeth.2089", "10.1016/s0167-8655(02)00102-2", "10.1111/j.1365-2966.2011.18394.x", "10.1109/tvcg.2012.200", "10.1002/1527-2648(20021014)4:10", "10.1016/j.patcog.2016.01.022", "10.1109/tvcg.2018.2864848", "10.1007/s00371-005-0308-0", "10.1016/j.msea.2017.08.102", "10.1016/0165-1684(94)90061-2"], "wos": 1, "children": [], "len": 1}], "len": 3}, {"doi": "10.1109/tvcg.2018.2865152", "title": "DXR: A Toolkit for Building Immersive Data Visualizations", "year": "2018", "conferenceName": "InfoVis", "authors": "Ronell Sicat;Jiabao Li;Junyoung Choi;Maxime Cordeil;Won-Ki Jeong;Benjamin Bach;Hanspeter Pfister", "citationCount": "12", "affiliation": "Sicat, R (Corresponding Author), Harvard Visual Comp Grp, Cambridge, MA USA. Sicat, Ronell; Pfister, Hanspeter, Harvard Visual Comp Grp, Cambridge, MA USA. Li, Jiabao, Harvard Grad Sch Design, Cambridge, MA USA. Bach, Benjamin, Univ Edinburgh, Sch Informat, Edinburgh, Midlothian, Scotland. Cordeil, Maxime, Monash Univ, Immers Analyt Lab, Clayton, Vic, Australia. Choi, JunYoung; Jeong, Won-Ki, Ulsan Natl Inst Sci \\& Technol, Ulsan, South Korea.", "countries": "Scotland;USA;Korea;Australia", "abstract": "This paper presents DXR, a toolkit for building immersive data visualizations based on the Unity development platform. Over the past years, immersive data visualizations in augmented and virtual reality (AR, VR) have been emerging as a promising medium for data sense-making beyond the desktop. However, creating immersive visualizations remains challenging, and often require complex low-level programming and tedious manual encoding of data attributes to geometric and visual properties. These can hinder the iterative idea-to-prototype process, especially for developers without experience in 3D graphics, AR, and VR programming. With DXR, developers can efficiently specify visualization designs using a concise declarative visualization grammar inspired by Vega-Lite. DXR further provides a GUI for easy and quick edits and previews of visualization designs in-situ, i.e., while immersed in the virtual world. DXR also provides reusable templates and customizable graphical marks, enabling unique and engaging visualizations. We demonstrate the flexibility of DXR through several examples spanning a wide range of applications.", "keywords": "Augmented Reality,Virtual Reality,Immersive Visualization,Immersive Analytics,Visualization Toolkit", "link": "http://dx.doi.org/10.1109/TVCG.2018.2865152", "refList": ["10.1145/2642918.2647369", "10.1109/tvcg.2015.2467449", "10.1109/tvcg.2011.185", "10.1145/2598153.2598175", "10.1109/tvcg.2016.2598609", "10.1145/1980462.1980470", "10.1109/tvcg.2014.2346318", "10.1145/3009939.3009947", "10.2312/conf/eg2013/stars/039-063", "10.1145/3013971.3014006", "10.1109/tvcg.2016.2598608", "10.1109/tvcg.2016.2599107", "10.1145/3173574.3173664", "10.1109/tvcg.2017.2745941", "10.1145/2556288.2557010", "10.1145/3126594.3126613", "10.1016/j.visinf.2017.11.002", "10.1111/cgf.12391", "10.1109/tvcg.2015.2467091", "10.1109/bigdata.2014.7004282", "10.1109/bdva.2015.7314302", "10.1109/tvcg.2010.144", "10.1109/tvcg.2009.174", "10.1109/infvis.2004.64", "10.1145/2133416.2146416", "10.1109/tvcg.2014.2346322", "10.1109/tvcg.2017.2744079", "10.1111/cgf.12804", "10.1371/journal.pone.0057990", "10.1109/tvcg.2016.2599030"], "wos": 1, "children": [], "len": 1}, {"doi": "10.1111/cgf.13439", "year": "2018", "title": "Rendering and Extracting Extremal Features in 3D Fields", "conferenceName": "EuroVis", "authors": "Gordon L. Kindlmann;Charisee Chiw;T. Huynh;Attila Gyulassy;John H. Reppy;Peer{-}Timo Bremer", "citationCount": "4", "affiliation": "Kindlmann, G (Corresponding Author), Univ Chicago, Dept Comp Sci, Chicago, IL 60637 USA.\nKindlmann, G.; Chiw, C.; Huynh, T.; Reppy, J., Univ Chicago, Dept Comp Sci, Chicago, IL 60637 USA.\nGyulassy, A.; Bremer, P. -T., Univ Utah, SCI Inst, Salt Lake City, UT 84112 USA.", "countries": "USA", "abstract": "Visualizing and extracting three-dimensional features is important for many computational science applications, each with their own feature definitions and data types. While some are simple to state and implement (e.g. isosurfaces), others require more complicated mathematics (e.g. multiple derivatives, curvature, eigenvectors, etc.). Correctly implementing mathematical definitions is difficult, so experimenting with new features requires substantial investments. Furthermore, traditional interpolants rarely support the necessary derivatives, and approximations can reduce numerical stability. Our new approach directly translates mathematical notation into practical visualization and feature extraction, with minimal mental and implementation overhead. Using a mathematically expressive domain-specific language, Diderot, we compute direct volume renderings and particle-based feature samplings for a range of mathematical features. Non-expert users can experiment with feature definitions without any exposure to meshes, interpolants, derivative computation, etc. We demonstrate high-quality results on notoriously difficult features, such as ridges and vortex cores, using working code simple enough to be presented in its entirety.", "keywords": "", "link": "https://doi.org/10.1111/cgf.13439", "refList": ["10.1016/j.procs.2010.04.192", "10.1145/1015706.1015713", "10.1109/visual.1997.663930", "10.1109/tvcg.2009.204", "10.1109/tvcg.2015.2467449", "10.1063/1.857730", "10.1109/icpr.1994.576356", "10.1109/tvcg.2006.149", "10.1145/2345156.2254079", "10.1016/0734-189x(83)90094-4", "10.2140/pjm.1966.16.1", "10.1242/dev.087148", "10.1109/visual.1999.809896", "10.1109/tvcg.2007.70554", "10.1016/s0022-5096(00)00023-5", "10.1109/tvcg.2009.177", "10.1109/pacificvis.2012.6183587", "10.1002/dvdy.22283", "10.1006/cviu.1995.1014", "10.1109/tvcg.2012.218", "10.1109/tvcg.2011.98", "10.1109/tvcg.2009.44", "10.1109/visual.1998.745290", "10.2140/camcos.2016.11.37", "10.1109/tvcg.2009.11", "10.1109/visual.1996.568137", "10.1109/smi.2005.41", "10.1017/s0022112004002526", "10.1109/visual.2003.1250414", "10.1007/s00427-001-0196-x", "10.1109/tvcg.2008.148", "10.1016/j.media.2007.07.005", "10.1145/37402.37422", "10.1002/nbm.1940080707", "10.1111/j.1467-8659.2011.01945.x", "10.1109/38.511", "10.1016/s0091-679x(06)81006-x", "10.1109/34.632985", "10.1017/jfm.2012.257", "10.1017/s0022112095000462", "10.1109/tvcg.2007.1053", "10.1109/visual.2004.105"], "wos": 1, "children": [{"doi": "10.1109/tvcg.2018.2864828", "title": "Objective Vortex Corelines of Finite-sized Objects in Fluid Flows", "year": "2018", "conferenceName": "SciVis", "authors": "Tobias G\u00fcnther;Holger Theisel", "citationCount": "1", "affiliation": "Gunther, T (Corresponding Author), Swiss Fed Inst Technol, Comp Graph Lab, Zurich, Switzerland. Guenther, Tobias, Swiss Fed Inst Technol, Comp Graph Lab, Zurich, Switzerland. Theisel, Holger, Univ Magdeburg, Visual Comp Grp, Magdeburg, Germany.", "countries": "Switzerland;Germany", "abstract": "Vortices are one of the most-frequently studied phenomena in fluid flows. The center of the rotating motion is called the vortex coreline and its successful detection strongly depends on the choice of the reference frame. The optimal frame moves with the center of the vortex, which incidentally makes the observed fluid flow steady and thus standard vortex coreline extractors such as Sujudi-Haimes become applicable. Recently, an objective optimization framework was proposed that determines a near-steady reference frame for tracer particles. In this paper, we extend this technique to the detection of vortex corelines of inertial particles. An inertial particle is a finite-sized object that is carried by a fluid flow. In contrast to the usual tracer particles, they do not move tangentially with the flow, since they are subject to gravity and exhibit mass-dependent inertia. Their particle state is determined by their position and own velocity, which makes the search for the optimal frame a high-dimensional problem. We demonstrate in this paper that the objective detection of an inertial vortex coreline can be reduced in 2D to a critical point search in 2D. For 3D flows, however, the vortex coreline criterion remains a parallel vectors condition in 6D. To detect the vortex corelines we propose a recursive subdivision approach that is tailored to the underlying structure of the 6D vectors. The resulting algorithm is objective, and we demonstrate the vortex coreline extraction in a number of 2D and 3D vector fields.", "keywords": "Vortex extraction,inertial particles,objectivity,vortex coreline", "link": "http://dx.doi.org/10.1109/TVCG.2018.2864828", "refList": ["10.1016/0377-0257(79)87004-4", "10.1111/cgf.12358", "10.1016/0167-2789(91)90088-q", "10.1109/2.35197", "10.1109/tvcg.2016.2599016", "10.5194/npg-22-571-2015", "10.1109/tvcg.2007.70633", "10.1007/978-3-540-70823-0\\_9", "10.1016/b978-012387582-2/50040-x", "10.1111/cgf.12846", "10.1007/s11538-010-9594-4", "10.1017/s002211209900467x", "10.1143/jpsj.66.1331", "10.1063/1.857730", "10.1017/s0022112092001460", "10.1016/s0097-8493(02)00056-0", "10.1017/jfm.2016.151", "10.1175/2009jas2865.1", "10.1111/j.1467-8659.2008.01238.x", "10.1016/j.nonrwa.2014.08.002", "10.1109/visual.1997.663910", "10.1109/visual.1999.809896", "10.1146/annurev.fluid.23.1.601", "10.1109/tvcg.2015.2467200", "10.1145/1057432.1057452", "10.1109/tvcg.2014.2346415", "10.1111/cgf.13114", "10.1007/s100219900068", "10.2514/2.744", "10.1111/cgf.12659", "10.1145/3072959.3073684", "10.1023/a:1001816013475", "10.1007/s10569-015-9617-4", "10.1016/0960-0779(94)90137-6", "10.1016/0010-4655(88)90020-3", "10.1109/visual.1991.175773", "10.1063/1.864230", "10.1088/1742-6596/333/1/012003", "10.1111/cgf.12108", "10.1017/s0022112004002526", "10.1017/s0022112008005089", "10.1007/978-94-007-2482-2\\_30", "10.1016/j.ijengsci.2007.10.005", "10.1111/cgf.12913", "10.1109/tvcg.2009.11", "10.1111/cgf.13439", "10.1016/j.crme.2015.08.002", "10.1109/tvcg.2007.70545", "10.1145/2897824.2925919", "10.1109/visual.1998.745296", "10.1109/tvcg.2016.2599018", "10.1016/j.physd.2007.09.027", "10.1088/0031-8949/2010/t142/014001", "10.1016/0011-7471(70)90059-8", "10.1017/s0022112095000462", "10.1109/tvcg.2007.1053"], "wos": 1, "children": [{"doi": "10.1111/cgf.13689", "year": "2019", "title": "Robust Reference Frame Extraction from Unsteady 2D Vector Fields with Convolutional Neural Networks", "conferenceName": "EuroVis", "authors": "Byungsoo Kim;Tobias G{\\\"{u}}nther", "citationCount": "3", "affiliation": "Kim, B (Corresponding Author), Swiss Fed Inst Technol, Dept Comp Sci, Zurich, Switzerland.\nKim, Byungsoo; Guenther, Tobias, Swiss Fed Inst Technol, Dept Comp Sci, Zurich, Switzerland.", "countries": "Switzerland", "abstract": "Robust feature extraction is an integral part of scientific visualization. In unsteady vector field analysis, researchers recently directed their attention towards the computation of near-steady reference frames for vortex extraction, which is a numerically challenging endeavor. In this paper, we utilize a convolutional neural network to combine two steps of the visualization pipeline in an end-to-end manner: the filtering and the feature extraction. We use neural networks for the extraction of a steady reference frame for a given unsteady 2D vector field. By conditioning the neural network to noisy inputs and resampling artifacts, we obtain numerically stabler results than existing optimization-based approaches. Supervised deep learning typically requires a large amount of training data. Thus, our second contribution is the creation of a vector field benchmark data set, which is generally useful for any local deep learning-based feature extraction. Based on Vatistas velocity profile, we formulate a parametric vector field mixture model that we parameterize based on numerically-computed example vector fields in near-steady reference frames. Given the parametric model, we can efficiently synthesize thousands of vector fields that serve as input to our deep learning architecture. The proposed network is evaluated on an unseen numerical fluid flow simulation.", "keywords": "", "link": "https://doi.org/10.1111/cgf.13689", "refList": ["10.1016/0377-0257(79)87004-4", "10.1111/cgf.12358", "10.1109/tvcg.2018.2864828", "10.1016/0167-2789(91)90088-q", "10.1007/978-3-540-70823-0\\_9", "10.1016/b978-012387582-2/50040-x", "10.1111/cgf.13405", "10.1111/cgf.13319", "10.1109/tvcg.2018.2843369", "10.1007/bf00538235", "10.23940/ijpe.18.03", "10.1017/jfm.2016.151", "10.1109/visual.1999.809896", "10.1146/annurev.fluid.23.1.601", "10.1109/tvcg.2007.1036", "10.1109/tvcg.2018.2864839", "10.1007/978-3-319-54024-5\\_6", "10.1109/tvcg.2013.189", "10.1145/3072959.3073684", "10.1109/tvcg.2015.2467203", "10.2514/2.957", "10.1016/0960-0779(94)90137-6", "10.1109/visual.1991.175773", "10.1109/visual.1996.568137", "10.1017/s0022112004002526", "10.1109/pacificvis.2016.7465253", "10.1007/bf00849110", "10.1007/bf00198434", "10.1109/tvcg.2007.70545", "10.3390/informatics4030027", "10.1137/140983665", "10.1016/0011-7471(70)90059-8", "10.1017/s0022112095000462", "10.1145/1183287.1183290"], "wos": 1, "children": [{"doi": "10.1109/tvcg.2020.3028947", "title": "A Fluid Flow Data Set for Machine Learning and its Application to Neural Flow Map Interpolation", "year": "2020", "conferenceName": "SciVis", "authors": "Jakob Jakob;Markus H. Gross;Tobias G\u00fcnther", "citationCount": "0", "affiliation": "Jakob, J (Corresponding Author), Swiss Fed Inst Technol, Zurich, Switzerland. Jakob, Jakob; Gross, Markus; Guenther, Tobias, Swiss Fed Inst Technol, Zurich, Switzerland.", "countries": "Switzerland", "abstract": "In recent years, deep learning has opened countless research opportunities across many different disciplines. At present, visualization is mainly applied to explore and explain neural networks. Its counterpart-the application of deep learning to visualization problems-requires us to share data more openly in order to enable more scientists to engage in data-driven research. In this paper, we construct a large fluid flow data set and apply it to a deep learning problem in scientific visualization. Parameterized by the Reynolds number, the data set contains a wide spectrum of laminar and turbulent fluid flow regimes. The full data set was simulated on a high-performance compute cluster and contains 8000 time-dependent 2D vector fields, accumulating to more than 16 TB in size. Using our public fluid data set, we trained deep convolutional neural networks in order to set a benchmark for an improved post-hoc Lagrangian fluid flow analysis. In in-situ settings, flow maps are exported and interpolated in order to assess the transport characteristics of time-dependent fluids. Using deep learning, we improve the accuracy of flow map interpolations, allowing a more precise flow analysis at a reduced memory IO footprint.", "keywords": "Scientific visualization,deep learning,flow maps", "link": "http://dx.doi.org/10.1109/TVCG.2020.3028947", "refList": ["10.1007/978-3-319-10593-2\\_25", "10.1145/3355089.3356560", "10.1109/access.2019.2903582", "10.1111/cgf.13405", "10.1109/tmm.2019.2919431", "10.1017/jfm.2016.151", "10.1016/j.physd.2005.10.007", "10.1007/978-3-030-00533-7\\_36", "10.3390/rs11161921", "10.1007/978-3-030-48457-6\\_1", "10.1145/3309993", "10.1109/pacificvis.2018.00018", "10.1109/tvcg.2007.70554", "10.1109/mcg.2018.2881523", "10.1109/cvpr.2016.207", "10.1145/1073204.1073264", "10.1145/3072959.3073643", "10.1109/tpami.2015.2439281", "10.2312/pgv", "10.4208/cicp.oa-2018-0035", "10.1109/cvpr.2017.693", "10.1109/tvcg.2013.128", "10.1109/igarss.2018.8519261", "10.1063/1.3270044", "10.2312/pgv.20191115", "10.1145/3197517.3201304", "10.1145/3065386", "10.1145/1360612.1360649", "10.1109/mcse.2015.103", "10.1145/3355089.3356575", "10.1109/mcg.2018.2881502", "10.1029/2019jd032121", "10.3390/informatics4030027", "10.1109/access.2019.2931781", "10.1007/s12650-018-0523-1", "10.1109/tvcg.2019.2934332", "10.1146/annurev.fluid.32.1.165", "10.1007/978-3-319-46475-6\\_43", "10.1126/science.1127647", "10.1007/978-3-319-46475-6\\_25", "10.1111/cgf.13689"], "wos": 1, "children": [], "len": 1}, {"doi": "10.1109/pacificvis48177.2020.8737", "year": "2020", "title": "SSR-VFD: Spatial Super-Resolution for Vector Field Data Analysis and Visualization", "conferenceName": "PacificVis", "authors": "Li Guo;Shaojie Ye;Jun Han;Hao Zheng;Han Gao;Danny Z. Chen;Jian{-}Xun Wang;Chaoli Wang", "citationCount": "1", "affiliation": "Guo, L (Corresponding Author), Nankai Univ, Tianjin, Peoples R China.\nGuo, Li, Nankai Univ, Tianjin, Peoples R China.\nYe, Shaojie, Zhejiang Univ, Hangzhou, Zhejiang, Peoples R China.\nHan, Jun; Zheng, Hao; Gao, Han; Chen, Danny Z.; Wang, Jian-Xun; Wang, Chaoli, Univ Notre Dame, Notre Dame, IN 46556 USA.", "countries": "USA;China", "abstract": "We present SSR-VFD, a novel deep learning framework that produces coherent spatial super-resolution (SSR) of three-dimensional vector field data (VFD). SSR-VFD is the first work that advocates a machine learning approach to generate high-resolution vector fields from low-resolution ones. The core of SSR-VFD lies in the use of three separate neural nets that take the three components of a low-resolution vector field as input and jointly output a synthesized high-resolution vector field. To capture spatial coherence, we take into account magnitude and angle losses in network optimization. Our method can work in the in situ scenario where VFD are down-sampled at simulation time for storage saving and these reduced VFD are upsampled back to their original resolution during postprocessing. To demonstrate the effectiveness of SSR-VFD, we show quantitative and qualitative results with several vector field data sets of different characteristics and compare our method against volume upscaling using bicubic interpolation, and two solutions based on CNN and GAN, respectively.", "keywords": "Spatial super-resolution; vector field data; convolutional neural network; deep learning", "link": "https://doi.org/10.1109/PacificVis48177.2020.8737", "refList": ["10.1016/j.ijvsm.2017.05.001", "10.1016/j.jvs.2005.01.020", "10.1109/iccv.2015.123", "10.1111/cgf.13620", "10.1109/cvpr.2019.00831", "10.1109/cvpr.2019.00817", "10.1109/cvpr.2019.00399", "10.1109/tvcg.2019.2934312", "10.1145/3309993", "10.1109/pacificvis.2018.00018", "10.1109/tvcg.2018.2816059", "10.1109/mcg.2018.2881523", "10.1109/tpami.2015.2439281", "10.1109/bigdata.2018.8622520", "10.1145/3197517.3201304", "10.1109/tvcg.2018.2796085", "10.1109/tvcg.2019.2934255", "10.1109/cvpr.2016.90", "10.1109/pacificvis.2019.00041", "10.1111/cgf.13689"], "wos": 1, "children": [{"doi": "10.1109/tvcg.2020.3030374", "title": "VC-Net: Deep Volume-Composition Networks for Segmentation and Visualization of Highly Sparse and Noisy Image Data", "year": "2020", "conferenceName": "SciVis", "authors": "Yifan Wang;Guoli Yan;Haikuan Zhu;Sagar Buch;Ying Wang;E. Mark Haacke;Jing Hua;Zichun Zhong", "citationCount": "0", "affiliation": "Wang, YF (Corresponding Author), Wayne State Univ, Dept Comp Sci, Detroit, MI 48202 USA. Wang, Yifan; Yan, Guoli; Zhu, Haikuan; Hua, Jing; Zhong, Zichun, Wayne State Univ, Dept Comp Sci, Detroit, MI 48202 USA. Buch, Sagar; Wang, Ying; Haacke, Ewart Mark, Wayne State Univ, Dept Radiol, Detroit, MI 48201 USA.", "countries": "USA", "abstract": "The fundamental motivation of the proposed work is to present a new visualization-guided computing paradigm to combine direct 3D volume processing and volume rendered clues for effective 3D exploration. For example, extracting and visualizing microstructures in-vivo have been a long-standing challenging problem. However, due to the high sparseness and noisiness in cerebrovasculature data as well as highly complex geometry and topology variations of micro vessels, it is still extremely challenging to extract the complete 3D vessel structure and visualize it in 3D with high fidelity. In this paper, we present an end-to-end deep learning method, VC-Net, for robust extraction of 3D microvascular structure through embedding the image composition, generated by maximum intensity projection (MIP), into the 3D volumetric image learning process to enhance the overall performance. The core novelty is to automatically leverage the volume visualization technique (e.g., MIP - a volume rendering scheme for 3D volume images) to enhance the 3D data exploration at the deep learning level. The MIP embedding features can enhance the local vessel signal (through canceling out the noise) and adapt to the geometric variability and scalability of vessels, which is of great importance in microvascular tracking. A multi-stream convolutional neural network (CNN) framework is proposed to effectively learn the 3D volume and 2D MIP feature vectors, respectively, and then explore their inter-dependencies in a joint volume-composition embedding space by unprojecting the 2D feature vectors into the 3D volume embedding space. It is noted that the proposed framework can better capture the small/micro vessels and improve the vessel connectivity. To our knowledge, this is the first time that a deep learning framework is proposed to construct a joint convolutional embedding space, where the computed vessel probabilities from volume rendering based 2D projection and 3D volume can be explored and integrated synergistically. Experimental results are evaluated and compared with the traditional 3D vessel segmentation methods and the state-of-the-art in deep learning, by using extensive public and real patient (micro- )cerebrovascular image datasets. The application of this accurate segmentation and visualization of sparse and complicated 3D microvascular structure facilitated by our method demonstrates the potential in a powerful MR arteriogram and venogram diagnosis of vascular disease.", "keywords": "Deep neural network,3D cerebrovascular segmentation and visualization,maximum intensity projection (MIP),joint embedding", "link": "http://dx.doi.org/10.1109/TVCG.2020.3030374", "refList": ["10.1109/cluster.2018.00036", "10.1109/iccv.2015.123", "10.1109/tvcg.2013.133", "10.1109/cvpr.2017.19", "10.1109/tvcg.2019.2934312", "10.1007/978-3-319-46487-9\\_40", "10.1109/tvcg.2006.175", "10.1109/tvcg.2007.70523", "10.1109/tvcg.2018.2880207", "10.1145/3309993", "10.1109/pacificvis.2018.00018", "10.1109/iccv.2017.244", "10.1109/cvpr.2017.632", "10.1109/tvcg.2018.2816059", "10.1109/pacificvis.2009.4906852", "10.1109/tvcg.2018.2864808", "10.1109/mcg.2018.2881523", "10.1109/tvcg.2015.2467431", "10.1109/tpami.2015.2439281", "10.1109/pacificvis48177.2020.8737", "10.1109/cvpr.2019.00244", "10.1109/tvcg.2006.165", "10.1109/bigdata.2018.8622520", "10.1007/978-3-319-46466-4\\_29", "10.1109/visual.2019.8933759", "10.1145/3197517.3201304", "10.1109/pacificvis.2011.5742378", "10.1109/cvpr.2006.91", "10.1109/pacificvis.2011.5742369", "10.1109/tvcg.2019.2934255", "10.1109/cvpr.2016.90", "10.1007/978-3-319-24574-4\\_28", "10.1109/pacificvis.2019.00041", "10.1109/tvcg.2019.2934332", "10.1109/cvpr.2018.00916", "10.1007/978-3-319-46475-6\\_43"], "wos": 1, "children": [], "len": 1}], "len": 3}], "len": 7}], "len": 9}, {"doi": "10.1109/tvcg.2019.2934310", "title": "Extraction and Visual Analysis of Potential Vorticity Banners around the Alps", "year": "2019", "conferenceName": "SciVis", "authors": "Robin Bader;Michael Sprenger;Nikolina Ban;Stefan R\u00fcdis\u00fchli;Christoph Sch\u00e4r;Tobias G\u00fcnther", "citationCount": "0", "affiliation": "Bader, R (Corresponding Author), Swiss Fed Inst Technol, Dept Comp Sci, Zurich, Switzerland. Bader, Robin; Guenther, Tobias, Swiss Fed Inst Technol, Dept Comp Sci, Zurich, Switzerland. Sprenger, Michael; Ban, Nikolina; Ruedisuehli, Stefan; Schaer, Christoph, Swiss Fed Inst Technol, Inst Atmospher \\& Climate Sci, Zurich, Switzerland.", "countries": "Switzerland", "abstract": "Potential vorticity is among the most important scalar quantities in atmospheric dynamics. For instance, potential vorticity plays a key role in particularly strong wind peaks in extratropical cyclones and it is able to explain the occurrence of frontal rain bands. Potential vorticity combines the key quantities of atmospheric dynamics, namely rotation and stratification. Under suitable wind conditions elongated banners of potential vorticity appear in the lee of mountains. Their role in atmospheric dynamics has recently raised considerable interest in the meteorological community for instance due to their influence in aviation wind hazards and maritime transport. In order to support meteorologists and climatologists in the analysis of these structures, we developed an extraction algorithm and a visual exploration framework consisting of multiple linked views. For the extraction we apply a predictor-corrector algorithm that follows streamlines and realigns them with extremal lines of potential vorticity. Using the agglomerative hierarchical clustering algorithm, we group banners from different sources based on their proximity. To visually analyze the time-dependent banner geometry, we provide interactive overviews and enable the query for detail on demand, including the analysis of different time steps, potentially correlated scalar quantities, and the wind vector field. In particular, we study the relationship between relative humidity and the banners for their potential in indicating the development of precipitation. Working with our method, the collaborating meteorologists gained a deeper understanding of the three-dimensional processes, which may spur follow-up research in the future.", "keywords": "Scientific Visualization,potential vorticity,meteorology,feature extraction", "link": "http://dx.doi.org/10.1109/TVCG.2019.2934310", "refList": ["10.1002/qj.49710042520", "10.1111/j.1467-8659.2009.01702.x", "10.1111/cgf.13319", "10.1175/1520-0469(1998)055", "10.1007/bf01475602", "10.1143/jpsj.66.1331", "10.1109/tvcg.2013.2297914", "10.1007/978-3-540-88606-8\\_6", "10.1175/1520-0477(2001)082", "10.1175/mwr-d-16-0042.1", "10.1007/s00703-001-0592-9", "10.1002/qj.49710544615", "10.1111/cgf.13163", "10.1007/bf01446807", "10.1109/visual.1994.346327", "10.1109/visual.1999.809896", "10.1109/tvcg.2011.78", "10.1109/tvcg.2015.2467200", "10.2514/2.744", "10.1145/1013208.1013209", "10.1007/978-3", "10.1111/cgf.12933", "10.1175/1520-0477(2002)083", "10.1007/978-94-015-8765-5", "10.1175/2011mwr3504.1", "10.1007/s007030170008", "10.5194/gmd-9-3393-2016", "10.1175/bams-d-15-00299.1", "10.1002/2014gl062588", "10.1256/smsqj.47001", "10.1175/2010mwr3334.1", "10.1109/tvcg.2017.2779501", "10.1256/qj.02.47", "10.1111/cgf.13439", "10.5194/gmd-2017-230", "10.1109/visual.2003.1250376", "10.14529/jsfi140103", "10.1109/tvcg.2017.2743989", "10.1109/tvcg.2007.70545", "10.1111/j.1467-8659.2003.00723.x", "10.1109/tvcg.2007.1053", "10.1002/qj.828", "10.1002/2016jd026013", "10.1007/bf01450097"], "wos": 1, "children": [], "len": 1}, {"doi": "10.1111/cgf.13984", "year": "2020", "title": "Visual Analysis of the Finite-Time Lyapunov Exponent", "conferenceName": "EuroVis", "authors": "Antoni Sagrist{\\`{a}};Stefan Jordan;Filip Sadlo", "citationCount": "0", "affiliation": "Sagrista, A (Corresponding Author), Heidelberg Univ, Heidelberg, Germany.\nSagrista, Antoni; Jordan, Stefan; Sadlo, Filip, Heidelberg Univ, Heidelberg, Germany.", "countries": "Germany", "abstract": "In this paper, we present an integrated visual analytics approach to support the parametrization and exploration of flow visualization based on the finite-time Lyapunov exponent. Such visualization of time-dependent flow faces various challenges, including the choice of appropriate advection times, temporal regions of interest, and spatial resolution. Our approach eases these challenges by providing the user with context by means of parametric aggregations, with support and guidance for a more directed exploration, and with a set of derived measures for better qualitative assessment. We demonstrate the utility of our approach with examples from computation fluid dynamics and time-dependent dynamical systems.", "keywords": "", "link": "https://doi.org/10.1111/cgf.13984", "refList": ["10.1145/37402.37422", "10.1109/38.79452", "10.1016/j.parco.2011.09.001", "10.1016/j.physd.2005.10.007", "10.1109/2.35197", "10.1109/tvcg.2007.70551", "10.1016/s0167-2789(00)00199-8", "10.1109/tvcg.2016.2599018", "10.1109/tvcg.2017.2743938", "10.1109/tvcg.2015.2467449", "10.2307/2003354", "10.1109/tvcg.2007.70554", "10.1090/s0002-9904-1967-11798-1", "10.1109/visual.2005.1532788", "10.1017/s0022112004009929", "10.1111/j.1467-8659.2011.01901.x", "10.1111/cgf.13439", "10.1111/cgf.12933"], "wos": 1, "children": [], "len": 1}], "len": 15}, {"doi": "10.1111/cgf.13984", "year": "2020", "title": "Visual Analysis of the Finite-Time Lyapunov Exponent", "conferenceName": "EuroVis", "authors": "Antoni Sagrist{\\`{a}};Stefan Jordan;Filip Sadlo", "citationCount": "0", "affiliation": "Sagrista, A (Corresponding Author), Heidelberg Univ, Heidelberg, Germany.\nSagrista, Antoni; Jordan, Stefan; Sadlo, Filip, Heidelberg Univ, Heidelberg, Germany.", "countries": "Germany", "abstract": "In this paper, we present an integrated visual analytics approach to support the parametrization and exploration of flow visualization based on the finite-time Lyapunov exponent. Such visualization of time-dependent flow faces various challenges, including the choice of appropriate advection times, temporal regions of interest, and spatial resolution. Our approach eases these challenges by providing the user with context by means of parametric aggregations, with support and guidance for a more directed exploration, and with a set of derived measures for better qualitative assessment. We demonstrate the utility of our approach with examples from computation fluid dynamics and time-dependent dynamical systems.", "keywords": "", "link": "https://doi.org/10.1111/cgf.13984", "refList": ["10.1145/37402.37422", "10.1109/38.79452", "10.1016/j.parco.2011.09.001", "10.1016/j.physd.2005.10.007", "10.1109/2.35197", "10.1109/tvcg.2007.70551", "10.1016/s0167-2789(00)00199-8", "10.1109/tvcg.2016.2599018", "10.1109/tvcg.2017.2743938", "10.1109/tvcg.2015.2467449", "10.2307/2003354", "10.1109/tvcg.2007.70554", "10.1090/s0002-9904-1967-11798-1", "10.1109/visual.2005.1532788", "10.1017/s0022112004009929", "10.1111/j.1467-8659.2011.01901.x", "10.1111/cgf.13439", "10.1111/cgf.12933"], "wos": 1, "children": [], "len": 1}], "len": 27}, {"doi": "10.1109/tvcg.2018.2864841", "title": "A Declarative Grammar of Flexible Volume Visualization Pipelines", "year": "2018", "conferenceName": "SciVis", "authors": "Min Shih;Charles Rozhon;Kwan-Liu Ma", "citationCount": "1", "affiliation": "Shih, M (Corresponding Author), Univ Calif Davis, Davis, CA 95616 USA. Shih, Min; Rozhon, Charles; Ma, Kwan-Liu, Univ Calif Davis, Davis, CA 95616 USA.", "countries": "USA", "abstract": "This paper presents a declarative grammar for conveniently and effectively specifying advanced volume visualizations. Existing methods for creating volume visualizations either lack the flexibility to specify sophisticated visualizations or are difficult to use for those unfamiliar with volume rendering implementation and parameterization. Our design provides the ability to quickly create expressive visualizations without knowledge of the volume rendering implementation. It attempts to capture aspects of those difficult but powerful methods while remaining flexible and easy to use. As a proof of concept, our current implementation of the grammar allows users to combine multiple data variables in various ways and define transfer functions for diverse input data. The grammar also has the ability to describe advanced shading effects and create animations. We demonstrate the power and flexibility of our approach using multiple practical volume visualizations.", "keywords": "Volume visualization,direct volume rendering,declarative specification,multivariate/multimodal volume data,animation", "link": "http://dx.doi.org/10.1109/TVCG.2018.2864841", "refList": ["10.1109/38.31462", "10.1007/978-0-387-98141-3\\_1", "10.1109/visual.1992.235219", "10.1109/visual.2004.95", "10.1080/14685240802376389", "10.1109/tvcg.2015.2467449", "10.1109/visual.2005.1532788", "10.1109/tvcg.2011.185", "10.1145/2345156.2254079", "10.1109/scivis.2015.7429514", "10.1109/tvcg.2014.2346318", "10.1111/j.1467-8659.2011.01952.x", "10.2312/vissym/eurovis07/115-122", "10.1109/tvcg.2002.1021579", "10.1109/mcg.2009.130", "10.1109/tvcg.2015.2467091", "10.1109/tvcg.2007.70555", "10.1111/j.1467-8659.2007.01095.x", "10.1016/j.parco.2007.09.001", "10.1109/tvcg.2009.174", "10.1109/tvcg.2007.70534", "10.1109/tvcg.2016.2599041", "10.1109/tvcg.2014.2346322", "10.1109/mcg.2008.96", "10.1109/tvcg.2009.189", "10.1109/ipdps.2011.385", "10.1109/tvcg.2016.2599030"], "wos": 1, "children": [], "len": 1}, {"doi": "10.1109/tvcg.2018.2865152", "title": "DXR: A Toolkit for Building Immersive Data Visualizations", "year": "2018", "conferenceName": "InfoVis", "authors": "Ronell Sicat;Jiabao Li;Junyoung Choi;Maxime Cordeil;Won-Ki Jeong;Benjamin Bach;Hanspeter Pfister", "citationCount": "12", "affiliation": "Sicat, R (Corresponding Author), Harvard Visual Comp Grp, Cambridge, MA USA. Sicat, Ronell; Pfister, Hanspeter, Harvard Visual Comp Grp, Cambridge, MA USA. Li, Jiabao, Harvard Grad Sch Design, Cambridge, MA USA. Bach, Benjamin, Univ Edinburgh, Sch Informat, Edinburgh, Midlothian, Scotland. Cordeil, Maxime, Monash Univ, Immers Analyt Lab, Clayton, Vic, Australia. Choi, JunYoung; Jeong, Won-Ki, Ulsan Natl Inst Sci \\& Technol, Ulsan, South Korea.", "countries": "Scotland;USA;Korea;Australia", "abstract": "This paper presents DXR, a toolkit for building immersive data visualizations based on the Unity development platform. Over the past years, immersive data visualizations in augmented and virtual reality (AR, VR) have been emerging as a promising medium for data sense-making beyond the desktop. However, creating immersive visualizations remains challenging, and often require complex low-level programming and tedious manual encoding of data attributes to geometric and visual properties. These can hinder the iterative idea-to-prototype process, especially for developers without experience in 3D graphics, AR, and VR programming. With DXR, developers can efficiently specify visualization designs using a concise declarative visualization grammar inspired by Vega-Lite. DXR further provides a GUI for easy and quick edits and previews of visualization designs in-situ, i.e., while immersed in the virtual world. DXR also provides reusable templates and customizable graphical marks, enabling unique and engaging visualizations. We demonstrate the flexibility of DXR through several examples spanning a wide range of applications.", "keywords": "Augmented Reality,Virtual Reality,Immersive Visualization,Immersive Analytics,Visualization Toolkit", "link": "http://dx.doi.org/10.1109/TVCG.2018.2865152", "refList": ["10.1145/2642918.2647369", "10.1109/tvcg.2015.2467449", "10.1109/tvcg.2011.185", "10.1145/2598153.2598175", "10.1109/tvcg.2016.2598609", "10.1145/1980462.1980470", "10.1109/tvcg.2014.2346318", "10.1145/3009939.3009947", "10.2312/conf/eg2013/stars/039-063", "10.1145/3013971.3014006", "10.1109/tvcg.2016.2598608", "10.1109/tvcg.2016.2599107", "10.1145/3173574.3173664", "10.1109/tvcg.2017.2745941", "10.1145/2556288.2557010", "10.1145/3126594.3126613", "10.1016/j.visinf.2017.11.002", "10.1111/cgf.12391", "10.1109/tvcg.2015.2467091", "10.1109/bigdata.2014.7004282", "10.1109/bdva.2015.7314302", "10.1109/tvcg.2010.144", "10.1109/tvcg.2009.174", "10.1109/infvis.2004.64", "10.1145/2133416.2146416", "10.1109/tvcg.2014.2346322", "10.1109/tvcg.2017.2744079", "10.1111/cgf.12804", "10.1371/journal.pone.0057990", "10.1109/tvcg.2016.2599030"], "wos": 1, "children": [], "len": 1}], "len": 33}, "index": 329, "embedding": [0.4420214891433716, 1.2861112356185913, -1.0271400213241577, -1.04525887966156, -0.6604432463645935, 0.16650904715061188, -0.7167134881019592, 2.2301688194274902, 0.7692570686340332, 1.279079556465149, 0.7926604151725769, 0.4915190041065216, 1.4457882642745972, 2.746776819229126, -0.11351378262042999, 1.716381311416626, 0.38491010665893555, 0.0788058489561081, -0.14239421486854553, 3.729264974594116, -0.06630208343267441, 1.6401981115341187, 0.03893714025616646, 2.2344231605529785, -2.4801409244537354, 2.9442496299743652, -0.5328229665756226, 0.7760390043258667, 1.7735062837600708, -1.8509862422943115, 0.6835851073265076, 1.3478248119354248], "projection": [0.7908331751823425, 8.986279487609863], "size": 17, "height": 7, "width": 5}