{"data": {"doi": "10.1109/tvcg.2019.2934395", "title": "The Impact of Immersion on Cluster Identification Tasks", "year": "2019", "conferenceName": "InfoVis", "authors": "Matthias Kraus;Niklas Weiler;Daniela Oelke;Johannes Kehrer;Daniel A. Keim;Johannes Fuchs", "citationCount": "4", "affiliation": "Kraus, M (Corresponding Author), Univ Konstanz, Constance, Germany. Kraus, M.; Weiler, N.; Keim, D. A.; Fuchs, J., Univ Konstanz, Constance, Germany. Oelke, D.; Kehrer, J., Siemens Corp Technol, Munich, Germany.", "countries": "Germany", "abstract": "Recent developments in technology encourage the use of head-mounted displays (HMDs) as a medium to explore visualizations in virtual realities (VRs). VR environments (VREs) enable new, more immersive visualization design spaces compared to traditional computer screens. Previous studies in different domains, such as medicine, psychology, and geology, report a positive effect of immersion, e.g., on learning performance or phobia treatment effectiveness. Our work presented in this paper assesses the applicability of those findings to a common task from the information visualization (InfoVis) domain. We conducted a quantitative user study to investigate the impact of immersion on cluster identification tasks in scatterplot visualizations. The main experiment was carried out with 18 participants in a within-subjects setting using four different visualizations, (1) a 2D scatterplot matrix on a screen, (2) a 3D scatterplot on a screen, (3) a 3D scatterplot miniature in a VRE and (4) a fully immersive 3D scatterplot in a VRE. The four visualization design spaces vary in their level of immersion, as shown in a supplementary study. The results of our main study indicate that task performance differs between the investigated visualization design spaces in terms of accuracy, efficiency, memorability, sense of orientation, and user preference. In particular, the 2D visualization on the screen performed worse compared to the 3D visualizations with regard to the measured variables. The study shows that an increased level of immersion can be a substantial benefit in the context of 3D data and cluster detection.", "keywords": "Virtual reality,evaluation,visual analytics,clustering", "link": "http://dx.doi.org/10.1109/TVCG.2019.2934395", "refList": ["10.1111/j.1467-9671.2010.01194.x", "10.1177/1473871614556393", "10.1109/tvcg.2008.153", "10.1111/cgf.13430", "10.1109/tvcg.2004.17", "10.1109/tvcg.2015.2467202", "10.1109/tvcg.2007.70433", "10.1089/109493103322011641", "10.2307/2290001", "10.2307/2289444", "10.1016/j.ijhcs.2008.04.004", "10.1109/tvcg.2012.42", "10.1109/vr.2018.8447558", "10.1162/105474602760204318", "10.2307/2986199", "10.3758/bf03200735", "10.1097/opx.0b013e31825da430", "10.1109/infvis.1999.801851", "10.1109/vast.2008.4677350", "10.1162/105474698565686", "10.1109/iv.2013.51", "10.1109/tvcg.2017.2745941", "10.1109/infvis.1998.729555", "10.1111/j.1467-8659.2012.03125.x", "10.1109/2945.506223", "10.1016/s1045-926x(03)00046-6", "10.1097/00042871-200701010-00099", "10.1109/iv.2004.1320137", "10.1109/visual.2002.1183816", "10.1109/tvcg.2018.2864477", "10.1109/vast.2007.4389000", "10.1016/j.ijms.2006.06.015", "10.1007/pl00022704", "10.1111/cgf.13072", "10.1145/3290605.3300555", "10.1109/bdva.2016.7787042", "10.1109/hicss.2013.197", "10.2312/vissym/vissym04/255-260", "10.1115/imece2007-43781", "10.1007/978-4-431-68057-43", "10.1109/tvcg.2016.2520921", "10.1109/mcg.2004.1255801", "10.1109/tvcg.2013.153", "10.1162/pres.1996.5.3.274", "10.1198/106186004x12425", "10.1162/105474601300343612", "10.1162/pres.1997.6.6.603", "10.1111/cgf.12804", "10.1111/j.1467-8659.2009.01666.x", "10.1109/vr.2004.1310069", "10.1109/vr.1999.756938", "10.1007/978-3-658-02897-8\\_16", "10.1162/pres\\_a\\_00016", "10.2307/2288711"], "wos": 1, "children": [{"doi": "10.1109/tvcg.2020.3030456", "title": "Cartographic Relief Shading with Neural Networks", "year": "2020", "conferenceName": "InfoVis", "authors": "Bernhard Jenny;Magnus Heitzler;Dilpreet Singh;Marianna Farmakis-Serebryakova;Jeffery Chieh Liu;Lorenz Hurni", "citationCount": "4", "affiliation": "Jenny, B (Corresponding Author), Monash Univ, Melbourne, Vic, Australia. Jenny, Bernhard; Singh, Dilpreet; Liu, Jeffery Chieh, Monash Univ, Melbourne, Vic, Australia. Heitzler, Magnus; Farmakis-Serebryakova, Marianna; Hurni, Lorenz, Swiss Fed Inst Technol, Inst Cartog \\& Geoinformat, Zurich, Switzerland.", "countries": "Switzerland;Australia", "abstract": "Shaded relief is an effective method for visualising terrain on topographic maps, especially when the direction of illumination is adapted locally to emphasise individual terrain features. However, digital shading algorithms are unable to fully match the expressiveness of hand-crafted masterpieces, which are created through a laborious process by highly specialised cartographers. We replicate hand-drawn relief shading using U-Net neural networks. The deep neural networks are trained with manual shaded relief images of the Swiss topographic map series and terrain models of the same area. The networks generate shaded relief that closely resemble hand-drawn shaded relief art. The networks learn essential design principles from manual relief shading such as removing unnecessary terrain details, locally adjusting the illumination direction to accentuate individual terrain features, and varying brightness to emphasise larger landforms. Neural network shadings are generated from digital elevation models in a few seconds, and a study with 18 relief shading experts found that they are of high quality.", "keywords": "Relief shading,shaded relief,hillshade,neural rendering,illustrative visualisation,image-to-image translation", "link": "http://dx.doi.org/10.1109/TVCG.2020.3030456", "refList": ["10.1145/1456650.1456652", "10.1145/1145/1556262.1556270", "10.1145/345513.345271", "10.1109/tvcg.2019.2934803", "10.1145/3180658", "10.1109/tridui.2006.1618264", "10.3389/fict.2018.00015", "10.1109/vr.2018.8447558", "10.1518/hfes.45.1.160.27234", "10.1145/3290605.3300377", "10.1089/cpb.2006.9.157", "10.1007/s00779-011-0500-3", "10.1109/vl.1996.545307", "10.1109/tvcg.2019.2934415", "10.1109/5.726791", "10.1145/3290605.3300288", "10.1109/tvcg.2017.2745941", "10.1109/vr.2001.913779", "10.1145/586081.586086", "10.18637/jss.v067.i01", "10.1145/1502800.1502805", "10.1145/1165734.1165736", "10.1145/3126594.3126613", "10.1109/tvcg.2008.109", "10.1109/tvcg.2017.2744184", "10.1016/j.cola.2019.100937", "10.1109/visual.2019.8933545", "10.1145/3290605.3300555", "10.1111/cgf.13431", "10.1109/tvcg.2019.2934395", "10.1109/vr.2019.8798340", "10.1145/3025453.3026046", "10.1109/vr.2019.8797871", "10.1145/3290605.3300752", "10.1109/tvcg.2016.2520921", "10.1109/tvcg.2018.2865191", "10.1145/1970378.1970384", "10.1109/tvcg.2019.2934208", "10.18637/jss.v069.i01", "10.1162/105474698565659", "10.1145/1124772.1124775", "10.1109/vrais.1997.583043"], "wos": 1, "children": [], "len": 1}, {"doi": "10.1109/tvcg.2020.3030450", "title": "Shared Surfaces and Spaces: Collaborative Data Visualisation in a Co-located Immersive Environment", "year": "2020", "conferenceName": "InfoVis", "authors": "Benjamin Lee;Xiaoyun Hu;Maxime Cordeil;Arnaud Prouzeau;Bernhard Jenny;Tim Dwyer", "citationCount": "0", "affiliation": "Lee, B (Corresponding Author), Monash Univ, Clayton, Vic, Australia. Lee, Benjamin; Hu, Xiaoyun; Cordeil, Maxime; Prouzeau, Arnaud; Jenny, Bernhard; Dwyer, Tim, Monash Univ, Clayton, Vic, Australia.", "countries": "Australia", "abstract": "Immersive technologies offer new opportunities to support collaborative visual data analysis by providing each collaborator a personal, high-resolution view of a flexible shared visualisation space through a head mounted display. However, most prior studies of collaborative immersive analytics have focused on how groups interact with surface interfaces such as tabletops and wall displays. This paper reports on a study in which teams of three co-located participants are given flexible visualisation authoring tools to allow a great deal of control in how they structure their shared workspace. They do so using a prototype system we call FIESTA: the Free-roaming Immersive Environment to Support Team-based Analysis. Unlike traditional visualisation tools, FIESTA allows users to freely position authoring interfaces and visualisation artefacts anywhere in the virtual environment, either on virtual surfaces or suspended within the interaction space. Our participants solved visual analytics tasks on a multivariate data set, doing so individually and collaboratively by creating a large number of 2D and 3D visualisations. Their behaviours suggest that the usage of surfaces is coupled with the type of visualisation used, often using walls to organise 2D visualisations, but positioning 3D visualisations in the space around them. Outside of tightly-coupled collaboration, participants followed social protocols and did not interact with visualisations that did not belong to them even if outside of its owner's personal workspace.", "keywords": "Immersive analytics,collaboration,virtual reality,qualitative study,multivariate data", "link": "http://dx.doi.org/10.1109/TVCG.2020.3030450", "refList": ["10.1109/tvcg.2008.153", "10.1007/s10606-004-5062-8", "10.1145/3343055.3359718", "10.1109/pacificvis.2019.00010", "10.1109/tvcg.2019.2914677", "10.1016/0020-7373(91)90039-a", "10.1109/tvcg.2011.287", "10.1117/12.2005484", "10.1109/mmul.2009.35", "10.1109/tvcg.2019.2934803", "10.1145/3359996.3364242", "10.1109/immersive.2016.7932384", "10.1016/j.future.2008.07.015", "10.1057/palgrave.ivs.9500167", "10.1109/mcg.2019.2898941", "10.1145/3343055.3360746", "10.1007/978-3-319-45853-3\\_8", "10.1145/2576099", "10.1145/2858036.2858039", "10.1109/tvcg.2016.2599107", "10.1145/3173574.3173664", "10.1007/978-3-030-01388-2\\_2", "10.1109/vr.2019.8797978", "10.1145/3126594.3126613", "10.1109/tvcg.2016.2592906", "10.1109/mcg.2019.2898856", "10.1007/978-3-030-01388-2\\_8", "10.1023/a:1021271517844", "10.1109/bigdata.2014.7004282", "10.1109/tvcg.2019.2934395", "10.1109/ismar.2010.5643530", "10.1007/978-3-030-01388-22", "10.1145/2133806.2133821", "10.1109/3dvis.2014.7160093", "10.1145/2556288.2557058", "10.1109/vr.2019.8797845"], "wos": 1, "children": [], "len": 1}], "len": 5}, "index": 896, "embedding": [1.523298740386963, -0.30501702427864075, 3.1343536376953125, 1.4384424686431885, -0.6897369623184204, 0.16650904715061188, -0.664513111114502, -0.5732959508895874, -0.46884602308273315, -0.9566591382026672, 0.6121384501457214, -0.21123604476451874, -0.1686236411333084, -0.13763785362243652, 2.068377733230591, -0.5263585448265076, 0.691218376159668, 0.06877747178077698, 0.38628026843070984, 0.8653731942176819, -0.06630208343267441, -0.5716211795806885, 0.47211673855781555, -0.1691095381975174, 0.4402097165584564, 0.04334019869565964, -0.5834015607833862, -0.11321822553873062, -0.5749752521514893, 3.2381820678710938, 1.196871280670166, 0.6506552696228027], "projection": [-3.004380941390991, 4.970355987548828], "size": 3, "height": 2, "width": 2}