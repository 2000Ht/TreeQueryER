{"data": {"doi": "10.1111/cgf.13439", "year": "2018", "title": "Rendering and Extracting Extremal Features in 3D Fields", "conferenceName": "EuroVis", "authors": "Gordon L. Kindlmann;Charisee Chiw;T. Huynh;Attila Gyulassy;John H. Reppy;Peer{-}Timo Bremer", "citationCount": "4", "affiliation": "Kindlmann, G (Corresponding Author), Univ Chicago, Dept Comp Sci, Chicago, IL 60637 USA.\nKindlmann, G.; Chiw, C.; Huynh, T.; Reppy, J., Univ Chicago, Dept Comp Sci, Chicago, IL 60637 USA.\nGyulassy, A.; Bremer, P. -T., Univ Utah, SCI Inst, Salt Lake City, UT 84112 USA.", "countries": "USA", "abstract": "Visualizing and extracting three-dimensional features is important for many computational science applications, each with their own feature definitions and data types. While some are simple to state and implement (e.g. isosurfaces), others require more complicated mathematics (e.g. multiple derivatives, curvature, eigenvectors, etc.). Correctly implementing mathematical definitions is difficult, so experimenting with new features requires substantial investments. Furthermore, traditional interpolants rarely support the necessary derivatives, and approximations can reduce numerical stability. Our new approach directly translates mathematical notation into practical visualization and feature extraction, with minimal mental and implementation overhead. Using a mathematically expressive domain-specific language, Diderot, we compute direct volume renderings and particle-based feature samplings for a range of mathematical features. Non-expert users can experiment with feature definitions without any exposure to meshes, interpolants, derivative computation, etc. We demonstrate high-quality results on notoriously difficult features, such as ridges and vortex cores, using working code simple enough to be presented in its entirety.", "keywords": "", "link": "https://doi.org/10.1111/cgf.13439", "refList": ["10.1016/j.procs.2010.04.192", "10.1145/1015706.1015713", "10.1109/visual.1997.663930", "10.1109/tvcg.2009.204", "10.1109/tvcg.2015.2467449", "10.1063/1.857730", "10.1109/icpr.1994.576356", "10.1109/tvcg.2006.149", "10.1145/2345156.2254079", "10.1016/0734-189x(83)90094-4", "10.2140/pjm.1966.16.1", "10.1242/dev.087148", "10.1109/visual.1999.809896", "10.1109/tvcg.2007.70554", "10.1016/s0022-5096(00)00023-5", "10.1109/tvcg.2009.177", "10.1109/pacificvis.2012.6183587", "10.1002/dvdy.22283", "10.1006/cviu.1995.1014", "10.1109/tvcg.2012.218", "10.1109/tvcg.2011.98", "10.1109/tvcg.2009.44", "10.1109/visual.1998.745290", "10.2140/camcos.2016.11.37", "10.1109/tvcg.2009.11", "10.1109/visual.1996.568137", "10.1109/smi.2005.41", "10.1017/s0022112004002526", "10.1109/visual.2003.1250414", "10.1007/s00427-001-0196-x", "10.1109/tvcg.2008.148", "10.1016/j.media.2007.07.005", "10.1145/37402.37422", "10.1002/nbm.1940080707", "10.1111/j.1467-8659.2011.01945.x", "10.1109/38.511", "10.1016/s0091-679x(06)81006-x", "10.1109/34.632985", "10.1017/jfm.2012.257", "10.1017/s0022112095000462", "10.1109/tvcg.2007.1053", "10.1109/visual.2004.105"], "wos": 1, "children": [{"doi": "10.1109/tvcg.2018.2864828", "title": "Objective Vortex Corelines of Finite-sized Objects in Fluid Flows", "year": "2018", "conferenceName": "SciVis", "authors": "Tobias G\u00fcnther;Holger Theisel", "citationCount": "1", "affiliation": "Gunther, T (Corresponding Author), Swiss Fed Inst Technol, Comp Graph Lab, Zurich, Switzerland. Guenther, Tobias, Swiss Fed Inst Technol, Comp Graph Lab, Zurich, Switzerland. Theisel, Holger, Univ Magdeburg, Visual Comp Grp, Magdeburg, Germany.", "countries": "Switzerland;Germany", "abstract": "Vortices are one of the most-frequently studied phenomena in fluid flows. The center of the rotating motion is called the vortex coreline and its successful detection strongly depends on the choice of the reference frame. The optimal frame moves with the center of the vortex, which incidentally makes the observed fluid flow steady and thus standard vortex coreline extractors such as Sujudi-Haimes become applicable. Recently, an objective optimization framework was proposed that determines a near-steady reference frame for tracer particles. In this paper, we extend this technique to the detection of vortex corelines of inertial particles. An inertial particle is a finite-sized object that is carried by a fluid flow. In contrast to the usual tracer particles, they do not move tangentially with the flow, since they are subject to gravity and exhibit mass-dependent inertia. Their particle state is determined by their position and own velocity, which makes the search for the optimal frame a high-dimensional problem. We demonstrate in this paper that the objective detection of an inertial vortex coreline can be reduced in 2D to a critical point search in 2D. For 3D flows, however, the vortex coreline criterion remains a parallel vectors condition in 6D. To detect the vortex corelines we propose a recursive subdivision approach that is tailored to the underlying structure of the 6D vectors. The resulting algorithm is objective, and we demonstrate the vortex coreline extraction in a number of 2D and 3D vector fields.", "keywords": "Vortex extraction,inertial particles,objectivity,vortex coreline", "link": "http://dx.doi.org/10.1109/TVCG.2018.2864828", "refList": ["10.1016/0377-0257(79)87004-4", "10.1111/cgf.12358", "10.1016/0167-2789(91)90088-q", "10.1109/2.35197", "10.1109/tvcg.2016.2599016", "10.5194/npg-22-571-2015", "10.1109/tvcg.2007.70633", "10.1007/978-3-540-70823-0\\_9", "10.1016/b978-012387582-2/50040-x", "10.1111/cgf.12846", "10.1007/s11538-010-9594-4", "10.1017/s002211209900467x", "10.1143/jpsj.66.1331", "10.1063/1.857730", "10.1017/s0022112092001460", "10.1016/s0097-8493(02)00056-0", "10.1017/jfm.2016.151", "10.1175/2009jas2865.1", "10.1111/j.1467-8659.2008.01238.x", "10.1016/j.nonrwa.2014.08.002", "10.1109/visual.1997.663910", "10.1109/visual.1999.809896", "10.1146/annurev.fluid.23.1.601", "10.1109/tvcg.2015.2467200", "10.1145/1057432.1057452", "10.1109/tvcg.2014.2346415", "10.1111/cgf.13114", "10.1007/s100219900068", "10.2514/2.744", "10.1111/cgf.12659", "10.1145/3072959.3073684", "10.1023/a:1001816013475", "10.1007/s10569-015-9617-4", "10.1016/0960-0779(94)90137-6", "10.1016/0010-4655(88)90020-3", "10.1109/visual.1991.175773", "10.1063/1.864230", "10.1088/1742-6596/333/1/012003", "10.1111/cgf.12108", "10.1017/s0022112004002526", "10.1017/s0022112008005089", "10.1007/978-94-007-2482-2\\_30", "10.1016/j.ijengsci.2007.10.005", "10.1111/cgf.12913", "10.1109/tvcg.2009.11", "10.1111/cgf.13439", "10.1016/j.crme.2015.08.002", "10.1109/tvcg.2007.70545", "10.1145/2897824.2925919", "10.1109/visual.1998.745296", "10.1109/tvcg.2016.2599018", "10.1016/j.physd.2007.09.027", "10.1088/0031-8949/2010/t142/014001", "10.1016/0011-7471(70)90059-8", "10.1017/s0022112095000462", "10.1109/tvcg.2007.1053"], "wos": 1, "children": [{"doi": "10.1111/cgf.13689", "year": "2019", "title": "Robust Reference Frame Extraction from Unsteady 2D Vector Fields with Convolutional Neural Networks", "conferenceName": "EuroVis", "authors": "Byungsoo Kim;Tobias G{\\\"{u}}nther", "citationCount": "3", "affiliation": "Kim, B (Corresponding Author), Swiss Fed Inst Technol, Dept Comp Sci, Zurich, Switzerland.\nKim, Byungsoo; Guenther, Tobias, Swiss Fed Inst Technol, Dept Comp Sci, Zurich, Switzerland.", "countries": "Switzerland", "abstract": "Robust feature extraction is an integral part of scientific visualization. In unsteady vector field analysis, researchers recently directed their attention towards the computation of near-steady reference frames for vortex extraction, which is a numerically challenging endeavor. In this paper, we utilize a convolutional neural network to combine two steps of the visualization pipeline in an end-to-end manner: the filtering and the feature extraction. We use neural networks for the extraction of a steady reference frame for a given unsteady 2D vector field. By conditioning the neural network to noisy inputs and resampling artifacts, we obtain numerically stabler results than existing optimization-based approaches. Supervised deep learning typically requires a large amount of training data. Thus, our second contribution is the creation of a vector field benchmark data set, which is generally useful for any local deep learning-based feature extraction. Based on Vatistas velocity profile, we formulate a parametric vector field mixture model that we parameterize based on numerically-computed example vector fields in near-steady reference frames. Given the parametric model, we can efficiently synthesize thousands of vector fields that serve as input to our deep learning architecture. The proposed network is evaluated on an unseen numerical fluid flow simulation.", "keywords": "", "link": "https://doi.org/10.1111/cgf.13689", "refList": ["10.1016/0377-0257(79)87004-4", "10.1111/cgf.12358", "10.1109/tvcg.2018.2864828", "10.1016/0167-2789(91)90088-q", "10.1007/978-3-540-70823-0\\_9", "10.1016/b978-012387582-2/50040-x", "10.1111/cgf.13405", "10.1111/cgf.13319", "10.1109/tvcg.2018.2843369", "10.1007/bf00538235", "10.23940/ijpe.18.03", "10.1017/jfm.2016.151", "10.1109/visual.1999.809896", "10.1146/annurev.fluid.23.1.601", "10.1109/tvcg.2007.1036", "10.1109/tvcg.2018.2864839", "10.1007/978-3-319-54024-5\\_6", "10.1109/tvcg.2013.189", "10.1145/3072959.3073684", "10.1109/tvcg.2015.2467203", "10.2514/2.957", "10.1016/0960-0779(94)90137-6", "10.1109/visual.1991.175773", "10.1109/visual.1996.568137", "10.1017/s0022112004002526", "10.1109/pacificvis.2016.7465253", "10.1007/bf00849110", "10.1007/bf00198434", "10.1109/tvcg.2007.70545", "10.3390/informatics4030027", "10.1137/140983665", "10.1016/0011-7471(70)90059-8", "10.1017/s0022112095000462", "10.1145/1183287.1183290"], "wos": 1, "children": [{"doi": "10.1109/tvcg.2020.3028947", "title": "A Fluid Flow Data Set for Machine Learning and its Application to Neural Flow Map Interpolation", "year": "2020", "conferenceName": "SciVis", "authors": "Jakob Jakob;Markus H. Gross;Tobias G\u00fcnther", "citationCount": "0", "affiliation": "Jakob, J (Corresponding Author), Swiss Fed Inst Technol, Zurich, Switzerland. Jakob, Jakob; Gross, Markus; Guenther, Tobias, Swiss Fed Inst Technol, Zurich, Switzerland.", "countries": "Switzerland", "abstract": "In recent years, deep learning has opened countless research opportunities across many different disciplines. At present, visualization is mainly applied to explore and explain neural networks. Its counterpart-the application of deep learning to visualization problems-requires us to share data more openly in order to enable more scientists to engage in data-driven research. In this paper, we construct a large fluid flow data set and apply it to a deep learning problem in scientific visualization. Parameterized by the Reynolds number, the data set contains a wide spectrum of laminar and turbulent fluid flow regimes. The full data set was simulated on a high-performance compute cluster and contains 8000 time-dependent 2D vector fields, accumulating to more than 16 TB in size. Using our public fluid data set, we trained deep convolutional neural networks in order to set a benchmark for an improved post-hoc Lagrangian fluid flow analysis. In in-situ settings, flow maps are exported and interpolated in order to assess the transport characteristics of time-dependent fluids. Using deep learning, we improve the accuracy of flow map interpolations, allowing a more precise flow analysis at a reduced memory IO footprint.", "keywords": "Scientific visualization,deep learning,flow maps", "link": "http://dx.doi.org/10.1109/TVCG.2020.3028947", "refList": ["10.1007/978-3-319-10593-2\\_25", "10.1145/3355089.3356560", "10.1109/access.2019.2903582", "10.1111/cgf.13405", "10.1109/tmm.2019.2919431", "10.1017/jfm.2016.151", "10.1016/j.physd.2005.10.007", "10.1007/978-3-030-00533-7\\_36", "10.3390/rs11161921", "10.1007/978-3-030-48457-6\\_1", "10.1145/3309993", "10.1109/pacificvis.2018.00018", "10.1109/tvcg.2007.70554", "10.1109/mcg.2018.2881523", "10.1109/cvpr.2016.207", "10.1145/1073204.1073264", "10.1145/3072959.3073643", "10.1109/tpami.2015.2439281", "10.2312/pgv", "10.4208/cicp.oa-2018-0035", "10.1109/cvpr.2017.693", "10.1109/tvcg.2013.128", "10.1109/igarss.2018.8519261", "10.1063/1.3270044", "10.2312/pgv.20191115", "10.1145/3197517.3201304", "10.1145/3065386", "10.1145/1360612.1360649", "10.1109/mcse.2015.103", "10.1145/3355089.3356575", "10.1109/mcg.2018.2881502", "10.1029/2019jd032121", "10.3390/informatics4030027", "10.1109/access.2019.2931781", "10.1007/s12650-018-0523-1", "10.1109/tvcg.2019.2934332", "10.1146/annurev.fluid.32.1.165", "10.1007/978-3-319-46475-6\\_43", "10.1126/science.1127647", "10.1007/978-3-319-46475-6\\_25", "10.1111/cgf.13689"], "wos": 1, "children": [], "len": 1}, {"doi": "10.1109/pacificvis48177.2020.8737", "year": "2020", "title": "SSR-VFD: Spatial Super-Resolution for Vector Field Data Analysis and Visualization", "conferenceName": "PacificVis", "authors": "Li Guo;Shaojie Ye;Jun Han;Hao Zheng;Han Gao;Danny Z. Chen;Jian{-}Xun Wang;Chaoli Wang", "citationCount": "1", "affiliation": "Guo, L (Corresponding Author), Nankai Univ, Tianjin, Peoples R China.\nGuo, Li, Nankai Univ, Tianjin, Peoples R China.\nYe, Shaojie, Zhejiang Univ, Hangzhou, Zhejiang, Peoples R China.\nHan, Jun; Zheng, Hao; Gao, Han; Chen, Danny Z.; Wang, Jian-Xun; Wang, Chaoli, Univ Notre Dame, Notre Dame, IN 46556 USA.", "countries": "USA;China", "abstract": "We present SSR-VFD, a novel deep learning framework that produces coherent spatial super-resolution (SSR) of three-dimensional vector field data (VFD). SSR-VFD is the first work that advocates a machine learning approach to generate high-resolution vector fields from low-resolution ones. The core of SSR-VFD lies in the use of three separate neural nets that take the three components of a low-resolution vector field as input and jointly output a synthesized high-resolution vector field. To capture spatial coherence, we take into account magnitude and angle losses in network optimization. Our method can work in the in situ scenario where VFD are down-sampled at simulation time for storage saving and these reduced VFD are upsampled back to their original resolution during postprocessing. To demonstrate the effectiveness of SSR-VFD, we show quantitative and qualitative results with several vector field data sets of different characteristics and compare our method against volume upscaling using bicubic interpolation, and two solutions based on CNN and GAN, respectively.", "keywords": "Spatial super-resolution; vector field data; convolutional neural network; deep learning", "link": "https://doi.org/10.1109/PacificVis48177.2020.8737", "refList": ["10.1016/j.ijvsm.2017.05.001", "10.1016/j.jvs.2005.01.020", "10.1109/iccv.2015.123", "10.1111/cgf.13620", "10.1109/cvpr.2019.00831", "10.1109/cvpr.2019.00817", "10.1109/cvpr.2019.00399", "10.1109/tvcg.2019.2934312", "10.1145/3309993", "10.1109/pacificvis.2018.00018", "10.1109/tvcg.2018.2816059", "10.1109/mcg.2018.2881523", "10.1109/tpami.2015.2439281", "10.1109/bigdata.2018.8622520", "10.1145/3197517.3201304", "10.1109/tvcg.2018.2796085", "10.1109/tvcg.2019.2934255", "10.1109/cvpr.2016.90", "10.1109/pacificvis.2019.00041", "10.1111/cgf.13689"], "wos": 1, "children": [{"doi": "10.1109/tvcg.2020.3030374", "title": "VC-Net: Deep Volume-Composition Networks for Segmentation and Visualization of Highly Sparse and Noisy Image Data", "year": "2020", "conferenceName": "SciVis", "authors": "Yifan Wang;Guoli Yan;Haikuan Zhu;Sagar Buch;Ying Wang;E. Mark Haacke;Jing Hua;Zichun Zhong", "citationCount": "0", "affiliation": "Wang, YF (Corresponding Author), Wayne State Univ, Dept Comp Sci, Detroit, MI 48202 USA. Wang, Yifan; Yan, Guoli; Zhu, Haikuan; Hua, Jing; Zhong, Zichun, Wayne State Univ, Dept Comp Sci, Detroit, MI 48202 USA. Buch, Sagar; Wang, Ying; Haacke, Ewart Mark, Wayne State Univ, Dept Radiol, Detroit, MI 48201 USA.", "countries": "USA", "abstract": "The fundamental motivation of the proposed work is to present a new visualization-guided computing paradigm to combine direct 3D volume processing and volume rendered clues for effective 3D exploration. For example, extracting and visualizing microstructures in-vivo have been a long-standing challenging problem. However, due to the high sparseness and noisiness in cerebrovasculature data as well as highly complex geometry and topology variations of micro vessels, it is still extremely challenging to extract the complete 3D vessel structure and visualize it in 3D with high fidelity. In this paper, we present an end-to-end deep learning method, VC-Net, for robust extraction of 3D microvascular structure through embedding the image composition, generated by maximum intensity projection (MIP), into the 3D volumetric image learning process to enhance the overall performance. The core novelty is to automatically leverage the volume visualization technique (e.g., MIP - a volume rendering scheme for 3D volume images) to enhance the 3D data exploration at the deep learning level. The MIP embedding features can enhance the local vessel signal (through canceling out the noise) and adapt to the geometric variability and scalability of vessels, which is of great importance in microvascular tracking. A multi-stream convolutional neural network (CNN) framework is proposed to effectively learn the 3D volume and 2D MIP feature vectors, respectively, and then explore their inter-dependencies in a joint volume-composition embedding space by unprojecting the 2D feature vectors into the 3D volume embedding space. It is noted that the proposed framework can better capture the small/micro vessels and improve the vessel connectivity. To our knowledge, this is the first time that a deep learning framework is proposed to construct a joint convolutional embedding space, where the computed vessel probabilities from volume rendering based 2D projection and 3D volume can be explored and integrated synergistically. Experimental results are evaluated and compared with the traditional 3D vessel segmentation methods and the state-of-the-art in deep learning, by using extensive public and real patient (micro- )cerebrovascular image datasets. The application of this accurate segmentation and visualization of sparse and complicated 3D microvascular structure facilitated by our method demonstrates the potential in a powerful MR arteriogram and venogram diagnosis of vascular disease.", "keywords": "Deep neural network,3D cerebrovascular segmentation and visualization,maximum intensity projection (MIP),joint embedding", "link": "http://dx.doi.org/10.1109/TVCG.2020.3030374", "refList": ["10.1109/cluster.2018.00036", "10.1109/iccv.2015.123", "10.1109/tvcg.2013.133", "10.1109/cvpr.2017.19", "10.1109/tvcg.2019.2934312", "10.1007/978-3-319-46487-9\\_40", "10.1109/tvcg.2006.175", "10.1109/tvcg.2007.70523", "10.1109/tvcg.2018.2880207", "10.1145/3309993", "10.1109/pacificvis.2018.00018", "10.1109/iccv.2017.244", "10.1109/cvpr.2017.632", "10.1109/tvcg.2018.2816059", "10.1109/pacificvis.2009.4906852", "10.1109/tvcg.2018.2864808", "10.1109/mcg.2018.2881523", "10.1109/tvcg.2015.2467431", "10.1109/tpami.2015.2439281", "10.1109/pacificvis48177.2020.8737", "10.1109/cvpr.2019.00244", "10.1109/tvcg.2006.165", "10.1109/bigdata.2018.8622520", "10.1007/978-3-319-46466-4\\_29", "10.1109/visual.2019.8933759", "10.1145/3197517.3201304", "10.1109/pacificvis.2011.5742378", "10.1109/cvpr.2006.91", "10.1109/pacificvis.2011.5742369", "10.1109/tvcg.2019.2934255", "10.1109/cvpr.2016.90", "10.1007/978-3-319-24574-4\\_28", "10.1109/pacificvis.2019.00041", "10.1109/tvcg.2019.2934332", "10.1109/cvpr.2018.00916", "10.1007/978-3-319-46475-6\\_43"], "wos": 1, "children": [], "len": 1}], "len": 3}], "len": 7}], "len": 9}, {"doi": "10.1109/tvcg.2019.2934310", "title": "Extraction and Visual Analysis of Potential Vorticity Banners around the Alps", "year": "2019", "conferenceName": "SciVis", "authors": "Robin Bader;Michael Sprenger;Nikolina Ban;Stefan R\u00fcdis\u00fchli;Christoph Sch\u00e4r;Tobias G\u00fcnther", "citationCount": "0", "affiliation": "Bader, R (Corresponding Author), Swiss Fed Inst Technol, Dept Comp Sci, Zurich, Switzerland. Bader, Robin; Guenther, Tobias, Swiss Fed Inst Technol, Dept Comp Sci, Zurich, Switzerland. Sprenger, Michael; Ban, Nikolina; Ruedisuehli, Stefan; Schaer, Christoph, Swiss Fed Inst Technol, Inst Atmospher \\& Climate Sci, Zurich, Switzerland.", "countries": "Switzerland", "abstract": "Potential vorticity is among the most important scalar quantities in atmospheric dynamics. For instance, potential vorticity plays a key role in particularly strong wind peaks in extratropical cyclones and it is able to explain the occurrence of frontal rain bands. Potential vorticity combines the key quantities of atmospheric dynamics, namely rotation and stratification. Under suitable wind conditions elongated banners of potential vorticity appear in the lee of mountains. Their role in atmospheric dynamics has recently raised considerable interest in the meteorological community for instance due to their influence in aviation wind hazards and maritime transport. In order to support meteorologists and climatologists in the analysis of these structures, we developed an extraction algorithm and a visual exploration framework consisting of multiple linked views. For the extraction we apply a predictor-corrector algorithm that follows streamlines and realigns them with extremal lines of potential vorticity. Using the agglomerative hierarchical clustering algorithm, we group banners from different sources based on their proximity. To visually analyze the time-dependent banner geometry, we provide interactive overviews and enable the query for detail on demand, including the analysis of different time steps, potentially correlated scalar quantities, and the wind vector field. In particular, we study the relationship between relative humidity and the banners for their potential in indicating the development of precipitation. Working with our method, the collaborating meteorologists gained a deeper understanding of the three-dimensional processes, which may spur follow-up research in the future.", "keywords": "Scientific Visualization,potential vorticity,meteorology,feature extraction", "link": "http://dx.doi.org/10.1109/TVCG.2019.2934310", "refList": ["10.1002/qj.49710042520", "10.1111/j.1467-8659.2009.01702.x", "10.1111/cgf.13319", "10.1175/1520-0469(1998)055", "10.1007/bf01475602", "10.1143/jpsj.66.1331", "10.1109/tvcg.2013.2297914", "10.1007/978-3-540-88606-8\\_6", "10.1175/1520-0477(2001)082", "10.1175/mwr-d-16-0042.1", "10.1007/s00703-001-0592-9", "10.1002/qj.49710544615", "10.1111/cgf.13163", "10.1007/bf01446807", "10.1109/visual.1994.346327", "10.1109/visual.1999.809896", "10.1109/tvcg.2011.78", "10.1109/tvcg.2015.2467200", "10.2514/2.744", "10.1145/1013208.1013209", "10.1007/978-3", "10.1111/cgf.12933", "10.1175/1520-0477(2002)083", "10.1007/978-94-015-8765-5", "10.1175/2011mwr3504.1", "10.1007/s007030170008", "10.5194/gmd-9-3393-2016", "10.1175/bams-d-15-00299.1", "10.1002/2014gl062588", "10.1256/smsqj.47001", "10.1175/2010mwr3334.1", "10.1109/tvcg.2017.2779501", "10.1256/qj.02.47", "10.1111/cgf.13439", "10.5194/gmd-2017-230", "10.1109/visual.2003.1250376", "10.14529/jsfi140103", "10.1109/tvcg.2017.2743989", "10.1109/tvcg.2007.70545", "10.1111/j.1467-8659.2003.00723.x", "10.1109/tvcg.2007.1053", "10.1002/qj.828", "10.1002/2016jd026013", "10.1007/bf01450097"], "wos": 1, "children": [], "len": 1}, {"doi": "10.1111/cgf.13984", "year": "2020", "title": "Visual Analysis of the Finite-Time Lyapunov Exponent", "conferenceName": "EuroVis", "authors": "Antoni Sagrist{\\`{a}};Stefan Jordan;Filip Sadlo", "citationCount": "0", "affiliation": "Sagrista, A (Corresponding Author), Heidelberg Univ, Heidelberg, Germany.\nSagrista, Antoni; Jordan, Stefan; Sadlo, Filip, Heidelberg Univ, Heidelberg, Germany.", "countries": "Germany", "abstract": "In this paper, we present an integrated visual analytics approach to support the parametrization and exploration of flow visualization based on the finite-time Lyapunov exponent. Such visualization of time-dependent flow faces various challenges, including the choice of appropriate advection times, temporal regions of interest, and spatial resolution. Our approach eases these challenges by providing the user with context by means of parametric aggregations, with support and guidance for a more directed exploration, and with a set of derived measures for better qualitative assessment. We demonstrate the utility of our approach with examples from computation fluid dynamics and time-dependent dynamical systems.", "keywords": "", "link": "https://doi.org/10.1111/cgf.13984", "refList": ["10.1145/37402.37422", "10.1109/38.79452", "10.1016/j.parco.2011.09.001", "10.1016/j.physd.2005.10.007", "10.1109/2.35197", "10.1109/tvcg.2007.70551", "10.1016/s0167-2789(00)00199-8", "10.1109/tvcg.2016.2599018", "10.1109/tvcg.2017.2743938", "10.1109/tvcg.2015.2467449", "10.2307/2003354", "10.1109/tvcg.2007.70554", "10.1090/s0002-9904-1967-11798-1", "10.1109/visual.2005.1532788", "10.1017/s0022112004009929", "10.1111/j.1467-8659.2011.01901.x", "10.1111/cgf.13439", "10.1111/cgf.12933"], "wos": 1, "children": [], "len": 1}], "len": 15}, "index": 1475, "embedding": [2.114097833633423, 0.8012467622756958, -1.030107021331787, 0.5518006682395935, -0.04011833295226097, 0.16650904715061188, -0.7323254346847534, 1.3928343057632446, 1.0889935493469238, 0.7323812246322632, 0.9843894839286804, 0.8936830163002014, 0.45895612239837646, 1.1958662271499634, -0.804432213306427, 1.2703438997268677, 0.7563071250915527, 0.07072390615940094, -0.5860064625740051, 2.892183542251587, -0.06630208343267441, 0.34751397371292114, -0.12865427136421204, 1.4185941219329834, -2.224714994430542, 2.044567584991455, -0.5452967882156372, -0.1320013552904129, 1.7871015071868896, -1.6385117769241333, 0.08718807995319366, 0.39519044756889343], "projection": [-0.9662377834320068, 7.399230003356934], "size": 8, "height": 5, "width": 3}