{"data": {"doi": "10.1109/tvcg.2014.2346753", "title": "Genotet: An Interactive Web-based Visual Exploration Framework to Support Validation of Gene Regulatory Networks", "year": "2014", "conferenceName": "VAST", "authors": "Bowen Yu 0004;Harish Doraiswamy;Xi Chen;Emily R. Miraldi;Mario Luis Arrieta-Ortiz;Christoph Hafemeister;Aviv Madar;Richard Bonneau;Cl\u00e1udio T. Silva", "citationCount": "9", "affiliation": "Yu, BW (Corresponding Author), NYU, Polytech Sch Engn, New York, NY 10003 USA. Yu, Bowen; Doraiswamy, Harish; Silva, Claudio T., NYU, Polytech Sch Engn, New York, NY 10003 USA. Chen, Xi; Miraldi, Emily; Arrieta-Ortiz, Mario Luis; Hafemeister, Christoph; Bonneau, Richard, NYU, Ctr Genom \\& Syst Biol, New York, NY 10003 USA. Madar, Aviv, Cornell Univ, Ithaca, NY 14853 USA.", "countries": "USA", "abstract": "Elucidation of transcriptional regulatory networks (TRNs) is a fundamental goal in biology, and one of the most important components of TRNs are transcription factors (TFs), proteins that specifically bind to gene promoter and enhancer regions to alter target gene expression patterns. Advances in genomic technologies as well as advances in computational biology have led to multiple large regulatory network models (directed networks) each with a large corpus of supporting data and gene-annotation. There are multiple possible biological motivations for exploring large regulatory network models, including: validating TF-target gene relationships, figuring out co-regulation patterns, and exploring the coordination of cell processes in response to changes in cell state or environment. Here we focus on queries aimed at validating regulatory network models, and on coordinating visualization of primary data and directed weighted gene regulatory networks. The large size of both the network models and the primary data can make such coordinated queries cumbersome with existing tools and, in particular, inhibits the sharing of results between collaborators. In this work, we develop and demonstrate a web-based framework for coordinating visualization and exploration of expression data (RNA-seq, microarray), network models and gene-binding data (ChIP-seq). Using specialized data structures and multiple coordinated views, we design an efficient querying model to support interactive analysis of the data. Finally, we show the effectiveness of our framework through case studies for the mouse immune system (a dataset focused on a subset of key cellular functions) and a model bacteria (a small genome with high data-completeness).", "keywords": "Web-based visualization, gene regulatory network", "link": "http://dx.doi.org/10.1109/TVCG.2014.2346753", "refList": ["10.1109/tvcg.2009.167", "10.1101/gr.1239303", "10.1109/tvcg.2008.117", "10.1126/science.1105136", "10.1038/nchembio.122", "10.1126/science.270.5235.467", "10.1093/nar/gkg083", "10.1038/nmeth.2688", "10.1016/j.cell.2012.09.016", "10.1186/1471-2164-14-289", "10.1111/j.1467-8659.2009.01710.x", "10.1093/bib/bbs017", "10.1186/1471-2105-7-176", "10.1101/gr.4074106", "10.1109/tvcg.2009.146", "10.1093/nar/gks1172", "10.1038/nprot.2007.324", "10.1016/j.cub.2010.06.031", "10.1038/nbt.1754", "10.1101/gr.5533506", "10.1038/nrg2484"], "wos": 1, "children": [{"doi": "10.1109/tvcg.2016.2598497", "title": "VisFlow - Web-based Visualization Framework for Tabular Data with a Subset Flow Model", "year": "2016", "conferenceName": "VAST", "authors": "Bowen Yu 0004;Cl\u00e1udio T. Silva", "citationCount": "11", "affiliation": "Yu, BW (Corresponding Author), New York Univ, New York, NY USA. Yu, Bowen; Silva, Claudio T., New York Univ, New York, NY USA.", "countries": "USA", "abstract": "Data flow systems allow the user to design a flow diagram that specifies the relations between system components which process, filter or visually present the data. Visualization systems may benefit from user-defined data flows as an analysis typically consists of rendering multiple plots on demand and performing different types of interactive queries across coordinated views. In this paper, we propose VisFlow, a web-based visualization framework for tabular data that employs a specific type of data flow model called the subset flow model. VisFlow focuses on interactive queries within the data flow, overcoming the limitation of interactivity from past computational data flow systems. In particular, VisFlow applies embedded visualizations and supports interactive selections, brushing and linking within a visualization-oriented data flow. The model requires all data transmitted by the flow to be a data item subset (i.e. groups of table rows) of some original input table, so that rendering properties can be assigned to the subset unambiguously for tracking and comparison. VisFlow features the analysis flexibility of a flow diagram, and at the same time reduces the diagram complexity and improves usability. We demonstrate the capability of VisFlow on two case studies with domain experts on real-world datasets showing that VisFlow is capable of accomplishing a considerable set of visualization and analysis tasks. The VisFlow system is available as open source on GitHub.", "keywords": "Visualization framework;data flow;subset flow model;tabular data", "link": "http://dx.doi.org/10.1109/TVCG.2016.2598497", "refList": ["10.1109/tvcg.2014.2346753", "10.1109/38.31462", "10.1177/1473871611416549", "10.1016/0167-739x(87)90033-1", "10.1109/tvcg.2009.195", "10.1109/visual.2005.1532788", "10.1002/cpe.994", "10.1109/tvcg.2011.185", "10.1016/s0167-8191(99)00070-8", "10.1109/vl.1996.545307", "10.1111/cgf.12131", "10.1016/j.cell.2012.09.016", "10.1109/infvis.2005.1532136", "10.1057/palgrave.ivs.9500020", "10.1117/12.309533", "10.1093/nar/gkt328", "10.1109/mcg.2009.130", "10.1109/infvis.2004.12", "10.1109/tvcg.2014.2346291", "10.1109/infvis.1998.729560", "10.1117/12.342832", "10.1109/vast.2011.6102440", "10.1007/11890850\\_2", "10.1109/infvis.2003.1249013"], "wos": 1, "children": [{"doi": "10.1109/tvcg.2019.2934668", "title": "FlowSense: A Natural Language Interface for Visual Data Exploration within a Dataflow System", "year": "2019", "conferenceName": "VAST", "authors": "Bowen Yu 0004;Cl\u00e1udio T. Silva", "citationCount": "4", "affiliation": "Yu, BW (Corresponding Author), NYU, New York, NY 10003 USA. Yu, Bowen; Silva, Claudio T., NYU, New York, NY 10003 USA.", "countries": "USA", "abstract": "Dataflow visualization systems enable flexible visual data exploration by allowing the user to construct a dataflow diagram that composes query and visualization modules to specify system functionality. However learning dataflow diagram usage presents overhead that often discourages the user. In this work we design FlowSense, a natural language interface for dataflow visualization systems that utilizes state-of-the-art natural language processing techniques to assist dataflow diagram construction. FlowSense employs a semantic parser with special utterance tagging and special utterance placeholders to generalize to different datasets and dataflow diagrams. It explicitly presents recognized dataset and diagram special utterances to the user for dataflow context awareness. With FlowSense the user can expand and adjust dataflow diagrams more conveniently via plain English. We apply FlowSense to the VisFlow subset-flow visualization system to enhance its usability. We evaluate FlowSense by one case study with domain experts on a real-world data analysis problem and a formal user study.", "keywords": "Natural language interface,dataflow visualization system,visual data exploration", "link": "http://dx.doi.org/10.1109/TVCG.2019.2934668", "refList": ["10.1109/38.31462", "10.1145/1292609.1292620", "10.1109/visual.2005.1532788", "10.1109/tvcg.2007.70594", "10.1017/s135132490000005x.http://j0urnals.cambridge.0rg/article\\_", "10.1145/3025171.3025227", "10.1109/vl.1996.545307", "10.1111/cgf.12131", "10.1109/mci.2018.2840738", "10.3115/v1/p14-5010", "10.1109/tvcg.2017.2744684", "10.1109/infvis.2005.1532136", "10.1109/tvcg.2017.2745219", "10.1145/2984511.2984588", "10.1117/12.309533", "10.1093/nar/gkt328", "10.1109/tvcg.2012.323", "10.1017/s135132490000005x", "10.1109/mcg.2009.130", "10.1146/annurev-linguist-030514-125312", "10.1023/a:1011368926479", "10.1145/375360.375365", "10.1111/cgf.12628", "10.1145/2807442.2807478", "10.1109/tvcg.2010.164", "10.1109/tvcg.2016.2598497", "10.1109/tse.1986.6312901", "10.1117/12.342832"], "wos": 1, "children": [{"doi": "10.1111/cgf.14035", "year": "2020", "title": "Survey on the Analysis of User Interactions and Visualization Provenance", "conferenceName": "EuroVis", "authors": "Kai Xu;Alvitta Ottley;Conny Walchshofer;Marc Streit;Remco Chang;John E. Wenskovitch", "citationCount": "0", "affiliation": "Xu, K (Corresponding Author), Middlesex Univ, London, England.\nXu, Kai, Middlesex Univ, London, England.\nOttley, Alvitta, Washington Univ, St Louis, MO 63110 USA.\nWalchshofer, Conny; Streit, Marc, Johannes Kepler Univ Linz, Linz, Austria.\nChang, Remco, Tufts Univ, Medford, MA 02155 USA.\nWenskovitch, John, Virginia Tech, Blacksburg, VA USA.", "countries": "USA;England;Austria", "abstract": "There is fast-growing literature on provenance-related research, covering aspects such as its theoretical framework, use cases, and techniques for capturing, visualizing, and analyzing provenance data. As a result, there is an increasing need to identify and taxonomize the existing scholarship. Such an organization of the research landscape will provide a complete picture of the current state of inquiry and identify knowledge gaps or possible avenues for further investigation. In this STAR, we aim to produce a comprehensive survey of work in the data visualization and visual analytics field that focus on the analysis of user interaction and provenance data. We structure our survey around three primary questions: (1) WHY analyze provenance data, (2) WHAT provenance data to encode and how to encode it, and (3) HOW to analyze provenance data. A concluding discussion provides evidence-based guidelines and highlights concrete opportunities for future development in this emerging area. The survey and papers discussed can be explored online interactively at https://provenance-survey.caleydo.org.", "keywords": "", "link": "https://doi.org/10.1111/cgf.14035", "refList": ["10.1145/3186266", "10.1145/3185524", "10.1109/tvcg.2014.2346575", "10.1109/tvcg.2016.2598471", "10.1109/tvcg.2016.2598446", "10.1145/2856767.2856779", "10.1109/tvcg.2017.2745278", "10.1109/tvcg.2015.2467871", "10.1109/tvcg.2019.2934668", "10.1145/3301275.3302307", "10.1145/2207676.2208293", "10.1111/cgf.13402", "10.1111/cgf.12895", "10.1145/1084805.1084812", "10.1145/2983923", "10.1007/978-1-4419-5874-7\\_12", "10.1109/mcg.2010.18", "10.1109/tvcg.2015.2467153", "10.1109/tvcg.2013.211", "10.1145/3172944.3172964", "10.1145/3290605.3300360", "10.1109/tvcg.2009.199", "10.1109/vast.2016.7883515", "10.1145/2207676.2208412", "10.1145/1979742.1979570", "10.1145/2207676.2208565", "10.1109/tvcg.2017.2745078", "10.1109/tvcg.2013.226", "10.1145/3301275.3302270", "10.1145/2882903.2882919", "10.1109/tvcg.2013.132", "10.1007/978-1-4614-3223-4\\_6", "10.1007/978-1-4899-7993-3\\_80747-1", "10.1145/2449396.2449439", "10.4230/dagrep.8.11.35", "10.1111/cgf.13424", "10.1109/tvcg.2015.2467613", "10.1109/mcse.2007.106", "10.1109/vast.2014.7042486", "10.1145/3126594.3126653", "10.1145/2591510", "10.1109/vast.2017.8585665", "10.1109/tvcg.2017.2744684", "10.1109/vast.2009.5333564", "10.1111/cgf.12631", "10.1145/2702123.2702262", "10.1111/cgf.13717", "10.2312/evs.20191181", "10.1111/cgf.12925", "10.1145/2702123.2702590", "10.1109/tvcg.2015.2467551", "10.1145/3025171.3025187", "10.1145/3316416.3316418", "10.1109/tvcg.2015.2468078", "10.1109/mcg.2014.73", "10.1109/tvcg.2017.2744479", "10.1109/tvcg.2018.2859969", "10.1109/tvcg.2014.2346321", "10.1109/tvcg.2007.70589", "10.1007/s13218-012-0167-6", "10.1111/cgf.13670", "10.1145/2807442.2807478", "10.1111/cgf.13715", "10.1109/tvcg.2012.23", "10.1109/tvcg.2017.2745279", "10.1109/tvcg.2013.164", "10.1109/vast.2008.4677365", "10.1145/3301275.3302291", "10.1109/tvcg.2012.260", "10.1109/tvcg.2010.177", "10.1109/tvcg.2018.2865024", "10.1109/mcg.2015.51", "10.1145/2240236.2240260", "10.1109/tvcg.2016.2599030.2", "10.1109/tvcg.2007.70515", "10.1109/tvcg.2012.175", "10.1109/mcg.2019.2941856", "10.1109/tvcg.2008.137", "10.1016/j.visinf.2018.09.003", "10.4304/jmm.9.5.635-643", "10.1109/tvcg.2017.2744843", "10.1111/cgf.13405", "10.1145/2633043", "10.1109/tvcg.2009.129", "10.1109/tvcg.2019.2934609", "10.1111/cgf.12924", "10.1145/2702123.2702376", "10.1109/vast.2017.8585669", "10.1145/1502650.1502695", "10.1111/cgf.13730", "10.1109/tvcg.2013.124", "10.1109/tvcg.2017.2744805", "10.1109/mcg.2009.49", "10.1109/vast.2015.7347625", "10.1145/3009973", "10.1145/2470654.2470723", "10.1109/vast.2016.7883520", "10.1109/vast.2014.7042492", "10.1145/2984511.2984588", "10.1111/cgf.12391", "10.1561/1900000006", "10.1007/s00778-017-0486-1", "10.1109/vast.2009.5333020", "10.1145/1926385.1926423", "10.1145/1057977.1057978", "10.1145/3290605.3300892", "10.1111/j.1467-8659.2011.01928.x", "10.1109/tvcg.2013.188", "10.1109/tvcg.2015.2467191", "10.1109/iccicct.2014.6993023", "10.1145/3290605.3300874", "10.1145/2557500.2557524", "10.1109/mcg.2015.91", "10.1109/vast.2012.6400494", "10.1109/tvcg.2013.220", "10.1109/mcg.2019.2945378", "10.1109/vast.2012.6400486", "10.1109/tvcg.2018.2865158", "10.1109/tvcg.2016.2598839", "10.1145/1142473.1142574", "10.1177/1555343416672782", "10.1109/vast.2011.6102449", "10.1111/cgf.12090", "10.1109/vast.2016.7883518", "10.1111/cgf.13678", "10.1109/mcg.2009.53", "10.1109/tvcg.2014.2346250", "10.1109/tvcg.2016.2598797", "10.1111/cgf.13400", "10.1109/tvcg.2014.2346573", "10.1080/01431160600746456", "10.1145/2642918.2647378", "10.1109/mcg.2019.2945720", "10.1145/2207676.2207741", "10.1145/3025171.3025189", "10.1145/634067.634292", "10.1109/tvcg.2015.2467611", "10.1109/tit.1982.1056489", "10.1109/tvcg.2018.2865117", "10.1109/vast.2009.5333023", "10.1145/3332165.3347866", "10.1109/mcg.2019.2933419", "10.1145/3184900", "10.1109/tvcg.2012.273", "10.1109/vast.2010.5652885", "10.1109/vast.2015.7347627", "10.1145/3290605.3300803", "10.1109/tvcg.2012.258", "10.1109/mcg.2009.87", "10.1109/tvcg.2019.2934556", "10.1145/1869397.1869399", "10.1109/mcg.2015.50", "10.1145/3172944.3172979", "10.1111/cgf.13208", "10.1111/cgf.12619", "10.1145/3290605.3300358", "10.1109/vast.2008.4677352", "10.1109/tvcg.2016.2598468", "10.1109/vast.2016.7883519", "10.1109/mcse.2008.79"], "wos": 1, "children": [], "len": 1}], "len": 3}], "len": 5}, {"doi": "10.1109/tvcg.2020.3030411", "title": "Co-Bridges: Pair-wise Visual Connection and Comparison for Multi-item Data Streams", "year": "2020", "conferenceName": "VAST", "authors": "Siming Chen;Natalia V. Andrienko;Gennady L. Andrienko;Jie Li 0006;Xiaoru Yuan", "citationCount": "0", "affiliation": "Yuan, XR (Corresponding Author), Peking Univ, Beijing, Peoples R China. Chen, Siming, Fudan Univ, Sch Data Sci, Shanghai, Peoples R China. Chen, Siming; Andrienko, Natalia; Andrienko, Gennady, Fraunhofer Inst IAIS, St Augustin, Germany. Andrienko, Natalia; Andrienko, Gennady, City Univ London, London, England. Li, Jie, Tianjin Univ, Tianjin, Peoples R China. Yuan, Xiaoru, Peking Univ, Beijing, Peoples R China.", "countries": "Germany;China;England", "abstract": "In various domains, there are abundant streams or sequences of multi-item data of various kinds, e.g. streams of news and social media texts, sequences of genes and sports events, etc. Comparison is an important and general task in data analysis. For comparing data streams involving multiple items (e.g., words in texts, actors or action types in action sequences, visited places in itineraries, etc.), we propose Co-Bridges, a visual design involving connection and comparison techniques that reveal similarities and differences between two streams. Co-Bridges use river and bridge metaphors, where two sides of a river represent data streams, and bridges connect temporally or sequentially aligned segments of streams. Commonalities and differences between these segments in terms of involvement of various items are shown on the bridges. Interactive query tools support the selection of particular stream subsets for focused exploration. The visualization supports both qualitative (common and distinct items) and quantitative (stream volume, amount of item involvement) comparisons. We further propose Comparison-of-Comparisons, in which two or more Co-Bridges corresponding to different selections are juxtaposed. We test the applicability of the Co-Bridges in different domains, including social media text streams and sports event sequences. We perform an evaluation of the users' capability to understand and use Co-Bridges. The results confirm that Co-Bridges is effective for supporting pair-wise visual comparisons in a wide range of applications.", "keywords": "Visual Comparison,Pair-wise Analysis,Multi-item Data Stream,Social Media", "link": "http://dx.doi.org/10.1109/TVCG.2020.3030411", "refList": ["10.1109/tvcg.2014.2346753", "10.1109/pacificvis.2010.5429590", "10.1109/vast.2009.5333443", "10.1101/gr.2289704", "10.1177/1473871611416549", "10.1057/palgrave.ivs.9500099", "10.1109/vast.2017.8585638", "10.1109/vast.2014.7042496", "10.1109/tvcg.2017.2764459", "10.1109/tvcg.2013.221", "10.1109/vast.2011.6102439", "10.1109/tvcg.2013.213", "10.1109/tmm.2016.2614220", "10.1109/tvcg.2016.2598797", "10.1145/2207676.2208556", "10.1145/1835804.1835827", "10.1109/tvcg.2013.124", "10.2312/conf/eg2013/stars/039-063", "10.1111/cgf.13211", "10.1109/tvcg.2014.2346920", "10.1109/tvcg.2011.239", "10.1016/j.jvlc.2018.08.008", "10.1109/mcg.2018.032421661", "10.1109/tvcg.2017.2744199", "10.1109/tvcg.2019.2934535", "10.1109/tvcg.2018.2864526", "10.1007/978-0-85729-436-4\\_9", "10.1109/vast.2016.7883511", "10.1109/tvcg.2014.2346682", "10.1109/tvcg.2015.2467618", "10.1145/2566486.2567977", "10.1109/tvcg.2017.2745320", "10.1080/136588199241247", "10.1111/cgf.13401", "10.1109/tvcg.2018.2864884", "10.1109/tvcg.2012.291", "10.1109/vast.2012.6400485", "10.1109/pacificvis.2016.7465266", "10.1109/tvcg.2011.232", "10.1109/tvcg.2017.2745083", "10.1109/tvcg.2012.253", "10.1007/s12650-014-0246-x", "10.1109/tvcg.2010.20", "10.1109/tvcg.2014.2346919", "10.1109/visual.2019.8933646", "10.1007/978-0-85729-079-3"], "wos": 1, "children": [], "len": 1}, {"doi": "10.1109/pacificvis.2017.8031597", "year": "2017", "title": "Quasi-biclique edge concentration: A visual analytics method for biclustering", "conferenceName": "PacificVis", "authors": "Yosuke Onoue;Koji Koyamada", "citationCount": "2", "affiliation": "Onoue, Y (Corresponding Author), Kyoto Univ, Kyoto, Japan.\nOnoue, Yosuke; Koyamada, Koji, Kyoto Univ, Kyoto, Japan.", "countries": "Japan", "abstract": "Biclustering is a well-known approach for data mining, and it is applied in many fields, such as genome analyses, security services, and social network analyses. Biclustering finds bicliques contained in a bipartite graph. However, in real data, a biclique may lack several edges because of various reasons, such as errors. In this situation, traditional biclustering methods cannot find correct biclusters. A novel biclustering method that can analyze real data under uncertainty is needed. Quasi-biclique is a mathematical concept that represents incomplete bicliques. We propose the quasi-biclique edge concentration (QBEC) method, which is a visual analysis method for biclustering using quasi-biclique mining. QBEC includes visual representations and user interactions for quasi-bicliques. Quasibicliques contained in a bipartite graph are represented based on edge concentration. The incompleteness of a quasi-biclique is reflected in edge opacity. Users can interactively explore data by adjusting the incompleteness parameter of the quasi-biclique. We demonstrate the effectiveness of QBEC using real-world data.", "keywords": "G.2.2 {[}Discrete Mathematics]: Graph Theory-Graph Algorithms; H.3.3 {[}Information Storage and Retrieval]: Information Search and Retrieval-Clustering", "link": "https://doi.org/10.1109/PACIFICVIS.2017.8031597", "refList": ["10.1109/tvcg.2014.2346753", "10.1109/tvcg.2015.2467813", "10.1109/bigdata.congress.2013.53", "10.1109/tvcg.2016.2534519", "10.1016/j.jbi.2015.06.028", "10.1109/tvcg.2013.77", "10.1093/nar/gkg340", "10.1109/vl.1996.545307", "10.1007/s10618-012-0258-x", "10.1016/j.ins.2010.08.035", "10.1177/0047287510394192", "10.1007/978-1-4419-6045-0", "10.1016/j.cor.2007.01.005", "10.1007/s10878-011-9392-4", "10.1109/tvcg.2014.2346665", "10.1093/nar/gks1107", "10.1016/j.biotechadv.2007.12.002", "10.1109/tsmc.1981.4308636", "10.1016/j.ympev.2005.02.008", "10.1109/tcbb.2008.61", "10.1145/1880022.1880030", "10.1109/tkde.2005.60"], "wos": 1, "children": [{"doi": "10.1109/pacificvis.2018.00012", "year": "2018", "title": "Development of an Integrated Visualization System for Phenotypic Character Networks", "conferenceName": "PacificVis", "authors": "Yosuke Onoue;Koji Kyoda;Miki Kioka;Kazutaka Baba;Shuichi Onami;Koji Koyamada", "citationCount": "0", "affiliation": "Onoue, Y (Corresponding Author), Kyoto Univ, Kyoto, Japan.\nOnoue, Yosuke; Kioka, Miki; Koyamada, Koji, Kyoto Univ, Kyoto, Japan.\nKyoda, Koji; Onami, Shuichi, RIKEN, Tokyo, Japan.\nBaba, Kazutaka, JP DOT COM Co Ltd, Tokyo, Japan.", "countries": "Japan", "abstract": "visually integrating the initiation and developmental processes of organisms, we might reveal new causalities in biological data. Here we present an integrated visualization system for a causality network constructed from phenotypic developmental characters and their related scientific literature. To obtain the phenotypic characters, we applied bio-imaging informatics techniques to the data of wet experiments. The phenotypic character network was visually rendered in the CausalNet system, which provides both explanatory and verification visualization functions. Statistical analysis and scientific literature mining proved useful for determining the mechanisms underlying the phenotypic character network. The validity of the system was confirmed in an application example and expert feedback on the developmental process of the nematode Caenorhabditis gans. The discussed methodology is applicable to other multicellular organisms.", "keywords": "E.1 {[}Data]: Data structures; Graphs and networks; J.3 {[}Computer applications]: Life and medical science; Biology and genetics", "link": "https://doi.org/10.1109/PacificVis.2018.00012", "refList": ["10.1109/tvcg.2016.2598919", "10.1145/3139295.3139310", "10.1101/gr.1239303", "10.1186/s12859-015-0550-z", "10.1109/tvcg.2016.2534519", "10.1111/cgf.12791", "10.1109/iv.2015.54", "10.1162/coli.2008.34.1.35", "10.1016/s0010-0285(03)00036-7", "10.1109/tvcg.2017.2745280", "10.1023/a:1022627411411", "10.3115/v1/p14-5010", "10.1186/s13104-017-2607-8", "10.1109/tvcg.2015.2467931", "10.1007/978-3-662-43968-5\\_7", "10.1093/nar/gks1107", "10.1109/pacificvis.2017.8031597", "10.1109/tsmc.1981.4308636", "10.1093/bib/bbw132/2843629"], "wos": 1, "children": [], "len": 1}], "len": 3}], "len": 13}, "index": 402, "embedding": [0.18345490097999573, 1.2747361660003662, -1.030107021331787, -1.7029038667678833, -0.6539726853370667, 0.16650904715061188, -0.7323254346847534, 2.6057326793670654, -0.4441397190093994, 1.0861486196517944, 0.663878321647644, 0.7125341892242432, 0.3121282458305359, 0.18824325501918793, -0.7085734605789185, 1.0824944972991943, 0.8227923512458801, 2.3089182376861572, -0.7047576308250427, 0.9573023915290833, -0.06630208343267441, 1.5072180032730103, -1.2409613132476807, 1.3434950113296509, -2.405334949493408, 0.08711085468530655, -0.5452967882156372, 1.00633704662323, 2.376561164855957, -0.9119835495948792, 0.12926095724105835, 0.912166953086853], "projection": [-0.3362472951412201, 8.113116264343262], "size": 7, "height": 4, "width": 3}