{"data": {"doi": "10.1111/cgf.13187", "year": "2017", "title": "Graph Layouts by t-SNE", "conferenceName": "EuroVis", "authors": "Johannes F. Kruiger;Paulo E. Rauber;Rafael Messias Martins;Andreas Kerren;Stephen G. Kobourov;Alexandru Telea", "citationCount": "15", "affiliation": "Kruiger, JF (Corresponding Author), Univ Groningen, Groningen, Netherlands.\nKruiger, JF (Corresponding Author), Ecole Natl Aviat Civile, Toulouse, France.\nKruiger, J. F.; Rauber, P. E.; Telea, A. C., Univ Groningen, Groningen, Netherlands.\nKruiger, J. F., Ecole Natl Aviat Civile, Toulouse, France.\nRauber, P. E., Univ Estadual Campinas, Campinas, SP, Brazil.\nMartins, R. M.; Kerren, A., Linnaeus Univ, Vaxjo, Sweden.\nKobourov, S., Univ Arizona, Tucson, AZ 85721 USA.", "countries": "USA;France;Netherlands;Sweden;Brazil", "abstract": "We propose a new graph layout method based on a modification of the t-distributed Stochastic Neighbor Embedding (t-SNE) dimensionality reduction technique. Although t-SNE is one of the best techniques for visualizing high-dimensional data as 2D scatterplots, t-SNE has not been used in the context of classical graph layout. We propose a new graph layout method, tsNET, based on representing a graph with a distance matrix, which together with a modified t-SNE cost function results in desirable layouts. We evaluate our method by a formal comparison with state-of-the-art methods, both visually and via established quality metrics on a comprehensive benchmark, containing real-world and synthetic graphs. As evidenced by the quality metrics and visual inspection, tsNET produces excellent layouts.", "keywords": "", "link": "https://doi.org/10.1111/cgf.13187", "refList": ["10.1016/j.cag.2014.01.006", "10.1103/physreve.74.036104", "10.1109/tvcg.2007.70443", "10.1006/jcph.2002.7095", "10.1109/tvcg.2007.70580", "10.1111/j.1467-8659.2011.01898.x", "10.1073/pnas.021544898", "10.1177/1753193413501588", "10.1109/tvcg.2012.299", "10.1016/0020-0190(89)90102-6", "10.3402/qhw.v6i2.5918", "10.1109/icassp.2013.6638231", "10.1109/tvcg.2011.220", "10.1109/tvcg.2016.2515611", "10.1126/science.290.5500.2319", "10.1038/30918", "10.1002/spe.4380211102", "10.1137/s154034590241370x", "10.1145/2049662.2049670", "10.1145/2049662.2049663", "10.1109/sibgrapi.2007.21", "10.1287/mnsc.17.3.219", "10.1198/106186008x318440", "10.1038/nature14236", "10.1145/62038.62043", "10.1007/s11390-012-1265-5", "10.1142/s0219525903001067", "10.1007/978-3-642-00219-9\\_21"], "wos": 1, "children": [{"doi": "10.1109/tvcg.2019.2934396", "title": "A Deep Generative Model for Graph Layout", "year": "2019", "conferenceName": "InfoVis", "authors": "Oh-Hyun Kwon;Kwan-Liu Ma", "citationCount": "4", "affiliation": "Kwon, OH (Corresponding Author), Univ Calif Davis, Davis, CA 95616 USA. Kwon, Oh-Hyun; Ma, Kwan-Liu, Univ Calif Davis, Davis, CA 95616 USA.", "countries": "USA", "abstract": "Different layouts can characterize different aspects of the same graph. Finding a \u201cgood\u201d layout of a graph is thus an important task for graph visualization. In practice, users often visualize a graph in multiple layouts by using different methods and varying parameter settings until they find a layout that best suits the purpose of the visualization. However, this trial-and-error process is often haphazard and time-consuming. To provide users with an intuitive way to navigate the layout design space, we present a technique to systematically visualize a graph in diverse layouts using deep generative models. We design an encoder-decoder architecture to learn a model from a collection of example layouts, where the encoder represents training examples in a latent space and the decoder produces layouts from the latent space. In particular, we train the model to construct a two-dimensional latent space for users to easily explore and generate various layouts. We demonstrate our approach through quantitative and qualitative evaluations of the generated layouts. The results of our evaluations show that our model is capable of learning and generalizing abstract concepts of graph layouts, not just memorizing the training examples. In summary, this paper presents a fundamentally new approach to graph visualization where a machine learning model learns to visualize a graph from examples without manually-defined heuristics.", "keywords": "Graph,network,visualization,layout,machine learning,deep learning,neural network,generative model,autoencoder", "link": "http://dx.doi.org/10.1109/TVCG.2019.2934396", "refList": ["10.1103/physreve.74.036104", "10.1145/234535.234538", "10.2307/2412323", "10.1109/tvcg.2007.70580", "10.7155/jgaa.00405", "10.1177/1473871612455749", "10.1109/tvcg.2011.185", "10.1073/pnas.122653799", "10.1007/3-540-58950-3", "10.1145/2897824.2925974", "10.1007/3-540-44541-2\\_17", "10.1007/bf00410640", "10.1021/acscentsci.7b00572", "10.1007/s10208-011-9093-5", "10.1109/tvcg.2015.2467451", "10.1016/0020-0190(89)90102-6", "10.3402/qhw.v6i2.5918", "10.1111/cgf.13187", "10.1214/aoms/1177729586", "10.1109/tvcg.2014.2346277", "10.1109/tvcg.2017.2743858", "10.1007/978-3-662-44043-8\\_3", "10.1038/30918", "10.1109/mcg.2018.2881501", "10.1016/j.camwa.2004.08.015", "10.1109/tvcg.2010.269", "10.1006/s1045-926x(02)00016-2", "10.1016/0925-7721(94)00014-x", "10.1145/2049662.2049670", "10.1145/2049662.2049663", "10.1103/physrevx.4.011047", "10.1371/journal.pone.0098679", "10.1145/2487788.2488173", "10.1007/978-3-030-01418-6\\_41", "10.1007/978-3-030-04414-5\\_12", "10.1109/tvcg.2018.2865139", "10.1142/s0219525903001067", "10.7155/jgaa.00051"], "wos": 1, "children": [{"doi": "10.1109/tvcg.2020.3030367", "title": "Lyra 2: Designing Interactive Visualizations by Demonstration", "year": "2020", "conferenceName": "InfoVis", "authors": "Jonathan Zong;Dhiraj Barnwal;Rupayan Neogy;Arvind Satyanarayan", "citationCount": "0", "affiliation": "Zong, J (Corresponding Author), MIT, Cambridge, MA 02139 USA. Zong, Jonathan; Neogy, Rupayan; Satyanarayan, Arvind, MIT, Cambridge, MA 02139 USA. Barnwal, Dhiraj, Indian Inst Technol Kharagpur, Kharagpur, W Bengal, India.", "countries": "India;USA", "abstract": "Recent graphical interfaces offer direct manipulation mechanisms for authoring visualizations, but are largely restricted to static output. To author interactive visualizations, users must instead turn to textual specification, but such approaches impose a higher technical burden. To bridge this gap, we introduce Lyra 2, a system that extends a prior visualization design environment with novel methods for authoring interaction techniques by demonstration. Users perform an interaction (e.g., button clicks, drags, or key presses) directly on the visualization they are editing. The system interprets this performance using a set of heuristics and enumerates suggestions of possible interaction designs. These heuristics account for the properties of the interaction (e.g., target and event type) as well as the visualization (e.g., mark and scale types, and multiple views). Interaction design suggestions are displayed as thumbnails; users can preview and test these suggestions, iteratively refine them through additional demonstrations, and finally apply and customize them via property inspectors. We evaluate our approach through a gallery of diverse examples, and evaluate its usability through a first-use study and via an analysis of its cognitive dimensions. We find that, in Lyra 2, interaction design by demonstration enables users to rapidly express a wide range of interactive visualizations.", "keywords": "Direct manipulation,interactive visualization,interaction design by demonstration", "link": "http://dx.doi.org/10.1109/TVCG.2020.3030367", "refList": ["10.1109/tvcg.2019.2934396", "10.1613/jair.301", "10.1016/j.automatica.2009.07.008", "10.1016/j.visinf.2018.12.001", "10.1016/j.neucom.2007.11.026", "10.1109/tvcg.2015.2392771", "10.1109/tvcg.2019.2934798", "10.1613/jair.3912", "10.1109/tvcg.2012.212", "10.1109/tvcg.2018.2816203", "10.1111/cgf.13193", "10.1109/21.87055", "10.1109/tvcg.2018.2864899", "10.1016/j.visinf.2017.11.002", "10.1007/s11432-018-9801-4", "10.1109/tvcg.2013.196", "10.1145/302979.303030", "10.1109/tvcg.2013.191", "10.1007/978-3-642-36955-1\\_16", "10.1109/vast.2017.8585487", "10.1109/cvpr.2016.90", "10.1038/nature14236", "10.1145/568522.568523", "10.1016/j.neunet.2014.09.003", "10.1016/j.visinf.2018.04.011", "10.1109/iccv.2019.00880", "10.1109/tvcg.2016.2598831"], "wos": 1, "children": [], "len": 1}, {"doi": "10.1109/tvcg.2020.3030467", "title": "PlotThread: Creating Expressive Storyline Visualizations using Reinforcement Learning", "year": "2020", "conferenceName": "InfoVis", "authors": "Tan Tang;Renzhong Li;Xinke Wu;Shuhan Liu;Johannes Knittel;Steffen Koch;Lingyun Yu;Peiran Ren;Thomas Ertl;Yingcai Wu", "citationCount": "1", "affiliation": "Wu, YC (Corresponding Author), Zhejiang Univ, Zhejiang Lab, Hangzhou, Peoples R China. Wu, YC (Corresponding Author), Zhejiang Univ, Stare Key Lab CAD\\&CG, Hangzhou, Peoples R China. Tang, Tan; Li, Renzhong; Wu, Xinke; Liu, Shuhan; Wu, Yingcai, Zhejiang Univ, Zhejiang Lab, Hangzhou, Peoples R China. Tang, Tan; Li, Renzhong; Wu, Xinke; Liu, Shuhan; Wu, Yingcai, Zhejiang Univ, Stare Key Lab CAD\\&CG, Hangzhou, Peoples R China. Knittel, Johannes; Koch, Steffen; Ertl, Thomas, Univ Stuttgart, VIS VISUS, Stuttgart, Germany. Yu, Lingyun, Xian Jiaotong Liverpool Univ, Dept Comp Sci \\& Software Engn, Suzhou, Peoples R China. Ren, Peiran, Alibaba Grp, Hangzhou, Peoples R China.", "countries": "Germany;China", "abstract": "Storyline visualizations are an effective means to present the evolution of plots and reveal the scenic interactions among characters. However, the design of storyline visualizations is a difficult task as users need to balance between aesthetic goals and narrative constraints. Despite that the optimization-based methods have been improved significantly in terms of producing aesthetic and legible layouts, the existing (semi-) automatic methods are still limited regarding 1) efficient exploration of the storyline design space and 2) flexible customization of storyline layouts. In this work, we propose a reinforcement learning framework to train an AI agent that assists users in exploring the design space efficiently and generating well-optimized storylines. Based on the framework, we introduce PlotThread, an authoring tool that integrates a set of flexible interactions to support easy customization of storyline visualizations. To seamlessly integrate the AI agent into the authoring process, we employ a mixed-initiative approach where both the agent and designers work on the same canvas to boost the collaborative design of storylines. We evaluate the reinforcement learning model through qualitative and quantitative experiments and demonstrate the usage of PlotThread using a collection of use cases.", "keywords": "Storyline visualization,reinforcement learning,mixed-initiative design", "link": "http://dx.doi.org/10.1109/TVCG.2020.3030467", "refList": ["10.1109/tvcg.2019.2934396", "10.1613/jair.301", "10.1016/j.automatica.2009.07.008", "10.1016/j.visinf.2018.12.001", "10.1016/j.neucom.2007.11.026", "10.1109/tvcg.2015.2392771", "10.1109/tvcg.2019.2934798", "10.1613/jair.3912", "10.1109/tvcg.2012.212", "10.1109/tvcg.2018.2816203", "10.1111/cgf.13193", "10.1109/21.87055", "10.1109/tvcg.2018.2864899", "10.1016/j.visinf.2017.11.002", "10.1007/s11432-018-9801-4", "10.1109/tvcg.2013.196", "10.1145/302979.303030", "10.1109/tvcg.2013.191", "10.1007/978-3-642-36955-1\\_16", "10.1109/vast.2017.8585487", "10.1109/cvpr.2016.90", "10.1038/nature14236", "10.1145/568522.568523", "10.1016/j.neunet.2014.09.003", "10.1016/j.visinf.2018.04.011", "10.1109/iccv.2019.00880", "10.1109/tvcg.2016.2598831"], "wos": 1, "children": [], "len": 1}, {"doi": "10.1109/tvcg.2020.3030459", "title": "Scalability of Network Visualisation from a Cognitive Load Perspective", "year": "2020", "conferenceName": "InfoVis", "authors": "Vahan Yoghourdjian;Yalong Yang;Tim Dwyer;Lawrence Lee;Michael Wybrow;Kim Marriott", "citationCount": "0", "affiliation": "Yoghourdjian, V (Corresponding Author), Monash Univ, Fac Informat Technol, Dept Human Ctr Comp, Melbourne, Vic, Australia. Yoghourdjian, Vahan; Yang, Yalong; Dwyer, Tim; Wybrow, Michael; Marriott, Kim, Monash Univ, Fac Informat Technol, Dept Human Ctr Comp, Melbourne, Vic, Australia. Lawrence, Lee, Monash Univ, Fac Business \\& Econ, Melbourne, Vic, Australia. Yang, Yalong, Harvard Univ, Sch Engn \\& Appl Sci, Cambridge, MA 02138 USA.", "countries": "USA;Australia", "abstract": "Node-link diagrams are widely used to visualise networks. However, even the best network layout algorithms ultimately result in \u2018hairball\u2019 visualisations when the graph reaches a certain degree of complexity, requiring simplification through aggregation or interaction (such as filtering) to remain usable. Until now, there has been little data to indicate at what level of complexity node-link diagrams become ineffective or how visual complexity affects cognitive load. To this end, we conducted a controlled study to understand workload limits for a task that requires a detailed understanding of the network topology-finding the shortest path between two nodes. We tested performance on graphs with 25 to 175 nodes with varying density. We collected performance measures (accuracy and response time), subjective feedback, and physiological measures (EEG, pupil dilation, and heart rate variability). To the best of our knowledge this is the first network visualisation study to include physiological measures. Our results show that people have significant difficulty finding the shortest path in high density node-link diagrams with more than 50 nodes and even low density graphs with more than 100 nodes. From our collected EEG data we observe functional differences in brain activity between hard and easy tasks. We found that cognitive load increased up to certain level of difficulty after which it decreased, likely because participants had given up. We also explored the effects of global network layout features such as size or number of crossings, and features of the shortest path such as length or straightness on task difficulty. We found that global features generally had a greater impact than those of the shortest path.", "keywords": "Data Visualisation,Network Visualisation,Cognitive Load,EEG", "link": "http://dx.doi.org/10.1109/TVCG.2020.3030459", "refList": ["10.1109/tvcg.2019.2934396", "10.1109/tvcg.2016.2598867", "10.1109/tvcg.2016.2570755", "10.1007/s00371-013-0892-3", "10.1007/b98835", "10.1109/isda.2014.7066252", "10.1109/tvcg.2015.2467251", "10.1177/1473871612455749", "10.1109/tvcg.2012.299", "10.1007/3-540-58950-3", "10.1111/cgf.12878", "10.1109/mcse.2007.55", "10.1109/tvcg.2012.238", "10.1145/264645.264657", "10.1109/tvcg.2015.2467451", "10.1109/tvcg.2013.151", "10.1016/0020-0190(89)90102-6", "10.1109/tvcg.2019.2934307", "10.1109/tvcg.2015.2468151", "10.1109/tvcg.2017.2745919", "10.3402/qhw.v6i2.5918", "10.1111/cgf.13440", "10.1109/tvcg.2011.220", "10.1111/cgf.13187", "10.1109/t-c.1969.222678", "10.1109/tvcg.2017.2743858", "10.1126/science.290.5500.2319", "10.1109/cahpc.2018.8645912", "10.1109/tvcg.2015.2465151", "10.1109/tvcg.2016.2598958", "10.1109/tvcg.2017.2751473", "10.1002/spe.4380211102", "10.1109/tpds.2018.2869805", "10.1016/j.jpdc.2019.04.008", "10.1109/pacificvis.2017.8031574", "10.1006/s1045-926x(02)00016-2", "10.1109/tvcg.2017.2674999", "10.1145/2872427.2883041", "10.1145/3292500.3330989", "10.1109/tvcg.2017.2744878", "10.1145/2049662.2049670", "10.1145/2049662.2049663", "10.1109/sbac-pad.2018.00060", "10.1007/978-3-662-45803-7\\_27", "10.1109/pacificvis.2011.5742389", "10.1371/journal.pone.0098679", "10.1111/j.1469-1809.1936.tb02137.x", "10.1007/bf02289565", "10.1109/tvcg.2017.2689016", "10.1007/3-540-63938-1\\_"], "wos": 1, "children": [], "len": 1}, {"doi": "10.1109/tvcg.2020.3030471", "title": "Visual Analysis of Discrimination in Machine Learning", "year": "2020", "conferenceName": "InfoVis", "authors": "Qianwen Wang;Zhenhua Xu;Zhutian Chen;Yong Wang;Shixia Liu;Huamin Qu", "citationCount": "0", "affiliation": "Wang, QW (Corresponding Author), Hong Kong Univ Sci \\& Technol, Hong Kong, Peoples R China. Wang, Qianwen; Xu, Zhenhua; Chen, Zhutian; Wang, Yong; Qu, Huamin, Hong Kong Univ Sci \\& Technol, Hong Kong, Peoples R China. Liu, Shixia, Tsinghua Univ, Beijing, Peoples R China.", "countries": "China", "abstract": "The growing use of automated decision-making in critical applications, such as crime prediction and college admission, has raised questions about fairness in machine learning. How can we decide whether different treatments are reasonable or discriminatory? In this paper, we investigate discrimination in machine learning from a visual analytics perspective and propose an interactive visualization tool, DiscriLens, to support a more comprehensive analysis. To reveal detailed information on algorithmic discrimination, DiscriLens identifies a collection of potentially discriminatory itemsets based on causal modeling and classification rules mining. By combining an extended Euler diagram with a matrix-based visualization, we develop a novel set visualization to facilitate the exploration and interpretation of discriminatory itemsets. A user study shows that users can interpret the visually encoded information in DiscriLens quickly and accurately. Use cases demonstrate that DiscriLens provides informative guidance in understanding and reducing algorithmic discrimination.", "keywords": "Machine Learning,Discrimination,Data Visualization", "link": "http://dx.doi.org/10.1109/TVCG.2020.3030471", "refList": ["10.1109/tvcg.2019.2934396", "10.2312/eurovisstar.20141170", "10.1145/3357384.3357910", "10.1111/cgf.12791", "10.1109/tvcg.2018.2861397", "10.1111/j.1467-8659.2011.01898.x", "10.1145/2702123.2702237", "10.1109/tvcg.2019.2934798", "10.1109/mcg.2017.21", "10.1109/tvcg.2019.2934300", "10.1109/tvcg.2017.2745085", "10.1109/tvcg.2018.2859997", "10.1145/3173574.3174237", "10.1109/tvcg.2018.2865126", "10.1145/1718487.1718520", "10.1109/tvcg.2017.2743858", "10.1109/pacificvis.2015.7156392", "10.1109/tvcg.2018.2864477", "10.1145/324133.324140", "10.1137/140976649", "10.1145/3219819.3220088", "10.1109/tvcg.2019.2934805", "10.1145/1134271.1134277", "10.1137/090772745", "10.1016/j.jelectrocard.2010.09.003", "10.1109/tvcg.2012.253", "10.1145/2556612", "10.1109/tvcg.2013.173", "10.1109/tvcg.2019.2934619", "10.1109/tvcg.2017.2745078"], "wos": 1, "children": [], "len": 1}, {"doi": "10.1109/pacificvis48177.2020.4722", "year": "2020", "title": "A Study of Mental Maps in Immersive Network Visualization", "conferenceName": "PacificVis", "authors": "Joseph Kotlarek;Oh{-}Hyun Kwon;Kwan{-}Liu Ma;Peter Eades;Andreas Kerren;Karsten Klein;Falk Schreiber", "citationCount": "0", "affiliation": "Kotlarek, J (Corresponding Author), Univ Calif Davis, Davis, CA 95616 USA.\nKotlarek, Joseph; Kwon, Oh-Hyun; Ma, Kwan-Liu, Univ Calif Davis, Davis, CA 95616 USA.\nEades, Peter, Univ Sydney, Sydney, NSW, Australia.\nKerren, Andreas, Linnaeus Univ, Vaxjo, Sweden.\nKlein, Karsten; Schreiber, Falk, Univ Konstanz, Constance, Germany.", "countries": "Sweden;Germany;USA;Australia", "abstract": "The visualization of a network influences the quality of the mental map that the viewer develops to understand the network. In this study, we investigate the effects of a 3D immersive visualization environment compared to a traditional 2D desktop environment on the comprehension of a network's structure. We compare the two visualization environments using three tasks-interpreting network structure, memorizing a set of nodes, and identifying the structural changes-commonly used for evaluating the quality of a mental map in network visualization. The results show that participants were able to interpret network structure more accurately when viewing the network in an immersive environment, particularly for larger networks. However, we found that 2D visualizations performed better than immersive visualization for tasks that required spatial memory.", "keywords": "Human-centered computing; Visualization; Visualization techniques; Graph drawings; Human-centered computing; Visualization; Empirical studies in visualization", "link": "https://doi.org/10.1109/PacificVis48177.2020.4722", "refList": ["10.1103/physreve.74.036104", "10.1109/tvcg.2019.2934396", "10.1007/978-3-540-87730-1\\_9", "10.1117/12.2005484", "10.1177/1473871612455749", "10.1109/pacificvis.2017.8031577", "10.1007/978-3-319-73207-7", "10.1109/38.888006", "10.1109/2945.841119", "10.1109/mc.2005.297", "10.1007/s10055-018-0346-3", "10.1109/tvcg.2016.2599107", "10.1109/icsmc.1992.271688", "10.1038/30918", "10.1006/jvlc.1995.1010", "10.1089/109493101300117938", "10.1109/vrais.1998.658488", "10.1109/pacificvis.2015.7156357", "10.1109/tvcg.2010.78", "10.1109/tvcg.2016.2520921", "10.1007/978-3-030-01388-22", "10.1145/229459.229467", "10.1145/1056808.1056875", "10.1109/tvcg.2017.2744079", "10.1109/bdva.2015.7314293", "10.1086/jar.33.4.3629752", "10.1016/j.ijhcs.2013.08.004"], "wos": 1, "children": [], "len": 1}], "len": 11}, {"doi": "10.1109/tvcg.2019.2934798", "title": "DeepDrawing: A Deep Learning Approach to Graph Drawing", "year": "2019", "conferenceName": "InfoVis", "authors": "Yong Wang;Zhihua Jin;Qianwen Wang;Weiwei Cui;Tengfei Ma;Huamin Qu", "citationCount": "4", "affiliation": "Wang, Y (Corresponding Author), Hong Kong Univ Sci \\& Technol, Hong Kong, Peoples R China. Wang, Yong; Jin, Zhihua; Wang, Qianwen; Qu, Huamin, Hong Kong Univ Sci \\& Technol, Hong Kong, Peoples R China. Jin, Zhihua, Zhejiang Univ, Hangzhou, Peoples R China. Cui, Weiwei, Microsoft Res Asia, Beijing, Peoples R China. Ma, Tengfei, IBM TJ Watson Res Ctr, Yorktown Hts, NY 10598 USA.", "countries": "USA;China", "abstract": "Node-link diagrams are widely used to facilitate network explorations. However, when using a graph drawing technique to visualize networks, users often need to tune different algorithm-specific parameters iteratively by comparing the corresponding drawing results in order to achieve a desired visual effect. This trial and error process is often tedious and time-consuming, especially for non-expert users. Inspired by the powerful data modelling and prediction capabilities of deep learning techniques, we explore the possibility of applying deep learning techniques to graph drawing. Specifically, we propose using a graph-LSTM-based approach to directly map network structures to graph drawings. Given a set of layout examples as the training dataset, we train the proposed graph-LSTM-based model to capture their layout characteristics. Then, the trained model is used to generate graph drawings in a similar style for new networks. We evaluated the proposed approach on two special types of layouts (i.e., grid layouts and star layouts) and two general types of layouts (i.e., ForceAtlas2 and PivotMDS) in both qualitative and quantitative ways. The results provide support for the effectiveness of our approach. We also conducted a time cost assessment on the drawings of small graphs with 20 to 50 nodes. We further report the lessons we learned and discuss the limitations and future work.", "keywords": "Graph Drawing,Deep Learning,LSTM,Procrustes Analysis", "link": "http://dx.doi.org/10.1109/TVCG.2019.2934798", "refList": ["10.1057/ivs.2009.10", "10.1145/2939672.2939754", "10.1016/s0020-0190(98)00108-2", "10.5555/3157382.3157527", "10.1145/2939672.2939753", "10.1111/j.1467-8659.2011.01898.x", "10.1016/j.visinf.2018.12.006", "10.1177/1473871612455749", "10.1111/j.2517-6161.1991.tb01825.x", "10.1109/cvpr.2017.576", "10.1631/fitee.1700808", "10.1109/2945.841119", "10.1109/72.485670", "10.1007/3-540-58950-3\\_393", "10.1007/978-3-642-36763-2", "10.1162/089976600300015015", "10.1016/0020-0190(89)90102-6", "10.1145/2623330.2623732", "10.3402/qhw.v6i2.5918", "10.1007/978-3-642-36763-2\\_48", "10.1111/cgf.13187", "10.1038/nature14539", "10.1016/s0020-0255(02)00191-3", "10.1109/tvcg.2015.2467691", "10.1109/72.279181", "10.1109/tvcg.2017.2743858", "10.1007/978-3-662-44043-8\\_3", "10.1002/spe.4380211102", "10.1007/3-540-44541-2\\_18", "10.1162/neco.1997.9.8.1735", "10.1103/physreve.78.046110", "10.1006/s1045-926x(02)00016-2", "10.1109/pacificvis.2012.6183571", "10.1016/0925-7721(94)00014-x", "10.1109/infvis.2004.1", "10.1145/1830483.1830503", "10.1112/plms/s3-13.1.743", "10.1371/journal.pone.0098679", "10.1007/978-3-030-04414-5\\_12", "10.1147/jrd.2015.2411412"], "wos": 1, "children": [{"doi": "10.1109/tvcg.2020.3030367", "title": "Lyra 2: Designing Interactive Visualizations by Demonstration", "year": "2020", "conferenceName": "InfoVis", "authors": "Jonathan Zong;Dhiraj Barnwal;Rupayan Neogy;Arvind Satyanarayan", "citationCount": "0", "affiliation": "Zong, J (Corresponding Author), MIT, Cambridge, MA 02139 USA. Zong, Jonathan; Neogy, Rupayan; Satyanarayan, Arvind, MIT, Cambridge, MA 02139 USA. Barnwal, Dhiraj, Indian Inst Technol Kharagpur, Kharagpur, W Bengal, India.", "countries": "India;USA", "abstract": "Recent graphical interfaces offer direct manipulation mechanisms for authoring visualizations, but are largely restricted to static output. To author interactive visualizations, users must instead turn to textual specification, but such approaches impose a higher technical burden. To bridge this gap, we introduce Lyra 2, a system that extends a prior visualization design environment with novel methods for authoring interaction techniques by demonstration. Users perform an interaction (e.g., button clicks, drags, or key presses) directly on the visualization they are editing. The system interprets this performance using a set of heuristics and enumerates suggestions of possible interaction designs. These heuristics account for the properties of the interaction (e.g., target and event type) as well as the visualization (e.g., mark and scale types, and multiple views). Interaction design suggestions are displayed as thumbnails; users can preview and test these suggestions, iteratively refine them through additional demonstrations, and finally apply and customize them via property inspectors. We evaluate our approach through a gallery of diverse examples, and evaluate its usability through a first-use study and via an analysis of its cognitive dimensions. We find that, in Lyra 2, interaction design by demonstration enables users to rapidly express a wide range of interactive visualizations.", "keywords": "Direct manipulation,interactive visualization,interaction design by demonstration", "link": "http://dx.doi.org/10.1109/TVCG.2020.3030367", "refList": ["10.1109/tvcg.2019.2934396", "10.1613/jair.301", "10.1016/j.automatica.2009.07.008", "10.1016/j.visinf.2018.12.001", "10.1016/j.neucom.2007.11.026", "10.1109/tvcg.2015.2392771", "10.1109/tvcg.2019.2934798", "10.1613/jair.3912", "10.1109/tvcg.2012.212", "10.1109/tvcg.2018.2816203", "10.1111/cgf.13193", "10.1109/21.87055", "10.1109/tvcg.2018.2864899", "10.1016/j.visinf.2017.11.002", "10.1007/s11432-018-9801-4", "10.1109/tvcg.2013.196", "10.1145/302979.303030", "10.1109/tvcg.2013.191", "10.1007/978-3-642-36955-1\\_16", "10.1109/vast.2017.8585487", "10.1109/cvpr.2016.90", "10.1038/nature14236", "10.1145/568522.568523", "10.1016/j.neunet.2014.09.003", "10.1016/j.visinf.2018.04.011", "10.1109/iccv.2019.00880", "10.1109/tvcg.2016.2598831"], "wos": 1, "children": [], "len": 1}, {"doi": "10.1109/tvcg.2020.3030467", "title": "PlotThread: Creating Expressive Storyline Visualizations using Reinforcement Learning", "year": "2020", "conferenceName": "InfoVis", "authors": "Tan Tang;Renzhong Li;Xinke Wu;Shuhan Liu;Johannes Knittel;Steffen Koch;Lingyun Yu;Peiran Ren;Thomas Ertl;Yingcai Wu", "citationCount": "1", "affiliation": "Wu, YC (Corresponding Author), Zhejiang Univ, Zhejiang Lab, Hangzhou, Peoples R China. Wu, YC (Corresponding Author), Zhejiang Univ, Stare Key Lab CAD\\&CG, Hangzhou, Peoples R China. Tang, Tan; Li, Renzhong; Wu, Xinke; Liu, Shuhan; Wu, Yingcai, Zhejiang Univ, Zhejiang Lab, Hangzhou, Peoples R China. Tang, Tan; Li, Renzhong; Wu, Xinke; Liu, Shuhan; Wu, Yingcai, Zhejiang Univ, Stare Key Lab CAD\\&CG, Hangzhou, Peoples R China. Knittel, Johannes; Koch, Steffen; Ertl, Thomas, Univ Stuttgart, VIS VISUS, Stuttgart, Germany. Yu, Lingyun, Xian Jiaotong Liverpool Univ, Dept Comp Sci \\& Software Engn, Suzhou, Peoples R China. Ren, Peiran, Alibaba Grp, Hangzhou, Peoples R China.", "countries": "Germany;China", "abstract": "Storyline visualizations are an effective means to present the evolution of plots and reveal the scenic interactions among characters. However, the design of storyline visualizations is a difficult task as users need to balance between aesthetic goals and narrative constraints. Despite that the optimization-based methods have been improved significantly in terms of producing aesthetic and legible layouts, the existing (semi-) automatic methods are still limited regarding 1) efficient exploration of the storyline design space and 2) flexible customization of storyline layouts. In this work, we propose a reinforcement learning framework to train an AI agent that assists users in exploring the design space efficiently and generating well-optimized storylines. Based on the framework, we introduce PlotThread, an authoring tool that integrates a set of flexible interactions to support easy customization of storyline visualizations. To seamlessly integrate the AI agent into the authoring process, we employ a mixed-initiative approach where both the agent and designers work on the same canvas to boost the collaborative design of storylines. We evaluate the reinforcement learning model through qualitative and quantitative experiments and demonstrate the usage of PlotThread using a collection of use cases.", "keywords": "Storyline visualization,reinforcement learning,mixed-initiative design", "link": "http://dx.doi.org/10.1109/TVCG.2020.3030467", "refList": ["10.1109/tvcg.2019.2934396", "10.1613/jair.301", "10.1016/j.automatica.2009.07.008", "10.1016/j.visinf.2018.12.001", "10.1016/j.neucom.2007.11.026", "10.1109/tvcg.2015.2392771", "10.1109/tvcg.2019.2934798", "10.1613/jair.3912", "10.1109/tvcg.2012.212", "10.1109/tvcg.2018.2816203", "10.1111/cgf.13193", "10.1109/21.87055", "10.1109/tvcg.2018.2864899", "10.1016/j.visinf.2017.11.002", "10.1007/s11432-018-9801-4", "10.1109/tvcg.2013.196", "10.1145/302979.303030", "10.1109/tvcg.2013.191", "10.1007/978-3-642-36955-1\\_16", "10.1109/vast.2017.8585487", "10.1109/cvpr.2016.90", "10.1038/nature14236", "10.1145/568522.568523", "10.1016/j.neunet.2014.09.003", "10.1016/j.visinf.2018.04.011", "10.1109/iccv.2019.00880", "10.1109/tvcg.2016.2598831"], "wos": 1, "children": [], "len": 1}, {"doi": "10.1109/tvcg.2020.3030471", "title": "Visual Analysis of Discrimination in Machine Learning", "year": "2020", "conferenceName": "InfoVis", "authors": "Qianwen Wang;Zhenhua Xu;Zhutian Chen;Yong Wang;Shixia Liu;Huamin Qu", "citationCount": "0", "affiliation": "Wang, QW (Corresponding Author), Hong Kong Univ Sci \\& Technol, Hong Kong, Peoples R China. Wang, Qianwen; Xu, Zhenhua; Chen, Zhutian; Wang, Yong; Qu, Huamin, Hong Kong Univ Sci \\& Technol, Hong Kong, Peoples R China. Liu, Shixia, Tsinghua Univ, Beijing, Peoples R China.", "countries": "China", "abstract": "The growing use of automated decision-making in critical applications, such as crime prediction and college admission, has raised questions about fairness in machine learning. How can we decide whether different treatments are reasonable or discriminatory? In this paper, we investigate discrimination in machine learning from a visual analytics perspective and propose an interactive visualization tool, DiscriLens, to support a more comprehensive analysis. To reveal detailed information on algorithmic discrimination, DiscriLens identifies a collection of potentially discriminatory itemsets based on causal modeling and classification rules mining. By combining an extended Euler diagram with a matrix-based visualization, we develop a novel set visualization to facilitate the exploration and interpretation of discriminatory itemsets. A user study shows that users can interpret the visually encoded information in DiscriLens quickly and accurately. Use cases demonstrate that DiscriLens provides informative guidance in understanding and reducing algorithmic discrimination.", "keywords": "Machine Learning,Discrimination,Data Visualization", "link": "http://dx.doi.org/10.1109/TVCG.2020.3030471", "refList": ["10.1109/tvcg.2019.2934396", "10.2312/eurovisstar.20141170", "10.1145/3357384.3357910", "10.1111/cgf.12791", "10.1109/tvcg.2018.2861397", "10.1111/j.1467-8659.2011.01898.x", "10.1145/2702123.2702237", "10.1109/tvcg.2019.2934798", "10.1109/mcg.2017.21", "10.1109/tvcg.2019.2934300", "10.1109/tvcg.2017.2745085", "10.1109/tvcg.2018.2859997", "10.1145/3173574.3174237", "10.1109/tvcg.2018.2865126", "10.1145/1718487.1718520", "10.1109/tvcg.2017.2743858", "10.1109/pacificvis.2015.7156392", "10.1109/tvcg.2018.2864477", "10.1145/324133.324140", "10.1137/140976649", "10.1145/3219819.3220088", "10.1109/tvcg.2019.2934805", "10.1145/1134271.1134277", "10.1137/090772745", "10.1016/j.jelectrocard.2010.09.003", "10.1109/tvcg.2012.253", "10.1145/2556612", "10.1109/tvcg.2013.173", "10.1109/tvcg.2019.2934619", "10.1109/tvcg.2017.2745078"], "wos": 1, "children": [], "len": 1}], "len": 7}, {"doi": "10.1109/tvcg.2020.3030447", "title": "DRGraph: An Efficient Graph Layout Algorithm for Large-scale Graphs by Dimensionality Reduction", "year": "2020", "conferenceName": "InfoVis", "authors": "Minfeng Zhu;Wei Chen;Yuanzhe Hu;Yuxuan Hou;Liangjun Liu;Kaiyuan Zhang", "citationCount": "0", "affiliation": "Chen, W (Corresponding Author), Zhejiang Univ, State Key Lab CAD\\&CG, Hangzhou, Peoples R China. Zhu, Minfeng; Chen, Wei; Hu, Yuanzhe; Hou, Yuxuan; Liu, Liangjun; Zhang, Kaiyuan, Zhejiang Univ, State Key Lab CAD\\&CG, Hangzhou, Peoples R China.", "countries": "China", "abstract": "Efficient layout of large-scale graphs remains a challenging problem: the force-directed and dimensionality reduction-based methods suffer from high overhead for graph distance and gradient computation. In this paper, we present a new graph layout algorithm, called DRGraph, that enhances the nonlinear dimensionality reduction process with three schemes: approximating graph distances by means of a sparse distance matrix, estimating the gradient by using the negative sampling technique, and accelerating the optimization process through a multi-level layout scheme. DRGraph achieves a linear complexity for the computation and memory consumption, and scales up to large-scale graphs with millions of nodes. Experimental results and comparisons with state-of-the-art graph layout methods demonstrate that DRGraph can generate visually comparable layouts with a faster running time and a lower memory requirement.", "keywords": "graph visualization,graph layout,dimensionality reduction,force-directed layout", "link": "http://dx.doi.org/10.1109/TVCG.2020.3030447", "refList": ["10.1109/tvcg.2007.70582", "10.1371/journal.pone.0136497", "10.1109/tvcg.2016.2598867", "10.1145/234535.234538", "10.1145/3018661.3018731", "10.1109/34.491619", "10.1145/2939672.2939754", "10.1145/3269206.3271788", "10.1016/j.comnet.2011.08.019", "10.1007/s11263-011-0442-2", "10.1016/s0020-0190(98)00108-2", "10.1109/tvcg.2018.2865151", "10.1007/978-3-319-61188-4\\_2", "10.1177/1473871612455749", "10.1177/1473871616666394", "10.1109/tvcg.2015.2467035", "10.1186/1471-2105-10-375", "10.1145/3097983.3098061", "10.1109/tvcg.2018.2864911", "10.1145/3025453.3025628", "10.1109/tvcg.2015.2467451", "10.1109/2945.841119", "10.1016/j.swevo.2015.10.002", "10.1016/0020-0190(89)90102-6", "10.1109/infvis.2003.1249009", "10.1109/tvcg.2017.2745919", "10.1111/cgf.13187", "10.1111/cgf.13440", "10.1109/tvcg.2012.245", "10.1109/tvcg.2017.2743858", "10.1177/1473871618821740", "10.1186/s12859-015-0585-1", "10.1002/nav.3800020109", "10.1145/263407.263521", "10.1002/spe.4380211102", "10.1006/s1045-926x(02)00016-2", "10.1109/cvpr.2012.6247667", "10.1023/b:jogo.0000042115.44455.f3", "10.1109/pacificvis.2017.8031607", "10.1002/nav.3800030404", "10.1109/cvpr.2008.4587500", "10.1109/pacificvis.2011.5742389", "10.1371/journal.pone.0098679", "10.1090/s0002-9904-1920-03322-7", "10.1109/iv.2013.3", "10.1145/568522.568523", "10.1109/tvcg.2006.156", "10.1109/tvcg.2012.236", "10.1109/tvcg.2018.2865139", "10.1145/3219819.3220025", "10.1007/3-540-63938-1\\_"], "wos": 1, "children": [], "len": 1}, {"doi": "10.1109/tvcg.2020.3030393", "title": "Exemplar-based Layout Fine-tuning for Node-link Diagrams", "year": "2020", "conferenceName": "InfoVis", "authors": "Jiacheng Pan;Wei Chen;Xiaodong Zhao;Shuyue Zhou;Wei Zeng;Minfeng Zhu;Jian Chen;Siwei Fu;Yingcai Wu", "citationCount": "1", "affiliation": "Chen, W; Wu, YC (Corresponding Author), Zhejiang Univ, State Key Lab CAD\\&CG, Hangzhou, Peoples R China. Wu, YC (Corresponding Author), Zhejiang Lab, Hangzhou, Peoples R China. Pan, Jiacheng; Chen, Wei; Zhao, Xiaodong; Zhou, Shuyue; Zhu, Minfeng; Wu, Yingcai, Zhejiang Univ, State Key Lab CAD\\&CG, Hangzhou, Peoples R China. Fu, Siwei; Wu, Yingcai, Zhejiang Lab, Hangzhou, Peoples R China. Zeng, Wei, Chinese Acad Sci, Shenzhen Inst Adv Technol, Shenzhen, Peoples R China. Chen, Jian, Ohio State Univ, Columbus, OH 43210 USA.", "countries": "USA;China", "abstract": "We design and evaluate a novel layout fine-tuning technique for node-link diagrams that facilitates exemplar-based adjustment of a group of substructures in batching mode. The key idea is to transfer user modifications on a local substructure to other substructures in the entire graph that are topologically similar to the exemplar. We first precompute a canonical representation for each substructure with node embedding techniques and then use it for on-the-fly substructure retrieval. We design and develop a light-weight interactive system to enable intuitive adjustment, modification transfer, and visual graph exploration. We also report some results of quantitative comparisons, three case studies, and a within-participant user study.", "keywords": "Node-link diagram,graph layout,graph visualization,user interactions", "link": "http://dx.doi.org/10.1109/TVCG.2020.3030393", "refList": ["10.1109/tvcg.2007.70582", "10.1371/journal.pone.0136497", "10.1109/tvcg.2016.2598867", "10.1145/234535.234538", "10.1145/3018661.3018731", "10.1109/34.491619", "10.1145/2939672.2939754", "10.1145/3269206.3271788", "10.1016/j.comnet.2011.08.019", "10.1007/s11263-011-0442-2", "10.1016/s0020-0190(98)00108-2", "10.1109/tvcg.2018.2865151", "10.1177/1473871612455749", "10.1177/1473871616666394", "10.1109/tvcg.2015.2467035", "10.1186/1471-2105-10-375", "10.1145/3097983.3098061", "10.1109/tvcg.2018.2864911", "10.1145/3025453.3025628", "10.1109/tvcg.2015.2467451", "10.1016/j.swevo.2015.10.002", "10.1016/0020-0190(89)90102-6", "10.1109/infvis.2003.1249009", "10.1109/tvcg.2017.2745919", "10.1111/cgf.13187", "10.1111/cgf.13440", "10.1109/tvcg.2012.245", "10.1109/tvcg.2017.2743858", "10.1177/1473871618821740", "10.1186/s12859-015-0585-1", "10.1002/nav.3800020109", "10.1145/263407.263521", "10.1002/spe.4380211102", "10.1006/s1045-926x(02)00016-2", "10.1109/cvpr.2012.6247667", "10.1023/b:jogo.0000042115.44455.f3", "10.1109/pacificvis.2017.8031607", "10.1002/nav.3800030404", "10.1109/infvis.2004.1", "10.1109/cvpr.2008.4587500", "10.1109/pacificvis.2011.5742389", "10.1140/epjb/e2011-10979-2", "10.1371/journal.pone.0098679", "10.1090/s0002-9904-1920-03322-7", "10.1109/iv.2013.3", "10.1145/568522.568523", "10.1109/tvcg.2006.156", "10.1109/tvcg.2012.236", "10.1109/tvcg.2018.2865139", "10.1145/3219819.3220025", "10.1007/3-540-63938-1\\_"], "wos": 1, "children": [], "len": 1}, {"doi": "10.1109/tvcg.2020.3030459", "title": "Scalability of Network Visualisation from a Cognitive Load Perspective", "year": "2020", "conferenceName": "InfoVis", "authors": "Vahan Yoghourdjian;Yalong Yang;Tim Dwyer;Lawrence Lee;Michael Wybrow;Kim Marriott", "citationCount": "0", "affiliation": "Yoghourdjian, V (Corresponding Author), Monash Univ, Fac Informat Technol, Dept Human Ctr Comp, Melbourne, Vic, Australia. Yoghourdjian, Vahan; Yang, Yalong; Dwyer, Tim; Wybrow, Michael; Marriott, Kim, Monash Univ, Fac Informat Technol, Dept Human Ctr Comp, Melbourne, Vic, Australia. Lawrence, Lee, Monash Univ, Fac Business \\& Econ, Melbourne, Vic, Australia. Yang, Yalong, Harvard Univ, Sch Engn \\& Appl Sci, Cambridge, MA 02138 USA.", "countries": "USA;Australia", "abstract": "Node-link diagrams are widely used to visualise networks. However, even the best network layout algorithms ultimately result in \u2018hairball\u2019 visualisations when the graph reaches a certain degree of complexity, requiring simplification through aggregation or interaction (such as filtering) to remain usable. Until now, there has been little data to indicate at what level of complexity node-link diagrams become ineffective or how visual complexity affects cognitive load. To this end, we conducted a controlled study to understand workload limits for a task that requires a detailed understanding of the network topology-finding the shortest path between two nodes. We tested performance on graphs with 25 to 175 nodes with varying density. We collected performance measures (accuracy and response time), subjective feedback, and physiological measures (EEG, pupil dilation, and heart rate variability). To the best of our knowledge this is the first network visualisation study to include physiological measures. Our results show that people have significant difficulty finding the shortest path in high density node-link diagrams with more than 50 nodes and even low density graphs with more than 100 nodes. From our collected EEG data we observe functional differences in brain activity between hard and easy tasks. We found that cognitive load increased up to certain level of difficulty after which it decreased, likely because participants had given up. We also explored the effects of global network layout features such as size or number of crossings, and features of the shortest path such as length or straightness on task difficulty. We found that global features generally had a greater impact than those of the shortest path.", "keywords": "Data Visualisation,Network Visualisation,Cognitive Load,EEG", "link": "http://dx.doi.org/10.1109/TVCG.2020.3030459", "refList": ["10.1109/tvcg.2019.2934396", "10.1109/tvcg.2016.2598867", "10.1109/tvcg.2016.2570755", "10.1007/s00371-013-0892-3", "10.1007/b98835", "10.1109/isda.2014.7066252", "10.1109/tvcg.2015.2467251", "10.1177/1473871612455749", "10.1109/tvcg.2012.299", "10.1007/3-540-58950-3", "10.1111/cgf.12878", "10.1109/mcse.2007.55", "10.1109/tvcg.2012.238", "10.1145/264645.264657", "10.1109/tvcg.2015.2467451", "10.1109/tvcg.2013.151", "10.1016/0020-0190(89)90102-6", "10.1109/tvcg.2019.2934307", "10.1109/tvcg.2015.2468151", "10.1109/tvcg.2017.2745919", "10.3402/qhw.v6i2.5918", "10.1111/cgf.13440", "10.1109/tvcg.2011.220", "10.1111/cgf.13187", "10.1109/t-c.1969.222678", "10.1109/tvcg.2017.2743858", "10.1126/science.290.5500.2319", "10.1109/cahpc.2018.8645912", "10.1109/tvcg.2015.2465151", "10.1109/tvcg.2016.2598958", "10.1109/tvcg.2017.2751473", "10.1002/spe.4380211102", "10.1109/tpds.2018.2869805", "10.1016/j.jpdc.2019.04.008", "10.1109/pacificvis.2017.8031574", "10.1006/s1045-926x(02)00016-2", "10.1109/tvcg.2017.2674999", "10.1145/2872427.2883041", "10.1145/3292500.3330989", "10.1109/tvcg.2017.2744878", "10.1145/2049662.2049670", "10.1145/2049662.2049663", "10.1109/sbac-pad.2018.00060", "10.1007/978-3-662-45803-7\\_27", "10.1109/pacificvis.2011.5742389", "10.1371/journal.pone.0098679", "10.1111/j.1469-1809.1936.tb02137.x", "10.1007/bf02289565", "10.1109/tvcg.2017.2689016", "10.1007/3-540-63938-1\\_"], "wos": 1, "children": [], "len": 1}, {"doi": "10.1109/pacificvis48177.2020.3756", "year": "2020", "title": "BatchLayout: A Batch-Parallel Force-Directed Graph Layout Algorithm in Shared Memory", "conferenceName": "PacificVis", "authors": "Md. Khaledur Rahman;Majedul Haque Sujon;Ariful Azad", "citationCount": "0", "affiliation": "Azad, A (Corresponding Author), Indiana Univ, Dept Intelligent Syst Engn, Bloomington, IN 47405 USA.\nRahman, Md Khaledur, Indiana Univ, Dept Comp Sci, Bloomington, IN 47405 USA.\nSujon, Majedul Haque; Azad, Ariful, Indiana Univ, Dept Intelligent Syst Engn, Bloomington, IN 47405 USA.", "countries": "USA", "abstract": "Force-directed algorithms are widely used to generate aesthetically-pleasing layouts of graphs or networks arisen in many scientific disciplines. To visualize large-scale graphs, several parallel algorithms have been discussed in the literature. However, existing parallel algorithms do not utilize memory hierarchy efficiently and often offer limited parallelism. This paper addresses these limitations with BatchLayout, an algorithm that groups vertices into minibatches and processes them in parallel. BatchLayout also employs cache blocking techniques to utilize memory hierarchy efficiently. More parallelism and improved memory accesses coupled with force approximating techniques, better initialization, and optimized learning rate make BatchLayout significantly faster than other state-of-the-art algorithms such as ForceAtlas2 and OpenOrd. The visualization quality of layouts from BatchLayout is comparable or better than similar visualization tools.", "keywords": "Human-centered computing; Visualization; Visualization techniques; Graph drawings; Human-centered computing; Visualization; Visualization systems and tools; Visualization toolkits", "link": "https://doi.org/10.1109/PacificVis48177.2020.3756", "refList": ["10.1101/gr.1239303", "10.1109/tvcg.2012.299", "10.1109/tpds.2014.2331243", "10.1145/169627.169640", "10.1038/324446a0", "10.1016/j.ins.2016.11.012", "10.1016/0020-0190(89)90102-6", "10.1109/tvcg.2018.2859997", "10.3402/qhw.v6i2.5918", "10.1111/cgf.13187", "10.1109/icpp.2017.47", "10.1109/tvcg.2017.2743858", "10.1103/physreve.79.026102", "10.1002/spe.4380211102", "10.1109/tpds.2018.2869805", "10.1103/physreve.78.046110", "10.1006/s1045-926x(02)00016-2", "10.1117/12.871402", "10.1137/s154034590241370x", "10.1371/journal.pone.0098679", "10.1007/978-3-642-00219-9\\_21"], "wos": 1, "children": [], "len": 1}, {"doi": "10.1111/cgf.13418", "year": "2018", "title": "PixelSNE: Pixel-Aligned Stochastic Neighbor Embedding for Efficient 2D Visualization with Screen-Resolution Precision", "conferenceName": "EuroVis", "authors": "Minjeong Kim;Minsuk Choi;Sunwoong Lee;Jian Tang;Haesun Park;Jaegul Choo", "citationCount": "0", "affiliation": "Kim, M (Corresponding Author), Korea Univ, Seoul, South Korea.\nKim, M (Corresponding Author), Clova AI Res, NAVER, Seongnam Si, South Korea.\nKim, Minjeong; Choi, Minsuk; Lee, Sunwoong; Choo, Jaegul, Korea Univ, Seoul, South Korea.\nKim, Minjeong; Choo, Jaegul, Clova AI Res, NAVER, Seongnam Si, South Korea.\nTang, Jian, Montreal Inst Learning Algorithm, Montreal, PQ, Canada.\nTang, Jian, HEC Montreal, Montreal, PQ, Canada.\nPark, Haesun, Georgia Inst Technol, Atlanta, GA 30332 USA.", "countries": "Canada;USA;Korea", "abstract": "Embedding and visualizing large-scale high-dimensional data in a two-dimensional space is an important problem, because such visualization can reveal deep insights of complex data. However, most of the existing embedding approaches run on an excessively high precision, even when users want to obtain a brief insight from a visualization of large-scale datasets, ignoring the fact that in the end, the outputs are embedded onto a fixed-range pixel-based screen space. Motivated by this observation and directly considering the properties of screen space in an embedding algorithm, we propose Pixel-Aligned Stochastic Neighbor Embedding (PixelSNE), a highly efficient screen resolution-driven 2D embedding method which accelerates Barnes-Hut tree-based t-distributed stochastic neighbor embedding (BH-SNE), which is known to be a state-of-the-art 2D embedding method. Our experimental results show a significantly faster running time for PixelSNE compared to BH-SNE for various datasets while maintaining comparable embedding quality.", "keywords": "", "link": "https://doi.org/10.1111/cgf.13418", "refList": ["10.1109/tvcg.2007.70443", "10.1109/tvcg.2016.2570755", "10.1162/153244304322972667", "10.1007/s10994-011-5273-4", "10.1109/tvcg.2016.2598445", "10.1111/cgf.12878", "10.1038/44565", "10.1038/324446a0", "10.1109/tvcg.2013.212", "10.1111/cgf.13187", "10.1109/t-c.1969.222678", "10.1126/science.290.5500.2319", "10.1162/jmlr.2003.3.4-5.951", "10.1145/2872427.2883041", "10.1111/j.1467-8659.2012.03107.x", "10.1038/nbt.2594", "10.1162/089976698300017953", "10.1109/tvcg.2013.153", "10.1162/089976603321780317", "10.1007/bf02289565", "10.1007/s11263-005-4939-z", "10.1126/science.1127647"], "wos": 1, "children": [], "len": 1}, {"doi": "10.1111/cgf.13724", "year": "2019", "title": "A Random Sampling O(n) Force-calculation Algorithm for Graph Layouts", "conferenceName": "EuroVis", "authors": "Robert Gove", "citationCount": "1", "affiliation": "Gove, R (Corresponding Author), Two Six Labs, Arlington, VA 22203 USA.\nGove, R., Two Six Labs, Arlington, VA 22203 USA.", "countries": "USA", "abstract": "This paper proposes a linear-time repulsive-force-calculation algorithm with sub-linear auxiliary space requirements, achieving an asymptotic improvement over the Barnes-Hut and Fast Multipole Method force-calculation algorithms. The algorithm, named random vertex sampling (RVS), achieves its speed by updating a random sample of vertices at each iteration, each with a random sample of repulsive forces. This paper also proposes a combination algorithm that uses RVS to derive an initial layout and then applies Barnes-Hut to refine the layout. An evaluation of RVS and the combination algorithm compares their speed and quality on 109 graphs against a Barnes-Hut layout algorithm. The RVS algorithm performs up to 6.1 times faster on the tested graphs while maintaining comparable layout quality. The combination algorithm also performs faster than Barnes-Hut, but produces layouts that are more symmetric than using RVS alone. Data and code: https://osf.io/nb7m8/", "keywords": "", "link": "https://doi.org/10.1111/cgf.13724", "refList": ["10.1145/200836.200853", "10.1103/physreve.74.036104", "10.1109/tvcg.2016.2598867", "10.1145/234535.234538", "10.3390/a9030053", "10.1016/j.jmmm.2009.09.033", "10.7155/jgaa.00405", "10.1111/j.1467-8659.2011.01898.x", "10.1109/infvis.2002.1173159", "10.1073/pnas.021544898", "10.1109/tvcg.2011.185", "10.1007/3-540-58950-3", "10.1109/tvcg.2008.158", "10.1145/2384416.2384418", "10.1109/visual.1996.567787", "10.1136/qshc.2004.010033", "10.1038/324446a0", "10.1007/978-3-319-27261-0\\_4", "10.1002/1097-024x(200009)30:11", "10.1109/tvcg.2015.2467451", "10.1007/978-3-662-45803-7\\_20", "10.1145/1232722.1232727", "10.1006/jvlc.1995.1014", "10.3402/qhw.v6i2.5918", "10.1111/cgf.13187", "10.1109/tvcg.2009.109", "10.1142/s0219525914500222", "10.1109/tvcg.2008.155", "10.1007/978-3-319-50106-2\\_2", "10.1007/978-3-319-27261-0\\_5", "10.1038/30918", "10.1126/science.286.5439.509", "10.1007/3-540-62495-3\\_50", "10.1109/iv.2015.56", "10.1002/spe.4380211102", "10.1006/jcph.2000.6451", "10.1109/icdm.2012.159", "10.1109/tvcg.2017.2674999", "10.1111/j.1467-8659.2012.03090.x", "10.1016/j.physa.2011.03.036", "10.1111/ajps.12102", "10.1023/a:1008047806690", "10.1109/tvcg.2007.46", "10.1145/2049662.2049670", "10.1145/2049662.2049663", "10.1109/tvcg.2009.174", "10.1016/j.jelectrocard.2010.09.003", "10.13140/2.1.1341.1520", "10.1057/palgrave.ivs.9500040", "10.1112/plms/s3-13.1.743", "10.1371/journal.pone.0098679", "10.1517/14728222.10.1.1", "10.1007/978-3-319-26633-6\\_13", "10.1145/1054972.1055031", "10.1147/jrd.2015.2411412", "10.1109/pacificvis.2017.8031607"], "wos": 1, "children": [], "len": 1}, {"doi": "10.1111/cgf.13728", "year": "2019", "title": "The State of the Art in Visualizing Multivariate Networks", "conferenceName": "EuroVis", "authors": "Carolina Nobre;Miriah D. Meyer;Marc Streit;Alexander Lex", "citationCount": "5", "affiliation": "Nobre, C (Corresponding Author), Univ Utah, Salt Lake City, UT 84112 USA.\nNobre, C.; Meyer, M.; Lex, A., Univ Utah, Salt Lake City, UT 84112 USA.\nStreit, M., Johannes Kepler Univ Linz, Linz, Austria.", "countries": "USA;Austria", "abstract": "Multivariate networks are made up of nodes and their relationships (links), but also data about those nodes and links as attributes. Most real-world networks are associated with several attributes, and many analysis tasks depend on analyzing both, relationships and attributes. Visualization of multivariate networks, however, is challenging, especially when both the topology of the network and the attributes need to be considered concurrently. In this state-of-the-art report, we analyze current practices and classify techniques along four axes: layouts, view operations, layout operations, and data operations. We also provide an analysis of tasks specific to multivariate networks and give recommendations for which technique to use in which scenario. Finally, we survey application areas and evaluation methodologies.", "keywords": "", "link": "https://doi.org/10.1111/cgf.13728", "refList": ["10.2312/eurovisstar.20151110", "10.1111/cgf.12106", "10.1109/iv.2016.19", "10.1111/j.1467-8659.2011.02087.x", "10.1111/j.1467-8659.2008.01214.x", "10.1109/tvcg.2014.2346893", "10.1145/1124772.1124891", "10.1109/vast.2014.7042484", "10.1109/tvcg.2018.2865149", "10.1080/10447318.2010.516722", "10.1109/icsmc.2011.6084125", "10.1109/mcg.2011.103", "10.1117/12.378894", "10.1145/2207676.2208293", "10.1109/tvcg.2009.122", "10.1111/cgf.12935", "10.1016/s0020-0255(02)00191-3", "10.1038/nmeth.1436", "10.1109/tvcg.2011.187", "10.1109/32.177365", "10.1007/978-3-642-03658-3\\_47", "10.1109/tvcg.2006.147", "10.1109/pacificvis.2011.5742390", "10.1145/2470654.2466444", "10.1109/tvcg.2006.166", "10.1145/2470654.2470724", "10.1109/tvcg.2014.2346441", "10.1109/vizsec.2005.1532070", "10.1101/gr.092759.109", "10.1111/cgf.13184", "10.1109/tvcg.2018.2865940", "10.1016/j.scico.2012.05.002", "10.1109/biovis.2012.6378600", "10.1111/cgf.13213", "10.1109/noms.2006.1687547", "10.1109/tvcg.2008.141", "10.1007/978-3-540-78243-8\\_13", "10.1145/1029208.1029217", "10.1145/345513.345271", "10.1109/tvcg.2015.2467811", "10.1109/visual.1991.175815", "10.1186/1471-2105-10-375", "10.1007/978-3-319-06793-3\\_1", "10.1186/1471-2105-13-275", "10.1109/tvcg.2010.79", "10.1109/tvcg.2011.217", "10.1186/1471-2105-14-s19-s3", "10.3389/fmicb.2017.00010", "10.1109/infvis.2003.1249009", "10.1111/cgf.13187", "10.1111/j.1467-8659.2008.01231.x", "10.1109/tvcg.2011.144", "10.1145/2556288.2557010", "10.1111/j.1467-8659.2009.01710.x", "10.1109/infvis.2004.46", "10.1109/iv.2009.97", "10.1109/tvcg.2008.34", "10.1109/infvis.2003.1249011", "10.1109/iv.2016.41", "10.1109/pacificvis.2010.5429609", "10.1109/tvcg.2006.160", "10.1109/tvcg.2010.205", "10.1109/38.486685", "10.1109/tvcg.2006.106", "10.1057/palgrave.ivs.9500092", "10.1145/568522.568523", "10.1111/j.1467-8659.2008.01221.x", "10.1109/iv.2010.15", "10.1145/22339.22342", "10.1109/csmr.2009.17", "10.1109/tvcg.2017.2744898", "10.1109/tvcg.2008.117", "10.1186/1752-0509-3-82", "10.1109/tvcg.2008.61", "10.1109/pacificvis.2013.6596127", "10.1109/tvcg.2007.70529", "10.1186/1471-2105-15-198", "10.1109/tvcg.2009.128", "10.2312/eurovisshort.20151124", "10.1093/bioinformatics/btq675", "10.1109/tvcg.2009.143", "10.1109/tvcg.2014.2346752", "10.1109/tvcg.2013.124", "10.1007/s00450-007-0036-y", "10.1093/bioinformatics/17.suppl\\_1.s22", "10.2312/eurovisstar.20151109", "10.1007/978-3-319-06793-3\\_5", "10.1109/vissof.2007.4290706", "10.1109/tvcg.2009.145", "10.1109/mcas.2003.1228503", "10.1109/infvis.2005.1532128", "10.1145/989863.989941", "10.1109/infvis.1999.801860", "10.1111/j.1467-8659.2009.01687.x", "10.1109/tvcg.2013.120", "10.1109/tvcg.2007.70582", "10.1109/tvcg.2009.167", "10.1109/pacificvis.2010.5429590", "10.1109/infvis.2000.885091", "10.1109/tvcg.2012.189", "10.1109/tvcg.2009.108", "10.1109/tvcg.2013.154", "10.1111/j.1467-8659.2011.01898.x", "10.1109/tvcg.2010.159", "10.1016/s0306-4573(98)00024-7", "10.1109/tvcg.2013.223", "10.1002/sam.10071", "10.2312/vissym/eurovis07/083-090", "10.1109/infvis.2002.1173156", "10.1186/1471-2105-7-109", "10.1177/1473871612455983", "10.1073/pnas.95.25.14863", "10.1007/978-3-319-06793-3\\_2", "10.1111/cgf.12883", "10.1007/978-3-540-78243-8\\_9", "10.1057/palgrave.ivs.9500180", "10.1109/pacificvis.2012.6183556", "10.1117/12.872578", "10.1145/1168149.1168169", "10.1109/iv.2013.3", "10.1109/tvcg.2011.186", "10.2307/2685881", "10.1109/pacificvis.2015.7156354", "10.1109/tvcg.2016.2598885", "10.1109/tvcg.2018.2811488", "10.1109/infvis.2005.1532129", "10.1111/j.1467-8659.2009.01450.x", "10.1057/palgrave.ivs.9500162", "10.1109/tvcg.2009.116", "10.1109/2945.468391"], "wos": 1, "children": [{"doi": "10.1109/tvcg.2020.3029413", "title": "A Design Space of Vision Science Methods for Visualization Research", "year": "2020", "conferenceName": "InfoVis", "authors": "Madison A. Elliott;Christine Nothelfer;Cindy Xiong;Danielle Albers Szafir", "citationCount": "0", "affiliation": "Elliott, MA (Corresponding Author), Univ British Columbia, Vancouver, BC, Canada. Elliott, Madison A., Univ British Columbia, Vancouver, BC, Canada. Nothelfer, Christine, Northwestern Univ, Evanston, IL 60208 USA. Xiong, Cindy, Univ Massachusetts, Amherst, MA 01003 USA. Szafir, Danielle Albers, Univ Colorado, Boulder, CO 80309 USA.", "countries": "Canada;USA", "abstract": "A growing number of efforts aim to understand what people see when using a visualization. These efforts provide scientific grounding to complement design intuitions, leading to more effective visualization practice. However, published visualization research currently reflects a limited set of available methods for understanding how people process visualized data. Alternative methods from vision science offer a rich suite of tools for understanding visualizations, but no curated collection of these methods exists in either perception or visualization research. We introduce a design space of experimental methods for empirically investigating the perceptual processes involved with viewing data visualizations to ultimately inform visualization design guidelines. This paper provides a shared lexicon for facilitating experimental visualization research. We discuss popular experimental paradigms, adjustment types, response types, and dependent measures used in vision science research, rooting each in visualization examples. We then discuss the advantages and limitations of each technique. Researchers can use this design space to create innovative studies and progress scientific understanding of design choices and evaluations in visualization. We highlight a history of collaborative success between visualization and vision science research and advocate for a deeper relationship between the two fields that can elaborate on and extend the methodological design space for understanding visualization and vision.", "keywords": "Perception,human vision,empirical research,evaluation,HCI", "link": "http://dx.doi.org/10.1109/TVCG.2020.3029413", "refList": ["10.1109/tvcg.2019.2934790", "10.1177/146879410200200205", "10.2312/eurovisshort", "10.1109/tvcg.2015.2467811", "10.1111/j.1467-6486.2009.00859.x", "10.1177/1473871613510429", "10.1109/tvcg.2018.2864836", "10.1109/tvcg.2018.2865076", "10.1109/tvcg.2013.231", "10.1002/cphy.c100079", "10.1177/0886109909354981", "10.1109/tvcg.2018.2865149", "10.1080/1750984x.2017.1317357", "10.1007/978-3-7643-8472-2\\_6", "10.1093/bioinformatics/btq110", "10.1111/cgf.13728", "10.2307/1511837", "10.1109/tvcg.2019.2934539", "10.3233/efi-2004-22201", "10.1002/chp.1340180402", "10.1111/2041-210x.12034", "10.1111/j.2041-210x.2011.00169.x", "10.1109/tvcg.2015.2467452", "10.1002/chp", "10.1177/1077800410383121", "10.1177/1744987107081254", "10.1002/cpbi.96", "10.1109/tvcg.2018.2864526", "10.1109/beliv.2018.8634026", "10.2307/1511637", "10.1109/tvcg.2014.2346431", "10.1111/cgf.12883", "10.1109/tvcg.2019.2934281", "10.1145/2993901.2993916", "10.2307/3178066", "10.1145/2993901.2993913", "10.1145/1182475.1182476", "10.1016/j.destud.2004.06.002", "10.1177/1609406918763214", "10.2312/eurovisshort.20151137", "10.1145/882262.882291", "10.1177/174498710501000305", "10.1017/s1049096513001789", "10.1109/tvcg.2012.213", "10.1093/nar/gkz239", "10.1093/sysbio/sys062", "10.1109/tvcg.2019.2898186", "10.1109/tvcg.2018.2811488", "10.1007/s11135-006-9044-4", "10.1109/tvcg.2009.111", "10.1111/2041-210x.12066", "10.1109/mcg.2018.2874523", "10.1177/1609406920909938"], "wos": 1, "children": [], "len": 1}, {"doi": "10.1109/tvcg.2020.3030405", "title": "Insights From Experiments With Rigor in an EvoBio Design Study", "year": "2020", "conferenceName": "InfoVis", "authors": "Jennifer Rogers;Austin H. Patton;Luke Harmon;Alexander Lex;Miriah D. Meyer", "citationCount": "0", "affiliation": "Rogers, J (Corresponding Author), Univ Utah, Salt Lake City, UT 84112 USA. Rogers, Jen; Lex, Alexander; Meyer, Miriah, Univ Utah, Salt Lake City, UT 84112 USA. Patton, Austin H., Washington State Univ, Pullman, WA 99164 USA. Harmon, Luke, Univ Idaho, Moscow, ID 83843 USA.", "countries": "USA", "abstract": "Design study is an established approach of conducting problem-driven visualization research. The academic visualization community has produced a large body of work for reporting on design studies, informed by a handful of theoretical frameworks, and applied to a broad range of application areas. The result is an abundance of reported insights into visualization design, with an emphasis on novel visualization techniques and systems as the primary contribution of these studies. In recent work we proposed a new, interpretivist perspective on design study and six companion criteria for rigor that highlight the opportunities for researchers to contribute knowledge that extends beyond visualization idioms and software. In this work we conducted a year-long collaboration with evolutionary biologists to develop an interactive tool for visual exploration of multivariate datasets and phylogenetic trees. During this design study we experimented with methods to support three of the rigor criteria: ABUNDANT, REFLEXIVE, and TRANSPARENT. As a result we contribute two novel visualization techniques for the analysis of multivariate phylogenetic datasets, three methodological recommendations for conducting design studies drawn from reflections over our process of experimentation, and two writing devices for reporting interpretivist design study. We offer this work as an example for implementing the rigor criteria to produce a diverse range of knowledge contributions.", "keywords": "Methodologies,Application Motivated Visualization,Guidelines,Life Sciences Visualization,Health,Medicine,Biology,Bioinformatics,Genomics", "link": "http://dx.doi.org/10.1109/TVCG.2020.3030405", "refList": ["10.1109/tvcg.2019.2934790", "10.1177/146879410200200205", "10.2312/eurovisshort", "10.1109/tvcg.2015.2467811", "10.1111/j.1467-6486.2009.00859.x", "10.1177/1473871613510429", "10.1109/tvcg.2018.2864836", "10.1109/tvcg.2018.2865076", "10.1109/tvcg.2013.231", "10.1002/cphy.c100079", "10.1109/tvcg.2018.2865149", "10.1080/1750984x.2017.1317357", "10.1007/978-3-7643-8472-2\\_6", "10.1111/cgf.13728", "10.2307/1511837", "10.1109/tvcg.2019.2934539", "10.3233/efi-2004-22201", "10.1080/17493460802276893", "10.1002/chp.1340180402", "10.1111/2041-210x.12034", "10.1111/j.2041-210x.2011.00169.x", "10.1109/tvcg.2015.2467452", "10.1002/chp", "10.1177/1077800410383121", "10.1002/cpbi.96", "10.1109/tvcg.2018.2864526", "10.1109/beliv.2018.8634026", "10.2307/1511637", "10.1109/tvcg.2014.2346431", "10.1111/cgf.12883", "10.1109/tvcg.2019.2934281", "10.1145/2993901.2993916", "10.2307/3178066", "10.1145/2993901.2993913", "10.1145/1182475.1182476", "10.1016/j.destud.2004.06.002", "10.1177/1609406918763214", "10.2312/eurovisshort.20151137", "10.1145/882262.882291", "10.1109/tvcg.2012.213", "10.1109/tvcg.2019.2898186", "10.1109/tvcg.2018.2811488", "10.1007/s11135-006-9044-4", "10.1109/tvcg.2009.111", "10.1111/2041-210x.12066", "10.1109/mcg.2018.2874523", "10.1177/1609406920909938"], "wos": 1, "children": [], "len": 1}, {"doi": "10.1111/cgf.13963", "year": "2020", "title": "MotionGlyphs: Visual Abstraction of Spatio-Temporal Networks in Collective Animal Behavior", "conferenceName": "EuroVis", "authors": "Eren Cakmak;Hanna Sch{\\\"{a}}fer;Juri Buchm{\\\"{u}}ller;Johannes Fuchs;Tobias Schreck;A. Jordan;Daniel A. Keim", "citationCount": "0", "affiliation": "Cakmak, E (Corresponding Author), Univ Konstanz, Constance, Germany.\nCakmak, E (Corresponding Author), Ctr Adv Study Collect Behav, Constance, Germany.\nCakmak, E.; Schaefer, H.; Buchmueller, J.; Fuchs, J.; Jordan, A.; Keim, D., Univ Konstanz, Constance, Germany.\nCakmak, E.; Jordan, A.; Keim, D., Ctr Adv Study Collect Behav, Constance, Germany.\nSchreck, T., Graz Univ Technol, Graz, Austria.\nJordan, A., Max Planck Inst Anim Behav, Radolfzell am Bodensee, Germany.", "countries": "Germany;Austria", "abstract": "Domain experts for collective animal behavior analyze relationships between single animal movers and groups of animals over time and space to detect emergent group properties. A common way to interpret this type of data is to visualize it as a spatio-temporal network. Collective behavior data sets are often large, and may hence result in dense and highly connected node-link diagrams, resulting in issues of node-overlap and edge clutter. In this design study, in an iterative design process, we developed glyphs as a design for seamlessly encoding relationships and movement characteristics of a single mover or clusters of movers. Based on these glyph designs, we developed a visual exploration prototype, MotionGlyphs, that supports domain experts in interactively filtering, clustering, and animating spatio-temporal networks for collective animal behavior analysis. By means of an expert evaluation, we show how MotionGlyphs supports important tasks and analysis goals of our domain experts, and we give evidence of the usefulness for analyzing spatio-temporal networks of collective animal behavior.", "keywords": "", "link": "https://doi.org/10.1111/cgf.13963", "refList": ["10.1109/tvcg.2007.70582", "10.1111/cgf.13213", "10.1109/pacificvis.2014.13", "10.1145/2093973.2094038", "10.1111/j.1467-8659.2009.01664.x", "10.1109/tvcg.2010.44", "10.1111/cgf.12106", "10.1111/cgf.12791", "10.1080/15230406.2014.890071", "10.1111/tgis.12100", "10.1111/j.1467-8659.2009.01451.x", "10.1179/000870409x12525737905042", "10.1111/cgf.12923", "10.1006/ijhc.2002.1017", "10.1145/1124772.1124891", "10.1109/tvcg.2011.213", "10.1109/vast.2014.7042484", "10.1007/s12650-016-0375-5", "10.1109/vlhcc.2012.6344514", "10.1073/pnas.1420068112", "10.1006/ijhc.1017", "10.1007/s00371-017-1461-y", "10.1109/infvis.2003.1249008", "10.1111/cgf.13728", "10.2312/conf/eg2013/stars/039-063", "10.1109/tvcg.2014.2346271", "10.1109/hicss.2011.339", "10.1068/p3104", "10.1145/2931002.2931012", "10.1109/asonam.2012.39", "10.1179/000870403235002042", "10.1145/2556288.2557010", "10.1145/2470654.2466443", "10.1109/tvcg.2011.209", "10.1016/j.tree.2013.06.002", "10.1111/1365-2656.12418", "10.1111/cgf.12872", "10.1145/2470654.2466444", "10.1109/tvcg.2014.2322594", "10.1109/tvcg.2008.125", "10.1109/tvcg.2014.2346426", "10.1109/tvcg.2006.166", "10.1111/cgf.12615", "10.1057/palgrave.ivs.9500170", "10.1007/3-540-36151-0", "10.1117/12.872578", "10.1016/j.tics.2008.10.002", "10.1006/jtbi.2002.3065", "10.1109/tvcg.2010.78", "10.1109/iv.2013.3", "10.1073/pnas.1001763107", "10.1109/pacificvis.2015.7156354", "10.1371/journal.pbio.1001805", "10.5220/0005303801230130", "10.1111/j.1467-8659.2009.01687.x", "10.1007/s10844-011-0159-2", "10.1007/s12650-018-00543-4", "10.1145/2669557.2669572", "10.1111/cgf.13184", "10.1186/s40462-015-0032-y", "10.1016/j.ins.2016.06.048", "10.1109/tvcg.2017.2744898"], "wos": 1, "children": [], "len": 1}, {"doi": "10.1111/cgf.13987", "year": "2020", "title": "Augmenting Node-Link Diagrams with Topographic Attribute Maps", "conferenceName": "EuroVis", "authors": "Reinhold Preiner;Johanna Schmidt;Katharina Kr{\\\"{o}}sl;Tobias Schreck;Gabriel Mistelbauer", "citationCount": "0", "affiliation": "Preiner, R (Corresponding Author), Graz Univ Technol, Inst Comp Graph \\& Knowledge Visualizat, Graz, Austria.\nPreiner, R.; Schreck, T., Graz Univ Technol, Inst Comp Graph \\& Knowledge Visualizat, Graz, Austria.\nSchmidt, J.; Kroesl, K., Virtual Real \\& Visualisierung Forsch GmbH, VRVis Zentrum, Vienna, Austria.\nKroesl, K., TU Wien, Inst Visual Comp \\& Human Ctr Technol, Vienna, Austria.\nMistelbauer, G., Otto von Guericke Univ, Dept Simulat \\& Graph, Magdeburg, Germany.", "countries": "Germany;Austria", "abstract": "We propose a novel visualization technique for graphs that are attributed with scalar data. In many scenarios, these attributes (e.g., birth date in a family network) provide ambient context information for the graph structure, whose consideration is important for different visual graph analysis tasks. Graph attributes are usually conveyed using different visual representations (e.g., color, size, shape) or by reordering the graph structure according to the attribute domain (e.g., timelines). While visual encodings allow graphs to be arranged in a readable layout, assessing contextual information such as the relative similarities of attributes across the graph is often cumbersome. In contrast, attribute-based graph reordering serves the comparison task of attributes, but typically strongly impairs the readability of the structural information given by the graph's topology. In this work, we augment force-directed node-link diagrams with a continuous ambient representation of the attribute context. This way, we provide a consistent overview of the graph's topological structure as well as its attributes, supporting a wide range of graph-related analysis tasks. We resort to an intuitive height field metaphor, illustrated by a topographic map rendering using contour lines and suitable color maps. Contour lines visually connect nodes of similar attribute values, and depict their relative arrangement within the global context. Moreover, our contextual representation supports visualizing attribute value ranges associated with graph nodes (e.g., lifespans in a family network) as trajectories routed through this height field. We discuss how user interaction with both the structural and the contextual information fosters exploratory graph analysis tasks. The effectiveness and versatility of our technique is confirmed in a user study and case studies from various application domains.", "keywords": "", "link": "https://doi.org/10.1111/cgf.13987", "refList": ["10.1109/tvcg.2013.269", "10.1109/pacificvis.2010.5429590", "10.1073/pnas.0307654100", "10.1145/2505515.2505758", "10.1559/152304082783948286", "10.1109/pacificvis.2014.47", "10.1093/bioinformatics/btp432", "10.1111/j.1467-8659.2011.01898.x", "10.1111/cgf.12931", "10.1111/cgf.12880", "10.1109/tvcg.2014.2346422", "10.1111/j.1467-8659.2009.01706.x", "10.1109/tvcg.2016.2598795", "10.1111/cgf.12800", "10.1109/tvcg.2014.2315995", "10.1111/cgf.12656", "10.1111/cgf.13728", "10.1109/tvcg.2009.122", "10.1111/cgf.13211", "10.1109/tvcg.2007.70596", "10.1109/infvis.2002.1173152", "10.1109/tvcg.2015.2467691", "10.1109/tvcg.2003.1196007", "10.1109/infvis.2005.1532150", "10.1145/3243250.3243266", "10.1080/02693799008941549", "10.1371/journal.pone.0058779", "10.1109/infvis.1995.528686", "10.1111/cgf.12872", "10.1002/spe.4380211102", "10.1109/38.974518", "10.1145/3097983.3098130", "10.1002/aris.1440370106", "10.1145/1360612.1360691", "10.1109/mc.2016.145", "10.2307/3006914", "10.1111/j.1467-8659.2009.01683.x", "10.1145/1639714.1639784"], "wos": 1, "children": [], "len": 1}], "len": 9}], "len": 43}, "index": 1405, "embedding": [4.0456109046936035, 3.395711898803711, -1.0404996871948242, -2.2971394062042236, -0.6897369623184204, 0.16650904715061188, -0.664513111114502, 2.7948288917541504, -0.221489816904068, 3.495243549346924, 1.5254193544387817, 2.6724209785461426, 0.2391367107629776, 3.2360048294067383, 1.0625518560409546, 5.428105354309082, 3.496619462966919, 5.109307289123535, -0.030737193301320076, 5.347872734069824, -0.06630208343267441, 1.857051134109497, 1.8666338920593262, 5.917497634887695, -2.3829734325408936, 3.0829293727874756, -0.5834015607833862, 4.34485387802124, 3.849747896194458, 0.579859733581543, 2.4661715030670166, 4.146564483642578], "projection": [0.6705543994903564, 10.348980903625488], "size": 22, "height": 3, "width": 12}