{"data": {"doi": "10.1109/tvcg.2018.2865235", "title": "Multiple Coordinated Views at Large Displays for Multiple Users: Empirical Findings on User Behavior, Movements, and Distances", "year": "2018", "conferenceName": "InfoVis", "authors": "Ricardo Langner;Ulrike Kister;Raimund Dachselt", "citationCount": "5", "affiliation": "Langner, R (Corresponding Author), Tech Univ Dresden, Interact Media Lab, Dresden, Germany. Langner, Ricardo; Kister, Ulrike; Dachselt, Raimund, Tech Univ Dresden, Interact Media Lab, Dresden, Germany.", "countries": "Germany", "abstract": "Interactive wall-sized displays benefit data visualization. Due to their sheer display size, they make it possible to show large amounts of data in multiple coordinated views (MCV) and facilitate collaborative data analysis. In this work, we propose a set of important design considerations and contribute a fundamental input vocabulary and interaction mapping for MCV functionality. We also developed a fully functional application with more than 45 coordinated views visualizing a real-world, multivariate data set of crime activities, which we used in a comprehensive qualitative user study investigating how pairs of users behave. Most importantly, we found that flexible movement is essential and-depending on user goals-is connected to collaboration, perception, and interaction. Therefore, we argue that for future systems interaction from the distance is required and needs good support. We show that our consistent design for both direct touch at the large display and distant interaction using mobile phones enables the seamless exploration of large-scale MCV at wall-sized displays. Our MCV application builds on design aspects such as simplicity, flexibility, and visual consistency and, therefore, supports realistic workflows. We believe that in the future, many visual data analysis scenarios will benefit from wall-sized displays presenting numerous coordinated visualizations, for which our findings provide a valuable foundation.", "keywords": "Multiple coordinated views,wall-sized displays,mobile devices,distant interaction,physical navigation,user behavior,user movements,multi-user,collaborative data analysis", "link": "http://dx.doi.org/10.1109/TVCG.2018.2865235", "refList": ["10.1109/mcg.2014.82", "10.1111/j.1467-8659.2009.01444.x", "10.1016/j.cag.2007.01.029", "10.1109/vast.2010.5652880", "10.1109/tvcg.2013.166", "10.1145/3025453.3025594", "10.1109/tvcg.2012.275", "10.1145/2254556.2254652", "10.1145/1866029.1866034", "10.1145/1099203.1099209", "10.1145/2470654.2470695", "10.1109/tvcg.2017.2744019", "10.1109/tvcg.2012.237", "10.1145/3173574.3173593", "10.1109/tvcg.2013.134", "10.1109/vast.2016.7883506", "10.1145/2817721.2817735", "10.1145/2317956.2318025", "10.1111/cgf.12871", "10.1109/tvcg.2017.2744198", "10.1145/3025453.3026006", "10.1109/cmv.2007.20", "10.1145/2470654.2481318", "10.1145/2598153.2598195", "10.1109/tvcg.2009.162", "10.1145/3173574.3173747", "10.1145/2576099", "10.1145/2207676.2208691", "10.1145/2858036.2858039", "10.1145/2556288.2557231", "10.1145/2556288.2556956", "10.1109/tvcg.2017.2745219", "10.1177/1473871617725907", "10.1145/2557500.2557541", "10.1007/978-3-319-22698-9\\_31", "10.1145/2785830.2785849", "10.1145/2207676.2208690", "10.1007/s00779-013-0727-2", "10.1109/tvcg.2016.2592906", "10.1111/cgf.13206", "10.1145/2207676.2208639", "10.1145/2817721.2817726", "10.1145/2556288.2557020", "10.1145/2598153.2598163", "10.1145/2254556.2254708", "10.1145/2669485.2669507", "10.1109/tvcg.2006.184", "10.1109/tvcg.2017.2743859", "10.1109/tvcg.2012.204", "10.1145/2207676.2208297", "10.1145/1897239.1897250", "10.1145/2858036.2858118", "10.1145/2396636.2396675", "10.1145/1731903.1731926", "10.1145/2702123.2702406", "10.1109/tvcg.2012.251", "10.1145/2702123.2702312", "10.1145/1936652.1936693", "10.1177/1473871611415997", "10.1145/2556288.2557170", "10.1145/2992154.2992157", "10.1145/3206505.3206506", "10.1007/978-3-319-45853-3\\_5"], "wos": 1, "children": [{"doi": "10.1109/tvcg.2020.3030338", "title": "Composition and Configuration Patterns in Multiple-View Visualizations", "year": "2020", "conferenceName": "InfoVis", "authors": "Xi Chen;Wei Zeng 0004;Yanna Lin;Hayder Al-Maneea;Jonathan Roberts 0002;Remco Chang", "citationCount": "0", "affiliation": "Zeng, W (Corresponding Author), Chinese Acad Sci, Shenzhen Inst Adv Technol, Shenzhen, Peoples R China. Chen, Xi; Zeng, Wei; Lin, Yanna, Chinese Acad Sci, Shenzhen Inst Adv Technol, Shenzhen, Peoples R China. AI-maneea, Hayder Mahdi; Roberts, Jonathan, Bangor Univ, Bangor, Gwynedd, Wales. Chang, Remco, Tufts Univ, Medford, MA 02155 USA.", "countries": "USA;Wales;China", "abstract": "Multiple-view visualization (MV) is a layout design technique often employed to help users see a large number of data attributes and values in a single cohesive representation. Because of its generalizability, the MV design has been widely adopted by the visualization community to help users examine and interact with large, complex, and high-dimensional data. However, although ubiquitous, there has been little work to categorize and analyze MVs in order to better understand its design space. As a result, there has been little to no guideline in how to use the MV design effectively. In this paper, we present an in-depth study of how MVs are designed in practice. We focus on two fundamental measures of multiple-view patterns: composition, which quantifies what view types and how many are there; and configuration, which characterizes spatial arrangement of view layouts in the display space. We build a new dataset containing 360 images of MVs collected from IEEE VIS, EuroVis, and PacificVis publications 2011 to 2019, and make fine-grained annotations of view types and layouts for these visualization images. From this data we conduct composition and configuration analyses using quantitative metrics of term frequency and layout topology. We identify common practices around MVs, including relationship of view types, popular view layouts, and correlation between view types and layouts. We combine the findings into a MV recommendation system, providing interactive tools to explore the design space, and support example-based design.", "keywords": "Multiple views,design pattern,quantitative analysis,example-based design", "link": "http://dx.doi.org/10.1109/TVCG.2020.3030338", "refList": ["10.1109/tvcg.2018.2865235", "10.1109/tvcg.2016.2615308", "10.1145/2642918.2647398", "10.1177/1473871611416549", "10.1109/tvcg.2019.2934810", "10.1109/tvcg.2014.48", "10.1109/tvcg.2018.2864903", "10.1145/345513.345271", "10.1109/iv.1998.694193", "10.1109/tvcg.2007.70594", "10.1109/tvcg.2017.2744019", "10.1109/tvcg.2011.185", "10.1109/tvcg.2015.2467194", "10.1109/visual.1991.175815", "10.14778/2831360.2831371", "10.1109/mcg.2019.2924636", "10.1111/cgf.13673", "10.1111/cgf.12131", "10.1109/tvcg.2017.2744198", "10.1145/108360.108361", "10.1109/vl.1996.545307", "10.1109/tvcg.2017.2745140", "10.1109/cmv.2007.20", "10.1145/198366.198376", "10.1145/2508363.2508405", "10.1111/cgf.12114", "10.1109/icde.2018.00019", "10.1109/tvcg.2017.2787113", "10.1109/tvcg.2018.2865240", "10.1111/cgf.13380", "10.1111/cgf.12902", "10.1109/vast.2015.7347628", "10.2307/2288400", "10.1109/infvis.2004.12", "10.1145/102377.115768", "10.1109/tvcg.2009.179", "10.1109/2945.981851", "10.1109/tvcg.2007.70521", "10.1109/pacificvis.2012.6183556", "10.1145/2213836", "10.1109/tvcg.2013.234", "10.1109/iv.2008.87"], "wos": 1, "children": [], "len": 1}, {"doi": "10.1109/tvcg.2020.3030460", "title": "Personal Augmented Reality for Information Visualization on Large Interactive Displays", "year": "2020", "conferenceName": "InfoVis", "authors": "Patrick Reipschl\u00e4ger;Tamara Flemisch;Raimund Dachselt", "citationCount": "0", "affiliation": "Reipschlager, P (Corresponding Author), Tech Univ Dresden, Interact Media Lab, Dresden, Germany. Reipschlager, Patrick; Flemisch, Tamara; Dachselt, Raimund, Tech Univ Dresden, Interact Media Lab, Dresden, Germany. Dachselt, Raimund, Tech Univ Dresden, Ctr Tactile Internet CeTi, Dresden, Germany. Dachselt, Raimund, Tech Univ Dresden, Cluster Excellence Phys Life, Dresden, Germany.", "countries": "Germany", "abstract": "In this work we propose the combination of large interactive displays with personal head-mounted Augmented Reality (AR) for information visualization to facilitate data exploration and analysis. Even though large displays provide more display space, they are challenging with regard to perception, effective multi-user support, and managing data density and complexity. To address these issues and illustrate our proposed setup, we contribute an extensive design space comprising first, the spatial alignment of display, visualizations, and objects in AR space. Next, we discuss which parts of a visualization can be augmented. Finally, we analyze how AR can be used to display personal views in order to show additional information and to minimize the mutual disturbance of data analysts. Based on this conceptual foundation, we present a number of exemplary techniques for extending visualizations with AR and discuss their relation to our design space. We further describe how these techniques address typical visualization problems that we have identified during our literature research. To examine our concepts, we introduce a generic AR visualization framework as well as a prototype implementing several example techniques. In order to demonstrate their potential, we further present a use case walkthrough in which we analyze a movie data set. From these experiences, we conclude that the contributed techniques can be useful in exploring and understanding multivariate data. We are convinced that the extension of large displays with AR for information visualization has a great potential for data analysis and sense-making.", "keywords": "Augmented Reality,Information Visualization,InfoVis,Large Displays,Immersive Analytics,Physical Navigation,Multiple Coordinated Views", "link": "http://dx.doi.org/10.1109/TVCG.2020.3030460", "refList": ["10.1109/tvcg.2008.153", "10.1109/tvcg.2013.166", "10.1109/tvcg.2012.275", "10.1109/tvcg.2019.2934803", "10.1177/1473871611412817", "10.1109/tvcg.2017.2745958", "10.1109/tvcg.2019.2934415", "10.1109/tvcg.2009.162", "10.1109/mcg.2019.2897927", "10.1109/tvcg.2017.2744199", "10.1145/3126594.3126613", "10.1145/3173574.3173759", "10.1145/3290605.3300360", "10.1145/2858036.2858158", "10.1145/642611.642695", "10.1145/2702123.2702312", "10.1109/3dui.2014.6798833", "10.1109/tvcg.2018.2865235", "10.1111/cgf.13213", "10.1109/mcg.2014.82", "10.1145/3343055.3359718", "10.1007/978-3-030-01388-2\\_1", "10.1145/2858036.2858524", "10.1145/3173574.3173610", "10.1145/2817721.2817735", "10.1145/1166253.1166280", "10.1109/vr46266.2020.1582298687237", "10.1145/2576099", "10.1145/3173574.3173664", "10.1109/infvis.2005.1532136", "10.1080/15384047.2020.1806642", "10.1023/a:1021271517844", "10.1109/tvcg.2019.2903956", "10.1177/1473871611415997", "10.1145/2817721.2823505", "10.1145/3290605.3300521", "10.1016/s1071-5819(03)00021-1", "10.1145/2470654.2466431", "10.1109/vr.2019.8797733", "10.1177/1473871611416549", "10.1109/tvcg.2011.287", "10.2312/eurp.20191136", "10.1111/cgf.12871", "10.1145/3290605.3300288", "10.1109/3dui.2014.6798842", "10.1145/302979.303113", "10.1145/3343055.3359709", "10.1109/tvcg.2013.197", "10.1007/s11071-020-05736-x", "10.1109/vr46266.2020.00-23", "10.1109/tvcg.2016.2592906", "10.1109/mcg.2019.2898856", "10.1109/tvcg.2016.2640960", "10.1109/tvcg.2017.2745258", "10.1145/2817721.2817726", "10.1109/tvcg.2018.2865192", "10.1109/bigdata.2018.8622521", "10.1109/tvcg.2012.204", "10.1080/07370024.2019.1697697", "10.1109/vr46266.2020.1581122519414", "10.1109/vr46266.2020.00-20", "10.1109/pacificvis.2019.00010", "10.1145/3359996.3364242", "10.1145/3173574.3173593", "10.1109/ismar-adjunct.2016.0030", "10.1145/2317956.2318025", "10.1109/cmv.2007.20", "10.1080/07370020902739429", "10.1109/visual.2019.8933673", "10.1109/tvcg.2016.2598608", "10.1145/2702123.2702331", "10.1109/tvcg.2017.2745941", "10.1145/1936652.1936676", "10.1117/12.2521648", "10.1145/3009939.3009945", "10.1111/cgf.13206", "10.1109/tvcg.2013.163", "10.1109/tvcg.2017.2744184", "10.1145/2785830.2785871", "10.1109/tvcg.2012.251"], "wos": 1, "children": [], "len": 1}, {"doi": "10.1109/tvcg.2020.3030334", "title": "Uplift: A Tangible and Immersive Tabletop System for Casual Collaborative Visual Analytics", "year": "2020", "conferenceName": "VAST", "authors": "Barrett Ens;Sarah Goodwin;Arnaud Prouzeau;Fraser Anderson;Florence Y. Wang;Samuel Gratzl;Zac Lucarelli;Brendan Moyle;Jim Smiley;Tim Dwyer", "citationCount": "0", "affiliation": "Ens, B (Corresponding Author), Monash Univ, Clayton, Vic, Australia. Ens, Barrett; Goodwin, Sarah; Prouzeau, Arnaud; Wang, Florence Y.; Gratzl, Samuel; Lucarelli, Zac; Moyle, Brendan; Smiley, Jim; Dwyer, Tim, Monash Univ, Clayton, Vic, Australia. Anderson, Fraser, Autodesk Res, Toronto, ON, Canada.", "countries": "Canada;Australia", "abstract": "Collaborative visual analytics leverages social interaction to support data exploration and sensemaking. These processes are typically imagined as formalised, extended activities, between groups of dedicated experts, requiring expertise with sophisticated data analysis tools. However, there are many professional domains that benefit from support for short 'bursts' of data exploration between a subset of stakeholders with a diverse breadth of knowledge. Such 'casual collaborative\u2019 scenarios will require engaging features to draw users' attention, with intuitive, 'walk-up and use\u2019 interfaces. This paper presents Uplift, a novel prototype system to support 'casual collaborative visual analytics' for a campus microgrid, co-designed with local stakeholders. An elicitation workshop with key members of the building management team revealed relevant knowledge is distributed among multiple experts in their team, each using bespoke analysis tools. Uplift combines an engaging 3D model on a central tabletop display with intuitive tangible interaction, as well as augmented-reality, mid-air data visualisation, in order to support casual collaborative visual analytics for this complex domain. Evaluations with expert stakeholders from the building management and energy domains were conducted during and following our prototype development and indicate that Uplift is successful as an engaging backdrop for casual collaboration. Experts see high potential in such a system to bring together diverse knowledge holders and reveal complex interactions between structural, operational, and financial aspects of their domain. Such systems have further potential in other domains that require collaborative discussion or demonstration of models, forecasts, or cost-benefit analyses to high-level stakeholders.", "keywords": "Data visualisation,tangible and embedded interaction,augmented reality,immersive analytics", "link": "http://dx.doi.org/10.1109/TVCG.2020.3030334", "refList": ["10.1109/vr.2019.8797733", "10.1109/tvcg.2018.2865235", "10.1111/cgf.13213", "10.1109/mcg.2014.82", "10.1109/tvcg.2008.153", "10.1145/1240624.1240701", "10.1109/tvcg.2013.166", "10.1177/1473871611416549", "10.1145/3343055.3359718", "10.1109/pacificvis.2019.00010", "10.1109/tvcg.2012.275", "10.1109/vr46266.2020.00-20", "10.1109/tvcg.2011.287", "10.3788/co.20201301.0001", "10.1109/tvcg.2019.2934803", "10.1145/3173574.3173610", "10.1145/2858036.2858524", "10.1145/3359996.3364242", "10.1145/3173574.3173593", "10.1177/1473871611412817", "10.1109/tvcg.2017.2745958", "10.1111/cgf.12871", "10.1145/2817721.2817735", "10.1145/2317956.2318025", "10.1145/1166253.1166280", "10.1007/978-3-319-73207-7", "10.1109/tvcg.2019.2934415", "10.1109/cmv.2007.20", "10.1109/vr46266.2020.1582298687237", "10.1109/tvcg.2009.162", "10.1109/visual.2019.8933673", "10.1109/mcg.2019.2897927", "10.1145/2702123.2702331", "10.1145/2576099", "10.1145/3290605.3300288", "10.1145/3173574.3173664", "10.1109/infvis.2005.1532136", "10.1109/3dui.2014.6798842", "10.1145/302979.303113", "10.1145/3343055.3359709", "10.1109/tvcg.2016.2598608", "10.1109/tvcg.2017.2744199", "10.1145/1936652.1936676", "10.1117/12.2521648", "10.1080/15384047.2020.1806642", "10.1109/tvcg.2013.197", "10.1145/3009939.3009945", "10.1145/3126594.3126613", "10.1109/tvcg.2016.2592906", "10.1109/mcg.2019.2898856", "10.1111/cgf.13206", "10.1109/tvcg.2013.163", "10.1109/tvcg.2016.2640960", "10.1145/3173574.3173759", "10.1109/tvcg.2017.2744184", "10.1109/tvcg.2017.2745258", "10.1023/a:1021271517844", "10.1145/2817721.2817726", "10.1145/2858036.2858158", "10.1109/tvcg.2018.2865192", "10.1109/bigdata.2018.8622521", "10.1145/642611.642695", "10.1145/2785830.2785871", "10.1109/tvcg.2012.204", "10.1080/07370024.2019.1697697", "10.1109/tvcg.2019.2903956", "10.1109/tcyb.2020.2970556", "10.1109/tvcg.2012.251", "10.1145/2702123.2702312", "10.1177/1473871611415997", "10.1145/2817721.2823505", "10.1145/3290605.3300521", "10.2312/eurp", "10.1145/2470654.2466431"], "wos": 1, "children": [], "len": 1}, {"doi": "10.1111/cgf.13995", "year": "2020", "title": "GTMapLens: Interactive Lens for Geo-Text Data Browsing on Map", "conferenceName": "EuroVis", "authors": "Chao Ma;Ye Zhao;Shamal Al{-}Dohuki;Jing Yang;Xinyue Ye;Farah Kamw;Md. Amiruzzaman", "citationCount": "0", "affiliation": "Zhao, Y (Corresponding Author), Kent State Univ, Kent, OH 44240 USA.\nMa, Chao; Zhao, Ye; Amiruzzaman, Md, Kent State Univ, Kent, OH 44240 USA.\nAl-Dohuki, Shamal, Univ Duhok, Duhok, Iraq.\nYang, Jing, Univ N Carolina, Charlotte, NC USA.\nYe, Xinyue, New Jersey Inst Technol, Newark, NJ 07102 USA.\nKamw, Farah, Concordia Univ, Ann Arbor, MI USA.", "countries": "USA;Iraq", "abstract": "Data containing geospatial semantics, such as geotagged tweets, travel blogs, and crime reports, associates natural language texts with geographical locations. This paper presents a lens-based visual interaction technique, GTMapLens, to flexibly browse the geo-text data on a map. It allows users to perform dynamic focus+context exploration by using movable lenses to browse geographical regions, find locations of interest, and perform comparative and drill-down studies. Geo-text data is visualized in a way that users can easily perceive the underlying geospatial semantics along with lens moving. Based on a requirement analysis with a cohort of multidisciplinary domain experts, a set of lens interaction techniques are developed including keywords control, path management, context visualization, and snapshot anchors. They allow users to achieve a guided and controllable exploration of geo-text data. A hierarchical data model enables the interactive lens operations by accelerated data retrieval from a geo-text database. Evaluation with real-world datasets is presented to show the usability and effectiveness of GTMapLens.", "keywords": "", "link": "https://doi.org/10.1111/cgf.13995", "refList": ["10.1109/tvcg.2018.2865235", "10.1145/1936652.1936673", "10.1145/2598153.2598200", "10.1145/1456650.1456652", "10.1109/vast.2011.6102456", "10.1145/3290605.3300864", "10.1177/1473871611413180", "10.1109/iv.2011.43", "10.1109/tvcg.2015.2467971", "10.1109/iv.2016.62", "10.1080/13658816.2017.1325488", "10.1111/cgf.12871", "10.1111/cgf.12132", "10.1109/mc.2012.430", "10.1109/tvcg.2016.2598585", "10.1109/tvcg.2011.195", "10.1109/tvcg.2015.2467619", "10.1109/pacificvis.2013.6596122", "10.13140/rg.2.2.36636.59521", "10.1145/3170427.3188506", "10.1016/b978-155860915-0/50040-8", "10.1109/infvis.2003.1249008", "10.1109/tvcg.2018.2850781", "10.1016/j.datak.2006.01.013", "10.1109/tvcg.2015.2467991", "10.1111/gec3.12404", "10.1109/tvcg.2008.149", "10.1109/visual.1998.745317", "10.1109/pacificvis.2012.6183572", "10.1109/tvcg.2011.176", "10.1016/j.visinf.2018.04.006.2", "10.1111/cgf.13264", "10.1080/13658816.2010.508043", "10.1007/s41651-017-0002-6", "10.1109/tvcg.2009.65", "10.1109/vast.2011.6102498", "10.1145/3025453.3025777", "10.1109/tvcg.2006.138"], "wos": 1, "children": [], "len": 1}, {"doi": "10.1111/cgf.13979", "year": "2020", "title": "Short-Contact Touch-Manipulation of Scatterplot Matrices on Wall Displays", "conferenceName": "EuroVis", "authors": "Patrick Riehmann;Gabriela Molina Le{\\'{o}}n;Joshua Reibert;Florian Echtler;Bernd Fr{\\\"{o}}hlich", "citationCount": "0", "affiliation": "Riehmann, P (Corresponding Author), Bauhaus Univ Weimar, Weimar, Germany.\nRiehmann, P.; Leon, G. Molina; Reibert, J.; Echtler, F.; Froehlich, B., Bauhaus Univ Weimar, Weimar, Germany.\nReibert, J., German Aerosp Ctr DLR, Inst Data Sci, Jena, Germany.\nLeon, G. Molina, Univ Bremen, Bremen, Germany.", "countries": "Germany", "abstract": "This paper presents a short-contact multitouch vocabulary for interacting with scatterplot matrices (SPLOMs) on wall-sized displays. Fling-based gestures overcome central interaction challenges of such large displays by avoiding long swipes on the typically blunt surfaces, frequent physical navigation by walking for accessing screen areas beyond arm's reach in the horizontal direction and uncomfortable postures for accessing screen areas in the vertical direction. Furthermore, we make use of the display's high resolution and large size by supporting the efficient specification of two-tiered focus + context regions which are consistently propagated across the SPLOM. These techniques are complemented by axis-centered and lasso-based selection techniques for specifying subsets of the data. An expert review as well as a user study confirmed the potential and general usability of our seamlessly integrated multitouch interaction techniques for SPLOMs on large vertical displays.", "keywords": "", "link": "https://doi.org/10.1111/cgf.13979", "refList": ["10.1109/tvcg.2018.2865235", "10.1145/3152832.3152852", "10.1109/tvcg.2008.153", "10.1016/j.cag.2007.01.029", "10.1145/3025453.3025594", "10.1109/vast.2009.5332595", "10.1145/2971485.2971503", "10.1145/3173574.3173593", "10.1145/2817721.2817735", "10.1145/2670444.2670445", "10.1145/2470654.2481318", "10.1109/mcg.2005.88", "10.1145/1936652.1936707", "10.1145/2556288.2557231", "10.1111/cgf.12902", "10.1201/9781498710411", "10.1109/tvcg.2016.2592906", "10.1111/cgf.13206", "10.1145/1520340.1520467", "10.1109/tvcg.2010.130", "10.1145/2598153.2598163", "10.1145/2909132.2909258", "10.1002/hbm.20701", "10.1145/2396636.2396675", "10.1145/2702123.2702406", "10.1109/tvcg.2012.251", "10.2312/eurovisshort.20181088", "10.1145/2702123.2702312", "10.1177/1473871611415997", "10.1145/22339.22342", "10.1109/mcg.2013.24", "10.1145/2669485.2669507"], "wos": 1, "children": [], "len": 1}], "len": 11}, "index": 844, "embedding": [3.2807044982910156, 0.9779882431030273, -1.0434188842773438, 2.6749634742736816, -0.02304103597998619, 0.16650904715061188, -0.713410496711731, 1.8534704446792603, 0.17613846063613892, 0.6932321190834045, 1.472191572189331, 0.8474777340888977, -0.15996834635734558, 0.9686423540115356, -0.9109163880348206, 2.283820152282715, 0.4339520037174225, 0.09486686438322067, -0.7097932696342468, 5.354115962982178, -0.06630208343267441, 1.459335446357727, 0.8688979744911194, 1.8847664594650269, -1.2917741537094116, 2.2532854080200195, -0.5581337213516235, -0.20058391988277435, 2.767204761505127, -0.8573732972145081, 0.15140649676322937, 0.855690062046051], "projection": [-1.6221483945846558, 7.481534004211426], "size": 6, "height": 2, "width": 5}