{"data": {"doi": "10.1109/tvcg.2018.2865147", "title": "Mapping Color to Meaning in Colormap Data Visualizations", "year": "2018", "conferenceName": "InfoVis", "authors": "Karen B. Schloss;Connor Gramazio;Allison T. Silverman;Madeline L. Parker;Audrey S. Wang", "citationCount": "4", "affiliation": "Schloss, KB (Corresponding Author), Univ Wisconsin, Dept Psychol, 1202 W Johnson St, Madison, WI 53706 USA. Schloss, KB (Corresponding Author), Univ Wisconsin, Wisconsin Inst Discovery, Madison, WI 53706 USA. Schloss, Karen B.; Parker, Madeline L., Univ Wisconsin, Dept Psychol, 1202 W Johnson St, Madison, WI 53706 USA. Schloss, Karen B.; Parker, Madeline L., Univ Wisconsin, Wisconsin Inst Discovery, Madison, WI 53706 USA. Gramazio, Connor C., Brown Univ, Dept Comp Sci, Providence, RI 02912 USA. Silverman, Allison T., Brown Univ, Sch Publ Hlth, Providence, RI 02912 USA. Wang, Audrey S., CALTECH, Dept Appl \\& Computat Math, Pasadena, CA 91125 USA.", "countries": "USA", "abstract": "To interpret data visualizations, people must determine how visual features map onto concepts. For example, to interpret colormaps, people must determine how dimensions of color (e.g., lightness, hue) map onto quantities of a given measure (e.g., brain activity, correlation magnitude). This process is easier when the encoded mappings in the visualization match people's predictions of how visual features will map onto concepts, their inferred mappings. To harness this principle in visualization design, it is necessary to understand what factors determine people's inferred mappings. In this study, we investigated how inferred color-quantity mappings for colormap data visualizations were influenced by the background color. Prior literature presents seemingly conflicting accounts of how the background color affects inferred color-quantity mappings. The present results help resolve those conflicts, demonstrating that sometimes the background has an effect and sometimes it does not, depending on whether the colormap appears to vary in opacity. When there is no apparent variation in opacity, participants infer that darker colors map to larger quantities (dark-is-more bias). As apparent variation in opacity increases, participants become biased toward inferring that more opaque colors map to larger quantities (opaque-is-more bias). These biases work together on light backgrounds and conflict on dark backgrounds. Under such conflicts, the opaque-is-more bias can negate, or even supersede the dark-is-more bias. The results suggest that if a design goal is to produce colormaps that match people's inferred mappings and are robust to changes in background color, it is beneficial to use colormaps that will not appear to vary in opacity on any background color, and to encode larger quantities in darker colors.", "keywords": "Visual Reasoning,Visual Communication,Colormaps,Color Perception,Visual Encoding,Visual Design", "link": "http://dx.doi.org/10.1109/TVCG.2018.2865147", "refList": ["10.1109/tvcg.2015.2489649", "10.1109/tvcg.2017.2744359", "10.1111/j.1756-8765.2010.01113.x", "10.1109/tvcg.2016.2598918", "10.1007/978-3-642-10520-3\\_9", "10.1016/b978-0-08-042415-6.50014-4", "10.1016/0010-0285(92)90004-l", "10.1006/ijhc.2002.1017", "10.1559/152304090783805663", "10.1037/1076-898x.5.4.393", "10.1126/scitranslmed.aah6904", "10.1179/000870409x12488753453372", "10.1109/6.736450", "10.1037//0033-295x.109.3.492", "10.1006/ijhc.1017", "10.1117/12.384882", "10.3758/bf03201236", "10.1179/000870403235002042", "10.1559/152304097782439231", "10.1109/38.7760", "10.1016/j.neuroimage.2015.04.026", "10.1111/cgf.12127", "10.1109/tvcg.2007.70583", "10.1016/j.cag.2010.11.015", "10.1109/tvcg.2017.2743978", "10.3758/bf03203917", "10.1186/s41235-018-0090-y", "10.1145/3406601.3406602", "10.1016/j.neuroimage.2013.01.068", "10.1109/tvcg.2010.162", "10.1559/152304089783813918", "10.1177/1073858409355817", "10.1016/j.visres.2004.02.009"], "wos": 1, "children": [{"doi": "10.1109/tvcg.2019.2934284", "title": "Color Crafting: Automating the Construction of Designer Quality Color Ramps", "year": "2019", "conferenceName": "InfoVis", "authors": "Stephen Smart;Keke Wu;Danielle Albers Szafir", "citationCount": "3", "affiliation": "Smart, S (Corresponding Author), Univ Colorado, Boulder, CO 80309 USA. Smart, Stephen; Wu, Keke; Szafir, Danielle Albers, Univ Colorado, Boulder, CO 80309 USA.", "countries": "USA", "abstract": "Visualizations often encode numeric data using sequential and diverging color ramps. Effective ramps use colors that are sufficiently discriminable, align well with the data, and are aesthetically pleasing. Designers rely on years of experience to create high-quality color ramps. However, it is challenging for novice visualization developers that lack this experience to craft effective ramps as most guidelines for constructing ramps are loosely defined qualitative heuristics that are often difficult to apply. Our goal is to enable visualization developers to readily create effective color encodings using a single seed color. We do this using an algorithmic approach that models designer practices by analyzing patterns in the structure of designer-crafted color ramps. We construct these models from a corpus of 222 expert-designed color ramps, and use the results to automatically generate ramps that mimic designer practices. We evaluate our approach through an empirical study comparing the outputs of our approach with designer-crafted color ramps. Our models produce ramps that support accurate and aesthetically pleasing visualizations at least as well as designer ramps and that outperform conventional mathematical approaches.", "keywords": "Visualization,Aesthetics in Visualization,Color Perception,Visual Design,Design Mining", "link": "http://dx.doi.org/10.1109/TVCG.2019.2934284", "refList": ["10.1145/3009924", "10.1109/tvcg.2015.2489649", "10.1109/tvcg.2017.2744359", "10.1002/(sici)1098-1098(199622)7:2", "10.1016/s0734-189x(83)80046-2", "10.1109/tvcg.2016.2599106", "10.1364/josaa.29.000313", "10.1109/tvcg.2016.2598918", "10.2307/2683294", "10.1109/tvcg.2017.2653106", "10.1016/j.ijhcs.2010.05.006", "10.1016/0146-664x(81)90006-x", "10.1007/978-3-642-10520-3\\_9", "10.1109/38.135886", "10.1146/annurev-psych-120710-100504", "10.1016/j.csda.2008.11.033", "10.1145/2461912.2461988", "10.1016/j.cub.2007.06.022", "10.1016/s0146-664x(79)80040-4", "10.1109/mcg.2004.1297012", "10.1109/iv.2009.94", "10.1109/tpami.2010.184", "10.3758/s13414-010-0027-0", "10.1145/22949.22950", "10.1109/visual.1995.480803", "10.1109/tvcg.2014.2346277", "10.2307/2684111", "10.1109/tvcg.2018.2865240", "10.1111/cgf.12633", "10.1109/38.7760", "10.1016/j.jspi.2015.04.007", "10.1109/iv.2008.24", "10.1145/2939502.2939506", "10.1111/cgf.12127", "10.1016/j.cag.2010.11.015", "10.1145/3025453.3026041", "10.1109/tvcg.2012.315", "10.2307/2288400", "10.1511/2005.5.436", "10.1016/s0097-8493(96)00072-6", "10.1109/mcg.2018.011461525", "10.1145/2470654.2466420", "10.1109/tvcg.2012.279", "10.1109/tvcg.2014.2346978", "10.1109/tvcg.2017.2743978", "10.1145/3406601.3406602", "10.1117/12.2084548", "10.1109/tvcg.2018.2865147", "10.1109/tvcg.2015.2467191", "10.1111/cgf.13446", "10.1109/tvcg.2017.2744320", "10.1111/j.1467-8659.2008.01203.x", "10.1145/2702613.2702975", "10.1007/978-3-319-26633-6\\_13", "10.1145/2207676.2208547", "10.1109/tvcg.2008.174", "10.1179/000870403235002042"], "wos": 1, "children": [{"doi": "10.1109/tvcg.2020.3028891", "title": "A Structured Review of Data Management Technology for Interactive Visualization and Analysis", "year": "2020", "conferenceName": "InfoVis", "authors": "Leilani Battle;Carlos Scheidegger", "citationCount": "0", "affiliation": "Battle, L (Corresponding Author), Univ Maryland, Dept Comp Sci, College Pk, MD 20742 USA. Battle, Leilani, Univ Maryland, Dept Comp Sci, College Pk, MD 20742 USA. Scheidegger, Carlos, Univ Arizona, Dept Comp Sci, HDC Lab, Tucson, AZ 85721 USA.", "countries": "USA", "abstract": "In the last two decades, interactive visualization and analysis have become a central tool in data-driven decision making. Concurrently to the contributions in data visualization, research in data management has produced technology that directly benefits interactive analysis. Here, we contribute a systematic review of 30 years of work in this adjacent field, and highlight techniques and principles we believe to be underappreciated in visualization work. We structure our review along two axes. First, we use task taxonomies from the visualization literature to structure the space of interactions in usual systems. Second, we created a categorization of data management work that strikes a balance between specificity and generality. Concretely, we contribute a characterization of 131 research papers along these two axes. We find that five notions in data management venues fit interactive visualization systems well: materialized views, approximate query processing, user modeling and query prediction, muiti-query optimization, lineage techniques, and indexing techniques. In addition, we find a preponderance of work in materialized views and approximate query processing, most targeting a limited subset of the interaction tasks in the taxonomy we used. This suggests natural avenues of future research both in visualization and data management. Our categorization both changes how we visualization researchers design and build our systems, and highlights where future work is necessary.", "keywords": "", "link": "http://dx.doi.org/10.1109/TVCG.2020.3028891", "refList": ["10.1109/tvcg.2012.233", "10.1016/s0022-5371(74)80015-0", "10.1109/tvcg.2017.2744359", "10.1037/0096-3445.136.4.623", "10.1109/tvcg.2015.2467732", "10.1109/tvcg.2012.196", "10.1037/a0029856", "10.1109/tvcg.2014.2346979", "10.1037/h0030300", "10.1109/tvcg.2016.2598918", "10.1109/beliv.2018.8634420", "10.1109/tvcg.2018.2864909", "10.1111/cgf.13079", "10.3389/fpsyg.2012.00355", "10.1145/2858036.2858465", "10.1080/01621459.1989.10478821", "10.1037/0278-7393.24.3.732", "10.1109/tvcg.2011.127", "10.1145/2858036.2858063", "10.4249/scholarpedia.3325", "10.4324/9781410611949", "10.1111/cgf.13444", "10.1145/2993901.2993909", "10.1037/0033-295x.96.2.267", "10.1006/ijhc.1017", "10.1086/405615", "10.1109/tvcg.2019.2934801", "10.1038/17953", "10.1037/xhp0000314", "10.1109/tvcg.2019.2934400", "10.1145/2470654.2470723", "10.1037/0096-1523.16.2.332", "10.1167/16.5.11", "10.3758/s13423-016-1174-7", "10.3758/bf03207704", "10.1146/annurev.psych.55.090902.141415", "10.2307/2288400", "10.3758/bf03204258", "10.1109/tvcg.2011.279", "10.1109/vissoft.2014.36", "10.3758/s13423-011-0055-3", "10.1145/3025453.3025922", "10.1109/tvcg.2019.2934284", "10.3758/bf03210498", "10.3758/bf03200774", "10.2307/1419876", "10.1038/s41562-017-0058", "10.1109/tvcg.2010.237", "10.1109/pacificvis.2012.6183556", "10.1109/infvis.1997.636792", "10.1093/acprof:oso/9780198523192.003.0005", "10.1073/pnas.1117465109", "10.1109/tvcg.2013.234", "10.1038/nn.3655", "10.1111/cgf.12379", "10.1146/annurev-psych-010416-044232", "10.1111/cgf.13695", "10.1037/0033-295x.107.3.500", "10.1109/tvcg.2013.183", "10.1146/annurev.psych.53.100901.135125", "10.1037//0022-3514.79.6.995", "10.1559/152304003100010929", "10.1109/tvcg.2018.2865147", "10.1037/0096-1523.18.3.849", "10.1111/j.1467-8659.2009.01694.x", "10.1145/3290605.3300771"], "wos": 1, "children": [], "len": 1}], "len": 3}, {"doi": "10.1109/tvcg.2019.2934536", "title": "Estimating Color-Concept Associations from Image Statistics", "year": "2019", "conferenceName": "InfoVis", "authors": "Ragini Rathore;Zachary Leggon;Laurent Lessard;Karen B. Schloss", "citationCount": "1", "affiliation": "Rathore, R (Corresponding Author), Univ Wisconsin, Comp Sci, Madison, WI 53706 USA. Rathore, R (Corresponding Author), Univ Wisconsin, WID, Madison, WI 53706 USA. Rathore, Ragini, Univ Wisconsin, Comp Sci, Madison, WI 53706 USA. Rathore, Ragini; Leggon, Zachary; Lessard, Laurent; Schloss, Karen B., Univ Wisconsin, WID, Madison, WI 53706 USA. Leggon, Zachary, Univ Wisconsin, Biol, Madison, WI 53706 USA. Lessard, Laurent, Univ Wisconsin, Elect \\& Comp Engn, Madison, WI 53706 USA. Schloss, Karen B., Univ Wisconsin, Psychol, Madison, WI 53706 USA.", "countries": "USA", "abstract": "To interpret the meanings of colors in visualizations of categorical information, people must determine how distinct colors correspond to different concepts. This process is easier when assignments between colors and concepts in visualizations match people's expectations, making color palettes semantically interpretable. Efforts have been underway to optimize color palette design for semantic interpretablity, but this requires having good estimates of human color-concept associations. Obtaining these data from humans is costly, which motivates the need for automated methods. We developed and evaluated a new method for automatically estimating color-concept associations in a way that strongly correlates with human ratings. Building on prior studies using Google Images, our approach operates directly on Google Image search results without the need for humans in the loop. Specifically, we evaluated several methods for extracting raw pixel content of the images in order to best estimate color-concept associations obtained from human ratings. The most effective method extracted colors using a combination of cylindrical sectors and color categories in color space. We demonstrate that our approach can accurately estimate average human color-concept associations for different fruits using only a small set of images. The approach also generalizes moderately well to more complicated recycling-related concepts of objects that can appear in any color.", "keywords": "Visual Reasoning,Visual Communication,Visual Encoding,Color Perception,Color Cognition,Color Categories", "link": "http://dx.doi.org/10.1109/TVCG.2019.2934536", "refList": ["10.1145/3009924", "10.1023/b:bttj.0000047600.45421.6d", "10.1525/ae.1974.1.1.02a00030", "10.1109/tvcg.2017.2744359", "10.1109/tvcg.2016.2598918", "10.1146/annurev-vision-091517-034231", "10.1109/tvcg.2015.2467471", "10.1037/xge0000076", "10.1016/b978-0-08-042415-6.50014-4", "10.1146/annurev-psych-120710-100504", "10.1073/pnas.0906172107", "10.1109/visual.1996.568118", "10.1163/156856808784532662", "10.1073/pnas.1532837100", "10.1016/j.cogpsych.2004.10.001", "10.7717/peerj.453", "10.1037/met0000159", "10.1073/pnas.1619666114", "10.1080/00221309.1962.9711531", "10.1002/col.20010", "10.1037/xlm0000357", "10.1073/pnas.1513298113", "10.1016/0010-0285(73)90017-0", "10.1111/cgf.12127", "10.1007/bf00133570", "10.1145/3025453.3026041", "10.1037/xge0000560", "10.3758/bf03207619", "10.1371/journal.pone.0149538", "10.1186/s41235-018-0090-y", "10.1525/aa.1984.86.1.02a00050", "10.1016/j.apergo.2018.08.010", "10.1073/pnas.0701644104", "10.1109/cvpr.2015.7298965", "10.1002/col.21756", "10.1145/2207676.2208547", "10.1023/a:1008036829907", "10.1109/tvcg.2018.2865147"], "wos": 1, "children": [{"doi": "10.1109/tvcg.2020.3030439", "title": "Rainbows Revisited: Modeling Effective Colormap Design for Graphical Inference", "year": "2020", "conferenceName": "InfoVis", "authors": "Khairi Reda;Danielle Albers Szafir", "citationCount": "0", "affiliation": "Reda, K (Corresponding Author), Indiana Univ Purdue Univ, Indianapolis, IN 46202 USA. Reda, Khairi, Indiana Univ Purdue Univ, Indianapolis, IN 46202 USA. Szafir, Danielle Albers, Univ Colorado, Boulder, CO 80309 USA.", "countries": "USA", "abstract": "Color mapping is a foundational technique for visualizing scalar data. Prior literature offers guidelines for effective colormap design, such as emphasizing luminance variation while limiting changes in hue. However, empirical studies of color are largely focused on perceptual tasks. This narrow focus inhibits our understanding of how generalizable these guidelines are, particularly to tasks like visual inference that require synthesis and judgement across multiple percepts. Furthermore, the emphasis on traditional ramp designs (e.g., sequential or diverging) may sideline other key metrics or design strategies. We study how a cognitive metric-color name variation-impacts people's ability to make model-based judgments. In two graphical inference experiments, participants saw a series of color-coded scalar fields sampled from different models and assessed the relationships between these models. Contrary to conventional guidelines, participants were more accurate when viewing colormaps that cross a variety of uniquely nameable colors. We modeled participants' performance using this metric and found that it provides a better fit to the experimental data than do existing design principles. Our findings indicate cognitive advantages for colorful maps like rainbow, which exhibit high color categorization, despite their traditionally undesirable perceptual properties. We also found no evidence that color categorization would lead observers to infer false data features. Our results provide empirically grounded metrics for predicting a colormap's performance and suggest alternative guidelines for designing new quantitative colormaps to support inference. The data and materials for this paper are available at: https://osf.io/tck2r/", "keywords": "Color,perception,graphical inference,scalar data", "link": "http://dx.doi.org/10.1109/TVCG.2020.3030439", "refList": ["10.1109/tvcg.2012.233", "10.1109/tvcg.2017.2744359", "10.1111/j.1756-8765.2010.01113.x", "10.1109/tvcg.2016.2598918", "10.1109/tvcg.2015.2467471", "10.1016/b978-0-08-042415-6.50014-4", "10.1146/annurev-psych-120710-100504", "10.1080/13875868.2015.1137577", "10.1109/visual.1996.568118", "10.1006/ijhc.1017", "10.1109/tvcg.2014.2346983", "10.3758/bf03201236", "10.2307/2981473", "10.1037/0033-2909.114.3.510", "10.1111/cgf.12127", "10.1002/nav.3800020109", "10.1145/3025453.3026041", "10.1111/j.1756-8765.2011.01150.x", "10.1016/0010-0285(80)90005-5", "10.1207/s15516709cog1003\\_2", "10.1109/tvcg.2019.2934536", "10.1186/s41235-018-0090-y", "10.1023/a:1013180410169", "10.1038/s41562-017-0058", "10.20982/tqmp.01.1.p042", "10.1137/0105003", "10.1559/152304089783813918", "10.1109/tvcg.2018.2865147", "10.1179/000870403235002042", "10.1179/caj.1968.5.1.54"], "wos": 1, "children": [], "len": 1}, {"doi": "10.1109/tvcg.2020.3030434", "title": "Semantic Discriminability for Visual Communication", "year": "2020", "conferenceName": "InfoVis", "authors": "Karen B. Schloss;Zachary Leggon;Laurent Lessard", "citationCount": "0", "affiliation": "Schloss, KB (Corresponding Author), Univ Wisconsin, Psychol, Madison, WI 53706 USA. Schloss, KB (Corresponding Author), Univ Wisconsin, Wisconsin Inst Discovery, Madison, WI 53706 USA. Schloss, Karen B., Univ Wisconsin, Psychol, Madison, WI 53706 USA. Schloss, Karen B.; Leggon, Zachary, Univ Wisconsin, Wisconsin Inst Discovery, Madison, WI 53706 USA. Leggon, Zachary, Univ Wisconsin, Biol, Madison, WI USA. Lessard, Laurent, Northeastern Univ, Mech \\& Ind Engn, Boston, MA 02115 USA.", "countries": "USA", "abstract": "To interpret information visualizations, observers must determine how visual features map onto concepts. First and foremost, this ability depends on perceptual discriminability; observers must be able to see the difference between different colors for those colors to communicate different meanings. However, the ability to interpret visualizations also depends on semantic discriminability, the degree to which observers can infer a unique mapping between visual features and concepts, based on the visual features and concepts alone (i.e., without help from verbal cues such as legends or labels). Previous evidence suggested that observers were better at interpreting encoding systems that maximized semantic discriminability (maximizing association strength between assigned colors and concepts while minimizing association strength between unassigned colors and concepts), compared to a system that only maximized color-concept association strength. However, increasing semantic discriminability also resulted in increased perceptual distance, so it is unclear which factor was responsible for improved performance. In the present study, we conducted two experiments that tested for independent effects of semantic distance and perceptual distance on semantic discriminability of bar graph data visualizations. Perceptual distance was large enough to ensure colors were more than just noticeably different. We found that increasing semantic distance improved performance, independent of variation in perceptual distance, and when these two factors were uncorrelated, responses were dominated by semantic distance. These results have implications for navigating trade-offs in color palette design optimization for visual communication.", "keywords": "Visual Reasoning,Information Visualization,Visual Communication,Visual Encoding,Color Perception,Color Cognition", "link": "http://dx.doi.org/10.1109/TVCG.2020.3030434", "refList": ["10.1109/tvcg.2012.233", "10.1109/tvcg.2017.2744359", "10.1109/tvcg.2016.2598918", "10.1109/tvcg.2015.2467471", "10.1016/b978-0-08-042415-6.50014-4", "10.1146/annurev-psych-120710-100504", "10.1080/13875868.2015.1137577", "10.1109/visual.1996.568118", "10.1006/ijhc.1017", "10.1109/tvcg.2014.2346983", "10.1145/2254556.2254572", "10.3758/bf03201236", "10.2307/2981473", "10.1037/0033-2909.114.3.510", "10.1111/cgf.12127", "10.1002/nav.3800020109", "10.1145/3025453.3026041", "10.1111/j.1756-8765.2011.01150.x", "10.1016/0010-0285(80)90005-5", "10.1207/s15516709cog1003\\_2", "10.1109/tvcg.2019.2934536", "10.1186/s41235-018-0090-y", "10.1023/a:1013180410169", "10.1038/s41562-017-0058", "10.20982/tqmp.01.1.p042", "10.1137/0105003", "10.1559/152304089783813918", "10.1109/tvcg.2018.2865147", "10.1179/000870403235002042", "10.1179/caj.1968.5.1.54"], "wos": 1, "children": [], "len": 1}], "len": 5}, {"doi": "10.1109/tvcg.2020.3028891", "title": "A Structured Review of Data Management Technology for Interactive Visualization and Analysis", "year": "2020", "conferenceName": "InfoVis", "authors": "Leilani Battle;Carlos Scheidegger", "citationCount": "0", "affiliation": "Battle, L (Corresponding Author), Univ Maryland, Dept Comp Sci, College Pk, MD 20742 USA. Battle, Leilani, Univ Maryland, Dept Comp Sci, College Pk, MD 20742 USA. Scheidegger, Carlos, Univ Arizona, Dept Comp Sci, HDC Lab, Tucson, AZ 85721 USA.", "countries": "USA", "abstract": "In the last two decades, interactive visualization and analysis have become a central tool in data-driven decision making. Concurrently to the contributions in data visualization, research in data management has produced technology that directly benefits interactive analysis. Here, we contribute a systematic review of 30 years of work in this adjacent field, and highlight techniques and principles we believe to be underappreciated in visualization work. We structure our review along two axes. First, we use task taxonomies from the visualization literature to structure the space of interactions in usual systems. Second, we created a categorization of data management work that strikes a balance between specificity and generality. Concretely, we contribute a characterization of 131 research papers along these two axes. We find that five notions in data management venues fit interactive visualization systems well: materialized views, approximate query processing, user modeling and query prediction, muiti-query optimization, lineage techniques, and indexing techniques. In addition, we find a preponderance of work in materialized views and approximate query processing, most targeting a limited subset of the interaction tasks in the taxonomy we used. This suggests natural avenues of future research both in visualization and data management. Our categorization both changes how we visualization researchers design and build our systems, and highlights where future work is necessary.", "keywords": "", "link": "http://dx.doi.org/10.1109/TVCG.2020.3028891", "refList": ["10.1109/tvcg.2012.233", "10.1016/s0022-5371(74)80015-0", "10.1109/tvcg.2017.2744359", "10.1037/0096-3445.136.4.623", "10.1109/tvcg.2015.2467732", "10.1109/tvcg.2012.196", "10.1037/a0029856", "10.1109/tvcg.2014.2346979", "10.1037/h0030300", "10.1109/tvcg.2016.2598918", "10.1109/beliv.2018.8634420", "10.1109/tvcg.2018.2864909", "10.1111/cgf.13079", "10.3389/fpsyg.2012.00355", "10.1145/2858036.2858465", "10.1080/01621459.1989.10478821", "10.1037/0278-7393.24.3.732", "10.1109/tvcg.2011.127", "10.1145/2858036.2858063", "10.4249/scholarpedia.3325", "10.4324/9781410611949", "10.1111/cgf.13444", "10.1145/2993901.2993909", "10.1037/0033-295x.96.2.267", "10.1006/ijhc.1017", "10.1086/405615", "10.1109/tvcg.2019.2934801", "10.1038/17953", "10.1037/xhp0000314", "10.1109/tvcg.2019.2934400", "10.1145/2470654.2470723", "10.1037/0096-1523.16.2.332", "10.1167/16.5.11", "10.3758/s13423-016-1174-7", "10.3758/bf03207704", "10.1146/annurev.psych.55.090902.141415", "10.2307/2288400", "10.3758/bf03204258", "10.1109/tvcg.2011.279", "10.1109/vissoft.2014.36", "10.3758/s13423-011-0055-3", "10.1145/3025453.3025922", "10.1109/tvcg.2019.2934284", "10.3758/bf03210498", "10.3758/bf03200774", "10.2307/1419876", "10.1038/s41562-017-0058", "10.1109/tvcg.2010.237", "10.1109/pacificvis.2012.6183556", "10.1109/infvis.1997.636792", "10.1093/acprof:oso/9780198523192.003.0005", "10.1073/pnas.1117465109", "10.1109/tvcg.2013.234", "10.1038/nn.3655", "10.1111/cgf.12379", "10.1146/annurev-psych-010416-044232", "10.1111/cgf.13695", "10.1037/0033-295x.107.3.500", "10.1109/tvcg.2013.183", "10.1146/annurev.psych.53.100901.135125", "10.1037//0022-3514.79.6.995", "10.1559/152304003100010929", "10.1109/tvcg.2018.2865147", "10.1037/0096-1523.18.3.849", "10.1111/j.1467-8659.2009.01694.x", "10.1145/3290605.3300771"], "wos": 1, "children": [], "len": 1}, {"doi": "10.1109/tvcg.2020.3030439", "title": "Rainbows Revisited: Modeling Effective Colormap Design for Graphical Inference", "year": "2020", "conferenceName": "InfoVis", "authors": "Khairi Reda;Danielle Albers Szafir", "citationCount": "0", "affiliation": "Reda, K (Corresponding Author), Indiana Univ Purdue Univ, Indianapolis, IN 46202 USA. Reda, Khairi, Indiana Univ Purdue Univ, Indianapolis, IN 46202 USA. Szafir, Danielle Albers, Univ Colorado, Boulder, CO 80309 USA.", "countries": "USA", "abstract": "Color mapping is a foundational technique for visualizing scalar data. Prior literature offers guidelines for effective colormap design, such as emphasizing luminance variation while limiting changes in hue. However, empirical studies of color are largely focused on perceptual tasks. This narrow focus inhibits our understanding of how generalizable these guidelines are, particularly to tasks like visual inference that require synthesis and judgement across multiple percepts. Furthermore, the emphasis on traditional ramp designs (e.g., sequential or diverging) may sideline other key metrics or design strategies. We study how a cognitive metric-color name variation-impacts people's ability to make model-based judgments. In two graphical inference experiments, participants saw a series of color-coded scalar fields sampled from different models and assessed the relationships between these models. Contrary to conventional guidelines, participants were more accurate when viewing colormaps that cross a variety of uniquely nameable colors. We modeled participants' performance using this metric and found that it provides a better fit to the experimental data than do existing design principles. Our findings indicate cognitive advantages for colorful maps like rainbow, which exhibit high color categorization, despite their traditionally undesirable perceptual properties. We also found no evidence that color categorization would lead observers to infer false data features. Our results provide empirically grounded metrics for predicting a colormap's performance and suggest alternative guidelines for designing new quantitative colormaps to support inference. The data and materials for this paper are available at: https://osf.io/tck2r/", "keywords": "Color,perception,graphical inference,scalar data", "link": "http://dx.doi.org/10.1109/TVCG.2020.3030439", "refList": ["10.1109/tvcg.2012.233", "10.1109/tvcg.2017.2744359", "10.1111/j.1756-8765.2010.01113.x", "10.1109/tvcg.2016.2598918", "10.1109/tvcg.2015.2467471", "10.1016/b978-0-08-042415-6.50014-4", "10.1146/annurev-psych-120710-100504", "10.1080/13875868.2015.1137577", "10.1109/visual.1996.568118", "10.1006/ijhc.1017", "10.1109/tvcg.2014.2346983", "10.3758/bf03201236", "10.2307/2981473", "10.1037/0033-2909.114.3.510", "10.1111/cgf.12127", "10.1002/nav.3800020109", "10.1145/3025453.3026041", "10.1111/j.1756-8765.2011.01150.x", "10.1016/0010-0285(80)90005-5", "10.1207/s15516709cog1003\\_2", "10.1109/tvcg.2019.2934536", "10.1186/s41235-018-0090-y", "10.1023/a:1013180410169", "10.1038/s41562-017-0058", "10.20982/tqmp.01.1.p042", "10.1137/0105003", "10.1559/152304089783813918", "10.1109/tvcg.2018.2865147", "10.1179/000870403235002042", "10.1179/caj.1968.5.1.54"], "wos": 1, "children": [], "len": 1}, {"doi": "10.1109/tvcg.2020.3030434", "title": "Semantic Discriminability for Visual Communication", "year": "2020", "conferenceName": "InfoVis", "authors": "Karen B. Schloss;Zachary Leggon;Laurent Lessard", "citationCount": "0", "affiliation": "Schloss, KB (Corresponding Author), Univ Wisconsin, Psychol, Madison, WI 53706 USA. Schloss, KB (Corresponding Author), Univ Wisconsin, Wisconsin Inst Discovery, Madison, WI 53706 USA. Schloss, Karen B., Univ Wisconsin, Psychol, Madison, WI 53706 USA. Schloss, Karen B.; Leggon, Zachary, Univ Wisconsin, Wisconsin Inst Discovery, Madison, WI 53706 USA. Leggon, Zachary, Univ Wisconsin, Biol, Madison, WI USA. Lessard, Laurent, Northeastern Univ, Mech \\& Ind Engn, Boston, MA 02115 USA.", "countries": "USA", "abstract": "To interpret information visualizations, observers must determine how visual features map onto concepts. First and foremost, this ability depends on perceptual discriminability; observers must be able to see the difference between different colors for those colors to communicate different meanings. However, the ability to interpret visualizations also depends on semantic discriminability, the degree to which observers can infer a unique mapping between visual features and concepts, based on the visual features and concepts alone (i.e., without help from verbal cues such as legends or labels). Previous evidence suggested that observers were better at interpreting encoding systems that maximized semantic discriminability (maximizing association strength between assigned colors and concepts while minimizing association strength between unassigned colors and concepts), compared to a system that only maximized color-concept association strength. However, increasing semantic discriminability also resulted in increased perceptual distance, so it is unclear which factor was responsible for improved performance. In the present study, we conducted two experiments that tested for independent effects of semantic distance and perceptual distance on semantic discriminability of bar graph data visualizations. Perceptual distance was large enough to ensure colors were more than just noticeably different. We found that increasing semantic distance improved performance, independent of variation in perceptual distance, and when these two factors were uncorrelated, responses were dominated by semantic distance. These results have implications for navigating trade-offs in color palette design optimization for visual communication.", "keywords": "Visual Reasoning,Information Visualization,Visual Communication,Visual Encoding,Color Perception,Color Cognition", "link": "http://dx.doi.org/10.1109/TVCG.2020.3030434", "refList": ["10.1109/tvcg.2012.233", "10.1109/tvcg.2017.2744359", "10.1109/tvcg.2016.2598918", "10.1109/tvcg.2015.2467471", "10.1016/b978-0-08-042415-6.50014-4", "10.1146/annurev-psych-120710-100504", "10.1080/13875868.2015.1137577", "10.1109/visual.1996.568118", "10.1006/ijhc.1017", "10.1109/tvcg.2014.2346983", "10.1145/2254556.2254572", "10.3758/bf03201236", "10.2307/2981473", "10.1037/0033-2909.114.3.510", "10.1111/cgf.12127", "10.1002/nav.3800020109", "10.1145/3025453.3026041", "10.1111/j.1756-8765.2011.01150.x", "10.1016/0010-0285(80)90005-5", "10.1207/s15516709cog1003\\_2", "10.1109/tvcg.2019.2934536", "10.1186/s41235-018-0090-y", "10.1023/a:1013180410169", "10.1038/s41562-017-0058", "10.20982/tqmp.01.1.p042", "10.1137/0105003", "10.1559/152304089783813918", "10.1109/tvcg.2018.2865147", "10.1179/000870403235002042", "10.1179/caj.1968.5.1.54"], "wos": 1, "children": [], "len": 1}], "len": 17}, "index": 829, "embedding": [1.6059749126434326, 1.1993125677108765, -1.0662840604782104, 1.6523499488830566, -0.6415178775787354, 0.16650904715061188, -0.7643030881881714, 2.508087158203125, -0.4787178039550781, 0.7585062980651855, 1.487989902496338, 0.46165454387664795, -0.15792734920978546, 0.6723825335502625, -0.8806813955307007, 1.7547732591629028, -0.09861598163843155, 2.056586265563965, -0.7424624562263489, 3.2012975215911865, -0.06630208343267441, 2.680227756500244, -0.14990302920341492, 1.4723591804504395, -1.5555545091629028, 0.9132704734802246, -0.5536867380142212, 0.06615491956472397, 2.7701621055603027, -0.7351844310760498, -0.018582351505756378, 0.9613170623779297], "projection": [-1.487914800643921, 7.622148513793945], "size": 9, "height": 3, "width": 5}