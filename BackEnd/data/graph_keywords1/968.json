{"data": {"doi": "10.1109/tvcg.2019.2934810", "title": "Towards Automated Infographic Design: Deep Learning-based Auto-Extraction of Extensible Timeline", "year": "2019", "conferenceName": "InfoVis", "authors": "Zhutian Chen;Yun Wang 0012;Qianwen Wang;Yong Wang;Huamin Qu", "citationCount": "3", "affiliation": "Chen, ZT (Corresponding Author), Hong Kong Univ Sci \\& Technol, Hong Kong, Peoples R China. Chen, Zhutian; Wang, Qianwen; Wang, Yong; Qu, Huamin, Hong Kong Univ Sci \\& Technol, Hong Kong, Peoples R China. Wang, Yun, Microsoft Res, Redmond, WA USA.", "countries": "USA;China", "abstract": "Designers need to consider not only perceptual effectiveness but also visual styles when creating an infographic. This process can be difficult and time consuming for professional designers, not to mention non-expert users, leading to the demand for automated infographics design. As a first step, we focus on timeline infographics, which have been widely used for centuries. We contribute an end-to-end approach that automatically extracts an extensible timeline template from a bitmap image. Our approach adopts a deconstruction and reconstruction paradigm. At the deconstruction stage, we propose a multi-task deep neural network that simultaneously parses two kinds of information from a bitmap timeline: 1) the global information, i.e., the representation, scale, layout, and orientation of the timeline, and 2) the local information, i.e., the location, category, and pixels of each visual element on the timeline. At the reconstruction stage, we propose a pipeline with three techniques, i.e., Non-Maximum Merging, Redundancy Recover, and DL GrabCut, to extract an extensible template from the infographic, by utilizing the deconstruction results. To evaluate the effectiveness of our approach, we synthesize a timeline dataset (4296 images) and collect a real-world timeline dataset (393 images) from the Internet. We first report quantitative evaluation results of our approach over the two datasets. Then, we present examples of automatically extracted templates and timelines automatically generated based on these templates to qualitatively demonstrate the performance. The results confirm that our approach can effectively extract extensible templates from real-world timeline infographics.", "keywords": "Automated Infographic Design,Deep Learning-based Approach,Timeline Infographics,Multi-task Model", "link": "http://dx.doi.org/10.1109/TVCG.2019.2934810", "refList": ["10.1109/cvpr.2016.89", "10.1109/tvcg.2015.2467732", "10.1109/iccv.2017.324", "10.1109/cvpr.2014.81", "10.1145/2702123.2702275", "10.1109/cvpr.2016.91", "10.1007/978-3-319-46493-0\\_15", "10.1145/3025453.3025957", "10.1109/icdar.2007.4376991", "10.1109/tpami.2016.2577031", "10.1145/2047196.2047247", "10.1109/tvcg.2007.70594", "10.1007/978-3-319-46478-7\\_41", "10.1145/2702123.2702545", "10.1109/cvpr.2015.7298594", "10.1109/cvpr.2017.634", "10.1007/s11263-014-0733-5", "10.1145/3126594.3126653", "10.1145/108360.108361", "10.1145/22949.22950", "10.1109/cvpr.2018.00592", "10.1145/1015706.1015720", "10.1109/icde.2018.00019", "10.1109/tvcg.2018.2865240", "10.1111/cgf.13193", "10.1007/978-3-319-46448-0\\_2", "10.1109/iccv.2017.322", "10.2307/2288400", "10.1109/tpami.2018.2858826", "10.1109/cvpr.2017.106", "10.1109/tvcg.2016.2598620", "10.1109/iccv.2015.169", "10.1109/tvcg.2015.2467191", "10.1109/tvcg.2017.2744320", "10.1145/3242587.3242650", "10.1109/tvcg.2016.2614803"], "wos": 1, "children": [{"doi": "10.1109/tvcg.2020.3030338", "title": "Composition and Configuration Patterns in Multiple-View Visualizations", "year": "2020", "conferenceName": "InfoVis", "authors": "Xi Chen;Wei Zeng 0004;Yanna Lin;Hayder Al-Maneea;Jonathan Roberts 0002;Remco Chang", "citationCount": "0", "affiliation": "Zeng, W (Corresponding Author), Chinese Acad Sci, Shenzhen Inst Adv Technol, Shenzhen, Peoples R China. Chen, Xi; Zeng, Wei; Lin, Yanna, Chinese Acad Sci, Shenzhen Inst Adv Technol, Shenzhen, Peoples R China. AI-maneea, Hayder Mahdi; Roberts, Jonathan, Bangor Univ, Bangor, Gwynedd, Wales. Chang, Remco, Tufts Univ, Medford, MA 02155 USA.", "countries": "USA;Wales;China", "abstract": "Multiple-view visualization (MV) is a layout design technique often employed to help users see a large number of data attributes and values in a single cohesive representation. Because of its generalizability, the MV design has been widely adopted by the visualization community to help users examine and interact with large, complex, and high-dimensional data. However, although ubiquitous, there has been little work to categorize and analyze MVs in order to better understand its design space. As a result, there has been little to no guideline in how to use the MV design effectively. In this paper, we present an in-depth study of how MVs are designed in practice. We focus on two fundamental measures of multiple-view patterns: composition, which quantifies what view types and how many are there; and configuration, which characterizes spatial arrangement of view layouts in the display space. We build a new dataset containing 360 images of MVs collected from IEEE VIS, EuroVis, and PacificVis publications 2011 to 2019, and make fine-grained annotations of view types and layouts for these visualization images. From this data we conduct composition and configuration analyses using quantitative metrics of term frequency and layout topology. We identify common practices around MVs, including relationship of view types, popular view layouts, and correlation between view types and layouts. We combine the findings into a MV recommendation system, providing interactive tools to explore the design space, and support example-based design.", "keywords": "Multiple views,design pattern,quantitative analysis,example-based design", "link": "http://dx.doi.org/10.1109/TVCG.2020.3030338", "refList": ["10.1109/tvcg.2018.2865235", "10.1109/tvcg.2016.2615308", "10.1145/2642918.2647398", "10.1177/1473871611416549", "10.1109/tvcg.2019.2934810", "10.1109/tvcg.2014.48", "10.1109/tvcg.2018.2864903", "10.1145/345513.345271", "10.1109/iv.1998.694193", "10.1109/tvcg.2007.70594", "10.1109/tvcg.2017.2744019", "10.1109/tvcg.2011.185", "10.1109/tvcg.2015.2467194", "10.1109/visual.1991.175815", "10.14778/2831360.2831371", "10.1109/mcg.2019.2924636", "10.1111/cgf.13673", "10.1111/cgf.12131", "10.1109/tvcg.2017.2744198", "10.1145/108360.108361", "10.1109/vl.1996.545307", "10.1109/tvcg.2017.2745140", "10.1109/cmv.2007.20", "10.1145/198366.198376", "10.1145/2508363.2508405", "10.1111/cgf.12114", "10.1109/icde.2018.00019", "10.1109/tvcg.2017.2787113", "10.1109/tvcg.2018.2865240", "10.1111/cgf.13380", "10.1111/cgf.12902", "10.1109/vast.2015.7347628", "10.2307/2288400", "10.1109/infvis.2004.12", "10.1145/102377.115768", "10.1109/tvcg.2009.179", "10.1109/2945.981851", "10.1109/tvcg.2007.70521", "10.1109/pacificvis.2012.6183556", "10.1145/2213836", "10.1109/tvcg.2013.234", "10.1109/iv.2008.87"], "wos": 1, "children": [], "len": 1}, {"doi": "10.1111/cgf.14004", "year": "2020", "title": "Infomages: Embedding Data into Thematic Images", "conferenceName": "EuroVis", "authors": "Darius Coelho;Klaus Mueller", "citationCount": "0", "affiliation": "Coelho, D (Corresponding Author), SUNY Stony Brook, Dept Comp Sci, Stony Brook, NY 11794 USA.\nCoelho, D.; Mueller, K., SUNY Stony Brook, Dept Comp Sci, Stony Brook, NY 11794 USA.", "countries": "USA", "abstract": "Recent studies have indicated that visually embellished charts such as infographics have the ability to engage viewers and positively affect memorability. Fueled by these findings, researchers have proposed a variety of infographic design tools. However, these tools do not cover the entire design space. In this work, we identify a subset of infographics that we call infomages. Infomages are casual visuals of data in which a data chart is embedded into a thematic image such that the content of the image reflects the subject and the designer's interpretation of the data. Creating an effective infomage, however, can require a fair amount of design expertise and is thus out of reach for most people. In order to also afford non-artists with the means to design convincing infomages, we first study the principled design of existing infomages and identify a set of key chart embedding techniques. Informed by these findings we build a design tool that links web-scale image search with a set of interactive image processing tools to empower novice users with the ability to design a wide variety of infomages. As the embedding process might introduce some amount of visual distortion of the data our tool also aids users to gauge the amount of this distortion, if any. We experimentally demonstrate the usability of our tool and conclude with a discussion of infomages and our design tool.", "keywords": "", "link": "https://doi.org/10.1111/cgf.14004", "refList": ["10.1109/mcg.2018.2879066", "10.1109/tvcg.2015.2467732", "10.1002/acp.2350030302", "10.1145/361237.361242", "10.1109/tvcg.2019.2934398", "10.1145/2702123.2702275", "10.1109/tvcg.2019.2934810", "10.1111/cgf.12634", "10.1109/tvcg.2012.221", "10.1145/2702123.2702545", "10.1145/2501988.2502046", "10.1109/tvcg.2012.197", "10.1109/tvcg.2016.2598609", "10.1086/209244", "10.1145/1015706.1015720", "10.1109/tvcg.2011.175", "10.1111/cgf.12888", "10.1109/tvcg.2015.2467321", "10.2307/2288400", "10.1109/tvcg.2006.163", "10.1109/tvcg.2015.2440241", "10.1080/10447319509526110", "10.1109/tvcg.2016.2598620", "10.1109/tvcg.2013.234", "10.1109/tvcg.2019.2934785", "10.1126/science.220.4598.671", "10.1111/j.1469-8986.1993.tb03352.x", "10.1179/000870403235002042", "10.1145/2702123.2702608"], "wos": 1, "children": [], "len": 1}], "len": 5}, "index": 968, "embedding": [0.6005211472511292, -0.10515287518501282, -0.9042168855667114, 0.4749208986759186, 0.4476374089717865, 0.16650904715061188, -0.7477038502693176, 0.691204309463501, 0.6011390089988708, 0.4586586654186249, 0.4566822946071625, -0.2619595229625702, -0.1268409788608551, -1.30717134475708, -0.7128351926803589, -0.13379529118537903, 0.17685288190841675, 0.06584581732749939, -0.6218824982643127, 0.8971555233001709, -0.06630208343267441, -0.2245328724384308, -0.36666226387023926, 0.14095816016197205, -0.7527774572372437, 0.10673608630895615, -0.4969606399536133, -0.16244997084140778, 0.7460197806358337, -0.9087364077568054, -0.2505434453487396, -0.24694526195526123], "projection": [-1.718597650527954, 8.481344223022461], "size": 3, "height": 2, "width": 2}