{"data": {"doi": "10.1109/tvcg.2017.2743898", "title": "Imagining Replications: Graphical Prediction & Discrete Visualizations Improve Recall & Estimation of Effect Uncertainty", "year": "2017", "conferenceName": "InfoVis", "authors": "Jessica Hullman;Matthew Kay;Yea-Seul Kim;Samana Shrestha", "citationCount": "9", "affiliation": "Hulman, J (Corresponding Author), Univ Washington, Seattle, WA 98195 USA. Hulman, Jessica; Kim, Yea-Seul, Univ Washington, Seattle, WA 98195 USA. Kay, Matthew, Univ Michigan, Ann Arbor, MI 48109 USA. Shrestha, Samana, Vassar Coll, Poughkeepsie, NY 12601 USA.", "countries": "USA", "abstract": "People often have erroneous intuitions about the results of uncertain processes, such as scientific experiments. Many uncertainty visualizations assume considerable statistical knowledge, but have been shown to prompt erroneous conclusions even when users possess this knowledge. Active learning approaches been shown to improve statistical reasoning, but are rarely applied in visualizing uncertainty in scientific reports. We present a controlled study to evaluate the impact of an interactive, graphical uncertainty prediction technique for communicating uncertainty in experiment results. Using our technique, users sketch their prediction of the uncertainty in experimental effects prior to viewing the true sampling distribution from an experiment. We find that having a user graphically predict the possible effects from experiment replications is an effective way to improve one's ability to make predictions about replications of new experiments. Additionally, visualizing uncertainty as a set of discrete outcomes, as opposed to a continuous probability distribution, can improve recall of a sampling distribution from a single experiment. Our work has implications for various applications where it is important to elicit peoples' estimates of probability distributions and to communicate uncertainty effectively.", "keywords": "Graphical prediction,interactive uncertainty visualization,replication crisis,probability distribution", "link": "http://dx.doi.org/10.1109/TVCG.2017.2743898", "refList": ["10.1037/0278-7393.26.6.1744", "10.1207/s1532690xci2202\\_1", "10.1097/00001888-199805000-00024", "10.1371/journal.pmed.0020124", "10.1109/tvcg.2012.199", "10.1002/acp.1460", "10.1145/2851581.2886442", "10.2307/1403333", "10.1145/1958824.1958865", "10.1371/journal.pone.0142444", "10.1016/s0022-5371(76)90040-2", "10.1145/2468356.2479636", "10.1109/tvcg.2013.247", "10.1145/1979742.1979491", "10.1214/aoms/1177729694", "10.1016/j.chb.2013.05.009", "10.1016/j.socscimed.2013.01.034", "10.3758/s13423-013-0572-3", "10.1002/bdm.421", "10.1016/s0959-4752(98)00051-6", "10.1002/sce.3730660207", "10.1109/tse.1983.235429", "10.1002/acp.1068", "10.1037//0096-3445.130.3.380", "10.1037/0033-295x.90.4.339", "10.1037/1082-989x.10.4.389", "10.1371/journal.pone.0162874", "10.1016/bs.plm.2016.11.006", "10.1177/0963721413481473", "10.1177/1745691612465253", "10.1037/0033-295x.102.4.684", "10.1109/tvcg.2014.2346298", "10.1016/0010-0277(95)00664-8", "10.1038/nrd3439-c1", "10.1016/0010-0285(86)90001-0", "10.2307/749456", "10.1086/589562"], "wos": 1, "children": [{"doi": "10.1109/tvcg.2018.2864889", "title": "In Pursuit of Error: A Survey of Uncertainty Visualization Evaluation", "year": "2018", "conferenceName": "InfoVis", "authors": "Jessica Hullman;Xiaoli Qiao;Michael Correll;Alex Kale;Matthew Kay", "citationCount": "10", "affiliation": "Hullman, J (Corresponding Author), Northwestern Univ, Evanston, IL 60208 USA. Hullman, Jessica, Northwestern Univ, Evanston, IL 60208 USA. Qiao, Xiaoli; Kale, Alex, Univ Washington, Seattle, WA 98195 USA. Correll, Michael, Tableau Software, Seattle, WA USA. Kay, Matthew, Univ Michigan, Ann Arbor, MI 48109 USA.", "countries": "USA", "abstract": "Understanding and accounting for uncertainty is critical to effectively reasoning about visualized data. However, evaluating the impact of an uncertainty visualization is complex due to the difficulties that people have interpreting uncertainty and the challenge of defining correct behavior with uncertainty information. Currently, evaluators of uncertainty visualization must rely on general purpose visualization evaluation frameworks which can be ill-equipped to provide guidance with the unique difficulties of assessing judgments under uncertainty. To help evaluators navigate these complexities, we present a taxonomy for characterizing decisions made in designing an evaluation of an uncertainty visualization. Our taxonomy differentiates six levels of decisions that comprise an uncertainty visualization evaluation: the behavioral targets of the study, expected effects from an uncertainty visualization, evaluation goals, measures, elicitation techniques, and analysis approaches. Applying our taxonomy to 86 user studies of uncertainty visualizations, we find that existing evaluation practice, particularly in visualization research, focuses on Performance and Satisfaction-based measures that assume more predictable and statistically-driven judgment behavior than is suggested by research on human judgment and decision making. We reflect on common themes in evaluation practice concerning the interpretation and semantics of uncertainty, the use of confidence reporting, and a bias toward evaluating performance as accuracy rather than decision quality. We conclude with a concrete set of recommendations for evaluators designed to reduce the mismatch between the conceptualization of uncertainty in visualization versus other fields.", "keywords": "Uncertainty visualization,user study,subjective confidence,probability distribution", "link": "http://dx.doi.org/10.1109/TVCG.2018.2864889", "refList": ["10.1145/1520340.1520616", "10.1006/obhd.1997.2679", "10.1037/h0031322", "10.1559/152304003100011180", "10.1007/bf01211526", "10.1371/journal.pmed.0020124", "10.1179/1743277414y.0000000099", "10.1007/s003710050111", "10.1109/tvcg.2013.126", "10.1145/3025453.3025998", "10.2307/1914185", "10.3758/s13423-012-0247-5", "10.1109/tvcg.2009.114", "10.1371/journal.pone.0142444", "10.1518/155534309x474460", "10.1057/ivs.2009.1", "10.1037/xap0000037", "10.1109/tvcg.2013.247", "10.1109/tvcg.2007.70530", "10.2307/1884324", "10.1037/a0025185", "10.1080/15230406.2015.1089792", "10.1109/ivs.2013.6629529", "10.1016/0010-0285(73)90033-9", "10.1117/12.643631", "10.1109/tvcg.2017.2743898", "10.1016/s0098-3004(97)00011-3", "10.1175/waf1020.1", "10.14714/cp13.1000", "10.1111/j.1539-6924.1987.tb00488.x", "10.1080/13658816.2015.1131829", "10.1559/1523040054738936", "10.1007/978-1-4471-6497-5\\_1", "10.1109/mcg.2003.1231171", "10.3138/3645-4v22-0m23-3t52", "10.1007/978-94-010-1834-0\\_8", "10.1002/rcs.1541", "10.1016/0749-5978(91)90008-h", "10.1109/tvcg.2015.2467752", "10.1111/risa.12531", "10.1109/tvcg.2011.279", "10.1109/tvcg.2007.70518", "10.1518/001872005775570916", "10.1177/1555343411432338", "10.1037/1082-989x.10.4.389", "10.1111/acfi.2000.40.issue-2", "10.1007/s11548-012-0790-6", "10.1145/1168149.1168158", "10.1109/tvcg.2012.220", "10.1177/0963721413481473", "10.3758/pbr.16.1.204", "10.1117/12.587254", "10.1037/0033-295x.102.4.684", "10.1109/tvcg.2014.2346298", "10.1016/j.neuron.2016.03.025", "10.1080/10447318.2016.1224527", "10.1559/152304000783548037", "10.1080/00223980.1993.9915580", "10.1145/2858036.2858558", "10.1080/17524032.2016.1176946", "10.1371/journal.pone.0096511"], "wos": 1, "children": [{"doi": "10.1109/tvcg.2019.2934287", "title": "Why Authors Don't Visualize Uncertainty", "year": "2019", "conferenceName": "InfoVis", "authors": "Jessica Hullman", "citationCount": "5", "affiliation": "Hullman, J (Corresponding Author), Northwestern Univ, Evanston, IL 60208 USA. Hullman, Jessica, Northwestern Univ, Evanston, IL 60208 USA.", "countries": "USA", "abstract": "Clear presentation of uncertainty is an exception rather than rule in media articles, data-driven reports, and consumer applications, despite proposed techniques for communicating sources of uncertainty in data. This work considers, Why do so many visualization authors choose not to visualize uncertainty? I contribute a detailed characterization of practices, associations, and attitudes related to uncertainty communication among visualization authors, derived from the results of surveying 90 authors who regularly create visualizations for others as part of their work, and interviewing thirteen influential visualization designers. My results highlight challenges that authors face and expose assumptions and inconsistencies in beliefs about the role of uncertainty in visualization. In particular, a clear contradiction arises between authors' acknowledgment of the value of depicting uncertainty and the norm of omitting direct depiction of uncertainty. To help explain this contradiction, I present a rhetorical model of uncertainty omission in visualization-based communication. I also adapt a formal statistical model of how viewers judge the strength of a signal in a visualization to visualization-based communication, to argue that uncertainty communication necessarily reduces degrees of freedom in viewers' statistical inferences. I conclude with recommendations for how visualization research on uncertainty communication could better serve practitioners' current needs and values while deepening understanding of assumptions that reinforce uncertainty omission.", "keywords": "Uncertainty visualization,graphical statistical inference,visualization rhetoric", "link": "http://dx.doi.org/10.1109/TVCG.2019.2934287", "refList": ["10.1145/1520340.1520616", "10.1006/obhd.1997.2679", "10.1177/0011000006287390", "10.1145/3173574.3173718", "10.1007/s003710050111", "10.1198/106186004x11435", "10.1080/14639220110110324", "10.1371/journal.pone.0142444", "10.1057/ivs.2009.1", "10.1016/s0098-3004(01)00051-6", "10.3758/s13423-013-0572-3", "10.14714/cp13.1000", "10.1109/mcg.2003.1231171", "10.1098/rsta.2009.0120", "10.1257/jel.53.3.631", "10.1016/0749-5978(90)90002-q", "10.1111/j.1539-6924.1995.tb00308.x", "10.1002/(sici)1099-0771(199706)10:2", "10.1080/01621459.2013.808157", "10.1037/0096-1523.3.4.552", "10.1002/for.3980010203", "10.1073/pnas.1317504111", "10.1145/3025453.3025738", "10.1037/1082-989x.10.4.389", "10.1109/2945.537309", "10.1016/s0098-3004(97)00012-5", "10.1117/12.587254", "10.1109/tvcg.2014.2346298", "10.1109/tvcg.2010.161", "10.1109/tvcg.2018.2864889", "10.1023/a:1026351131038", "10.1016/s0098-3004(97)00005-8", "10.1109/tvcg.2011.255", "10.1145/2858036.2858558", "10.1111/rssa.12378"], "wos": 1, "children": [{"doi": "10.1109/tvcg.2020.3028984", "title": "Bayesian-Assisted Inference from Visualized Data", "year": "2020", "conferenceName": "InfoVis", "authors": "Yea-Seul Kim;Paula Kayongo;Madeleine Grunde-McLaughlin;Jessica Hullman", "citationCount": "0", "affiliation": "Kim, YS (Corresponding Author), Univ Washington, Seattle, WA 98195 USA. Kim, Yea-Seul, Univ Washington, Seattle, WA 98195 USA. Kayongo, Paula; Hullman, Jessica, Northwestern Univ, Evanston, IL 60208 USA. Grunde-McLaughlin, Madeleine, Univ Penn, Philadelphia, PA 19104 USA.", "countries": "USA", "abstract": "A Bayesian view of data interpretation suggests that a visualization user should update their existing beliefs about a parameter's value in accordance with the amount of information about the parameter value captured by the new observations. Extending recent work applying Bayesian models to understand and evaluate belief updating from visualizations, we show how the predictions of Bayesian inference can be used to guide more rational belief updating. We design a Bayesian inference-assisted uncertainty analogy that numerically relates uncertainty in observed data to the user's subjective uncertainty, and a posterior visualization that prescribes how a user should update their beliefs given their prior beliefs and the observed data. In a pre-registered experiment on 4,800 people, we find that when a newly observed data sample is relatively small (N=158), both techniques reliably improve people's Bayesian updating on average compared to the current best practice of visualizing uncertainty in the observed data. For large data samples (N=5208), where people's updated beliefs tend to deviate more strongly from the prescriptions of a Bayesian model, we find evidence that the effectiveness of the two forms of Bayesian assistance may depend on people's proclivity toward trusting the source of the data. We discuss how our results provide insight into individual processes of belief updating and subjective uncertainty, and how understanding these aspects of interpretation paves the way for more sophisticated interactive visualizations for analysis and communication.", "keywords": "Bayesian cognition,Belief updating,Uncertainty visualization,Adaptive visualization", "link": "http://dx.doi.org/10.1109/TVCG.2020.3028984", "refList": ["10.1080/19336896.2018.1471922", "10.3758/bf03196976", "10.1037/1089-2680.2.2.175", "10.1016/j.jclinepi.2009.06.003", "10.1109/tvcg.2014.2346979", "10.1109/tvcg.2018.2864909", "10.1145/3173574.3173718", "10.1006/cogp.1998.0702", "10.1086/209424", "10.1109/tvcg.2012.199", "10.7717/peerj-cs.55", "10.1145/2993901.2993919", "10.1371/journal.pone.0142444", "10.1080/13875868.2015.1137577", "10.1037/1076-898x.3.1.3", "10.1109/tvcg.2019.2934287", "10.1109/tvcg.2017.2743898", "10.1145/3025453.3025592", "10.1057/ivs.2008.13", "10.1214/ss/1015346320", "10.1016/0749-5978(92)90055-c", "10.1080/13546780542000005", "10.1109/tvcg.2015.2467671", "10.1109/tvcg.2016.2607204", "10.3758/s13423-016-1174-7", "10.1016/j.cag.2014.03.002", "10.1198/016214505000000105", "10.1109/tvcg.2012.279", "10.1111/1467-8624.00232", "10.1111/j.1467-9280.2006.01780.x", "10.2307/2682899", "10.1080/00335557743000053", "10.1109/tvcg.2010.177", "10.1057/ivs.2008.28", "10.1109/tvcg.2018.2864889", "10.1109/tvcg.2013.153", "10.1109/tvcg.2015.2467758", "10.1145/2858036.2858558", "10.1287/mnsc.46.8.1100.12023", "10.1016/j.tics.2003.08.012", "10.1111/j.1467-8659.2009.01694.x"], "wos": 1, "children": [], "len": 1}, {"doi": "10.1109/tvcg.2020.3030435", "title": "Data Visceralization: Enabling Deeper Understanding of Data Using Virtual Reality", "year": "2020", "conferenceName": "InfoVis", "authors": "Benjamin Lee;Dave Brown;Bongshin Lee;Christophe Hurter;Steven Mark Drucker;Tim Dwyer", "citationCount": "1", "affiliation": "Lee, B (Corresponding Author), Monash Univ, Clayton, Vic, Australia. Lee, Benjamin; Dwyer, Tim, Monash Univ, Clayton, Vic, Australia. Brown, Dave; Lee, Bongshin; Drucker, Steven, Microsoft Res, Redmond, WA USA. Hurter, Christophe, French Civil Aviat Univ, ENAC, Toulouse, France.", "countries": "USA;France;Australia", "abstract": "A fundamental part of data visualization is transforming data to map abstract information onto visual attributes. While this abstraction is a powerful basis for data visualization, the connection between the representation and the original underlying data (i.e., what the quantities and measurements actually correspond with in reality) can be lost. On the other hand, virtual reality (VR) is being increasingly used to represent real and abstract models as natural experiences to users. In this work, we explore the potential of using VR to help restore the basic understanding of units and measures that are often abstracted away in data visualization in an approach we call data visceralization. By building VR prototypes as design probes, we identify key themes and factors for data visceralization. We do this first through a critical reflection by the authors, then by involving external participants. We find that data visceralization is an engaging way of understanding the qualitative aspects of physical measures and their real-life form, which complements analytical and quantitative understanding commonly gained from data visualization. However, data visceralization is most effective when there is a one-to-one mapping between data and representation, with transformations such as scaling affecting this understanding. We conclude with a discussion of future directions for data visceralization.", "keywords": "Data visceralization,virtual reality,exploratory study", "link": "http://dx.doi.org/10.1109/TVCG.2020.3030435", "refList": ["10.1080/01973762.2013.761106", "10.1109/tvcg.2015.2467811", "10.1109/tvcg.2012.221", "10.1145/3284179.3284326", "10.1109/tvcg.2019.2934287", "10.1109/2945.841119", "10.1109/tvcg.2019.2934539", "10.1109/mcg.2013.101", "10.1109/tvcg.2011.175", "10.1109/tvcg.2018.2830759", "10.1109/3dvis.2014.7160096", "10.1109/mcg.2018.2878900", "10.1109/iv.2011.32", "10.1109/tvcg.2013.196", "10.1109/tvcg.2018.2865241", "10.1515/abitech-2017-0002", "10.1145/2468356.2468739", "10.16995/olh.280", "10.1080/15230406.2018.1513343", "10.1109/iv.2004.1320189", "10.1109/tvcg.2012.213", "10.1109/mcg.2006.120", "10.1109/icdar.2017.286", "10.1371/journal.pone.0146368", "10.1080/1472586x.2011.548488", "10.1109/tvcg.2014.2346574", "10.1080/0013838x.2017.1332021"], "wos": 1, "children": [], "len": 1}], "len": 5}, {"doi": "10.1109/tvcg.2020.3029412", "title": "A Bayesian cognition approach for belief updating of correlation judgement through uncertainty visualizations", "year": "2020", "conferenceName": "InfoVis", "authors": "Alireza Karduni;Douglas Markant;Ryan Wesslen;Wenwen Dou", "citationCount": "0", "affiliation": "Karduni, A (Corresponding Author), Univ North Carolina Charlotte, Charlotte, NC 28223 USA. Karduni, Alireza; Markant, Douglas; Wesslen, Ryan; Dou, Wenwen, Univ North Carolina Charlotte, Charlotte, NC 28223 USA.", "countries": "USA", "abstract": "Understanding correlation judgement is important to designing effective visualizations of bivariate data. Prior work on correlation perception has not considered how factors including prior beliefs and uncertainty representation impact such judgements. The present work focuses on the impact of uncertainty communication when judging bivariate visualizations. Specifically, we model how users update their beliefs about variable relationships after seeing a scatterplot with and without uncertainty representation. To model and evaluate the belief updating, we present three studies. Study 1 focuses on a proposed \u201cLine + Cone\u201d visual elicitation method for capturing users' beliefs in an accurate and intuitive fashion. The findings reveal that our proposed method of belief solicitation reduces complexity and accurately captures the users' uncertainty about a range of bivariate relationships. Study 2 leverages the \u201cLine + Cone\u201d elicitation method to measure belief updating on the relationship between different sets of variables when seeing correlation visualization with and without uncertainty representation. We compare changes in users beliefs to the predictions of Bayesian cognitive models which provide normative benchmarks for how users should update their prior beliefs about a relationship in light of observed data. The findings from Study 2 revealed that one of the visualization conditions with uncertainty communication led to users being slightly more confident about their judgement compared to visualization without uncertainty information. Study 3 builds on findings from Study 2 and explores differences in belief update when the bivariate visualization is congruent or incongruent with users' prior belief. Our results highlight the effects of incorporating uncertainty representation, and the potential of measuring belief updating on correlation judgement with Bayesian cognitive models.", "keywords": "Information visualization,Bayesian modeling,uncertainty visualizations,correlations,belief elicitation", "link": "http://dx.doi.org/10.1109/TVCG.2020.3029412", "refList": ["10.1109/tvcg.2014.2346424", "10.1177/0539018417752089", "10.1145/2702613.2732501", "10.1007/978-3-319-91376-6\\_19", "10.1109/vlsicircuits18222.2020.9162811", "10.1145/2702123.2702431", "10.1371/journal.pbio.1000412", "10.1145/3290605.3300447", "10.1109/tvcg.2009.139", "10.1145/3161187", "10.1016/j.endeavour.2004.07.003", "10.1371/journal.pone.0133753", "10.1109/tfuzz.2019.2919484", "10.1111/j.1365-2362.2009.02234.x", "10.1145/2858036.2858387", "10.1017/s0269889713000082", "10.1109/tvcg.2017.2745941", "10.1080/21548455.2014.941040", "10.1073/pnas.1710351114", "10.1145/1323688.1323689", "10.1109/tvcg.2013.210", "10.1109/tvcg.2012.262", "10.1007/s11165-013-9358-x", "10.1109/mcg.2017.33", "10.3389/fpsyg.2013.00186", "10.1162/posc\\_a\\_00240", "10.1136/bmj.c332", "10.1001/jama.283.15.2008", "10.1145/3173574.3173612", "10.1145/2470654.2470724", "10.1016/j.jhevol.2010.04.005", "10.22323/2.17010401", "10.1002/0470870168", "10.1109/tvcg.2014.2346298", "10.1109/tvcg.2013.234", "10.1109/tvcg.2018.2864889", "10.1136/bmj.330.7485.256-a", "10.1109/tii.2019.2958106", "10.1007/978-3-319-26633-6\\_13", "10.1109/cicc48029.2020.9075900", "10.1016/s0140-6736(09)60329-9"], "wos": 1, "children": [], "len": 1}, {"doi": "10.1109/tvcg.2020.3028958", "title": "Auditing the Sensitivity of Graph-based Ranking with Visual Analytics", "year": "2020", "conferenceName": "VAST", "authors": "Tiankai Xie;Yuxin Ma;Hanghang Tong;My T. Thai;Ross Maciejewski", "citationCount": "0", "affiliation": "Xie, TK (Corresponding Author), Arizona State Univ, Tempe, AZ 85287 USA. Xie, Tiankai; Ma, Yuxin; Maciejewski, Ross, Arizona State Univ, Tempe, AZ 85287 USA. Tong, Hanghang, Univ Illinois, Urbana, IL USA. Thai, My T., Univ Florida, Gainesville, FL 32611 USA.", "countries": "USA", "abstract": "Graph mining plays a pivotal role across a number of disciplines, and a variety of algorithms have been developed to answer who/what type questions. For example, what items shall we recommend to a given user on an e-commerce platform? The answers to such questions are typically returned in the form of a ranked list, and graph-based ranking methods are widely used in industrial information retrieval settings. However, these ranking algorithms have a variety of sensitivities, and even small changes in rank can lead to vast reductions in product sales and page hits. As such, there is a need for tools and methods that can help model developers and analysts explore the sensitivities of graph ranking algorithms with respect to perturbations within the graph structure. In this paper, we present a visual analytics framework for explaining and exploring the sensitivity of any graph-based ranking algorithm by performing perturbation-based what-if analysis. We demonstrate our framework through three case studies inspecting the sensitivity of two classic graph-based ranking algorithms (PageRank and HITS) as applied to rankings in political news media and social networks.", "keywords": "Graph-based ranking,sensitivity analysis,visual analytics", "link": "http://dx.doi.org/10.1109/TVCG.2020.3028958", "refList": ["10.1109/wsc.2017.8247800", "10.1023/a:1022649401552", "10.1515/1559-0410.11416", "10.1109/tvcg.2016.2598919", "10.1177/1473871611416549", "10.1109/tvcg.2019.2934630", "10.1140/epjds29", "10.1109/tvcg.2019.2934670", "10.1016/j.eswa.2015.09.004", "10.1145/2702123.2702509", "10.1016/j.visinf.2018.12.001", "10.2307/3002000", "10.1109/tvcg.2019.2934399", "10.1007/s41060-016-0032-z", "10.1111/cgf.13198", "10.14778/2350229.2350254", "10.1145/2939672.2939764", "10.1016/j.visinf.2017.01.006", "10.1145/2858036.2858529", "10.1109/vast.2017.8585647", "10.1007/bf01187020", "10.1109/icdm.2015.26", "10.1145/2362383.2362387", "10.1177/0049124104268644", "10.1109/vast.2011.6102442", "10.1109/infvis.2003.1249025", "10.1109/tvcg.2018.2864475", "10.1109/tvcg.2007.70528", "10.1109/tvcg.2015.2467691", "10.1111/cgf.13210", "10.1214/aos/1176344136", "10.1109/tvcg.2015.2424872", "10.1016/j.visinf.2018.09.001", "10.1177/089443939100900106", "10.1109/tvcg.2015.2467931", "10.1162/neco.1997.9.8.1735", "10.1007/s11162-011-9241-4", "10.1111/cgf.13680", "10.1145/3065386", "10.1109/tvcg.2018.2864889", "10.1177/003804070808100402", "10.1109/icdm.2010.62", "10.1038/s41598-020-59669-x", "10.1162/153244303321897717", "10.1109/tvcg.2019.2934619", "10.1007/bf00356088", "10.1109/tvcg.2016.2598432", "10.1109/tvcg.2016.2598831"], "wos": 1, "children": [], "len": 1}, {"doi": "10.1109/tvcg.2020.3028984", "title": "Bayesian-Assisted Inference from Visualized Data", "year": "2020", "conferenceName": "InfoVis", "authors": "Yea-Seul Kim;Paula Kayongo;Madeleine Grunde-McLaughlin;Jessica Hullman", "citationCount": "0", "affiliation": "Kim, YS (Corresponding Author), Univ Washington, Seattle, WA 98195 USA. Kim, Yea-Seul, Univ Washington, Seattle, WA 98195 USA. Kayongo, Paula; Hullman, Jessica, Northwestern Univ, Evanston, IL 60208 USA. Grunde-McLaughlin, Madeleine, Univ Penn, Philadelphia, PA 19104 USA.", "countries": "USA", "abstract": "A Bayesian view of data interpretation suggests that a visualization user should update their existing beliefs about a parameter's value in accordance with the amount of information about the parameter value captured by the new observations. Extending recent work applying Bayesian models to understand and evaluate belief updating from visualizations, we show how the predictions of Bayesian inference can be used to guide more rational belief updating. We design a Bayesian inference-assisted uncertainty analogy that numerically relates uncertainty in observed data to the user's subjective uncertainty, and a posterior visualization that prescribes how a user should update their beliefs given their prior beliefs and the observed data. In a pre-registered experiment on 4,800 people, we find that when a newly observed data sample is relatively small (N=158), both techniques reliably improve people's Bayesian updating on average compared to the current best practice of visualizing uncertainty in the observed data. For large data samples (N=5208), where people's updated beliefs tend to deviate more strongly from the prescriptions of a Bayesian model, we find evidence that the effectiveness of the two forms of Bayesian assistance may depend on people's proclivity toward trusting the source of the data. We discuss how our results provide insight into individual processes of belief updating and subjective uncertainty, and how understanding these aspects of interpretation paves the way for more sophisticated interactive visualizations for analysis and communication.", "keywords": "Bayesian cognition,Belief updating,Uncertainty visualization,Adaptive visualization", "link": "http://dx.doi.org/10.1109/TVCG.2020.3028984", "refList": ["10.1080/19336896.2018.1471922", "10.3758/bf03196976", "10.1037/1089-2680.2.2.175", "10.1016/j.jclinepi.2009.06.003", "10.1109/tvcg.2014.2346979", "10.1109/tvcg.2018.2864909", "10.1145/3173574.3173718", "10.1006/cogp.1998.0702", "10.1086/209424", "10.1109/tvcg.2012.199", "10.7717/peerj-cs.55", "10.1145/2993901.2993919", "10.1371/journal.pone.0142444", "10.1080/13875868.2015.1137577", "10.1037/1076-898x.3.1.3", "10.1109/tvcg.2019.2934287", "10.1109/tvcg.2017.2743898", "10.1145/3025453.3025592", "10.1057/ivs.2008.13", "10.1214/ss/1015346320", "10.1016/0749-5978(92)90055-c", "10.1080/13546780542000005", "10.1109/tvcg.2015.2467671", "10.1109/tvcg.2016.2607204", "10.3758/s13423-016-1174-7", "10.1016/j.cag.2014.03.002", "10.1198/016214505000000105", "10.1109/tvcg.2012.279", "10.1111/1467-8624.00232", "10.1111/j.1467-9280.2006.01780.x", "10.2307/2682899", "10.1080/00335557743000053", "10.1109/tvcg.2010.177", "10.1057/ivs.2008.28", "10.1109/tvcg.2018.2864889", "10.1109/tvcg.2013.153", "10.1109/tvcg.2015.2467758", "10.1145/2858036.2858558", "10.1287/mnsc.46.8.1100.12023", "10.1016/j.tics.2003.08.012", "10.1111/j.1467-8659.2009.01694.x"], "wos": 1, "children": [], "len": 1}, {"doi": "10.1109/tvcg.2020.3030433", "title": "Data Comics for Reporting Controlled User Studies in Human-Computer Interaction", "year": "2020", "conferenceName": "InfoVis", "authors": "Zezhong Wang;Jacob Ritchie;Jingtao Zhou;Fanny Chevalier;Benjamin Bach", "citationCount": "0", "affiliation": "Wang, ZZ (Corresponding Author), Univ Edinburgh, Edinburgh, Midlothian, Scotland. Wang, Zezhong; Zhou, Jingtao; Bach, Benjamin, Univ Edinburgh, Edinburgh, Midlothian, Scotland. Ritchie, Jacob, Stanford Univ, Stanford, CA 94305 USA. Zhou, Jingtao, Tianjin Univ, Tianjin, Peoples R China. Chevalier, Fanny, Univ Toronto, Toronto, ON, Canada.", "countries": "Scotland;Canada;China;USA", "abstract": "Inspired by data comics, this paper introduces a novel format for reporting controlled studies in the domain of human-computer interaction (HCI). While many studies in HCI follow similar steps in explaining hypotheses, laying out a study design, and reporting results, many of these decisions are buried in blocks of dense scientific text. We propose leveraging data comics as study reports to provide an open and glanceable view of studies by tightly integrating text and images, illustrating design decisions and key insights visually, resulting in visual narratives that can be compelling to non-scientists and researchers alike. Use cases of data comics study reports range from illustrations for non-scientific audiences to graphical abstracts, study summaries, technical talks, textbooks, teaching, blogs, supplementary submission material, and inclusion in scientific articles. This paper provides examples of data comics study reports alongside a graphical repertoire of examples, embedded in a framework of guidelines for creating comics reports which was iterated upon and evaluated through a series of collaborative design sessions.", "keywords": "Statistical communication,comics,scientific reports", "link": "http://dx.doi.org/10.1109/TVCG.2020.3030433", "refList": ["10.1109/tvcg.2014.2346424", "10.1177/0539018417752089", "10.1145/2702123.2702431", "10.1371/journal.pbio.1000412", "10.1145/3290605.3300447", "10.1109/tvcg.2009.139", "10.1145/3161187", "10.18637/jss.v040.i01", "10.1016/j.endeavour.2004.07.003", "10.1145/989863.989865", "10.1111/j.1365-2362.2009.02234.x", "10.1145/2858036.2858387", "10.1109/tvcg.2017.2745941", "10.1080/21548455.2014.941040", "10.1073/pnas.1710351114", "10.1145/1323688.1323689", "10.1109/tvcg.2013.210", "10.1109/tvcg.2012.262", "10.1007/s00778-008-0098-x", "10.1007/s11165-013-9358-x", "10.1109/mcg.2017.33", "10.1162/posc\\_a\\_00240", "10.1001/jama.283.15.2008", "10.1145/3173574.3173612", "10.17349/jmc117309", "10.1016/j.jhevol.2010.04.005", "10.22323/2.17010401", "10.1002/0470870168", "10.1145/1378773.1378792", "10.1109/tvcg.2014.2346298", "10.1109/tvcg.2013.234", "10.1109/tvcg.2018.2864889", "10.1136/bmj.330.7485.256-a", "10.25165/j.ijabe.20201302.5353", "10.1007/978-3-319-26633-6\\_13", "10.1016/s0140-6736(09)60329-9", "10.1016/j.ces.2018.11.036"], "wos": 1, "children": [], "len": 1}, {"doi": "10.1109/pacificvis48177.2020.1014", "year": "2020", "title": "Uncertainty Visualisation: An Interactive Visual Survey", "conferenceName": "PacificVis", "authors": "Amit Jena;Ulrich Engelke;Tim Dwyer;Venkatesh Raiamanickam;C{\\'{e}}cile Paris", "citationCount": "0", "affiliation": "Jena, A (Corresponding Author), IITB Monash Res Acad, Mumbai, Maharashtra, India.\nJena, Amit, IITB Monash Res Acad, Mumbai, Maharashtra, India.\nEngelke, Ulrich, CSIRO Data61, Perth, WA, Australia.\nDwyer, Tim, Monash Univ, Melbourne, Vic, Australia.\nRajamanickam, Venkatesh, Indian Inst Technol, Mumbai, Maharashtra, India.\nParis, Cecile, CSIRO Data61, Sydney, NSW, Australia.", "countries": "India;Australia", "abstract": "There exists a gulf between the rhetoric in visualisation research about the significance of uncertainty and the inclusion of representations of uncertainty in visualisations used in practice. The graphical representation of uncertainty information has emerged as a problem of great importance in visualisation research. This contribution presents a survey of 286 uncertainty visualisation research publications. All publications are categorised with regard to publication type, publication venue, application domain, target user, and evaluation type. We present an interactive web-based browser that facilitates easy visual search and exploration of the publications included in the survey. We conclude that uncertainty visualisation is severely limited by the quality and scope of uncertainty data, by the limited confidence in the data, and by the perceptual and cognitive confusion that the graphical representation of the data can generate.", "keywords": "Human-centered computing; Visualization; Uncertainty Visualization; Human-centered computing; Visualization; Visualization application domains", "link": "https://doi.org/10.1109/PacificVis48177.2020.1014", "refList": ["10.1117/12.587254", "10.1007/978-1-4471-2804-5\\_6", "10.1109/tvcg.2018.2864889", "10.1177/0272989x07307270", "10.1177/0272989x10371830", "10.1016/0010-0277(82)90023-3", "10.1007/s003710050111", "10.1126/science.1191181", "10.1109/tvcg.2012.285", "10.2307/2683467", "10.1109/mcse.2007.27", "10.2307/2683729"], "wos": 1, "children": [], "len": 1}, {"doi": "10.1109/pacificvis48177.2020.7614", "year": "2020", "title": "Uncertainty Treemaps", "conferenceName": "PacificVis", "authors": "Max Sondag;Wouter Meulemans;Christoph Schulz;Kevin Verbeek;Daniel Weiskopf;Bettina Speckmann", "citationCount": "0", "affiliation": "Sondag, M (Corresponding Author), TU Eindhoven, Eindhoven, Netherlands.\nSondag, Max; Meulemans, Wouter; Verbeek, Kevin; Speckmann, Bettina, TU Eindhoven, Eindhoven, Netherlands.\nSchulz, Christoph; Weiskopf, Daniel, Univ Stuttgart, Stuttgart, Germany.", "countries": "Germany;Netherlands", "abstract": "Rectangular treemaps visualize hierarchical numerical data by recursively partitioning an input rectangle into smaller rectangles whose areas match the data. Numerical data often has uncertainty associated with it. To visualize uncertainty in a rectangular treemap, we identify two conflicting key requirements: (i) to assess the data value of a node in the hierarchy, the area of its rectangle should directly match its data value, and (ii) to facilitate comparison between data and uncertainty, uncertainty should be encoded using the same visual variable as the data, that is, area. We present Uncertainty Treemaps, which meet both requirements simultaneously by introducing the concept of hierarchical uncertainty masks. First, we define a new cost function that measures the quality of Uncertainty Treemaps. Then, we show how to adapt existing treemapping algorithms to support uncertainty masks. Finally, we demonstrate the usefulness and quality of our technique through an expert review and a computational experiment on real-world datasets.", "keywords": "Human-centered computing; Visualization; Visualization techniques; Treemaps", "link": "https://doi.org/10.1109/PacificVis48177.2020.7614", "refList": ["10.1109/tvcg.2013.180", "10.1109/tvcg.2015.2467591", "10.1111/cgf.12380", "10.1109/tvcg.2018.2864909", "10.1109/tvcg.2017.2743959", "10.1142/s0129183111016397", "10.1057/ivs.2009.4", "10.1080/15230406.2014.949868", "10.1007/978-1-4471-2804-5\\_6", "10.1145/1124772.1124851", "10.1109/tvcg.2017.2745140", "10.1145/22949.22950", "10.1109/tvcg.2010.79", "10.2307/1420573", "10.1109/tvcg.2010.186", "10.1037/h0046162", "10.1016/j.comgeo.2013.12.008", "10.1109/tvcg.2015.2424872", "10.1145/571647.571649", "10.1109/tvcg.2015.2467752", "10.2307/2288400", "10.1109/tvcg.2012.279", "10.1109/tvcg.2011.197", "10.1145/1056018.1056041", "10.1109/tvcg.2012.220", "10.1109/tvcg.2014.2346298", "10.1109/tvcg.2018.2864889", "10.1016/j.dam.2006.08.005", "10.1109/pacificvis.2018.00020", "10.1109/tvcg.2013.91"], "wos": 1, "children": [], "len": 1}, {"doi": "10.1111/cgf.13698", "year": "2019", "title": "Visual-Interactive Preprocessing of Multivariate Time Series Data", "conferenceName": "EuroVis", "authors": "J{\\\"{u}}rgen Bernard;Marco Hutter;Heiko Reinemuth;Hendrik Pfeifer;Christian Bors;J{\\\"{o}}rn Kohlhammer", "citationCount": "2", "affiliation": "Bernard, J (Corresponding Author), Tech Univ Darmstadt, Darmstadt, Germany.\nBernard, Juergen; Hutter, Marco; Reinemuth, Heiko; Pfeifer, Hendrik, Tech Univ Darmstadt, Darmstadt, Germany.\nBors, Christian, TU Wien, Vienna, Austria.\nKohlhammer, Joern, Fraunhofer IGD, Darmstadt, Germany.", "countries": "Germany;Austria", "abstract": "Pre-processing is a prerequisite to conduct effective and efficient downstream data analysis. Pre-processing pipelines often require multiple routines to address data quality challenges and to bring the data into a usable form. For both the construction and the refinement of pre-processing pipelines, human-in-the-loop approaches are highly beneficial. This particularly applies to multivariate time series, a complex data type with multiple values developing over time. Due to the high specificity of this domain, it has not been subject to in-depth research in visual analytics. We present a visual-interactive approach for preprocessing multivariate time series data with the following aspects. Our approach supports analysts to carry out six core analysis tasks related to pre-processing of multivariate time series. To support these tasks, we identify requirements to baseline toolkits that may help practitioners in their choice. We characterize the space of visualization designs for uncertainty-aware pre-processing and justify our decisions. Two usage scenarios demonstrate applicability of our approach, design choices, and uncertainty visualizations for the six analysis tasks. This work is one step towards strengthening the visual analytics support for data pre-processing in general and for uncertainty-aware pre-processing of multivariate time series in particular.", "keywords": "", "link": "https://doi.org/10.1111/cgf.13698", "refList": ["10.1016/j.engappai.2010.09.007", "10.1109/tvcg.2015.2467591", "10.1111/cgf.13190", "10.1177/1473871611416549", "10.1007/3-7908-1701-5\\_9", "10.1109/icdmw.2009.55", "10.3758/s13423-012-0247-5", "10.1109/pacificvis.2010.5429596", "10.1177/1473871611415994", "10.1117/12.2080001", "10.1145/2379776.2379788", "10.1145/3105971.3105984", "10.1016/j.patcog.2005.01.025", "10.1594/pangaea.150017", "10.1109/tvcg.2013.178", "10.1109/tvcg.2018.2859973", "10.1109/tvcg.2011.195", "10.1145/1126004.1126005", "10.1145/1656274.1656278", "10.1594/pangaea.804156", "10.1594/pangaea.787726", "10.1109/tvcg.2018.2865077", "10.1007/978-1-4471-6497-5\\_1", "10.2312/eurova.20151104", "10.1109/tvcg.2012.285", "10.1023/a:1024988512476", "10.1109/tvcg.2010.225", "10.1109/vast.2015.7347672", "10.1007/s00799-014-0134-y", "10.1109/tvcg.2016.2598495", "10.1109/tvcg.2018.2864907", "10.1007/s40430-018-1079-7", "10.1007/978-3-642-32498-7\\_5", "10.1111/cgf.13237", "10.1109/vast.2009.5332611", "10.1109/tvcg.2015.2467752", "10.1016/j.cviu.2006.08.002", "10.1109/tvcg.2014.2346321", "10.1145/1014052.1014104", "10.1007/978-3-540-71949-6", "10.2312/sca/sca10/001-010", "10.1145/3025453.3025738", "10.2312/eurova.20181112", "10.1109/pacificvis.2018.00034", "10.1007/978-0-85729-079-3\\_8", "10.1109/tvcg.2017.2779501", "10.1109/tvcg.2008.166", "10.1007/s10618-012-0285-7", "10.1109/tvcg.2013.222", "10.1109/tvcg.2018.2864889", "10.1109/tvcg.2016.2598592", "10.1109/vast.2010.5652530", "10.1145/2723372.2731081", "10.1109/tvcg.2018.2864914", "10.1109/infvis.2000.885098", "10.1016/j.neucom.2017.01.105", "10.2352/issn.2470-1173.2017.1.vda-387", "10.1109/tvcg.2015.2467851", "10.1109/tvcg.2016.2598468", "10.1109/tvcg.2016.2603178"], "wos": 1, "children": [{"doi": "10.1109/tvcg.2020.3030364", "title": "Supporting the Problem-Solving Loop: Designing Highly Interactive Optimisation Systems", "year": "2020", "conferenceName": "VAST", "authors": "Jie Liu;Tim Dwyer;Guido Tack;Samuel Gratzl;Kim Marriott", "citationCount": "0", "affiliation": "Liu, J (Corresponding Author), Monash Univ, Clayton, Vic, Australia. Liu, Jie; Dwyer, Tim; Tack, Guido; Gratzl, Samuel; Marriott, Kim, Monash Univ, Clayton, Vic, Australia.", "countries": "Australia", "abstract": "Efficient optimisation algorithms have become important tools for finding high-quality solutions to hard, real-world problems such as production scheduling, timetabling, or vehicle routing. These algorithms are typically \u201cblack boxes\u201d that work on mathematical models of the problem to solve. However, many problems are difficult to fully specify, and require a \u201chuman in the loop\u201d who collaborates with the algorithm by refining the model and guiding the search to produce acceptable solutions. Recently, the Problem-Solving Loop was introduced as a high-level model of such interactive optimisation. Here, we present and evaluate nine recommendations for the design of interactive visualisation tools supporting the Problem-Solving Loop. They range from the choice of visual representation for solutions and constraints to the use of a solution gallery to support exploration of alternate solutions. We first examined the applicability of the recommendations by investigating how well they had been supported in previous interactive optimisation tools. We then evaluated the recommendations in the context of the vehicle routing problem with time windows (VRPTW). To do so we built a sophisticated interactive visual system for solving VRPTW that was informed by the recommendations. Ten participants then used this system to solve a variety of routing problems. We report on participant comments and interaction patterns with the tool. These showed the tool was regarded as highly usable and the results generally supported the usefulness of the underlying recommendations.", "keywords": "Interactive optimisation,Interface design,Usability,Interactive systems and tools,Vehicle routing", "link": "http://dx.doi.org/10.1109/TVCG.2020.3030364", "refList": ["10.1176/appi.ajp.2018.18070881", "10.1006/obhd.1997.2679", "10.1109/vlhcc.2018.8506576", "10.1177/0956797611417632", "10.1177/0956797619830649", "10.1177/0049124115610347", "10.1177/1948550618775108", "10.1145/3313831.3376533", "10.1511/2014.111.460", "10.1145/2858036.2858465", "10.1145/3173574.3173606", "10.1177/1745691616658637", "10.1038/483531a", "10.1145/3173574.3174053", "10.1037/pspp0000186", "10.1016/j.jclinepi.2015.05.029", "10.1126/science.aac4716", "10.1145/985692.985782", "10.1080/02699931.2018.1524747", "10.1073/pnas.1402786111", "10.1145/3290605.3300295", "10.1111/cgf.13698", "10.1145/3290605.3300709", "10.2307/2686111", "10.1214/17-ba1091", "10.1145/1449715.1449732", "10.2139/ssrn.2694998", "10.1145/3313831.3376777", "10.1177/2515245917747646", "10.1145/3290605.3300754", "10.1145/3025453.3025626", "10.1109/tvcg.2014.2346321", "10.1037/gpr0000123", "10.2139/ssrn.2535453", "10.1145/3025453.3025738", "10.1038/533452a", "10.1177/1948550617714584", "10.1007/s11222-013-9416-2", "10.3389/fpsyg.2016.01832", "10.1038/s41562-018-0506-1", "10.1007/s11222-016-9696-4", "10.1177/1367006918763132", "10.1109/tsmc.1981.4308636", "10.1038/nrd3439-c1", "10.1177/0956797617723726", "10.1111/j.1467-8659.2012.03116.x", "10.1146/annurev-psych-122216-011836", "10.1145/3290605.3300432"], "wos": 1, "children": [], "len": 1}], "len": 3}], "len": 23}, {"doi": "10.1109/tvcg.2018.2864913", "title": "A Framework for Externalizing Implicit Error Using Visualization", "year": "2018", "conferenceName": "InfoVis", "authors": "Nina McCurdy;Julie Gerdes;Miriah D. Meyer", "citationCount": "8", "affiliation": "McCurdy, N (Corresponding Author), Univ Utah, Sch Comp, Salt Lake City, UT 84112 USA. McCurdy, Nina; Meyer, Miriah, Univ Utah, Sch Comp, Salt Lake City, UT 84112 USA. Gerdes, Julie, Texas Tech Univ, Coll Arts \\& Sci, Lubbock, TX 79409 USA.", "countries": "USA", "abstract": "This paper presents a framework for externalizing and analyzing expert knowledge about discrepancies in data through the use of visualization. Grounded in an 18-month design study with global health experts, the framework formalizes the notion of data discrepancies as implicit error, both in global health data and more broadly. We use the term implicit error to describe measurement error that is inherent to and pervasive throughout a dataset, but that isn't explicitly accounted for or defined. Instead, implicit error exists in the minds of experts, is mainly qualitative, and is accounted for subjectively during expert interpretation of the data. Externalizing knowledge surrounding implicit error can assist in synchronizing, validating, and enhancing interpretation, and can inform error analysis and mitigation. The framework consists of a description of implicit error components that are important for downstream analysis, along with a process model for externalizing and analyzing implicit error using visualization. As a second contribution, we provide a rich, reflective, and verifiable description of our research process as an exemplar summary toward the ongoing inquiry into ways of increasing the validity and transferability of design study research.", "keywords": "implicit error,knowledge externalization,design study", "link": "http://dx.doi.org/10.1109/TVCG.2018.2864913", "refList": ["10.1197/jamia.m2342", "10.1109/tvcg.2013.132", "10.1111/cgf.13169", "10.1179/1743277414y.0000000099", "10.1016/j.cag.2009.06.004", "10.1111/j.1467-8659.2009.01678.x", "10.1111/j.0361-3666.2003.00237.x", "10.1111/cgf.12392", "10.1016/j.jvlc.2011.04.002", "10.1186/1471-2334-11-37", "10.1371/journal.pmed.1000376", "10.1109/infvis.2005.1532134", "10.1109/pacificvis.2017.8031599", "10.1109/tvcg.2017.2743898", "10.1197/jamia.m2544", "10.1145/3025453.3025592", "10.1109/tvcg.2015.2468151", "10.1007/978-1-4471-6497-5\\_1", "10.3233/978-1-60750-533-4-23", "10.1177/0165551506070706", "10.1145/642611.642616", "10.6064/2012/875253", "10.1109/tvcg.2015.2467551", "10.1109/tvcg.2015.2465151", "10.1111/j.1467-9604.2007.00468.x", "10.1109/mcg.2012.31", "10.1109/tvcg.2007.70589", "10.1145/2993901.2993916", "10.1109/vast.2010.5652885", "10.1145/3025453.3025738", "10.1109/38.689662", "10.1016/s0925-7535(97)00052-0", "10.9745/ghsp-d-15-00207", "10.1518/001872095779049543", "10.1080/15323269.2011.587100", "10.1117/12.587254", "10.1016/j.cie.2014.11.025", "10.1109/tvcg.2017.2745240", "10.1109/tvcg.2012.213", "10.1109/vast.2011.6102457", "10.1109/mcg.2015.50", "10.1145/1385569.1385582", "10.1016/j.jbi.2014.04.006", "10.1136/amiajnl-2011-000486"], "wos": 1, "children": [{"doi": "10.1109/tvcg.2019.2934539", "title": "Criteria for Rigor in Visualization Design Study", "year": "2019", "conferenceName": "InfoVis", "authors": "Miriah D. Meyer;Jason Dykes", "citationCount": "16", "affiliation": "Meyer, M (Corresponding Author), Univ Utah, Salt Lake City, UT 84112 USA. Meyer, Miriah, Univ Utah, Salt Lake City, UT 84112 USA. Dykes, Jason, City Univ London, London, England.", "countries": "USA;England", "abstract": "We develop a new perspective on research conducted through visualization design study that emphasizes design as a method of inquiry and the broad range of knowledge-contributions achieved through it as multiple, subjective, and socially constructed. From this interpretivist position we explore the nature of visualization design study and develop six criteria for rigor. We propose that rigor is established and judged according to the extent to which visualization design study research and its reporting are INFORMED, REFLEXIVE, ABUNDANT, PLAUSIBLE, RESONANT, and TRANSPARENT. This perspective and the criteria were constructed through a four-year engagement with the discourse around rigor and the nature of knowledge in social science, information systems, and design. We suggest methods from cognate disciplines that can support visualization researchers in meeting these criteria during the planning, execution, and reporting of design study. Through a series of deliberately provocative questions, we explore implications of this new perspective for design study research in visualization, concluding that as a discipline, visualization is not yet well positioned to embrace, nurture, and fully benefit from a rigorous, interpretivist approach to design study. The perspective and criteria we present are intended to stimulate dialogue and debate around the nature of visualization design study and the broader underpinnings of the discipline.", "keywords": "design study,relativism,interpretivism,knowledge construction,qualitative research,research through design", "link": "http://dx.doi.org/10.1109/TVCG.2019.2934539", "refList": ["10.1007/978-1-4939-0378-8\\_8", "10.1177/1049732315588501", "10.1177/146879410200200205", "10.2307/1177100", "10.1016/0142-694x(82)90040-0", "10.1109/tvcg.2014.2346331", "10.1109/beliv.2018.8634420", "10.1145/2362364.2362371", "10.1080/2159676x.2017.1393221", "10.1177/1473871613510429", "10.1145/2212877.2212889", "10.1080/09650790802011973", "10.1109/tvcg.2018.2864836", "10.1109/tvcg.2018.2865076", "10.1109/tvcg.2015.2467195", "10.1109/mcse.2007.106", "10.1080/1750984x.2017.1317357", "10.1109/tvcg.2017.2745958", "10.1177/1525822x0101300203", "10.1080/23265507.2017.1300068", "10.1111/j.1540-4560.1946.tb02295.x", "10.1177/1468794108098034", "10.1007/978-3-7643-8472-2\\_6", "10.1145/2317956.2317968", "10.2307/1511837", "10.1177/104973202129120052", "10.3233/efi-2004-22201", "10.1109/beliv.2018.8634427", "10.1109/beliv.2018.8634261", "10.1016/s0142-694x(01)00009-6", "10.1007/978-3-7643-8472-2\\_3", "10.1145/642611.642616", "10.1177/1468794107085301", "10.1177/1077800410383121", "10.1109/tvcg.2010.137", "10.1145/2405716.2405725", "10.1145/2702123.2702172", "10.1109/tvcg.2014.2346248", "10.1109/tvcg.2011.209", "10.1111/j.1467-8659.2009.01710.x", "10.1145/3173574.3173775", "10.1145/1993060.1993065", "10.1007/978-1-4419-5653-8\\_2", "10.1177/107780049900500402", "10.1109/tvcg.2018.2864905", "10.2307/2288400", "10.2307/1511637", "10.1109/tvcg.2014.2346431", "10.1177/160940690400300403", "10.1145/2993901.2993916", "10.1145/1879831.1879836", "10.2307/3178066", "10.1109/tvcg.2018.2864913", "10.3102/0013189x022004016", "10.1109/tvcg.2015.2511718", "10.1109/tvcg.2018.2865241", "10.1016/j.ijnurstu.2010.06.004", "10.1109/tvcg.2012.213", "10.1111/0735-2751.00040", "10.1109/tvcg.2013.145", "10.1002/ev.1427", "10.1109/tvcg.2018.2811488", "10.1075/idj.23.1.07thu", "10.1109/tvcg.2009.111", "10.1109/mcg.2018.2874523", "10.1111/cgf.13184", "10.1111/cgf.13595"], "wos": 1, "children": [{"doi": "10.1109/tvcg.2020.3029413", "title": "A Design Space of Vision Science Methods for Visualization Research", "year": "2020", "conferenceName": "InfoVis", "authors": "Madison A. Elliott;Christine Nothelfer;Cindy Xiong;Danielle Albers Szafir", "citationCount": "0", "affiliation": "Elliott, MA (Corresponding Author), Univ British Columbia, Vancouver, BC, Canada. Elliott, Madison A., Univ British Columbia, Vancouver, BC, Canada. Nothelfer, Christine, Northwestern Univ, Evanston, IL 60208 USA. Xiong, Cindy, Univ Massachusetts, Amherst, MA 01003 USA. Szafir, Danielle Albers, Univ Colorado, Boulder, CO 80309 USA.", "countries": "Canada;USA", "abstract": "A growing number of efforts aim to understand what people see when using a visualization. These efforts provide scientific grounding to complement design intuitions, leading to more effective visualization practice. However, published visualization research currently reflects a limited set of available methods for understanding how people process visualized data. Alternative methods from vision science offer a rich suite of tools for understanding visualizations, but no curated collection of these methods exists in either perception or visualization research. We introduce a design space of experimental methods for empirically investigating the perceptual processes involved with viewing data visualizations to ultimately inform visualization design guidelines. This paper provides a shared lexicon for facilitating experimental visualization research. We discuss popular experimental paradigms, adjustment types, response types, and dependent measures used in vision science research, rooting each in visualization examples. We then discuss the advantages and limitations of each technique. Researchers can use this design space to create innovative studies and progress scientific understanding of design choices and evaluations in visualization. We highlight a history of collaborative success between visualization and vision science research and advocate for a deeper relationship between the two fields that can elaborate on and extend the methodological design space for understanding visualization and vision.", "keywords": "Perception,human vision,empirical research,evaluation,HCI", "link": "http://dx.doi.org/10.1109/TVCG.2020.3029413", "refList": ["10.1109/tvcg.2019.2934790", "10.1177/146879410200200205", "10.2312/eurovisshort", "10.1109/tvcg.2015.2467811", "10.1111/j.1467-6486.2009.00859.x", "10.1177/1473871613510429", "10.1109/tvcg.2018.2864836", "10.1109/tvcg.2018.2865076", "10.1109/tvcg.2013.231", "10.1002/cphy.c100079", "10.1177/0886109909354981", "10.1109/tvcg.2018.2865149", "10.1080/1750984x.2017.1317357", "10.1007/978-3-7643-8472-2\\_6", "10.1093/bioinformatics/btq110", "10.1111/cgf.13728", "10.2307/1511837", "10.1109/tvcg.2019.2934539", "10.3233/efi-2004-22201", "10.1002/chp.1340180402", "10.1111/2041-210x.12034", "10.1111/j.2041-210x.2011.00169.x", "10.1109/tvcg.2015.2467452", "10.1002/chp", "10.1177/1077800410383121", "10.1177/1744987107081254", "10.1002/cpbi.96", "10.1109/tvcg.2018.2864526", "10.1109/beliv.2018.8634026", "10.2307/1511637", "10.1109/tvcg.2014.2346431", "10.1111/cgf.12883", "10.1109/tvcg.2019.2934281", "10.1145/2993901.2993916", "10.2307/3178066", "10.1145/2993901.2993913", "10.1145/1182475.1182476", "10.1016/j.destud.2004.06.002", "10.1177/1609406918763214", "10.2312/eurovisshort.20151137", "10.1145/882262.882291", "10.1177/174498710501000305", "10.1017/s1049096513001789", "10.1109/tvcg.2012.213", "10.1093/nar/gkz239", "10.1093/sysbio/sys062", "10.1109/tvcg.2019.2898186", "10.1109/tvcg.2018.2811488", "10.1007/s11135-006-9044-4", "10.1109/tvcg.2009.111", "10.1111/2041-210x.12066", "10.1109/mcg.2018.2874523", "10.1177/1609406920909938"], "wos": 1, "children": [], "len": 1}, {"doi": "10.1109/tvcg.2020.3030438", "title": "ChemVA: Interactive Visual Analysis of Chemical Compound Similarity in Virtual Screening", "year": "2020", "conferenceName": "SciVis", "authors": "Mar\u00eda Virginia Sabando;Pavol Ulbrich;Mat\u00edas N. Selzer;Jan Byska;Jan Mican;Ignacio Ponzoni;Axel J. Soto;Maria Luj\u00e1n Ganuza;Barbora Kozl\u00edkov\u00e1", "citationCount": "0", "affiliation": "Sabando, MV (Corresponding Author), Univ Nacl Sur, Inst Comp Sci \\& Engn UNS CONICET, Bahia Blanca, Buenos Aires, Argentina. Sabando, MV (Corresponding Author), Univ Nacl Sur, Dept Comp Sci \\& Engn, Bahia Blanca, Buenos Aires, Argentina. Sabando, Maria Virginia; Selzer, Matias; Ponzoni, Ignacio; Soto, Axel J.; Ganuza, Maria Lujan, Univ Nacl Sur, Inst Comp Sci \\& Engn UNS CONICET, Bahia Blanca, Buenos Aires, Argentina. Sabando, Maria Virginia; Ponzoni, Ignacio; Soto, Axel J., Univ Nacl Sur, Dept Comp Sci \\& Engn, Bahia Blanca, Buenos Aires, Argentina. Ulbrich, Pavol; Byska, Jan; Kozlikova, Barbora, Masaryk Univ, Fac Informat, Visitlab, Brno, Czech Republic. Selzer, Matias; Ganuza, Maria Lujan, Univ Nacl Sur, VyGLab Res Lab UNS CICPBA, Dept Comp Sci \\& Engn, Bahia Blanca, Buenos Aires, Argentina. Mican, Jan, Masaryk Univ, Dept Expt Biol, Loschmidt Labs, Brno, Czech Republic. Mican, Jan, Masaryk Univ, RECETOX, Brno, Czech Republic. Mican, Jan, Masaryk Univ, Fac Med, Brno, Czech Republic.", "countries": "Argentina;Republic", "abstract": "In the modern drug discovery process, medicinal chemists deal with the complexity of analysis of large ensembles of candidate molecules. Computational tools, such as dimensionality reduction (DR) and classification, are commonly used to efficiently process the multidimensional space of features. These underlying calculations often hinder interpretability of results and prevent experts from assessing the impact of individual molecular features on the resulting representations. To provide a solution for scrutinizing such complex data, we introduce ChemVA, an interactive application for the visual exploration of large molecular ensembles and their features. Our tool consists of multiple coordinated views: Hexagonal view, Detail view, 3D view, Table view, and a newly proposed Difference view designed for the comparison of DR projections. These views display DR projections combined with biological activity, selected molecular features, and confidence scores for each of these projections. This conjunction of views allows the user to drill down through the dataset and to efficiently select candidate compounds. Our approach was evaluated on two case studies of finding structurally similar ligands with similar binding affinity to a target protein, as well as on an external qualitative evaluation. The results suggest that our system allows effective visual inspection and comparison of different high-dimensional molecular representations. Furthermore, ChemVA assists in the identification of candidate compounds while providing information on the certainty behind different molecular representations.", "keywords": "Virtual screening,visual analysis,dimensionality reduction,coordinated views,cheminformatics", "link": "http://dx.doi.org/10.1109/TVCG.2020.3030438", "refList": ["10.1109/tvcg.2008.137", "10.1057/ivs.2009.10", "10.2312/eurovisstar.20151110", "10.1109/eisic.2015.35", "10.1109/pacificvis.2014.44", "10.1145/1142473.1142574", "10.1109/tvcg.2013.223", "10.1109/tvcg.2014.2346573", "10.1109/tvcg.2019.2934539", "10.1111/cgf.13717", "10.1109/vizsec.2009.5375536", "10.1111/cgf.12925", "10.1109/tvcg.2015.2467551", "10.1109/mcg.2015.99", "10.1007/978-3-319", "10.1109/tvcg.2012.255", "10.1145/1064830.1064834", "10.1177/1473871611433713", "10.1207/s1532690xci0804\\_2", "10.1145/1168149.1168168", "10.1016/j.chb.2006.10.002", "10.1109/tvcg.2014.2346441", "10.1109/eisic.2017.15", "10.1111/1467-8721.00160", "10.1109/tvcg.2018.2865024", "10.1109/infvis.2004.2"], "wos": 1, "children": [], "len": 1}, {"doi": "10.1109/tvcg.2020.3030435", "title": "Data Visceralization: Enabling Deeper Understanding of Data Using Virtual Reality", "year": "2020", "conferenceName": "InfoVis", "authors": "Benjamin Lee;Dave Brown;Bongshin Lee;Christophe Hurter;Steven Mark Drucker;Tim Dwyer", "citationCount": "1", "affiliation": "Lee, B (Corresponding Author), Monash Univ, Clayton, Vic, Australia. Lee, Benjamin; Dwyer, Tim, Monash Univ, Clayton, Vic, Australia. Brown, Dave; Lee, Bongshin; Drucker, Steven, Microsoft Res, Redmond, WA USA. Hurter, Christophe, French Civil Aviat Univ, ENAC, Toulouse, France.", "countries": "USA;France;Australia", "abstract": "A fundamental part of data visualization is transforming data to map abstract information onto visual attributes. While this abstraction is a powerful basis for data visualization, the connection between the representation and the original underlying data (i.e., what the quantities and measurements actually correspond with in reality) can be lost. On the other hand, virtual reality (VR) is being increasingly used to represent real and abstract models as natural experiences to users. In this work, we explore the potential of using VR to help restore the basic understanding of units and measures that are often abstracted away in data visualization in an approach we call data visceralization. By building VR prototypes as design probes, we identify key themes and factors for data visceralization. We do this first through a critical reflection by the authors, then by involving external participants. We find that data visceralization is an engaging way of understanding the qualitative aspects of physical measures and their real-life form, which complements analytical and quantitative understanding commonly gained from data visualization. However, data visceralization is most effective when there is a one-to-one mapping between data and representation, with transformations such as scaling affecting this understanding. We conclude with a discussion of future directions for data visceralization.", "keywords": "Data visceralization,virtual reality,exploratory study", "link": "http://dx.doi.org/10.1109/TVCG.2020.3030435", "refList": ["10.1080/01973762.2013.761106", "10.1109/tvcg.2015.2467811", "10.1109/tvcg.2012.221", "10.1145/3284179.3284326", "10.1109/tvcg.2019.2934287", "10.1109/2945.841119", "10.1109/tvcg.2019.2934539", "10.1109/mcg.2013.101", "10.1109/tvcg.2011.175", "10.1109/tvcg.2018.2830759", "10.1109/3dvis.2014.7160096", "10.1109/mcg.2018.2878900", "10.1109/iv.2011.32", "10.1109/tvcg.2013.196", "10.1109/tvcg.2018.2865241", "10.1515/abitech-2017-0002", "10.1145/2468356.2468739", "10.16995/olh.280", "10.1080/15230406.2018.1513343", "10.1109/iv.2004.1320189", "10.1109/tvcg.2012.213", "10.1109/mcg.2006.120", "10.1109/icdar.2017.286", "10.1371/journal.pone.0146368", "10.1080/1472586x.2011.548488", "10.1109/tvcg.2014.2346574", "10.1080/0013838x.2017.1332021"], "wos": 1, "children": [], "len": 1}, {"doi": "10.1109/tvcg.2020.3030464", "title": "Designing Narrative-Focused Role-Playing Games for Visualization Literacy in Young Children", "year": "2020", "conferenceName": "InfoVis", "authors": "Elaine Huynh;Angela Nyhout;Patricia Ganea;Fanny Chevalier", "citationCount": "0", "affiliation": "Huynh, E (Corresponding Author), Univ Toronto, Dept Comp Sci, Toronto, ON, Canada. Huynh, Elaine, Univ Toronto, Dept Comp Sci, Toronto, ON, Canada. Nyhout, Angela; Ganea, Patricia, Univ Toronto, Ontario Inst Studies Educ, Toronto, ON, Canada. Chevalier, Fanny, Univ Toronto, Dept Comp Sci \\& Stat Sci, Toronto, ON, Canada.", "countries": "Canada", "abstract": "Building on game design and education research, this paper introduces narrative-focused role-playing games as a way to promote visualization literacy in young children. Visualization literacy skills are vital in understanding the world around us and constructing meaningful visualizations, yet, how to better develop these skills at an early age remains largely overlooked and understudied. Only recently has the visualization community started to fill this gap, resulting in preliminary studies and development of educational tools for use in early education. We add to these efforts through the exploration of gamification to support learning, and identify an opportunity to apply role-playing game-based designs by leveraging the presence of narratives in data-related problems involving visualizations. We study the effects of including narrative elements on learning through a technology probe, grounded in a set of design considerations stemming from visualization, game design and education science. We create two versions of a game - one with narrative elements and one without - and evaluate our instances on 33 child participants between 11- to 13-years old using a between-subjects study design. Despite participants requiring double the amount of time to complete their game due to additional narrative elements, the inclusion of such elements were found to improve engagement without sacrificing learning; our results indicate no significant differences in development of graph-reading skills, but significant differences in engagement and overall enjoyment of the game. We report observations and qualitative feedback collected, and note areas for improvement and room for future work.", "keywords": "Visualization Literacy,Educational technology,Gamification,Narrative", "link": "http://dx.doi.org/10.1109/TVCG.2020.3030464", "refList": ["10.1007/978-981-13-2694-3\\_2", "10.1145/2702123.2702298", "10.1145/2702123.2702558", "10.1007/978-981-13-2694-3\\_8", "10.1145/2702123.2702245", "10.1109/mis.2012.27", "10.18061/dsq.v21i4.318", "10.1109/tvcg.2013.134", "10.1109/vl.1996.545307", "10.1007/s10708-008-9186-0", "10.1093/cje/ben057", "10.5210/fm.v16i2.3316", "10.1109/tvcg.2019.2934539", "10.1109/tvcg.2016.2598608", "10.1007/978-3-319-94659-7\\_10", "10.1109/mcg.2013.28", "10.17351/ests2017.134", "10.1109/pacificvis.2014.39", "10.1145/3173574.3173728", "10.1145/2598784.2598806", "10.1145/2491500.2491501", "10.1145/1993060.1993065", "10.1109/tvcg.2018.2802520", "10.1145/3025453.3025667", "10.1145/2598510.2598566", "10.1080/15710882.2015.1081240", "10.17351/ests2017.133", "10.1109/tvcg.2014.2346431", "10.1016/j.ijhcs.2015.02.005", "10.1145/2702123.2702180", "10.1109/tvcg.2007.70577", "10.1109/mcg.2019.2923483", "10.5931/djim.v12.i1.6449", "10.1145/3240167.3240206", "10.1145/2468356.2468739", "10.1109/tvcg.2012.213", "10.1145/3025453.3025751", "10.4018/978-1-4666-6497-5.ch003"], "wos": 1, "children": [], "len": 1}, {"doi": "10.1109/tvcg.2020.3030355", "title": "Guidelines For Pursuing and Revealing Data Abstractions", "year": "2020", "conferenceName": "InfoVis", "authors": "Alex Bigelow;Katy Williams;Katherine E. Isaacs", "citationCount": "0", "affiliation": "Bigelow, A (Corresponding Author), Univ Arizona, Tucson, AZ 85721 USA. Bigelow, Alex; Williams, Katy; Isaacs, Katherine E., Univ Arizona, Tucson, AZ 85721 USA.", "countries": "USA", "abstract": "Many data abstraction types, such as networks or set relationships, remain unfamiliar to data workers beyond the visualization research community. We conduct a survey and series of interviews about how people describe their data, either directly or indirectly. We refer to the latter as latent data abstractions. We conduct a Grounded Theory analysis that (1) interprets the extent to which latent data abstractions exist, (2) reveals the far-reaching effects that the interventionist pursuit of such abstractions can have on data workers, (3) describes why and when data workers may resist such explorations, and (4) suggests how to take advantage of opportunities and mitigate risks through transparency about visualization research perspectives and agendas. We then use the themes and codes discovered in the Grounded Theory analysis to develop guidelines for data abstraction in visualization projects. To continue the discussion, we make our dataset open along with a visual interface for further exploration.", "keywords": "Data abstraction,Grounded theory,Survey design,Data wrangling", "link": "http://dx.doi.org/10.1109/TVCG.2020.3030355", "refList": ["10.1080/2159676x.2016.1251701", "10.1109/infvis.2000.885092", "10.1145/2702123.2702298", "10.4135/9781848607941.n14", "10.1007/978-1-4939", "10.1109/tvcg.2014.2346331", "10.1109/tvcg.2017.2744843", "10.1177/1473871613510429", "10.1007/978-1-4939-0378-8\\_2", "10.1145/2598153.2598175", "10.1109/tvcg.2019.2934285", "10.1177/1473871613488591", "10.1145/2501105.2501106", "10.1109/tvcg.2019.2934538", "10.1109/tvcg.2019.2934539", "10.1017/s1049096510990781", "10.1145/3025453.3025837", "10.1145/3290605.3300474", "10.1145/3290605.3300356", "10.1002/nur.1025", "10.1145/2993901.2993916", "10.1145/3392826", "10.1086/269268", "10.1109/tvcg.2018.2865241", "10.1145/2998181.2998331", "10.1145/291224.291229", "10.1057/ivs.2009.13", "10.1145/2047196.2047205", "10.1109/tvcg.2012.213", "10.1145/3274405", "10.1109/tvcg.2013.145", "10.1016/0040-6031(92)85160-w", "10.1109/iv.2013.45", "10.1109/tvcg.2009.111", "10.1109/mcg.2019.2914844", "10.1109/tvcg.2009.116"], "wos": 1, "children": [], "len": 1}, {"doi": "10.1109/tvcg.2020.3030405", "title": "Insights From Experiments With Rigor in an EvoBio Design Study", "year": "2020", "conferenceName": "InfoVis", "authors": "Jennifer Rogers;Austin H. Patton;Luke Harmon;Alexander Lex;Miriah D. Meyer", "citationCount": "0", "affiliation": "Rogers, J (Corresponding Author), Univ Utah, Salt Lake City, UT 84112 USA. Rogers, Jen; Lex, Alexander; Meyer, Miriah, Univ Utah, Salt Lake City, UT 84112 USA. Patton, Austin H., Washington State Univ, Pullman, WA 99164 USA. Harmon, Luke, Univ Idaho, Moscow, ID 83843 USA.", "countries": "USA", "abstract": "Design study is an established approach of conducting problem-driven visualization research. The academic visualization community has produced a large body of work for reporting on design studies, informed by a handful of theoretical frameworks, and applied to a broad range of application areas. The result is an abundance of reported insights into visualization design, with an emphasis on novel visualization techniques and systems as the primary contribution of these studies. In recent work we proposed a new, interpretivist perspective on design study and six companion criteria for rigor that highlight the opportunities for researchers to contribute knowledge that extends beyond visualization idioms and software. In this work we conducted a year-long collaboration with evolutionary biologists to develop an interactive tool for visual exploration of multivariate datasets and phylogenetic trees. During this design study we experimented with methods to support three of the rigor criteria: ABUNDANT, REFLEXIVE, and TRANSPARENT. As a result we contribute two novel visualization techniques for the analysis of multivariate phylogenetic datasets, three methodological recommendations for conducting design studies drawn from reflections over our process of experimentation, and two writing devices for reporting interpretivist design study. We offer this work as an example for implementing the rigor criteria to produce a diverse range of knowledge contributions.", "keywords": "Methodologies,Application Motivated Visualization,Guidelines,Life Sciences Visualization,Health,Medicine,Biology,Bioinformatics,Genomics", "link": "http://dx.doi.org/10.1109/TVCG.2020.3030405", "refList": ["10.1109/tvcg.2019.2934790", "10.1177/146879410200200205", "10.2312/eurovisshort", "10.1109/tvcg.2015.2467811", "10.1111/j.1467-6486.2009.00859.x", "10.1177/1473871613510429", "10.1109/tvcg.2018.2864836", "10.1109/tvcg.2018.2865076", "10.1109/tvcg.2013.231", "10.1002/cphy.c100079", "10.1109/tvcg.2018.2865149", "10.1080/1750984x.2017.1317357", "10.1007/978-3-7643-8472-2\\_6", "10.1111/cgf.13728", "10.2307/1511837", "10.1109/tvcg.2019.2934539", "10.3233/efi-2004-22201", "10.1080/17493460802276893", "10.1002/chp.1340180402", "10.1111/2041-210x.12034", "10.1111/j.2041-210x.2011.00169.x", "10.1109/tvcg.2015.2467452", "10.1002/chp", "10.1177/1077800410383121", "10.1002/cpbi.96", "10.1109/tvcg.2018.2864526", "10.1109/beliv.2018.8634026", "10.2307/1511637", "10.1109/tvcg.2014.2346431", "10.1111/cgf.12883", "10.1109/tvcg.2019.2934281", "10.1145/2993901.2993916", "10.2307/3178066", "10.1145/2993901.2993913", "10.1145/1182475.1182476", "10.1016/j.destud.2004.06.002", "10.1177/1609406918763214", "10.2312/eurovisshort.20151137", "10.1145/882262.882291", "10.1109/tvcg.2012.213", "10.1109/tvcg.2019.2898186", "10.1109/tvcg.2018.2811488", "10.1007/s11135-006-9044-4", "10.1109/tvcg.2009.111", "10.1111/2041-210x.12066", "10.1109/mcg.2018.2874523", "10.1177/1609406920909938"], "wos": 1, "children": [], "len": 1}, {"doi": "10.1109/tvcg.2020.3030462", "title": "Table Scraps: An Actionable Framework for Multi-Table Data Wrangling From An Artifact Study of Computational Journalism", "year": "2020", "conferenceName": "InfoVis", "authors": "Stephen Kasica;Charles Berret;Tamara Munzner", "citationCount": "0", "affiliation": "Kasica, S (Corresponding Author), Univ British Columbia, Dept Comp Sci, Vancouver, BC, Canada. Kasica, Stephen; Munzner, Tamara, Univ British Columbia, Dept Comp Sci, Vancouver, BC, Canada. Berret, Charles, Univ British Columbia, Sch Journalism Writing \\& Media, Vancouver, BC, Canada.", "countries": "Canada", "abstract": "For the many journalists who use data and computation to report the news, data wrangling is an integral part of their work. Despite an abundance of literature on data wrangling in the context of enterprise data analysis, little is known about the specific operations, processes, and pain points journalists encounter while performing this tedious, time-consuming task. To better understand the needs of this user group, we conduct a technical observation study of 50 public repositories of data and analysis code authored by 33 professional journalists at 26 news organizations. We develop two detailed and cross-cutting taxonomies of data wrangling in computational journalism, for actions and for processes. We observe the extensive use of multiple tables, a notable gap in previous wrangling analyses. We develop a concise, actionable framework for general multi-table data wrangling that includes wrangling operations documented in our taxonomy that are without clear parallels in other work. This framework, the first to incorporate tables as first-class objects, will support future interactive wrangling tools for both computational journalism and general-purpose use. We assess the generative and descriptive power of our framework through discussion of its relationship to our set of taxonomies.", "keywords": "Computational journalism,Data journalism,Data wrangling", "link": "http://dx.doi.org/10.1109/TVCG.2020.3030462", "refList": ["10.1145/1378773.1378792", "10.1109/tvcg.2012.219", "10.1109/vast47406.2019.8986909", "10.1145/1084805.1084812", "10.1007/s00778-008-0098-x", "10.1016/j.websem.2008.09.005", "10.18637/jss.v040.i01", "10.1145/989863.989865", "10.1109/tvcg.2015.2467551", "10.5281/zenodo.3509134", "10.1109/tvcg.2019.2934539", "10.1109/tvcg.2019.2934593", "10.1109/tse.2018.2796554", "10.17349/jmc117309", "10.1109/2945.981851", "10.1109/vast.2011.6102440", "10.1177/1473871611415994", "10.1145/2001269.2001288"], "wos": 1, "children": [], "len": 1}, {"doi": "10.1111/cgf.13964", "year": "2020", "title": "Reading Traces: Scalable Exploration in Elastic Visualizations of Cultural Heritage Data", "conferenceName": "EuroVis", "authors": "Mark{-}Jan Bludau;Viktoria Br{\\\"{u}}ggemann;Anna Busch;Marian D{\\\"{o}}rk", "citationCount": "1", "affiliation": "Bludau, MJ (Corresponding Author), Univ Appl Sci Potsdam, UCLAB, Potsdam, Germany.\nBludau, M. -J.; Brueggemann, V.; Doerk, M., Univ Appl Sci Potsdam, UCLAB, Potsdam, Germany.\nBusch, A., Univ Potsdam, Theodor Fontane Archiv, Potsdam, Germany.", "countries": "Germany", "abstract": "Through a design study, we develop an approach to data exploration that utilizes elastic visualizations designed to support varying degrees of detail and abstraction. Examining the notions of scalability and elasticity in interactive visualizations, we introduce a visualization of personal reading traces such as marginalia or markings inside the reference library of German realist author Theodor Fontane. To explore such a rich and extensive collection, meaningful visual forms of abstraction and detail are as important as the transitions between those states. Following a growing research interest in the role of fluid interactivity and animations between views, we are particularly interested in the potential of carefully designed transitions and consistent representations across scales. The resulting prototype addresses humanistic research questions about the interplay of distant and close reading with visualization research on continuous navigation along several granularity levels, using scrolling as one of the main interaction mechanisms. In addition to presenting the design process and resulting prototype, we present findings from a qualitative evaluation of the tool, which suggest that bridging between distant and close views can enhance exploration, but that transitions between views need to be crafted very carefully to facilitate comprehension.", "keywords": "", "link": "https://doi.org/10.1111/cgf.13964", "refList": ["10.1007/s41244-017-0048-4", "10.1109/tvcg.2009.108", "10.1145/1456650.1456652", "10.1109/tvcg.2014.2346424", "10.1177/1473871611416549", "10.1111/cgf.13195", "10.1145/2207676.2208607", "10.1145/1376616.1376618", "10.1006/ijhc.2002.1017", "10.1109/tvcg.2011.185", "10.1177/1473871611413180", "10.1109/vl.1996.545307", "10.1006/ijhc.1017", "10.1109/tvcg.2019.2934539", "10.1109/tvcg.2018.2830759", "10.1145/1556262.1556300", "10.1109/tvcg.2014.2346677", "10.1145/2909132.2909255", "10.1109/tvcg.2007.70539", "10.1145/2396636.2396675", "10.1145/1978942.1979124", "10.1016/j.ijhcs.2003.08.005", "10.2312/eurovisstar.20151113", "10.1109/infvis.2005.1532127"], "wos": 1, "children": [], "len": 1}], "len": 17}, {"doi": "10.1109/tvcg.2019.2934283", "title": "What is Interaction for Data Visualization?", "year": "2019", "conferenceName": "InfoVis", "authors": "Evanthia Dimara;Charles Perin", "citationCount": "1", "affiliation": "Dimara, E (Corresponding Author), Sorbonne Univ, Paris, France. Dimara, Evanthia, Sorbonne Univ, Paris, France. Perin, Charles, Univ Victoria, Victoria, BC, Canada.", "countries": "Canada;France", "abstract": "Interaction is fundamental to data visualization, but what \u201cinteraction\u201d means in the context of visualization is ambiguous and confusing. We argue that this confusion is due to a lack of consensual definition. To tackle this problem, we start by synthesizing an inclusive view of interaction in the visualization community \u2013 including insights from information visualization, visual analytics and scientific visualization, as well as the input of both senior and junior visualization researchers. Once this view takes shape, we look at how interaction is defined in the field of human-computer interaction (HCI). By extracting commonalities and differences between the views of interaction in visualization and in HCI, we synthesize a definition of interaction for visualization. Our definition is meant to be a thinking tool and inspire novel and bolder interaction design practices. We hope that by better understanding what interaction in visualization is and what it can be, we will enrich the quality of interaction in visualization systems and empower those who use them.", "keywords": "interaction,visualization,data,definition,human-computer interaction", "link": "http://dx.doi.org/10.1109/TVCG.2019.2934283", "refList": ["10.1057/ivs.2009.22", "10.1515/icom-2017-0027", "10.1145/2493102.2493104", "10.1007/978-3-319-06793-3\\_6", "10.1080/03640210801898177", "10.1109/mcg.2010.30", "10.1109/tvcg.2013.134", "10.1109/tvcg.2017.2745958", "10.1109/tvcg.2018.2865237", "10.1109/2945.981847", "10.1145/2598784.2598806", "10.1109/tvcg.2013.130", "10.1109/tvcg.2007.70577", "10.1109/mic.2015.129", "10.1145/2909132.2909267", "10.1080/01449290500330331", "10.1109/tvcg.2018.2865233", "10.1109/tvcg.2015.2467831", "10.1109/iv.2015.34", "10.1109/tvcg.2009.111", "10.1145/3290605.3300565", "10.1145/3173574.3173797", "10.1145/948496.948514", "10.1145/3025453.3025765", "10.1109/tvcg.2015.2467613", "10.1145/2659796", "10.1109/tvcg.2014.2346311", "10.1145/3025453.3025524", "10.1080/17452759.2011.558588", "10.1145/3027063.3053113", "10.1109/infvis.2005.1532136", "10.1145/2470654.2481307", "10.1109/tvcg.2018.2864913", "10.1145/345513.345267", "10.3102/00028312005004437", "10.1109/tvcg.2007.70436", "10.1037/0033-295x.106.4.643", "10.1145/2133416.2146416", "10.1109/tvcg.2013.191", "10.1109/tvcg.2010.177", "10.1145/960201.957206", "10.1109/tvcg.2007.70515", "10.1109/infvis.2000.885092", "10.1145/2636240.2636844", "10.1037/h0055392", "10.1177/1473871611413180", "10.1109/vl.1996.545307", "10.1111/j.1471-1842.2009.00848.x", "10.1145/989863.989865", "10.1109/tvcg.2013.124", "10.1109/tvcg.2008.109", "10.1145/1166253.1166265", "10.1145/2702123.2702180", "10.1109/tvcg.2016.2598620", "10.1080/07370024.2016.1226139", "10.1145/3173574.3173909", "10.1109/pacificvis.2010.5429613", "10.1111/j.1467-6478.2006.00368.x", "10.1109/tvcg.2012.204", "10.1109/tvcg.2013.120", "10.1179/1743277412y.0000000019", "10.1145/1936652.1936684", "10.2307/1269768", "10.1109/infvis.1996.559213", "10.1109/tvcg.2016.2598839", "10.1145/2642918.2647360", "10.1057/palgrave.ivs.9500099", "10.1016/j.cag.2009.06.004", "10.1109/mc.2013.178", "10.1109/tvcg.2007.70541", "10.1109/vast.2011.6102473", "10.1145/358886.358895", "10.1109/tvcg.2014.2346573", "10.1109/tvcg.2018.2865159", "10.1145/2207676.2207741", "10.1109/tvcg.2015.2396062", "10.1145/2207676.2208572", "10.1109/tvcg.2016.2598608", "10.1057/ivs.2008.31", "10.1177/001316446002000104", "10.1109/tvcg.2017.2680452", "10.1109/tvcg.2006.80", "10.1145/2598510.2598566", "10.1037/0003-066x.51.4.355", "10.7146/dpb.v16i224.7586", "10.1109/infvis.1998.729560", "10.1162/leon\\_a\\_00011", "10.1109/tvcg.2010.157", "10.1109/tvcg.2014.2359887"], "wos": 1, "children": [], "len": 1}], "len": 21}, {"doi": "10.1109/tvcg.2018.2865193", "title": "Visualizing Uncertain Tropical Cyclone Predictions using Representative Samples from Ensembles of Forecast Tracks", "year": "2018", "conferenceName": "InfoVis", "authors": "Le Liu 0007;Lace M. K. Padilla;Sarah H. Creem-Regehr;Donald H. House", "citationCount": "4", "affiliation": "Liu, L (Corresponding Author), Mag Weaver Inc, 2755 Great Amer Way,Ste 135, Santa Clara, CA 95054 USA. Liu, Le, Mag Weaver Inc, 2755 Great Amer Way,Ste 135, Santa Clara, CA 95054 USA. Padilla, Lace, Northwestern Univ, Dept Psychol, 2029 Sheridan Rd, Evanston, IL 60208 USA. Creem-Regehr, Sarah H., Univ Utah, Dept Psychol, 380 S 1530 E Beh S 502, Salt Lake City, UT 84112 USA. House, Donald H., Clemson Univ, Sch Comp, 100 McAdams Hall, Clemson, SC 29672 USA. House, Donald H., Bahai Inst Higher Educ, Tehran, Iran.", "countries": "Iran;USA", "abstract": "A common approach to sampling the space of a prediction is the generation of an ensemble of potential outcomes, where the ensemble's distribution reveals the statistical structure of the prediction space. For example, the US National Hurricane Center generates multiple day predictions for a storm's path, size, and wind speed, and then uses a Monte Carlo approach to sample this prediction into a large ensemble of potential storm outcomes. Various forms of summary visualizations are generated from such an ensemble, often using spatial spread to indicate its statistical characteristics. However, studies have shown that changes in the size of such summary glyphs, representing changes in the uncertainty of the prediction, are frequently confounded with other attributes of the phenomenon, such as its size or strength. In addition, simulation ensembles typically encode multivariate information, which can be difficult or confusing to include in a summary display. This problem can be overcome by directly displaying the ensemble as a set of annotated trajectories, however this solution will not be effective if ensembles are densely overdrawn or structurally disorganized. We propose to overcome these difficulties by selectively sampling the original ensemble, constructing a smaller representative and spatially well organized ensemble. This can be drawn directly as a set of paths that implicitly reveals the underlying spatial uncertainty distribution of the prediction. Since this approach does not use a visual channel to encode uncertainty, additional information can more easily be encoded in the display without leading to visual confusion. To demonstrate our argument, we describe the development of a visualization for ensembles of tropical cyclone forecast tracks, explaining how their spatial and temporal predictions, as well as other crucial storm characteristics such as size and intensity, can be clearly revealed. We verify the effectiveness of this visualization approach through a cognitive study exploring how storm damage estimates are affected by the density of tracks drawn, and by the presence or absence of annotating information on storm size and intensity.", "keywords": "uncertainty visualization,hurricane forecasts,ensemble visualization,ensemble sampling,implicit uncertainty", "link": "http://dx.doi.org/10.1109/TVCG.2018.2865193", "refList": ["10.1186/s41235-017-0076-1", "10.1007/978-3-540-71158-2\\_12", "10.1175/waf-d-12-00116.1", "10.1615/int.j.uncertaintyquantification.2012003966", "10.3138/fm57-6770-u75u-7727", "10.1080/13875868.2015.1137577", "10.1080/00207179608921659", "10.1175/2009waf2222286.1", "10.20982/tqmp.04.2.p061", "10.1109/tvcg.2014.2346455", "10.1109/tvcg.2010.181", "10.1109/tvcg.2017.2743898", "10.1109/72.80341", "10.1090/qam/15914", "10.1214/aos/1176347507", "10.1111/cgf.12649", "10.18637/jss.v067.i01", "10.1109/tvcg.2016.2607204", "10.1179/000870406x93490", "10.1145/2858036.2858558"], "wos": 1, "children": [{"doi": "10.1109/tvcg.2020.3030466", "title": "Uncertainty in Continuous Scatterplots, Continuous Parallel Coordinates, and Fibers", "year": "2020", "conferenceName": "SciVis", "authors": "Boyan Zheng;Filip Sadlo", "citationCount": "0", "affiliation": "Zheng, BY (Corresponding Author), Heidelberg Univ, Heidelberg, Germany. Zheng, Boyan; Sadlo, Filip, Heidelberg Univ, Heidelberg, Germany.", "countries": "Germany", "abstract": "In this paper, we introduce uncertainty to continuous scatterplots and continuous parallel coordinates. We derive respective models, validate them with sampling-based brute-force schemes, and present acceleration strategies for their computation. At the same time, we show that our approach lends itself as well for introducing uncertainty into the definition of fibers in bivariate data. Finally, we demonstrate the properties and the utility of our approach using specifically designed synthetic cases and simulated data.", "keywords": "Multivariate data,uncertainty visualization,uncertain continuous scatterplots,uncertain continuous parallel coordinates,uncertain fibers", "link": "http://dx.doi.org/10.1109/TVCG.2020.3030466", "refList": ["10.1109/tvcg.2018.2865193", "10.1109/tvcg.2013.143", "10.1109/tvcg.2015.2467204", "10.1109/pacificvis.2013.6596144", "10.1109/tvcg.2017.2745178", "10.1109/tmm.2016.2614227", "10.1109/scivis.2015.7429488", "10.1111/cgf.12100", "10.1109/pacificvis.2016.7465251", "10.1111/cgf.12898", "10.1109/tvcg.2015.2410278", "10.1109/icdmw.2009.55", "10.1109/tvcg.2015.2467754", "10.1109/tvcg.2010.247", "10.1109/tvcg.2019.2934312", "10.1111/cgf.13397", "10.1109/tvcg.2016.2598868", "10.1111/j.1467-8659.2011.01944.x", "10.1109/tvcg.2015.2507569", "10.1109/tvcg.2013.92", "10.1145/1268517.1268563", "10.1109/tvcg.2014.2346455", "10.1109/tvcg.2010.181", "10.1109/tvcg.2018.2853721", "10.1109/tvcg.2008.140", "10.1007/s12650-015-0341-7", "10.1109/mcg.2014.52", "10.1109/tvcg.2018.2864815", "10.1111/j.1467-8659.2012.03095.x", "10.1109/tvcg.2013.138", "10.1109/tvcg.2019.2934242", "10.3390/e20070540", "10.1016/j.jcp.2007.02.014", "10.1111/cgf.13999", "10.1109/tvcg.2017.2779501", "10.1111/cgf.12390", "10.1109/tvcg.2014.2307892", "10.1111/cgf.13531", "10.1109/tvcg.2013.152", "10.1038/nature14956", "10.1007/978-3-540-88606-8\\_4", "10.1109/mcg.2005.71", "10.1111/j.1467-8659.2011.01942.x", "10.1109/tvcg.2019.2934800", "10.1109/tvcg.2016.2598830", "10.1109/cvpr.2005.188", "10.1109/tvcg.2011.261", "10.1111/cgf.13731", "10.1109/tvcg.2017.2754480"], "wos": 1, "children": [], "len": 1}], "len": 3}, {"doi": "10.1109/tvcg.2019.2934399", "title": "Illusion of Causality in Visualized Data", "year": "2019", "conferenceName": "InfoVis", "authors": "Cindy Xiong;Joel Shapiro;Jessica Hullman;Steven Franconeri", "citationCount": "4", "affiliation": "Xiong, C (Corresponding Author), Northwestern Univ, Evanston, IL 60208 USA. Xiong, Cindy; Hullman, Jessica; Franconeri, Steven, Northwestern Univ, Evanston, IL 60208 USA. Shapiro, Joel, Northwestern Univ, Kellogg Sch Management, Evanston, IL 60208 USA.", "countries": "USA", "abstract": "Students who eat breakfast more frequently tend to have a higher grade point average. From this data, many people might confidently state that a before-school breakfast program would lead to higher grades. This is a reasoning error, because correlation does not necessarily indicate causation \u2013 X and Y can be correlated without one directly causing the other. While this error is pervasive, its prevalence might be amplified or mitigated by the way that the data is presented to a viewer. Across three crowdsourced experiments, we examined whether how simple data relations are presented would mitigate this reasoning error. The first experiment tested examples similar to the breakfast-GPA relation, varying in the plausibility of the causal link. We asked participants to rate their level of agreement that the relation was correlated, which they rated appropriately as high. However, participants also expressed high agreement with a causal interpretation of the data. Levels of support for the causal interpretation were not equally strong across visualization types: causality ratings were highest for text descriptions and bar graphs, but weaker for scatter plots. But is this effect driven by bar graphs aggregating data into two groups or by the visual encoding type? We isolated data aggregation versus visual encoding type and examined their individual effect on perceived causality. Overall, different visualization designs afford different cognitive reasoning affordances across the same data. High levels of data aggregation by graphs tend to be associated with higher perceived causality in data. Participants perceived line and dot visual encodings as more causal than bar encodings. Our results demonstrate how some visualization designs trigger stronger causal links while choosing others can help mitigate unwarranted perceptions of causality.", "keywords": "Information Visualization,Correlation and Causation,Visualization Design,Reasoning Affordance", "link": "http://dx.doi.org/10.1109/TVCG.2019.2934399", "refList": ["10.1109/tvcg.2014.2346979", "10.1109/tvcg.2018.2864909", "10.2307/2277140", "10.2307/2276829", "10.3389/fpsyg.2015.00888", "10.3758/s13423-012-0247-5", "10.1177/1075547012458290", "10.1109/tvcg.2014.2346419", "10.1207/s15516709cog0000\\_70", "10.1037/0003-066x.53.4.449", "10.1109/tvcg.2017.2743898", "10.1109/vast.2017.8585665", "10.1159/000323281", "10.1016/j.crm.2015.06.007", "10.1002/9781119055259", "10.1002/acp.2350050106", "10.1136/bmj.g7015", "10.3758/bf03201236", "10.1073/pnas.1608845113", "10.1109/tvcg.2013.173", "10.1109/beliv.2018.8634267", "10.1145/3025453.3025512", "10.1109/tvcg.2016.2598594", "10.2307/2288400", "10.1080/00461520.2014.921572", "10.1002/jhbs.20078", "10.1016/s0010-0277(00)00060-3", "10.1016/0885-2014(88)90027-5", "10.1016/bs.plm.2016.11.006", "10.1016/j.cognition.2012.04.005", "10.1109/tvcg.2014.2346298", "10.1257/aer.100.2.573", "10.1145/2858036.2858558"], "wos": 1, "children": [{"doi": "10.1109/tvcg.2020.3028958", "title": "Auditing the Sensitivity of Graph-based Ranking with Visual Analytics", "year": "2020", "conferenceName": "VAST", "authors": "Tiankai Xie;Yuxin Ma;Hanghang Tong;My T. Thai;Ross Maciejewski", "citationCount": "0", "affiliation": "Xie, TK (Corresponding Author), Arizona State Univ, Tempe, AZ 85287 USA. Xie, Tiankai; Ma, Yuxin; Maciejewski, Ross, Arizona State Univ, Tempe, AZ 85287 USA. Tong, Hanghang, Univ Illinois, Urbana, IL USA. Thai, My T., Univ Florida, Gainesville, FL 32611 USA.", "countries": "USA", "abstract": "Graph mining plays a pivotal role across a number of disciplines, and a variety of algorithms have been developed to answer who/what type questions. For example, what items shall we recommend to a given user on an e-commerce platform? The answers to such questions are typically returned in the form of a ranked list, and graph-based ranking methods are widely used in industrial information retrieval settings. However, these ranking algorithms have a variety of sensitivities, and even small changes in rank can lead to vast reductions in product sales and page hits. As such, there is a need for tools and methods that can help model developers and analysts explore the sensitivities of graph ranking algorithms with respect to perturbations within the graph structure. In this paper, we present a visual analytics framework for explaining and exploring the sensitivity of any graph-based ranking algorithm by performing perturbation-based what-if analysis. We demonstrate our framework through three case studies inspecting the sensitivity of two classic graph-based ranking algorithms (PageRank and HITS) as applied to rankings in political news media and social networks.", "keywords": "Graph-based ranking,sensitivity analysis,visual analytics", "link": "http://dx.doi.org/10.1109/TVCG.2020.3028958", "refList": ["10.1109/wsc.2017.8247800", "10.1023/a:1022649401552", "10.1515/1559-0410.11416", "10.1109/tvcg.2016.2598919", "10.1177/1473871611416549", "10.1109/tvcg.2019.2934630", "10.1140/epjds29", "10.1109/tvcg.2019.2934670", "10.1016/j.eswa.2015.09.004", "10.1145/2702123.2702509", "10.1016/j.visinf.2018.12.001", "10.2307/3002000", "10.1109/tvcg.2019.2934399", "10.1007/s41060-016-0032-z", "10.1111/cgf.13198", "10.14778/2350229.2350254", "10.1145/2939672.2939764", "10.1016/j.visinf.2017.01.006", "10.1145/2858036.2858529", "10.1109/vast.2017.8585647", "10.1007/bf01187020", "10.1109/icdm.2015.26", "10.1145/2362383.2362387", "10.1177/0049124104268644", "10.1109/vast.2011.6102442", "10.1109/infvis.2003.1249025", "10.1109/tvcg.2018.2864475", "10.1109/tvcg.2007.70528", "10.1109/tvcg.2015.2467691", "10.1111/cgf.13210", "10.1214/aos/1176344136", "10.1109/tvcg.2015.2424872", "10.1016/j.visinf.2018.09.001", "10.1177/089443939100900106", "10.1109/tvcg.2015.2467931", "10.1162/neco.1997.9.8.1735", "10.1007/s11162-011-9241-4", "10.1111/cgf.13680", "10.1145/3065386", "10.1109/tvcg.2018.2864889", "10.1177/003804070808100402", "10.1109/icdm.2010.62", "10.1038/s41598-020-59669-x", "10.1162/153244303321897717", "10.1109/tvcg.2019.2934619", "10.1007/bf00356088", "10.1109/tvcg.2016.2598432", "10.1109/tvcg.2016.2598831"], "wos": 1, "children": [], "len": 1}, {"doi": "10.1109/tvcg.2020.3030465", "title": "Visual Causality Analysis of Event Sequence Data", "year": "2020", "conferenceName": "VAST", "authors": "Zhuochen Jin;Shunan Guo;Nan Chen;Daniel Weiskopf;David Gotz;Nan Cao", "citationCount": "0", "affiliation": "Cao, N (Corresponding Author), Tongji Univ, IDVx Lab, Shanghai, Peoples R China. Jin, Zhuochen; Guo, Shunan; Chen, Nan; Cao, Nan, Tongji Univ, IDVx Lab, Shanghai, Peoples R China. Weiskopf, Daniel, Univ Stuttgart, Stuttgart, Germany. Gotz, David, Univ N Carolina, Chapel Hill, NC 27515 USA.", "countries": "USA;Germany;China", "abstract": "Causality is crucial to understanding the mechanisms behind complex systems and making decisions that lead to intended outcomes. Event sequence data is widely collected from many real-world processes, such as electronic health records, web clickstreams, and financial transactions, which transmit a great deal of information reflecting the causal relations among event types. Unfortunately, recovering causalities from observational event sequences is challenging, as the heterogeneous and high-dimensional event variables are often connected to rather complex underlying event excitation mechanisms that are hard to infer from limited observations. Many existing automated causal analysis techniques suffer from poor explainability and fail to include an adequate amount of human knowledge. In this paper, we introduce a visual analytics method for recovering causalities in event sequence data. We extend the Granger causality analysis algorithm on Hawkes processes to incorporate user feedback into causal model refinement. The visualization system includes an interactive causal analysis framework that supports bottom-up causal exploration, iterative causal verification and refinement, and causal comparison through a set of novel visualizations and interactions. We report two forms of evaluation: a quantitative evaluation of the model improvements resulting from the user-feedback mechanism, and a qualitative evaluation through case studies in different application domains to demonstrate the usefulness of the system.", "keywords": "Event sequence data,causality analysis,visual analytics", "link": "http://dx.doi.org/10.1109/TVCG.2020.3030465", "refList": ["10.5555/1642718", "10.1109/tvcg.2018.2865022", "10.5555/2074094.2074151", "10.1109/tvcg.2016.2618797", "10.1073/pnas.1320645111", "10.1109/tvcg.2017.2744843", "10.1109/iv.2017.69", "10.1109/tvcg.2019.2934399", "10.1145/3172944.3173007", "10.5555/1795555", "10.1109/mcg.2005.102", "10.1145/381641.381653", "10.1162/153244301753344614", "10.1111/cgf.14034", "10.1111/cgf.13198", "10.1017/cbo9780511519857", "10.1007/s10462-016-9475-9", "10.1075/ssol.2.2.07bor", "10.1007/978-1-4614-3223-4\\_3", "10.1109/infvis.2003.1249025", "10.1007/978-94-007-6094-313", "10.1145/2858036.2858387", "10.1109/tvcg.2007.70528", "10.1109/tvcg.2017.2674958", "10.1147/sj.454.0801", "10.1109/tvcg.2013.119", "10.1145/3173574.3173711", "10.1016/j.erss.2017.06.034", "10.1109/visual.2019.8933695", "10.1007/s11665-016-2173-6", "10.1016/0377-0427(87)90125-7", "10.2307/3601125", "10.1016/b978-0-444-88738-2.50018-x", "10.1109/mcg.2006.70", "10.1109/tvcg.2018.2865145", "10.1017/s1351324997001502", "10.1109/tvcg.2010.179", "10.1214/aos/1176344552", "10.1109/mcg.2009.22", "10.1007/978-3-319-26633-6\\_13", "10.1080/10447318.2014.905422", "10.1016/j.visinf.2019.03.004", "10.1057/palgrave.ivs.9500074", "10.1007/978-1-4614-3223-4"], "wos": 1, "children": [], "len": 1}], "len": 5}, {"doi": "10.1109/tvcg.2020.3028984", "title": "Bayesian-Assisted Inference from Visualized Data", "year": "2020", "conferenceName": "InfoVis", "authors": "Yea-Seul Kim;Paula Kayongo;Madeleine Grunde-McLaughlin;Jessica Hullman", "citationCount": "0", "affiliation": "Kim, YS (Corresponding Author), Univ Washington, Seattle, WA 98195 USA. Kim, Yea-Seul, Univ Washington, Seattle, WA 98195 USA. Kayongo, Paula; Hullman, Jessica, Northwestern Univ, Evanston, IL 60208 USA. Grunde-McLaughlin, Madeleine, Univ Penn, Philadelphia, PA 19104 USA.", "countries": "USA", "abstract": "A Bayesian view of data interpretation suggests that a visualization user should update their existing beliefs about a parameter's value in accordance with the amount of information about the parameter value captured by the new observations. Extending recent work applying Bayesian models to understand and evaluate belief updating from visualizations, we show how the predictions of Bayesian inference can be used to guide more rational belief updating. We design a Bayesian inference-assisted uncertainty analogy that numerically relates uncertainty in observed data to the user's subjective uncertainty, and a posterior visualization that prescribes how a user should update their beliefs given their prior beliefs and the observed data. In a pre-registered experiment on 4,800 people, we find that when a newly observed data sample is relatively small (N=158), both techniques reliably improve people's Bayesian updating on average compared to the current best practice of visualizing uncertainty in the observed data. For large data samples (N=5208), where people's updated beliefs tend to deviate more strongly from the prescriptions of a Bayesian model, we find evidence that the effectiveness of the two forms of Bayesian assistance may depend on people's proclivity toward trusting the source of the data. We discuss how our results provide insight into individual processes of belief updating and subjective uncertainty, and how understanding these aspects of interpretation paves the way for more sophisticated interactive visualizations for analysis and communication.", "keywords": "Bayesian cognition,Belief updating,Uncertainty visualization,Adaptive visualization", "link": "http://dx.doi.org/10.1109/TVCG.2020.3028984", "refList": ["10.1080/19336896.2018.1471922", "10.3758/bf03196976", "10.1037/1089-2680.2.2.175", "10.1016/j.jclinepi.2009.06.003", "10.1109/tvcg.2014.2346979", "10.1109/tvcg.2018.2864909", "10.1145/3173574.3173718", "10.1006/cogp.1998.0702", "10.1086/209424", "10.1109/tvcg.2012.199", "10.7717/peerj-cs.55", "10.1145/2993901.2993919", "10.1371/journal.pone.0142444", "10.1080/13875868.2015.1137577", "10.1037/1076-898x.3.1.3", "10.1109/tvcg.2019.2934287", "10.1109/tvcg.2017.2743898", "10.1145/3025453.3025592", "10.1057/ivs.2008.13", "10.1214/ss/1015346320", "10.1016/0749-5978(92)90055-c", "10.1080/13546780542000005", "10.1109/tvcg.2015.2467671", "10.1109/tvcg.2016.2607204", "10.3758/s13423-016-1174-7", "10.1016/j.cag.2014.03.002", "10.1198/016214505000000105", "10.1109/tvcg.2012.279", "10.1111/1467-8624.00232", "10.1111/j.1467-9280.2006.01780.x", "10.2307/2682899", "10.1080/00335557743000053", "10.1109/tvcg.2010.177", "10.1057/ivs.2008.28", "10.1109/tvcg.2018.2864889", "10.1109/tvcg.2013.153", "10.1109/tvcg.2015.2467758", "10.1145/2858036.2858558", "10.1287/mnsc.46.8.1100.12023", "10.1016/j.tics.2003.08.012", "10.1111/j.1467-8659.2009.01694.x"], "wos": 1, "children": [], "len": 1}, {"doi": "10.1109/tvcg.2020.3030426", "title": "Introducing Layers of Meaning (LoM): A Framework to Reduce Semantic Distance of Visualization In Humanistic Research", "year": "2020", "conferenceName": "InfoVis", "authors": "Houda Lamqaddam;Andrew Vande Moere;Vero Vanden Abeele;Koenraad Brosens;Katrien Verbert", "citationCount": "0", "affiliation": "Lamqaddam, H (Corresponding Author), Katholieke Univ Leuven, Leuven, Belgium. Lamqaddam, Houda; Vande Moere, Andrew; Vanden Abeele, Vero; Brosens, Koenraad; Verbert, Katrien, Katholieke Univ Leuven, Leuven, Belgium.", "countries": "Belgium", "abstract": "Information visualization (infovis) is a powerful tool for exploring rich datasets. Within humanistic research, rich qualitative data and domain culture make traditional infovis approaches appear reductive and disconnected, leading to low adoption. In this paper, we use a multi-step approach to scrutinize the relationship between infovis and the humanities and suggest new directions for it. We first look into infovis from the humanistic perspective by exploring the humanistic literature around infovis. We validate and expand those findings though a co-design workshop with humanist and infovis experts. Then, we translate our findings into guidelines for designers and conduct a design critique exercise to explore their effect on the perception of humanist researchers. Based on these steps, we introduce Layers of Meaning, a framework to reduce the semantic distance between humanist researchers and visualizations of their research material, by grounding infovis tools in time and space, physicality, terminology, nuance, and provenance.", "keywords": "Infovis,Humanities,Digital Humanities", "link": "http://dx.doi.org/10.1109/TVCG.2020.3030426", "refList": ["10.1177/1473871611416549", "10.1109/tvcg.2014.2346979", "10.1016/j.jesp.2013.03.013", "10.1109/tvcg.2018.2864909", "10.1145/2858036.2858465", "10.1145/1553374.1553527", "10.1037/1076-898x.14.1.36", "10.1109/tvcg.2011.185", "10.2200/s00371ed1v01y201107aim013", "10.1145/3025453.3025912", "10.3758/s13423-018-1525-7", "10.1109/tvcg.2017.2743898", "10.1037/a0029146", "10.1109/infvis.2005.1532136", "10.1109/tvcg.2015.2467671", "10.1109/tvcg.2018.2864907", "10.3758/s13423-016-1174-7", "10.1136/bmj.312.7047.1654", "10.2307/2288400", "10.1085/jgp.7.2.235", "10.3758/s13423-017-1323-7", "10.1109/tvcg.2018.2810918", "10.1080/13803390500205718", "10.1016/s0364-0213(87)80026-5", "10.1109/tvcg.2018.2864884", "10.2307/1419876", "10.1109/tvcg.2010.161", "10.5281/zenodo", "10.1109/tvcg.2005.63", "10.1177/001872089203400503", "10.1126/science.220.4598.671", "10.2307/2289447", "10.1006/jesp.1996.0009", "10.1007/s10898-012-9951-y", "10.3758/s13423-017-1343-3", "10.1109/tvcg.2007.70515", "10.21105/joss.01686", "10.18637/jss.v080.i01", "10.1111/j.1467-8659.2009.01694.x", "10.1145/2702123.2702608"], "wos": 1, "children": [], "len": 1}, {"doi": "10.1109/tvcg.2020.3030448", "title": "Retrieve-Then-Adapt: Example-based Automatic Generation for Proportion-related Infographics", "year": "2020", "conferenceName": "InfoVis", "authors": "Chunyao Qian;Shizhao Sun;Weiwei Cui;Jian-Guang Lou;Haidong Zhang;Dongmei Zhang", "citationCount": "0", "affiliation": "Qian, CY (Corresponding Author), Peking Univ, Beijing, Peoples R China. Qian, Chunyao; Sun, Shizhao; Cui, Weiwei; Lou, Jian-Guang; Zhang, Haidong; Zhang, Dongmei, Microsoft Res Asia, Beijing, Peoples R China. Qian, Chunyao, Peking Univ, Beijing, Peoples R China.", "countries": "China", "abstract": "Infographic is a data visualization technique which combines graphic and textual descriptions in an aesthetic and effective manner. Creating infographics is a difficult and time-consuming process which often requires significant attempts and adjustments even for experienced designers, not to mention novice users with limited design expertise. Recently, a few approaches have been proposed to automate the creation process by applying predefined blueprints to user information. However, predefined blueprints are often hard to create, hence limited in volume and diversity. In contrast, good infogrpahics have been created by professionals and accumulated on the Internet rapidly. These online examples often represent a wide variety of design styles, and serve as exemplars or inspiration to people who like to create their own infographics. Based on these observations, we propose to generate infographics by automatically imitating examples. We present a two-stage approach, namely retrieve-then-adapt. In the retrieval stage, we index online examples by their visual elements. For a given user information, we transform it to a concrete query by sampling from a learned distribution about visual elements, and then find appropriate examples in our example library based on the similarity between example indexes and the query. For a retrieved example, we generate an initial drafts by replacing its content with user information. However, in many cases, user information cannot be perfectly fitted to retrieved examples. Therefore, we further introduce an adaption stage. Specifically, we propose a MCMC-like approach and leverage recursive neural networks to help adjust the initial draft and improve its visual appearance iteratively, until a satisfactory result is obtained. We implement our approach on widely-used proportion-related infographics, and demonstrate its effectiveness by sample results and expert reviews.", "keywords": "Infographics,automatic visualization", "link": "http://dx.doi.org/10.1109/TVCG.2020.3030448", "refList": ["10.1001/archpediatrics.2011.97", "10.1016/j.infsof.2007.02.015", "10.1177/1745691614528520", "10.1177/0165025413515169", "10.1145/2702123.2702347", "10.1109/tvcg.2016.2598918", "10.1145/3290605.3300447", "10.1016/s0020-7373(86)80019-0", "10.1038/nrn3475", "10.1007/978-3-319-26633-6\\_6", "10.1098/rsif.2006.0134", "10.1037/0033-295x.101.1.80", "10.1109/tvcg.2017.2743898", "10.1198/000313001317098149", "10.1007/978-3-319-67687-6\\_10", "10.1145/3290605.3300295", "10.1109/tvcg.2013.124", "10.1016/b978-0-12-805390-4.00003-0", "10.1111/j.1467-8659.2011.01938.x", "10.18637/jss.v067.i01", "10.1145/3173574.3174216", "10.1037/0033-2909.86.3.638", "10.1002/ejsp.2023", "10.1109/tvcg.2015.2467954", "10.1109/tvcg.2005.53", "10.3758/s13428-013-0424-0", "10.1145/3173574.3173715", "10.1016/b978-0-12-179060-8.50012-8", "10.1109/visual.2019.8933695", "10.3758/bf03203630", "10.1002/bimj.200810425", "10.1207/s15328007sem0904\\_8", "10.1109/pacificvis.2012.6183556", "10.1016/j.apergo.2004.01.002", "10.1109/tvcg.2014.2346298", "10.1109/beliv.2018.8634392", "10.1145/2858036.2858498", "10.3758/bf03193146", "10.2307/2685373", "10.1016/b978-0-12-179060-8.50007-4", "10.1145/1735223.1735255"], "wos": 1, "children": [], "len": 1}], "len": 63}, "index": 634, "embedding": [-0.5009088516235352, 3.571903944015503, -1.059349536895752, -2.3949873447418213, -0.6495316028594971, 0.16650904715061188, -0.7143645286560059, 2.2604098320007324, -0.4013857841491699, 1.3867665529251099, 0.3608550727367401, 1.2699097394943237, -0.1336275339126587, 2.9760665893554688, 6.752293586730957, 6.24453592300415, 0.9767427444458008, 1.4728282690048218, -0.13446463644504547, 5.047274589538574, -0.06630208343267441, 4.512956142425537, 4.583605766296387, 5.230916500091553, -2.532860279083252, 4.750199794769287, -0.5399249196052551, 3.5989458560943604, 2.6455209255218506, 2.793731927871704, 2.522054433822632, 4.817867279052734], "projection": [0.4773448407649994, 11.01555347442627], "size": 32, "height": 4, "width": 13}