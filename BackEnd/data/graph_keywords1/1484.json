{"data": {"doi": "10.1111/cgf.13668", "year": "2019", "title": "Optimizing Stepwise Animation in Dynamic Set Diagrams", "conferenceName": "EuroVis", "authors": "Kazuyo Mizuno;Hsiang{-}Yun Wu;Shigeo Takahashi;Takeo Igarashi", "citationCount": "1", "affiliation": "Mizuno, K (Corresponding Author), Yahoo Japan Corp, Tokyo, Japan.\nMizuno, Kazuyo, Yahoo Japan Corp, Tokyo, Japan.\nWu, Hsiang-Yun, TU Wien, Vienna, Austria.\nTakahashi, Shigeo, Univ Aizu, Aizu Wakamatsu, Fukushima, Japan.\nIgarashi, Takeo, Univ Tokyo, Tokyo, Japan.", "countries": "Japan;Austria", "abstract": "A set diagram represents the membership relation among data elements. It is often visualized as secondary information on top of primary information, such as the spatial positions of elements on maps and charts. Visualizing the temporal evolution of such set diagrams as well as their primary features is quite important; however, conventional approaches have only focused on the temporal behavior of the primary features and do not provide an effective means to highlight notable transitions within the set relationships. This paper presents an approach for generating a stepwise animation between set diagrams by decomposing the entire transition into atomic changes associated with individual data elements. The key idea behind our approach is to optimize the ordering of the atomic changes such that the synthesized animation minimizes unwanted set occlusions by considering their depth ordering and reduces the gaze shift between two consecutive stepwise changes. Experimental results and a user study demonstrate that the proposed approach effectively facilitates the visual identification of the detailed transitions inherent in dynamic set diagrams.", "keywords": "", "link": "https://doi.org/10.1111/cgf.13668", "refList": ["10.1145/2093973.2094010", "10.1109/infvis.2004.18", "10.2312/eurovisstar.20151110", "10.1109/tvcg.2013.76", "10.2312/eurovisstar.20141170", "10.1016/j.jvlc.2013.08.006", "10.1186/1471-2105-15-201", "10.1109/iv.2008.78", "10.1002/acp.2887", "10.1016/j.socnet.2011.06.002", "10.1186/s12859-015-0611-3", "10.1109/vlhcc.2004.21", "10.1111/j.1467-8659.2012.03080.x", "10.1109/pacificvis.2009.4906835", "10.1007/3-540-44541-2\\_", "10.1109/tvcg.2013.254", "10.1109/tvcg.2010.210", "10.1016/j.ins.2015.04.017", "10.1109/tvcg.2009.122", "10.1109/tvcg.2011.288", "10.1137/1.9781611972801.37", "10.1007/3-540-45848-4\\_18", "10.1109/tvcg.2013.149", "10.2312/pe/eurovast/eurova11/041-044", "10.1109/tvcg.2010.78", "10.1007/978-3-319-09620-9\\_8", "10.1007/3-540-44541-2\\_37", "10.1109/tvcg.2011.186", "10.1016/j.ijhcs.2013.08.004"], "wos": 1, "children": [{"doi": "10.1109/tvcg.2020.3030398", "title": "Multiscale Snapshots: Visual Analysis of Temporal Summaries in Dynamic Graphs", "year": "2020", "conferenceName": "VAST", "authors": "Eren Cakmak;Udo Schlegel;Dominik J\u00e4ckle;Daniel A. Keim;Tobias Schreck", "citationCount": "0", "affiliation": "Cakmak, E (Corresponding Author), Univ Konstanz, Constance, Germany. Cakmak, Eren; Schlegel, Udo; Keim, Daniel, Univ Konstanz, Constance, Germany. Schreck, Tobias, Graz Univ Technol, Graz, Austria.", "countries": "Germany;Austria", "abstract": "The overview-driven visual analysis of large-scale dynamic graphs poses a major challenge. We propose Multiscale Snapshots, a visual analytics approach to analyze temporal summaries of dynamic graphs at multiple temporal scales. First, we recursively generate temporal summaries to abstract overlapping sequences of graphs into compact snapshots. Second, we apply graph embeddings to the snapshots to learn low-dimensional representations of each sequence of graphs to speed up specific analytical tasks (e.g., similarity search). Third, we visualize the evolving data from a coarse to fine-granular snapshots to semi-automatically analyze temporal states, trends, and outliers. The approach enables us to discover similar temporal summaries (e.g., reoccurring states), reduces the temporal data to speed up automatic analysis, and to explore both structural and temporal properties of a dynamic graph. We demonstrate the usefulness of our approach by a quantitative evaluation and the application to a real-world dataset.", "keywords": "Dynamic Graph,Dynamic Network,Unsupervised Graph Learning,Graph Embedding,Multiscale Visualization", "link": "http://dx.doi.org/10.1109/TVCG.2020.3030398", "refList": ["10.1007/s00442-002-1137-8", "10.1111/cgf.13668", "10.1086/282697", "10.1109/tvcg.2002.1044518", "10.1890/0012-9658(2000)081{[}0008:ppbatp]2.0.co", "2", "10.1101/2020.04.08.032524", "10.1111/j.1461-0248.2009.01391.x", "10.1016/0040-5809(80)90016-7", "10.1109/tvcg.2009.181", "10.1145/2669557.2669559", "10.1109/vl.1996.545307", "10.1109/tvcg.2013.254", "10.1109/tvcg.2019.2934251", "10.1073/pnas.93.6.2608", "10.2312/cgvc", "10.1080/14786440109462720", "10.1111/1440-1703.12057", "10.2307/1940591", "10.1037/h0071325", "10.1073/pnas.1215506110", "10.1126/science.283.5407.1528", "10.1109/tvcg.2013.198", "10.7717/peerj.824", "10.1126/science.290.5500.2319", "10.1038/nature06512", "10.1109/2945.981847", "10.1109/tvcg.2006.192", "10.1098/rsta.1994.0106", "10.1126/science.1227079", "10.1109/tvcg.2015.2468078", "10.1098/rspb.2015.2258", "10.2312/cgvc.20181210", "10.1177/1473871617692841", "10.1007/s11284-017-1469-9", "10.1109/wi.2006.118", "10.1038/nature25504", "10.1109/tvcg.2017.2745258", "10.1109/tvcg.2013.109", "10.1126/science.290.5500.2323", "10.1109/iv.2013.8", "10.1038/344734a0", "10.1890/0012-9658(1998)079{[}0201:acoams]2.0.co", "2", "10.1109/tvcg.2018.2846735", "10.1038/srep14750", "10.1111/cgf.12396", "10.1007/bf02289565", "10.1890/07-1246.1", "10.1046/j.1461-0248.2002.00312.x", "10.1145/3139295.3139303", "10.1177/1473871613487087"], "wos": 1, "children": [], "len": 1}, {"doi": "10.1111/cgf.13988", "year": "2020", "title": "Set Streams: Visual Exploration of Dynamic Overlapping Sets", "conferenceName": "EuroVis", "authors": "Shivam Agarwal;Fabian Beck", "citationCount": "0", "affiliation": "Agarwal, S (Corresponding Author), Univ Duisburg Essen, Paluno, Essen, Germany.\nAgarwal, Shivam; Beck, Fabian, Univ Duisburg Essen, Paluno, Essen, Germany.", "countries": "Germany", "abstract": "In many applications, membership of set elements changes over time. Since each element can be present in multiple sets, the sets also overlap. As a result, it becomes challenging to visualize the temporal change in set membership of elements across several timesteps while showing individual set intersections. We propose Set Streams, a visualization technique that represents changing set structures on a timeline as branching and merging streams. The streams encode the changing membership of elements with set intersections. A query-based selection mechanism supports a flexible comparison of selected groups of elements across the temporal evolution. The main timeline view is complemented with additional panels to provide details about the elements. While the proposed visualization is an application-independent visualization technique for dynamic sets, we demonstrate its effectiveness and applicability through three diverse application examples and expert feedback.", "keywords": "", "link": "https://doi.org/10.1111/cgf.13988", "refList": ["10.1111/cgf.12722", "10.1109/tvcg.2016.2615308", "10.1109/vast.2012.6400553", "10.1109/tvcg.2013.76", "10.1111/cgf.13668", "10.1177/1473871615605347", "10.1111/cgf.12791", "10.1111/j.1467-8659.2008.01214.x", "10.1109/tvcg.2019.2933196.2", "10.1006/ijhc.2002.1017", "10.1109/vlhcc.2012.6344514", "10.1371/journal.pone.0008694", "10.1006/ijhc.1017", "10.1109/tvcg.2009.122", "10.1109/tvcg.2014.2346248", "10.1109/tvcg.2015.2507595", "10.1111/cgf.12512", "10.1109/vissoft.2015.7332421", "10.1057/ivs.2009.29", "10.1109/tsmc.1981.4308636", "10.1109/tvcg.2019.2933196"], "wos": 1, "children": [{"doi": "10.1109/tvcg.2020.3030461", "title": "CNNPruner: Pruning Convolutional Neural Networks with Visual Analytics", "year": "2020", "conferenceName": "VAST", "authors": "Guan Li;Junpeng Wang;Han-Wei Shen;Kaixin Chen;Guihua Shan;Zhonghua Lu", "citationCount": "0", "affiliation": "Shan, GH (Corresponding Author), Chinese Acad Sci, Comp Network Informat Ctr, Beijing, Peoples R China. Li, Guan; Chen, Kaixin; Shan, Guihua; Lu, Zhonghua, Chinese Acad Sci, Comp Network Informat Ctr, Beijing, Peoples R China. Li, Guan; Chen, Kaixin; Shan, Guihua; Lu, Zhonghua, Univ Chinese Acad Sci, Beijing, Peoples R China. Wang, Junpeng, Visa Res, Beijing, Peoples R China. Shen, Han-Wei, Ohio State Univ, Columbus, OH 43210 USA.", "countries": "USA;China", "abstract": "Convolutional neural networks (CNNs) have demonstrated extraordinarily good performance in many computer vision tasks. The increasing size of CNN models, however, prevents them from being widely deployed to devices with limited computational resources, e.g., mobile/embedded devices. The emerging topic of model pruning strives to address this problem by removing less important neurons and fine-tuning the pruned networks to minimize the accuracy loss. Nevertheless, existing automated pruning solutions often rely on a numerical threshold of the pruning criteria, lacking the flexibility to optimally balance the trade-off between efficiency and accuracy. Moreover, the complicated interplay between the stages of neuron pruning and model fine-tuning makes this process opaque, and therefore becomes difficult to optimize. In this paper, we address these challenges through a visual analytics approach, named CNNPruner. It considers the importance of convolutional filters through both instability and sensitivity, and allows users to interactively create pruning plans according to a desired goal on model size or accuracy. Also, CNNPruner integrates state-of-the-art filter visualization techniques to help users understand the roles that different filters played and refine their pruning plans. Through comprehensive case studies on CNNs with real-world sizes, we validate the effectiveness of CNNPruner.", "keywords": "visualization,model pruning,convolutional neural network,explainable artificial intelligence", "link": "http://dx.doi.org/10.1109/TVCG.2020.3030461", "refList": ["10.1109/tvcg.2015.2509990", "10.1145/2468356.2468434", "10.1007/978-3-642-18469-7\\_22", "10.1007/bf02603120", "10.1145/2702123.2702419", "10.1109/pacificvis.2018.00025", "10.1145/345513.345271", "10.1109/32.221135", "10.1007/s10654-016-0149-3", "10.1109/tvcg.2015.2392771", "10.1109/tvcg.2018.2865076", "10.1109/tvcg.2013.89", "10.1109/infvis.2005.1532152", "10.1007/3-540-49381-6\\_9", "10.1109/gl0bec0m38437.2019.9014197", "10.2337/dc18-s006", "10.11234/gi1990.5.90", "10.1007/bf01187020", "10.1016/j.jbi.2015.06.020", "10.1109/pacificvis.2013.6596125", "10.1109/tvcg.2015.2468151", "10.1109/tvcg.2013.124", "10.1111/cgf.13988", "10.1109/pacificvis.2011.5742371", "10.1109/tvcg.2016.2539960", "10.1109/tvcg.2013.200", "10.1109/tsmc.1977.4309760", "10.1109/tvcg.2012.225", "10.1109/tvcg.2015.2465151", "10.1186/1753-6561-8-s2-s8", "10.1109/tvcg.2018.2864899", "10.1109/tits.2015.2436897", "10.1109/tvcg.2013.196", "10.1214/ss/1177013815", "10.1111/j.2517-6161.1995.tb02031.x", "10.2144/00286ir01", "10.1109/tsmc.1981.4308636", "10.1145/3025453.3026024", "10.2337/dc14-2919", "10.2307/2683905", "10.3238/arztebl.2009.0335", "10.1109/vast.2011.6102453"], "wos": 1, "children": [], "len": 1}], "len": 3}], "len": 7}, "index": 1484, "embedding": [1.018936276435852, 0.6566621661186218, -1.0741424560546875, 0.5243445038795471, -0.6870212554931641, 0.16650904715061188, -0.6826844215393066, 0.9100527763366699, -0.40999409556388855, 0.2790091633796692, 0.21331627666950226, -0.2192074954509735, -0.12592144310474396, 0.8696279525756836, -0.7502163648605347, 1.9918469190597534, -0.11131151020526886, 1.6164227724075317, -0.6852008700370789, 2.6481873989105225, -0.06630208343267441, 1.1713645458221436, 0.4304448366165161, 1.2530080080032349, -2.10050892829895, 1.517311692237854, -0.5670700073242188, 0.010599659755825996, 1.2406350374221802, -1.2933595180511475, -0.3217572569847107, 0.5654175877571106], "projection": [-0.9209251999855042, 7.748393535614014], "size": 4, "height": 3, "width": 2}