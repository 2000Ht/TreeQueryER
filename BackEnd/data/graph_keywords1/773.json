{"data": {"doi": "10.1109/tvcg.2018.2864847", "title": "Culling for Extreme-Scale Segmentation Volumes: A Hybrid Deterministic and Probabilistic Approach", "year": "2018", "conferenceName": "SciVis", "authors": "Johanna Beyer;Haneen Mohammed;Marco Agus;Ali K. Al-Awami;Hanspeter Pfister;Markus Hadwiger", "citationCount": "2", "affiliation": "Beyer, J (Corresponding Author), Harvard Univ, Cambridge, MA 02138 USA. Beyer, Johanna; Mohammed, Haneen; Pfister, Hanspeter, Harvard Univ, Cambridge, MA 02138 USA. Mohammed, Haneen; Agus, Marco; Hadwiger, Markus, KAUST, Thuwal, Saudi Arabia. Al-Awami, Ali K., KAUST, Dhahran, Saudi Arabia. Al-Awami, Ali K., Saudi Aramco, Dhahran, Saudi Arabia.", "countries": "Arabia;USA", "abstract": "With the rapid increase in raw volume data sizes, such as terabyte-sized microscopy volumes, the corresponding segmentation label volumes have become extremely large as well. We focus on integer label data, whose efficient representation in memory, as well as fast random data access, pose an even greater challenge than the raw image data. Often, it is crucial to be able to rapidly identify which segments are located where, whether for empty space skipping for fast rendering, or for spatial proximity queries. We refer to this process as<i>culling</i>. In order to enable efficient culling of millions of labeled segments, we present a novel hybrid approach that combines deterministic and probabilistic representations of label data in a data-adaptive hierarchical data structure that we call the label list tree. In each node, we adaptively encode label data using either a probabilistic constant-time access representation for fast conservative culling, or a deterministic logarithmic-time access representation for exact queries. We choose the best data structures for representing the labels of each spatial region while building the label list tree. At run time, we further employ a novel<i>query-adaptive</i>culling strategy. While filtering a query down the tree, we prune it successively, and in each node adaptively select the representation that is best suited for evaluating the pruned query, depending on its size. We show an analysis of the efficiency of our approach with several large data sets from connectomics, including a brain scan with more than 13 million labeled segments, and compare our method to conventional culling approaches. Our approach achieves significant reductions in storage size as well as faster query times.", "keywords": "Hierarchical Culling,Segmented Volume Data,Bloom Filter,Volume Rendering,Spatial Queries", "link": "http://dx.doi.org/10.1109/TVCG.2018.2864847", "refList": ["10.1145/362686.362692", "10.1109/tvcg.2005.59", "10.1364/boe.2.002888", "10.1109/tvcg.2009.121", "10.1007/pl00013406", "10.1111/j.1467-8659.2005.00855.x", "10.1145/2674005.2674994", "10.1002/spe.2402", "10.1109/visual.1999.809908", "10.1109/visual.1995.480792", "10.1016/j.cell.2015.06.054", "10.1109/tvcg.2012.240", "10.1109/visual.1992.235231", "10.1002/spe.2325", "10.1109/visual.1990.146377", "10.1111/cgf.12605", "10.1002/spe.2560", "10.1007/s00371-008-0261-9", "10.1145/78973.78977", "10.1109/90.851975", "10.1109/visual.2003.1250386", "10.1109/tvcg.2013.142", "10.1007/978-3-319-66182-7\\_89", "10.1145/1507149.1507152", "10.1145/263407.263545", "10.1109/visual.2003.1250384", "10.1109/pacificvis.2011.5742370", "10.1016/j.media.2015.02.001", "10.1109/mcg.2013.55", "10.1109/tvcg.2017.2744238", "10.1109/visual.2001.964521"], "wos": 1, "children": [{"doi": "10.1111/cgf.13700", "year": "2019", "title": "Interactive Volumetric Visual Analysis of Glycogen-derived Energy Absorption in Nanometric Brain Structures", "conferenceName": "EuroVis", "authors": "Marco Agus;Corrado Cal{\\`{\\i}};Ali K. Al{-}Awami;Enrico Gobbetti;Pierre J. Magistretti;Markus Hadwiger", "citationCount": "3", "affiliation": "Agus, M (Corresponding Author), KAUST, Thuwal, Saudi Arabia.\nAgus, M (Corresponding Author), VCC, Thuwal, Saudi Arabia.\nAgus, M (Corresponding Author), Ctr Adv Studies Res \\& Dev Sardinia CRS4, Visual Comp Grp, Cagliari, Italy.\nAgus, M.; Cali, C.; Al-Awami, A.; Magistretti, P.; Hadwiger, M., KAUST, Thuwal, Saudi Arabia.\nAgus, M.; Al-Awami, A.; Hadwiger, M., VCC, Thuwal, Saudi Arabia.\nCali, C.; Magistretti, P., BESE, Thuwal, Saudi Arabia.\nAgus, M.; Gobbetti, E., Ctr Adv Studies Res \\& Dev Sardinia CRS4, Visual Comp Grp, Cagliari, Italy.\nAl-Awami, A., Saudi Aramco \\& EXPEC Comp Ctr, Dharhan, Saudi Arabia.", "countries": "Italy;Arabia", "abstract": "Digital acquisition and processing techniques are changing the way neuroscience investigation is carried out. Emerging applications range from statistical analysis on image stacks to complex connectomics visual analysis tools targeted to develop and test hypotheses of brain development and activity. In this work, we focus on neuroenergetics, a field where neuroscientists analyze nanoscale brain morphology and relate energy consumption to glucose storage in form of glycogen granules. In order to facilitate the understanding of neuroenergetic mechanisms, we propose a novel customized pipeline for the visual analysis of nanometric-level reconstructions based on electron microscopy image data. Our framework supports analysis tasks by combining i) a scalable volume visualization architecture able to selectively render image stacks and corresponding labelled data, ii) a method for highlighting distance-based energy absorption probabilities in form of glow maps, and iii) a hybrid connectivitybased and absorption-based interactive layout representation able to support queries for selective analysis of areas of interest and potential activity within the segmented datasets. This working pipeline is currently used in a variety of studies in the neuroenergetics domain. Here, we discuss a test case in which the framework was successfully used by domain scientists for the analysis of aging effects on glycogen metabolism, extracting knowledge from a series of nanoscale brain stacks of rodents somatosensory cortex.", "keywords": "", "link": "https://doi.org/10.1111/cgf.13700", "refList": ["10.1371/journal.pone.0038011", "10.1016/j.coisb.2017.07.011", "10.1145/234535.234538", "10.1109/tvcg.2018.2864847", "10.2312/conf/eg2012/stars/053-074", "10.3389/fnins.2018.00664", "10.1109/tpami.2018.2835450", "10.1109/tvcg.2014.2346312", "10.1109/tvcg.2009.121", "10.1002/glia.23020", "10.1117/1.jbo.18.5.050902", "10.1111/cgf.12927", "10.1038/nn.3837", "10.1109/isbi.2011.5872394", "10.3868/j.issn.2096-0689.2017.04.004", "10.1111/cgf.12792", "10.1016/j.neuroscience.2012.09.077", "10.1109/tvcg.2012.240", "10.1523/jneurosci.4825-12.2013", "10.1002/cne.23852", "10.2312/vcbm.20151213", "10.1111/cgf.12605", "10.1016/j.cag.2018.04.007", "10.1038/s41592-018-0049-4", "10.1007/s00371-015-1151-6", "10.1109/tvcg.2018.2864852", "10.1109/ic3d.2016.7823463", "10.3389/fncel.2019.00082", "10.1111/boc.201600024", "10.2312/vg/vg10/053-060", "10.1109/tvcg.2013.142", "10.1371/journal.pone.0198131", "10.1111/cgf.12280", "10.1038/nature22356", "10.1109/tvcg.2015.2467441", "10.1016/j.neuron.2015.03.035", "10.2312/vcbm.20161276", "10.1016/j.neuroscience.2007.07.014", "10.1109/tvcg.2017.2744238", "10.1002/glia.23250", "10.3389/fncel.2018.00308", "10.1016/j.cell.2018.06.019", "10.1109/tvcg.2017.2744278", "10.1109/biovis.2013.6664349", "10.1179/000870403235002042"], "wos": 1, "children": [], "len": 1}], "len": 3}, "index": 773, "embedding": [0.3764514923095703, -0.30501702427864075, -1.0404996871948242, 1.2400219440460205, 0.39235222339630127, 0.16650904715061188, 0.7351260781288147, 0.42598438262939453, 0.7971413731575012, 0.7396745085716248, 0.38831454515457153, -0.4391750395298004, -0.1686236411333084, -0.21182793378829956, -0.99098140001297, -0.10445459187030792, -0.24749651551246643, 0.06877747178077698, -0.7571966052055359, 1.4726380109786987, -0.06630208343267441, -0.11106475442647934, -0.142256498336792, 0.09129331260919571, 0.2138049155473709, 1.001713514328003, -0.5834015607833862, -0.21145495772361755, 0.5009344816207886, -0.8570042252540588, -0.8281638026237488, -0.4927598834037781], "projection": [-1.4248489141464233, 6.79484748840332], "size": 2, "height": 2, "width": 1}