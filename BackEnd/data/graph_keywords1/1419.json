{"data": {"doi": "10.1111/cgf.13201", "year": "2017", "title": "Illustrative Visualization of Mesoscale Ocean Eddies", "conferenceName": "EuroVis", "authors": "Li Liu;Deborah Silver;Karen G. Bemis;D. Kang;E. Curchitser", "citationCount": "10", "affiliation": "Liu, L (Corresponding Author), Rutgers State Univ, Dept Elect \\& Comp Engn, Piscataway, NJ 08855 USA.\nLiu, L.; Silver, D., Rutgers State Univ, Dept Elect \\& Comp Engn, Piscataway, NJ 08855 USA.\nBemis, K., Rutgers State Univ, Dept Marine \\& Coastal Sci, Piscataway, NJ USA.\nKang, D.; Curchitser, E., Rutgers State Univ, Dept Environm Sci, Piscataway, NJ USA.", "countries": "USA", "abstract": "Feature-based time-varying volume visualization is combined with illustrative visualization to tell the story of how mesoscale ocean eddies form in the Gulf Stream and transport heat and nutrients across the ocean basin. The internal structure of these three-dimensional eddies and the kinematics with which they move are critical to a full understanding of ocean eddies. In this work, we apply a feature-based method to track instances of ocean eddies through the time steps of a high-resolution multi-decadal regional ocean model and generate a series of eddy paths which reflect the life cycle of individual eddy instances. Based on the computed metadata, several important geometric and physical properties of eddy are computed. Illustrative visualization techniques, including visual effectiveness enhancement, focus+context, and smart visibility, are combined with the extracted volume features to explore eddy characteristics at different levels. An evaluation by domain experts indicates that combining our feature-based techniques with illustrative visualization techniques provides an insight into the role eddies play in ocean circulation. The domain experts expressed a preference for our methods over existing tools.", "keywords": "", "link": "https://doi.org/10.1111/cgf.13201", "refList": ["10.1109/tvcg.2008.105", "10.1016/0167-2789(91)90088-q", "10.1109/38.920623", "10.1118/1.596911", "10.1109/tvcg.2015.2467411", "10.1029/2006jc003952", "10.1002/jgrc.20318", "10.1109/tvcg.2005.62", "10.1007/3-540-30790-7\\_18", "10.1109/2.299407", "10.1029/2001jc001047", "10.1109/visual.1999.809910", "10.1109/tvcg.2007.70599", "10.1109/tvcg.2009.69", "10.1007/pl00013399", "10.1109/2945.597796", "10.1006/jagm.1995.1021", "10.1109/tvcg.2012.171", "10.1109/ldav.2012.6378982", "10.1002/jgrc.20155", "10.1111/j.1467-8659.2011.01948.x", "10.1109/pacificvis.2009.4906833", "10.1109/2945.942693", "10.1109/tvcg.2010.166", "10.1111/j.1467-8659.2008.01235.x", "10.1109/tvcg.2013.117", "10.1109/visual.2002.1183822", "10.1029/2011jc007134", "10.1109/tvcg.2002.1021580", "10.2312/compaesth/compaesth05/209-216", "10.1109/mcg.2012.24", "10.1016/0011-7471(70)90059-8", "10.1016/j.procs.2016.05.491"], "wos": 1, "children": [{"doi": "10.1109/tvcg.2019.2934806", "title": "GenerativeMap: Visualization and Exploration of Dynamic Density Maps via Generative Learning Model", "year": "2019", "conferenceName": "InfoVis", "authors": "Chen Chen;Changbo Wang;Xue Bai;Peiying Zhang;Chenhui Li", "citationCount": "0", "affiliation": "Li, CH (Corresponding Author), East China Normal Univ, Sch Comp Sci \\& Technol, Shanghai, Peoples R China. Chen, Chen; Wang, Changbo; Bai, Xue; Zhang, Peiying; Li, Chenhui, East China Normal Univ, Sch Comp Sci \\& Technol, Shanghai, Peoples R China.", "countries": "China", "abstract": "The density map is widely used for data sampling, time-varying detection, ensemble representation, etc. The visualization of dynamic evolution is a challenging task when exploring spatiotemporal data. Many approaches have been provided to explore the variation of data patterns over time, which commonly need multiple parameters and preprocessing works. Image generation is a well-known topic in deep learning, and a variety of generating models have been promoted in recent years. In this paper, we introduce a general pipeline called GenerativeMap to extract dynamics of density maps by generating interpolation information. First, a trained generative model comprises an important part of our approach, which can generate nonlinear and natural results by implementing a few parameters. Second, a visual presentation is proposed to show the density change, which is combined with the level of detail and blue noise sampling for a better visual effect. Third, for dynamic visualization of large-scale density maps, we extend this approach to show the evolution in regions of interest, which costs less to overcome the drawback of the learning-based generative model. We demonstrate our method on different types of cases, and we evaluate and compare the approach from multiple aspects. The results help identify the effectiveness of our approach and confirm its applicability in different scenarios.", "keywords": "Density map,deep learning,spatiotemporal data,generative model", "link": "http://dx.doi.org/10.1109/TVCG.2019.2934806", "refList": ["10.1002/rcs.128", "10.1109/tvcg.2015.2468111", "10.1109/icip.2000.899541", "10.1109/tvcg.2011.155", "10.1145/1778765.1778816", "10.1016/j.cviu.2015.02.008", "10.2312/localchapterevents/tpcg/tpcg09/149-163", "10.1111/j.1467-8659.2011.01964.x", "10.1109/visual.1998.745282", "10.1016/j.patrec.2014.01.008", "10.1109/pacificvis.2014.15", "10.1111/cgf.13201", "10.1109/tvcg.2014.2346920", "10.1016/j.softx.2019.02.007", "10.1111/cgf.12933", "10.1109/tvcg.2007.70599", "10.1109/iccv.2017.206", "10.1109/pacificvis.2014.48", "10.1109/tvcg.2016.2607204", "10.1007/s12650-018-0516-0", "10.1214/10-aos799", "10.1109/tvcg.2014.2346594", "10.1109/tvcg.2017.2779501", "10.1145/1778765.1778785", "10.1145/1866158.1866189", "10.1007/s11390-015-1535-0", "10.1155/2016/6156513", "10.1109/tvcg.2013.131", "10.1109/iccv.2017.299", "10.1109/tvcg.2016.2598869"], "wos": 1, "children": [], "len": 1}, {"doi": "10.1111/cgf.13438", "year": "2018", "title": "Spatio-Temporal Contours from Deep Volume Raycasting", "conferenceName": "EuroVis", "authors": "Steffen Frey", "citationCount": "2", "affiliation": "Frey, S (Corresponding Author), Univ Stuttgart, Visualizat Res Ctr, Stuttgart, Germany.\nFrey, S., Univ Stuttgart, Visualizat Res Ctr, Stuttgart, Germany.", "countries": "Germany", "abstract": "We visualize contours for spatio-temporal processes to indicate where and when non-continuous changes occur or spatial bounds are encountered. All time steps are comprised densely in one visualization, with contours allowing to efficiently analyze processes in the data even in case of spatial or temporal overlap. Contours are determined on the basis of deep raycasting that collects samples across time and depth along each ray. For each sample along a ray, its closest neighbors from adjacent rays are identified, considering time, depth, and value in the process. Large distances are represented as contours in image space, using color to indicate temporal occurrence. This contour representation can easily be combined with volume rendering-based techniques, providing both full spatial detail for individual time steps and an outline of the whole time series in one view. Our view-dependent technique supports efficient progressive computation, and requires no prior assumptions regarding the shape or nature of processes in the data. We discuss and demonstrate the performance and utility of our approach via a variety of data sets, comparison and combination with an alternative technique, and feedback by a domain scientist.", "keywords": "", "link": "https://doi.org/10.1111/cgf.13438", "refList": ["10.1109/pacificvis.2009.4906831", "10.1109/tvcg.2008.105", "10.1145/1073204.1073222", "10.1145/1268517.1268528", "10.1145/2461912.2461928", "10.1109/pacificvis.2015.7156386", "10.1109/tvcg.2016.2599042", "10.1023/a:1026543900054", "10.2312/conf/eg2012/stars/075-094", "10.1145/1268517.1268563", "10.1016/j.amc.2015.05.095", "10.1109/tvcg.2008.140", "10.1111/cgf.13201", "10.1038/nature05428", "10.1109/tvcg.2009.200", "10.1109/ldav.2012.6378962", "10.1109/2945.597796", "10.1111/j.1467-8659.2010.01650.x", "10.1111/j.1467-8659.2008.01235.x", "10.1109/tvcg.2017.2692781", "10.1109/tvcg.2007.47", "10.1109/ldav.2012.6378975", "10.1109/tvcg.2012.284", "10.1109/visual.2003.1250402", "10.1111/cgf.13070", "10.1111/j.1467-8659.2003.00723.x", "10.3390/informatics4030027", "10.1109/tvcg.2008.143", "10.1109/visual.2001.964554", "10.1111/cgf.12804"], "wos": 1, "children": [], "len": 1}], "len": 5}, "index": 1419, "embedding": [1.8806039094924927, -0.26727086305618286, -0.35107719898223877, 1.9314286708831787, 0.903876006603241, 0.16650904715061188, -0.706787109375, -0.1986144334077835, 0.9782109260559082, 0.22767937183380127, 1.362898349761963, 0.11573249846696854, -0.13366082310676575, -0.0809868723154068, -0.7231093645095825, -0.5409541130065918, -0.13654521107673645, 0.06482167541980743, 0.34646934270858765, 1.0979053974151611, -0.06630208343267441, -0.6113291382789612, 0.43884021043777466, -0.1414090394973755, -0.5585641860961914, 0.08472851663827896, -0.5077023506164551, -0.17138656973838806, 0.12781168520450592, -0.050985995680093765, 0.37700125575065613, -0.36764219403266907], "projection": [-0.8592149615287781, 6.335784912109375], "size": 3, "height": 2, "width": 2}