{"data": {"doi": "10.1109/pacificvis.2015.7156366", "year": "2015", "title": "Text visualization techniques: Taxonomy, visual survey, and community insights", "conferenceName": "PacificVis", "authors": "Kostiantyn Kucher;Andreas Kerren", "citationCount": "60", "affiliation": "Kucher, K (Corresponding Author), Linnaeus Univ, Dept Comp Sci, ISOVIS Grp, Vaxjo, Sweden.\nKucher, Kostiantyn; Kerren, Andreas, Linnaeus Univ, Dept Comp Sci, ISOVIS Grp, Vaxjo, Sweden.", "countries": "Sweden", "abstract": "Text visualization has become a growing and increasingly important subfield of information visualization. Thus, it is getting harder for researchers to look for related work with specific tasks or visual metaphors in mind. In this paper, we present an interactive visual survey of text visualization techniques that can be used for the purposes of search for related work, introduction to the subfield and gaining insight into research trends. We describe the taxonomy used for categorization of text visualization techniques and compare it to approaches employed in several other surveys. Finally, we present results of analyses performed on the entries data.", "keywords": "Visualization; text visualization; survey; interaction; web-based systems; taxonomy; community analysis", "link": "https://doi.org/10.1109/PACIFICVIS.2015.7156366", "refList": ["10.1109/pacificvis.2010.5429590", "10.1109/vast.2009.5333443", "10.1177/1473871611416549", "10.1016/j.respol.2013.06.012", "10.1109/tvcg.2009.139", "10.1109/mcg.2011.103", "10.1136/qshc.2004.010033", "10.1111/j.1467-8659.2009.01439.x", "10.1002/wics.1285", "10.1109/infvis.2002.1173155", "10.1109/tvcg.2010.183", "10.1109/32.177365", "10.1109/mcg.2005.70", "10.1109/2945.981848", "10.1103/physreve.69.026113", "10.1109/infvis.1995.528686", "10.1109/icdew.2010.5452710", "10.1109/visual.1992.235198", "10.1057/palgrave.ivs.9500023", "10.1145/2089094.2089096", "10.1002/widm.1071", "10.1109/vast.2012.6400485", "10.13140/2.1.1341.1520", "10.1103/physreve.69.066133", "10.1109/tvcg.2011.100", "10.1109/tvcg.2010.154", "10.3145/epi.2014.may.02", "10.1109/tvcg.2008.172"], "wos": 1, "children": [{"doi": "10.1109/tvcg.2015.2467757", "title": "Visual Analysis and Dissemination of Scientific Literature Collections with SurVis", "year": "2015", "conferenceName": "VAST", "authors": "Fabian Beck;Sebastian Koch;Daniel Weiskopf", "citationCount": "39", "affiliation": "Beck, F (Corresponding Author), Univ Stuttgart, VISUS, Stuttgart, Germany. Beck, Fabian; Koch, Sebastian; Weiskopf, Daniel, Univ Stuttgart, VISUS, Stuttgart, Germany.", "countries": "Germany", "abstract": "Bibliographic data such as collections of scientific articles and citation networks have been studied extensively in information visualization and visual analytics research. Powerful systems have been built to support various types of bibliographic analysis, but they require some training and cannot be used to disseminate the insights gained. In contrast, we focused on developing a more accessible visual analytics system, called SurVis, that is ready to disseminate a carefully surveyed literature collection. The authors of a survey may use our Web-based system to structure and analyze their literature database. Later, readers of the survey can obtain an overview, quickly retrieve specific publications, and reproduce or extend the original bibliographic analysis. Our system employs a set of selectors that enable users to filter and browse the literature collection as well as to control interactive visualizations. The versatile selector concept includes selectors for textual search, filtering by keywords and meta-information, selection and clustering of similar publications, and following citation links. Agreement to the selector is represented by word-sized sparkline visualizations seamlessly integrated into the user interface. Based on an analysis of the analytical reasoning process, we derived requirements for the system. We developed the system in a formative way involving other researchers writing literature surveys. A questionnaire study with 14 visual analytics experts confirms that SurVis meets the initially formulated requirements.", "keywords": "Visual analytics of documents, bibliographic data, dissemination, literature browser", "link": "http://dx.doi.org/10.1109/TVCG.2015.2467757", "refList": ["10.1109/mcg.2006.5", "10.1007/978-3-642-41335-3\\_29", "10.2312/eurovisstar.20141170", "10.1109/tvcg.2010.85", "10.1057/palgrave.ivs.9500156", "10.1109/tvcg.2013.167", "10.1109/pacificvis.2015.7156366", "10.1109/tvcg.2012.252", "10.1109/mcg.2011.103", "10.1002/asi.22652", "10.1109/tvcg.2011.169", "10.1109/vissoft.2013.6650545", "10.1109/vast.2009.5333564", "10.2312/eurovisstar.20141174", "10.1111/j.1467-8659.2011.01921.x", "10.1145/2212776.2212796", "10.1007/s00799-004-0111-y", "10.1057/palgrave.ivs.9500180", "10.1109/icpc.2013.6613834", "10.2312/eurovisstar.20141173", "10.1109/tvcg.2010.194", "10.1007/978-0-85729-079-3"], "wos": 1, "children": [{"doi": "10.1109/tvcg.2016.2598667", "title": "cite2vec: Citation-Driven Document Exploration via Word Embeddings", "year": "2016", "conferenceName": "InfoVis", "authors": "Matthew Berger;Katherine McDonough;Lee M. Seversky", "citationCount": "27", "affiliation": "Berger, M (Corresponding Author), Air Force Res Lab, Wright Patterson AFB, OH 45433 USA. Berger, Matthew; Seversky, Lee M., Air Force Res Lab, Wright Patterson AFB, OH 45433 USA. McDonough, Katherine, Northeastern Univ, Boston, MA 02115 USA.", "countries": "USA", "abstract": "Effectively exploring and browsing document collections is a fundamental problem in visualization. Traditionally, document visualization is based on a data model that represents each document as the set of its comprised words, effectively characterizing what the document is. In this paper we take an alternative perspective: motivated by the manner in which users search documents in the research process, we aim to visualize documents via their usage, or how documents tend to be used. We present a new visualization scheme - cite2vec - that allows the user to dynamically explore and browse documents via how other documents use them, information that we capture through citation contexts in a document collection. Starting from a usage-oriented word-document 2D projection, the user can dynamically steer document projections by prescribing semantic concepts, both in the form of phrase/document compositions and document:phrase analogies, enabling the exploration and comparison of documents by their use. The user interactions are enabled by a joint representation of words and documents in a common high-dimensional embedding space where user-specified concepts correspond to linear operations of word and document vectors. Our case studies, centered around a large document corpus of computer vision research papers, highlight the potential for usage-based document visualization.", "keywords": "word embeddings;document visualization", "link": "http://dx.doi.org/10.1109/TVCG.2016.2598667", "refList": ["10.1109/vast.2014.7042493", "10.1109/tvcg.2007.70443", "10.1002/(sici)1097-4571(1999)50:13", "10.1111/cgf.12376", "10.1109/jphot.2014.2387262", "10.1109/vast.2009.5333428", "10.1109/tvcg.2015.2467757", "10.1109/iccv.2015.167", "10.1002/asi.20317", "10.1111/j.1467-8659.2012.03108.x", "10.1109/tvcg.2015.2467621", "10.1002/asi.22652", "10.3115/v1/p14-2050", "10.1109/tvcg.2015.2467451", "10.1109/tvcg.2013.212", "10.1145/1835804.1835827", "10.1109/tvcg.2013.162", "10.1109/tvcg.2011.220", "10.1523/jneurosci.0003-08.2008", "10.1145/997817.997857", "10.1145/2339530.2339706", "10.1109/2945.981848", "10.1145/302979.303148", "10.1109/tvcg.2014.2346431", "10.1162/jmlr.2003.3.4-5.951", "10.1109/tvcg.2010.207", "10.1109/pacificvis.2014.59", "10.1109/38.974518", "10.1109/tvcg.2009.202", "10.1111/j.2517-6161.1996.tb02080.x", "10.1109/tvcg.2014.2346978", "10.1111/j.1467-8659.2012.03107.x", "10.1162/jmlr.2003.3.4-5.993", "10.3115/v1/d14-1162", "10.1109/vast.2011.6102461", "10.1109/tvcg.2008.138", "10.1016/j.neucom.2014.07.073", "10.1109/tvcg.2012.324"], "wos": 1, "children": [{"doi": "10.1109/tvcg.2017.2744478", "title": "ConceptVector: Text Visual Analytics via Interactive Lexicon Building Using Word Embedding", "year": "2017", "conferenceName": "VAST", "authors": "Deok Gun Park;Seungyeon Kim;Jurim Lee;Jaegul Choo;Nicholas Diakopoulos;Niklas Elmqvist", "citationCount": "9", "affiliation": "Choo, J (Corresponding Author), Korea Univ, Seoul, South Korea. Park, Deokgun; Elmqvist, Niklas, Univ Maryland, College Pk, MD 20742 USA. Kim, Seungyeon, Google Inc, Mountain View, CA USA. Lee, Jurim; Choo, Jaegul, Korea Univ, Seoul, South Korea. Diakopoulos, Nicholas, Northwestern Univ, Evanston, IL 60201 USA.", "countries": "USA;Korea", "abstract": "Central to many text analysis methods is the notion of a concept: a set of semantically related keywords characterizing a specific object, phenomenon, or theme. Advances in word embedding allow building a concept from a small set of seed terms. However, naive application of such techniques may result in false positive errors because of the polysemy of natural language. To mitigate this problem, we present a visual analytics system called ConceptVector that guides a user in building such concepts and then using them to analyze documents. Document-analysis case studies with real-world datasets demonstrate the fine-grained analysis provided by ConceptVector. To support the elaborate modeling of concepts, we introduce a bipolar concept model and support for specifying irrelevant words. We validate the interactive lexicon building interface by a user study and expert reviews. Quantitative evaluation shows that the bipolar lexicon generated with our methods is comparable to human-generated ones.", "keywords": "Text analytics,visual analytics,word embedding,text summarization,text classification,concepts", "link": "http://dx.doi.org/10.1109/TVCG.2017.2744478", "refList": ["10.1145/2939672.2939754", "10.1145/2856767.2856783", "10.1111/j.1460-2466.1993.tb01304.x", "10.1111/j.1467-8659.2012.03108.x", "10.1038/44565", "10.1109/tvcg.2015.2467555", "10.1109/tvcg.2016.2598446", "10.1561/1500000001", "10.18653/v1/d15-1161", "10.1038/nmeth.1619", "10.3115/v1/n15-1142", "10.1145/219717.219748", "10.1109/tvcg.2013.212", "10.1145/1835804.1835827", "10.1145/2254556.2254572", "10.1109/tvcg.2011.239", "10.1145/2858036.2858389", "10.1371/journal.pone.0026752", "10.1109/2945.981848", "10.1002/(sici)1097-4571(199009)41:6", "10.1162/jmlr.2003.3.4-5.951", "10.1111/cgf.12873", "10.1109/tvcg.2016.2598667", "10.1162/jmlr.2003.3.4-5.993", "10.3115/v1/d14-1162", "10.1145/290941.291025", "10.1109/vast.2011.6102461", "10.1162/coli\\_a\\_00049", "10.1007/978-1-4614-3223-4", "10.1145/2858036.2858535"], "wos": 1, "children": [{"doi": "10.1109/tvcg.2018.2864905", "title": "Doccurate: A Curation-Based Approach for Clinical Text Visualization", "year": "2018", "conferenceName": "VAST", "authors": "Nicole Sultanum;Devin Singh;Michael Brudno;Fanny Chevalier", "citationCount": "2", "affiliation": "Sultanum, N (Corresponding Author), Hosp Sick Children, Toronto, ON, Canada. Sultanum, N (Corresponding Author), Univ Toronto, Toronto, ON, Canada. Sultanum, Nicole; Singh, Devin; Brudno, Michael, Hosp Sick Children, Toronto, ON, Canada. Sultanum, Nicole; Brudno, Michael; Chevalier, Fanny, Univ Toronto, Toronto, ON, Canada.", "countries": "Canada", "abstract": "Before seeing a patient, physicians seek to obtain an overview of the patient's medical history. Text plays a major role in this activity since it represents the bulk of the clinical documentation, but reviewing it quickly becomes onerous when patient charts grow too large. Text visualization methods have been widely explored to manage this large scale through visual summaries that rely on information retrieval algorithms to structure text and make it amenable to visualization. However, the integration with such automated approaches comes with a number of limitations, including significant error rates and the need for healthcare providers to fine-tune algorithms without expert knowledge of their inner mechanics. In addition, several of these approaches obscure or substitute the original clinical text and therefore fail to leverage qualitative and rhetorical flavours of the clinical notes. These drawbacks have limited the adoption of text visualization and other summarization technologies in clinical practice. In this work we present Doccurate, a novel system embodying a curation-based approach for the visualization of large clinical text datasets. Our approach offers automation auditing and customizability to physicians while also preserving and extensively linking to the original text. We discuss findings of a formal qualitative evaluation conducted with 6 domain experts, shedding light onto physicians' information needs, perceived strengths and limitations of automated tools, and the importance of customization while balancing efficiency. We also present use case scenarios to showcase Doccurate's envisioned usage in practice.", "keywords": "Visual Curation,Clinical Text,Text Visualization,Medical Narrative", "link": "http://dx.doi.org/10.1109/TVCG.2018.2864905", "refList": ["10.1109/tvcg.2017.2744478", "10.1109/tvcg.2015.2467591", "10.1109/tkde.2014.2324581", "10.1093/jamia/ocv069", "10.1136/amiajnl-2014-002945", "10.1145/2089094.2089101", "10.1109/titb.2012.2186149", "10.1093/jamia/ocv032", "10.1109/tvcg.2010.129", "10.1145/2939672.2939778", "10.1136/jamia.2009.001560", "10.1016/j.cmpb.2015.10.014", "10.3122/jabfm.2011.06.100255", "10.1109/titb.2006.884365", "10.1109/tvcg.2014.2346677", "10.1109/tvcg.2015.2467531", "10.1016/0020-7101(96)01178-6", "10.1145/2531602.2531620", "10.1109/vast.2012.6400485", "10.1038/sdata.2016.35", "10.1016/s0140-6736(94)91406-0", "10.1109/vast.2014.7042502", "10.1561/1100000039", "10.1093/jamia/ocx070", "10.1145/3173574.3173996", "10.1109/infvis.2000.885098", "10.1145/1378773.1378785", "10.1093/bioinformatics/btx228"], "wos": 1, "children": [{"doi": "10.1109/tvcg.2019.2934539", "title": "Criteria for Rigor in Visualization Design Study", "year": "2019", "conferenceName": "InfoVis", "authors": "Miriah D. Meyer;Jason Dykes", "citationCount": "16", "affiliation": "Meyer, M (Corresponding Author), Univ Utah, Salt Lake City, UT 84112 USA. Meyer, Miriah, Univ Utah, Salt Lake City, UT 84112 USA. Dykes, Jason, City Univ London, London, England.", "countries": "USA;England", "abstract": "We develop a new perspective on research conducted through visualization design study that emphasizes design as a method of inquiry and the broad range of knowledge-contributions achieved through it as multiple, subjective, and socially constructed. From this interpretivist position we explore the nature of visualization design study and develop six criteria for rigor. We propose that rigor is established and judged according to the extent to which visualization design study research and its reporting are INFORMED, REFLEXIVE, ABUNDANT, PLAUSIBLE, RESONANT, and TRANSPARENT. This perspective and the criteria were constructed through a four-year engagement with the discourse around rigor and the nature of knowledge in social science, information systems, and design. We suggest methods from cognate disciplines that can support visualization researchers in meeting these criteria during the planning, execution, and reporting of design study. Through a series of deliberately provocative questions, we explore implications of this new perspective for design study research in visualization, concluding that as a discipline, visualization is not yet well positioned to embrace, nurture, and fully benefit from a rigorous, interpretivist approach to design study. The perspective and criteria we present are intended to stimulate dialogue and debate around the nature of visualization design study and the broader underpinnings of the discipline.", "keywords": "design study,relativism,interpretivism,knowledge construction,qualitative research,research through design", "link": "http://dx.doi.org/10.1109/TVCG.2019.2934539", "refList": ["10.1007/978-1-4939-0378-8\\_8", "10.1177/1049732315588501", "10.1177/146879410200200205", "10.2307/1177100", "10.1016/0142-694x(82)90040-0", "10.1109/tvcg.2014.2346331", "10.1109/beliv.2018.8634420", "10.1145/2362364.2362371", "10.1080/2159676x.2017.1393221", "10.1177/1473871613510429", "10.1145/2212877.2212889", "10.1080/09650790802011973", "10.1109/tvcg.2018.2864836", "10.1109/tvcg.2018.2865076", "10.1109/tvcg.2015.2467195", "10.1109/mcse.2007.106", "10.1080/1750984x.2017.1317357", "10.1109/tvcg.2017.2745958", "10.1177/1525822x0101300203", "10.1080/23265507.2017.1300068", "10.1111/j.1540-4560.1946.tb02295.x", "10.1177/1468794108098034", "10.1007/978-3-7643-8472-2\\_6", "10.1145/2317956.2317968", "10.2307/1511837", "10.1177/104973202129120052", "10.3233/efi-2004-22201", "10.1109/beliv.2018.8634427", "10.1109/beliv.2018.8634261", "10.1016/s0142-694x(01)00009-6", "10.1007/978-3-7643-8472-2\\_3", "10.1145/642611.642616", "10.1177/1468794107085301", "10.1177/1077800410383121", "10.1109/tvcg.2010.137", "10.1145/2405716.2405725", "10.1145/2702123.2702172", "10.1109/tvcg.2014.2346248", "10.1109/tvcg.2011.209", "10.1111/j.1467-8659.2009.01710.x", "10.1145/3173574.3173775", "10.1145/1993060.1993065", "10.1007/978-1-4419-5653-8\\_2", "10.1177/107780049900500402", "10.1109/tvcg.2018.2864905", "10.2307/2288400", "10.2307/1511637", "10.1109/tvcg.2014.2346431", "10.1177/160940690400300403", "10.1145/2993901.2993916", "10.1145/1879831.1879836", "10.2307/3178066", "10.1109/tvcg.2018.2864913", "10.3102/0013189x022004016", "10.1109/tvcg.2015.2511718", "10.1109/tvcg.2018.2865241", "10.1016/j.ijnurstu.2010.06.004", "10.1109/tvcg.2012.213", "10.1111/0735-2751.00040", "10.1109/tvcg.2013.145", "10.1002/ev.1427", "10.1109/tvcg.2018.2811488", "10.1075/idj.23.1.07thu", "10.1109/tvcg.2009.111", "10.1109/mcg.2018.2874523", "10.1111/cgf.13184", "10.1111/cgf.13595"], "wos": 1, "children": [{"doi": "10.1109/tvcg.2020.3029413", "title": "A Design Space of Vision Science Methods for Visualization Research", "year": "2020", "conferenceName": "InfoVis", "authors": "Madison A. Elliott;Christine Nothelfer;Cindy Xiong;Danielle Albers Szafir", "citationCount": "0", "affiliation": "Elliott, MA (Corresponding Author), Univ British Columbia, Vancouver, BC, Canada. Elliott, Madison A., Univ British Columbia, Vancouver, BC, Canada. Nothelfer, Christine, Northwestern Univ, Evanston, IL 60208 USA. Xiong, Cindy, Univ Massachusetts, Amherst, MA 01003 USA. Szafir, Danielle Albers, Univ Colorado, Boulder, CO 80309 USA.", "countries": "Canada;USA", "abstract": "A growing number of efforts aim to understand what people see when using a visualization. These efforts provide scientific grounding to complement design intuitions, leading to more effective visualization practice. However, published visualization research currently reflects a limited set of available methods for understanding how people process visualized data. Alternative methods from vision science offer a rich suite of tools for understanding visualizations, but no curated collection of these methods exists in either perception or visualization research. We introduce a design space of experimental methods for empirically investigating the perceptual processes involved with viewing data visualizations to ultimately inform visualization design guidelines. This paper provides a shared lexicon for facilitating experimental visualization research. We discuss popular experimental paradigms, adjustment types, response types, and dependent measures used in vision science research, rooting each in visualization examples. We then discuss the advantages and limitations of each technique. Researchers can use this design space to create innovative studies and progress scientific understanding of design choices and evaluations in visualization. We highlight a history of collaborative success between visualization and vision science research and advocate for a deeper relationship between the two fields that can elaborate on and extend the methodological design space for understanding visualization and vision.", "keywords": "Perception,human vision,empirical research,evaluation,HCI", "link": "http://dx.doi.org/10.1109/TVCG.2020.3029413", "refList": ["10.1109/tvcg.2019.2934790", "10.1177/146879410200200205", "10.2312/eurovisshort", "10.1109/tvcg.2015.2467811", "10.1111/j.1467-6486.2009.00859.x", "10.1177/1473871613510429", "10.1109/tvcg.2018.2864836", "10.1109/tvcg.2018.2865076", "10.1109/tvcg.2013.231", "10.1002/cphy.c100079", "10.1177/0886109909354981", "10.1109/tvcg.2018.2865149", "10.1080/1750984x.2017.1317357", "10.1007/978-3-7643-8472-2\\_6", "10.1093/bioinformatics/btq110", "10.1111/cgf.13728", "10.2307/1511837", "10.1109/tvcg.2019.2934539", "10.3233/efi-2004-22201", "10.1002/chp.1340180402", "10.1111/2041-210x.12034", "10.1111/j.2041-210x.2011.00169.x", "10.1109/tvcg.2015.2467452", "10.1002/chp", "10.1177/1077800410383121", "10.1177/1744987107081254", "10.1002/cpbi.96", "10.1109/tvcg.2018.2864526", "10.1109/beliv.2018.8634026", "10.2307/1511637", "10.1109/tvcg.2014.2346431", "10.1111/cgf.12883", "10.1109/tvcg.2019.2934281", "10.1145/2993901.2993916", "10.2307/3178066", "10.1145/2993901.2993913", "10.1145/1182475.1182476", "10.1016/j.destud.2004.06.002", "10.1177/1609406918763214", "10.2312/eurovisshort.20151137", "10.1145/882262.882291", "10.1177/174498710501000305", "10.1017/s1049096513001789", "10.1109/tvcg.2012.213", "10.1093/nar/gkz239", "10.1093/sysbio/sys062", "10.1109/tvcg.2019.2898186", "10.1109/tvcg.2018.2811488", "10.1007/s11135-006-9044-4", "10.1109/tvcg.2009.111", "10.1111/2041-210x.12066", "10.1109/mcg.2018.2874523", "10.1177/1609406920909938"], "wos": 1, "children": [], "len": 1}, {"doi": "10.1109/tvcg.2020.3030438", "title": "ChemVA: Interactive Visual Analysis of Chemical Compound Similarity in Virtual Screening", "year": "2020", "conferenceName": "SciVis", "authors": "Mar\u00eda Virginia Sabando;Pavol Ulbrich;Mat\u00edas N. Selzer;Jan Byska;Jan Mican;Ignacio Ponzoni;Axel J. Soto;Maria Luj\u00e1n Ganuza;Barbora Kozl\u00edkov\u00e1", "citationCount": "0", "affiliation": "Sabando, MV (Corresponding Author), Univ Nacl Sur, Inst Comp Sci \\& Engn UNS CONICET, Bahia Blanca, Buenos Aires, Argentina. Sabando, MV (Corresponding Author), Univ Nacl Sur, Dept Comp Sci \\& Engn, Bahia Blanca, Buenos Aires, Argentina. Sabando, Maria Virginia; Selzer, Matias; Ponzoni, Ignacio; Soto, Axel J.; Ganuza, Maria Lujan, Univ Nacl Sur, Inst Comp Sci \\& Engn UNS CONICET, Bahia Blanca, Buenos Aires, Argentina. Sabando, Maria Virginia; Ponzoni, Ignacio; Soto, Axel J., Univ Nacl Sur, Dept Comp Sci \\& Engn, Bahia Blanca, Buenos Aires, Argentina. Ulbrich, Pavol; Byska, Jan; Kozlikova, Barbora, Masaryk Univ, Fac Informat, Visitlab, Brno, Czech Republic. Selzer, Matias; Ganuza, Maria Lujan, Univ Nacl Sur, VyGLab Res Lab UNS CICPBA, Dept Comp Sci \\& Engn, Bahia Blanca, Buenos Aires, Argentina. Mican, Jan, Masaryk Univ, Dept Expt Biol, Loschmidt Labs, Brno, Czech Republic. Mican, Jan, Masaryk Univ, RECETOX, Brno, Czech Republic. Mican, Jan, Masaryk Univ, Fac Med, Brno, Czech Republic.", "countries": "Argentina;Republic", "abstract": "In the modern drug discovery process, medicinal chemists deal with the complexity of analysis of large ensembles of candidate molecules. Computational tools, such as dimensionality reduction (DR) and classification, are commonly used to efficiently process the multidimensional space of features. These underlying calculations often hinder interpretability of results and prevent experts from assessing the impact of individual molecular features on the resulting representations. To provide a solution for scrutinizing such complex data, we introduce ChemVA, an interactive application for the visual exploration of large molecular ensembles and their features. Our tool consists of multiple coordinated views: Hexagonal view, Detail view, 3D view, Table view, and a newly proposed Difference view designed for the comparison of DR projections. These views display DR projections combined with biological activity, selected molecular features, and confidence scores for each of these projections. This conjunction of views allows the user to drill down through the dataset and to efficiently select candidate compounds. Our approach was evaluated on two case studies of finding structurally similar ligands with similar binding affinity to a target protein, as well as on an external qualitative evaluation. The results suggest that our system allows effective visual inspection and comparison of different high-dimensional molecular representations. Furthermore, ChemVA assists in the identification of candidate compounds while providing information on the certainty behind different molecular representations.", "keywords": "Virtual screening,visual analysis,dimensionality reduction,coordinated views,cheminformatics", "link": "http://dx.doi.org/10.1109/TVCG.2020.3030438", "refList": ["10.1109/tvcg.2008.137", "10.1057/ivs.2009.10", "10.2312/eurovisstar.20151110", "10.1109/eisic.2015.35", "10.1109/pacificvis.2014.44", "10.1145/1142473.1142574", "10.1109/tvcg.2013.223", "10.1109/tvcg.2014.2346573", "10.1109/tvcg.2019.2934539", "10.1111/cgf.13717", "10.1109/vizsec.2009.5375536", "10.1111/cgf.12925", "10.1109/tvcg.2015.2467551", "10.1109/mcg.2015.99", "10.1007/978-3-319", "10.1109/tvcg.2012.255", "10.1145/1064830.1064834", "10.1177/1473871611433713", "10.1207/s1532690xci0804\\_2", "10.1145/1168149.1168168", "10.1016/j.chb.2006.10.002", "10.1109/tvcg.2014.2346441", "10.1109/eisic.2017.15", "10.1111/1467-8721.00160", "10.1109/tvcg.2018.2865024", "10.1109/infvis.2004.2"], "wos": 1, "children": [], "len": 1}, {"doi": "10.1109/tvcg.2020.3030435", "title": "Data Visceralization: Enabling Deeper Understanding of Data Using Virtual Reality", "year": "2020", "conferenceName": "InfoVis", "authors": "Benjamin Lee;Dave Brown;Bongshin Lee;Christophe Hurter;Steven Mark Drucker;Tim Dwyer", "citationCount": "1", "affiliation": "Lee, B (Corresponding Author), Monash Univ, Clayton, Vic, Australia. Lee, Benjamin; Dwyer, Tim, Monash Univ, Clayton, Vic, Australia. Brown, Dave; Lee, Bongshin; Drucker, Steven, Microsoft Res, Redmond, WA USA. Hurter, Christophe, French Civil Aviat Univ, ENAC, Toulouse, France.", "countries": "USA;France;Australia", "abstract": "A fundamental part of data visualization is transforming data to map abstract information onto visual attributes. While this abstraction is a powerful basis for data visualization, the connection between the representation and the original underlying data (i.e., what the quantities and measurements actually correspond with in reality) can be lost. On the other hand, virtual reality (VR) is being increasingly used to represent real and abstract models as natural experiences to users. In this work, we explore the potential of using VR to help restore the basic understanding of units and measures that are often abstracted away in data visualization in an approach we call data visceralization. By building VR prototypes as design probes, we identify key themes and factors for data visceralization. We do this first through a critical reflection by the authors, then by involving external participants. We find that data visceralization is an engaging way of understanding the qualitative aspects of physical measures and their real-life form, which complements analytical and quantitative understanding commonly gained from data visualization. However, data visceralization is most effective when there is a one-to-one mapping between data and representation, with transformations such as scaling affecting this understanding. We conclude with a discussion of future directions for data visceralization.", "keywords": "Data visceralization,virtual reality,exploratory study", "link": "http://dx.doi.org/10.1109/TVCG.2020.3030435", "refList": ["10.1080/01973762.2013.761106", "10.1109/tvcg.2015.2467811", "10.1109/tvcg.2012.221", "10.1145/3284179.3284326", "10.1109/tvcg.2019.2934287", "10.1109/2945.841119", "10.1109/tvcg.2019.2934539", "10.1109/mcg.2013.101", "10.1109/tvcg.2011.175", "10.1109/tvcg.2018.2830759", "10.1109/3dvis.2014.7160096", "10.1109/mcg.2018.2878900", "10.1109/iv.2011.32", "10.1109/tvcg.2013.196", "10.1109/tvcg.2018.2865241", "10.1515/abitech-2017-0002", "10.1145/2468356.2468739", "10.16995/olh.280", "10.1080/15230406.2018.1513343", "10.1109/iv.2004.1320189", "10.1109/tvcg.2012.213", "10.1109/mcg.2006.120", "10.1109/icdar.2017.286", "10.1371/journal.pone.0146368", "10.1080/1472586x.2011.548488", "10.1109/tvcg.2014.2346574", "10.1080/0013838x.2017.1332021"], "wos": 1, "children": [], "len": 1}, {"doi": "10.1109/tvcg.2020.3030464", "title": "Designing Narrative-Focused Role-Playing Games for Visualization Literacy in Young Children", "year": "2020", "conferenceName": "InfoVis", "authors": "Elaine Huynh;Angela Nyhout;Patricia Ganea;Fanny Chevalier", "citationCount": "0", "affiliation": "Huynh, E (Corresponding Author), Univ Toronto, Dept Comp Sci, Toronto, ON, Canada. Huynh, Elaine, Univ Toronto, Dept Comp Sci, Toronto, ON, Canada. Nyhout, Angela; Ganea, Patricia, Univ Toronto, Ontario Inst Studies Educ, Toronto, ON, Canada. Chevalier, Fanny, Univ Toronto, Dept Comp Sci \\& Stat Sci, Toronto, ON, Canada.", "countries": "Canada", "abstract": "Building on game design and education research, this paper introduces narrative-focused role-playing games as a way to promote visualization literacy in young children. Visualization literacy skills are vital in understanding the world around us and constructing meaningful visualizations, yet, how to better develop these skills at an early age remains largely overlooked and understudied. Only recently has the visualization community started to fill this gap, resulting in preliminary studies and development of educational tools for use in early education. We add to these efforts through the exploration of gamification to support learning, and identify an opportunity to apply role-playing game-based designs by leveraging the presence of narratives in data-related problems involving visualizations. We study the effects of including narrative elements on learning through a technology probe, grounded in a set of design considerations stemming from visualization, game design and education science. We create two versions of a game - one with narrative elements and one without - and evaluate our instances on 33 child participants between 11- to 13-years old using a between-subjects study design. Despite participants requiring double the amount of time to complete their game due to additional narrative elements, the inclusion of such elements were found to improve engagement without sacrificing learning; our results indicate no significant differences in development of graph-reading skills, but significant differences in engagement and overall enjoyment of the game. We report observations and qualitative feedback collected, and note areas for improvement and room for future work.", "keywords": "Visualization Literacy,Educational technology,Gamification,Narrative", "link": "http://dx.doi.org/10.1109/TVCG.2020.3030464", "refList": ["10.1007/978-981-13-2694-3\\_2", "10.1145/2702123.2702298", "10.1145/2702123.2702558", "10.1007/978-981-13-2694-3\\_8", "10.1145/2702123.2702245", "10.1109/mis.2012.27", "10.18061/dsq.v21i4.318", "10.1109/tvcg.2013.134", "10.1109/vl.1996.545307", "10.1007/s10708-008-9186-0", "10.1093/cje/ben057", "10.5210/fm.v16i2.3316", "10.1109/tvcg.2019.2934539", "10.1109/tvcg.2016.2598608", "10.1007/978-3-319-94659-7\\_10", "10.1109/mcg.2013.28", "10.17351/ests2017.134", "10.1109/pacificvis.2014.39", "10.1145/3173574.3173728", "10.1145/2598784.2598806", "10.1145/2491500.2491501", "10.1145/1993060.1993065", "10.1109/tvcg.2018.2802520", "10.1145/3025453.3025667", "10.1145/2598510.2598566", "10.1080/15710882.2015.1081240", "10.17351/ests2017.133", "10.1109/tvcg.2014.2346431", "10.1016/j.ijhcs.2015.02.005", "10.1145/2702123.2702180", "10.1109/tvcg.2007.70577", "10.1109/mcg.2019.2923483", "10.5931/djim.v12.i1.6449", "10.1145/3240167.3240206", "10.1145/2468356.2468739", "10.1109/tvcg.2012.213", "10.1145/3025453.3025751", "10.4018/978-1-4666-6497-5.ch003"], "wos": 1, "children": [], "len": 1}, {"doi": "10.1109/tvcg.2020.3030355", "title": "Guidelines For Pursuing and Revealing Data Abstractions", "year": "2020", "conferenceName": "InfoVis", "authors": "Alex Bigelow;Katy Williams;Katherine E. Isaacs", "citationCount": "0", "affiliation": "Bigelow, A (Corresponding Author), Univ Arizona, Tucson, AZ 85721 USA. Bigelow, Alex; Williams, Katy; Isaacs, Katherine E., Univ Arizona, Tucson, AZ 85721 USA.", "countries": "USA", "abstract": "Many data abstraction types, such as networks or set relationships, remain unfamiliar to data workers beyond the visualization research community. We conduct a survey and series of interviews about how people describe their data, either directly or indirectly. We refer to the latter as latent data abstractions. We conduct a Grounded Theory analysis that (1) interprets the extent to which latent data abstractions exist, (2) reveals the far-reaching effects that the interventionist pursuit of such abstractions can have on data workers, (3) describes why and when data workers may resist such explorations, and (4) suggests how to take advantage of opportunities and mitigate risks through transparency about visualization research perspectives and agendas. We then use the themes and codes discovered in the Grounded Theory analysis to develop guidelines for data abstraction in visualization projects. To continue the discussion, we make our dataset open along with a visual interface for further exploration.", "keywords": "Data abstraction,Grounded theory,Survey design,Data wrangling", "link": "http://dx.doi.org/10.1109/TVCG.2020.3030355", "refList": ["10.1080/2159676x.2016.1251701", "10.1109/infvis.2000.885092", "10.1145/2702123.2702298", "10.4135/9781848607941.n14", "10.1007/978-1-4939", "10.1109/tvcg.2014.2346331", "10.1109/tvcg.2017.2744843", "10.1177/1473871613510429", "10.1007/978-1-4939-0378-8\\_2", "10.1145/2598153.2598175", "10.1109/tvcg.2019.2934285", "10.1177/1473871613488591", "10.1145/2501105.2501106", "10.1109/tvcg.2019.2934538", "10.1109/tvcg.2019.2934539", "10.1017/s1049096510990781", "10.1145/3025453.3025837", "10.1145/3290605.3300474", "10.1145/3290605.3300356", "10.1002/nur.1025", "10.1145/2993901.2993916", "10.1145/3392826", "10.1086/269268", "10.1109/tvcg.2018.2865241", "10.1145/2998181.2998331", "10.1145/291224.291229", "10.1057/ivs.2009.13", "10.1145/2047196.2047205", "10.1109/tvcg.2012.213", "10.1145/3274405", "10.1109/tvcg.2013.145", "10.1016/0040-6031(92)85160-w", "10.1109/iv.2013.45", "10.1109/tvcg.2009.111", "10.1109/mcg.2019.2914844", "10.1109/tvcg.2009.116"], "wos": 1, "children": [], "len": 1}, {"doi": "10.1109/tvcg.2020.3030405", "title": "Insights From Experiments With Rigor in an EvoBio Design Study", "year": "2020", "conferenceName": "InfoVis", "authors": "Jennifer Rogers;Austin H. Patton;Luke Harmon;Alexander Lex;Miriah D. Meyer", "citationCount": "0", "affiliation": "Rogers, J (Corresponding Author), Univ Utah, Salt Lake City, UT 84112 USA. Rogers, Jen; Lex, Alexander; Meyer, Miriah, Univ Utah, Salt Lake City, UT 84112 USA. Patton, Austin H., Washington State Univ, Pullman, WA 99164 USA. Harmon, Luke, Univ Idaho, Moscow, ID 83843 USA.", "countries": "USA", "abstract": "Design study is an established approach of conducting problem-driven visualization research. The academic visualization community has produced a large body of work for reporting on design studies, informed by a handful of theoretical frameworks, and applied to a broad range of application areas. The result is an abundance of reported insights into visualization design, with an emphasis on novel visualization techniques and systems as the primary contribution of these studies. In recent work we proposed a new, interpretivist perspective on design study and six companion criteria for rigor that highlight the opportunities for researchers to contribute knowledge that extends beyond visualization idioms and software. In this work we conducted a year-long collaboration with evolutionary biologists to develop an interactive tool for visual exploration of multivariate datasets and phylogenetic trees. During this design study we experimented with methods to support three of the rigor criteria: ABUNDANT, REFLEXIVE, and TRANSPARENT. As a result we contribute two novel visualization techniques for the analysis of multivariate phylogenetic datasets, three methodological recommendations for conducting design studies drawn from reflections over our process of experimentation, and two writing devices for reporting interpretivist design study. We offer this work as an example for implementing the rigor criteria to produce a diverse range of knowledge contributions.", "keywords": "Methodologies,Application Motivated Visualization,Guidelines,Life Sciences Visualization,Health,Medicine,Biology,Bioinformatics,Genomics", "link": "http://dx.doi.org/10.1109/TVCG.2020.3030405", "refList": ["10.1109/tvcg.2019.2934790", "10.1177/146879410200200205", "10.2312/eurovisshort", "10.1109/tvcg.2015.2467811", "10.1111/j.1467-6486.2009.00859.x", "10.1177/1473871613510429", "10.1109/tvcg.2018.2864836", "10.1109/tvcg.2018.2865076", "10.1109/tvcg.2013.231", "10.1002/cphy.c100079", "10.1109/tvcg.2018.2865149", "10.1080/1750984x.2017.1317357", "10.1007/978-3-7643-8472-2\\_6", "10.1111/cgf.13728", "10.2307/1511837", "10.1109/tvcg.2019.2934539", "10.3233/efi-2004-22201", "10.1080/17493460802276893", "10.1002/chp.1340180402", "10.1111/2041-210x.12034", "10.1111/j.2041-210x.2011.00169.x", "10.1109/tvcg.2015.2467452", "10.1002/chp", "10.1177/1077800410383121", "10.1002/cpbi.96", "10.1109/tvcg.2018.2864526", "10.1109/beliv.2018.8634026", "10.2307/1511637", "10.1109/tvcg.2014.2346431", "10.1111/cgf.12883", "10.1109/tvcg.2019.2934281", "10.1145/2993901.2993916", "10.2307/3178066", "10.1145/2993901.2993913", "10.1145/1182475.1182476", "10.1016/j.destud.2004.06.002", "10.1177/1609406918763214", "10.2312/eurovisshort.20151137", "10.1145/882262.882291", "10.1109/tvcg.2012.213", "10.1109/tvcg.2019.2898186", "10.1109/tvcg.2018.2811488", "10.1007/s11135-006-9044-4", "10.1109/tvcg.2009.111", "10.1111/2041-210x.12066", "10.1109/mcg.2018.2874523", "10.1177/1609406920909938"], "wos": 1, "children": [], "len": 1}, {"doi": "10.1109/tvcg.2020.3030462", "title": "Table Scraps: An Actionable Framework for Multi-Table Data Wrangling From An Artifact Study of Computational Journalism", "year": "2020", "conferenceName": "InfoVis", "authors": "Stephen Kasica;Charles Berret;Tamara Munzner", "citationCount": "0", "affiliation": "Kasica, S (Corresponding Author), Univ British Columbia, Dept Comp Sci, Vancouver, BC, Canada. Kasica, Stephen; Munzner, Tamara, Univ British Columbia, Dept Comp Sci, Vancouver, BC, Canada. Berret, Charles, Univ British Columbia, Sch Journalism Writing \\& Media, Vancouver, BC, Canada.", "countries": "Canada", "abstract": "For the many journalists who use data and computation to report the news, data wrangling is an integral part of their work. Despite an abundance of literature on data wrangling in the context of enterprise data analysis, little is known about the specific operations, processes, and pain points journalists encounter while performing this tedious, time-consuming task. To better understand the needs of this user group, we conduct a technical observation study of 50 public repositories of data and analysis code authored by 33 professional journalists at 26 news organizations. We develop two detailed and cross-cutting taxonomies of data wrangling in computational journalism, for actions and for processes. We observe the extensive use of multiple tables, a notable gap in previous wrangling analyses. We develop a concise, actionable framework for general multi-table data wrangling that includes wrangling operations documented in our taxonomy that are without clear parallels in other work. This framework, the first to incorporate tables as first-class objects, will support future interactive wrangling tools for both computational journalism and general-purpose use. We assess the generative and descriptive power of our framework through discussion of its relationship to our set of taxonomies.", "keywords": "Computational journalism,Data journalism,Data wrangling", "link": "http://dx.doi.org/10.1109/TVCG.2020.3030462", "refList": ["10.1145/1378773.1378792", "10.1109/tvcg.2012.219", "10.1109/vast47406.2019.8986909", "10.1145/1084805.1084812", "10.1007/s00778-008-0098-x", "10.1016/j.websem.2008.09.005", "10.18637/jss.v040.i01", "10.1145/989863.989865", "10.1109/tvcg.2015.2467551", "10.5281/zenodo.3509134", "10.1109/tvcg.2019.2934539", "10.1109/tvcg.2019.2934593", "10.1109/tse.2018.2796554", "10.17349/jmc117309", "10.1109/2945.981851", "10.1109/vast.2011.6102440", "10.1177/1473871611415994", "10.1145/2001269.2001288"], "wos": 1, "children": [], "len": 1}, {"doi": "10.1111/cgf.13964", "year": "2020", "title": "Reading Traces: Scalable Exploration in Elastic Visualizations of Cultural Heritage Data", "conferenceName": "EuroVis", "authors": "Mark{-}Jan Bludau;Viktoria Br{\\\"{u}}ggemann;Anna Busch;Marian D{\\\"{o}}rk", "citationCount": "1", "affiliation": "Bludau, MJ (Corresponding Author), Univ Appl Sci Potsdam, UCLAB, Potsdam, Germany.\nBludau, M. -J.; Brueggemann, V.; Doerk, M., Univ Appl Sci Potsdam, UCLAB, Potsdam, Germany.\nBusch, A., Univ Potsdam, Theodor Fontane Archiv, Potsdam, Germany.", "countries": "Germany", "abstract": "Through a design study, we develop an approach to data exploration that utilizes elastic visualizations designed to support varying degrees of detail and abstraction. Examining the notions of scalability and elasticity in interactive visualizations, we introduce a visualization of personal reading traces such as marginalia or markings inside the reference library of German realist author Theodor Fontane. To explore such a rich and extensive collection, meaningful visual forms of abstraction and detail are as important as the transitions between those states. Following a growing research interest in the role of fluid interactivity and animations between views, we are particularly interested in the potential of carefully designed transitions and consistent representations across scales. The resulting prototype addresses humanistic research questions about the interplay of distant and close reading with visualization research on continuous navigation along several granularity levels, using scrolling as one of the main interaction mechanisms. In addition to presenting the design process and resulting prototype, we present findings from a qualitative evaluation of the tool, which suggest that bridging between distant and close views can enhance exploration, but that transitions between views need to be crafted very carefully to facilitate comprehension.", "keywords": "", "link": "https://doi.org/10.1111/cgf.13964", "refList": ["10.1007/s41244-017-0048-4", "10.1109/tvcg.2009.108", "10.1145/1456650.1456652", "10.1109/tvcg.2014.2346424", "10.1177/1473871611416549", "10.1111/cgf.13195", "10.1145/2207676.2208607", "10.1145/1376616.1376618", "10.1006/ijhc.2002.1017", "10.1109/tvcg.2011.185", "10.1177/1473871611413180", "10.1109/vl.1996.545307", "10.1006/ijhc.1017", "10.1109/tvcg.2019.2934539", "10.1109/tvcg.2018.2830759", "10.1145/1556262.1556300", "10.1109/tvcg.2014.2346677", "10.1145/2909132.2909255", "10.1109/tvcg.2007.70539", "10.1145/2396636.2396675", "10.1145/1978942.1979124", "10.1016/j.ijhcs.2003.08.005", "10.2312/eurovisstar.20151113", "10.1109/infvis.2005.1532127"], "wos": 1, "children": [], "len": 1}], "len": 17}, {"doi": "10.1109/tvcg.2019.2934264", "title": "The Validity, Generalizability and Feasibility of Summative Evaluation Methods in Visual Analytics", "year": "2019", "conferenceName": "VAST", "authors": "Mosab Khayat;Morteza Karimzadeh;David S. Ebert;Arif Ghafoor", "citationCount": "1", "affiliation": "Khayat, M (Corresponding Author), Purdue Univ, W Lafayette, IN 47907 USA. Khayat, Mosab; Karimzadeh, Morteza; Ebert, David S.; Ghafoor, Arif, Purdue Univ, W Lafayette, IN 47907 USA. Karimzadeh, Morteza, Univ Colorado, Boulder, CO 80309 USA.", "countries": "USA", "abstract": "Many evaluation methods have been used to assess the usefulness of Visual Analytics (VA) solutions. These methods stem from a variety of origins with different assumptions and goals, which cause confusion about their proofing capabilities. Moreover, the lack of discussion about the evaluation processes may limit our potential to develop new evaluation methods specialized for VA. In this paper, we present an analysis of evaluation methods that have been used to summatively evaluate VA solutions. We provide a survey and taxonomy of the evaluation methods that have appeared in the VAST literature in the past two years. We then analyze these methods in terms of validity and generalizability of their findings, as well as the feasibility of using them. We propose a new metric called summative quality to compare evaluation methods according to their ability to prove usefulness, and make recommendations for selecting evaluation methods based on their summative quality in the VA domain.", "keywords": "Summative evaluation,usefulness,evaluation process,taxonomy,visual analytics", "link": "http://dx.doi.org/10.1109/TVCG.2019.2934264", "refList": ["10.1109/tvcg.2017.2744478", "10.1109/tvcg.2018.2865025", "10.1109/tvcg.2006.85", "10.1109/tvcg.2014.2346331", "10.1109/beliv.2018.8634420", "10.1109/tvcg.2017.2745181", "10.1111/cgf.13677", "10.1109/tvcg.2018.2864844", "10.1109/tvcg.2013.126", "10.1109/tvcg.2018.2864811", "10.1109/infvis.2005.1532147", "10.1177/0956797613504966", "10.1145/2669557.2669579", "10.1109/mcg.2005.102", "10.1109/visual.2003.1250426", "10.1136/bmj.39489.470347.ad", "10.1109/tvcg.2017.2744080", "10.1109/mcg.2009.53", "10.1111/j.1467-8527.2005.00307.x", "10.1109/tvcg.2010.132", "10.1109/tvcg.2018.2864886", "10.1109/tvcg.2018.2864843", "10.1109/tvcg.2018.2865028", "10.1109/tvcg.2018.2865051", "10.1109/tvcg.2018.2865044", "10.1109/tvcg.2018.2865026", "10.1007/978-3-540-71080-6\\_6", "10.1109/tvcg.2018.2865020", "10.1177/1473871611407399", "10.1109/tvcg.2018.2864504", "10.1109/tvcg.2018.2864526", "10.1109/tvcg.2005.53", "10.1109/tvcg.2018.2864905", "10.1049/sej.1991.0040", "10.1109/tvcg.2015.2513410", "10.1109/tvcg.2017.2711030", "10.1109/tvcg.2011.279", "10.1109/vast.2017.8585505", "10.1147/jrd.2010.2042914", "10.1016/s0378-7206(98)00044-5", "10.1145/2993901.2993913", "10.1109/tvcg.2018.2865041", "10.1109/tvcg.2018.2864812", "10.1109/tvcg.2017.2744758", "10.1145/1168149.1168158", "10.1109/tvcg.2017.2745279", "10.1109/tvcg.2012.213", "10.1109/tvcg.2017.2744738", "10.1109/tvcg.2017.2745083", "10.1109/tvcg.2018.2864826", "10.1145/1377966.1377974", "10.1109/apec.2009.4802646", "10.1145/1168149.1168152", "10.1016/j.jss.2008.03.059", "10.1109/vast.2017.8585484", "10.1109/tvcg.2017.2744818", "10.1109/tvcg.2017.2744358", "10.1109/tvcg.2018.2864499", "10.1109/tvcg.2018.2865042", "10.1109/tvcg.2017.2744898"], "wos": 1, "children": [{"doi": "10.1109/tvcg.2020.3030388", "title": "Visualization of Human Spine Biomechanics for Spinal Surgery", "year": "2020", "conferenceName": "SciVis", "authors": "Pepe Eulzer;Sabine Bauer;Francis Kilian;Kai Lawonn", "citationCount": "0", "affiliation": "Eulzer, P (Corresponding Author), Univ Jena, Jena, Germany. Eulzer, Pepe; Lawonn, Kai, Univ Jena, Jena, Germany. Bauer, Sabine, Univ Koblenz Landau, Koblenz, Germany. Kilian, Francis, Cath Clin Koblenz Montabaur, Dept Spine Surg, Koblenz, Germany.", "countries": "Germany", "abstract": "We propose a visualization application, designed for the exploration of human spine simulation data. Our goal is to support research in biomechanical spine simulation and advance efforts to implement simulation-backed analysis in surgical applications. Biomechanical simulation is a state-of-the-art technique for analyzing load distributions of spinal structures. Through the inclusion of patient-specific data, such simulations may facilitate personalized treatment and customized surgical interventions. Difficulties in spine modelling and simulation can be partly attributed to poor result representation, which may also be a hindrance when introducing such techniques into a clinical environment. Comparisons of measurements across multiple similar anatomical structures and the integration of temporal data make commonly available diagrams and charts insufficient for an intuitive and systematic display of results. Therefore, we facilitate methods such as multiple coordinated views, abstraction and focus and context to display simulation outcomes in a dedicated tool. $\\mathrm{By}$ linking the result data with patient-specific anatomy, we make relevant parameters tangible for clinicians. Furthermore, we introduce new concepts to show the directions of impact force vectors, which were not accessible before. We integrated our toolset into a spine segmentation and simulation pipeline and evaluated our methods with both surgeons and biomechanical researchers. When comparing our methods against standard representations that are currently in use, we found increases in accuracy and speed in data exploration tasks. $\\mathrm{in}$ a qualitative review, domain experts deemed the tool highly useful when dealing with simulation result data, which typically combines time-dependent patient movement and the resulting force distributions on spinal structures.", "keywords": "Medical visualization,bioinformatics,coordinated views,focus and context,biomechanical simulation", "link": "http://dx.doi.org/10.1109/TVCG.2020.3030388", "refList": ["10.1109/tvcg.2018.2864903", "10.1177/1473871613510429", "10.1093/ehjqcco/qcz052", "10.1109/tvcg.2007.70594", "10.1109/tvcg.2018.2865076", "10.1055/s-0039-1687862", "10.1109/visual.1990.146375", "10.1109/tvcg.2017.2744198", "10.1016/j.ijmedinf.2014.10.001", "10.1109/tvcg.2013.124", "10.1016/j.jacc", "10.1111/cgf.13167", "10.17705/1thci.00055", "10.1136/bmjqs.2009.037895", "10.1109/tvcg.2013.238", "10.1109/tvcg.2018.2865240", "10.1186/1471-2261-6-34", "10.1109/tvcg.2019.2934264", "10.1109/tvcg.2013.200", "10.1109/tvcg.2011.209", "10.1109/tvcg.2014.2346682", "10.1109/tvcg.2015.2467091", "10.1136/bmjopen-2019-033208", "10.1109/beliv.2018.8634027", "10.1109/tvcg.2012.213", "10.1109/tvcg.2015.2467191", "10.1109/tvcg.2015.2467325", "10.1145/2133806.2133821", "10.1145/1806799.1806866", "10.1108/02635570610688869", "10.1002/hbm.20701", "10.1561/1100000039", "10.1145/3025453.3025645", "10.1109/tvcg.2009.111", "10.1109/tvcg.2013.120", "10.1109/tvcg.2016.2599030"], "wos": 1, "children": [], "len": 1}], "len": 3}], "len": 23}, {"doi": "10.1109/tvcg.2018.2865044", "title": "Seq2Seq-Vis: A Visual Debugging Tool for Sequence-to-Sequence Models", "year": "2018", "conferenceName": "VAST", "authors": "Hendrik Strobelt;Sebastian Gehrmann;Michael Behrisch;Adam Perer;Hanspeter Pfister;Alexander M. Rush", "citationCount": "22", "affiliation": "Strobelt, H (Corresponding Author), IBM Res, Yorktown Hts, NY 10598 USA. Strobelt, H (Corresponding Author), MIT IBM Watson Al Lab, Cambridge, MA 02142 USA. Strobelt, Hendrik; Perer, Adam, IBM Res, Yorktown Hts, NY 10598 USA. Strobelt, Hendrik; Perer, Adam, MIT IBM Watson Al Lab, Cambridge, MA 02142 USA. Gehrmann, Sebastian; Rush, Alexander M., Harvard NLP Grp, Cambridge, MA USA. Behrisch, Michael; Pfister, Hanspeter, Harvard Visual Comp Grp, Cambridge, MA USA.", "countries": "USA", "abstract": "Neural sequence-to-sequence models have proven to be accurate and robust for many sequence prediction tasks, and have become the standard approach for automatic translation of text. The models work with a five-stage blackbox pipeline that begins with encoding a source sequence to a vector space and then decoding out to a new target sequence. This process is now standard, but like many deep learning methods remains quite difficult to understand or debug. In this work, we present a visual analysis tool that allows interaction and \u201cwhat if\u201d-style exploration of trained sequence-to-sequence models through each stage of the translation process. The aim is to identify which patterns have been learned, to detect model errors, and to probe the model with counterfactual scenario. We demonstrate the utility of our tool through several real-world sequence-to-sequence use cases on large-scale models.", "keywords": "Explainable AI,Visual Debugging,Visual Analytics,Machine Learning,Deep Learning,NLP", "link": "http://dx.doi.org/10.1109/TVCG.2018.2865044", "refList": ["10.1109/tvcg.2017.2744478", "10.18653/v1/d16-1011", "10.18653/v1/p17-4004", "10.1145/2858036.2858529", "10.18653/v1/p17-1106", "10.1371/journal.pone.0130140", "10.1007/978-3-319-10590-1\\_53", "10.1109/tvcg.2017.2744158", "10.1109/5.726791", "10.1145/2939672.2939778", "10.1109/cvpr.2015.7298640", "10.1007/bf02289565", "10.1109/72\\_279181", "10.1109/tvcg.2017.2744718", "10.23915/distill.00010", "10.1007/s10107-014-0839-0", "10.23915/disti11.00001"], "wos": 1, "children": [{"doi": "10.1109/tvcg.2019.2934261", "title": "Ablate, Variate, and Contemplate: Visual Analytics for Discovering Neural Architectures", "year": "2019", "conferenceName": "VAST", "authors": "Dylan Cashman;Adam Perer;Remco Chang;Hendrik Strobelt", "citationCount": "1", "affiliation": "Cashman, D (Corresponding Author), Tufts Univ, Medford, MA 02155 USA. Cashman, Dylan; Chang, Remco, Tufts Univ, Medford, MA 02155 USA. Perer, Adam, Carnegie Mellon Univ, Pittsburgh, PA 15213 USA. Strobelt, Hendrik, MIT IBM Watson AI Lab, Cambridge, MA USA.", "countries": "USA", "abstract": "The performance of deep learning models is dependent on the precise configuration of many layers and parameters. However, there are currently few systematic guidelines for how to configure a successful model. This means model builders often have to experiment with different configurations by manually programming different architectures (which is tedious and time consuming) or rely on purely automated approaches to generate and train the architectures (which is expensive). In this paper, we present Rapid Exploration of Model Architectures and Parameters, or REMAP, a visual analytics tool that allows a model builder to discover a deep learning model quickly via exploration and rapid experimentation of neural network architectures. In REMAP, the user explores the large and complex parameter space for neural network architectures using a combination of global inspection and local experimentation. Through a visual overview of a set of models, the user identifies interesting clusters of architectures. Based on their findings, the user can run ablation and variation experiments to identify the effects of adding, removing, or replacing layers in a given architecture and generate new models accordingly. They can also handcraft new models using a simple graphical interface. As a result, a model builder can build deep learning models quickly, efficiently, and without manual programming. We inform the design of REMAP through a design study with four deep learning model builders. Through a use case, we demonstrate that REMAP allows users to discover performant neural network architectures efficiently using visual exploration and user-defined semi-automated searches through the model space.", "keywords": "visual analytics,neural networks,parameter space exploration", "link": "http://dx.doi.org/10.1109/TVCG.2019.2934261", "refList": ["10.1109/mcg.2018.2878902", "10.1111/cgf.12639", "10.1109/tvcg.2017.2744938", "10.1117/12.2007316", "10.1109/cvpr.2014.81", "10.1016/j.csda.2008.02.031", "10.1080/00994480.2000.10748487", "10.1088/1749-4699/8/1/014008", "10.1109/tvcg.2013.125", "10.1109/cvpr.2015.7298594", "10.1111/j.1467-8659.2009.01475.x", "10.1109/tvcg.2012.65", "10.1109/tvcg.2017.2745085", "10.1109/tvcg.2017.2745158", "10.1109/tvcg.2017.2744805", "10.1145/2487575.2487629", "10.1109/tvcg.2018.2865044", "10.23915/distill.00010", "10.1109/72.279181", "10.1109/tvcg.2017.2744199", "10.1007/s13398-014-0173-7.2", "10.1109/tvcg.2018.2864504", "10.1109/vast.2012.6400490", "10.1007/978-3-319-10590-1\\_53", "10.1109/tvcg.2018.2864477", "10.1109/tvcg.2014.2346321", "10.1094/pdis-11-11-0999-pdn", "10.1109/ijcnn.2015.7280767", "10.1109/tvcg.2017.2744878", "10.5555/3326943.3327130", "10.1109/tvcg.2017.2744718", "10.1109/iccv.2015.169", "10.1109/tvcg.2018.2864500", "10.1109/tvcg.2017.2744158", "10.1109/cvpr.2014.223", "10.1109/cvpr.2016.90", "10.1109/vast.2010.5652443", "10.1111/cgf.13681", "10.1109/tvcg.2016.2598831", "10.1109/vast.2011.6102453"], "wos": 1, "children": [{"doi": "10.1109/tvcg.2020.3028888", "title": "A Visual Analytics Framework for Explaining and Diagnosing Transfer Learning Processes", "year": "2020", "conferenceName": "VAST", "authors": "Yuxin Ma;Arlen Fan;Jingrui He;Arun Reddy Nelakurthi;Ross Maciejewski", "citationCount": "0", "affiliation": "Ma, YX (Corresponding Author), Arizona State Univ, Tempe, AZ 85287 USA. Ma, Yuxin; Fan, Arlen; Maciejewski, Ross, Arizona State Univ, Tempe, AZ 85287 USA. He, Jingrui, Univ Illinois, Champaign, IL USA. Nelakurthi, Arun Reddy, Samsung Res Amer, Mountain View, CA USA.", "countries": "USA", "abstract": "Many statistical learning models hold an assumption that the training data and the future unlabeled data are drawn from the same distribution. However, this assumption is difficult to fulfill in real-world scenarios and creates barriers in reusing existing labels from similar application domains. Transfer Learning is intended to relax this assumption by modeling relationships between domains, and is often applied in deep learning applications to reduce the demand for labeled data and training time. Despite recent advances in exploring deep learning models with visual analytics tools, little work has explored the issue of explaining and diagnosing the knowledge transfer process between deep learning models. In this paper, we present a visual analytics framework for the multi-level exploration of the transfer learning processes when training deep neural networks. Our framework establishes a multi-aspect design to explain how the learned knowledge from the existing model is transferred into the new learning task when training deep neural networks. Based on a comprehensive requirement and task analysis, we employ descriptive visualization with performance measures and detailed inspections of model behaviors from the statistical, instance, feature, and model structure levels. We demonstrate our framework through two case studies on image classification by fine-tuning AlexNets to illustrate how analysts can utilize our framework.", "keywords": "Transfer learning,deep learning,visual analytics", "link": "http://dx.doi.org/10.1109/TVCG.2020.3028888", "refList": ["10.1109/tvcg.2014.2346578", "10.1109/tvcg.2019.2934629", "10.1109/tvcg.2017.2744683", "10.1109/tvcg.2016.2598838", "10.1109/tvcg.2017.2744938", "10.1109/tvcg.2019.2934262", "10.1109/tpami.2018.2868685", "10.1145/2702123.2702509", "10.1109/vast.2017.8585721", "10.1109/tvcg.2018.2843369", "10.1109/tvcg.2016.2598828", "10.1111/j.1467-8659.2011.01898.x", "10.1109/tvcg.2013.65", "10.1145/2976749.2978318", "10.1007/978-3-030-01424-7\\_27", "10.1109/tvcg.2019.2934261", "10.1007/s11704-016-6028-y", "10.1016/j.visinf.2017.01.006", "10.1145/2858036.2858529", "10.1109/iccv.2015.279", "10.1109/mci.2018.2840738", "10.1109/tvcg.2019.2892483", "10.1109/vast.2018.8802509", "10.1109/tvcg.2013.124", "10.1186/s40537-016-0043-6", "10.1109/tvcg.2018.2864475", "10.1145/3200489", "10.1109/tvcg.2018.2865044", "10.1111/cgf.13210", "10.1109/tvcg.2018.2816223", "10.23915/distill.00007", "10.1109/tvcg.2017.2744199", "10.1109/tkde.2018.2876857", "10.1109/tvcg.2019.2934631", "10.1109/tvcg.2018.2864504", "10.1109/tvcg.2014.2346482", "10.1109/tvcg.2015.2467618", "10.1109/tvcg.2014.2346594", "10.1109/tvcg.2011.188", "10.1007/978-3-642-15561-1\\_16", "10.1109/tvcg.2018.2864812", "10.1109/mcg.2019.2919033", "10.1109/tvcg.2017.2744718", "10.1109/tvcg.2017.2744878", "10.1109/tvcg.2016.2598541", "10.1109/tkde.2009.191", "10.1145/3065386", "10.1016/j.ins.2016.03.021", "10.1109/tvcg.2019.2903943", "10.1007/s10994-009-5152-4", "10.1109/tvcg.2019.2934659", "10.1109/tvcg.2018.2864500", "10.1109/iccv.2017.74", "10.1109/tvcg.2017.2744158", "10.1109/tvcg.2012.207", "10.1111/cgf.13092", "10.1109/tvcg.2018.2865027", "10.1109/tvcg.2017.2744378", "10.1109/tvcg.2017.2744358", "10.1109/tvcg.2019.2934619", "10.1109/tvcg.2018.2864499", "10.1109/tvcg.2017.2754480", "10.1109/tvcg.2016.2598831"], "wos": 1, "children": [], "len": 1}, {"doi": "10.1111/cgf.14034", "year": "2020", "title": "The State of the Art in Enhancing Trust in Machine Learning Models with the Use of Visualizations", "conferenceName": "EuroVis", "authors": "Angelos Chatzimparmpas;Rafael Messias Martins;Ilir Jusufi;Kostiantyn Kucher;Fabrice Rossi;Andreas Kerren", "citationCount": "2", "affiliation": "Chatzimparmpas, A (Corresponding Author), Linnaeus Univ, Dept Comp Sci \\& Media Technol, Vaxjo, Sweden.\nChatzimparmpas, A.; Martins, R. M.; Jusufi, I.; Kucher, K.; Kerren, A., Linnaeus Univ, Dept Comp Sci \\& Media Technol, Vaxjo, Sweden.\nRossi, F., PSL Univ, Univ Paris Dauphine, Ceremade, Paris, France.", "countries": "Sweden;France", "abstract": "Machine learning (ML) models are nowadays used in complex applications in various domains, such as medicine, bioinformatics, and other sciences. Due to their black box nature, however, it may sometimes be hard to understand and trust the results they provide. This has increased the demand for reliable visualization tools related to enhancing trust in ML models, which has become a prominent topic of research in the visualization community over the past decades. To provide an overview and present the frontiers of current research on the topic, we present a State-of-the-Art Report (STAR) on enhancing trust in ML models with the use of interactive visualization. We define and describe the background of the topic, introduce a categorization for visualization techniques that aim to accomplish this goal, and discuss insights and opportunities for future research directions. Among our contributions is a categorization of trust against different facets of interactive ML, expanded and improved from previous research. Our results are investigated from different analytical perspectives: (a) providing a statistical overview, (b) summarizing key findings, (c) performing topic analyses, and (d) exploring the data sets used in the individual papers, all with the support of an interactive web-based survey browser. We intend this survey to be beneficial for visualization researchers whose interests involve making ML models more trustworthy, as well as researchers and practitioners from other disciplines in their search for effective visualization techniques suitable for solving their tasks with confidence and conveying meaning to their data.", "keywords": "trustworthy machine learning; visualization; interpretable machine learning; explainable machine learning", "link": "https://doi.org/10.1111/cgf.14034", "refList": ["10.1109/mcg.2018.2878902", "10.1109/tvcg.2008.153", "10.2312/mlvis.20181130", "10.1109/tvcg.2016.2598828", "10.1145/3290605.3300911", "10.1145/2993901.2993909", "10.2312/mlvis.20191158", "10.1109/tvcg.2016.2598446", "10.1111/j.1467-8659.2009.01475.x", "10.1145/3290605.3300809", "10.1109/pacificvis.2018.00031", "10.1055/s-0029-1216348", "10.1007/978-3-319-90403-0\\_13", "10.1109/tvcg.2017.2745085", "10.1111/j.1467-8659.2011.01938.x", "10.1007/978-3-319-54024-5\\_6", "10.1016/s0167-9473(01)00065-2", "10.1111/cgf.12895", "10.2312/eurovisshort.20141152.17", "10.2312/eurova.20151098.22", "10.1111/cgf.13667", "10.3115/1072228.1072378", "10.1109/tbdata.2018.2877350.16", "10.1109/lars.2009.5418323.25", "10.1109/tvcg.2017.2744878", "10.1016/j.combustflame.2005.09.018", "10.1016/j.cag.2014.01.006", "10.1109/tvcg.2016.2570755", "10.2312/mlvis.20191158.1,19", "10.1518/hfes.46.1.50.30392", "10.1145/3301275.3302280", "10.1145/3351095.3372834.1", "10.1016/s0377-2217(01)00264-8", "10.1111/cgf.13424", "10.1007/978-3-319-23485-4\\_53", "10.1007/978-94-007-0753-5\\_3623", "10.1109/tvcg.2013.101", "10.1111/cgf.12884", "10.1111/j.1467-8659.2010.01835.x", "10.1021/ci9901338", "10.4230/lipics.itcs:2017", "10.1109/mis.2013.24", "10.1109/tvcg.2014.2346482", "10.1109/tvcg.2018.2865230", "10.1073/pnas.1807180116", "10.1109/dsaa.2018.00018", "10.1109/tvcg.2009.153", "10.3115/1219840.1219855", "10.1109/tvcg.2018.2864812", "10.1109/tvcg.2018.2872577", "10.2312/trvis.20191183", "10.1109/cvpr:2004.383", "10.1109/vast.2008.4677350", "10.1145/302979.303001", "10.1109/tvcg.2018.2864499", "10.1111/cgf.13672", "10.1109/tvcg.2014.2346626", "10.23915/distill.00010.18", "10.1109/tvcg.2017.2744805", "10.2312/mlvis:20191160.18", "10.23915/distill:00016", "10.1109/pacificvis.2016.7465260", "10.1111/cgf.13683", "10.23915/distill.00016.19", "10.1145/32906053.300803.22", "10.1109/tvcg.2014.2346574", "10.1177/1473871615600010", "10.1109/tvcg.2016.2598831", "10.1145/3230623", "10.1109/visual.2019.8933744", "10.1145/2993901.2993915", "10.1016/j.visinf.2017.01.006", "10.1145/2993901.2993914", "10.1109/tvcg.2014.2346984", "10.1109/5.726791", "10.23915/distill.00010", "10.1109/tvcg.2018.2864825", "10.2307/2394164", "10.1109/tvcg.2017.2744458", "10.1145/2993901.2993917.28", "10.1111/cgf.13711", "10.1109/tvcg.2016.2598664", "10.2307/2530428", "10.1109/icdar.1997.620583", "10.1109/tvcg.2017.2744718", "10.1111/cgf.13425", "10.1109/tvcg.2019.2903943", "10.1145/1518701.1518895", "10.1109/tvcg.2018.2864838", "10.1145/62038.62043", "10.1111/j.1467-8659.2011.01920.x", "10.1145/3025171.3025208", "10.1145/355112.355124", "10.1109/vast.2010.5652398", "10.1109/tvcg.2014.2346578", "10.1145/3173574.3174209", "10.4178/epih/e2014008", "10.1109/beliv.2018.8634201.25,28", "10.1016/j.eswa.2007.12.020", "10.1111/cgf:13406", "10.1109/mcg.2011.103", "10.1631/fitee.1700808", "10.1109/tvcg.2017.2745158", "10.1073/pnas.0307752101", "10.1109/tvcg.2018.2816223", "10.1109/tvcg.2017.2745141", "10.1145/32232.32234", "10.1109/tvcg.2019.2934267", "10.1109/tvcg.2018.2864477", "10.1145/3132169", "10.2312/eurova.20151100.19", "10.1145/3172944.3172964", "10.1145/2601248.2601268", "10.1109/isai-nlp.2018.8693002.1", "10.1111/cgf.13404", "10.1007/s100320200071", "10.2312/trvis.20191183.16", "10.1111/cgf.12755", "10.1145/2702123.2702509", "10.1145/1401890.1402008.25", "10.1109/tvcg.2012.65", "10.1177/1473871617733996", "10.2312/trvis.20191187.7", "10.21236/ada273556", "10.1109/vast.2010.5652450", "10.1111/j.1467-8659.2011.01940.x", "10.1177/875647939000600106", "10.1109/tvcg.2017.2711030", "10.1016/j.immuni.2016.04.014", "10.1109/tvcg.2019.2934209", "10.1016/0095-0696(78)90006-2", "10.1016/j.jclinepi.2015.04.014", "10.1016/j.ress.2013.02.013", "10.1111/cgf.12640", "10.1145/1015330.1015388.25", "10.1111/j.1467-8659.2009.01468.x", "10.1145/1541880.1541882", "10.1109/vast.2011.6102453", "10.1016/s0008-8846(98)00165-3", "10.2312/trvis.20191186.7", "10.1007/s13748-013-0040-3", "10.1109/tvcg.2015.2467757", "10.1109/tbdata.2018.2877350", "10.1109/vast.2017.8585613", "10.1080/10556789208805504", "10.1109/vast.2012.6400484", "10.1145/3025171.3025181", "10.1007/978-3-319-90403-0\\_12", "10.1109/mcg.2019.2922592", "10.1021/ci000392t", "10.1109/vast.2007.4389000", "10.1111/cgf.13406.16", "10.1111/cgf.13684", "10.2312/eurovisshort.20161166.17", "10.2312/evs:20191168", "10.1145/3041021.3055135", "10.1145/3301275.3302265", "10.1613/jair.4135", "10.1109/tvcg.2018.2864500", "10.1109/tvcg.2017.2744158", "10.1109/ssci.2015.33", "10.1111/cgf.13453", "10.2312/pe/eurovast/eurova11/049-052", "10.1145/3025171.3025181.13", "10.1145/371920.372094", "10.1109/tvcg.2017.2744938", "10.1111/j.1467-8659.2012.03108.x", "10.1109/tvcg.2019.2934251", "10.1145/3290605.3300809.18", "10.1109/ldav.2016.7874305", "10.1109/vast.2016.7883514", "10.1109/iccv.2015.425", "10.1145/3301275.3302324", "10.1109/tnnls.2013.2292894", "10.1109/tvcg.2018.2865044", "10.1109/tvcg.2013.157", "10.1371/journal.pcbi.0020161", "10.1186/s12916-019-1426-2", "10.1109/10.867928", "10.1111/cgf.13217", "10.1109/mcg.2019.2919033", "10.1145/2993901.2993910", "10.1109/tvcg.2017.2744738", "10.2307/258792", "10.1111/cgf.12655", "10.1016/j.dss.2014.03.001", "10.1109/tvcg.2019.2904069", "10.1111/cgf.13205", "10.1002/mds.22340", "10.1109/tvcg.2019.2934595", "10.1287/inte.2018.0957", "10.1109/cvpr.2007.382974", "10.1109/tvcg.2012.280", "10.1145/2678025.2701399.13", "10.2312/mlvis.20181130.13", "10.2312/eurova.20181106.16", "10.1109/tvcg.2018.2864475", "10.2312/mlvis.20191160.18,22", "10.1007/978-1-4612-4026-6.25", "10.1109/cvpr.2006.42", "10.1145/3172944.3172950", "10.1109/cvpr.2004.383.25", "10.1109/tvcg.2019.2934812", "10.1609/aimag.v35i4.2513", "10.2312/trvis.20191185.7", "10.1111/j.1467-8659.2009.01684.x", "10.1371/journal.pone.0129126", "10.1111/cgf.13092", "10.1162/coli\\_a\\_00237", "10.1109/tvcg.2017.2744818", "10.1109/vast.2011.6102448", "10.1109/tvcg.2009.111", "10.1109/tvcg.2019.2934619", "10.1016/s0377-2217(01)00264-8.25", "10.1111/cgf.12639", "10.1109/access.2019.2919343", "10.1186/s12874-019-0681-4", "10.1109/pacificvis.2015.7156366", "10.1109/pacificvis.2018.00029", "10.1109/tvcg.2019.2934261", "10.1080/13506280444000102.http://www.uvt.nl/ticc", "10.1109/vast.2018.8802509", "10.1111/cgf.13212", "10.1145/3200489", "10.1111/cgf.13176", "10.1177/1473871620904671", "10.1007/978-3-319-10590-1\\_53", "10.1111/j.1467-8659.2012.03126.x", "10.1111/cgf.13172", "10.1145/3025171.3025208.6,21", "10.1111/cgf.12366", "10.1109/tvcg.2019.2934659", "10.1109/cvprw.2009.5206848", "10.1016/j.media.2014.11.010", "10.1109/tvcg.2017.2744683", "10.1109/tvcg.2019.2934262", "10.1016/j.neucom.2006.11.018", "10.1177/1473871615571951", "10.1371/journal.pcbi.0020161.25", "10.1177/1473871611415994", "10.2312/trvis20191187", "10.2312/eurova", "10.1145/2858036.2858529", "10.1145/2207676.2207738", "10.1007/s11042-009-0417-2", "10.1145/3301275.3302317", "10.1038/s41746-019-0148-3", "10.1145/3351095.3372834", "10.1080/10691898.2011.11889627", "10.1109/tvcg.2018.2864504", "10.1109/vast.2017.8585720", "10.1109/mcg.2018.053491732", "10.1007/s10994-010-5207-6", "10.1109/tvcg.2019.2934433", "10.1016/j.cag.2017.05.005", "10.1109/tvcg.2012.279", "10.1145/3231622.3231641.19,20", "10.1145/1562849.1562851", "10.1007/11564126\\_", "10.1109/tvcg.2018.2846735", "10.3115/1225403.1225421", "10.1109/vast.2012.6400486", "10.2312/eurova.20191116.22", "10.1109/tvcg.2007.70443", "10.1080/027868291009242", "10.2312/eurova.20151100", "10.1145/2939502.2939503.19", "10.1016/j.cag.2014.02.004", "10.1145/2939672.2939778", "10.1109/vast.2010.5652484", "10.1111/cgf.12641", "10.1145/3301275.3302289", "10.1109/visual.2019.8933619", "10.1109/tvcg.2017.2672987", "10.1109/vast.2016.7883517.20", "10.1109/igarss.2017.8127684", "10.1016/j.jcae.2010.04.002", "10.1109/vast.2010.5652885", "10.1016/j.visinf.2019.03.002", "10.1007/s00371-018-1500-3", "10.1109/mcg.2018.042731661", "10.1109/34.598228", "10.1109/tvcg.2018.2865027", "10.1016/j.neucom.2017.01.105", "10.1111/cgf.12389", "10.1109/tvcg.2019.2934591", "10.1109/vast.2010.5652392.16", "10.1111/cgf.13416", "10.1080/02701367.1992.10608764", "10.1109/vast.2017.8585721", "10.1109/tvcg.2018.2843369", "10.1109/sbes.2010.27", "10.1109/vast.2015.7347637", "10.1145/1401890.1402008", "10.1016/j.bpj.2010.04.064", "10.1109/tvcg.2013.125", "10.1109/isai-nlp.2018.8693002", "10.1371/journal.pone.0160127", "10.1145/2856767.2856779", "10.1145/2678025.2701399", "10.1109/vast.2011.6102451", "10.1109/mcg.2010.18", "10.1021/ci4000213", "10.1109/vast.2012.6400492", "10.1007/11564126-49.25", "10.2312/eurova.20171114", "10.1109/vast.2010.5652443", "10.1145/3134599", "10.2312/pe/eurovast/eurovast10/013-018.19", "10.1109/tvcg.2019.2903946", "10.1109/tvcg.2015.2467717", "10.1177/1473871612460526", "10.1016/j.cag.2018.09.018", "10.1109/tvcg.2016.2598838", "10.1145/3172944.3172964.14", "10.1109/vast.2009.5333428", "10.1109/vast.2014.7042480", "10.2312/pe/eurovast/eurovast10/013-018", "10.1177/0962280215588241", "10.1145/2993901.2993917", "10.1109/cvpr.2008:4587581", "10.1109/tvcg.2015.2467551", "10.1016/j.visinf.2018.09.001", "10.1126/science.290.5500.2319", "10.2312/eurova.20151107", "10.1109/visual.2019.8933695", "10.13140/2.1.2393.1847", "10.1197/jamia.m1929", "10.1109/cvpr.2008.4587581.25", "10.1145/1518701.1518895.16", "10.1109/vds.2017.8573444", "10.2312/trvis:20191185", "10.1145/3359786", "10.13140/2.1.1341.1520", "10.2312/pe/eurovast/eurova11/049-052.17", "10.1109/tvcg.2014.2346660", "10.1145/3185517", "10.1109/adprl.2011.5967372", "10.1109/tvcg.2015.2467591", "10.1111/j.1751-9004.2009.00232.x", "10.1136/qshc.2004.010033", "10.1109/vast.2012.6400493", "10.1109/tvcg.2019.2934266", "10.1145/2971763.2971775", "10.1111/cgf.13730", "10.1109/vast.2012.6400488", "10.1111/cgf.13210", "10.1109/tvcg.2019.2934631", "10.1145/3172944.3172965", "10.1057/ivs.2010.2", "10.1109/tvcg.2017.2745258", "10.1016/j.jbusres.2019.07.039", "10.1162/jmlr.2003.3.4-5.993", "10.1109/pacificvis.2019.00044", "10.2312/pe/eurovast/eurova12/037-041", "10.1109/tvcg.2019.2934629", "10.1177/0018720814547570", "10.1145/3292500.3330908", "10.1111/j.1467-8659.2009.01467.x", "10.2312/eurova.20151098", "10.1177/1473871617713337", "10.1109/lars:2009.5418323", "10.1109/vast.2011.6102437", "10.1111/cgf.12878", "10.1561/1500000001", "10.1145/3025171.3025222", "10.1007/s11704-016-6028-y", "10.1016/j.procs.2017.05.216", "10.1109/cvpr.2007.382974.25", "10.1080/10447318.2020.1741118", "10.1109/vast.2012.6400489", "10.1145/3025171.3025172", "10.1109/tvcg.2017.2744098", "10.1109/tvcg.2005.66", "10.1016/j.dss.2009.05.016", "10.1007/978-1-4612-4026-6", "10.2312/evs.20191168.16,20,28", "10.2312/pe/eurovast/eurova12/037-041.17", "10.1145/3290605.3300803", "10.1145/1015330.1015388", "10.1111/cgf.13197", "10.1016/b978-1-55860-377-6.50048-7", "10.1111/cgf.13681", "10.1109/tvcg.2017.2744378", "10.1109/tvcg.2017.2744358", "10.1109/vast.2008.4677352"], "wos": 1, "children": [{"doi": "10.1109/tvcg.2020.3030368", "title": "Implicit Multidimensional Projection of Local Subspaces", "year": "2020", "conferenceName": "InfoVis", "authors": "Rongzheng Bian;Yumeng Xue;Liang Zhou;Jian Zhang 0070;Baoquan Chen;Daniel Weiskopf;Yunhai Wang", "citationCount": "1", "affiliation": "Wang, YH (Corresponding Author), Shandong Univ, Qingdao, Peoples R China. Zhou, L (Corresponding Author), Univ Utah, Salt Lake City, UT 84112 USA. Bian, Rongzheng; Xue, Yumeng; Wang, Yunhai, Shandong Univ, Qingdao, Peoples R China. Chen, Baoquan, Peking Univ, Beijing, Peoples R China. Zhang, Jian, Chinese Acad Sci, CNIC, Beijing, Peoples R China. Zhou, Liang, Univ Utah, Salt Lake City, UT 84112 USA. Weiskopf, Daniel, Univ Stuttgart, Stuttgart, Germany.", "countries": "USA;Germany;China", "abstract": "We propose a visualization method to understand the effect of multidimensional projection on local subspaces, using implicit function differentiation. Here, we understand the local subspace as the multidimensional local neighborhood of data points. Existing methods focus on the projection of multidimensional data points, and the neighborhood information is ignored. Our method is able to analyze the shape and directional information of the local subspace to gain more insights into the global structure of the data through the perception of local structures. Local subspaces are fitted by multidimensional ellipses that are spanned by basis vectors. An accurate and efficient vector transformation method is proposed based on analytical differentiation of multidimensional projections formulated as implicit functions. The results are visualized as glyphs and analyzed using a full set of specifically-designed interactions supported in our efficient web-based visualization tool. The usefulness of our method is demonstrated using various multi- and high-dimensional benchmark datasets. Our implicit differentiation vector transformation is evaluated through numerical comparisons; the overall method is evaluated through exploration examples and use cases.", "keywords": "High-dimensional data visualization,dimensionality reduction,local linear subspaces,user interaction", "link": "http://dx.doi.org/10.1109/TVCG.2020.3030368", "refList": ["10.3844/jcssp.2018.613.622", "10.1016/j.aci.2018.08.003", "10.3390/info9030065", "10.1016/j.visinf.2018.09.003", "10.1371/journal.pone.0118432", "10.1016/s0893-6080(05)80023-1", "10.1109/tvcg.2020.2986996", "10.1109/icst.2012.56", "10.1007/s10844-013-0250-y", "10.1109/tbdata.2018", "10.1145/1125451.1125659", "10.1109/tvcg.2013.125", "10.1177/1473871611412817", "10.1145/3290605.3300911", "10.1111/cgf.14034", "10.1007/s13721-013-0034-x", "10.1016/j.procs.2017.05.216", "10.1016/j.ins.2009.08.025", "10.1109/tvcg.2013.124", "10.1109/tvcg.2018.2864499", "10.1109/tvcg.2018.2864475", "10.1080/10447318.2020.1741118", "10.1016/j.imu.2019.100203", "10.1109/tvcg.2018.2865240", "10.1186/s12864-019-6413-7", "10.1109/tvcg.2015.2467551", "10.1002/widm.1249", "10.1007/978-3-319-66429-3\\_29", "10.1109/tvcg.2014.2346481", "10.1109/tvcg.2018.2864825", "10.1177/1473871620904671", "10.1109/tvcg.2019.2934267", "10.1136/bmjopen-2016-012799", "10.1109/smartgridcomm.2017.8340682", "10.1007/s10664-015-9401-9", "10.1145/1143844.1143874", "10.1111/cgf.12389", "10.1109/tvcg.2018.2872577", "10.1007/978-981-13-5802-9\\_20", "10.1016/j.ipm.2009.03.002", "10.5220/0006431602160222", "10.1109/mcg.2015.50", "10.1109/tvcg.2014.2346574", "10.1007/bf02289565", "10.1109/tvcg.2017.2744378", "10.1016/j.patrec.2008.08.010", "10.1023/a:1010933404324", "10.9735/2229-3981"], "wos": 1, "children": [], "len": 1}, {"doi": "10.1109/tvcg.2020.3030465", "title": "Visual Causality Analysis of Event Sequence Data", "year": "2020", "conferenceName": "VAST", "authors": "Zhuochen Jin;Shunan Guo;Nan Chen;Daniel Weiskopf;David Gotz;Nan Cao", "citationCount": "0", "affiliation": "Cao, N (Corresponding Author), Tongji Univ, IDVx Lab, Shanghai, Peoples R China. Jin, Zhuochen; Guo, Shunan; Chen, Nan; Cao, Nan, Tongji Univ, IDVx Lab, Shanghai, Peoples R China. Weiskopf, Daniel, Univ Stuttgart, Stuttgart, Germany. Gotz, David, Univ N Carolina, Chapel Hill, NC 27515 USA.", "countries": "USA;Germany;China", "abstract": "Causality is crucial to understanding the mechanisms behind complex systems and making decisions that lead to intended outcomes. Event sequence data is widely collected from many real-world processes, such as electronic health records, web clickstreams, and financial transactions, which transmit a great deal of information reflecting the causal relations among event types. Unfortunately, recovering causalities from observational event sequences is challenging, as the heterogeneous and high-dimensional event variables are often connected to rather complex underlying event excitation mechanisms that are hard to infer from limited observations. Many existing automated causal analysis techniques suffer from poor explainability and fail to include an adequate amount of human knowledge. In this paper, we introduce a visual analytics method for recovering causalities in event sequence data. We extend the Granger causality analysis algorithm on Hawkes processes to incorporate user feedback into causal model refinement. The visualization system includes an interactive causal analysis framework that supports bottom-up causal exploration, iterative causal verification and refinement, and causal comparison through a set of novel visualizations and interactions. We report two forms of evaluation: a quantitative evaluation of the model improvements resulting from the user-feedback mechanism, and a qualitative evaluation through case studies in different application domains to demonstrate the usefulness of the system.", "keywords": "Event sequence data,causality analysis,visual analytics", "link": "http://dx.doi.org/10.1109/TVCG.2020.3030465", "refList": ["10.5555/1642718", "10.1109/tvcg.2018.2865022", "10.5555/2074094.2074151", "10.1109/tvcg.2016.2618797", "10.1073/pnas.1320645111", "10.1109/tvcg.2017.2744843", "10.1109/iv.2017.69", "10.1109/tvcg.2019.2934399", "10.1145/3172944.3173007", "10.5555/1795555", "10.1109/mcg.2005.102", "10.1145/381641.381653", "10.1162/153244301753344614", "10.1111/cgf.14034", "10.1111/cgf.13198", "10.1017/cbo9780511519857", "10.1007/s10462-016-9475-9", "10.1075/ssol.2.2.07bor", "10.1007/978-1-4614-3223-4\\_3", "10.1109/infvis.2003.1249025", "10.1007/978-94-007-6094-313", "10.1145/2858036.2858387", "10.1109/tvcg.2007.70528", "10.1109/tvcg.2017.2674958", "10.1147/sj.454.0801", "10.1109/tvcg.2013.119", "10.1145/3173574.3173711", "10.1016/j.erss.2017.06.034", "10.1109/visual.2019.8933695", "10.1007/s11665-016-2173-6", "10.1016/0377-0427(87)90125-7", "10.2307/3601125", "10.1016/b978-0-444-88738-2.50018-x", "10.1109/mcg.2006.70", "10.1109/tvcg.2018.2865145", "10.1017/s1351324997001502", "10.1109/tvcg.2010.179", "10.1214/aos/1176344552", "10.1109/mcg.2009.22", "10.1007/978-3-319-26633-6\\_13", "10.1080/10447318.2014.905422", "10.1016/j.visinf.2019.03.004", "10.1057/palgrave.ivs.9500074", "10.1007/978-1-4614-3223-4"], "wos": 1, "children": [], "len": 1}], "len": 5}], "len": 9}, {"doi": "10.1109/tvcg.2019.2934631", "title": "Explaining Vulnerabilities to Adversarial Machine Learning through Visual Analytics", "year": "2019", "conferenceName": "VAST", "authors": "Yuxin Ma;Tiankai Xie;Jundong Li;Ross Maciejewski", "citationCount": "5", "affiliation": "Ma, YX (Corresponding Author), Arizona State Univ, Sch Comp Informat \\& Decis Syst Engn, Tempe, AZ 85287 USA. Ma, Yuxin; Xie, Tiankai; Maciejewski, Ross, Arizona State Univ, Sch Comp Informat \\& Decis Syst Engn, Tempe, AZ 85287 USA. Li, Jundong, Univ Virginia, Dept Elect \\& Comp Engn, Charlottesville, VA 22903 USA.", "countries": "USA", "abstract": "Machine learning models are currently being deployed in a variety of real-world applications where model predictions are used to make decisions about healthcare, bank loans, and numerous other critical tasks. As the deployment of artificial intelligence technologies becomes ubiquitous, it is unsurprising that adversaries have begun developing methods to manipulate machine learning models to their advantage. While the visual analytics community has developed methods for opening the black box of machine learning models, little work has focused on helping the user understand their model vulnerabilities in the context of adversarial attacks. In this paper, we present a visual analytics framework for explaining and exploring model vulnerabilities to adversarial attacks. Our framework employs a multi-faceted visualization scheme designed to support the analysis of data poisoning attacks from the perspective of models, data instances, features, and local structures. We demonstrate our framework through two case studies on binary classifiers and illustrate model vulnerabilities with respect to varying attack strategies.", "keywords": "Adversarial machine learning,data poisoning,visual analytics", "link": "http://dx.doi.org/10.1109/TVCG.2019.2934631", "refList": ["10.1109/tvcg.2014.2346578", "10.1109/jbhi.2014.2344095", "10.1109/tvcg.2016.2598838", "10.3390/informatics5030031", "10.1145/1014052.1014066", "10.1109/tvcg.2017.2744938", "10.1145/2089125.2089129", "10.1145/2702123.2702509", "10.1109/vast.2017.8585721", "10.1109/tits.2017.2706978", "10.1109/tvcg.2016.2598828", "10.1109/tvcg.2013.65", "10.1109/vl.1996.545307", "10.1007/s11704-016-6028-y", "10.1007/s10994-010-5188-5", "10.1145/2858036.2858529", "10.1016/j.visinf.2017.01.006", "10.1109/5.726791", "10.1109/tvcg.2018.2864499", "10.1109/tvcg.2018.2864475", "10.1145/3190618", "10.1007/s10462-009-9109-6", "10.1109/tvcg.2018.2865044", "10.1111/cgf.13210", "10.1109/tvcg.2018.2816223", "10.3233/978-1-61499-098-7-870", "10.1109/tvcg.2018.2864504", "10.1109/vast.2017.8585720", "10.1109/tvcg.2014.2346482", "10.1109/tvcg.2014.2346594", "10.1109/tkde.2013.57", "10.1016/j.patcog.2018.07.023", "10.1109/tvcg.2018.2864812", "10.1007/978-3-030-10925-74", "10.1109/tvcg.2017.2744878", "10.1109/msp.2015.2426728", "10.1145/1562849.1562851", "10.1007/978-3-642-40994-325", "10.1109/tvcg.2014.2346660", "10.1038/nature21056", "10.1109/tvcg.2018.2864500", "10.1109/tvcg.2017.2744158", "10.1145/3041008.3041012", "10.1109/tvcg.2018.2865027", "10.1109/tvcg.2014.2346574", "10.1109/tvcg.2017.2744378", "10.1109/sp.2018.00057", "10.1145/2254556.2254651", "10.1109/tvcg.2017.2754480", "10.1109/vast.2011.6102453"], "wos": 1, "children": [{"doi": "10.1109/tvcg.2020.3028888", "title": "A Visual Analytics Framework for Explaining and Diagnosing Transfer Learning Processes", "year": "2020", "conferenceName": "VAST", "authors": "Yuxin Ma;Arlen Fan;Jingrui He;Arun Reddy Nelakurthi;Ross Maciejewski", "citationCount": "0", "affiliation": "Ma, YX (Corresponding Author), Arizona State Univ, Tempe, AZ 85287 USA. Ma, Yuxin; Fan, Arlen; Maciejewski, Ross, Arizona State Univ, Tempe, AZ 85287 USA. He, Jingrui, Univ Illinois, Champaign, IL USA. Nelakurthi, Arun Reddy, Samsung Res Amer, Mountain View, CA USA.", "countries": "USA", "abstract": "Many statistical learning models hold an assumption that the training data and the future unlabeled data are drawn from the same distribution. However, this assumption is difficult to fulfill in real-world scenarios and creates barriers in reusing existing labels from similar application domains. Transfer Learning is intended to relax this assumption by modeling relationships between domains, and is often applied in deep learning applications to reduce the demand for labeled data and training time. Despite recent advances in exploring deep learning models with visual analytics tools, little work has explored the issue of explaining and diagnosing the knowledge transfer process between deep learning models. In this paper, we present a visual analytics framework for the multi-level exploration of the transfer learning processes when training deep neural networks. Our framework establishes a multi-aspect design to explain how the learned knowledge from the existing model is transferred into the new learning task when training deep neural networks. Based on a comprehensive requirement and task analysis, we employ descriptive visualization with performance measures and detailed inspections of model behaviors from the statistical, instance, feature, and model structure levels. We demonstrate our framework through two case studies on image classification by fine-tuning AlexNets to illustrate how analysts can utilize our framework.", "keywords": "Transfer learning,deep learning,visual analytics", "link": "http://dx.doi.org/10.1109/TVCG.2020.3028888", "refList": ["10.1109/tvcg.2014.2346578", "10.1109/tvcg.2019.2934629", "10.1109/tvcg.2017.2744683", "10.1109/tvcg.2016.2598838", "10.1109/tvcg.2017.2744938", "10.1109/tvcg.2019.2934262", "10.1109/tpami.2018.2868685", "10.1145/2702123.2702509", "10.1109/vast.2017.8585721", "10.1109/tvcg.2018.2843369", "10.1109/tvcg.2016.2598828", "10.1111/j.1467-8659.2011.01898.x", "10.1109/tvcg.2013.65", "10.1145/2976749.2978318", "10.1007/978-3-030-01424-7\\_27", "10.1109/tvcg.2019.2934261", "10.1007/s11704-016-6028-y", "10.1016/j.visinf.2017.01.006", "10.1145/2858036.2858529", "10.1109/iccv.2015.279", "10.1109/mci.2018.2840738", "10.1109/tvcg.2019.2892483", "10.1109/vast.2018.8802509", "10.1109/tvcg.2013.124", "10.1186/s40537-016-0043-6", "10.1109/tvcg.2018.2864475", "10.1145/3200489", "10.1109/tvcg.2018.2865044", "10.1111/cgf.13210", "10.1109/tvcg.2018.2816223", "10.23915/distill.00007", "10.1109/tvcg.2017.2744199", "10.1109/tkde.2018.2876857", "10.1109/tvcg.2019.2934631", "10.1109/tvcg.2018.2864504", "10.1109/tvcg.2014.2346482", "10.1109/tvcg.2015.2467618", "10.1109/tvcg.2014.2346594", "10.1109/tvcg.2011.188", "10.1007/978-3-642-15561-1\\_16", "10.1109/tvcg.2018.2864812", "10.1109/mcg.2019.2919033", "10.1109/tvcg.2017.2744718", "10.1109/tvcg.2017.2744878", "10.1109/tvcg.2016.2598541", "10.1109/tkde.2009.191", "10.1145/3065386", "10.1016/j.ins.2016.03.021", "10.1109/tvcg.2019.2903943", "10.1007/s10994-009-5152-4", "10.1109/tvcg.2019.2934659", "10.1109/tvcg.2018.2864500", "10.1109/iccv.2017.74", "10.1109/tvcg.2017.2744158", "10.1109/tvcg.2012.207", "10.1111/cgf.13092", "10.1109/tvcg.2018.2865027", "10.1109/tvcg.2017.2744378", "10.1109/tvcg.2017.2744358", "10.1109/tvcg.2019.2934619", "10.1109/tvcg.2018.2864499", "10.1109/tvcg.2017.2754480", "10.1109/tvcg.2016.2598831"], "wos": 1, "children": [], "len": 1}, {"doi": "10.1111/cgf.14034", "year": "2020", "title": "The State of the Art in Enhancing Trust in Machine Learning Models with the Use of Visualizations", "conferenceName": "EuroVis", "authors": "Angelos Chatzimparmpas;Rafael Messias Martins;Ilir Jusufi;Kostiantyn Kucher;Fabrice Rossi;Andreas Kerren", "citationCount": "2", "affiliation": "Chatzimparmpas, A (Corresponding Author), Linnaeus Univ, Dept Comp Sci \\& Media Technol, Vaxjo, Sweden.\nChatzimparmpas, A.; Martins, R. M.; Jusufi, I.; Kucher, K.; Kerren, A., Linnaeus Univ, Dept Comp Sci \\& Media Technol, Vaxjo, Sweden.\nRossi, F., PSL Univ, Univ Paris Dauphine, Ceremade, Paris, France.", "countries": "Sweden;France", "abstract": "Machine learning (ML) models are nowadays used in complex applications in various domains, such as medicine, bioinformatics, and other sciences. Due to their black box nature, however, it may sometimes be hard to understand and trust the results they provide. This has increased the demand for reliable visualization tools related to enhancing trust in ML models, which has become a prominent topic of research in the visualization community over the past decades. To provide an overview and present the frontiers of current research on the topic, we present a State-of-the-Art Report (STAR) on enhancing trust in ML models with the use of interactive visualization. We define and describe the background of the topic, introduce a categorization for visualization techniques that aim to accomplish this goal, and discuss insights and opportunities for future research directions. Among our contributions is a categorization of trust against different facets of interactive ML, expanded and improved from previous research. Our results are investigated from different analytical perspectives: (a) providing a statistical overview, (b) summarizing key findings, (c) performing topic analyses, and (d) exploring the data sets used in the individual papers, all with the support of an interactive web-based survey browser. We intend this survey to be beneficial for visualization researchers whose interests involve making ML models more trustworthy, as well as researchers and practitioners from other disciplines in their search for effective visualization techniques suitable for solving their tasks with confidence and conveying meaning to their data.", "keywords": "trustworthy machine learning; visualization; interpretable machine learning; explainable machine learning", "link": "https://doi.org/10.1111/cgf.14034", "refList": ["10.1109/mcg.2018.2878902", "10.1109/tvcg.2008.153", "10.2312/mlvis.20181130", "10.1109/tvcg.2016.2598828", "10.1145/3290605.3300911", "10.1145/2993901.2993909", "10.2312/mlvis.20191158", "10.1109/tvcg.2016.2598446", "10.1111/j.1467-8659.2009.01475.x", "10.1145/3290605.3300809", "10.1109/pacificvis.2018.00031", "10.1055/s-0029-1216348", "10.1007/978-3-319-90403-0\\_13", "10.1109/tvcg.2017.2745085", "10.1111/j.1467-8659.2011.01938.x", "10.1007/978-3-319-54024-5\\_6", "10.1016/s0167-9473(01)00065-2", "10.1111/cgf.12895", "10.2312/eurovisshort.20141152.17", "10.2312/eurova.20151098.22", "10.1111/cgf.13667", "10.3115/1072228.1072378", "10.1109/tbdata.2018.2877350.16", "10.1109/lars.2009.5418323.25", "10.1109/tvcg.2017.2744878", "10.1016/j.combustflame.2005.09.018", "10.1016/j.cag.2014.01.006", "10.1109/tvcg.2016.2570755", "10.2312/mlvis.20191158.1,19", "10.1518/hfes.46.1.50.30392", "10.1145/3301275.3302280", "10.1145/3351095.3372834.1", "10.1016/s0377-2217(01)00264-8", "10.1111/cgf.13424", "10.1007/978-3-319-23485-4\\_53", "10.1007/978-94-007-0753-5\\_3623", "10.1109/tvcg.2013.101", "10.1111/cgf.12884", "10.1111/j.1467-8659.2010.01835.x", "10.1021/ci9901338", "10.4230/lipics.itcs:2017", "10.1109/mis.2013.24", "10.1109/tvcg.2014.2346482", "10.1109/tvcg.2018.2865230", "10.1073/pnas.1807180116", "10.1109/dsaa.2018.00018", "10.1109/tvcg.2009.153", "10.3115/1219840.1219855", "10.1109/tvcg.2018.2864812", "10.1109/tvcg.2018.2872577", "10.2312/trvis.20191183", "10.1109/cvpr:2004.383", "10.1109/vast.2008.4677350", "10.1145/302979.303001", "10.1109/tvcg.2018.2864499", "10.1111/cgf.13672", "10.1109/tvcg.2014.2346626", "10.23915/distill.00010.18", "10.1109/tvcg.2017.2744805", "10.2312/mlvis:20191160.18", "10.23915/distill:00016", "10.1109/pacificvis.2016.7465260", "10.1111/cgf.13683", "10.23915/distill.00016.19", "10.1145/32906053.300803.22", "10.1109/tvcg.2014.2346574", "10.1177/1473871615600010", "10.1109/tvcg.2016.2598831", "10.1145/3230623", "10.1109/visual.2019.8933744", "10.1145/2993901.2993915", "10.1016/j.visinf.2017.01.006", "10.1145/2993901.2993914", "10.1109/tvcg.2014.2346984", "10.1109/5.726791", "10.23915/distill.00010", "10.1109/tvcg.2018.2864825", "10.2307/2394164", "10.1109/tvcg.2017.2744458", "10.1145/2993901.2993917.28", "10.1111/cgf.13711", "10.1109/tvcg.2016.2598664", "10.2307/2530428", "10.1109/icdar.1997.620583", "10.1109/tvcg.2017.2744718", "10.1111/cgf.13425", "10.1109/tvcg.2019.2903943", "10.1145/1518701.1518895", "10.1109/tvcg.2018.2864838", "10.1145/62038.62043", "10.1111/j.1467-8659.2011.01920.x", "10.1145/3025171.3025208", "10.1145/355112.355124", "10.1109/vast.2010.5652398", "10.1109/tvcg.2014.2346578", "10.1145/3173574.3174209", "10.4178/epih/e2014008", "10.1109/beliv.2018.8634201.25,28", "10.1016/j.eswa.2007.12.020", "10.1111/cgf:13406", "10.1109/mcg.2011.103", "10.1631/fitee.1700808", "10.1109/tvcg.2017.2745158", "10.1073/pnas.0307752101", "10.1109/tvcg.2018.2816223", "10.1109/tvcg.2017.2745141", "10.1145/32232.32234", "10.1109/tvcg.2019.2934267", "10.1109/tvcg.2018.2864477", "10.1145/3132169", "10.2312/eurova.20151100.19", "10.1145/3172944.3172964", "10.1145/2601248.2601268", "10.1109/isai-nlp.2018.8693002.1", "10.1111/cgf.13404", "10.1007/s100320200071", "10.2312/trvis.20191183.16", "10.1111/cgf.12755", "10.1145/2702123.2702509", "10.1145/1401890.1402008.25", "10.1109/tvcg.2012.65", "10.1177/1473871617733996", "10.2312/trvis.20191187.7", "10.21236/ada273556", "10.1109/vast.2010.5652450", "10.1111/j.1467-8659.2011.01940.x", "10.1177/875647939000600106", "10.1109/tvcg.2017.2711030", "10.1016/j.immuni.2016.04.014", "10.1109/tvcg.2019.2934209", "10.1016/0095-0696(78)90006-2", "10.1016/j.jclinepi.2015.04.014", "10.1016/j.ress.2013.02.013", "10.1111/cgf.12640", "10.1145/1015330.1015388.25", "10.1111/j.1467-8659.2009.01468.x", "10.1145/1541880.1541882", "10.1109/vast.2011.6102453", "10.1016/s0008-8846(98)00165-3", "10.2312/trvis.20191186.7", "10.1007/s13748-013-0040-3", "10.1109/tvcg.2015.2467757", "10.1109/tbdata.2018.2877350", "10.1109/vast.2017.8585613", "10.1080/10556789208805504", "10.1109/vast.2012.6400484", "10.1145/3025171.3025181", "10.1007/978-3-319-90403-0\\_12", "10.1109/mcg.2019.2922592", "10.1021/ci000392t", "10.1109/vast.2007.4389000", "10.1111/cgf.13406.16", "10.1111/cgf.13684", "10.2312/eurovisshort.20161166.17", "10.2312/evs:20191168", "10.1145/3041021.3055135", "10.1145/3301275.3302265", "10.1613/jair.4135", "10.1109/tvcg.2018.2864500", "10.1109/tvcg.2017.2744158", "10.1109/ssci.2015.33", "10.1111/cgf.13453", "10.2312/pe/eurovast/eurova11/049-052", "10.1145/3025171.3025181.13", "10.1145/371920.372094", "10.1109/tvcg.2017.2744938", "10.1111/j.1467-8659.2012.03108.x", "10.1109/tvcg.2019.2934251", "10.1145/3290605.3300809.18", "10.1109/ldav.2016.7874305", "10.1109/vast.2016.7883514", "10.1109/iccv.2015.425", "10.1145/3301275.3302324", "10.1109/tnnls.2013.2292894", "10.1109/tvcg.2018.2865044", "10.1109/tvcg.2013.157", "10.1371/journal.pcbi.0020161", "10.1186/s12916-019-1426-2", "10.1109/10.867928", "10.1111/cgf.13217", "10.1109/mcg.2019.2919033", "10.1145/2993901.2993910", "10.1109/tvcg.2017.2744738", "10.2307/258792", "10.1111/cgf.12655", "10.1016/j.dss.2014.03.001", "10.1109/tvcg.2019.2904069", "10.1111/cgf.13205", "10.1002/mds.22340", "10.1109/tvcg.2019.2934595", "10.1287/inte.2018.0957", "10.1109/cvpr.2007.382974", "10.1109/tvcg.2012.280", "10.1145/2678025.2701399.13", "10.2312/mlvis.20181130.13", "10.2312/eurova.20181106.16", "10.1109/tvcg.2018.2864475", "10.2312/mlvis.20191160.18,22", "10.1007/978-1-4612-4026-6.25", "10.1109/cvpr.2006.42", "10.1145/3172944.3172950", "10.1109/cvpr.2004.383.25", "10.1109/tvcg.2019.2934812", "10.1609/aimag.v35i4.2513", "10.2312/trvis.20191185.7", "10.1111/j.1467-8659.2009.01684.x", "10.1371/journal.pone.0129126", "10.1111/cgf.13092", "10.1162/coli\\_a\\_00237", "10.1109/tvcg.2017.2744818", "10.1109/vast.2011.6102448", "10.1109/tvcg.2009.111", "10.1109/tvcg.2019.2934619", "10.1016/s0377-2217(01)00264-8.25", "10.1111/cgf.12639", "10.1109/access.2019.2919343", "10.1186/s12874-019-0681-4", "10.1109/pacificvis.2015.7156366", "10.1109/pacificvis.2018.00029", "10.1109/tvcg.2019.2934261", "10.1080/13506280444000102.http://www.uvt.nl/ticc", "10.1109/vast.2018.8802509", "10.1111/cgf.13212", "10.1145/3200489", "10.1111/cgf.13176", "10.1177/1473871620904671", "10.1007/978-3-319-10590-1\\_53", "10.1111/j.1467-8659.2012.03126.x", "10.1111/cgf.13172", "10.1145/3025171.3025208.6,21", "10.1111/cgf.12366", "10.1109/tvcg.2019.2934659", "10.1109/cvprw.2009.5206848", "10.1016/j.media.2014.11.010", "10.1109/tvcg.2017.2744683", "10.1109/tvcg.2019.2934262", "10.1016/j.neucom.2006.11.018", "10.1177/1473871615571951", "10.1371/journal.pcbi.0020161.25", "10.1177/1473871611415994", "10.2312/trvis20191187", "10.2312/eurova", "10.1145/2858036.2858529", "10.1145/2207676.2207738", "10.1007/s11042-009-0417-2", "10.1145/3301275.3302317", "10.1038/s41746-019-0148-3", "10.1145/3351095.3372834", "10.1080/10691898.2011.11889627", "10.1109/tvcg.2018.2864504", "10.1109/vast.2017.8585720", "10.1109/mcg.2018.053491732", "10.1007/s10994-010-5207-6", "10.1109/tvcg.2019.2934433", "10.1016/j.cag.2017.05.005", "10.1109/tvcg.2012.279", "10.1145/3231622.3231641.19,20", "10.1145/1562849.1562851", "10.1007/11564126\\_", "10.1109/tvcg.2018.2846735", "10.3115/1225403.1225421", "10.1109/vast.2012.6400486", "10.2312/eurova.20191116.22", "10.1109/tvcg.2007.70443", "10.1080/027868291009242", "10.2312/eurova.20151100", "10.1145/2939502.2939503.19", "10.1016/j.cag.2014.02.004", "10.1145/2939672.2939778", "10.1109/vast.2010.5652484", "10.1111/cgf.12641", "10.1145/3301275.3302289", "10.1109/visual.2019.8933619", "10.1109/tvcg.2017.2672987", "10.1109/vast.2016.7883517.20", "10.1109/igarss.2017.8127684", "10.1016/j.jcae.2010.04.002", "10.1109/vast.2010.5652885", "10.1016/j.visinf.2019.03.002", "10.1007/s00371-018-1500-3", "10.1109/mcg.2018.042731661", "10.1109/34.598228", "10.1109/tvcg.2018.2865027", "10.1016/j.neucom.2017.01.105", "10.1111/cgf.12389", "10.1109/tvcg.2019.2934591", "10.1109/vast.2010.5652392.16", "10.1111/cgf.13416", "10.1080/02701367.1992.10608764", "10.1109/vast.2017.8585721", "10.1109/tvcg.2018.2843369", "10.1109/sbes.2010.27", "10.1109/vast.2015.7347637", "10.1145/1401890.1402008", "10.1016/j.bpj.2010.04.064", "10.1109/tvcg.2013.125", "10.1109/isai-nlp.2018.8693002", "10.1371/journal.pone.0160127", "10.1145/2856767.2856779", "10.1145/2678025.2701399", "10.1109/vast.2011.6102451", "10.1109/mcg.2010.18", "10.1021/ci4000213", "10.1109/vast.2012.6400492", "10.1007/11564126-49.25", "10.2312/eurova.20171114", "10.1109/vast.2010.5652443", "10.1145/3134599", "10.2312/pe/eurovast/eurovast10/013-018.19", "10.1109/tvcg.2019.2903946", "10.1109/tvcg.2015.2467717", "10.1177/1473871612460526", "10.1016/j.cag.2018.09.018", "10.1109/tvcg.2016.2598838", "10.1145/3172944.3172964.14", "10.1109/vast.2009.5333428", "10.1109/vast.2014.7042480", "10.2312/pe/eurovast/eurovast10/013-018", "10.1177/0962280215588241", "10.1145/2993901.2993917", "10.1109/cvpr.2008:4587581", "10.1109/tvcg.2015.2467551", "10.1016/j.visinf.2018.09.001", "10.1126/science.290.5500.2319", "10.2312/eurova.20151107", "10.1109/visual.2019.8933695", "10.13140/2.1.2393.1847", "10.1197/jamia.m1929", "10.1109/cvpr.2008.4587581.25", "10.1145/1518701.1518895.16", "10.1109/vds.2017.8573444", "10.2312/trvis:20191185", "10.1145/3359786", "10.13140/2.1.1341.1520", "10.2312/pe/eurovast/eurova11/049-052.17", "10.1109/tvcg.2014.2346660", "10.1145/3185517", "10.1109/adprl.2011.5967372", "10.1109/tvcg.2015.2467591", "10.1111/j.1751-9004.2009.00232.x", "10.1136/qshc.2004.010033", "10.1109/vast.2012.6400493", "10.1109/tvcg.2019.2934266", "10.1145/2971763.2971775", "10.1111/cgf.13730", "10.1109/vast.2012.6400488", "10.1111/cgf.13210", "10.1109/tvcg.2019.2934631", "10.1145/3172944.3172965", "10.1057/ivs.2010.2", "10.1109/tvcg.2017.2745258", "10.1016/j.jbusres.2019.07.039", "10.1162/jmlr.2003.3.4-5.993", "10.1109/pacificvis.2019.00044", "10.2312/pe/eurovast/eurova12/037-041", "10.1109/tvcg.2019.2934629", "10.1177/0018720814547570", "10.1145/3292500.3330908", "10.1111/j.1467-8659.2009.01467.x", "10.2312/eurova.20151098", "10.1177/1473871617713337", "10.1109/lars:2009.5418323", "10.1109/vast.2011.6102437", "10.1111/cgf.12878", "10.1561/1500000001", "10.1145/3025171.3025222", "10.1007/s11704-016-6028-y", "10.1016/j.procs.2017.05.216", "10.1109/cvpr.2007.382974.25", "10.1080/10447318.2020.1741118", "10.1109/vast.2012.6400489", "10.1145/3025171.3025172", "10.1109/tvcg.2017.2744098", "10.1109/tvcg.2005.66", "10.1016/j.dss.2009.05.016", "10.1007/978-1-4612-4026-6", "10.2312/evs.20191168.16,20,28", "10.2312/pe/eurovast/eurova12/037-041.17", "10.1145/3290605.3300803", "10.1145/1015330.1015388", "10.1111/cgf.13197", "10.1016/b978-1-55860-377-6.50048-7", "10.1111/cgf.13681", "10.1109/tvcg.2017.2744378", "10.1109/tvcg.2017.2744358", "10.1109/vast.2008.4677352"], "wos": 1, "children": [{"doi": "10.1109/tvcg.2020.3030368", "title": "Implicit Multidimensional Projection of Local Subspaces", "year": "2020", "conferenceName": "InfoVis", "authors": "Rongzheng Bian;Yumeng Xue;Liang Zhou;Jian Zhang 0070;Baoquan Chen;Daniel Weiskopf;Yunhai Wang", "citationCount": "1", "affiliation": "Wang, YH (Corresponding Author), Shandong Univ, Qingdao, Peoples R China. Zhou, L (Corresponding Author), Univ Utah, Salt Lake City, UT 84112 USA. Bian, Rongzheng; Xue, Yumeng; Wang, Yunhai, Shandong Univ, Qingdao, Peoples R China. Chen, Baoquan, Peking Univ, Beijing, Peoples R China. Zhang, Jian, Chinese Acad Sci, CNIC, Beijing, Peoples R China. Zhou, Liang, Univ Utah, Salt Lake City, UT 84112 USA. Weiskopf, Daniel, Univ Stuttgart, Stuttgart, Germany.", "countries": "USA;Germany;China", "abstract": "We propose a visualization method to understand the effect of multidimensional projection on local subspaces, using implicit function differentiation. Here, we understand the local subspace as the multidimensional local neighborhood of data points. Existing methods focus on the projection of multidimensional data points, and the neighborhood information is ignored. Our method is able to analyze the shape and directional information of the local subspace to gain more insights into the global structure of the data through the perception of local structures. Local subspaces are fitted by multidimensional ellipses that are spanned by basis vectors. An accurate and efficient vector transformation method is proposed based on analytical differentiation of multidimensional projections formulated as implicit functions. The results are visualized as glyphs and analyzed using a full set of specifically-designed interactions supported in our efficient web-based visualization tool. The usefulness of our method is demonstrated using various multi- and high-dimensional benchmark datasets. Our implicit differentiation vector transformation is evaluated through numerical comparisons; the overall method is evaluated through exploration examples and use cases.", "keywords": "High-dimensional data visualization,dimensionality reduction,local linear subspaces,user interaction", "link": "http://dx.doi.org/10.1109/TVCG.2020.3030368", "refList": ["10.3844/jcssp.2018.613.622", "10.1016/j.aci.2018.08.003", "10.3390/info9030065", "10.1016/j.visinf.2018.09.003", "10.1371/journal.pone.0118432", "10.1016/s0893-6080(05)80023-1", "10.1109/tvcg.2020.2986996", "10.1109/icst.2012.56", "10.1007/s10844-013-0250-y", "10.1109/tbdata.2018", "10.1145/1125451.1125659", "10.1109/tvcg.2013.125", "10.1177/1473871611412817", "10.1145/3290605.3300911", "10.1111/cgf.14034", "10.1007/s13721-013-0034-x", "10.1016/j.procs.2017.05.216", "10.1016/j.ins.2009.08.025", "10.1109/tvcg.2013.124", "10.1109/tvcg.2018.2864499", "10.1109/tvcg.2018.2864475", "10.1080/10447318.2020.1741118", "10.1016/j.imu.2019.100203", "10.1109/tvcg.2018.2865240", "10.1186/s12864-019-6413-7", "10.1109/tvcg.2015.2467551", "10.1002/widm.1249", "10.1007/978-3-319-66429-3\\_29", "10.1109/tvcg.2014.2346481", "10.1109/tvcg.2018.2864825", "10.1177/1473871620904671", "10.1109/tvcg.2019.2934267", "10.1136/bmjopen-2016-012799", "10.1109/smartgridcomm.2017.8340682", "10.1007/s10664-015-9401-9", "10.1145/1143844.1143874", "10.1111/cgf.12389", "10.1109/tvcg.2018.2872577", "10.1007/978-981-13-5802-9\\_20", "10.1016/j.ipm.2009.03.002", "10.5220/0006431602160222", "10.1109/mcg.2015.50", "10.1109/tvcg.2014.2346574", "10.1007/bf02289565", "10.1109/tvcg.2017.2744378", "10.1016/j.patrec.2008.08.010", "10.1023/a:1010933404324", "10.9735/2229-3981"], "wos": 1, "children": [], "len": 1}, {"doi": "10.1109/tvcg.2020.3030465", "title": "Visual Causality Analysis of Event Sequence Data", "year": "2020", "conferenceName": "VAST", "authors": "Zhuochen Jin;Shunan Guo;Nan Chen;Daniel Weiskopf;David Gotz;Nan Cao", "citationCount": "0", "affiliation": "Cao, N (Corresponding Author), Tongji Univ, IDVx Lab, Shanghai, Peoples R China. Jin, Zhuochen; Guo, Shunan; Chen, Nan; Cao, Nan, Tongji Univ, IDVx Lab, Shanghai, Peoples R China. Weiskopf, Daniel, Univ Stuttgart, Stuttgart, Germany. Gotz, David, Univ N Carolina, Chapel Hill, NC 27515 USA.", "countries": "USA;Germany;China", "abstract": "Causality is crucial to understanding the mechanisms behind complex systems and making decisions that lead to intended outcomes. Event sequence data is widely collected from many real-world processes, such as electronic health records, web clickstreams, and financial transactions, which transmit a great deal of information reflecting the causal relations among event types. Unfortunately, recovering causalities from observational event sequences is challenging, as the heterogeneous and high-dimensional event variables are often connected to rather complex underlying event excitation mechanisms that are hard to infer from limited observations. Many existing automated causal analysis techniques suffer from poor explainability and fail to include an adequate amount of human knowledge. In this paper, we introduce a visual analytics method for recovering causalities in event sequence data. We extend the Granger causality analysis algorithm on Hawkes processes to incorporate user feedback into causal model refinement. The visualization system includes an interactive causal analysis framework that supports bottom-up causal exploration, iterative causal verification and refinement, and causal comparison through a set of novel visualizations and interactions. We report two forms of evaluation: a quantitative evaluation of the model improvements resulting from the user-feedback mechanism, and a qualitative evaluation through case studies in different application domains to demonstrate the usefulness of the system.", "keywords": "Event sequence data,causality analysis,visual analytics", "link": "http://dx.doi.org/10.1109/TVCG.2020.3030465", "refList": ["10.5555/1642718", "10.1109/tvcg.2018.2865022", "10.5555/2074094.2074151", "10.1109/tvcg.2016.2618797", "10.1073/pnas.1320645111", "10.1109/tvcg.2017.2744843", "10.1109/iv.2017.69", "10.1109/tvcg.2019.2934399", "10.1145/3172944.3173007", "10.5555/1795555", "10.1109/mcg.2005.102", "10.1145/381641.381653", "10.1162/153244301753344614", "10.1111/cgf.14034", "10.1111/cgf.13198", "10.1017/cbo9780511519857", "10.1007/s10462-016-9475-9", "10.1075/ssol.2.2.07bor", "10.1007/978-1-4614-3223-4\\_3", "10.1109/infvis.2003.1249025", "10.1007/978-94-007-6094-313", "10.1145/2858036.2858387", "10.1109/tvcg.2007.70528", "10.1109/tvcg.2017.2674958", "10.1147/sj.454.0801", "10.1109/tvcg.2013.119", "10.1145/3173574.3173711", "10.1016/j.erss.2017.06.034", "10.1109/visual.2019.8933695", "10.1007/s11665-016-2173-6", "10.1016/0377-0427(87)90125-7", "10.2307/3601125", "10.1016/b978-0-444-88738-2.50018-x", "10.1109/mcg.2006.70", "10.1109/tvcg.2018.2865145", "10.1017/s1351324997001502", "10.1109/tvcg.2010.179", "10.1214/aos/1176344552", "10.1109/mcg.2009.22", "10.1007/978-3-319-26633-6\\_13", "10.1080/10447318.2014.905422", "10.1016/j.visinf.2019.03.004", "10.1057/palgrave.ivs.9500074", "10.1007/978-1-4614-3223-4"], "wos": 1, "children": [], "len": 1}], "len": 5}, {"doi": "10.1111/cgf.13972", "year": "2020", "title": "Boxer: Interactive Comparison of Classifier Results", "conferenceName": "EuroVis", "authors": "Michael Gleicher;Aditya Barve;Xinyi Yu;Florian Heimerl", "citationCount": "0", "affiliation": "Gleicher, M (Corresponding Author), Univ Wisconsin, Madison, WI 53706 USA.\nGleicher, Michael; Barve, Aditya; Yu, Xinyi; Heimerl, Florian, Univ Wisconsin, Madison, WI 53706 USA.", "countries": "USA", "abstract": "Machine learning practitioners often compare the results of different classifiers to help select, diagnose and tune models. We present Boxer, a system to enable such comparison. Our system facilitates interactive exploration of the experimental results obtained by applying multiple classifiers to a common set of model inputs. The approach focuses on allowing the user to identify interesting subsets of training and testing instances and comparing performance of the classifiers on these subsets. The system couples standard visual designs with set algebra interactions and comparative elements. This allows the user to compose and coordinate views to specify subsets and assess classifier performance on them. The flexibility of these compositions allow the user to address a wide range of scenarios in developing and assessing classifiers. We demonstrate Boxer in use cases including model selection, tuning, fairness assessment, and data quality diagnosis.", "keywords": "", "link": "https://doi.org/10.1111/cgf.13972", "refList": ["10.1109/tvcg.2019.2934629", "10.1109/tvcg.2017.2744359", "10.1109/tvcg.2016.2598838", "10.1007/s10618-014-0368-8", "10.1109/tvcg.2017.2744938", "10.1109/tvcg.2019.2934262", "10.1145/3287560.3287589", "10.1109/vast.2017.8585721", "10.1109/tvcg.2016.2598828", "10.1109/tvcg.2009.128", "10.1109/tvcg.2017.2744018", "10.1080/00994480.2000.10748487", "10.5555/3305890.3306024", "10.1109/iccv.2015.329", "10.1109/tvcg.2013.125", "10.1089/big.2016.0007", "10.1109/memsys.2019.8870817", "10.1145/2939672.2939778", "10.1007/s11104-019-04156-0", "10.1371/journal.pone.0181142", "10.1145/3301275.3302324", "10.1109/tvcg.2017.2745158", "10.1109/tvcg.2018.2865044", "10.1023/a:1010933404324", "10.1145/2487575.2487579", "10.1109/tvcg.2013.157", "10.1145/2783258.2788613", "10.1109/tvcg.2017.2744199", "10.1109/tvcg.2019.2934631", "10.1016/s0304-3800(02)00064-9", "10.1007/s10115-013-0679-x", "10.1109/tvcg.2019.2934267", "10.1007/978-3-319-10590-1\\_53", "10.1109/vast.2017.8585720", "10.1016/0004-3702(80)90021-1", "10.1109/tvcg.2015.2467618", "10.1109/tvcg.2018.2864477", "10.1109/tvcg.2009.84", "10.1007/s11263-016-0911-8", "10.1111/cgf.12918", "10.1111/cgf.12373", "10.1109/tvcg.2017.2744878", "10.1109/tvcg.2018.2864812", "10.1109/mcg.2019.2919033", "10.1080/00207176808905715", "10.1002/er.3827", "10.1109/tvcg.2014.2346660", "10.1111/cgf.13417", "10.1109/tvcg.2019.2934659", "10.1109/tvcg.2017.2744158", "10.1016/b978-0-12-815849-4.00004-9", "10.1097/ede.0b013e3181c30fb2", "10.1111/cgf.13681", "10.1016/j.ejor.2006.04.051", "10.1109/tvcg.2019.2934619", "10.1109/tvcg.2016.2598468", "10.9735/2229-3981", "10.1109/tvcg.2016.2598831"], "wos": 1, "children": [], "len": 1}], "len": 11}, {"doi": "10.1109/tvcg.2019.2934591", "title": "NNVA: Neural Network Assisted Visual Analysis of Yeast Cell Polarization Simulation", "year": "2019", "conferenceName": "VAST", "authors": "Subhashis Hazarika;Haoyu Li;Ko-Chih Wang;Han-Wei Shen;Ching-Shan Chou", "citationCount": "0", "affiliation": "Hazarika, S (Corresponding Author), Ohio State Univ, Dept Comp Sci, Columbus, OH 43210 USA. Hazarika, Subhashis; Li, Haoyu; Wang, Ko-Chih; Shen, Han-Wei, Ohio State Univ, Dept Comp Sci, Columbus, OH 43210 USA. Chou, Ching-Shan, Ohio State Univ, Dept Math, 231 W 18th Ave, Columbus, OH 43210 USA.", "countries": "USA", "abstract": "Complex computational models are often designed to simulate real-world physical phenomena in many scientific disciplines. However, these simulation models tend to be computationally very expensive and involve a large number of simulation input parameters, which need to be analyzed and properly calibrated before the models can be applied for real scientific studies. We propose a visual analysis system to facilitate interactive exploratory analysis of high-dimensional input parameter space for a complex yeast cell polarization simulation. The proposed system can assist the computational biologists, who designed the simulation model, to visually calibrate the input parameters by modifying the parameter values and immediately visualizing the predicted simulation outcome without having the need to run the original expensive simulation for every instance. Our proposed visual analysis system is driven by a trained neural network-based surrogate model as the backend analysis framework. In this work, we demonstrate the advantage of using neural networks as surrogate models for visual analysis by incorporating some of the recent advances in the field of uncertainty quantification, interpretability and explainability of neural network-based models. We utilize the trained network to perform interactive parameter sensitivity analysis of the original simulation as well as recommend optimal parameter configurations using the activation maximization framework of neural networks. We also facilitate detail analysis of the trained network to extract useful insights about the simulation model, learned by the network, during the training process. We performed two case studies, and discovered multiple new parameter configurations, which can trigger high cell polarization results in the original simulation model. We evaluated our results by comparing with the original simulation model outcomes as well as the findings from previous parameter analysis performed by our experts.", "keywords": "Surrogate modeling,Neural networks,Computational biology,Visual analysis,Parameter analysis", "link": "http://dx.doi.org/10.1109/TVCG.2019.2934591", "refList": ["10.1080/13685538.2018.1484443", "10.1016/j.swevo.2011.05.001", "10.1109/tvcg.2017.2744683", "10.1109/21.97458", "10.1109/tvcg.2018.2864503", "10.1109/tvcg.2018.2864887", "10.1109/vast.2017.8585721", "10.3354/cr01213", "10.1016/j.paerosci.2005.02.001", "10.1038/nbt.3300", "10.1038/nature02771", "10.1111/j.1467-8659.2012.03108.x", "10.1145/2089094.2089101", "10.1109/tvcg.2013.147", "10.1016/j.ins.2012.10.039", "10.1109/tvcg.2018.2864843", "10.1109/tvcg.2018.2865051", "10.1029/2011wr011527", "10.1109/tvcg.2018.2864499", "10.1007/bf00547132", "10.1109/tvcg.2018.2865044", "10.1109/tvcg.2018.2816223", "10.1109/tvcg.2018.2865026", "10.1109/tvcg.2018.2864504", "10.1111/j.1467-8659.2011.01940.x", "10.1016/j.dsp.2017.10.011", "10.1109/tvcg.2014.2346321", "10.1007/978-3-319-14445-0\\_9", "10.1038/89044", "10.1109/tvcg.2018.2865029", "10.1109/tvcg.2017.2764895", "10.1109/tvcg.2017.2744718", "10.1109/tvcg.2017.2744878", "10.1080/14786435.2010.546377", "10.1177/003754979205800610", "10.5555/3045390.3045502", "10.1109/tvcg.2019.2903943", "10.1109/tvcg.2018.2864500", "10.1109/tvcg.2017.2744158", "10.1109/iccv.2013.8", "10.1016/j.jneumeth.2016.10.008", "10.1111/j.1467-8659.2009.01684.x", "10.1111/cgf.13092", "10.1145/1081870.1081886", "10.1109/tvcg.2016.2598830", "10.1109/tvcg.2009.23", "10.1109/tvcg.2016.2598869", "10.1038/ncomms13890", "10.1109/tvcg.2016.2598831"], "wos": 1, "children": [{"doi": "10.1111/cgf.14034", "year": "2020", "title": "The State of the Art in Enhancing Trust in Machine Learning Models with the Use of Visualizations", "conferenceName": "EuroVis", "authors": "Angelos Chatzimparmpas;Rafael Messias Martins;Ilir Jusufi;Kostiantyn Kucher;Fabrice Rossi;Andreas Kerren", "citationCount": "2", "affiliation": "Chatzimparmpas, A (Corresponding Author), Linnaeus Univ, Dept Comp Sci \\& Media Technol, Vaxjo, Sweden.\nChatzimparmpas, A.; Martins, R. M.; Jusufi, I.; Kucher, K.; Kerren, A., Linnaeus Univ, Dept Comp Sci \\& Media Technol, Vaxjo, Sweden.\nRossi, F., PSL Univ, Univ Paris Dauphine, Ceremade, Paris, France.", "countries": "Sweden;France", "abstract": "Machine learning (ML) models are nowadays used in complex applications in various domains, such as medicine, bioinformatics, and other sciences. Due to their black box nature, however, it may sometimes be hard to understand and trust the results they provide. This has increased the demand for reliable visualization tools related to enhancing trust in ML models, which has become a prominent topic of research in the visualization community over the past decades. To provide an overview and present the frontiers of current research on the topic, we present a State-of-the-Art Report (STAR) on enhancing trust in ML models with the use of interactive visualization. We define and describe the background of the topic, introduce a categorization for visualization techniques that aim to accomplish this goal, and discuss insights and opportunities for future research directions. Among our contributions is a categorization of trust against different facets of interactive ML, expanded and improved from previous research. Our results are investigated from different analytical perspectives: (a) providing a statistical overview, (b) summarizing key findings, (c) performing topic analyses, and (d) exploring the data sets used in the individual papers, all with the support of an interactive web-based survey browser. We intend this survey to be beneficial for visualization researchers whose interests involve making ML models more trustworthy, as well as researchers and practitioners from other disciplines in their search for effective visualization techniques suitable for solving their tasks with confidence and conveying meaning to their data.", "keywords": "trustworthy machine learning; visualization; interpretable machine learning; explainable machine learning", "link": "https://doi.org/10.1111/cgf.14034", "refList": ["10.1109/mcg.2018.2878902", "10.1109/tvcg.2008.153", "10.2312/mlvis.20181130", "10.1109/tvcg.2016.2598828", "10.1145/3290605.3300911", "10.1145/2993901.2993909", "10.2312/mlvis.20191158", "10.1109/tvcg.2016.2598446", "10.1111/j.1467-8659.2009.01475.x", "10.1145/3290605.3300809", "10.1109/pacificvis.2018.00031", "10.1055/s-0029-1216348", "10.1007/978-3-319-90403-0\\_13", "10.1109/tvcg.2017.2745085", "10.1111/j.1467-8659.2011.01938.x", "10.1007/978-3-319-54024-5\\_6", "10.1016/s0167-9473(01)00065-2", "10.1111/cgf.12895", "10.2312/eurovisshort.20141152.17", "10.2312/eurova.20151098.22", "10.1111/cgf.13667", "10.3115/1072228.1072378", "10.1109/tbdata.2018.2877350.16", "10.1109/lars.2009.5418323.25", "10.1109/tvcg.2017.2744878", "10.1016/j.combustflame.2005.09.018", "10.1016/j.cag.2014.01.006", "10.1109/tvcg.2016.2570755", "10.2312/mlvis.20191158.1,19", "10.1518/hfes.46.1.50.30392", "10.1145/3301275.3302280", "10.1145/3351095.3372834.1", "10.1016/s0377-2217(01)00264-8", "10.1111/cgf.13424", "10.1007/978-3-319-23485-4\\_53", "10.1007/978-94-007-0753-5\\_3623", "10.1109/tvcg.2013.101", "10.1111/cgf.12884", "10.1111/j.1467-8659.2010.01835.x", "10.1021/ci9901338", "10.4230/lipics.itcs:2017", "10.1109/mis.2013.24", "10.1109/tvcg.2014.2346482", "10.1109/tvcg.2018.2865230", "10.1073/pnas.1807180116", "10.1109/dsaa.2018.00018", "10.1109/tvcg.2009.153", "10.3115/1219840.1219855", "10.1109/tvcg.2018.2864812", "10.1109/tvcg.2018.2872577", "10.2312/trvis.20191183", "10.1109/cvpr:2004.383", "10.1109/vast.2008.4677350", "10.1145/302979.303001", "10.1109/tvcg.2018.2864499", "10.1111/cgf.13672", "10.1109/tvcg.2014.2346626", "10.23915/distill.00010.18", "10.1109/tvcg.2017.2744805", "10.2312/mlvis:20191160.18", "10.23915/distill:00016", "10.1109/pacificvis.2016.7465260", "10.1111/cgf.13683", "10.23915/distill.00016.19", "10.1145/32906053.300803.22", "10.1109/tvcg.2014.2346574", "10.1177/1473871615600010", "10.1109/tvcg.2016.2598831", "10.1145/3230623", "10.1109/visual.2019.8933744", "10.1145/2993901.2993915", "10.1016/j.visinf.2017.01.006", "10.1145/2993901.2993914", "10.1109/tvcg.2014.2346984", "10.1109/5.726791", "10.23915/distill.00010", "10.1109/tvcg.2018.2864825", "10.2307/2394164", "10.1109/tvcg.2017.2744458", "10.1145/2993901.2993917.28", "10.1111/cgf.13711", "10.1109/tvcg.2016.2598664", "10.2307/2530428", "10.1109/icdar.1997.620583", "10.1109/tvcg.2017.2744718", "10.1111/cgf.13425", "10.1109/tvcg.2019.2903943", "10.1145/1518701.1518895", "10.1109/tvcg.2018.2864838", "10.1145/62038.62043", "10.1111/j.1467-8659.2011.01920.x", "10.1145/3025171.3025208", "10.1145/355112.355124", "10.1109/vast.2010.5652398", "10.1109/tvcg.2014.2346578", "10.1145/3173574.3174209", "10.4178/epih/e2014008", "10.1109/beliv.2018.8634201.25,28", "10.1016/j.eswa.2007.12.020", "10.1111/cgf:13406", "10.1109/mcg.2011.103", "10.1631/fitee.1700808", "10.1109/tvcg.2017.2745158", "10.1073/pnas.0307752101", "10.1109/tvcg.2018.2816223", "10.1109/tvcg.2017.2745141", "10.1145/32232.32234", "10.1109/tvcg.2019.2934267", "10.1109/tvcg.2018.2864477", "10.1145/3132169", "10.2312/eurova.20151100.19", "10.1145/3172944.3172964", "10.1145/2601248.2601268", "10.1109/isai-nlp.2018.8693002.1", "10.1111/cgf.13404", "10.1007/s100320200071", "10.2312/trvis.20191183.16", "10.1111/cgf.12755", "10.1145/2702123.2702509", "10.1145/1401890.1402008.25", "10.1109/tvcg.2012.65", "10.1177/1473871617733996", "10.2312/trvis.20191187.7", "10.21236/ada273556", "10.1109/vast.2010.5652450", "10.1111/j.1467-8659.2011.01940.x", "10.1177/875647939000600106", "10.1109/tvcg.2017.2711030", "10.1016/j.immuni.2016.04.014", "10.1109/tvcg.2019.2934209", "10.1016/0095-0696(78)90006-2", "10.1016/j.jclinepi.2015.04.014", "10.1016/j.ress.2013.02.013", "10.1111/cgf.12640", "10.1145/1015330.1015388.25", "10.1111/j.1467-8659.2009.01468.x", "10.1145/1541880.1541882", "10.1109/vast.2011.6102453", "10.1016/s0008-8846(98)00165-3", "10.2312/trvis.20191186.7", "10.1007/s13748-013-0040-3", "10.1109/tvcg.2015.2467757", "10.1109/tbdata.2018.2877350", "10.1109/vast.2017.8585613", "10.1080/10556789208805504", "10.1109/vast.2012.6400484", "10.1145/3025171.3025181", "10.1007/978-3-319-90403-0\\_12", "10.1109/mcg.2019.2922592", "10.1021/ci000392t", "10.1109/vast.2007.4389000", "10.1111/cgf.13406.16", "10.1111/cgf.13684", "10.2312/eurovisshort.20161166.17", "10.2312/evs:20191168", "10.1145/3041021.3055135", "10.1145/3301275.3302265", "10.1613/jair.4135", "10.1109/tvcg.2018.2864500", "10.1109/tvcg.2017.2744158", "10.1109/ssci.2015.33", "10.1111/cgf.13453", "10.2312/pe/eurovast/eurova11/049-052", "10.1145/3025171.3025181.13", "10.1145/371920.372094", "10.1109/tvcg.2017.2744938", "10.1111/j.1467-8659.2012.03108.x", "10.1109/tvcg.2019.2934251", "10.1145/3290605.3300809.18", "10.1109/ldav.2016.7874305", "10.1109/vast.2016.7883514", "10.1109/iccv.2015.425", "10.1145/3301275.3302324", "10.1109/tnnls.2013.2292894", "10.1109/tvcg.2018.2865044", "10.1109/tvcg.2013.157", "10.1371/journal.pcbi.0020161", "10.1186/s12916-019-1426-2", "10.1109/10.867928", "10.1111/cgf.13217", "10.1109/mcg.2019.2919033", "10.1145/2993901.2993910", "10.1109/tvcg.2017.2744738", "10.2307/258792", "10.1111/cgf.12655", "10.1016/j.dss.2014.03.001", "10.1109/tvcg.2019.2904069", "10.1111/cgf.13205", "10.1002/mds.22340", "10.1109/tvcg.2019.2934595", "10.1287/inte.2018.0957", "10.1109/cvpr.2007.382974", "10.1109/tvcg.2012.280", "10.1145/2678025.2701399.13", "10.2312/mlvis.20181130.13", "10.2312/eurova.20181106.16", "10.1109/tvcg.2018.2864475", "10.2312/mlvis.20191160.18,22", "10.1007/978-1-4612-4026-6.25", "10.1109/cvpr.2006.42", "10.1145/3172944.3172950", "10.1109/cvpr.2004.383.25", "10.1109/tvcg.2019.2934812", "10.1609/aimag.v35i4.2513", "10.2312/trvis.20191185.7", "10.1111/j.1467-8659.2009.01684.x", "10.1371/journal.pone.0129126", "10.1111/cgf.13092", "10.1162/coli\\_a\\_00237", "10.1109/tvcg.2017.2744818", "10.1109/vast.2011.6102448", "10.1109/tvcg.2009.111", "10.1109/tvcg.2019.2934619", "10.1016/s0377-2217(01)00264-8.25", "10.1111/cgf.12639", "10.1109/access.2019.2919343", "10.1186/s12874-019-0681-4", "10.1109/pacificvis.2015.7156366", "10.1109/pacificvis.2018.00029", "10.1109/tvcg.2019.2934261", "10.1080/13506280444000102.http://www.uvt.nl/ticc", "10.1109/vast.2018.8802509", "10.1111/cgf.13212", "10.1145/3200489", "10.1111/cgf.13176", "10.1177/1473871620904671", "10.1007/978-3-319-10590-1\\_53", "10.1111/j.1467-8659.2012.03126.x", "10.1111/cgf.13172", "10.1145/3025171.3025208.6,21", "10.1111/cgf.12366", "10.1109/tvcg.2019.2934659", "10.1109/cvprw.2009.5206848", "10.1016/j.media.2014.11.010", "10.1109/tvcg.2017.2744683", "10.1109/tvcg.2019.2934262", "10.1016/j.neucom.2006.11.018", "10.1177/1473871615571951", "10.1371/journal.pcbi.0020161.25", "10.1177/1473871611415994", "10.2312/trvis20191187", "10.2312/eurova", "10.1145/2858036.2858529", "10.1145/2207676.2207738", "10.1007/s11042-009-0417-2", "10.1145/3301275.3302317", "10.1038/s41746-019-0148-3", "10.1145/3351095.3372834", "10.1080/10691898.2011.11889627", "10.1109/tvcg.2018.2864504", "10.1109/vast.2017.8585720", "10.1109/mcg.2018.053491732", "10.1007/s10994-010-5207-6", "10.1109/tvcg.2019.2934433", "10.1016/j.cag.2017.05.005", "10.1109/tvcg.2012.279", "10.1145/3231622.3231641.19,20", "10.1145/1562849.1562851", "10.1007/11564126\\_", "10.1109/tvcg.2018.2846735", "10.3115/1225403.1225421", "10.1109/vast.2012.6400486", "10.2312/eurova.20191116.22", "10.1109/tvcg.2007.70443", "10.1080/027868291009242", "10.2312/eurova.20151100", "10.1145/2939502.2939503.19", "10.1016/j.cag.2014.02.004", "10.1145/2939672.2939778", "10.1109/vast.2010.5652484", "10.1111/cgf.12641", "10.1145/3301275.3302289", "10.1109/visual.2019.8933619", "10.1109/tvcg.2017.2672987", "10.1109/vast.2016.7883517.20", "10.1109/igarss.2017.8127684", "10.1016/j.jcae.2010.04.002", "10.1109/vast.2010.5652885", "10.1016/j.visinf.2019.03.002", "10.1007/s00371-018-1500-3", "10.1109/mcg.2018.042731661", "10.1109/34.598228", "10.1109/tvcg.2018.2865027", "10.1016/j.neucom.2017.01.105", "10.1111/cgf.12389", "10.1109/tvcg.2019.2934591", "10.1109/vast.2010.5652392.16", "10.1111/cgf.13416", "10.1080/02701367.1992.10608764", "10.1109/vast.2017.8585721", "10.1109/tvcg.2018.2843369", "10.1109/sbes.2010.27", "10.1109/vast.2015.7347637", "10.1145/1401890.1402008", "10.1016/j.bpj.2010.04.064", "10.1109/tvcg.2013.125", "10.1109/isai-nlp.2018.8693002", "10.1371/journal.pone.0160127", "10.1145/2856767.2856779", "10.1145/2678025.2701399", "10.1109/vast.2011.6102451", "10.1109/mcg.2010.18", "10.1021/ci4000213", "10.1109/vast.2012.6400492", "10.1007/11564126-49.25", "10.2312/eurova.20171114", "10.1109/vast.2010.5652443", "10.1145/3134599", "10.2312/pe/eurovast/eurovast10/013-018.19", "10.1109/tvcg.2019.2903946", "10.1109/tvcg.2015.2467717", "10.1177/1473871612460526", "10.1016/j.cag.2018.09.018", "10.1109/tvcg.2016.2598838", "10.1145/3172944.3172964.14", "10.1109/vast.2009.5333428", "10.1109/vast.2014.7042480", "10.2312/pe/eurovast/eurovast10/013-018", "10.1177/0962280215588241", "10.1145/2993901.2993917", "10.1109/cvpr.2008:4587581", "10.1109/tvcg.2015.2467551", "10.1016/j.visinf.2018.09.001", "10.1126/science.290.5500.2319", "10.2312/eurova.20151107", "10.1109/visual.2019.8933695", "10.13140/2.1.2393.1847", "10.1197/jamia.m1929", "10.1109/cvpr.2008.4587581.25", "10.1145/1518701.1518895.16", "10.1109/vds.2017.8573444", "10.2312/trvis:20191185", "10.1145/3359786", "10.13140/2.1.1341.1520", "10.2312/pe/eurovast/eurova11/049-052.17", "10.1109/tvcg.2014.2346660", "10.1145/3185517", "10.1109/adprl.2011.5967372", "10.1109/tvcg.2015.2467591", "10.1111/j.1751-9004.2009.00232.x", "10.1136/qshc.2004.010033", "10.1109/vast.2012.6400493", "10.1109/tvcg.2019.2934266", "10.1145/2971763.2971775", "10.1111/cgf.13730", "10.1109/vast.2012.6400488", "10.1111/cgf.13210", "10.1109/tvcg.2019.2934631", "10.1145/3172944.3172965", "10.1057/ivs.2010.2", "10.1109/tvcg.2017.2745258", "10.1016/j.jbusres.2019.07.039", "10.1162/jmlr.2003.3.4-5.993", "10.1109/pacificvis.2019.00044", "10.2312/pe/eurovast/eurova12/037-041", "10.1109/tvcg.2019.2934629", "10.1177/0018720814547570", "10.1145/3292500.3330908", "10.1111/j.1467-8659.2009.01467.x", "10.2312/eurova.20151098", "10.1177/1473871617713337", "10.1109/lars:2009.5418323", "10.1109/vast.2011.6102437", "10.1111/cgf.12878", "10.1561/1500000001", "10.1145/3025171.3025222", "10.1007/s11704-016-6028-y", "10.1016/j.procs.2017.05.216", "10.1109/cvpr.2007.382974.25", "10.1080/10447318.2020.1741118", "10.1109/vast.2012.6400489", "10.1145/3025171.3025172", "10.1109/tvcg.2017.2744098", "10.1109/tvcg.2005.66", "10.1016/j.dss.2009.05.016", "10.1007/978-1-4612-4026-6", "10.2312/evs.20191168.16,20,28", "10.2312/pe/eurovast/eurova12/037-041.17", "10.1145/3290605.3300803", "10.1145/1015330.1015388", "10.1111/cgf.13197", "10.1016/b978-1-55860-377-6.50048-7", "10.1111/cgf.13681", "10.1109/tvcg.2017.2744378", "10.1109/tvcg.2017.2744358", "10.1109/vast.2008.4677352"], "wos": 1, "children": [{"doi": "10.1109/tvcg.2020.3030368", "title": "Implicit Multidimensional Projection of Local Subspaces", "year": "2020", "conferenceName": "InfoVis", "authors": "Rongzheng Bian;Yumeng Xue;Liang Zhou;Jian Zhang 0070;Baoquan Chen;Daniel Weiskopf;Yunhai Wang", "citationCount": "1", "affiliation": "Wang, YH (Corresponding Author), Shandong Univ, Qingdao, Peoples R China. Zhou, L (Corresponding Author), Univ Utah, Salt Lake City, UT 84112 USA. Bian, Rongzheng; Xue, Yumeng; Wang, Yunhai, Shandong Univ, Qingdao, Peoples R China. Chen, Baoquan, Peking Univ, Beijing, Peoples R China. Zhang, Jian, Chinese Acad Sci, CNIC, Beijing, Peoples R China. Zhou, Liang, Univ Utah, Salt Lake City, UT 84112 USA. Weiskopf, Daniel, Univ Stuttgart, Stuttgart, Germany.", "countries": "USA;Germany;China", "abstract": "We propose a visualization method to understand the effect of multidimensional projection on local subspaces, using implicit function differentiation. Here, we understand the local subspace as the multidimensional local neighborhood of data points. Existing methods focus on the projection of multidimensional data points, and the neighborhood information is ignored. Our method is able to analyze the shape and directional information of the local subspace to gain more insights into the global structure of the data through the perception of local structures. Local subspaces are fitted by multidimensional ellipses that are spanned by basis vectors. An accurate and efficient vector transformation method is proposed based on analytical differentiation of multidimensional projections formulated as implicit functions. The results are visualized as glyphs and analyzed using a full set of specifically-designed interactions supported in our efficient web-based visualization tool. The usefulness of our method is demonstrated using various multi- and high-dimensional benchmark datasets. Our implicit differentiation vector transformation is evaluated through numerical comparisons; the overall method is evaluated through exploration examples and use cases.", "keywords": "High-dimensional data visualization,dimensionality reduction,local linear subspaces,user interaction", "link": "http://dx.doi.org/10.1109/TVCG.2020.3030368", "refList": ["10.3844/jcssp.2018.613.622", "10.1016/j.aci.2018.08.003", "10.3390/info9030065", "10.1016/j.visinf.2018.09.003", "10.1371/journal.pone.0118432", "10.1016/s0893-6080(05)80023-1", "10.1109/tvcg.2020.2986996", "10.1109/icst.2012.56", "10.1007/s10844-013-0250-y", "10.1109/tbdata.2018", "10.1145/1125451.1125659", "10.1109/tvcg.2013.125", "10.1177/1473871611412817", "10.1145/3290605.3300911", "10.1111/cgf.14034", "10.1007/s13721-013-0034-x", "10.1016/j.procs.2017.05.216", "10.1016/j.ins.2009.08.025", "10.1109/tvcg.2013.124", "10.1109/tvcg.2018.2864499", "10.1109/tvcg.2018.2864475", "10.1080/10447318.2020.1741118", "10.1016/j.imu.2019.100203", "10.1109/tvcg.2018.2865240", "10.1186/s12864-019-6413-7", "10.1109/tvcg.2015.2467551", "10.1002/widm.1249", "10.1007/978-3-319-66429-3\\_29", "10.1109/tvcg.2014.2346481", "10.1109/tvcg.2018.2864825", "10.1177/1473871620904671", "10.1109/tvcg.2019.2934267", "10.1136/bmjopen-2016-012799", "10.1109/smartgridcomm.2017.8340682", "10.1007/s10664-015-9401-9", "10.1145/1143844.1143874", "10.1111/cgf.12389", "10.1109/tvcg.2018.2872577", "10.1007/978-981-13-5802-9\\_20", "10.1016/j.ipm.2009.03.002", "10.5220/0006431602160222", "10.1109/mcg.2015.50", "10.1109/tvcg.2014.2346574", "10.1007/bf02289565", "10.1109/tvcg.2017.2744378", "10.1016/j.patrec.2008.08.010", "10.1023/a:1010933404324", "10.9735/2229-3981"], "wos": 1, "children": [], "len": 1}, {"doi": "10.1109/tvcg.2020.3030465", "title": "Visual Causality Analysis of Event Sequence Data", "year": "2020", "conferenceName": "VAST", "authors": "Zhuochen Jin;Shunan Guo;Nan Chen;Daniel Weiskopf;David Gotz;Nan Cao", "citationCount": "0", "affiliation": "Cao, N (Corresponding Author), Tongji Univ, IDVx Lab, Shanghai, Peoples R China. Jin, Zhuochen; Guo, Shunan; Chen, Nan; Cao, Nan, Tongji Univ, IDVx Lab, Shanghai, Peoples R China. Weiskopf, Daniel, Univ Stuttgart, Stuttgart, Germany. Gotz, David, Univ N Carolina, Chapel Hill, NC 27515 USA.", "countries": "USA;Germany;China", "abstract": "Causality is crucial to understanding the mechanisms behind complex systems and making decisions that lead to intended outcomes. Event sequence data is widely collected from many real-world processes, such as electronic health records, web clickstreams, and financial transactions, which transmit a great deal of information reflecting the causal relations among event types. Unfortunately, recovering causalities from observational event sequences is challenging, as the heterogeneous and high-dimensional event variables are often connected to rather complex underlying event excitation mechanisms that are hard to infer from limited observations. Many existing automated causal analysis techniques suffer from poor explainability and fail to include an adequate amount of human knowledge. In this paper, we introduce a visual analytics method for recovering causalities in event sequence data. We extend the Granger causality analysis algorithm on Hawkes processes to incorporate user feedback into causal model refinement. The visualization system includes an interactive causal analysis framework that supports bottom-up causal exploration, iterative causal verification and refinement, and causal comparison through a set of novel visualizations and interactions. We report two forms of evaluation: a quantitative evaluation of the model improvements resulting from the user-feedback mechanism, and a qualitative evaluation through case studies in different application domains to demonstrate the usefulness of the system.", "keywords": "Event sequence data,causality analysis,visual analytics", "link": "http://dx.doi.org/10.1109/TVCG.2020.3030465", "refList": ["10.5555/1642718", "10.1109/tvcg.2018.2865022", "10.5555/2074094.2074151", "10.1109/tvcg.2016.2618797", "10.1073/pnas.1320645111", "10.1109/tvcg.2017.2744843", "10.1109/iv.2017.69", "10.1109/tvcg.2019.2934399", "10.1145/3172944.3173007", "10.5555/1795555", "10.1109/mcg.2005.102", "10.1145/381641.381653", "10.1162/153244301753344614", "10.1111/cgf.14034", "10.1111/cgf.13198", "10.1017/cbo9780511519857", "10.1007/s10462-016-9475-9", "10.1075/ssol.2.2.07bor", "10.1007/978-1-4614-3223-4\\_3", "10.1109/infvis.2003.1249025", "10.1007/978-94-007-6094-313", "10.1145/2858036.2858387", "10.1109/tvcg.2007.70528", "10.1109/tvcg.2017.2674958", "10.1147/sj.454.0801", "10.1109/tvcg.2013.119", "10.1145/3173574.3173711", "10.1016/j.erss.2017.06.034", "10.1109/visual.2019.8933695", "10.1007/s11665-016-2173-6", "10.1016/0377-0427(87)90125-7", "10.2307/3601125", "10.1016/b978-0-444-88738-2.50018-x", "10.1109/mcg.2006.70", "10.1109/tvcg.2018.2865145", "10.1017/s1351324997001502", "10.1109/tvcg.2010.179", "10.1214/aos/1176344552", "10.1109/mcg.2009.22", "10.1007/978-3-319-26633-6\\_13", "10.1080/10447318.2014.905422", "10.1016/j.visinf.2019.03.004", "10.1057/palgrave.ivs.9500074", "10.1007/978-1-4614-3223-4"], "wos": 1, "children": [], "len": 1}], "len": 5}], "len": 7}, {"doi": "10.1109/tvcg.2019.2934267", "title": "ProtoSteer: Steering Deep Sequence Model with Prototypes", "year": "2019", "conferenceName": "VAST", "authors": "Yao Ming;Panpan Xu;Furui Cheng;Huamin Qu;Ren Liu", "citationCount": "2", "affiliation": "Ming, Y (Corresponding Author), Hong Kong Univ Sci \\& Technol, Hong Kong, Peoples R China. Ming, Yao; Cheng, Furui; Qu, Huamin, Hong Kong Univ Sci \\& Technol, Hong Kong, Peoples R China. Xu, Panpan; Ren, Liu, Bosch Res North Amer, Palo Alto, CA USA.", "countries": "USA;China", "abstract": "Recently we have witnessed growing adoption of deep sequence models (e.g. LSTMs) in many application domains, including predictive health care, natural language processing, and log analysis. However, the intricate working mechanism of these models confines their accessibility to the domain experts. Their black-box nature also makes it a challenging task to incorporate domain-specific knowledge of the experts into the model. In ProtoSteer (Prototype Steering), we tackle the challenge of directly involving the domain experts to steer a deep sequence model without relying on model developers as intermediaries. Our approach originates in case-based reasoning, which imitates the common human problem-solving process of consulting past experiences to solve new problems. We utilize ProSeNet (Prototype Sequence Network), which learns a small set of exemplar cases (i.e., prototypes) from historical data. In ProtoSteer they serve both as an efficient visual summary of the original data and explanations of model decisions. With ProtoSteer the domain experts can inspect, critique, and revise the prototypes interactively. The system then incorporates user-specified prototypes and incrementally updates the model. We conduct extensive case studies and expert interviews in application domains including sentiment analysis on texts and predictive diagnostics based on vehicle fault logs. The results demonstrate that involvements of domain users can help obtain more interpretable models with concise prototypes while retaining similar accuracy.", "keywords": "Sequence Data,Explainable Artificial Intelligence (XAI),Recurrent Neural Networks (RNNs),Prototype Learning", "link": "http://dx.doi.org/10.1109/TVCG.2019.2934267", "refList": ["10.1109/infvis.2000.885091", "10.1145/2468356.2468434", "10.1109/mcg.2018.2878902", "10.1145/2858036.2858107", "10.1145/2702123.2702419", "10.1109/vast.2015.7347682", "10.1109/tvcg.2016.2598797", "10.1145/2939672.2939778", "10.1109/tvcg.2018.2864885", "10.1109/tvcg.2018.2865044", "10.1073/pnas.95.25.14863", "10.1109/tvcg.2016.2539960", "10.1145/3025453.3025456", "10.1145/2557500.2557508", "10.1109/tvcg.2012.225", "10.1109/tvcg.2014.2346682", "10.1109/tvcg.2018.2865230", "10.1109/tvcg.2017.2745320", "10.1109/tvcg.2017.2744718", "10.18653/v1/n16-1082", "10.1016/j.neucom.2013.11.045", "10.1109/tvcg.2017.2745083", "10.1609/aimag.v35i4.2513", "10.1007/bf00155578", "10.1007/978-3-319-90403-0\\_17", "10.1109/tvcg.2017.2744158", "10.1109/tvcg.2018.2864838", "10.1109/tvcg.2018.2865027", "10.1145/312129.312298", "10.1145/3185517", "10.1109/vast.2011.6102453"], "wos": 1, "children": [{"doi": "10.1109/tvcg.2020.3030368", "title": "Implicit Multidimensional Projection of Local Subspaces", "year": "2020", "conferenceName": "InfoVis", "authors": "Rongzheng Bian;Yumeng Xue;Liang Zhou;Jian Zhang 0070;Baoquan Chen;Daniel Weiskopf;Yunhai Wang", "citationCount": "1", "affiliation": "Wang, YH (Corresponding Author), Shandong Univ, Qingdao, Peoples R China. Zhou, L (Corresponding Author), Univ Utah, Salt Lake City, UT 84112 USA. Bian, Rongzheng; Xue, Yumeng; Wang, Yunhai, Shandong Univ, Qingdao, Peoples R China. Chen, Baoquan, Peking Univ, Beijing, Peoples R China. Zhang, Jian, Chinese Acad Sci, CNIC, Beijing, Peoples R China. Zhou, Liang, Univ Utah, Salt Lake City, UT 84112 USA. Weiskopf, Daniel, Univ Stuttgart, Stuttgart, Germany.", "countries": "USA;Germany;China", "abstract": "We propose a visualization method to understand the effect of multidimensional projection on local subspaces, using implicit function differentiation. Here, we understand the local subspace as the multidimensional local neighborhood of data points. Existing methods focus on the projection of multidimensional data points, and the neighborhood information is ignored. Our method is able to analyze the shape and directional information of the local subspace to gain more insights into the global structure of the data through the perception of local structures. Local subspaces are fitted by multidimensional ellipses that are spanned by basis vectors. An accurate and efficient vector transformation method is proposed based on analytical differentiation of multidimensional projections formulated as implicit functions. The results are visualized as glyphs and analyzed using a full set of specifically-designed interactions supported in our efficient web-based visualization tool. The usefulness of our method is demonstrated using various multi- and high-dimensional benchmark datasets. Our implicit differentiation vector transformation is evaluated through numerical comparisons; the overall method is evaluated through exploration examples and use cases.", "keywords": "High-dimensional data visualization,dimensionality reduction,local linear subspaces,user interaction", "link": "http://dx.doi.org/10.1109/TVCG.2020.3030368", "refList": ["10.3844/jcssp.2018.613.622", "10.1016/j.aci.2018.08.003", "10.3390/info9030065", "10.1016/j.visinf.2018.09.003", "10.1371/journal.pone.0118432", "10.1016/s0893-6080(05)80023-1", "10.1109/tvcg.2020.2986996", "10.1109/icst.2012.56", "10.1007/s10844-013-0250-y", "10.1109/tbdata.2018", "10.1145/1125451.1125659", "10.1109/tvcg.2013.125", "10.1177/1473871611412817", "10.1145/3290605.3300911", "10.1111/cgf.14034", "10.1007/s13721-013-0034-x", "10.1016/j.procs.2017.05.216", "10.1016/j.ins.2009.08.025", "10.1109/tvcg.2013.124", "10.1109/tvcg.2018.2864499", "10.1109/tvcg.2018.2864475", "10.1080/10447318.2020.1741118", "10.1016/j.imu.2019.100203", "10.1109/tvcg.2018.2865240", "10.1186/s12864-019-6413-7", "10.1109/tvcg.2015.2467551", "10.1002/widm.1249", "10.1007/978-3-319-66429-3\\_29", "10.1109/tvcg.2014.2346481", "10.1109/tvcg.2018.2864825", "10.1177/1473871620904671", "10.1109/tvcg.2019.2934267", "10.1136/bmjopen-2016-012799", "10.1109/smartgridcomm.2017.8340682", "10.1007/s10664-015-9401-9", "10.1145/1143844.1143874", "10.1111/cgf.12389", "10.1109/tvcg.2018.2872577", "10.1007/978-981-13-5802-9\\_20", "10.1016/j.ipm.2009.03.002", "10.5220/0006431602160222", "10.1109/mcg.2015.50", "10.1109/tvcg.2014.2346574", "10.1007/bf02289565", "10.1109/tvcg.2017.2744378", "10.1016/j.patrec.2008.08.010", "10.1023/a:1010933404324", "10.9735/2229-3981"], "wos": 1, "children": [], "len": 1}, {"doi": "10.1111/cgf.14034", "year": "2020", "title": "The State of the Art in Enhancing Trust in Machine Learning Models with the Use of Visualizations", "conferenceName": "EuroVis", "authors": "Angelos Chatzimparmpas;Rafael Messias Martins;Ilir Jusufi;Kostiantyn Kucher;Fabrice Rossi;Andreas Kerren", "citationCount": "2", "affiliation": "Chatzimparmpas, A (Corresponding Author), Linnaeus Univ, Dept Comp Sci \\& Media Technol, Vaxjo, Sweden.\nChatzimparmpas, A.; Martins, R. M.; Jusufi, I.; Kucher, K.; Kerren, A., Linnaeus Univ, Dept Comp Sci \\& Media Technol, Vaxjo, Sweden.\nRossi, F., PSL Univ, Univ Paris Dauphine, Ceremade, Paris, France.", "countries": "Sweden;France", "abstract": "Machine learning (ML) models are nowadays used in complex applications in various domains, such as medicine, bioinformatics, and other sciences. Due to their black box nature, however, it may sometimes be hard to understand and trust the results they provide. This has increased the demand for reliable visualization tools related to enhancing trust in ML models, which has become a prominent topic of research in the visualization community over the past decades. To provide an overview and present the frontiers of current research on the topic, we present a State-of-the-Art Report (STAR) on enhancing trust in ML models with the use of interactive visualization. We define and describe the background of the topic, introduce a categorization for visualization techniques that aim to accomplish this goal, and discuss insights and opportunities for future research directions. Among our contributions is a categorization of trust against different facets of interactive ML, expanded and improved from previous research. Our results are investigated from different analytical perspectives: (a) providing a statistical overview, (b) summarizing key findings, (c) performing topic analyses, and (d) exploring the data sets used in the individual papers, all with the support of an interactive web-based survey browser. We intend this survey to be beneficial for visualization researchers whose interests involve making ML models more trustworthy, as well as researchers and practitioners from other disciplines in their search for effective visualization techniques suitable for solving their tasks with confidence and conveying meaning to their data.", "keywords": "trustworthy machine learning; visualization; interpretable machine learning; explainable machine learning", "link": "https://doi.org/10.1111/cgf.14034", "refList": ["10.1109/mcg.2018.2878902", "10.1109/tvcg.2008.153", "10.2312/mlvis.20181130", "10.1109/tvcg.2016.2598828", "10.1145/3290605.3300911", "10.1145/2993901.2993909", "10.2312/mlvis.20191158", "10.1109/tvcg.2016.2598446", "10.1111/j.1467-8659.2009.01475.x", "10.1145/3290605.3300809", "10.1109/pacificvis.2018.00031", "10.1055/s-0029-1216348", "10.1007/978-3-319-90403-0\\_13", "10.1109/tvcg.2017.2745085", "10.1111/j.1467-8659.2011.01938.x", "10.1007/978-3-319-54024-5\\_6", "10.1016/s0167-9473(01)00065-2", "10.1111/cgf.12895", "10.2312/eurovisshort.20141152.17", "10.2312/eurova.20151098.22", "10.1111/cgf.13667", "10.3115/1072228.1072378", "10.1109/tbdata.2018.2877350.16", "10.1109/lars.2009.5418323.25", "10.1109/tvcg.2017.2744878", "10.1016/j.combustflame.2005.09.018", "10.1016/j.cag.2014.01.006", "10.1109/tvcg.2016.2570755", "10.2312/mlvis.20191158.1,19", "10.1518/hfes.46.1.50.30392", "10.1145/3301275.3302280", "10.1145/3351095.3372834.1", "10.1016/s0377-2217(01)00264-8", "10.1111/cgf.13424", "10.1007/978-3-319-23485-4\\_53", "10.1007/978-94-007-0753-5\\_3623", "10.1109/tvcg.2013.101", "10.1111/cgf.12884", "10.1111/j.1467-8659.2010.01835.x", "10.1021/ci9901338", "10.4230/lipics.itcs:2017", "10.1109/mis.2013.24", "10.1109/tvcg.2014.2346482", "10.1109/tvcg.2018.2865230", "10.1073/pnas.1807180116", "10.1109/dsaa.2018.00018", "10.1109/tvcg.2009.153", "10.3115/1219840.1219855", "10.1109/tvcg.2018.2864812", "10.1109/tvcg.2018.2872577", "10.2312/trvis.20191183", "10.1109/cvpr:2004.383", "10.1109/vast.2008.4677350", "10.1145/302979.303001", "10.1109/tvcg.2018.2864499", "10.1111/cgf.13672", "10.1109/tvcg.2014.2346626", "10.23915/distill.00010.18", "10.1109/tvcg.2017.2744805", "10.2312/mlvis:20191160.18", "10.23915/distill:00016", "10.1109/pacificvis.2016.7465260", "10.1111/cgf.13683", "10.23915/distill.00016.19", "10.1145/32906053.300803.22", "10.1109/tvcg.2014.2346574", "10.1177/1473871615600010", "10.1109/tvcg.2016.2598831", "10.1145/3230623", "10.1109/visual.2019.8933744", "10.1145/2993901.2993915", "10.1016/j.visinf.2017.01.006", "10.1145/2993901.2993914", "10.1109/tvcg.2014.2346984", "10.1109/5.726791", "10.23915/distill.00010", "10.1109/tvcg.2018.2864825", "10.2307/2394164", "10.1109/tvcg.2017.2744458", "10.1145/2993901.2993917.28", "10.1111/cgf.13711", "10.1109/tvcg.2016.2598664", "10.2307/2530428", "10.1109/icdar.1997.620583", "10.1109/tvcg.2017.2744718", "10.1111/cgf.13425", "10.1109/tvcg.2019.2903943", "10.1145/1518701.1518895", "10.1109/tvcg.2018.2864838", "10.1145/62038.62043", "10.1111/j.1467-8659.2011.01920.x", "10.1145/3025171.3025208", "10.1145/355112.355124", "10.1109/vast.2010.5652398", "10.1109/tvcg.2014.2346578", "10.1145/3173574.3174209", "10.4178/epih/e2014008", "10.1109/beliv.2018.8634201.25,28", "10.1016/j.eswa.2007.12.020", "10.1111/cgf:13406", "10.1109/mcg.2011.103", "10.1631/fitee.1700808", "10.1109/tvcg.2017.2745158", "10.1073/pnas.0307752101", "10.1109/tvcg.2018.2816223", "10.1109/tvcg.2017.2745141", "10.1145/32232.32234", "10.1109/tvcg.2019.2934267", "10.1109/tvcg.2018.2864477", "10.1145/3132169", "10.2312/eurova.20151100.19", "10.1145/3172944.3172964", "10.1145/2601248.2601268", "10.1109/isai-nlp.2018.8693002.1", "10.1111/cgf.13404", "10.1007/s100320200071", "10.2312/trvis.20191183.16", "10.1111/cgf.12755", "10.1145/2702123.2702509", "10.1145/1401890.1402008.25", "10.1109/tvcg.2012.65", "10.1177/1473871617733996", "10.2312/trvis.20191187.7", "10.21236/ada273556", "10.1109/vast.2010.5652450", "10.1111/j.1467-8659.2011.01940.x", "10.1177/875647939000600106", "10.1109/tvcg.2017.2711030", "10.1016/j.immuni.2016.04.014", "10.1109/tvcg.2019.2934209", "10.1016/0095-0696(78)90006-2", "10.1016/j.jclinepi.2015.04.014", "10.1016/j.ress.2013.02.013", "10.1111/cgf.12640", "10.1145/1015330.1015388.25", "10.1111/j.1467-8659.2009.01468.x", "10.1145/1541880.1541882", "10.1109/vast.2011.6102453", "10.1016/s0008-8846(98)00165-3", "10.2312/trvis.20191186.7", "10.1007/s13748-013-0040-3", "10.1109/tvcg.2015.2467757", "10.1109/tbdata.2018.2877350", "10.1109/vast.2017.8585613", "10.1080/10556789208805504", "10.1109/vast.2012.6400484", "10.1145/3025171.3025181", "10.1007/978-3-319-90403-0\\_12", "10.1109/mcg.2019.2922592", "10.1021/ci000392t", "10.1109/vast.2007.4389000", "10.1111/cgf.13406.16", "10.1111/cgf.13684", "10.2312/eurovisshort.20161166.17", "10.2312/evs:20191168", "10.1145/3041021.3055135", "10.1145/3301275.3302265", "10.1613/jair.4135", "10.1109/tvcg.2018.2864500", "10.1109/tvcg.2017.2744158", "10.1109/ssci.2015.33", "10.1111/cgf.13453", "10.2312/pe/eurovast/eurova11/049-052", "10.1145/3025171.3025181.13", "10.1145/371920.372094", "10.1109/tvcg.2017.2744938", "10.1111/j.1467-8659.2012.03108.x", "10.1109/tvcg.2019.2934251", "10.1145/3290605.3300809.18", "10.1109/ldav.2016.7874305", "10.1109/vast.2016.7883514", "10.1109/iccv.2015.425", "10.1145/3301275.3302324", "10.1109/tnnls.2013.2292894", "10.1109/tvcg.2018.2865044", "10.1109/tvcg.2013.157", "10.1371/journal.pcbi.0020161", "10.1186/s12916-019-1426-2", "10.1109/10.867928", "10.1111/cgf.13217", "10.1109/mcg.2019.2919033", "10.1145/2993901.2993910", "10.1109/tvcg.2017.2744738", "10.2307/258792", "10.1111/cgf.12655", "10.1016/j.dss.2014.03.001", "10.1109/tvcg.2019.2904069", "10.1111/cgf.13205", "10.1002/mds.22340", "10.1109/tvcg.2019.2934595", "10.1287/inte.2018.0957", "10.1109/cvpr.2007.382974", "10.1109/tvcg.2012.280", "10.1145/2678025.2701399.13", "10.2312/mlvis.20181130.13", "10.2312/eurova.20181106.16", "10.1109/tvcg.2018.2864475", "10.2312/mlvis.20191160.18,22", "10.1007/978-1-4612-4026-6.25", "10.1109/cvpr.2006.42", "10.1145/3172944.3172950", "10.1109/cvpr.2004.383.25", "10.1109/tvcg.2019.2934812", "10.1609/aimag.v35i4.2513", "10.2312/trvis.20191185.7", "10.1111/j.1467-8659.2009.01684.x", "10.1371/journal.pone.0129126", "10.1111/cgf.13092", "10.1162/coli\\_a\\_00237", "10.1109/tvcg.2017.2744818", "10.1109/vast.2011.6102448", "10.1109/tvcg.2009.111", "10.1109/tvcg.2019.2934619", "10.1016/s0377-2217(01)00264-8.25", "10.1111/cgf.12639", "10.1109/access.2019.2919343", "10.1186/s12874-019-0681-4", "10.1109/pacificvis.2015.7156366", "10.1109/pacificvis.2018.00029", "10.1109/tvcg.2019.2934261", "10.1080/13506280444000102.http://www.uvt.nl/ticc", "10.1109/vast.2018.8802509", "10.1111/cgf.13212", "10.1145/3200489", "10.1111/cgf.13176", "10.1177/1473871620904671", "10.1007/978-3-319-10590-1\\_53", "10.1111/j.1467-8659.2012.03126.x", "10.1111/cgf.13172", "10.1145/3025171.3025208.6,21", "10.1111/cgf.12366", "10.1109/tvcg.2019.2934659", "10.1109/cvprw.2009.5206848", "10.1016/j.media.2014.11.010", "10.1109/tvcg.2017.2744683", "10.1109/tvcg.2019.2934262", "10.1016/j.neucom.2006.11.018", "10.1177/1473871615571951", "10.1371/journal.pcbi.0020161.25", "10.1177/1473871611415994", "10.2312/trvis20191187", "10.2312/eurova", "10.1145/2858036.2858529", "10.1145/2207676.2207738", "10.1007/s11042-009-0417-2", "10.1145/3301275.3302317", "10.1038/s41746-019-0148-3", "10.1145/3351095.3372834", "10.1080/10691898.2011.11889627", "10.1109/tvcg.2018.2864504", "10.1109/vast.2017.8585720", "10.1109/mcg.2018.053491732", "10.1007/s10994-010-5207-6", "10.1109/tvcg.2019.2934433", "10.1016/j.cag.2017.05.005", "10.1109/tvcg.2012.279", "10.1145/3231622.3231641.19,20", "10.1145/1562849.1562851", "10.1007/11564126\\_", "10.1109/tvcg.2018.2846735", "10.3115/1225403.1225421", "10.1109/vast.2012.6400486", "10.2312/eurova.20191116.22", "10.1109/tvcg.2007.70443", "10.1080/027868291009242", "10.2312/eurova.20151100", "10.1145/2939502.2939503.19", "10.1016/j.cag.2014.02.004", "10.1145/2939672.2939778", "10.1109/vast.2010.5652484", "10.1111/cgf.12641", "10.1145/3301275.3302289", "10.1109/visual.2019.8933619", "10.1109/tvcg.2017.2672987", "10.1109/vast.2016.7883517.20", "10.1109/igarss.2017.8127684", "10.1016/j.jcae.2010.04.002", "10.1109/vast.2010.5652885", "10.1016/j.visinf.2019.03.002", "10.1007/s00371-018-1500-3", "10.1109/mcg.2018.042731661", "10.1109/34.598228", "10.1109/tvcg.2018.2865027", "10.1016/j.neucom.2017.01.105", "10.1111/cgf.12389", "10.1109/tvcg.2019.2934591", "10.1109/vast.2010.5652392.16", "10.1111/cgf.13416", "10.1080/02701367.1992.10608764", "10.1109/vast.2017.8585721", "10.1109/tvcg.2018.2843369", "10.1109/sbes.2010.27", "10.1109/vast.2015.7347637", "10.1145/1401890.1402008", "10.1016/j.bpj.2010.04.064", "10.1109/tvcg.2013.125", "10.1109/isai-nlp.2018.8693002", "10.1371/journal.pone.0160127", "10.1145/2856767.2856779", "10.1145/2678025.2701399", "10.1109/vast.2011.6102451", "10.1109/mcg.2010.18", "10.1021/ci4000213", "10.1109/vast.2012.6400492", "10.1007/11564126-49.25", "10.2312/eurova.20171114", "10.1109/vast.2010.5652443", "10.1145/3134599", "10.2312/pe/eurovast/eurovast10/013-018.19", "10.1109/tvcg.2019.2903946", "10.1109/tvcg.2015.2467717", "10.1177/1473871612460526", "10.1016/j.cag.2018.09.018", "10.1109/tvcg.2016.2598838", "10.1145/3172944.3172964.14", "10.1109/vast.2009.5333428", "10.1109/vast.2014.7042480", "10.2312/pe/eurovast/eurovast10/013-018", "10.1177/0962280215588241", "10.1145/2993901.2993917", "10.1109/cvpr.2008:4587581", "10.1109/tvcg.2015.2467551", "10.1016/j.visinf.2018.09.001", "10.1126/science.290.5500.2319", "10.2312/eurova.20151107", "10.1109/visual.2019.8933695", "10.13140/2.1.2393.1847", "10.1197/jamia.m1929", "10.1109/cvpr.2008.4587581.25", "10.1145/1518701.1518895.16", "10.1109/vds.2017.8573444", "10.2312/trvis:20191185", "10.1145/3359786", "10.13140/2.1.1341.1520", "10.2312/pe/eurovast/eurova11/049-052.17", "10.1109/tvcg.2014.2346660", "10.1145/3185517", "10.1109/adprl.2011.5967372", "10.1109/tvcg.2015.2467591", "10.1111/j.1751-9004.2009.00232.x", "10.1136/qshc.2004.010033", "10.1109/vast.2012.6400493", "10.1109/tvcg.2019.2934266", "10.1145/2971763.2971775", "10.1111/cgf.13730", "10.1109/vast.2012.6400488", "10.1111/cgf.13210", "10.1109/tvcg.2019.2934631", "10.1145/3172944.3172965", "10.1057/ivs.2010.2", "10.1109/tvcg.2017.2745258", "10.1016/j.jbusres.2019.07.039", "10.1162/jmlr.2003.3.4-5.993", "10.1109/pacificvis.2019.00044", "10.2312/pe/eurovast/eurova12/037-041", "10.1109/tvcg.2019.2934629", "10.1177/0018720814547570", "10.1145/3292500.3330908", "10.1111/j.1467-8659.2009.01467.x", "10.2312/eurova.20151098", "10.1177/1473871617713337", "10.1109/lars:2009.5418323", "10.1109/vast.2011.6102437", "10.1111/cgf.12878", "10.1561/1500000001", "10.1145/3025171.3025222", "10.1007/s11704-016-6028-y", "10.1016/j.procs.2017.05.216", "10.1109/cvpr.2007.382974.25", "10.1080/10447318.2020.1741118", "10.1109/vast.2012.6400489", "10.1145/3025171.3025172", "10.1109/tvcg.2017.2744098", "10.1109/tvcg.2005.66", "10.1016/j.dss.2009.05.016", "10.1007/978-1-4612-4026-6", "10.2312/evs.20191168.16,20,28", "10.2312/pe/eurovast/eurova12/037-041.17", "10.1145/3290605.3300803", "10.1145/1015330.1015388", "10.1111/cgf.13197", "10.1016/b978-1-55860-377-6.50048-7", "10.1111/cgf.13681", "10.1109/tvcg.2017.2744378", "10.1109/tvcg.2017.2744358", "10.1109/vast.2008.4677352"], "wos": 1, "children": [{"doi": "10.1109/tvcg.2020.3030368", "title": "Implicit Multidimensional Projection of Local Subspaces", "year": "2020", "conferenceName": "InfoVis", "authors": "Rongzheng Bian;Yumeng Xue;Liang Zhou;Jian Zhang 0070;Baoquan Chen;Daniel Weiskopf;Yunhai Wang", "citationCount": "1", "affiliation": "Wang, YH (Corresponding Author), Shandong Univ, Qingdao, Peoples R China. Zhou, L (Corresponding Author), Univ Utah, Salt Lake City, UT 84112 USA. Bian, Rongzheng; Xue, Yumeng; Wang, Yunhai, Shandong Univ, Qingdao, Peoples R China. Chen, Baoquan, Peking Univ, Beijing, Peoples R China. Zhang, Jian, Chinese Acad Sci, CNIC, Beijing, Peoples R China. Zhou, Liang, Univ Utah, Salt Lake City, UT 84112 USA. Weiskopf, Daniel, Univ Stuttgart, Stuttgart, Germany.", "countries": "USA;Germany;China", "abstract": "We propose a visualization method to understand the effect of multidimensional projection on local subspaces, using implicit function differentiation. Here, we understand the local subspace as the multidimensional local neighborhood of data points. Existing methods focus on the projection of multidimensional data points, and the neighborhood information is ignored. Our method is able to analyze the shape and directional information of the local subspace to gain more insights into the global structure of the data through the perception of local structures. Local subspaces are fitted by multidimensional ellipses that are spanned by basis vectors. An accurate and efficient vector transformation method is proposed based on analytical differentiation of multidimensional projections formulated as implicit functions. The results are visualized as glyphs and analyzed using a full set of specifically-designed interactions supported in our efficient web-based visualization tool. The usefulness of our method is demonstrated using various multi- and high-dimensional benchmark datasets. Our implicit differentiation vector transformation is evaluated through numerical comparisons; the overall method is evaluated through exploration examples and use cases.", "keywords": "High-dimensional data visualization,dimensionality reduction,local linear subspaces,user interaction", "link": "http://dx.doi.org/10.1109/TVCG.2020.3030368", "refList": ["10.3844/jcssp.2018.613.622", "10.1016/j.aci.2018.08.003", "10.3390/info9030065", "10.1016/j.visinf.2018.09.003", "10.1371/journal.pone.0118432", "10.1016/s0893-6080(05)80023-1", "10.1109/tvcg.2020.2986996", "10.1109/icst.2012.56", "10.1007/s10844-013-0250-y", "10.1109/tbdata.2018", "10.1145/1125451.1125659", "10.1109/tvcg.2013.125", "10.1177/1473871611412817", "10.1145/3290605.3300911", "10.1111/cgf.14034", "10.1007/s13721-013-0034-x", "10.1016/j.procs.2017.05.216", "10.1016/j.ins.2009.08.025", "10.1109/tvcg.2013.124", "10.1109/tvcg.2018.2864499", "10.1109/tvcg.2018.2864475", "10.1080/10447318.2020.1741118", "10.1016/j.imu.2019.100203", "10.1109/tvcg.2018.2865240", "10.1186/s12864-019-6413-7", "10.1109/tvcg.2015.2467551", "10.1002/widm.1249", "10.1007/978-3-319-66429-3\\_29", "10.1109/tvcg.2014.2346481", "10.1109/tvcg.2018.2864825", "10.1177/1473871620904671", "10.1109/tvcg.2019.2934267", "10.1136/bmjopen-2016-012799", "10.1109/smartgridcomm.2017.8340682", "10.1007/s10664-015-9401-9", "10.1145/1143844.1143874", "10.1111/cgf.12389", "10.1109/tvcg.2018.2872577", "10.1007/978-981-13-5802-9\\_20", "10.1016/j.ipm.2009.03.002", "10.5220/0006431602160222", "10.1109/mcg.2015.50", "10.1109/tvcg.2014.2346574", "10.1007/bf02289565", "10.1109/tvcg.2017.2744378", "10.1016/j.patrec.2008.08.010", "10.1023/a:1010933404324", "10.9735/2229-3981"], "wos": 1, "children": [], "len": 1}, {"doi": "10.1109/tvcg.2020.3030465", "title": "Visual Causality Analysis of Event Sequence Data", "year": "2020", "conferenceName": "VAST", "authors": "Zhuochen Jin;Shunan Guo;Nan Chen;Daniel Weiskopf;David Gotz;Nan Cao", "citationCount": "0", "affiliation": "Cao, N (Corresponding Author), Tongji Univ, IDVx Lab, Shanghai, Peoples R China. Jin, Zhuochen; Guo, Shunan; Chen, Nan; Cao, Nan, Tongji Univ, IDVx Lab, Shanghai, Peoples R China. Weiskopf, Daniel, Univ Stuttgart, Stuttgart, Germany. Gotz, David, Univ N Carolina, Chapel Hill, NC 27515 USA.", "countries": "USA;Germany;China", "abstract": "Causality is crucial to understanding the mechanisms behind complex systems and making decisions that lead to intended outcomes. Event sequence data is widely collected from many real-world processes, such as electronic health records, web clickstreams, and financial transactions, which transmit a great deal of information reflecting the causal relations among event types. Unfortunately, recovering causalities from observational event sequences is challenging, as the heterogeneous and high-dimensional event variables are often connected to rather complex underlying event excitation mechanisms that are hard to infer from limited observations. Many existing automated causal analysis techniques suffer from poor explainability and fail to include an adequate amount of human knowledge. In this paper, we introduce a visual analytics method for recovering causalities in event sequence data. We extend the Granger causality analysis algorithm on Hawkes processes to incorporate user feedback into causal model refinement. The visualization system includes an interactive causal analysis framework that supports bottom-up causal exploration, iterative causal verification and refinement, and causal comparison through a set of novel visualizations and interactions. We report two forms of evaluation: a quantitative evaluation of the model improvements resulting from the user-feedback mechanism, and a qualitative evaluation through case studies in different application domains to demonstrate the usefulness of the system.", "keywords": "Event sequence data,causality analysis,visual analytics", "link": "http://dx.doi.org/10.1109/TVCG.2020.3030465", "refList": ["10.5555/1642718", "10.1109/tvcg.2018.2865022", "10.5555/2074094.2074151", "10.1109/tvcg.2016.2618797", "10.1073/pnas.1320645111", "10.1109/tvcg.2017.2744843", "10.1109/iv.2017.69", "10.1109/tvcg.2019.2934399", "10.1145/3172944.3173007", "10.5555/1795555", "10.1109/mcg.2005.102", "10.1145/381641.381653", "10.1162/153244301753344614", "10.1111/cgf.14034", "10.1111/cgf.13198", "10.1017/cbo9780511519857", "10.1007/s10462-016-9475-9", "10.1075/ssol.2.2.07bor", "10.1007/978-1-4614-3223-4\\_3", "10.1109/infvis.2003.1249025", "10.1007/978-94-007-6094-313", "10.1145/2858036.2858387", "10.1109/tvcg.2007.70528", "10.1109/tvcg.2017.2674958", "10.1147/sj.454.0801", "10.1109/tvcg.2013.119", "10.1145/3173574.3173711", "10.1016/j.erss.2017.06.034", "10.1109/visual.2019.8933695", "10.1007/s11665-016-2173-6", "10.1016/0377-0427(87)90125-7", "10.2307/3601125", "10.1016/b978-0-444-88738-2.50018-x", "10.1109/mcg.2006.70", "10.1109/tvcg.2018.2865145", "10.1017/s1351324997001502", "10.1109/tvcg.2010.179", "10.1214/aos/1176344552", "10.1109/mcg.2009.22", "10.1007/978-3-319-26633-6\\_13", "10.1080/10447318.2014.905422", "10.1016/j.visinf.2019.03.004", "10.1057/palgrave.ivs.9500074", "10.1007/978-1-4614-3223-4"], "wos": 1, "children": [], "len": 1}], "len": 5}, {"doi": "10.1111/cgf.13972", "year": "2020", "title": "Boxer: Interactive Comparison of Classifier Results", "conferenceName": "EuroVis", "authors": "Michael Gleicher;Aditya Barve;Xinyi Yu;Florian Heimerl", "citationCount": "0", "affiliation": "Gleicher, M (Corresponding Author), Univ Wisconsin, Madison, WI 53706 USA.\nGleicher, Michael; Barve, Aditya; Yu, Xinyi; Heimerl, Florian, Univ Wisconsin, Madison, WI 53706 USA.", "countries": "USA", "abstract": "Machine learning practitioners often compare the results of different classifiers to help select, diagnose and tune models. We present Boxer, a system to enable such comparison. Our system facilitates interactive exploration of the experimental results obtained by applying multiple classifiers to a common set of model inputs. The approach focuses on allowing the user to identify interesting subsets of training and testing instances and comparing performance of the classifiers on these subsets. The system couples standard visual designs with set algebra interactions and comparative elements. This allows the user to compose and coordinate views to specify subsets and assess classifier performance on them. The flexibility of these compositions allow the user to address a wide range of scenarios in developing and assessing classifiers. We demonstrate Boxer in use cases including model selection, tuning, fairness assessment, and data quality diagnosis.", "keywords": "", "link": "https://doi.org/10.1111/cgf.13972", "refList": ["10.1109/tvcg.2019.2934629", "10.1109/tvcg.2017.2744359", "10.1109/tvcg.2016.2598838", "10.1007/s10618-014-0368-8", "10.1109/tvcg.2017.2744938", "10.1109/tvcg.2019.2934262", "10.1145/3287560.3287589", "10.1109/vast.2017.8585721", "10.1109/tvcg.2016.2598828", "10.1109/tvcg.2009.128", "10.1109/tvcg.2017.2744018", "10.1080/00994480.2000.10748487", "10.5555/3305890.3306024", "10.1109/iccv.2015.329", "10.1109/tvcg.2013.125", "10.1089/big.2016.0007", "10.1109/memsys.2019.8870817", "10.1145/2939672.2939778", "10.1007/s11104-019-04156-0", "10.1371/journal.pone.0181142", "10.1145/3301275.3302324", "10.1109/tvcg.2017.2745158", "10.1109/tvcg.2018.2865044", "10.1023/a:1010933404324", "10.1145/2487575.2487579", "10.1109/tvcg.2013.157", "10.1145/2783258.2788613", "10.1109/tvcg.2017.2744199", "10.1109/tvcg.2019.2934631", "10.1016/s0304-3800(02)00064-9", "10.1007/s10115-013-0679-x", "10.1109/tvcg.2019.2934267", "10.1007/978-3-319-10590-1\\_53", "10.1109/vast.2017.8585720", "10.1016/0004-3702(80)90021-1", "10.1109/tvcg.2015.2467618", "10.1109/tvcg.2018.2864477", "10.1109/tvcg.2009.84", "10.1007/s11263-016-0911-8", "10.1111/cgf.12918", "10.1111/cgf.12373", "10.1109/tvcg.2017.2744878", "10.1109/tvcg.2018.2864812", "10.1109/mcg.2019.2919033", "10.1080/00207176808905715", "10.1002/er.3827", "10.1109/tvcg.2014.2346660", "10.1111/cgf.13417", "10.1109/tvcg.2019.2934659", "10.1109/tvcg.2017.2744158", "10.1016/b978-0-12-815849-4.00004-9", "10.1097/ede.0b013e3181c30fb2", "10.1111/cgf.13681", "10.1016/j.ejor.2006.04.051", "10.1109/tvcg.2019.2934619", "10.1109/tvcg.2016.2598468", "10.9735/2229-3981", "10.1109/tvcg.2016.2598831"], "wos": 1, "children": [], "len": 1}], "len": 11}, {"doi": "10.1109/tvcg.2019.2934264", "title": "The Validity, Generalizability and Feasibility of Summative Evaluation Methods in Visual Analytics", "year": "2019", "conferenceName": "VAST", "authors": "Mosab Khayat;Morteza Karimzadeh;David S. Ebert;Arif Ghafoor", "citationCount": "1", "affiliation": "Khayat, M (Corresponding Author), Purdue Univ, W Lafayette, IN 47907 USA. Khayat, Mosab; Karimzadeh, Morteza; Ebert, David S.; Ghafoor, Arif, Purdue Univ, W Lafayette, IN 47907 USA. Karimzadeh, Morteza, Univ Colorado, Boulder, CO 80309 USA.", "countries": "USA", "abstract": "Many evaluation methods have been used to assess the usefulness of Visual Analytics (VA) solutions. These methods stem from a variety of origins with different assumptions and goals, which cause confusion about their proofing capabilities. Moreover, the lack of discussion about the evaluation processes may limit our potential to develop new evaluation methods specialized for VA. In this paper, we present an analysis of evaluation methods that have been used to summatively evaluate VA solutions. We provide a survey and taxonomy of the evaluation methods that have appeared in the VAST literature in the past two years. We then analyze these methods in terms of validity and generalizability of their findings, as well as the feasibility of using them. We propose a new metric called summative quality to compare evaluation methods according to their ability to prove usefulness, and make recommendations for selecting evaluation methods based on their summative quality in the VA domain.", "keywords": "Summative evaluation,usefulness,evaluation process,taxonomy,visual analytics", "link": "http://dx.doi.org/10.1109/TVCG.2019.2934264", "refList": ["10.1109/tvcg.2017.2744478", "10.1109/tvcg.2018.2865025", "10.1109/tvcg.2006.85", "10.1109/tvcg.2014.2346331", "10.1109/beliv.2018.8634420", "10.1109/tvcg.2017.2745181", "10.1111/cgf.13677", "10.1109/tvcg.2018.2864844", "10.1109/tvcg.2013.126", "10.1109/tvcg.2018.2864811", "10.1109/infvis.2005.1532147", "10.1177/0956797613504966", "10.1145/2669557.2669579", "10.1109/mcg.2005.102", "10.1109/visual.2003.1250426", "10.1136/bmj.39489.470347.ad", "10.1109/tvcg.2017.2744080", "10.1109/mcg.2009.53", "10.1111/j.1467-8527.2005.00307.x", "10.1109/tvcg.2010.132", "10.1109/tvcg.2018.2864886", "10.1109/tvcg.2018.2864843", "10.1109/tvcg.2018.2865028", "10.1109/tvcg.2018.2865051", "10.1109/tvcg.2018.2865044", "10.1109/tvcg.2018.2865026", "10.1007/978-3-540-71080-6\\_6", "10.1109/tvcg.2018.2865020", "10.1177/1473871611407399", "10.1109/tvcg.2018.2864504", "10.1109/tvcg.2018.2864526", "10.1109/tvcg.2005.53", "10.1109/tvcg.2018.2864905", "10.1049/sej.1991.0040", "10.1109/tvcg.2015.2513410", "10.1109/tvcg.2017.2711030", "10.1109/tvcg.2011.279", "10.1109/vast.2017.8585505", "10.1147/jrd.2010.2042914", "10.1016/s0378-7206(98)00044-5", "10.1145/2993901.2993913", "10.1109/tvcg.2018.2865041", "10.1109/tvcg.2018.2864812", "10.1109/tvcg.2017.2744758", "10.1145/1168149.1168158", "10.1109/tvcg.2017.2745279", "10.1109/tvcg.2012.213", "10.1109/tvcg.2017.2744738", "10.1109/tvcg.2017.2745083", "10.1109/tvcg.2018.2864826", "10.1145/1377966.1377974", "10.1109/apec.2009.4802646", "10.1145/1168149.1168152", "10.1016/j.jss.2008.03.059", "10.1109/vast.2017.8585484", "10.1109/tvcg.2017.2744818", "10.1109/tvcg.2017.2744358", "10.1109/tvcg.2018.2864499", "10.1109/tvcg.2018.2865042", "10.1109/tvcg.2017.2744898"], "wos": 1, "children": [{"doi": "10.1109/tvcg.2020.3030388", "title": "Visualization of Human Spine Biomechanics for Spinal Surgery", "year": "2020", "conferenceName": "SciVis", "authors": "Pepe Eulzer;Sabine Bauer;Francis Kilian;Kai Lawonn", "citationCount": "0", "affiliation": "Eulzer, P (Corresponding Author), Univ Jena, Jena, Germany. Eulzer, Pepe; Lawonn, Kai, Univ Jena, Jena, Germany. Bauer, Sabine, Univ Koblenz Landau, Koblenz, Germany. Kilian, Francis, Cath Clin Koblenz Montabaur, Dept Spine Surg, Koblenz, Germany.", "countries": "Germany", "abstract": "We propose a visualization application, designed for the exploration of human spine simulation data. Our goal is to support research in biomechanical spine simulation and advance efforts to implement simulation-backed analysis in surgical applications. Biomechanical simulation is a state-of-the-art technique for analyzing load distributions of spinal structures. Through the inclusion of patient-specific data, such simulations may facilitate personalized treatment and customized surgical interventions. Difficulties in spine modelling and simulation can be partly attributed to poor result representation, which may also be a hindrance when introducing such techniques into a clinical environment. Comparisons of measurements across multiple similar anatomical structures and the integration of temporal data make commonly available diagrams and charts insufficient for an intuitive and systematic display of results. Therefore, we facilitate methods such as multiple coordinated views, abstraction and focus and context to display simulation outcomes in a dedicated tool. $\\mathrm{By}$ linking the result data with patient-specific anatomy, we make relevant parameters tangible for clinicians. Furthermore, we introduce new concepts to show the directions of impact force vectors, which were not accessible before. We integrated our toolset into a spine segmentation and simulation pipeline and evaluated our methods with both surgeons and biomechanical researchers. When comparing our methods against standard representations that are currently in use, we found increases in accuracy and speed in data exploration tasks. $\\mathrm{in}$ a qualitative review, domain experts deemed the tool highly useful when dealing with simulation result data, which typically combines time-dependent patient movement and the resulting force distributions on spinal structures.", "keywords": "Medical visualization,bioinformatics,coordinated views,focus and context,biomechanical simulation", "link": "http://dx.doi.org/10.1109/TVCG.2020.3030388", "refList": ["10.1109/tvcg.2018.2864903", "10.1177/1473871613510429", "10.1093/ehjqcco/qcz052", "10.1109/tvcg.2007.70594", "10.1109/tvcg.2018.2865076", "10.1055/s-0039-1687862", "10.1109/visual.1990.146375", "10.1109/tvcg.2017.2744198", "10.1016/j.ijmedinf.2014.10.001", "10.1109/tvcg.2013.124", "10.1016/j.jacc", "10.1111/cgf.13167", "10.17705/1thci.00055", "10.1136/bmjqs.2009.037895", "10.1109/tvcg.2013.238", "10.1109/tvcg.2018.2865240", "10.1186/1471-2261-6-34", "10.1109/tvcg.2019.2934264", "10.1109/tvcg.2013.200", "10.1109/tvcg.2011.209", "10.1109/tvcg.2014.2346682", "10.1109/tvcg.2015.2467091", "10.1136/bmjopen-2019-033208", "10.1109/beliv.2018.8634027", "10.1109/tvcg.2012.213", "10.1109/tvcg.2015.2467191", "10.1109/tvcg.2015.2467325", "10.1145/2133806.2133821", "10.1145/1806799.1806866", "10.1108/02635570610688869", "10.1002/hbm.20701", "10.1561/1100000039", "10.1145/3025453.3025645", "10.1109/tvcg.2009.111", "10.1109/tvcg.2013.120", "10.1109/tvcg.2016.2599030"], "wos": 1, "children": [], "len": 1}], "len": 3}, {"doi": "10.1109/tvcg.2019.2934595", "title": "Visual Interaction with Deep Learning Models through Collaborative Semantic Inference", "year": "2019", "conferenceName": "VAST", "authors": "Sebastian Gehrmann;Hendrik Strobelt;Robert Kr\u00fcger;Hanspeter Pfister;Alexander M. Rush", "citationCount": "3", "affiliation": "Gehrmann, S (Corresponding Author), Harvard NLP Grp, Cambridge, MA 02138 USA. Gehrmann, Sebastian; Rush, Alexander M., Harvard NLP Grp, Cambridge, MA 02138 USA. Strobelt, Hendrik, IBM Res Cambridge, Cambridge, MA USA. Kruger, Robert, MIT IBM Watson AI Lab, Cambridge, MA USA. Pfister, Hanspeter, Harvard Visual Comp Grp, Cambridge, MA USA.", "countries": "USA", "abstract": "Automation of tasks can have critical consequences when humans lose agency over decision processes. Deep learning models are particularly susceptible since current black-box approaches lack explainable reasoning. We argue that both the visual interface and model structure of deep learning systems need to take into account interaction design. We propose a framework of collaborative semantic inference (CSI) for the co-design of interactions and models to enable visual collaboration between humans and algorithms. The approach exposes the intermediate reasoning process of models which allows semantic interactions with the visual metaphors of a problem, which means that a user can both understand and control parts of the model reasoning process. We demonstrate the feasibility of CSI with a co-designed case study of a document summarization system.", "keywords": "Human-Computer Collaboration,Deep Learning,Neural Networks,Interaction Design,Human-Centered Design", "link": "http://dx.doi.org/10.1109/TVCG.2019.2934595", "refList": ["10.1109/vast.2017.8585721", "10.1109/tvcg.2012.195", "10.1613/jair.295", "10.1162/tacl\\textbackslash{}a\\textbackslash{}00254", "10.1007/978-3-540-70956-5", "10.1145/2678025.2701399", "10.1016/j.visinf.2017.01.006", "10.1145/2858036.2858529", "10.5555/645526.657137", "10.1146/annurev.neur0.26.041002.131047.issn", "10.1145/2207676.2207741", "10.1145/2939672.2939778", "10.1109/vlhcc.2010.15", "10.3115/v1/d14-1130", "10.18653/v1/p17-1099", "10.1109/tvcg.2018.2865044", "10.18653/v1/p17-1080", "10.1111/cgf.13210", "10.1162/tacl\\_a\\_00254", "10.1109/tvcg.2018.2816223", "10.1109/72.279181", "10.1145/2783258.2788613", "10.2112/si85-057.1", "10.1145/1866029.1866078", "10.1007/978-3-319-10590-1\\_53", "10.1109/tvcg.2018.2865230", "10.1007/s12650-018-0531-1", "10.1145/2365952.2365964", "10.1017/s026988890200019x", "10.1109/iccv.2015.337", "10.1109/tvcg.2017.2744878", "10.1145/3027063.3053103", "10.1109/tvcg.2017.2744718", "10.1145/302979.303030", "10.1109/cvpr.2018.00917", "10.1007/s40708-016-0042-6", "10.1073/pnas.1807184115", "10.1609/aimag.v35i4.2513", "10.1016/j.ijhcs.2009.03.004", "10.1109/tvcg.2017.2744158", "10.1109/tvcg.2018.2864838", "10.1111/cgf.13092", "10.1109/tvcg.2018.2865027", "10.1109/tvcg.2014.2346574", "10.1109/tvcg.2017.2744358", "10.1109/tvcg.2018.2864499", "10.1016/s0167-739x(97)00022-8", "10.1093/bi0inf0rmatics/bth267"], "wos": 1, "children": [{"doi": "10.1111/cgf.14034", "year": "2020", "title": "The State of the Art in Enhancing Trust in Machine Learning Models with the Use of Visualizations", "conferenceName": "EuroVis", "authors": "Angelos Chatzimparmpas;Rafael Messias Martins;Ilir Jusufi;Kostiantyn Kucher;Fabrice Rossi;Andreas Kerren", "citationCount": "2", "affiliation": "Chatzimparmpas, A (Corresponding Author), Linnaeus Univ, Dept Comp Sci \\& Media Technol, Vaxjo, Sweden.\nChatzimparmpas, A.; Martins, R. M.; Jusufi, I.; Kucher, K.; Kerren, A., Linnaeus Univ, Dept Comp Sci \\& Media Technol, Vaxjo, Sweden.\nRossi, F., PSL Univ, Univ Paris Dauphine, Ceremade, Paris, France.", "countries": "Sweden;France", "abstract": "Machine learning (ML) models are nowadays used in complex applications in various domains, such as medicine, bioinformatics, and other sciences. Due to their black box nature, however, it may sometimes be hard to understand and trust the results they provide. This has increased the demand for reliable visualization tools related to enhancing trust in ML models, which has become a prominent topic of research in the visualization community over the past decades. To provide an overview and present the frontiers of current research on the topic, we present a State-of-the-Art Report (STAR) on enhancing trust in ML models with the use of interactive visualization. We define and describe the background of the topic, introduce a categorization for visualization techniques that aim to accomplish this goal, and discuss insights and opportunities for future research directions. Among our contributions is a categorization of trust against different facets of interactive ML, expanded and improved from previous research. Our results are investigated from different analytical perspectives: (a) providing a statistical overview, (b) summarizing key findings, (c) performing topic analyses, and (d) exploring the data sets used in the individual papers, all with the support of an interactive web-based survey browser. We intend this survey to be beneficial for visualization researchers whose interests involve making ML models more trustworthy, as well as researchers and practitioners from other disciplines in their search for effective visualization techniques suitable for solving their tasks with confidence and conveying meaning to their data.", "keywords": "trustworthy machine learning; visualization; interpretable machine learning; explainable machine learning", "link": "https://doi.org/10.1111/cgf.14034", "refList": ["10.1109/mcg.2018.2878902", "10.1109/tvcg.2008.153", "10.2312/mlvis.20181130", "10.1109/tvcg.2016.2598828", "10.1145/3290605.3300911", "10.1145/2993901.2993909", "10.2312/mlvis.20191158", "10.1109/tvcg.2016.2598446", "10.1111/j.1467-8659.2009.01475.x", "10.1145/3290605.3300809", "10.1109/pacificvis.2018.00031", "10.1055/s-0029-1216348", "10.1007/978-3-319-90403-0\\_13", "10.1109/tvcg.2017.2745085", "10.1111/j.1467-8659.2011.01938.x", "10.1007/978-3-319-54024-5\\_6", "10.1016/s0167-9473(01)00065-2", "10.1111/cgf.12895", "10.2312/eurovisshort.20141152.17", "10.2312/eurova.20151098.22", "10.1111/cgf.13667", "10.3115/1072228.1072378", "10.1109/tbdata.2018.2877350.16", "10.1109/lars.2009.5418323.25", "10.1109/tvcg.2017.2744878", "10.1016/j.combustflame.2005.09.018", "10.1016/j.cag.2014.01.006", "10.1109/tvcg.2016.2570755", "10.2312/mlvis.20191158.1,19", "10.1518/hfes.46.1.50.30392", "10.1145/3301275.3302280", "10.1145/3351095.3372834.1", "10.1016/s0377-2217(01)00264-8", "10.1111/cgf.13424", "10.1007/978-3-319-23485-4\\_53", "10.1007/978-94-007-0753-5\\_3623", "10.1109/tvcg.2013.101", "10.1111/cgf.12884", "10.1111/j.1467-8659.2010.01835.x", "10.1021/ci9901338", "10.4230/lipics.itcs:2017", "10.1109/mis.2013.24", "10.1109/tvcg.2014.2346482", "10.1109/tvcg.2018.2865230", "10.1073/pnas.1807180116", "10.1109/dsaa.2018.00018", "10.1109/tvcg.2009.153", "10.3115/1219840.1219855", "10.1109/tvcg.2018.2864812", "10.1109/tvcg.2018.2872577", "10.2312/trvis.20191183", "10.1109/cvpr:2004.383", "10.1109/vast.2008.4677350", "10.1145/302979.303001", "10.1109/tvcg.2018.2864499", "10.1111/cgf.13672", "10.1109/tvcg.2014.2346626", "10.23915/distill.00010.18", "10.1109/tvcg.2017.2744805", "10.2312/mlvis:20191160.18", "10.23915/distill:00016", "10.1109/pacificvis.2016.7465260", "10.1111/cgf.13683", "10.23915/distill.00016.19", "10.1145/32906053.300803.22", "10.1109/tvcg.2014.2346574", "10.1177/1473871615600010", "10.1109/tvcg.2016.2598831", "10.1145/3230623", "10.1109/visual.2019.8933744", "10.1145/2993901.2993915", "10.1016/j.visinf.2017.01.006", "10.1145/2993901.2993914", "10.1109/tvcg.2014.2346984", "10.1109/5.726791", "10.23915/distill.00010", "10.1109/tvcg.2018.2864825", "10.2307/2394164", "10.1109/tvcg.2017.2744458", "10.1145/2993901.2993917.28", "10.1111/cgf.13711", "10.1109/tvcg.2016.2598664", "10.2307/2530428", "10.1109/icdar.1997.620583", "10.1109/tvcg.2017.2744718", "10.1111/cgf.13425", "10.1109/tvcg.2019.2903943", "10.1145/1518701.1518895", "10.1109/tvcg.2018.2864838", "10.1145/62038.62043", "10.1111/j.1467-8659.2011.01920.x", "10.1145/3025171.3025208", "10.1145/355112.355124", "10.1109/vast.2010.5652398", "10.1109/tvcg.2014.2346578", "10.1145/3173574.3174209", "10.4178/epih/e2014008", "10.1109/beliv.2018.8634201.25,28", "10.1016/j.eswa.2007.12.020", "10.1111/cgf:13406", "10.1109/mcg.2011.103", "10.1631/fitee.1700808", "10.1109/tvcg.2017.2745158", "10.1073/pnas.0307752101", "10.1109/tvcg.2018.2816223", "10.1109/tvcg.2017.2745141", "10.1145/32232.32234", "10.1109/tvcg.2019.2934267", "10.1109/tvcg.2018.2864477", "10.1145/3132169", "10.2312/eurova.20151100.19", "10.1145/3172944.3172964", "10.1145/2601248.2601268", "10.1109/isai-nlp.2018.8693002.1", "10.1111/cgf.13404", "10.1007/s100320200071", "10.2312/trvis.20191183.16", "10.1111/cgf.12755", "10.1145/2702123.2702509", "10.1145/1401890.1402008.25", "10.1109/tvcg.2012.65", "10.1177/1473871617733996", "10.2312/trvis.20191187.7", "10.21236/ada273556", "10.1109/vast.2010.5652450", "10.1111/j.1467-8659.2011.01940.x", "10.1177/875647939000600106", "10.1109/tvcg.2017.2711030", "10.1016/j.immuni.2016.04.014", "10.1109/tvcg.2019.2934209", "10.1016/0095-0696(78)90006-2", "10.1016/j.jclinepi.2015.04.014", "10.1016/j.ress.2013.02.013", "10.1111/cgf.12640", "10.1145/1015330.1015388.25", "10.1111/j.1467-8659.2009.01468.x", "10.1145/1541880.1541882", "10.1109/vast.2011.6102453", "10.1016/s0008-8846(98)00165-3", "10.2312/trvis.20191186.7", "10.1007/s13748-013-0040-3", "10.1109/tvcg.2015.2467757", "10.1109/tbdata.2018.2877350", "10.1109/vast.2017.8585613", "10.1080/10556789208805504", "10.1109/vast.2012.6400484", "10.1145/3025171.3025181", "10.1007/978-3-319-90403-0\\_12", "10.1109/mcg.2019.2922592", "10.1021/ci000392t", "10.1109/vast.2007.4389000", "10.1111/cgf.13406.16", "10.1111/cgf.13684", "10.2312/eurovisshort.20161166.17", "10.2312/evs:20191168", "10.1145/3041021.3055135", "10.1145/3301275.3302265", "10.1613/jair.4135", "10.1109/tvcg.2018.2864500", "10.1109/tvcg.2017.2744158", "10.1109/ssci.2015.33", "10.1111/cgf.13453", "10.2312/pe/eurovast/eurova11/049-052", "10.1145/3025171.3025181.13", "10.1145/371920.372094", "10.1109/tvcg.2017.2744938", "10.1111/j.1467-8659.2012.03108.x", "10.1109/tvcg.2019.2934251", "10.1145/3290605.3300809.18", "10.1109/ldav.2016.7874305", "10.1109/vast.2016.7883514", "10.1109/iccv.2015.425", "10.1145/3301275.3302324", "10.1109/tnnls.2013.2292894", "10.1109/tvcg.2018.2865044", "10.1109/tvcg.2013.157", "10.1371/journal.pcbi.0020161", "10.1186/s12916-019-1426-2", "10.1109/10.867928", "10.1111/cgf.13217", "10.1109/mcg.2019.2919033", "10.1145/2993901.2993910", "10.1109/tvcg.2017.2744738", "10.2307/258792", "10.1111/cgf.12655", "10.1016/j.dss.2014.03.001", "10.1109/tvcg.2019.2904069", "10.1111/cgf.13205", "10.1002/mds.22340", "10.1109/tvcg.2019.2934595", "10.1287/inte.2018.0957", "10.1109/cvpr.2007.382974", "10.1109/tvcg.2012.280", "10.1145/2678025.2701399.13", "10.2312/mlvis.20181130.13", "10.2312/eurova.20181106.16", "10.1109/tvcg.2018.2864475", "10.2312/mlvis.20191160.18,22", "10.1007/978-1-4612-4026-6.25", "10.1109/cvpr.2006.42", "10.1145/3172944.3172950", "10.1109/cvpr.2004.383.25", "10.1109/tvcg.2019.2934812", "10.1609/aimag.v35i4.2513", "10.2312/trvis.20191185.7", "10.1111/j.1467-8659.2009.01684.x", "10.1371/journal.pone.0129126", "10.1111/cgf.13092", "10.1162/coli\\_a\\_00237", "10.1109/tvcg.2017.2744818", "10.1109/vast.2011.6102448", "10.1109/tvcg.2009.111", "10.1109/tvcg.2019.2934619", "10.1016/s0377-2217(01)00264-8.25", "10.1111/cgf.12639", "10.1109/access.2019.2919343", "10.1186/s12874-019-0681-4", "10.1109/pacificvis.2015.7156366", "10.1109/pacificvis.2018.00029", "10.1109/tvcg.2019.2934261", "10.1080/13506280444000102.http://www.uvt.nl/ticc", "10.1109/vast.2018.8802509", "10.1111/cgf.13212", "10.1145/3200489", "10.1111/cgf.13176", "10.1177/1473871620904671", "10.1007/978-3-319-10590-1\\_53", "10.1111/j.1467-8659.2012.03126.x", "10.1111/cgf.13172", "10.1145/3025171.3025208.6,21", "10.1111/cgf.12366", "10.1109/tvcg.2019.2934659", "10.1109/cvprw.2009.5206848", "10.1016/j.media.2014.11.010", "10.1109/tvcg.2017.2744683", "10.1109/tvcg.2019.2934262", "10.1016/j.neucom.2006.11.018", "10.1177/1473871615571951", "10.1371/journal.pcbi.0020161.25", "10.1177/1473871611415994", "10.2312/trvis20191187", "10.2312/eurova", "10.1145/2858036.2858529", "10.1145/2207676.2207738", "10.1007/s11042-009-0417-2", "10.1145/3301275.3302317", "10.1038/s41746-019-0148-3", "10.1145/3351095.3372834", "10.1080/10691898.2011.11889627", "10.1109/tvcg.2018.2864504", "10.1109/vast.2017.8585720", "10.1109/mcg.2018.053491732", "10.1007/s10994-010-5207-6", "10.1109/tvcg.2019.2934433", "10.1016/j.cag.2017.05.005", "10.1109/tvcg.2012.279", "10.1145/3231622.3231641.19,20", "10.1145/1562849.1562851", "10.1007/11564126\\_", "10.1109/tvcg.2018.2846735", "10.3115/1225403.1225421", "10.1109/vast.2012.6400486", "10.2312/eurova.20191116.22", "10.1109/tvcg.2007.70443", "10.1080/027868291009242", "10.2312/eurova.20151100", "10.1145/2939502.2939503.19", "10.1016/j.cag.2014.02.004", "10.1145/2939672.2939778", "10.1109/vast.2010.5652484", "10.1111/cgf.12641", "10.1145/3301275.3302289", "10.1109/visual.2019.8933619", "10.1109/tvcg.2017.2672987", "10.1109/vast.2016.7883517.20", "10.1109/igarss.2017.8127684", "10.1016/j.jcae.2010.04.002", "10.1109/vast.2010.5652885", "10.1016/j.visinf.2019.03.002", "10.1007/s00371-018-1500-3", "10.1109/mcg.2018.042731661", "10.1109/34.598228", "10.1109/tvcg.2018.2865027", "10.1016/j.neucom.2017.01.105", "10.1111/cgf.12389", "10.1109/tvcg.2019.2934591", "10.1109/vast.2010.5652392.16", "10.1111/cgf.13416", "10.1080/02701367.1992.10608764", "10.1109/vast.2017.8585721", "10.1109/tvcg.2018.2843369", "10.1109/sbes.2010.27", "10.1109/vast.2015.7347637", "10.1145/1401890.1402008", "10.1016/j.bpj.2010.04.064", "10.1109/tvcg.2013.125", "10.1109/isai-nlp.2018.8693002", "10.1371/journal.pone.0160127", "10.1145/2856767.2856779", "10.1145/2678025.2701399", "10.1109/vast.2011.6102451", "10.1109/mcg.2010.18", "10.1021/ci4000213", "10.1109/vast.2012.6400492", "10.1007/11564126-49.25", "10.2312/eurova.20171114", "10.1109/vast.2010.5652443", "10.1145/3134599", "10.2312/pe/eurovast/eurovast10/013-018.19", "10.1109/tvcg.2019.2903946", "10.1109/tvcg.2015.2467717", "10.1177/1473871612460526", "10.1016/j.cag.2018.09.018", "10.1109/tvcg.2016.2598838", "10.1145/3172944.3172964.14", "10.1109/vast.2009.5333428", "10.1109/vast.2014.7042480", "10.2312/pe/eurovast/eurovast10/013-018", "10.1177/0962280215588241", "10.1145/2993901.2993917", "10.1109/cvpr.2008:4587581", "10.1109/tvcg.2015.2467551", "10.1016/j.visinf.2018.09.001", "10.1126/science.290.5500.2319", "10.2312/eurova.20151107", "10.1109/visual.2019.8933695", "10.13140/2.1.2393.1847", "10.1197/jamia.m1929", "10.1109/cvpr.2008.4587581.25", "10.1145/1518701.1518895.16", "10.1109/vds.2017.8573444", "10.2312/trvis:20191185", "10.1145/3359786", "10.13140/2.1.1341.1520", "10.2312/pe/eurovast/eurova11/049-052.17", "10.1109/tvcg.2014.2346660", "10.1145/3185517", "10.1109/adprl.2011.5967372", "10.1109/tvcg.2015.2467591", "10.1111/j.1751-9004.2009.00232.x", "10.1136/qshc.2004.010033", "10.1109/vast.2012.6400493", "10.1109/tvcg.2019.2934266", "10.1145/2971763.2971775", "10.1111/cgf.13730", "10.1109/vast.2012.6400488", "10.1111/cgf.13210", "10.1109/tvcg.2019.2934631", "10.1145/3172944.3172965", "10.1057/ivs.2010.2", "10.1109/tvcg.2017.2745258", "10.1016/j.jbusres.2019.07.039", "10.1162/jmlr.2003.3.4-5.993", "10.1109/pacificvis.2019.00044", "10.2312/pe/eurovast/eurova12/037-041", "10.1109/tvcg.2019.2934629", "10.1177/0018720814547570", "10.1145/3292500.3330908", "10.1111/j.1467-8659.2009.01467.x", "10.2312/eurova.20151098", "10.1177/1473871617713337", "10.1109/lars:2009.5418323", "10.1109/vast.2011.6102437", "10.1111/cgf.12878", "10.1561/1500000001", "10.1145/3025171.3025222", "10.1007/s11704-016-6028-y", "10.1016/j.procs.2017.05.216", "10.1109/cvpr.2007.382974.25", "10.1080/10447318.2020.1741118", "10.1109/vast.2012.6400489", "10.1145/3025171.3025172", "10.1109/tvcg.2017.2744098", "10.1109/tvcg.2005.66", "10.1016/j.dss.2009.05.016", "10.1007/978-1-4612-4026-6", "10.2312/evs.20191168.16,20,28", "10.2312/pe/eurovast/eurova12/037-041.17", "10.1145/3290605.3300803", "10.1145/1015330.1015388", "10.1111/cgf.13197", "10.1016/b978-1-55860-377-6.50048-7", "10.1111/cgf.13681", "10.1109/tvcg.2017.2744378", "10.1109/tvcg.2017.2744358", "10.1109/vast.2008.4677352"], "wos": 1, "children": [{"doi": "10.1109/tvcg.2020.3030368", "title": "Implicit Multidimensional Projection of Local Subspaces", "year": "2020", "conferenceName": "InfoVis", "authors": "Rongzheng Bian;Yumeng Xue;Liang Zhou;Jian Zhang 0070;Baoquan Chen;Daniel Weiskopf;Yunhai Wang", "citationCount": "1", "affiliation": "Wang, YH (Corresponding Author), Shandong Univ, Qingdao, Peoples R China. Zhou, L (Corresponding Author), Univ Utah, Salt Lake City, UT 84112 USA. Bian, Rongzheng; Xue, Yumeng; Wang, Yunhai, Shandong Univ, Qingdao, Peoples R China. Chen, Baoquan, Peking Univ, Beijing, Peoples R China. Zhang, Jian, Chinese Acad Sci, CNIC, Beijing, Peoples R China. Zhou, Liang, Univ Utah, Salt Lake City, UT 84112 USA. Weiskopf, Daniel, Univ Stuttgart, Stuttgart, Germany.", "countries": "USA;Germany;China", "abstract": "We propose a visualization method to understand the effect of multidimensional projection on local subspaces, using implicit function differentiation. Here, we understand the local subspace as the multidimensional local neighborhood of data points. Existing methods focus on the projection of multidimensional data points, and the neighborhood information is ignored. Our method is able to analyze the shape and directional information of the local subspace to gain more insights into the global structure of the data through the perception of local structures. Local subspaces are fitted by multidimensional ellipses that are spanned by basis vectors. An accurate and efficient vector transformation method is proposed based on analytical differentiation of multidimensional projections formulated as implicit functions. The results are visualized as glyphs and analyzed using a full set of specifically-designed interactions supported in our efficient web-based visualization tool. The usefulness of our method is demonstrated using various multi- and high-dimensional benchmark datasets. Our implicit differentiation vector transformation is evaluated through numerical comparisons; the overall method is evaluated through exploration examples and use cases.", "keywords": "High-dimensional data visualization,dimensionality reduction,local linear subspaces,user interaction", "link": "http://dx.doi.org/10.1109/TVCG.2020.3030368", "refList": ["10.3844/jcssp.2018.613.622", "10.1016/j.aci.2018.08.003", "10.3390/info9030065", "10.1016/j.visinf.2018.09.003", "10.1371/journal.pone.0118432", "10.1016/s0893-6080(05)80023-1", "10.1109/tvcg.2020.2986996", "10.1109/icst.2012.56", "10.1007/s10844-013-0250-y", "10.1109/tbdata.2018", "10.1145/1125451.1125659", "10.1109/tvcg.2013.125", "10.1177/1473871611412817", "10.1145/3290605.3300911", "10.1111/cgf.14034", "10.1007/s13721-013-0034-x", "10.1016/j.procs.2017.05.216", "10.1016/j.ins.2009.08.025", "10.1109/tvcg.2013.124", "10.1109/tvcg.2018.2864499", "10.1109/tvcg.2018.2864475", "10.1080/10447318.2020.1741118", "10.1016/j.imu.2019.100203", "10.1109/tvcg.2018.2865240", "10.1186/s12864-019-6413-7", "10.1109/tvcg.2015.2467551", "10.1002/widm.1249", "10.1007/978-3-319-66429-3\\_29", "10.1109/tvcg.2014.2346481", "10.1109/tvcg.2018.2864825", "10.1177/1473871620904671", "10.1109/tvcg.2019.2934267", "10.1136/bmjopen-2016-012799", "10.1109/smartgridcomm.2017.8340682", "10.1007/s10664-015-9401-9", "10.1145/1143844.1143874", "10.1111/cgf.12389", "10.1109/tvcg.2018.2872577", "10.1007/978-981-13-5802-9\\_20", "10.1016/j.ipm.2009.03.002", "10.5220/0006431602160222", "10.1109/mcg.2015.50", "10.1109/tvcg.2014.2346574", "10.1007/bf02289565", "10.1109/tvcg.2017.2744378", "10.1016/j.patrec.2008.08.010", "10.1023/a:1010933404324", "10.9735/2229-3981"], "wos": 1, "children": [], "len": 1}, {"doi": "10.1109/tvcg.2020.3030465", "title": "Visual Causality Analysis of Event Sequence Data", "year": "2020", "conferenceName": "VAST", "authors": "Zhuochen Jin;Shunan Guo;Nan Chen;Daniel Weiskopf;David Gotz;Nan Cao", "citationCount": "0", "affiliation": "Cao, N (Corresponding Author), Tongji Univ, IDVx Lab, Shanghai, Peoples R China. Jin, Zhuochen; Guo, Shunan; Chen, Nan; Cao, Nan, Tongji Univ, IDVx Lab, Shanghai, Peoples R China. Weiskopf, Daniel, Univ Stuttgart, Stuttgart, Germany. Gotz, David, Univ N Carolina, Chapel Hill, NC 27515 USA.", "countries": "USA;Germany;China", "abstract": "Causality is crucial to understanding the mechanisms behind complex systems and making decisions that lead to intended outcomes. Event sequence data is widely collected from many real-world processes, such as electronic health records, web clickstreams, and financial transactions, which transmit a great deal of information reflecting the causal relations among event types. Unfortunately, recovering causalities from observational event sequences is challenging, as the heterogeneous and high-dimensional event variables are often connected to rather complex underlying event excitation mechanisms that are hard to infer from limited observations. Many existing automated causal analysis techniques suffer from poor explainability and fail to include an adequate amount of human knowledge. In this paper, we introduce a visual analytics method for recovering causalities in event sequence data. We extend the Granger causality analysis algorithm on Hawkes processes to incorporate user feedback into causal model refinement. The visualization system includes an interactive causal analysis framework that supports bottom-up causal exploration, iterative causal verification and refinement, and causal comparison through a set of novel visualizations and interactions. We report two forms of evaluation: a quantitative evaluation of the model improvements resulting from the user-feedback mechanism, and a qualitative evaluation through case studies in different application domains to demonstrate the usefulness of the system.", "keywords": "Event sequence data,causality analysis,visual analytics", "link": "http://dx.doi.org/10.1109/TVCG.2020.3030465", "refList": ["10.5555/1642718", "10.1109/tvcg.2018.2865022", "10.5555/2074094.2074151", "10.1109/tvcg.2016.2618797", "10.1073/pnas.1320645111", "10.1109/tvcg.2017.2744843", "10.1109/iv.2017.69", "10.1109/tvcg.2019.2934399", "10.1145/3172944.3173007", "10.5555/1795555", "10.1109/mcg.2005.102", "10.1145/381641.381653", "10.1162/153244301753344614", "10.1111/cgf.14034", "10.1111/cgf.13198", "10.1017/cbo9780511519857", "10.1007/s10462-016-9475-9", "10.1075/ssol.2.2.07bor", "10.1007/978-1-4614-3223-4\\_3", "10.1109/infvis.2003.1249025", "10.1007/978-94-007-6094-313", "10.1145/2858036.2858387", "10.1109/tvcg.2007.70528", "10.1109/tvcg.2017.2674958", "10.1147/sj.454.0801", "10.1109/tvcg.2013.119", "10.1145/3173574.3173711", "10.1016/j.erss.2017.06.034", "10.1109/visual.2019.8933695", "10.1007/s11665-016-2173-6", "10.1016/0377-0427(87)90125-7", "10.2307/3601125", "10.1016/b978-0-444-88738-2.50018-x", "10.1109/mcg.2006.70", "10.1109/tvcg.2018.2865145", "10.1017/s1351324997001502", "10.1109/tvcg.2010.179", "10.1214/aos/1176344552", "10.1109/mcg.2009.22", "10.1007/978-3-319-26633-6\\_13", "10.1080/10447318.2014.905422", "10.1016/j.visinf.2019.03.004", "10.1057/palgrave.ivs.9500074", "10.1007/978-1-4614-3223-4"], "wos": 1, "children": [], "len": 1}], "len": 5}], "len": 7}, {"doi": "10.1109/tvcg.2020.3028957", "title": "A Visual Analytics Approach for Exploratory Causal Analysis: Exploration, Validation, and Applications", "year": "2020", "conferenceName": "VAST", "authors": "Xiao Xie;Fan Du;Yingcai Wu", "citationCount": "0", "affiliation": "Wu, YC (Corresponding Author), Zhejiang Univ, State Key Lab CAD\\&CG, Hangzhou, Zhejiang, Peoples R China. Du, F (Corresponding Author), Adobe Res, San Jose, CA 95110 USA. Xie, Xiao; Wu, Yingcai, Zhejiang Univ, State Key Lab CAD\\&CG, Hangzhou, Zhejiang, Peoples R China. Du, Fan, Adobe Res, San Jose, CA 95110 USA.", "countries": "USA;China", "abstract": "Using causal relations to guide decision making has become an essential analytical task across various domains, from marketing and medicine to education and social science. While powerful statistical models have been developed for inferring causal relations from data, domain practitioners still lack effective visual interface for interpreting the causal relations and applying them in their decision-making process. Through interview studies with domain experts, we characterize their current decision-making workflows, challenges, and needs. Through an iterative design process, we developed a visualization tool that allows analysts to explore, validate, and apply causal relations in real-world decision-making scenarios. The tool provides an uncertainty-aware causal graph visualization for presenting a large set of causal relations inferred from high-dimensional data. On top of the causal graph, it supports a set of intuitive user controls for performing what-if analyses and making action plans. We report on two case studies in marketing and student advising to demonstrate that users can effectively explore causal relations and design action plans for reaching their goals.", "keywords": "Exploratory causal analysis,correlation and causation,causal graph", "link": "http://dx.doi.org/10.1109/TVCG.2020.3028957", "refList": ["10.1109/tvcg.2019.2934629", "10.1109/tvcg.2017.2744683", "10.1109/tvcg.2017.2744938", "10.1109/tvcg.2019.2934262", "10.1109/vast.2017.8585721", "10.1109/tvcg.2018.2843369", "10.1145/3336191.3371824", "10.1016/j.visinf.2017.01.006", "10.1145/2858036.2858529", "10.1145/2939672.2939778", "10.1613/jair.346", "10.1038/s42256-019-0048-x", "10.1109/tvcg.2018.2865044", "10.1145/3287560.3287566", "10.1109/tvcg.2018.2816223", "10.1145/3287560.3287569", "10.1109/tvcg.2018.2864504", "10.1109/vast.2017.8585720", "10.1016/j.artint.2018.07.007", "10.1109/tvcg.2018.2864812", "10.1109/tvcg.2017.2744718", "10.1145/3359786", "10.1109/tvcg.2019.2934659", "10.1109/ic-cids.2019.8862140", "10.1109/tvcg.2017.2744158", "10.1038/ng.142", "10.1145/3351095.3372850", "10.1109/tvcg.2019.2934619", "10.1109/tvcg.2016.2598831"], "wos": 1, "children": [], "len": 1}, {"doi": "10.1109/tvcg.2020.3028888", "title": "A Visual Analytics Framework for Explaining and Diagnosing Transfer Learning Processes", "year": "2020", "conferenceName": "VAST", "authors": "Yuxin Ma;Arlen Fan;Jingrui He;Arun Reddy Nelakurthi;Ross Maciejewski", "citationCount": "0", "affiliation": "Ma, YX (Corresponding Author), Arizona State Univ, Tempe, AZ 85287 USA. Ma, Yuxin; Fan, Arlen; Maciejewski, Ross, Arizona State Univ, Tempe, AZ 85287 USA. He, Jingrui, Univ Illinois, Champaign, IL USA. Nelakurthi, Arun Reddy, Samsung Res Amer, Mountain View, CA USA.", "countries": "USA", "abstract": "Many statistical learning models hold an assumption that the training data and the future unlabeled data are drawn from the same distribution. However, this assumption is difficult to fulfill in real-world scenarios and creates barriers in reusing existing labels from similar application domains. Transfer Learning is intended to relax this assumption by modeling relationships between domains, and is often applied in deep learning applications to reduce the demand for labeled data and training time. Despite recent advances in exploring deep learning models with visual analytics tools, little work has explored the issue of explaining and diagnosing the knowledge transfer process between deep learning models. In this paper, we present a visual analytics framework for the multi-level exploration of the transfer learning processes when training deep neural networks. Our framework establishes a multi-aspect design to explain how the learned knowledge from the existing model is transferred into the new learning task when training deep neural networks. Based on a comprehensive requirement and task analysis, we employ descriptive visualization with performance measures and detailed inspections of model behaviors from the statistical, instance, feature, and model structure levels. We demonstrate our framework through two case studies on image classification by fine-tuning AlexNets to illustrate how analysts can utilize our framework.", "keywords": "Transfer learning,deep learning,visual analytics", "link": "http://dx.doi.org/10.1109/TVCG.2020.3028888", "refList": ["10.1109/tvcg.2014.2346578", "10.1109/tvcg.2019.2934629", "10.1109/tvcg.2017.2744683", "10.1109/tvcg.2016.2598838", "10.1109/tvcg.2017.2744938", "10.1109/tvcg.2019.2934262", "10.1109/tpami.2018.2868685", "10.1145/2702123.2702509", "10.1109/vast.2017.8585721", "10.1109/tvcg.2018.2843369", "10.1109/tvcg.2016.2598828", "10.1111/j.1467-8659.2011.01898.x", "10.1109/tvcg.2013.65", "10.1145/2976749.2978318", "10.1007/978-3-030-01424-7\\_27", "10.1109/tvcg.2019.2934261", "10.1007/s11704-016-6028-y", "10.1016/j.visinf.2017.01.006", "10.1145/2858036.2858529", "10.1109/iccv.2015.279", "10.1109/mci.2018.2840738", "10.1109/tvcg.2019.2892483", "10.1109/vast.2018.8802509", "10.1109/tvcg.2013.124", "10.1186/s40537-016-0043-6", "10.1109/tvcg.2018.2864475", "10.1145/3200489", "10.1109/tvcg.2018.2865044", "10.1111/cgf.13210", "10.1109/tvcg.2018.2816223", "10.23915/distill.00007", "10.1109/tvcg.2017.2744199", "10.1109/tkde.2018.2876857", "10.1109/tvcg.2019.2934631", "10.1109/tvcg.2018.2864504", "10.1109/tvcg.2014.2346482", "10.1109/tvcg.2015.2467618", "10.1109/tvcg.2014.2346594", "10.1109/tvcg.2011.188", "10.1007/978-3-642-15561-1\\_16", "10.1109/tvcg.2018.2864812", "10.1109/mcg.2019.2919033", "10.1109/tvcg.2017.2744718", "10.1109/tvcg.2017.2744878", "10.1109/tvcg.2016.2598541", "10.1109/tkde.2009.191", "10.1145/3065386", "10.1016/j.ins.2016.03.021", "10.1109/tvcg.2019.2903943", "10.1007/s10994-009-5152-4", "10.1109/tvcg.2019.2934659", "10.1109/tvcg.2018.2864500", "10.1109/iccv.2017.74", "10.1109/tvcg.2017.2744158", "10.1109/tvcg.2012.207", "10.1111/cgf.13092", "10.1109/tvcg.2018.2865027", "10.1109/tvcg.2017.2744378", "10.1109/tvcg.2017.2744358", "10.1109/tvcg.2019.2934619", "10.1109/tvcg.2018.2864499", "10.1109/tvcg.2017.2754480", "10.1109/tvcg.2016.2598831"], "wos": 1, "children": [], "len": 1}, {"doi": "10.1109/tvcg.2020.3030342", "title": "DECE: Decision Explorer with Counterfactual Explanations for Machine Learning Models", "year": "2020", "conferenceName": "VAST", "authors": "Furui Cheng;Yao Ming;Huamin Qu", "citationCount": "0", "affiliation": "Cheng, FR (Corresponding Author), Hong Kong Univ Sci \\& Technol, Hong Kong, Peoples R China. Cheng, Furui; Ming, Yao; Qu, Huamin, Hong Kong Univ Sci \\& Technol, Hong Kong, Peoples R China. Ming, Yao, Bloomberg LP, New York, NY USA.", "countries": "USA;China", "abstract": "With machine learning models being increasingly applied to various decision-making scenarios, people have spent growing efforts to make machine learning models more transparent and explainable. Among various explanation techniques, counterfactual explanations have the advantages of being human-friendly and actionable-a counterfactual explanation tells the user how to gain the desired prediction with minimal changes to the input. Besides, counterfactual explanations can also serve as efficient probes to the models' decisions. In this work, we exploit the potential of counterfactual explanations to understand and explore the behavior of machine learning models. We design DECE, an interactive visualization system that helps understand and explore a model's decisions on individual instances and data subsets, supporting users ranging from decision-subjects to model developers. DECE supports exploratory analysis of model decisions by combining the strengths of counterfactual explanations at instance- and subgroup-levels. We also introduce a set of interactions that enable users to customize the generation of counterfactual explanations to find more actionable ones that can suit their needs. Through three use cases and an expert interview, we demonstrate the effectiveness of DECE in supporting decision exploration tasks and instance explanations.", "keywords": "Tabular Data,Explainable Machine Learning,Counterfactual Explanation,Decision Making", "link": "http://dx.doi.org/10.1109/TVCG.2020.3030342", "refList": ["10.1109/tvcg.2019.2934629", "10.1109/tvcg.2017.2744683", "10.1145/3173574.3173951", "10.1109/tvcg.2017.2744938", "10.1109/tvcg.2019.2934262", "10.1145/3336191.3371824", "10.1016/j.visinf.2017.01.006", "10.1145/2858036.2858529", "10.1145/2939672.2939778", "10.1613/jair.346", "10.1038/s42256-019-0048-x", "10.1109/tvcg.2018.2865044", "10.1145/3287560.3287566", "10.1109/tvcg.2018.2816223", "10.1145/3287560.3287569", "10.1109/tvcg.2018.2864504", "10.1016/j.artint.2018.07.007", "10.1109/tvcg.2018.2864812", "10.1109/tvcg.2017.2744718", "10.1145/3359786", "10.1109/tvcg.2019.2934659", "10.1109/ic-cids.2019.8862140", "10.1109/tvcg.2017.2744158", "10.1038/ng.142", "10.2139/ssrn.3063289", "10.1145/3351095.3372850", "10.1109/tvcg.2019.2934619", "10.1109/tvcg.2016.2598831"], "wos": 1, "children": [], "len": 1}, {"doi": "10.1109/pacificvis48177.2020.2785", "year": "2020", "title": "Visual Interpretation of Recurrent Neural Network on Multi-dimensional Time-series Forecast", "conferenceName": "PacificVis", "authors": "Qiaomu Shen;Yanhong Wu;Yuzhe Jiang;Wei Zeng;Alexis Kai{-}Hon Lau;Anna Vianova;Huamin Qu", "citationCount": "0", "affiliation": "Shen, QM (Corresponding Author), Hong Kong Univ Sci \\& Technol, Hong Kong, Peoples R China.\nShen, Qiaomu; Jiang, Yuzhe; Lau, Alexis K. H.; Qu, Huamin, Hong Kong Univ Sci \\& Technol, Hong Kong, Peoples R China.\nWu, Yanhong, Visa Res, Palo Alto, CA USA.\nZeng, Wei, Shenzhen Inst Adv Technol, Shenzhen, Peoples R China.\nVianova, Anna, Delft Univ Technol, Delft, Netherlands.", "countries": "USA;China;Netherlands", "abstract": "Recent attempts at utilizing visual analytics to interpret Recurrent Neural Networks (RNNs) mainly focus on natural language processing (NLP) tasks that take symbolic sequences as input. However, many real-world problems like environment pollution forecasting apply RNNs on sequences of multi-dimensional data where each dimension represents an individual feature with semantic meaning such as PM2.5 and SO2. RNN interpretation on multi-dimensional sequences is challenging as users need to analyze what features are important at different time steps to better understand model behavior and gain trust in prediction. This requires effective and scalable visualization methods to reveal the complex many-to-many relations between hidden units and features. In this work, we propose a visual analytics system to interpret RNNs on multi-dimensional time-series forecasts. Specifically, to provide an overview to reveal the model mechanism, we propose a technique to estimate the hidden unit response by measuring how different feature selections affect the hidden unit output distribution. We then cluster the hidden units and features based on the response embedding vectors. Finally, we propose a visual analytics system which allows users to visually explore the model behavior from the global and individual levels. We demonstrate the effectiveness of our approach with case studies using air pollutant forecast applications.", "keywords": "interpretable machine learning; recurrent neural networks; multi-dimensional time series; air pollutant forecast", "link": "https://doi.org/10.1109/PacificVis48177.2020.2785", "refList": ["10.1109/78.650093", "10.1109/vast.2017.8585721", "10.1162/neco\\_a\\_01134", "10.1016/0950-7051(96)81920-4", "10.1111/cgf.12878", "10.1145/2783258.2788573", "10.1145/2939672.2939778", "10.1038/s41467-017-01689-9", "10.1109/cvpr.2015.7298907", "10.1109/tvcg.2018.2865044", "10.5555/2969239.2969329", "10.1016/0377-0427(87)90125-7", "10.1162/neco.1997.9.8.1735", "10.1214/aos/1013203451", "10.5555/3295222.3295230", "10.1109/icstcc.2016.7790762", "10.1016/s1352-2310(02)01002-6", "10.1016/j.atmosenv.2004.11.017", "10.1109/tvcg.2017.2744158", "10.1109/tvcg.2018.2865027", "10.1007/978-3-319-21233-3\\_6", "10.1109/tvcg.2017.2744358", "10.3115/v1/d14-1179", "10.1109/tvcg.2016.2598831"], "wos": 1, "children": [{"doi": "10.1109/tvcg.2020.3030370", "title": "TaxThemis: Interactive Mining and Exploration of Suspicious Tax Evasion Groups", "year": "2020", "conferenceName": "VAST", "authors": "Yating Lin;Kamkwai Wong;Yong Wang;Rong Zhang;Bo Dong;Huamin Qu;Qinghua Zheng", "citationCount": "0", "affiliation": "Lin, YT (Corresponding Author), Xi An Jiao Tong Univ, MOEKLINNS Lab, Xian, Shaanxi, Peoples R China. Lin, Yating; Zheng, Qinghua, Xi An Jiao Tong Univ, MOEKLINNS Lab, Xian, Shaanxi, Peoples R China. Wong, Kamkwai; Wang, Yong; Zhang, Rong; Qu, Huamin, Hong Kong Univ Sci \\& Technol, Hong Kong, Peoples R China. Dong, Bo, Xi An Jiao Tong Univ, Natl Engn Lab Big Data Analyt, Xian, Shaanxi, Peoples R China.", "countries": "China", "abstract": "Tax evasion is a serious economic problem for many countries, as it can undermine the government's tax system and lead to an unfair business competition environment. Recent research has applied data analytics techniques to analyze and detect tax evasion behaviors of individual taxpayers. However, they have failed to support the analysis and exploration of the related party transaction tax evasion (RPTTE) behaviors (e.g., transfer pricing), where a group of taxpayers is involved. In this paper, we present TaxThemis, an interactive visual analytics system to help tax officers mine and explore suspicious tax evasion groups through analyzing heterogeneous tax-related data. A taxpayer network is constructed and fused with the respective trade network to detect suspicious RPTTE groups. Rich visualizations are designed to facilitate the exploration and investigation of suspicious transactions between related taxpayers with profit and topological data analysis. Specifically, we propose a calendar heatmap with a carefully-designed encoding scheme to intuitively show the evidence of transferring revenue through related party transactions. We demonstrate the usefulness and effectiveness of TaxThemis through two case studies on real-world tax-related data and interviews with domain experts.", "keywords": "Visual Analytics,Tax Network,Tax Evasion Detection,Anomaly detection,Multidimensional data", "link": "http://dx.doi.org/10.1109/TVCG.2020.3030370", "refList": ["10.1111/cgf.12886", "10.2307/2277827", "10.1109/tvcg.2010.44", "10.1109/tits.2014.2315794", "10.1109/tvcg.2019.2934670", "10.1038/s41467-019-08987-4", "10.1111/cgf.12920", "10.1109/vast.2017.8585721", "10.1080/15230406.2015.1093431", "10.1109/tvcg.2018.2843369", "10.1038/srep01001", "10.1109/tvcg.2017.2744018", "10.1109/tvcg.2017.2744159", "10.1068/b130199p", "10.1109/tvcg.2009.143", "10.1016/j.visinf.2017.01.006", "10.1109/tvcg.2019.2892483", "10.1109/pacificvis.2017.8031583", "10.1109/pacificvis48177.2020.2785", "10.2307/2686111", "10.1109/tvcg.2015.2467199", "10.1111/cgf.12114", "10.1109/tvcg.2018.2865126", "10.1111/j.1538-4632.1996.tb00936.x", "10.1109/tvcg.2019.2934619", "10.2307/2332142", "10.1007/978-3-319-10590-1\\_53", "10.1109/cvpr.2016.485", "10.1109/cvpr.2017.17", "10.2307/2986645", "10.1109/tvcg.2014.2346321", "10.1017/s0140525x16001837", "10.1109/tvcg.2016.2598541", "10.1371/journal.pone.0207377", "10.1109/tvcg.2014.2346265", "10.1007/s4095-020-0191-7", "10.3141/1644-14", "10.1109/tvcg.2017.2744158", "10.1109/cvpr.2016.90", "10.1109/tvcg.2018.2865027", "10.1109/tvcg.2017.2785807", "10.1109/tvcg.2017.2744358", "10.1111/j.1538-4632.1995.tb00338.x", "10.1080/03081068808717359", "10.1109/tvcg.2016.2598831"], "wos": 1, "children": [], "len": 1}], "len": 3}, {"doi": "10.1111/cgf.13667", "year": "2019", "title": "V-Awake: A Visual Analytics Approach for Correcting Sleep Predictions from Deep Learning Models", "conferenceName": "EuroVis", "authors": "Humberto S. Garcia Caballero;Michel A. Westenberg;Binyam Gebre;Jarke J. van Wijk", "citationCount": "1", "affiliation": "Caballero, HSG (Corresponding Author), Eindhoven Univ Technol, Eindhoven, Netherlands.\nCaballero, Humberto S. Garcia; Westenberg, Michel A.; van Wijk, Jarke J., Eindhoven Univ Technol, Eindhoven, Netherlands.\nGebre, Binyam, Philips Res, Eindhoven, Netherlands.", "countries": "Netherlands", "abstract": "The usage of deep learning models for tagging input data has increased over the past years because of their accuracy and high-performance. A successful application is to score sleep stages. In this scenario, models are trained to predict the sleep stages of individuals. Although their predictive accuracy is high, there are still mis classifications that prevent doctors from properly diagnosing sleep-related disorders. This paper presents a system that allows users to explore the output of deep learning models in a real-life scenario to spot and analyze faulty predictions. These can be corrected by users to generate a sequence of sleep stages to be examined by doctors. Our approach addresses a real-life scenario with absence of ground truth. It differs from others in that our goal is not to improve the model itself, but to correct the predictions it provides. We demonstrate that our approach is effective in identifying faulty predictions and helping users to fix them in the proposed use case.", "keywords": "", "link": "https://doi.org/10.1111/cgf.13667", "refList": ["10.1109/tvcg.2016.2598838", "10.1109/tvcg.2017.2744938", "10.1038/nrn2868", "10.1145/2702123.2702509", "10.1109/tvcg.2016.2598828", "10.1177/1753193413501588", "10.1080/00994480.2000.10748487", "10.1007/s11263-017-1059-x", "10.1007/978-3-319-46466-4\\_8", "10.1155/2012/107046", "10.1177/0142331215587568", "10.1080/14786440109462720", "10.1109/tnsre.2017.2721116", "10.1111/cgf.12631", "10.1007/978-3-642-40763-5\\_50", "10.1016/j.jacc.2008.05.002", "10.1037/h0071325", "10.1109/tvcg.2018.2865044", "10.1109/10.867928", "10.1007/978-3-319-10590-1\\_53", "10.1161/01.cir.101.23.e215", "10.1109/cvpr.2015.7298856", "10.1109/tmi.2016.2528120", "10.1109/tvcg.2017.2744878", "10.1109/tvcg.2017.2744718", "10.1145/3065386", "10.1109/tmi.2016.2525803", "10.1109/tvcg.2017.2744158", "10.1109/iccv.2017.74", "10.1007/978-3-642-04898-2\\_455", "10.1109/cvpr.2015.7298754", "10.1007/bf02289565", "10.1109/cvpr.2015.7298935", "10.1109/tvcg.2017.2744358", "10.1109/cvpr.2016.319", "10.1109/tvcg.2016.2598831", "10.1109/tip.2005.852470"], "wos": 1, "children": [{"doi": "10.1111/cgf.14034", "year": "2020", "title": "The State of the Art in Enhancing Trust in Machine Learning Models with the Use of Visualizations", "conferenceName": "EuroVis", "authors": "Angelos Chatzimparmpas;Rafael Messias Martins;Ilir Jusufi;Kostiantyn Kucher;Fabrice Rossi;Andreas Kerren", "citationCount": "2", "affiliation": "Chatzimparmpas, A (Corresponding Author), Linnaeus Univ, Dept Comp Sci \\& Media Technol, Vaxjo, Sweden.\nChatzimparmpas, A.; Martins, R. M.; Jusufi, I.; Kucher, K.; Kerren, A., Linnaeus Univ, Dept Comp Sci \\& Media Technol, Vaxjo, Sweden.\nRossi, F., PSL Univ, Univ Paris Dauphine, Ceremade, Paris, France.", "countries": "Sweden;France", "abstract": "Machine learning (ML) models are nowadays used in complex applications in various domains, such as medicine, bioinformatics, and other sciences. Due to their black box nature, however, it may sometimes be hard to understand and trust the results they provide. This has increased the demand for reliable visualization tools related to enhancing trust in ML models, which has become a prominent topic of research in the visualization community over the past decades. To provide an overview and present the frontiers of current research on the topic, we present a State-of-the-Art Report (STAR) on enhancing trust in ML models with the use of interactive visualization. We define and describe the background of the topic, introduce a categorization for visualization techniques that aim to accomplish this goal, and discuss insights and opportunities for future research directions. Among our contributions is a categorization of trust against different facets of interactive ML, expanded and improved from previous research. Our results are investigated from different analytical perspectives: (a) providing a statistical overview, (b) summarizing key findings, (c) performing topic analyses, and (d) exploring the data sets used in the individual papers, all with the support of an interactive web-based survey browser. We intend this survey to be beneficial for visualization researchers whose interests involve making ML models more trustworthy, as well as researchers and practitioners from other disciplines in their search for effective visualization techniques suitable for solving their tasks with confidence and conveying meaning to their data.", "keywords": "trustworthy machine learning; visualization; interpretable machine learning; explainable machine learning", "link": "https://doi.org/10.1111/cgf.14034", "refList": ["10.1109/mcg.2018.2878902", "10.1109/tvcg.2008.153", "10.2312/mlvis.20181130", "10.1109/tvcg.2016.2598828", "10.1145/3290605.3300911", "10.1145/2993901.2993909", "10.2312/mlvis.20191158", "10.1109/tvcg.2016.2598446", "10.1111/j.1467-8659.2009.01475.x", "10.1145/3290605.3300809", "10.1109/pacificvis.2018.00031", "10.1055/s-0029-1216348", "10.1007/978-3-319-90403-0\\_13", "10.1109/tvcg.2017.2745085", "10.1111/j.1467-8659.2011.01938.x", "10.1007/978-3-319-54024-5\\_6", "10.1016/s0167-9473(01)00065-2", "10.1111/cgf.12895", "10.2312/eurovisshort.20141152.17", "10.2312/eurova.20151098.22", "10.1111/cgf.13667", "10.3115/1072228.1072378", "10.1109/tbdata.2018.2877350.16", "10.1109/lars.2009.5418323.25", "10.1109/tvcg.2017.2744878", "10.1016/j.combustflame.2005.09.018", "10.1016/j.cag.2014.01.006", "10.1109/tvcg.2016.2570755", "10.2312/mlvis.20191158.1,19", "10.1518/hfes.46.1.50.30392", "10.1145/3301275.3302280", "10.1145/3351095.3372834.1", "10.1016/s0377-2217(01)00264-8", "10.1111/cgf.13424", "10.1007/978-3-319-23485-4\\_53", "10.1007/978-94-007-0753-5\\_3623", "10.1109/tvcg.2013.101", "10.1111/cgf.12884", "10.1111/j.1467-8659.2010.01835.x", "10.1021/ci9901338", "10.4230/lipics.itcs:2017", "10.1109/mis.2013.24", "10.1109/tvcg.2014.2346482", "10.1109/tvcg.2018.2865230", "10.1073/pnas.1807180116", "10.1109/dsaa.2018.00018", "10.1109/tvcg.2009.153", "10.3115/1219840.1219855", "10.1109/tvcg.2018.2864812", "10.1109/tvcg.2018.2872577", "10.2312/trvis.20191183", "10.1109/cvpr:2004.383", "10.1109/vast.2008.4677350", "10.1145/302979.303001", "10.1109/tvcg.2018.2864499", "10.1111/cgf.13672", "10.1109/tvcg.2014.2346626", "10.23915/distill.00010.18", "10.1109/tvcg.2017.2744805", "10.2312/mlvis:20191160.18", "10.23915/distill:00016", "10.1109/pacificvis.2016.7465260", "10.1111/cgf.13683", "10.23915/distill.00016.19", "10.1145/32906053.300803.22", "10.1109/tvcg.2014.2346574", "10.1177/1473871615600010", "10.1109/tvcg.2016.2598831", "10.1145/3230623", "10.1109/visual.2019.8933744", "10.1145/2993901.2993915", "10.1016/j.visinf.2017.01.006", "10.1145/2993901.2993914", "10.1109/tvcg.2014.2346984", "10.1109/5.726791", "10.23915/distill.00010", "10.1109/tvcg.2018.2864825", "10.2307/2394164", "10.1109/tvcg.2017.2744458", "10.1145/2993901.2993917.28", "10.1111/cgf.13711", "10.1109/tvcg.2016.2598664", "10.2307/2530428", "10.1109/icdar.1997.620583", "10.1109/tvcg.2017.2744718", "10.1111/cgf.13425", "10.1109/tvcg.2019.2903943", "10.1145/1518701.1518895", "10.1109/tvcg.2018.2864838", "10.1145/62038.62043", "10.1111/j.1467-8659.2011.01920.x", "10.1145/3025171.3025208", "10.1145/355112.355124", "10.1109/vast.2010.5652398", "10.1109/tvcg.2014.2346578", "10.1145/3173574.3174209", "10.4178/epih/e2014008", "10.1109/beliv.2018.8634201.25,28", "10.1016/j.eswa.2007.12.020", "10.1111/cgf:13406", "10.1109/mcg.2011.103", "10.1631/fitee.1700808", "10.1109/tvcg.2017.2745158", "10.1073/pnas.0307752101", "10.1109/tvcg.2018.2816223", "10.1109/tvcg.2017.2745141", "10.1145/32232.32234", "10.1109/tvcg.2019.2934267", "10.1109/tvcg.2018.2864477", "10.1145/3132169", "10.2312/eurova.20151100.19", "10.1145/3172944.3172964", "10.1145/2601248.2601268", "10.1109/isai-nlp.2018.8693002.1", "10.1111/cgf.13404", "10.1007/s100320200071", "10.2312/trvis.20191183.16", "10.1111/cgf.12755", "10.1145/2702123.2702509", "10.1145/1401890.1402008.25", "10.1109/tvcg.2012.65", "10.1177/1473871617733996", "10.2312/trvis.20191187.7", "10.21236/ada273556", "10.1109/vast.2010.5652450", "10.1111/j.1467-8659.2011.01940.x", "10.1177/875647939000600106", "10.1109/tvcg.2017.2711030", "10.1016/j.immuni.2016.04.014", "10.1109/tvcg.2019.2934209", "10.1016/0095-0696(78)90006-2", "10.1016/j.jclinepi.2015.04.014", "10.1016/j.ress.2013.02.013", "10.1111/cgf.12640", "10.1145/1015330.1015388.25", "10.1111/j.1467-8659.2009.01468.x", "10.1145/1541880.1541882", "10.1109/vast.2011.6102453", "10.1016/s0008-8846(98)00165-3", "10.2312/trvis.20191186.7", "10.1007/s13748-013-0040-3", "10.1109/tvcg.2015.2467757", "10.1109/tbdata.2018.2877350", "10.1109/vast.2017.8585613", "10.1080/10556789208805504", "10.1109/vast.2012.6400484", "10.1145/3025171.3025181", "10.1007/978-3-319-90403-0\\_12", "10.1109/mcg.2019.2922592", "10.1021/ci000392t", "10.1109/vast.2007.4389000", "10.1111/cgf.13406.16", "10.1111/cgf.13684", "10.2312/eurovisshort.20161166.17", "10.2312/evs:20191168", "10.1145/3041021.3055135", "10.1145/3301275.3302265", "10.1613/jair.4135", "10.1109/tvcg.2018.2864500", "10.1109/tvcg.2017.2744158", "10.1109/ssci.2015.33", "10.1111/cgf.13453", "10.2312/pe/eurovast/eurova11/049-052", "10.1145/3025171.3025181.13", "10.1145/371920.372094", "10.1109/tvcg.2017.2744938", "10.1111/j.1467-8659.2012.03108.x", "10.1109/tvcg.2019.2934251", "10.1145/3290605.3300809.18", "10.1109/ldav.2016.7874305", "10.1109/vast.2016.7883514", "10.1109/iccv.2015.425", "10.1145/3301275.3302324", "10.1109/tnnls.2013.2292894", "10.1109/tvcg.2018.2865044", "10.1109/tvcg.2013.157", "10.1371/journal.pcbi.0020161", "10.1186/s12916-019-1426-2", "10.1109/10.867928", "10.1111/cgf.13217", "10.1109/mcg.2019.2919033", "10.1145/2993901.2993910", "10.1109/tvcg.2017.2744738", "10.2307/258792", "10.1111/cgf.12655", "10.1016/j.dss.2014.03.001", "10.1109/tvcg.2019.2904069", "10.1111/cgf.13205", "10.1002/mds.22340", "10.1109/tvcg.2019.2934595", "10.1287/inte.2018.0957", "10.1109/cvpr.2007.382974", "10.1109/tvcg.2012.280", "10.1145/2678025.2701399.13", "10.2312/mlvis.20181130.13", "10.2312/eurova.20181106.16", "10.1109/tvcg.2018.2864475", "10.2312/mlvis.20191160.18,22", "10.1007/978-1-4612-4026-6.25", "10.1109/cvpr.2006.42", "10.1145/3172944.3172950", "10.1109/cvpr.2004.383.25", "10.1109/tvcg.2019.2934812", "10.1609/aimag.v35i4.2513", "10.2312/trvis.20191185.7", "10.1111/j.1467-8659.2009.01684.x", "10.1371/journal.pone.0129126", "10.1111/cgf.13092", "10.1162/coli\\_a\\_00237", "10.1109/tvcg.2017.2744818", "10.1109/vast.2011.6102448", "10.1109/tvcg.2009.111", "10.1109/tvcg.2019.2934619", "10.1016/s0377-2217(01)00264-8.25", "10.1111/cgf.12639", "10.1109/access.2019.2919343", "10.1186/s12874-019-0681-4", "10.1109/pacificvis.2015.7156366", "10.1109/pacificvis.2018.00029", "10.1109/tvcg.2019.2934261", "10.1080/13506280444000102.http://www.uvt.nl/ticc", "10.1109/vast.2018.8802509", "10.1111/cgf.13212", "10.1145/3200489", "10.1111/cgf.13176", "10.1177/1473871620904671", "10.1007/978-3-319-10590-1\\_53", "10.1111/j.1467-8659.2012.03126.x", "10.1111/cgf.13172", "10.1145/3025171.3025208.6,21", "10.1111/cgf.12366", "10.1109/tvcg.2019.2934659", "10.1109/cvprw.2009.5206848", "10.1016/j.media.2014.11.010", "10.1109/tvcg.2017.2744683", "10.1109/tvcg.2019.2934262", "10.1016/j.neucom.2006.11.018", "10.1177/1473871615571951", "10.1371/journal.pcbi.0020161.25", "10.1177/1473871611415994", "10.2312/trvis20191187", "10.2312/eurova", "10.1145/2858036.2858529", "10.1145/2207676.2207738", "10.1007/s11042-009-0417-2", "10.1145/3301275.3302317", "10.1038/s41746-019-0148-3", "10.1145/3351095.3372834", "10.1080/10691898.2011.11889627", "10.1109/tvcg.2018.2864504", "10.1109/vast.2017.8585720", "10.1109/mcg.2018.053491732", "10.1007/s10994-010-5207-6", "10.1109/tvcg.2019.2934433", "10.1016/j.cag.2017.05.005", "10.1109/tvcg.2012.279", "10.1145/3231622.3231641.19,20", "10.1145/1562849.1562851", "10.1007/11564126\\_", "10.1109/tvcg.2018.2846735", "10.3115/1225403.1225421", "10.1109/vast.2012.6400486", "10.2312/eurova.20191116.22", "10.1109/tvcg.2007.70443", "10.1080/027868291009242", "10.2312/eurova.20151100", "10.1145/2939502.2939503.19", "10.1016/j.cag.2014.02.004", "10.1145/2939672.2939778", "10.1109/vast.2010.5652484", "10.1111/cgf.12641", "10.1145/3301275.3302289", "10.1109/visual.2019.8933619", "10.1109/tvcg.2017.2672987", "10.1109/vast.2016.7883517.20", "10.1109/igarss.2017.8127684", "10.1016/j.jcae.2010.04.002", "10.1109/vast.2010.5652885", "10.1016/j.visinf.2019.03.002", "10.1007/s00371-018-1500-3", "10.1109/mcg.2018.042731661", "10.1109/34.598228", "10.1109/tvcg.2018.2865027", "10.1016/j.neucom.2017.01.105", "10.1111/cgf.12389", "10.1109/tvcg.2019.2934591", "10.1109/vast.2010.5652392.16", "10.1111/cgf.13416", "10.1080/02701367.1992.10608764", "10.1109/vast.2017.8585721", "10.1109/tvcg.2018.2843369", "10.1109/sbes.2010.27", "10.1109/vast.2015.7347637", "10.1145/1401890.1402008", "10.1016/j.bpj.2010.04.064", "10.1109/tvcg.2013.125", "10.1109/isai-nlp.2018.8693002", "10.1371/journal.pone.0160127", "10.1145/2856767.2856779", "10.1145/2678025.2701399", "10.1109/vast.2011.6102451", "10.1109/mcg.2010.18", "10.1021/ci4000213", "10.1109/vast.2012.6400492", "10.1007/11564126-49.25", "10.2312/eurova.20171114", "10.1109/vast.2010.5652443", "10.1145/3134599", "10.2312/pe/eurovast/eurovast10/013-018.19", "10.1109/tvcg.2019.2903946", "10.1109/tvcg.2015.2467717", "10.1177/1473871612460526", "10.1016/j.cag.2018.09.018", "10.1109/tvcg.2016.2598838", "10.1145/3172944.3172964.14", "10.1109/vast.2009.5333428", "10.1109/vast.2014.7042480", "10.2312/pe/eurovast/eurovast10/013-018", "10.1177/0962280215588241", "10.1145/2993901.2993917", "10.1109/cvpr.2008:4587581", "10.1109/tvcg.2015.2467551", "10.1016/j.visinf.2018.09.001", "10.1126/science.290.5500.2319", "10.2312/eurova.20151107", "10.1109/visual.2019.8933695", "10.13140/2.1.2393.1847", "10.1197/jamia.m1929", "10.1109/cvpr.2008.4587581.25", "10.1145/1518701.1518895.16", "10.1109/vds.2017.8573444", "10.2312/trvis:20191185", "10.1145/3359786", "10.13140/2.1.1341.1520", "10.2312/pe/eurovast/eurova11/049-052.17", "10.1109/tvcg.2014.2346660", "10.1145/3185517", "10.1109/adprl.2011.5967372", "10.1109/tvcg.2015.2467591", "10.1111/j.1751-9004.2009.00232.x", "10.1136/qshc.2004.010033", "10.1109/vast.2012.6400493", "10.1109/tvcg.2019.2934266", "10.1145/2971763.2971775", "10.1111/cgf.13730", "10.1109/vast.2012.6400488", "10.1111/cgf.13210", "10.1109/tvcg.2019.2934631", "10.1145/3172944.3172965", "10.1057/ivs.2010.2", "10.1109/tvcg.2017.2745258", "10.1016/j.jbusres.2019.07.039", "10.1162/jmlr.2003.3.4-5.993", "10.1109/pacificvis.2019.00044", "10.2312/pe/eurovast/eurova12/037-041", "10.1109/tvcg.2019.2934629", "10.1177/0018720814547570", "10.1145/3292500.3330908", "10.1111/j.1467-8659.2009.01467.x", "10.2312/eurova.20151098", "10.1177/1473871617713337", "10.1109/lars:2009.5418323", "10.1109/vast.2011.6102437", "10.1111/cgf.12878", "10.1561/1500000001", "10.1145/3025171.3025222", "10.1007/s11704-016-6028-y", "10.1016/j.procs.2017.05.216", "10.1109/cvpr.2007.382974.25", "10.1080/10447318.2020.1741118", "10.1109/vast.2012.6400489", "10.1145/3025171.3025172", "10.1109/tvcg.2017.2744098", "10.1109/tvcg.2005.66", "10.1016/j.dss.2009.05.016", "10.1007/978-1-4612-4026-6", "10.2312/evs.20191168.16,20,28", "10.2312/pe/eurovast/eurova12/037-041.17", "10.1145/3290605.3300803", "10.1145/1015330.1015388", "10.1111/cgf.13197", "10.1016/b978-1-55860-377-6.50048-7", "10.1111/cgf.13681", "10.1109/tvcg.2017.2744378", "10.1109/tvcg.2017.2744358", "10.1109/vast.2008.4677352"], "wos": 1, "children": [{"doi": "10.1109/tvcg.2020.3030368", "title": "Implicit Multidimensional Projection of Local Subspaces", "year": "2020", "conferenceName": "InfoVis", "authors": "Rongzheng Bian;Yumeng Xue;Liang Zhou;Jian Zhang 0070;Baoquan Chen;Daniel Weiskopf;Yunhai Wang", "citationCount": "1", "affiliation": "Wang, YH (Corresponding Author), Shandong Univ, Qingdao, Peoples R China. Zhou, L (Corresponding Author), Univ Utah, Salt Lake City, UT 84112 USA. Bian, Rongzheng; Xue, Yumeng; Wang, Yunhai, Shandong Univ, Qingdao, Peoples R China. Chen, Baoquan, Peking Univ, Beijing, Peoples R China. Zhang, Jian, Chinese Acad Sci, CNIC, Beijing, Peoples R China. Zhou, Liang, Univ Utah, Salt Lake City, UT 84112 USA. Weiskopf, Daniel, Univ Stuttgart, Stuttgart, Germany.", "countries": "USA;Germany;China", "abstract": "We propose a visualization method to understand the effect of multidimensional projection on local subspaces, using implicit function differentiation. Here, we understand the local subspace as the multidimensional local neighborhood of data points. Existing methods focus on the projection of multidimensional data points, and the neighborhood information is ignored. Our method is able to analyze the shape and directional information of the local subspace to gain more insights into the global structure of the data through the perception of local structures. Local subspaces are fitted by multidimensional ellipses that are spanned by basis vectors. An accurate and efficient vector transformation method is proposed based on analytical differentiation of multidimensional projections formulated as implicit functions. The results are visualized as glyphs and analyzed using a full set of specifically-designed interactions supported in our efficient web-based visualization tool. The usefulness of our method is demonstrated using various multi- and high-dimensional benchmark datasets. Our implicit differentiation vector transformation is evaluated through numerical comparisons; the overall method is evaluated through exploration examples and use cases.", "keywords": "High-dimensional data visualization,dimensionality reduction,local linear subspaces,user interaction", "link": "http://dx.doi.org/10.1109/TVCG.2020.3030368", "refList": ["10.3844/jcssp.2018.613.622", "10.1016/j.aci.2018.08.003", "10.3390/info9030065", "10.1016/j.visinf.2018.09.003", "10.1371/journal.pone.0118432", "10.1016/s0893-6080(05)80023-1", "10.1109/tvcg.2020.2986996", "10.1109/icst.2012.56", "10.1007/s10844-013-0250-y", "10.1109/tbdata.2018", "10.1145/1125451.1125659", "10.1109/tvcg.2013.125", "10.1177/1473871611412817", "10.1145/3290605.3300911", "10.1111/cgf.14034", "10.1007/s13721-013-0034-x", "10.1016/j.procs.2017.05.216", "10.1016/j.ins.2009.08.025", "10.1109/tvcg.2013.124", "10.1109/tvcg.2018.2864499", "10.1109/tvcg.2018.2864475", "10.1080/10447318.2020.1741118", "10.1016/j.imu.2019.100203", "10.1109/tvcg.2018.2865240", "10.1186/s12864-019-6413-7", "10.1109/tvcg.2015.2467551", "10.1002/widm.1249", "10.1007/978-3-319-66429-3\\_29", "10.1109/tvcg.2014.2346481", "10.1109/tvcg.2018.2864825", "10.1177/1473871620904671", "10.1109/tvcg.2019.2934267", "10.1136/bmjopen-2016-012799", "10.1109/smartgridcomm.2017.8340682", "10.1007/s10664-015-9401-9", "10.1145/1143844.1143874", "10.1111/cgf.12389", "10.1109/tvcg.2018.2872577", "10.1007/978-981-13-5802-9\\_20", "10.1016/j.ipm.2009.03.002", "10.5220/0006431602160222", "10.1109/mcg.2015.50", "10.1109/tvcg.2014.2346574", "10.1007/bf02289565", "10.1109/tvcg.2017.2744378", "10.1016/j.patrec.2008.08.010", "10.1023/a:1010933404324", "10.9735/2229-3981"], "wos": 1, "children": [], "len": 1}, {"doi": "10.1109/tvcg.2020.3030465", "title": "Visual Causality Analysis of Event Sequence Data", "year": "2020", "conferenceName": "VAST", "authors": "Zhuochen Jin;Shunan Guo;Nan Chen;Daniel Weiskopf;David Gotz;Nan Cao", "citationCount": "0", "affiliation": "Cao, N (Corresponding Author), Tongji Univ, IDVx Lab, Shanghai, Peoples R China. Jin, Zhuochen; Guo, Shunan; Chen, Nan; Cao, Nan, Tongji Univ, IDVx Lab, Shanghai, Peoples R China. Weiskopf, Daniel, Univ Stuttgart, Stuttgart, Germany. Gotz, David, Univ N Carolina, Chapel Hill, NC 27515 USA.", "countries": "USA;Germany;China", "abstract": "Causality is crucial to understanding the mechanisms behind complex systems and making decisions that lead to intended outcomes. Event sequence data is widely collected from many real-world processes, such as electronic health records, web clickstreams, and financial transactions, which transmit a great deal of information reflecting the causal relations among event types. Unfortunately, recovering causalities from observational event sequences is challenging, as the heterogeneous and high-dimensional event variables are often connected to rather complex underlying event excitation mechanisms that are hard to infer from limited observations. Many existing automated causal analysis techniques suffer from poor explainability and fail to include an adequate amount of human knowledge. In this paper, we introduce a visual analytics method for recovering causalities in event sequence data. We extend the Granger causality analysis algorithm on Hawkes processes to incorporate user feedback into causal model refinement. The visualization system includes an interactive causal analysis framework that supports bottom-up causal exploration, iterative causal verification and refinement, and causal comparison through a set of novel visualizations and interactions. We report two forms of evaluation: a quantitative evaluation of the model improvements resulting from the user-feedback mechanism, and a qualitative evaluation through case studies in different application domains to demonstrate the usefulness of the system.", "keywords": "Event sequence data,causality analysis,visual analytics", "link": "http://dx.doi.org/10.1109/TVCG.2020.3030465", "refList": ["10.5555/1642718", "10.1109/tvcg.2018.2865022", "10.5555/2074094.2074151", "10.1109/tvcg.2016.2618797", "10.1073/pnas.1320645111", "10.1109/tvcg.2017.2744843", "10.1109/iv.2017.69", "10.1109/tvcg.2019.2934399", "10.1145/3172944.3173007", "10.5555/1795555", "10.1109/mcg.2005.102", "10.1145/381641.381653", "10.1162/153244301753344614", "10.1111/cgf.14034", "10.1111/cgf.13198", "10.1017/cbo9780511519857", "10.1007/s10462-016-9475-9", "10.1075/ssol.2.2.07bor", "10.1007/978-1-4614-3223-4\\_3", "10.1109/infvis.2003.1249025", "10.1007/978-94-007-6094-313", "10.1145/2858036.2858387", "10.1109/tvcg.2007.70528", "10.1109/tvcg.2017.2674958", "10.1147/sj.454.0801", "10.1109/tvcg.2013.119", "10.1145/3173574.3173711", "10.1016/j.erss.2017.06.034", "10.1109/visual.2019.8933695", "10.1007/s11665-016-2173-6", "10.1016/0377-0427(87)90125-7", "10.2307/3601125", "10.1016/b978-0-444-88738-2.50018-x", "10.1109/mcg.2006.70", "10.1109/tvcg.2018.2865145", "10.1017/s1351324997001502", "10.1109/tvcg.2010.179", "10.1214/aos/1176344552", "10.1109/mcg.2009.22", "10.1007/978-3-319-26633-6\\_13", "10.1080/10447318.2014.905422", "10.1016/j.visinf.2019.03.004", "10.1057/palgrave.ivs.9500074", "10.1007/978-1-4614-3223-4"], "wos": 1, "children": [], "len": 1}], "len": 5}], "len": 7}, {"doi": "10.1111/cgf.14034", "year": "2020", "title": "The State of the Art in Enhancing Trust in Machine Learning Models with the Use of Visualizations", "conferenceName": "EuroVis", "authors": "Angelos Chatzimparmpas;Rafael Messias Martins;Ilir Jusufi;Kostiantyn Kucher;Fabrice Rossi;Andreas Kerren", "citationCount": "2", "affiliation": "Chatzimparmpas, A (Corresponding Author), Linnaeus Univ, Dept Comp Sci \\& Media Technol, Vaxjo, Sweden.\nChatzimparmpas, A.; Martins, R. M.; Jusufi, I.; Kucher, K.; Kerren, A., Linnaeus Univ, Dept Comp Sci \\& Media Technol, Vaxjo, Sweden.\nRossi, F., PSL Univ, Univ Paris Dauphine, Ceremade, Paris, France.", "countries": "Sweden;France", "abstract": "Machine learning (ML) models are nowadays used in complex applications in various domains, such as medicine, bioinformatics, and other sciences. Due to their black box nature, however, it may sometimes be hard to understand and trust the results they provide. This has increased the demand for reliable visualization tools related to enhancing trust in ML models, which has become a prominent topic of research in the visualization community over the past decades. To provide an overview and present the frontiers of current research on the topic, we present a State-of-the-Art Report (STAR) on enhancing trust in ML models with the use of interactive visualization. We define and describe the background of the topic, introduce a categorization for visualization techniques that aim to accomplish this goal, and discuss insights and opportunities for future research directions. Among our contributions is a categorization of trust against different facets of interactive ML, expanded and improved from previous research. Our results are investigated from different analytical perspectives: (a) providing a statistical overview, (b) summarizing key findings, (c) performing topic analyses, and (d) exploring the data sets used in the individual papers, all with the support of an interactive web-based survey browser. We intend this survey to be beneficial for visualization researchers whose interests involve making ML models more trustworthy, as well as researchers and practitioners from other disciplines in their search for effective visualization techniques suitable for solving their tasks with confidence and conveying meaning to their data.", "keywords": "trustworthy machine learning; visualization; interpretable machine learning; explainable machine learning", "link": "https://doi.org/10.1111/cgf.14034", "refList": ["10.1109/mcg.2018.2878902", "10.1109/tvcg.2008.153", "10.2312/mlvis.20181130", "10.1109/tvcg.2016.2598828", "10.1145/3290605.3300911", "10.1145/2993901.2993909", "10.2312/mlvis.20191158", "10.1109/tvcg.2016.2598446", "10.1111/j.1467-8659.2009.01475.x", "10.1145/3290605.3300809", "10.1109/pacificvis.2018.00031", "10.1055/s-0029-1216348", "10.1007/978-3-319-90403-0\\_13", "10.1109/tvcg.2017.2745085", "10.1111/j.1467-8659.2011.01938.x", "10.1007/978-3-319-54024-5\\_6", "10.1016/s0167-9473(01)00065-2", "10.1111/cgf.12895", "10.2312/eurovisshort.20141152.17", "10.2312/eurova.20151098.22", "10.1111/cgf.13667", "10.3115/1072228.1072378", "10.1109/tbdata.2018.2877350.16", "10.1109/lars.2009.5418323.25", "10.1109/tvcg.2017.2744878", "10.1016/j.combustflame.2005.09.018", "10.1016/j.cag.2014.01.006", "10.1109/tvcg.2016.2570755", "10.2312/mlvis.20191158.1,19", "10.1518/hfes.46.1.50.30392", "10.1145/3301275.3302280", "10.1145/3351095.3372834.1", "10.1016/s0377-2217(01)00264-8", "10.1111/cgf.13424", "10.1007/978-3-319-23485-4\\_53", "10.1007/978-94-007-0753-5\\_3623", "10.1109/tvcg.2013.101", "10.1111/cgf.12884", "10.1111/j.1467-8659.2010.01835.x", "10.1021/ci9901338", "10.4230/lipics.itcs:2017", "10.1109/mis.2013.24", "10.1109/tvcg.2014.2346482", "10.1109/tvcg.2018.2865230", "10.1073/pnas.1807180116", "10.1109/dsaa.2018.00018", "10.1109/tvcg.2009.153", "10.3115/1219840.1219855", "10.1109/tvcg.2018.2864812", "10.1109/tvcg.2018.2872577", "10.2312/trvis.20191183", "10.1109/cvpr:2004.383", "10.1109/vast.2008.4677350", "10.1145/302979.303001", "10.1109/tvcg.2018.2864499", "10.1111/cgf.13672", "10.1109/tvcg.2014.2346626", "10.23915/distill.00010.18", "10.1109/tvcg.2017.2744805", "10.2312/mlvis:20191160.18", "10.23915/distill:00016", "10.1109/pacificvis.2016.7465260", "10.1111/cgf.13683", "10.23915/distill.00016.19", "10.1145/32906053.300803.22", "10.1109/tvcg.2014.2346574", "10.1177/1473871615600010", "10.1109/tvcg.2016.2598831", "10.1145/3230623", "10.1109/visual.2019.8933744", "10.1145/2993901.2993915", "10.1016/j.visinf.2017.01.006", "10.1145/2993901.2993914", "10.1109/tvcg.2014.2346984", "10.1109/5.726791", "10.23915/distill.00010", "10.1109/tvcg.2018.2864825", "10.2307/2394164", "10.1109/tvcg.2017.2744458", "10.1145/2993901.2993917.28", "10.1111/cgf.13711", "10.1109/tvcg.2016.2598664", "10.2307/2530428", "10.1109/icdar.1997.620583", "10.1109/tvcg.2017.2744718", "10.1111/cgf.13425", "10.1109/tvcg.2019.2903943", "10.1145/1518701.1518895", "10.1109/tvcg.2018.2864838", "10.1145/62038.62043", "10.1111/j.1467-8659.2011.01920.x", "10.1145/3025171.3025208", "10.1145/355112.355124", "10.1109/vast.2010.5652398", "10.1109/tvcg.2014.2346578", "10.1145/3173574.3174209", "10.4178/epih/e2014008", "10.1109/beliv.2018.8634201.25,28", "10.1016/j.eswa.2007.12.020", "10.1111/cgf:13406", "10.1109/mcg.2011.103", "10.1631/fitee.1700808", "10.1109/tvcg.2017.2745158", "10.1073/pnas.0307752101", "10.1109/tvcg.2018.2816223", "10.1109/tvcg.2017.2745141", "10.1145/32232.32234", "10.1109/tvcg.2019.2934267", "10.1109/tvcg.2018.2864477", "10.1145/3132169", "10.2312/eurova.20151100.19", "10.1145/3172944.3172964", "10.1145/2601248.2601268", "10.1109/isai-nlp.2018.8693002.1", "10.1111/cgf.13404", "10.1007/s100320200071", "10.2312/trvis.20191183.16", "10.1111/cgf.12755", "10.1145/2702123.2702509", "10.1145/1401890.1402008.25", "10.1109/tvcg.2012.65", "10.1177/1473871617733996", "10.2312/trvis.20191187.7", "10.21236/ada273556", "10.1109/vast.2010.5652450", "10.1111/j.1467-8659.2011.01940.x", "10.1177/875647939000600106", "10.1109/tvcg.2017.2711030", "10.1016/j.immuni.2016.04.014", "10.1109/tvcg.2019.2934209", "10.1016/0095-0696(78)90006-2", "10.1016/j.jclinepi.2015.04.014", "10.1016/j.ress.2013.02.013", "10.1111/cgf.12640", "10.1145/1015330.1015388.25", "10.1111/j.1467-8659.2009.01468.x", "10.1145/1541880.1541882", "10.1109/vast.2011.6102453", "10.1016/s0008-8846(98)00165-3", "10.2312/trvis.20191186.7", "10.1007/s13748-013-0040-3", "10.1109/tvcg.2015.2467757", "10.1109/tbdata.2018.2877350", "10.1109/vast.2017.8585613", "10.1080/10556789208805504", "10.1109/vast.2012.6400484", "10.1145/3025171.3025181", "10.1007/978-3-319-90403-0\\_12", "10.1109/mcg.2019.2922592", "10.1021/ci000392t", "10.1109/vast.2007.4389000", "10.1111/cgf.13406.16", "10.1111/cgf.13684", "10.2312/eurovisshort.20161166.17", "10.2312/evs:20191168", "10.1145/3041021.3055135", "10.1145/3301275.3302265", "10.1613/jair.4135", "10.1109/tvcg.2018.2864500", "10.1109/tvcg.2017.2744158", "10.1109/ssci.2015.33", "10.1111/cgf.13453", "10.2312/pe/eurovast/eurova11/049-052", "10.1145/3025171.3025181.13", "10.1145/371920.372094", "10.1109/tvcg.2017.2744938", "10.1111/j.1467-8659.2012.03108.x", "10.1109/tvcg.2019.2934251", "10.1145/3290605.3300809.18", "10.1109/ldav.2016.7874305", "10.1109/vast.2016.7883514", "10.1109/iccv.2015.425", "10.1145/3301275.3302324", "10.1109/tnnls.2013.2292894", "10.1109/tvcg.2018.2865044", "10.1109/tvcg.2013.157", "10.1371/journal.pcbi.0020161", "10.1186/s12916-019-1426-2", "10.1109/10.867928", "10.1111/cgf.13217", "10.1109/mcg.2019.2919033", "10.1145/2993901.2993910", "10.1109/tvcg.2017.2744738", "10.2307/258792", "10.1111/cgf.12655", "10.1016/j.dss.2014.03.001", "10.1109/tvcg.2019.2904069", "10.1111/cgf.13205", "10.1002/mds.22340", "10.1109/tvcg.2019.2934595", "10.1287/inte.2018.0957", "10.1109/cvpr.2007.382974", "10.1109/tvcg.2012.280", "10.1145/2678025.2701399.13", "10.2312/mlvis.20181130.13", "10.2312/eurova.20181106.16", "10.1109/tvcg.2018.2864475", "10.2312/mlvis.20191160.18,22", "10.1007/978-1-4612-4026-6.25", "10.1109/cvpr.2006.42", "10.1145/3172944.3172950", "10.1109/cvpr.2004.383.25", "10.1109/tvcg.2019.2934812", "10.1609/aimag.v35i4.2513", "10.2312/trvis.20191185.7", "10.1111/j.1467-8659.2009.01684.x", "10.1371/journal.pone.0129126", "10.1111/cgf.13092", "10.1162/coli\\_a\\_00237", "10.1109/tvcg.2017.2744818", "10.1109/vast.2011.6102448", "10.1109/tvcg.2009.111", "10.1109/tvcg.2019.2934619", "10.1016/s0377-2217(01)00264-8.25", "10.1111/cgf.12639", "10.1109/access.2019.2919343", "10.1186/s12874-019-0681-4", "10.1109/pacificvis.2015.7156366", "10.1109/pacificvis.2018.00029", "10.1109/tvcg.2019.2934261", "10.1080/13506280444000102.http://www.uvt.nl/ticc", "10.1109/vast.2018.8802509", "10.1111/cgf.13212", "10.1145/3200489", "10.1111/cgf.13176", "10.1177/1473871620904671", "10.1007/978-3-319-10590-1\\_53", "10.1111/j.1467-8659.2012.03126.x", "10.1111/cgf.13172", "10.1145/3025171.3025208.6,21", "10.1111/cgf.12366", "10.1109/tvcg.2019.2934659", "10.1109/cvprw.2009.5206848", "10.1016/j.media.2014.11.010", "10.1109/tvcg.2017.2744683", "10.1109/tvcg.2019.2934262", "10.1016/j.neucom.2006.11.018", "10.1177/1473871615571951", "10.1371/journal.pcbi.0020161.25", "10.1177/1473871611415994", "10.2312/trvis20191187", "10.2312/eurova", "10.1145/2858036.2858529", "10.1145/2207676.2207738", "10.1007/s11042-009-0417-2", "10.1145/3301275.3302317", "10.1038/s41746-019-0148-3", "10.1145/3351095.3372834", "10.1080/10691898.2011.11889627", "10.1109/tvcg.2018.2864504", "10.1109/vast.2017.8585720", "10.1109/mcg.2018.053491732", "10.1007/s10994-010-5207-6", "10.1109/tvcg.2019.2934433", "10.1016/j.cag.2017.05.005", "10.1109/tvcg.2012.279", "10.1145/3231622.3231641.19,20", "10.1145/1562849.1562851", "10.1007/11564126\\_", "10.1109/tvcg.2018.2846735", "10.3115/1225403.1225421", "10.1109/vast.2012.6400486", "10.2312/eurova.20191116.22", "10.1109/tvcg.2007.70443", "10.1080/027868291009242", "10.2312/eurova.20151100", "10.1145/2939502.2939503.19", "10.1016/j.cag.2014.02.004", "10.1145/2939672.2939778", "10.1109/vast.2010.5652484", "10.1111/cgf.12641", "10.1145/3301275.3302289", "10.1109/visual.2019.8933619", "10.1109/tvcg.2017.2672987", "10.1109/vast.2016.7883517.20", "10.1109/igarss.2017.8127684", "10.1016/j.jcae.2010.04.002", "10.1109/vast.2010.5652885", "10.1016/j.visinf.2019.03.002", "10.1007/s00371-018-1500-3", "10.1109/mcg.2018.042731661", "10.1109/34.598228", "10.1109/tvcg.2018.2865027", "10.1016/j.neucom.2017.01.105", "10.1111/cgf.12389", "10.1109/tvcg.2019.2934591", "10.1109/vast.2010.5652392.16", "10.1111/cgf.13416", "10.1080/02701367.1992.10608764", "10.1109/vast.2017.8585721", "10.1109/tvcg.2018.2843369", "10.1109/sbes.2010.27", "10.1109/vast.2015.7347637", "10.1145/1401890.1402008", "10.1016/j.bpj.2010.04.064", "10.1109/tvcg.2013.125", "10.1109/isai-nlp.2018.8693002", "10.1371/journal.pone.0160127", "10.1145/2856767.2856779", "10.1145/2678025.2701399", "10.1109/vast.2011.6102451", "10.1109/mcg.2010.18", "10.1021/ci4000213", "10.1109/vast.2012.6400492", "10.1007/11564126-49.25", "10.2312/eurova.20171114", "10.1109/vast.2010.5652443", "10.1145/3134599", "10.2312/pe/eurovast/eurovast10/013-018.19", "10.1109/tvcg.2019.2903946", "10.1109/tvcg.2015.2467717", "10.1177/1473871612460526", "10.1016/j.cag.2018.09.018", "10.1109/tvcg.2016.2598838", "10.1145/3172944.3172964.14", "10.1109/vast.2009.5333428", "10.1109/vast.2014.7042480", "10.2312/pe/eurovast/eurovast10/013-018", "10.1177/0962280215588241", "10.1145/2993901.2993917", "10.1109/cvpr.2008:4587581", "10.1109/tvcg.2015.2467551", "10.1016/j.visinf.2018.09.001", "10.1126/science.290.5500.2319", "10.2312/eurova.20151107", "10.1109/visual.2019.8933695", "10.13140/2.1.2393.1847", "10.1197/jamia.m1929", "10.1109/cvpr.2008.4587581.25", "10.1145/1518701.1518895.16", "10.1109/vds.2017.8573444", "10.2312/trvis:20191185", "10.1145/3359786", "10.13140/2.1.1341.1520", "10.2312/pe/eurovast/eurova11/049-052.17", "10.1109/tvcg.2014.2346660", "10.1145/3185517", "10.1109/adprl.2011.5967372", "10.1109/tvcg.2015.2467591", "10.1111/j.1751-9004.2009.00232.x", "10.1136/qshc.2004.010033", "10.1109/vast.2012.6400493", "10.1109/tvcg.2019.2934266", "10.1145/2971763.2971775", "10.1111/cgf.13730", "10.1109/vast.2012.6400488", "10.1111/cgf.13210", "10.1109/tvcg.2019.2934631", "10.1145/3172944.3172965", "10.1057/ivs.2010.2", "10.1109/tvcg.2017.2745258", "10.1016/j.jbusres.2019.07.039", "10.1162/jmlr.2003.3.4-5.993", "10.1109/pacificvis.2019.00044", "10.2312/pe/eurovast/eurova12/037-041", "10.1109/tvcg.2019.2934629", "10.1177/0018720814547570", "10.1145/3292500.3330908", "10.1111/j.1467-8659.2009.01467.x", "10.2312/eurova.20151098", "10.1177/1473871617713337", "10.1109/lars:2009.5418323", "10.1109/vast.2011.6102437", "10.1111/cgf.12878", "10.1561/1500000001", "10.1145/3025171.3025222", "10.1007/s11704-016-6028-y", "10.1016/j.procs.2017.05.216", "10.1109/cvpr.2007.382974.25", "10.1080/10447318.2020.1741118", "10.1109/vast.2012.6400489", "10.1145/3025171.3025172", "10.1109/tvcg.2017.2744098", "10.1109/tvcg.2005.66", "10.1016/j.dss.2009.05.016", "10.1007/978-1-4612-4026-6", "10.2312/evs.20191168.16,20,28", "10.2312/pe/eurovast/eurova12/037-041.17", "10.1145/3290605.3300803", "10.1145/1015330.1015388", "10.1111/cgf.13197", "10.1016/b978-1-55860-377-6.50048-7", "10.1111/cgf.13681", "10.1109/tvcg.2017.2744378", "10.1109/tvcg.2017.2744358", "10.1109/vast.2008.4677352"], "wos": 1, "children": [{"doi": "10.1109/tvcg.2020.3030368", "title": "Implicit Multidimensional Projection of Local Subspaces", "year": "2020", "conferenceName": "InfoVis", "authors": "Rongzheng Bian;Yumeng Xue;Liang Zhou;Jian Zhang 0070;Baoquan Chen;Daniel Weiskopf;Yunhai Wang", "citationCount": "1", "affiliation": "Wang, YH (Corresponding Author), Shandong Univ, Qingdao, Peoples R China. Zhou, L (Corresponding Author), Univ Utah, Salt Lake City, UT 84112 USA. Bian, Rongzheng; Xue, Yumeng; Wang, Yunhai, Shandong Univ, Qingdao, Peoples R China. Chen, Baoquan, Peking Univ, Beijing, Peoples R China. Zhang, Jian, Chinese Acad Sci, CNIC, Beijing, Peoples R China. Zhou, Liang, Univ Utah, Salt Lake City, UT 84112 USA. Weiskopf, Daniel, Univ Stuttgart, Stuttgart, Germany.", "countries": "USA;Germany;China", "abstract": "We propose a visualization method to understand the effect of multidimensional projection on local subspaces, using implicit function differentiation. Here, we understand the local subspace as the multidimensional local neighborhood of data points. Existing methods focus on the projection of multidimensional data points, and the neighborhood information is ignored. Our method is able to analyze the shape and directional information of the local subspace to gain more insights into the global structure of the data through the perception of local structures. Local subspaces are fitted by multidimensional ellipses that are spanned by basis vectors. An accurate and efficient vector transformation method is proposed based on analytical differentiation of multidimensional projections formulated as implicit functions. The results are visualized as glyphs and analyzed using a full set of specifically-designed interactions supported in our efficient web-based visualization tool. The usefulness of our method is demonstrated using various multi- and high-dimensional benchmark datasets. Our implicit differentiation vector transformation is evaluated through numerical comparisons; the overall method is evaluated through exploration examples and use cases.", "keywords": "High-dimensional data visualization,dimensionality reduction,local linear subspaces,user interaction", "link": "http://dx.doi.org/10.1109/TVCG.2020.3030368", "refList": ["10.3844/jcssp.2018.613.622", "10.1016/j.aci.2018.08.003", "10.3390/info9030065", "10.1016/j.visinf.2018.09.003", "10.1371/journal.pone.0118432", "10.1016/s0893-6080(05)80023-1", "10.1109/tvcg.2020.2986996", "10.1109/icst.2012.56", "10.1007/s10844-013-0250-y", "10.1109/tbdata.2018", "10.1145/1125451.1125659", "10.1109/tvcg.2013.125", "10.1177/1473871611412817", "10.1145/3290605.3300911", "10.1111/cgf.14034", "10.1007/s13721-013-0034-x", "10.1016/j.procs.2017.05.216", "10.1016/j.ins.2009.08.025", "10.1109/tvcg.2013.124", "10.1109/tvcg.2018.2864499", "10.1109/tvcg.2018.2864475", "10.1080/10447318.2020.1741118", "10.1016/j.imu.2019.100203", "10.1109/tvcg.2018.2865240", "10.1186/s12864-019-6413-7", "10.1109/tvcg.2015.2467551", "10.1002/widm.1249", "10.1007/978-3-319-66429-3\\_29", "10.1109/tvcg.2014.2346481", "10.1109/tvcg.2018.2864825", "10.1177/1473871620904671", "10.1109/tvcg.2019.2934267", "10.1136/bmjopen-2016-012799", "10.1109/smartgridcomm.2017.8340682", "10.1007/s10664-015-9401-9", "10.1145/1143844.1143874", "10.1111/cgf.12389", "10.1109/tvcg.2018.2872577", "10.1007/978-981-13-5802-9\\_20", "10.1016/j.ipm.2009.03.002", "10.5220/0006431602160222", "10.1109/mcg.2015.50", "10.1109/tvcg.2014.2346574", "10.1007/bf02289565", "10.1109/tvcg.2017.2744378", "10.1016/j.patrec.2008.08.010", "10.1023/a:1010933404324", "10.9735/2229-3981"], "wos": 1, "children": [], "len": 1}, {"doi": "10.1109/tvcg.2020.3030465", "title": "Visual Causality Analysis of Event Sequence Data", "year": "2020", "conferenceName": "VAST", "authors": "Zhuochen Jin;Shunan Guo;Nan Chen;Daniel Weiskopf;David Gotz;Nan Cao", "citationCount": "0", "affiliation": "Cao, N (Corresponding Author), Tongji Univ, IDVx Lab, Shanghai, Peoples R China. Jin, Zhuochen; Guo, Shunan; Chen, Nan; Cao, Nan, Tongji Univ, IDVx Lab, Shanghai, Peoples R China. Weiskopf, Daniel, Univ Stuttgart, Stuttgart, Germany. Gotz, David, Univ N Carolina, Chapel Hill, NC 27515 USA.", "countries": "USA;Germany;China", "abstract": "Causality is crucial to understanding the mechanisms behind complex systems and making decisions that lead to intended outcomes. Event sequence data is widely collected from many real-world processes, such as electronic health records, web clickstreams, and financial transactions, which transmit a great deal of information reflecting the causal relations among event types. Unfortunately, recovering causalities from observational event sequences is challenging, as the heterogeneous and high-dimensional event variables are often connected to rather complex underlying event excitation mechanisms that are hard to infer from limited observations. Many existing automated causal analysis techniques suffer from poor explainability and fail to include an adequate amount of human knowledge. In this paper, we introduce a visual analytics method for recovering causalities in event sequence data. We extend the Granger causality analysis algorithm on Hawkes processes to incorporate user feedback into causal model refinement. The visualization system includes an interactive causal analysis framework that supports bottom-up causal exploration, iterative causal verification and refinement, and causal comparison through a set of novel visualizations and interactions. We report two forms of evaluation: a quantitative evaluation of the model improvements resulting from the user-feedback mechanism, and a qualitative evaluation through case studies in different application domains to demonstrate the usefulness of the system.", "keywords": "Event sequence data,causality analysis,visual analytics", "link": "http://dx.doi.org/10.1109/TVCG.2020.3030465", "refList": ["10.5555/1642718", "10.1109/tvcg.2018.2865022", "10.5555/2074094.2074151", "10.1109/tvcg.2016.2618797", "10.1073/pnas.1320645111", "10.1109/tvcg.2017.2744843", "10.1109/iv.2017.69", "10.1109/tvcg.2019.2934399", "10.1145/3172944.3173007", "10.5555/1795555", "10.1109/mcg.2005.102", "10.1145/381641.381653", "10.1162/153244301753344614", "10.1111/cgf.14034", "10.1111/cgf.13198", "10.1017/cbo9780511519857", "10.1007/s10462-016-9475-9", "10.1075/ssol.2.2.07bor", "10.1007/978-1-4614-3223-4\\_3", "10.1109/infvis.2003.1249025", "10.1007/978-94-007-6094-313", "10.1145/2858036.2858387", "10.1109/tvcg.2007.70528", "10.1109/tvcg.2017.2674958", "10.1147/sj.454.0801", "10.1109/tvcg.2013.119", "10.1145/3173574.3173711", "10.1016/j.erss.2017.06.034", "10.1109/visual.2019.8933695", "10.1007/s11665-016-2173-6", "10.1016/0377-0427(87)90125-7", "10.2307/3601125", "10.1016/b978-0-444-88738-2.50018-x", "10.1109/mcg.2006.70", "10.1109/tvcg.2018.2865145", "10.1017/s1351324997001502", "10.1109/tvcg.2010.179", "10.1214/aos/1176344552", "10.1109/mcg.2009.22", "10.1007/978-3-319-26633-6\\_13", "10.1080/10447318.2014.905422", "10.1016/j.visinf.2019.03.004", "10.1057/palgrave.ivs.9500074", "10.1007/978-1-4614-3223-4"], "wos": 1, "children": [], "len": 1}], "len": 5}, {"doi": "10.1111/cgf.13972", "year": "2020", "title": "Boxer: Interactive Comparison of Classifier Results", "conferenceName": "EuroVis", "authors": "Michael Gleicher;Aditya Barve;Xinyi Yu;Florian Heimerl", "citationCount": "0", "affiliation": "Gleicher, M (Corresponding Author), Univ Wisconsin, Madison, WI 53706 USA.\nGleicher, Michael; Barve, Aditya; Yu, Xinyi; Heimerl, Florian, Univ Wisconsin, Madison, WI 53706 USA.", "countries": "USA", "abstract": "Machine learning practitioners often compare the results of different classifiers to help select, diagnose and tune models. We present Boxer, a system to enable such comparison. Our system facilitates interactive exploration of the experimental results obtained by applying multiple classifiers to a common set of model inputs. The approach focuses on allowing the user to identify interesting subsets of training and testing instances and comparing performance of the classifiers on these subsets. The system couples standard visual designs with set algebra interactions and comparative elements. This allows the user to compose and coordinate views to specify subsets and assess classifier performance on them. The flexibility of these compositions allow the user to address a wide range of scenarios in developing and assessing classifiers. We demonstrate Boxer in use cases including model selection, tuning, fairness assessment, and data quality diagnosis.", "keywords": "", "link": "https://doi.org/10.1111/cgf.13972", "refList": ["10.1109/tvcg.2019.2934629", "10.1109/tvcg.2017.2744359", "10.1109/tvcg.2016.2598838", "10.1007/s10618-014-0368-8", "10.1109/tvcg.2017.2744938", "10.1109/tvcg.2019.2934262", "10.1145/3287560.3287589", "10.1109/vast.2017.8585721", "10.1109/tvcg.2016.2598828", "10.1109/tvcg.2009.128", "10.1109/tvcg.2017.2744018", "10.1080/00994480.2000.10748487", "10.5555/3305890.3306024", "10.1109/iccv.2015.329", "10.1109/tvcg.2013.125", "10.1089/big.2016.0007", "10.1109/memsys.2019.8870817", "10.1145/2939672.2939778", "10.1007/s11104-019-04156-0", "10.1371/journal.pone.0181142", "10.1145/3301275.3302324", "10.1109/tvcg.2017.2745158", "10.1109/tvcg.2018.2865044", "10.1023/a:1010933404324", "10.1145/2487575.2487579", "10.1109/tvcg.2013.157", "10.1145/2783258.2788613", "10.1109/tvcg.2017.2744199", "10.1109/tvcg.2019.2934631", "10.1016/s0304-3800(02)00064-9", "10.1007/s10115-013-0679-x", "10.1109/tvcg.2019.2934267", "10.1007/978-3-319-10590-1\\_53", "10.1109/vast.2017.8585720", "10.1016/0004-3702(80)90021-1", "10.1109/tvcg.2015.2467618", "10.1109/tvcg.2018.2864477", "10.1109/tvcg.2009.84", "10.1007/s11263-016-0911-8", "10.1111/cgf.12918", "10.1111/cgf.12373", "10.1109/tvcg.2017.2744878", "10.1109/tvcg.2018.2864812", "10.1109/mcg.2019.2919033", "10.1080/00207176808905715", "10.1002/er.3827", "10.1109/tvcg.2014.2346660", "10.1111/cgf.13417", "10.1109/tvcg.2019.2934659", "10.1109/tvcg.2017.2744158", "10.1016/b978-0-12-815849-4.00004-9", "10.1097/ede.0b013e3181c30fb2", "10.1111/cgf.13681", "10.1016/j.ejor.2006.04.051", "10.1109/tvcg.2019.2934619", "10.1109/tvcg.2016.2598468", "10.9735/2229-3981", "10.1109/tvcg.2016.2598831"], "wos": 1, "children": [], "len": 1}], "len": 81}, {"doi": "10.1109/tvcg.2019.2934264", "title": "The Validity, Generalizability and Feasibility of Summative Evaluation Methods in Visual Analytics", "year": "2019", "conferenceName": "VAST", "authors": "Mosab Khayat;Morteza Karimzadeh;David S. Ebert;Arif Ghafoor", "citationCount": "1", "affiliation": "Khayat, M (Corresponding Author), Purdue Univ, W Lafayette, IN 47907 USA. Khayat, Mosab; Karimzadeh, Morteza; Ebert, David S.; Ghafoor, Arif, Purdue Univ, W Lafayette, IN 47907 USA. Karimzadeh, Morteza, Univ Colorado, Boulder, CO 80309 USA.", "countries": "USA", "abstract": "Many evaluation methods have been used to assess the usefulness of Visual Analytics (VA) solutions. These methods stem from a variety of origins with different assumptions and goals, which cause confusion about their proofing capabilities. Moreover, the lack of discussion about the evaluation processes may limit our potential to develop new evaluation methods specialized for VA. In this paper, we present an analysis of evaluation methods that have been used to summatively evaluate VA solutions. We provide a survey and taxonomy of the evaluation methods that have appeared in the VAST literature in the past two years. We then analyze these methods in terms of validity and generalizability of their findings, as well as the feasibility of using them. We propose a new metric called summative quality to compare evaluation methods according to their ability to prove usefulness, and make recommendations for selecting evaluation methods based on their summative quality in the VA domain.", "keywords": "Summative evaluation,usefulness,evaluation process,taxonomy,visual analytics", "link": "http://dx.doi.org/10.1109/TVCG.2019.2934264", "refList": ["10.1109/tvcg.2017.2744478", "10.1109/tvcg.2018.2865025", "10.1109/tvcg.2006.85", "10.1109/tvcg.2014.2346331", "10.1109/beliv.2018.8634420", "10.1109/tvcg.2017.2745181", "10.1111/cgf.13677", "10.1109/tvcg.2018.2864844", "10.1109/tvcg.2013.126", "10.1109/tvcg.2018.2864811", "10.1109/infvis.2005.1532147", "10.1177/0956797613504966", "10.1145/2669557.2669579", "10.1109/mcg.2005.102", "10.1109/visual.2003.1250426", "10.1136/bmj.39489.470347.ad", "10.1109/tvcg.2017.2744080", "10.1109/mcg.2009.53", "10.1111/j.1467-8527.2005.00307.x", "10.1109/tvcg.2010.132", "10.1109/tvcg.2018.2864886", "10.1109/tvcg.2018.2864843", "10.1109/tvcg.2018.2865028", "10.1109/tvcg.2018.2865051", "10.1109/tvcg.2018.2865044", "10.1109/tvcg.2018.2865026", "10.1007/978-3-540-71080-6\\_6", "10.1109/tvcg.2018.2865020", "10.1177/1473871611407399", "10.1109/tvcg.2018.2864504", "10.1109/tvcg.2018.2864526", "10.1109/tvcg.2005.53", "10.1109/tvcg.2018.2864905", "10.1049/sej.1991.0040", "10.1109/tvcg.2015.2513410", "10.1109/tvcg.2017.2711030", "10.1109/tvcg.2011.279", "10.1109/vast.2017.8585505", "10.1147/jrd.2010.2042914", "10.1016/s0378-7206(98)00044-5", "10.1145/2993901.2993913", "10.1109/tvcg.2018.2865041", "10.1109/tvcg.2018.2864812", "10.1109/tvcg.2017.2744758", "10.1145/1168149.1168158", "10.1109/tvcg.2017.2745279", "10.1109/tvcg.2012.213", "10.1109/tvcg.2017.2744738", "10.1109/tvcg.2017.2745083", "10.1109/tvcg.2018.2864826", "10.1145/1377966.1377974", "10.1109/apec.2009.4802646", "10.1145/1168149.1168152", "10.1016/j.jss.2008.03.059", "10.1109/vast.2017.8585484", "10.1109/tvcg.2017.2744818", "10.1109/tvcg.2017.2744358", "10.1109/tvcg.2018.2864499", "10.1109/tvcg.2018.2865042", "10.1109/tvcg.2017.2744898"], "wos": 1, "children": [{"doi": "10.1109/tvcg.2020.3030388", "title": "Visualization of Human Spine Biomechanics for Spinal Surgery", "year": "2020", "conferenceName": "SciVis", "authors": "Pepe Eulzer;Sabine Bauer;Francis Kilian;Kai Lawonn", "citationCount": "0", "affiliation": "Eulzer, P (Corresponding Author), Univ Jena, Jena, Germany. Eulzer, Pepe; Lawonn, Kai, Univ Jena, Jena, Germany. Bauer, Sabine, Univ Koblenz Landau, Koblenz, Germany. Kilian, Francis, Cath Clin Koblenz Montabaur, Dept Spine Surg, Koblenz, Germany.", "countries": "Germany", "abstract": "We propose a visualization application, designed for the exploration of human spine simulation data. Our goal is to support research in biomechanical spine simulation and advance efforts to implement simulation-backed analysis in surgical applications. Biomechanical simulation is a state-of-the-art technique for analyzing load distributions of spinal structures. Through the inclusion of patient-specific data, such simulations may facilitate personalized treatment and customized surgical interventions. Difficulties in spine modelling and simulation can be partly attributed to poor result representation, which may also be a hindrance when introducing such techniques into a clinical environment. Comparisons of measurements across multiple similar anatomical structures and the integration of temporal data make commonly available diagrams and charts insufficient for an intuitive and systematic display of results. Therefore, we facilitate methods such as multiple coordinated views, abstraction and focus and context to display simulation outcomes in a dedicated tool. $\\mathrm{By}$ linking the result data with patient-specific anatomy, we make relevant parameters tangible for clinicians. Furthermore, we introduce new concepts to show the directions of impact force vectors, which were not accessible before. We integrated our toolset into a spine segmentation and simulation pipeline and evaluated our methods with both surgeons and biomechanical researchers. When comparing our methods against standard representations that are currently in use, we found increases in accuracy and speed in data exploration tasks. $\\mathrm{in}$ a qualitative review, domain experts deemed the tool highly useful when dealing with simulation result data, which typically combines time-dependent patient movement and the resulting force distributions on spinal structures.", "keywords": "Medical visualization,bioinformatics,coordinated views,focus and context,biomechanical simulation", "link": "http://dx.doi.org/10.1109/TVCG.2020.3030388", "refList": ["10.1109/tvcg.2018.2864903", "10.1177/1473871613510429", "10.1093/ehjqcco/qcz052", "10.1109/tvcg.2007.70594", "10.1109/tvcg.2018.2865076", "10.1055/s-0039-1687862", "10.1109/visual.1990.146375", "10.1109/tvcg.2017.2744198", "10.1016/j.ijmedinf.2014.10.001", "10.1109/tvcg.2013.124", "10.1016/j.jacc", "10.1111/cgf.13167", "10.17705/1thci.00055", "10.1136/bmjqs.2009.037895", "10.1109/tvcg.2013.238", "10.1109/tvcg.2018.2865240", "10.1186/1471-2261-6-34", "10.1109/tvcg.2019.2934264", "10.1109/tvcg.2013.200", "10.1109/tvcg.2011.209", "10.1109/tvcg.2014.2346682", "10.1109/tvcg.2015.2467091", "10.1136/bmjopen-2019-033208", "10.1109/beliv.2018.8634027", "10.1109/tvcg.2012.213", "10.1109/tvcg.2015.2467191", "10.1109/tvcg.2015.2467325", "10.1145/2133806.2133821", "10.1145/1806799.1806866", "10.1108/02635570610688869", "10.1002/hbm.20701", "10.1561/1100000039", "10.1145/3025453.3025645", "10.1109/tvcg.2009.111", "10.1109/tvcg.2013.120", "10.1109/tvcg.2016.2599030"], "wos": 1, "children": [], "len": 1}], "len": 3}], "len": 111}, {"doi": "10.1109/tvcg.2018.2864503", "title": "Visual Abstraction of Large Scale Geospatial Origin-Destination Movement Data", "year": "2018", "conferenceName": "VAST", "authors": "Zhiguang Zhou;Linhao Meng;Cheng Tang;Ying Zhao;Zhiyong Guo;Miaoxin Hu;Wei Chen", "citationCount": "19", "affiliation": "Zhou, ZG (Corresponding Author), Zhejiang Univ Finance \\& Econ, Sch Informat, Hangzhou, Zhejiang, Peoples R China. Zhou, Zhiguang; Guo, Zhiyong; Hu, Miaoxin, Zhejiang Univ Finance \\& Econ, Sch Informat, Hangzhou, Zhejiang, Peoples R China. Meng, Linhao; Chen, Wei, Zhejiang Univ, State Key Lab CAD \\& CG, Hangzhou, Zhejiang, Peoples R China. Tang, Cheng, Zhejiang Sci Tech Univ, Informat Sch, Hangzhou, Zhejiang, Peoples R China. Zhao, Ying, Cent S Univ, Changsha, Hunan, Peoples R China.", "countries": "China", "abstract": "A variety of human movement datasets are represented in an Origin-Destination(OD) form, such as taxi trips, mobile phone locations, etc. As a commonly-used method to visualize OD data, flow map always fails to discover patterns of human mobility, due to massive intersections and occlusions of lines on a 2D geographical map. A large number of techniques have been proposed to reduce visual clutter of flow maps, such as filtering, clustering and edge bundling, but the correlations of OD flows are often neglected, which makes the simplified OD flow map present little semantic information. In this paper, a characterization of OD flows is established based on an analogy between OD flows and natural language processing (NPL) terms. Then, an iterative multi-objective sampling scheme is designed to select OD flows in a vectorized representation space. To enhance the readability of sampled OD flows, a set of meaningful visual encodings are designed to present the interactions of OD flows. We design and implement a visual exploration system that supports visual inspection and quantitative evaluation from a variety of perspectives. Case studies based on real-world datasets and interviews with domain experts have demonstrated the effectiveness of our system in reducing the visual clutter and enhancing correlations of OD flows.", "keywords": "Visual abstraction,human mobility,origin-destination,flow map,representation learning", "link": "http://dx.doi.org/10.1109/TVCG.2018.2864503", "refList": ["10.1109/tvcg.2008.135", "10.1109/tvcg.2013.226", "10.1145/2939672.2939754", "10.14714/cp30.663", "10.1007/s00371-013-0892-3", "10.1111/tgis.12100", "10.1111/tgis.12042", "10.1177/1473871612457601", "10.1109/mfi.2014.6997687", "10.1109/tvcg.2016.2616404", "10.1109/tvcg.2009.143", "10.1016/j.compenvurbsys.2009.01.007", "10.1080/13658810701349037", "10.1109/mcg.2017.6", "10.1145/2684822.2685317", "10.1109/tvcg.2011.233", "10.1109/pacificvis.2012.6183575", "10.1109/tvcg.2014.2346271", "10.1109/tvcg.2015.2467691", "10.1016/j.probengmech.2012.12.006", "10.1109/tvcg.2016.2607204", "10.1109/infvis.2005.1532150", "10.1080/03085696708592302", "10.1109/tvcg.2014.2346746", "10.1109/pacificvis.2011.5742390", "10.1145/2516971.2516973", "10.1162/jmlr.2003.3.4-5.951", "10.1109/tvcg.2014.2346594", "10.1109/tvcg.2013.196", "10.1179/000870410x12658023467367", "10.1109/tvcg.2016.2641963", "10.3138/carto.46.4.239", "10.3390/ijgi6110321", "10.1145/3119910", "10.2307/1791753", "10.1109/tvcg.2016.2598667", "10.1088/1742-5468/2008/10/p10008", "10.1145/3194657", "10.1559/152304087783875273", "10.1109/tvcg.2016.2598885", "10.1111/j.0033-0124.1981.00419.x", "10.1109/tvcg.2017.2744322", "10.1145/2487228.2487233", "10.1109/tvcg.2016.2598432", "10.1109/tvcg.2011.202"], "wos": 1, "children": [{"doi": "10.1109/tvcg.2019.2934671", "title": "A Natural-language-based Visual Query Approach of Uncertain Human Trajectories", "year": "2019", "conferenceName": "VAST", "authors": "Zhaosong Huang;Ye Zhao;Wei Chen;Shengjie Gao;Kejie Yu;Weixia Xu;MingJie Tang;Minfeng Zhu;Mingliang Xu", "citationCount": "0", "affiliation": "Chen, W (Corresponding Author), Zhejiang Univ, State Key Lab CAD \\& CG, Hangzhou, Peoples R China. Xu, ML (Corresponding Author), Zhengzhou Univ, Sch Informat Engn, Zhengzhou 450000, Peoples R China. Huang, Zhaosong; Chen, Wei; Gao, Shengjie; Yu, Kejie; Xu, Weixia; Zhu, Minfeng, Zhejiang Univ, State Key Lab CAD \\& CG, Hangzhou, Peoples R China. Zhao, Ye, Kent State Univ, Dept Comp Sci, Kent, OH 44242 USA. Tang, Mingjie, Ant Financial, San Mateo, CA USA. Xu, Mingliang, Zhengzhou Univ, Sch Informat Engn, Zhengzhou 450000, Peoples R China.", "countries": "USA;China", "abstract": "Visual querying is essential for interactively exploring massive trajectory data. However, the data uncertainty imposes profound challenges to fulfill advanced analytics requirements. On the one hand, many underlying data does not contain accurate geographic coordinates, e.g., positions of a mobile phone only refer to the regions (i.e., mobile cell stations) in which it resides, instead of accurate GPS coordinates. On the other hand, domain experts and general users prefer a natural way, such as using a natural language sentence, to access and analyze massive movement data. In this paper, we propose a visual analytics approach that can extract spatial-temporal constraints from a textual sentence and support an effective query method over uncertain mobile trajectory data. It is built up on encoding massive, spatially uncertain trajectories by the semantic information of the POls and regions covered by them, and then storing the trajectory documents in text database with an effective indexing scheme. The visual interface facilitates query condition specification, situation-aware visualization, and semantic exploration of large trajectory data. Usage scenarios on real-world human mobility datasets demonstrate the effectiveness of our approach.", "keywords": "Natural-language-based Visual Query,Spatial Uncertaity,Trajectory Exploration", "link": "http://dx.doi.org/10.1109/TVCG.2019.2934671", "refList": ["10.1017/s1351324909005129", "10.1109/tvcg.2013.226", "10.1109/tvcg.2018.2864503", "10.1561/1500000019", "10.1109/icde.2010.5447829", "10.1109/tvcg.2008.172", "10.1177/1473871612457601", "10.1145/2442810.2442828", "10.1109/pacificvis.2014.50", "10.1109/vast.2014.7042486", "10.1201/9781420008609.ch3", "10.1177/1473871613480062", "10.1109/tvcg.2017.2744159", "10.1145/2629592", "10.1109/tvcg.2016.2616404", "10.1109/vl.1996.545307", "10.5311/josis.2012.4.62", "10.5220/0005716900480059", "10.1109/tvcg.2018.2865049", "10.1109/tvcg.2015.2467619", "10.1109/tvcg.2015.2467771", "10.1109/tvcg.2011.233", "10.1186/s12859-015-0564-6", "10.1111/cgf.12114", "10.1108/eb026562", "10.1002/inc3.362", "10.1109/vast.2014.7042495", "10.1145/299917.299920", "10.1162/coli.2009.35.4.35403", "10.1016/j.datak.2007.10.008", "10.13140/2.1.2393.1847", "10.1109/tits.2017.2683539", "10.1109/tbdata.2017.2667700", "10.1177/1473871617692841", "10.1109/tits.2015.2436897", "10.1109/tvcg.2013.179", "10.1145/2339530.2339561", "10.1109/vast.2008.4677356", "10.1109/access.2016.2553681", "10.1109/tvcg.2017.2758362", "10.14778/2732232.2732235", "10.1109/tits.2017.2711644", "10.1162/jmlr.2003.3.4-5.993", "10.1145/330560.330692", "10.1109/tvcg.2014.2371856", "10.1111/cgf.12778", "10.1145/2743025", "10.1109/tnn.2003.820440", "10.1109/tvcg.2016.2598885", "10.1109/tits.2016.2639320", "10.1145/1341012.1341041", "10.1109/tvcg.2016.2598416", "10.1145/2501654.2501656", "10.1109/tvcg.2016.2598432", "10.1109/tvcg.2018.2865042"], "wos": 1, "children": [], "len": 1}, {"doi": "10.1109/tvcg.2019.2934670", "title": "AirVis: Visual Analytics of Air Pollution Propagation", "year": "2019", "conferenceName": "VAST", "authors": "Zikun Deng;Di Weng;Jiahui Chen;Ren Liu;Zhibin Wang;Jie Bao 0003;Yu Zheng 0004;Yingcai Wu", "citationCount": "6", "affiliation": "Wu, YC (Corresponding Author), Zhejiang Univ, State Key Lab CAD \\& CG, Hangzhou, Peoples R China. Deng, Zikun; Weng, Di; Chen, Jiahui; Liu, Ren; Wu, Yingcai, Zhejiang Univ, State Key Lab CAD \\& CG, Hangzhou, Peoples R China. Wang, Zhibin, Zhejiang Univ, Res Ctr Air Pollut \\& Hlth, Hangzhou, Peoples R China. Bao, Jie; Zheng, Yu, JD Intelligent City Res, Beijing, Peoples R China.", "countries": "China", "abstract": "Air pollution has become a serious public health problem for many cities around the world. To find the causes of air pollution, the propagation processes of air pollutants must be studied at a large spatial scale. However, the complex and dynamic wind fields lead to highly uncertain pollutant transportation. The state-of-the-art data mining approaches cannot fully support the extensive analysis of such uncertain spatiotemporal propagation processes across multiple districts without the integration of domain knowledge. The limitation of these automated approaches motivates us to design and develop AirVis, a novel visual analytics system that assists domain experts in efficiently capturing and interpreting the uncertain propagation patterns of air pollution based on graph visualizations. Designing such a system poses three challenges: a) the extraction of propagation patterns; b) the scalability of pattern presentations; and c) the analysis of propagation processes. To address these challenges, we develop a novel pattern mining framework to model pollutant transportation and extract frequent propagation patterns efficiently from large-scale atmospheric data. Furthermore, we organize the extracted patterns hierarchically based on the minimum description length (MDL) principle and empower expert users to explore and analyze these patterns effectively on the basis of pattern topologies. We demonstrated the effectiveness of our approach through two case studies conducted with a real-world dataset and positive feedback from domain experts.", "keywords": "Air pollution propagation,pattern mining,graph visualization", "link": "http://dx.doi.org/10.1109/TVCG.2019.2934670", "refList": ["10.1109/tvcg.2016.2598919", "10.1093/bib/bbr069", "10.1145/2487575.2488188", "10.1109/tvcg.2013.193", "10.1016/j.atmosenv.2014.12.011", "10.1109/tvcg.2013.226", "10.1109/tvcg.2018.2864503", "10.1109/tvcg.2015.2468111", "10.1109/icicta.2015.183", "10.1016/j.atmosenv.2014.05.039", "10.1111/cgf.12791", "10.1111/j.1467-8659.2009.01451.x", "10.1111/j.1467-8659.2011.01898.x", "10.5194/acp-12-5031-2012", "10.1016/j.atmosenv.2008.05.053", "10.1109/tvcg.2016.2535234", "10.1016/j.atmosres.2014.12.003", "10.1109/tvcg.2015.2467194", "10.1109/tvcg.2013.263", "10.1109/icdm.2002.1184038", "10.1145/2783258.2788573", "10.1109/tvcg.2018.2865149", "10.1109/tbdata.2017.2723899", "10.1109/tvcg.2012.311", "10.1109/vl.1996.545307", "10.1007/s12650-018-0481-7", "10.1016/j.envpol.2007.06.012", "10.3155/1047-3289.61.6.660", "10.1080/13658810701349037", "10.1145/3097983.3098090", "10.1109/tvcg.2007.70523", "10.1115/1.2128636", "10.1109/tvcg.2015.2467619", "10.3978/j.issn.2072-1439.2016.01.19", "10.1109/tkde.2005.127", "10.1017/s0269888912000331", "10.2312/conf/eg2013/stars/039-063", "10.1109/tvcg.2014.2346271", "10.1175/bams-d-14-00110.1", "10.1016/0005-1098(78)90005-5", "10.1007/s10618-006-0044-8", "10.1109/tvcg.2018.2865126", "10.2307/1912791", "10.3390/su6085322", "10.1007/s12650-018-0489-z", "10.2312/eurovisstar.20151109", "10.1109/tvcg.2011.181", "10.1126/science.298.5594.824", "10.1162/jmlr.2003.3.4-5.951", "10.1109/asonam.2014.6921638", "10.1111/j.1467-8659.2008.01213.x", "10.1038/s41598-017-18107-1", "10.1109/tvcg.2018.2865041", "10.1109/tits.2019.2901117", "10.1038/srep20668", "10.1109/tvcg.2012.265", "10.1109/tpami.2016.2608884", "10.1109/tvcg.2012.213", "10.1145/1376616.1376661", "10.1007/s00521-019-04567-1", "10.1109/tvcg.2017.2745083", "10.1126/science.243.4892.745", "10.1109/tvcg.2018.2864826", "10.1109/tnn.2003.820440", "10.1109/tvcg.2016.2598885", "10.1145/3219819.3219822", "10.1073/pnas.1502596112", "10.1016/j.envsoft.2009.01.004", "10.1002/pmic.200700095", "10.1145/2254556.2254651", "10.1109/tvcg.2016.2598432", "10.1109/tvcg.2011.202"], "wos": 1, "children": [{"doi": "10.1109/tvcg.2020.3028958", "title": "Auditing the Sensitivity of Graph-based Ranking with Visual Analytics", "year": "2020", "conferenceName": "VAST", "authors": "Tiankai Xie;Yuxin Ma;Hanghang Tong;My T. Thai;Ross Maciejewski", "citationCount": "0", "affiliation": "Xie, TK (Corresponding Author), Arizona State Univ, Tempe, AZ 85287 USA. Xie, Tiankai; Ma, Yuxin; Maciejewski, Ross, Arizona State Univ, Tempe, AZ 85287 USA. Tong, Hanghang, Univ Illinois, Urbana, IL USA. Thai, My T., Univ Florida, Gainesville, FL 32611 USA.", "countries": "USA", "abstract": "Graph mining plays a pivotal role across a number of disciplines, and a variety of algorithms have been developed to answer who/what type questions. For example, what items shall we recommend to a given user on an e-commerce platform? The answers to such questions are typically returned in the form of a ranked list, and graph-based ranking methods are widely used in industrial information retrieval settings. However, these ranking algorithms have a variety of sensitivities, and even small changes in rank can lead to vast reductions in product sales and page hits. As such, there is a need for tools and methods that can help model developers and analysts explore the sensitivities of graph ranking algorithms with respect to perturbations within the graph structure. In this paper, we present a visual analytics framework for explaining and exploring the sensitivity of any graph-based ranking algorithm by performing perturbation-based what-if analysis. We demonstrate our framework through three case studies inspecting the sensitivity of two classic graph-based ranking algorithms (PageRank and HITS) as applied to rankings in political news media and social networks.", "keywords": "Graph-based ranking,sensitivity analysis,visual analytics", "link": "http://dx.doi.org/10.1109/TVCG.2020.3028958", "refList": ["10.1109/wsc.2017.8247800", "10.1023/a:1022649401552", "10.1515/1559-0410.11416", "10.1109/tvcg.2016.2598919", "10.1177/1473871611416549", "10.1109/tvcg.2019.2934630", "10.1140/epjds29", "10.1109/tvcg.2019.2934670", "10.1016/j.eswa.2015.09.004", "10.1145/2702123.2702509", "10.1016/j.visinf.2018.12.001", "10.2307/3002000", "10.1109/tvcg.2019.2934399", "10.1007/s41060-016-0032-z", "10.1111/cgf.13198", "10.14778/2350229.2350254", "10.1145/2939672.2939764", "10.1016/j.visinf.2017.01.006", "10.1145/2858036.2858529", "10.1109/vast.2017.8585647", "10.1007/bf01187020", "10.1109/icdm.2015.26", "10.1145/2362383.2362387", "10.1177/0049124104268644", "10.1109/vast.2011.6102442", "10.1109/infvis.2003.1249025", "10.1109/tvcg.2018.2864475", "10.1109/tvcg.2007.70528", "10.1109/tvcg.2015.2467691", "10.1111/cgf.13210", "10.1214/aos/1176344136", "10.1109/tvcg.2015.2424872", "10.1016/j.visinf.2018.09.001", "10.1177/089443939100900106", "10.1109/tvcg.2015.2467931", "10.1162/neco.1997.9.8.1735", "10.1007/s11162-011-9241-4", "10.1111/cgf.13680", "10.1145/3065386", "10.1109/tvcg.2018.2864889", "10.1177/003804070808100402", "10.1109/icdm.2010.62", "10.1038/s41598-020-59669-x", "10.1162/153244303321897717", "10.1109/tvcg.2019.2934619", "10.1007/bf00356088", "10.1109/tvcg.2016.2598432", "10.1109/tvcg.2016.2598831"], "wos": 1, "children": [], "len": 1}, {"doi": "10.1109/tvcg.2020.3030410", "title": "Revisiting the Modifiable Areal Unit Problem in Deep Traffic Prediction with Visual Analytics", "year": "2020", "conferenceName": "VAST", "authors": "Wei Zeng 0002;Chengqiao Lin;Juncong Lin;Jincheng Jiang;Jiazhi Xia;Cagatay Turkay;Wei Chen", "citationCount": "0", "affiliation": "Lin, JC (Corresponding Author), Xiamen Univ, Xiamen, Peoples R China. Zeng, Wei; Jiang, Jincheng, Chinese Acad Sci, Shenzhen Inst Adv Technol, Shenzhen, Peoples R China. Lin, Chengqiao; Lin, Juncong, Xiamen Univ, Xiamen, Peoples R China. Xia, Jiazhi, Cent South Univ, Changsha, Peoples R China. Turkay, Cagatay, Univ Warwick, Coventry, W Midlands, England. Chen, Wei, Zhejiang Univ, State Key Lab CAD \\& CG, Hangzhou, Zhejiang, Peoples R China.", "countries": "China;England", "abstract": "Deep learning methods are being increasingly used for urban traffic prediction where spatiotemporal traffic data is aggregated into sequentially organized matrices that are then fed into convolution-based residual neural networks. However, the widely known modifiable areal unit problem within such aggregation processes can lead to perturbations in the network inputs. This issue can significantly destabilize the feature embeddings and the predictions - rendering deep networks much less useful for the experts. This paper approaches this challenge by leveraging unit visualization techniques that enable the investigation of many-to-many relationships between dynamically varied multi-scalar aggregations of urban traffic data and neural network predictions. Through regular exchanges with a domain expert, we design and develop a visual analytics solution that integrates 1) a Bivariate Map equipped with an advanced bivariate colormap to simultaneously depict input traffic and prediction errors across space, 2) a Moran's I Scatterplot that provides local indicators of spatial association analysis, and 3) a Multi-scale Attribution View that arranges non-linear dot plots in a tree layout to promote model analysis and comparison across scales. We evaluate our approach through a series of case studies involving a real-world dataset of Shenzhen taxi trips, and through interviews with domain experts. We observe that geographical scale variations have important impact on prediction performances, and interactive visual exploration of dynamically varying inputs and outputs benefit experts in the development of deep traffic prediction models.", "keywords": "MAUP,traffic prediction,deep learning,model diagnostic,visual analytics", "link": "http://dx.doi.org/10.1109/TVCG.2020.3030410", "refList": ["10.1038/srep26377", "10.1109/mcg.2011.88", "10.1080/13658816.2015.1119279", "10.1109/tvcg.2013.226", "10.1109/pacificvis.2011.5742387", "10.1038/s41467-017-01882-w", "10.1109/tvcg.2019.2934670", "10.1111/j.1467-8659.2009.01440.x", "10.1111/cgf.13712", "10.1016/j.compenvurbsys.2008.09.006", "10.1109/pacificvis.2014.50", "10.1109/tvcg.2018.2816219", "10.1109/tvcg.2016.2535234", "10.1109/tvcg.2014.2346893", "10.3390/ijgi8080344", "10.1109/tvcg.2013.246", "10.1007/s10940-005-9003-6", "10.1016/j.compenvurbsys.2008.05.001", "10.1007/s10661-019-7831-3", "10.1111/j.1538-4632.2007.00699.x", "10.1016/j.aap.2016.08.015", "10.1080/13658816.2018.1541177", "10.1109/pacificvis.2012.6183572", "10.1109/tvcg.2011.181", "10.1137/090759069", "10.1109/pacificvis.2011.5742390", "10.1214/10-aos799", "10.1109/tits.2017.2683539", "10.1109/tits.2015.2436897", "10.3390/ijerph16071150", "10.1109/tvcg.2009.145", "10.1109/tvcg.2012.265", "10.1080/10106049.2017.1404140", "10.3390/ijgi8020063", "10.3390/info6020134", "10.1080/13658816.2014.955027", "10.1109/tits.2016.2639320", "10.2307/143141", "10.1109/tvcg.2016.2598432"], "wos": 1, "children": [], "len": 1}, {"doi": "10.1109/tvcg.2020.3030370", "title": "TaxThemis: Interactive Mining and Exploration of Suspicious Tax Evasion Groups", "year": "2020", "conferenceName": "VAST", "authors": "Yating Lin;Kamkwai Wong;Yong Wang;Rong Zhang;Bo Dong;Huamin Qu;Qinghua Zheng", "citationCount": "0", "affiliation": "Lin, YT (Corresponding Author), Xi An Jiao Tong Univ, MOEKLINNS Lab, Xian, Shaanxi, Peoples R China. Lin, Yating; Zheng, Qinghua, Xi An Jiao Tong Univ, MOEKLINNS Lab, Xian, Shaanxi, Peoples R China. Wong, Kamkwai; Wang, Yong; Zhang, Rong; Qu, Huamin, Hong Kong Univ Sci \\& Technol, Hong Kong, Peoples R China. Dong, Bo, Xi An Jiao Tong Univ, Natl Engn Lab Big Data Analyt, Xian, Shaanxi, Peoples R China.", "countries": "China", "abstract": "Tax evasion is a serious economic problem for many countries, as it can undermine the government's tax system and lead to an unfair business competition environment. Recent research has applied data analytics techniques to analyze and detect tax evasion behaviors of individual taxpayers. However, they have failed to support the analysis and exploration of the related party transaction tax evasion (RPTTE) behaviors (e.g., transfer pricing), where a group of taxpayers is involved. In this paper, we present TaxThemis, an interactive visual analytics system to help tax officers mine and explore suspicious tax evasion groups through analyzing heterogeneous tax-related data. A taxpayer network is constructed and fused with the respective trade network to detect suspicious RPTTE groups. Rich visualizations are designed to facilitate the exploration and investigation of suspicious transactions between related taxpayers with profit and topological data analysis. Specifically, we propose a calendar heatmap with a carefully-designed encoding scheme to intuitively show the evidence of transferring revenue through related party transactions. We demonstrate the usefulness and effectiveness of TaxThemis through two case studies on real-world tax-related data and interviews with domain experts.", "keywords": "Visual Analytics,Tax Network,Tax Evasion Detection,Anomaly detection,Multidimensional data", "link": "http://dx.doi.org/10.1109/TVCG.2020.3030370", "refList": ["10.1111/cgf.12886", "10.2307/2277827", "10.1109/tvcg.2010.44", "10.1109/tits.2014.2315794", "10.1109/tvcg.2019.2934670", "10.1038/s41467-019-08987-4", "10.1111/cgf.12920", "10.1109/vast.2017.8585721", "10.1080/15230406.2015.1093431", "10.1109/tvcg.2018.2843369", "10.1038/srep01001", "10.1109/tvcg.2017.2744018", "10.1109/tvcg.2017.2744159", "10.1068/b130199p", "10.1109/tvcg.2009.143", "10.1016/j.visinf.2017.01.006", "10.1109/tvcg.2019.2892483", "10.1109/pacificvis.2017.8031583", "10.1109/pacificvis48177.2020.2785", "10.2307/2686111", "10.1109/tvcg.2015.2467199", "10.1111/cgf.12114", "10.1109/tvcg.2018.2865126", "10.1111/j.1538-4632.1996.tb00936.x", "10.1109/tvcg.2019.2934619", "10.2307/2332142", "10.1007/978-3-319-10590-1\\_53", "10.1109/cvpr.2016.485", "10.1109/cvpr.2017.17", "10.2307/2986645", "10.1109/tvcg.2014.2346321", "10.1017/s0140525x16001837", "10.1109/tvcg.2016.2598541", "10.1371/journal.pone.0207377", "10.1109/tvcg.2014.2346265", "10.1007/s4095-020-0191-7", "10.3141/1644-14", "10.1109/tvcg.2017.2744158", "10.1109/cvpr.2016.90", "10.1109/tvcg.2018.2865027", "10.1109/tvcg.2017.2785807", "10.1109/tvcg.2017.2744358", "10.1111/j.1538-4632.1995.tb00338.x", "10.1080/03081068808717359", "10.1109/tvcg.2016.2598831"], "wos": 1, "children": [], "len": 1}, {"doi": "10.1109/tvcg.2020.3030469", "title": "Topology Density Map for Urban Data Visualization and Analysis", "year": "2020", "conferenceName": "VAST", "authors": "Zezheng Feng;Haotian Li;Wei Zeng 0004;Shuang-Hua Yang;Huamin Qu", "citationCount": "0", "affiliation": "Zeng, W (Corresponding Author), Chinese Acad Sci, Shenzhen Inst Adv Technol, Shenzhen, Peoples R China. Feng, Zezheng; Li, Haotian; Qu, Huamin, Hong Kong Univ Sci \\& Technol, Hong Kong, Peoples R China. Zeng, Wei, Chinese Acad Sci, Shenzhen Inst Adv Technol, Shenzhen, Peoples R China. Yang, Shuang-Hua, Southern Univ Sci \\& Technol, Shenzhen, Peoples R China.", "countries": "China", "abstract": "Density map is an effective visualization technique for depicting the scalar field distribution in 2D space. Conventional methods for constructing density maps are mainly based on Euclidean distance, limiting their applicability in urban analysis that shall consider road network and urban traffic. In this work, we propose a new method named Topology Density Map, targeting for accurate and intuitive density maps in the context of urban environment. Based on the various constraints of road connections and traffic conditions, the method first constructs a directed acyclic graph (DAG) that propagates nonlinear scalar fields along 1D road networks. Next, the method extends the scalar fields to a 2D space by identifying key intersecting points in the DAG and calculating the scalar fields for every point, yielding a weighted Voronoi diagram like effect of space division. Two case studies demonstrate that the Topology Density Map supplies accurate information to users and provides an intuitive visualization for decision making. An interview with domain experts demonstrates the feasibility, usability, and effectiveness of our method.", "keywords": "Density map,network topology,urban data", "link": "http://dx.doi.org/10.1109/TVCG.2020.3030469", "refList": ["10.1109/vast.2009.5332584", "10.1109/tvcg.2013.193", "10.1080/03081060.2013.844903", "10.1109/tvcg.2018.2864503", "10.1145/2702123.2702419", "10.1109/tvcg.2019.2934670", "10.1109/tits.2015.2496783", "10.1177/1473871615581216", "10.3141/1617-02", "10.1145/2024156.2024169", "10.1111/cgf.13712", "10.1016/j.ejor.2007.02.005", "10.1109/tvcg.2014.2346893", "10.1007/11871842\\_29", "10.1109/vast.2010.5652478", "10.1016/j.visinf.2019.10.002", "10.1109/tvcg.2016.2616404", "10.1109/vl.1996.545307", "10.1145/2629592", "10.1155/2018/2696037", "10.1061/(asce)0733-947x(1998)124:4(368", "10.3141/1899-21", "10.1023/a:1026123329433", "10.1109/mcg.2010.79", "10.1057/palgrave.ivs.9500174", "10.1109/tcyb.2019.2963681", "10.1109/tvcg.2015.2467554", "10.1111/cgf.12114", "10.1145/2814575", "10.1016/j.jcps.2014.08.002", "10.1109/2945.981847", "10.1080/03052150210909", "10.1109/tciaig.2012.2186810", "10.1109/tits.2017.2683539", "10.1109/iv.2004.1320137", "10.1016/0377-2217(80)90126-5", "10.1109/tvcg.2016.2640960", "10.1109/tvcg.2015.2467196", "10.1145/3097983.3098056", "10.1007/s11432-018-9801-4", "10.1109/vast.2014.7042490", "10.1061/(asce)0733-947x(2006)132:2(122", "10.1016/j.tra.2008.03.011", "10.1109/tits.2014.2298892", "10.1016/j.trb.2005.12.003", "10.1007/bf01840357", "10.1109/vast.2011.6102454", "10.1109/tvcg.2013.145", "10.1007/bf02289588", "10.1109/pacificvis.2014.56", "10.1109/mcg.2018.053491730", "10.1109/tvcg.2009.111", "10.1057/palgrave.ivs.9500184", "10.1109/tvcg.2013.173", "10.1109/tvcg.2016.2598432", "10.1007/978-0-85729-079-3"], "wos": 1, "children": [], "len": 1}], "len": 9}, {"doi": "10.1109/tvcg.2019.2934591", "title": "NNVA: Neural Network Assisted Visual Analysis of Yeast Cell Polarization Simulation", "year": "2019", "conferenceName": "VAST", "authors": "Subhashis Hazarika;Haoyu Li;Ko-Chih Wang;Han-Wei Shen;Ching-Shan Chou", "citationCount": "0", "affiliation": "Hazarika, S (Corresponding Author), Ohio State Univ, Dept Comp Sci, Columbus, OH 43210 USA. Hazarika, Subhashis; Li, Haoyu; Wang, Ko-Chih; Shen, Han-Wei, Ohio State Univ, Dept Comp Sci, Columbus, OH 43210 USA. Chou, Ching-Shan, Ohio State Univ, Dept Math, 231 W 18th Ave, Columbus, OH 43210 USA.", "countries": "USA", "abstract": "Complex computational models are often designed to simulate real-world physical phenomena in many scientific disciplines. However, these simulation models tend to be computationally very expensive and involve a large number of simulation input parameters, which need to be analyzed and properly calibrated before the models can be applied for real scientific studies. We propose a visual analysis system to facilitate interactive exploratory analysis of high-dimensional input parameter space for a complex yeast cell polarization simulation. The proposed system can assist the computational biologists, who designed the simulation model, to visually calibrate the input parameters by modifying the parameter values and immediately visualizing the predicted simulation outcome without having the need to run the original expensive simulation for every instance. Our proposed visual analysis system is driven by a trained neural network-based surrogate model as the backend analysis framework. In this work, we demonstrate the advantage of using neural networks as surrogate models for visual analysis by incorporating some of the recent advances in the field of uncertainty quantification, interpretability and explainability of neural network-based models. We utilize the trained network to perform interactive parameter sensitivity analysis of the original simulation as well as recommend optimal parameter configurations using the activation maximization framework of neural networks. We also facilitate detail analysis of the trained network to extract useful insights about the simulation model, learned by the network, during the training process. We performed two case studies, and discovered multiple new parameter configurations, which can trigger high cell polarization results in the original simulation model. We evaluated our results by comparing with the original simulation model outcomes as well as the findings from previous parameter analysis performed by our experts.", "keywords": "Surrogate modeling,Neural networks,Computational biology,Visual analysis,Parameter analysis", "link": "http://dx.doi.org/10.1109/TVCG.2019.2934591", "refList": ["10.1080/13685538.2018.1484443", "10.1016/j.swevo.2011.05.001", "10.1109/tvcg.2017.2744683", "10.1109/21.97458", "10.1109/tvcg.2018.2864503", "10.1109/tvcg.2018.2864887", "10.1109/vast.2017.8585721", "10.3354/cr01213", "10.1016/j.paerosci.2005.02.001", "10.1038/nbt.3300", "10.1038/nature02771", "10.1111/j.1467-8659.2012.03108.x", "10.1145/2089094.2089101", "10.1109/tvcg.2013.147", "10.1016/j.ins.2012.10.039", "10.1109/tvcg.2018.2864843", "10.1109/tvcg.2018.2865051", "10.1029/2011wr011527", "10.1109/tvcg.2018.2864499", "10.1007/bf00547132", "10.1109/tvcg.2018.2865044", "10.1109/tvcg.2018.2816223", "10.1109/tvcg.2018.2865026", "10.1109/tvcg.2018.2864504", "10.1111/j.1467-8659.2011.01940.x", "10.1016/j.dsp.2017.10.011", "10.1109/tvcg.2014.2346321", "10.1007/978-3-319-14445-0\\_9", "10.1038/89044", "10.1109/tvcg.2018.2865029", "10.1109/tvcg.2017.2764895", "10.1109/tvcg.2017.2744718", "10.1109/tvcg.2017.2744878", "10.1080/14786435.2010.546377", "10.1177/003754979205800610", "10.5555/3045390.3045502", "10.1109/tvcg.2019.2903943", "10.1109/tvcg.2018.2864500", "10.1109/tvcg.2017.2744158", "10.1109/iccv.2013.8", "10.1016/j.jneumeth.2016.10.008", "10.1111/j.1467-8659.2009.01684.x", "10.1111/cgf.13092", "10.1145/1081870.1081886", "10.1109/tvcg.2016.2598830", "10.1109/tvcg.2009.23", "10.1109/tvcg.2016.2598869", "10.1038/ncomms13890", "10.1109/tvcg.2016.2598831"], "wos": 1, "children": [{"doi": "10.1111/cgf.14034", "year": "2020", "title": "The State of the Art in Enhancing Trust in Machine Learning Models with the Use of Visualizations", "conferenceName": "EuroVis", "authors": "Angelos Chatzimparmpas;Rafael Messias Martins;Ilir Jusufi;Kostiantyn Kucher;Fabrice Rossi;Andreas Kerren", "citationCount": "2", "affiliation": "Chatzimparmpas, A (Corresponding Author), Linnaeus Univ, Dept Comp Sci \\& Media Technol, Vaxjo, Sweden.\nChatzimparmpas, A.; Martins, R. M.; Jusufi, I.; Kucher, K.; Kerren, A., Linnaeus Univ, Dept Comp Sci \\& Media Technol, Vaxjo, Sweden.\nRossi, F., PSL Univ, Univ Paris Dauphine, Ceremade, Paris, France.", "countries": "Sweden;France", "abstract": "Machine learning (ML) models are nowadays used in complex applications in various domains, such as medicine, bioinformatics, and other sciences. Due to their black box nature, however, it may sometimes be hard to understand and trust the results they provide. This has increased the demand for reliable visualization tools related to enhancing trust in ML models, which has become a prominent topic of research in the visualization community over the past decades. To provide an overview and present the frontiers of current research on the topic, we present a State-of-the-Art Report (STAR) on enhancing trust in ML models with the use of interactive visualization. We define and describe the background of the topic, introduce a categorization for visualization techniques that aim to accomplish this goal, and discuss insights and opportunities for future research directions. Among our contributions is a categorization of trust against different facets of interactive ML, expanded and improved from previous research. Our results are investigated from different analytical perspectives: (a) providing a statistical overview, (b) summarizing key findings, (c) performing topic analyses, and (d) exploring the data sets used in the individual papers, all with the support of an interactive web-based survey browser. We intend this survey to be beneficial for visualization researchers whose interests involve making ML models more trustworthy, as well as researchers and practitioners from other disciplines in their search for effective visualization techniques suitable for solving their tasks with confidence and conveying meaning to their data.", "keywords": "trustworthy machine learning; visualization; interpretable machine learning; explainable machine learning", "link": "https://doi.org/10.1111/cgf.14034", "refList": ["10.1109/mcg.2018.2878902", "10.1109/tvcg.2008.153", "10.2312/mlvis.20181130", "10.1109/tvcg.2016.2598828", "10.1145/3290605.3300911", "10.1145/2993901.2993909", "10.2312/mlvis.20191158", "10.1109/tvcg.2016.2598446", "10.1111/j.1467-8659.2009.01475.x", "10.1145/3290605.3300809", "10.1109/pacificvis.2018.00031", "10.1055/s-0029-1216348", "10.1007/978-3-319-90403-0\\_13", "10.1109/tvcg.2017.2745085", "10.1111/j.1467-8659.2011.01938.x", "10.1007/978-3-319-54024-5\\_6", "10.1016/s0167-9473(01)00065-2", "10.1111/cgf.12895", "10.2312/eurovisshort.20141152.17", "10.2312/eurova.20151098.22", "10.1111/cgf.13667", "10.3115/1072228.1072378", "10.1109/tbdata.2018.2877350.16", "10.1109/lars.2009.5418323.25", "10.1109/tvcg.2017.2744878", "10.1016/j.combustflame.2005.09.018", "10.1016/j.cag.2014.01.006", "10.1109/tvcg.2016.2570755", "10.2312/mlvis.20191158.1,19", "10.1518/hfes.46.1.50.30392", "10.1145/3301275.3302280", "10.1145/3351095.3372834.1", "10.1016/s0377-2217(01)00264-8", "10.1111/cgf.13424", "10.1007/978-3-319-23485-4\\_53", "10.1007/978-94-007-0753-5\\_3623", "10.1109/tvcg.2013.101", "10.1111/cgf.12884", "10.1111/j.1467-8659.2010.01835.x", "10.1021/ci9901338", "10.4230/lipics.itcs:2017", "10.1109/mis.2013.24", "10.1109/tvcg.2014.2346482", "10.1109/tvcg.2018.2865230", "10.1073/pnas.1807180116", "10.1109/dsaa.2018.00018", "10.1109/tvcg.2009.153", "10.3115/1219840.1219855", "10.1109/tvcg.2018.2864812", "10.1109/tvcg.2018.2872577", "10.2312/trvis.20191183", "10.1109/cvpr:2004.383", "10.1109/vast.2008.4677350", "10.1145/302979.303001", "10.1109/tvcg.2018.2864499", "10.1111/cgf.13672", "10.1109/tvcg.2014.2346626", "10.23915/distill.00010.18", "10.1109/tvcg.2017.2744805", "10.2312/mlvis:20191160.18", "10.23915/distill:00016", "10.1109/pacificvis.2016.7465260", "10.1111/cgf.13683", "10.23915/distill.00016.19", "10.1145/32906053.300803.22", "10.1109/tvcg.2014.2346574", "10.1177/1473871615600010", "10.1109/tvcg.2016.2598831", "10.1145/3230623", "10.1109/visual.2019.8933744", "10.1145/2993901.2993915", "10.1016/j.visinf.2017.01.006", "10.1145/2993901.2993914", "10.1109/tvcg.2014.2346984", "10.1109/5.726791", "10.23915/distill.00010", "10.1109/tvcg.2018.2864825", "10.2307/2394164", "10.1109/tvcg.2017.2744458", "10.1145/2993901.2993917.28", "10.1111/cgf.13711", "10.1109/tvcg.2016.2598664", "10.2307/2530428", "10.1109/icdar.1997.620583", "10.1109/tvcg.2017.2744718", "10.1111/cgf.13425", "10.1109/tvcg.2019.2903943", "10.1145/1518701.1518895", "10.1109/tvcg.2018.2864838", "10.1145/62038.62043", "10.1111/j.1467-8659.2011.01920.x", "10.1145/3025171.3025208", "10.1145/355112.355124", "10.1109/vast.2010.5652398", "10.1109/tvcg.2014.2346578", "10.1145/3173574.3174209", "10.4178/epih/e2014008", "10.1109/beliv.2018.8634201.25,28", "10.1016/j.eswa.2007.12.020", "10.1111/cgf:13406", "10.1109/mcg.2011.103", "10.1631/fitee.1700808", "10.1109/tvcg.2017.2745158", "10.1073/pnas.0307752101", "10.1109/tvcg.2018.2816223", "10.1109/tvcg.2017.2745141", "10.1145/32232.32234", "10.1109/tvcg.2019.2934267", "10.1109/tvcg.2018.2864477", "10.1145/3132169", "10.2312/eurova.20151100.19", "10.1145/3172944.3172964", "10.1145/2601248.2601268", "10.1109/isai-nlp.2018.8693002.1", "10.1111/cgf.13404", "10.1007/s100320200071", "10.2312/trvis.20191183.16", "10.1111/cgf.12755", "10.1145/2702123.2702509", "10.1145/1401890.1402008.25", "10.1109/tvcg.2012.65", "10.1177/1473871617733996", "10.2312/trvis.20191187.7", "10.21236/ada273556", "10.1109/vast.2010.5652450", "10.1111/j.1467-8659.2011.01940.x", "10.1177/875647939000600106", "10.1109/tvcg.2017.2711030", "10.1016/j.immuni.2016.04.014", "10.1109/tvcg.2019.2934209", "10.1016/0095-0696(78)90006-2", "10.1016/j.jclinepi.2015.04.014", "10.1016/j.ress.2013.02.013", "10.1111/cgf.12640", "10.1145/1015330.1015388.25", "10.1111/j.1467-8659.2009.01468.x", "10.1145/1541880.1541882", "10.1109/vast.2011.6102453", "10.1016/s0008-8846(98)00165-3", "10.2312/trvis.20191186.7", "10.1007/s13748-013-0040-3", "10.1109/tvcg.2015.2467757", "10.1109/tbdata.2018.2877350", "10.1109/vast.2017.8585613", "10.1080/10556789208805504", "10.1109/vast.2012.6400484", "10.1145/3025171.3025181", "10.1007/978-3-319-90403-0\\_12", "10.1109/mcg.2019.2922592", "10.1021/ci000392t", "10.1109/vast.2007.4389000", "10.1111/cgf.13406.16", "10.1111/cgf.13684", "10.2312/eurovisshort.20161166.17", "10.2312/evs:20191168", "10.1145/3041021.3055135", "10.1145/3301275.3302265", "10.1613/jair.4135", "10.1109/tvcg.2018.2864500", "10.1109/tvcg.2017.2744158", "10.1109/ssci.2015.33", "10.1111/cgf.13453", "10.2312/pe/eurovast/eurova11/049-052", "10.1145/3025171.3025181.13", "10.1145/371920.372094", "10.1109/tvcg.2017.2744938", "10.1111/j.1467-8659.2012.03108.x", "10.1109/tvcg.2019.2934251", "10.1145/3290605.3300809.18", "10.1109/ldav.2016.7874305", "10.1109/vast.2016.7883514", "10.1109/iccv.2015.425", "10.1145/3301275.3302324", "10.1109/tnnls.2013.2292894", "10.1109/tvcg.2018.2865044", "10.1109/tvcg.2013.157", "10.1371/journal.pcbi.0020161", "10.1186/s12916-019-1426-2", "10.1109/10.867928", "10.1111/cgf.13217", "10.1109/mcg.2019.2919033", "10.1145/2993901.2993910", "10.1109/tvcg.2017.2744738", "10.2307/258792", "10.1111/cgf.12655", "10.1016/j.dss.2014.03.001", "10.1109/tvcg.2019.2904069", "10.1111/cgf.13205", "10.1002/mds.22340", "10.1109/tvcg.2019.2934595", "10.1287/inte.2018.0957", "10.1109/cvpr.2007.382974", "10.1109/tvcg.2012.280", "10.1145/2678025.2701399.13", "10.2312/mlvis.20181130.13", "10.2312/eurova.20181106.16", "10.1109/tvcg.2018.2864475", "10.2312/mlvis.20191160.18,22", "10.1007/978-1-4612-4026-6.25", "10.1109/cvpr.2006.42", "10.1145/3172944.3172950", "10.1109/cvpr.2004.383.25", "10.1109/tvcg.2019.2934812", "10.1609/aimag.v35i4.2513", "10.2312/trvis.20191185.7", "10.1111/j.1467-8659.2009.01684.x", "10.1371/journal.pone.0129126", "10.1111/cgf.13092", "10.1162/coli\\_a\\_00237", "10.1109/tvcg.2017.2744818", "10.1109/vast.2011.6102448", "10.1109/tvcg.2009.111", "10.1109/tvcg.2019.2934619", "10.1016/s0377-2217(01)00264-8.25", "10.1111/cgf.12639", "10.1109/access.2019.2919343", "10.1186/s12874-019-0681-4", "10.1109/pacificvis.2015.7156366", "10.1109/pacificvis.2018.00029", "10.1109/tvcg.2019.2934261", "10.1080/13506280444000102.http://www.uvt.nl/ticc", "10.1109/vast.2018.8802509", "10.1111/cgf.13212", "10.1145/3200489", "10.1111/cgf.13176", "10.1177/1473871620904671", "10.1007/978-3-319-10590-1\\_53", "10.1111/j.1467-8659.2012.03126.x", "10.1111/cgf.13172", "10.1145/3025171.3025208.6,21", "10.1111/cgf.12366", "10.1109/tvcg.2019.2934659", "10.1109/cvprw.2009.5206848", "10.1016/j.media.2014.11.010", "10.1109/tvcg.2017.2744683", "10.1109/tvcg.2019.2934262", "10.1016/j.neucom.2006.11.018", "10.1177/1473871615571951", "10.1371/journal.pcbi.0020161.25", "10.1177/1473871611415994", "10.2312/trvis20191187", "10.2312/eurova", "10.1145/2858036.2858529", "10.1145/2207676.2207738", "10.1007/s11042-009-0417-2", "10.1145/3301275.3302317", "10.1038/s41746-019-0148-3", "10.1145/3351095.3372834", "10.1080/10691898.2011.11889627", "10.1109/tvcg.2018.2864504", "10.1109/vast.2017.8585720", "10.1109/mcg.2018.053491732", "10.1007/s10994-010-5207-6", "10.1109/tvcg.2019.2934433", "10.1016/j.cag.2017.05.005", "10.1109/tvcg.2012.279", "10.1145/3231622.3231641.19,20", "10.1145/1562849.1562851", "10.1007/11564126\\_", "10.1109/tvcg.2018.2846735", "10.3115/1225403.1225421", "10.1109/vast.2012.6400486", "10.2312/eurova.20191116.22", "10.1109/tvcg.2007.70443", "10.1080/027868291009242", "10.2312/eurova.20151100", "10.1145/2939502.2939503.19", "10.1016/j.cag.2014.02.004", "10.1145/2939672.2939778", "10.1109/vast.2010.5652484", "10.1111/cgf.12641", "10.1145/3301275.3302289", "10.1109/visual.2019.8933619", "10.1109/tvcg.2017.2672987", "10.1109/vast.2016.7883517.20", "10.1109/igarss.2017.8127684", "10.1016/j.jcae.2010.04.002", "10.1109/vast.2010.5652885", "10.1016/j.visinf.2019.03.002", "10.1007/s00371-018-1500-3", "10.1109/mcg.2018.042731661", "10.1109/34.598228", "10.1109/tvcg.2018.2865027", "10.1016/j.neucom.2017.01.105", "10.1111/cgf.12389", "10.1109/tvcg.2019.2934591", "10.1109/vast.2010.5652392.16", "10.1111/cgf.13416", "10.1080/02701367.1992.10608764", "10.1109/vast.2017.8585721", "10.1109/tvcg.2018.2843369", "10.1109/sbes.2010.27", "10.1109/vast.2015.7347637", "10.1145/1401890.1402008", "10.1016/j.bpj.2010.04.064", "10.1109/tvcg.2013.125", "10.1109/isai-nlp.2018.8693002", "10.1371/journal.pone.0160127", "10.1145/2856767.2856779", "10.1145/2678025.2701399", "10.1109/vast.2011.6102451", "10.1109/mcg.2010.18", "10.1021/ci4000213", "10.1109/vast.2012.6400492", "10.1007/11564126-49.25", "10.2312/eurova.20171114", "10.1109/vast.2010.5652443", "10.1145/3134599", "10.2312/pe/eurovast/eurovast10/013-018.19", "10.1109/tvcg.2019.2903946", "10.1109/tvcg.2015.2467717", "10.1177/1473871612460526", "10.1016/j.cag.2018.09.018", "10.1109/tvcg.2016.2598838", "10.1145/3172944.3172964.14", "10.1109/vast.2009.5333428", "10.1109/vast.2014.7042480", "10.2312/pe/eurovast/eurovast10/013-018", "10.1177/0962280215588241", "10.1145/2993901.2993917", "10.1109/cvpr.2008:4587581", "10.1109/tvcg.2015.2467551", "10.1016/j.visinf.2018.09.001", "10.1126/science.290.5500.2319", "10.2312/eurova.20151107", "10.1109/visual.2019.8933695", "10.13140/2.1.2393.1847", "10.1197/jamia.m1929", "10.1109/cvpr.2008.4587581.25", "10.1145/1518701.1518895.16", "10.1109/vds.2017.8573444", "10.2312/trvis:20191185", "10.1145/3359786", "10.13140/2.1.1341.1520", "10.2312/pe/eurovast/eurova11/049-052.17", "10.1109/tvcg.2014.2346660", "10.1145/3185517", "10.1109/adprl.2011.5967372", "10.1109/tvcg.2015.2467591", "10.1111/j.1751-9004.2009.00232.x", "10.1136/qshc.2004.010033", "10.1109/vast.2012.6400493", "10.1109/tvcg.2019.2934266", "10.1145/2971763.2971775", "10.1111/cgf.13730", "10.1109/vast.2012.6400488", "10.1111/cgf.13210", "10.1109/tvcg.2019.2934631", "10.1145/3172944.3172965", "10.1057/ivs.2010.2", "10.1109/tvcg.2017.2745258", "10.1016/j.jbusres.2019.07.039", "10.1162/jmlr.2003.3.4-5.993", "10.1109/pacificvis.2019.00044", "10.2312/pe/eurovast/eurova12/037-041", "10.1109/tvcg.2019.2934629", "10.1177/0018720814547570", "10.1145/3292500.3330908", "10.1111/j.1467-8659.2009.01467.x", "10.2312/eurova.20151098", "10.1177/1473871617713337", "10.1109/lars:2009.5418323", "10.1109/vast.2011.6102437", "10.1111/cgf.12878", "10.1561/1500000001", "10.1145/3025171.3025222", "10.1007/s11704-016-6028-y", "10.1016/j.procs.2017.05.216", "10.1109/cvpr.2007.382974.25", "10.1080/10447318.2020.1741118", "10.1109/vast.2012.6400489", "10.1145/3025171.3025172", "10.1109/tvcg.2017.2744098", "10.1109/tvcg.2005.66", "10.1016/j.dss.2009.05.016", "10.1007/978-1-4612-4026-6", "10.2312/evs.20191168.16,20,28", "10.2312/pe/eurovast/eurova12/037-041.17", "10.1145/3290605.3300803", "10.1145/1015330.1015388", "10.1111/cgf.13197", "10.1016/b978-1-55860-377-6.50048-7", "10.1111/cgf.13681", "10.1109/tvcg.2017.2744378", "10.1109/tvcg.2017.2744358", "10.1109/vast.2008.4677352"], "wos": 1, "children": [{"doi": "10.1109/tvcg.2020.3030368", "title": "Implicit Multidimensional Projection of Local Subspaces", "year": "2020", "conferenceName": "InfoVis", "authors": "Rongzheng Bian;Yumeng Xue;Liang Zhou;Jian Zhang 0070;Baoquan Chen;Daniel Weiskopf;Yunhai Wang", "citationCount": "1", "affiliation": "Wang, YH (Corresponding Author), Shandong Univ, Qingdao, Peoples R China. Zhou, L (Corresponding Author), Univ Utah, Salt Lake City, UT 84112 USA. Bian, Rongzheng; Xue, Yumeng; Wang, Yunhai, Shandong Univ, Qingdao, Peoples R China. Chen, Baoquan, Peking Univ, Beijing, Peoples R China. Zhang, Jian, Chinese Acad Sci, CNIC, Beijing, Peoples R China. Zhou, Liang, Univ Utah, Salt Lake City, UT 84112 USA. Weiskopf, Daniel, Univ Stuttgart, Stuttgart, Germany.", "countries": "USA;Germany;China", "abstract": "We propose a visualization method to understand the effect of multidimensional projection on local subspaces, using implicit function differentiation. Here, we understand the local subspace as the multidimensional local neighborhood of data points. Existing methods focus on the projection of multidimensional data points, and the neighborhood information is ignored. Our method is able to analyze the shape and directional information of the local subspace to gain more insights into the global structure of the data through the perception of local structures. Local subspaces are fitted by multidimensional ellipses that are spanned by basis vectors. An accurate and efficient vector transformation method is proposed based on analytical differentiation of multidimensional projections formulated as implicit functions. The results are visualized as glyphs and analyzed using a full set of specifically-designed interactions supported in our efficient web-based visualization tool. The usefulness of our method is demonstrated using various multi- and high-dimensional benchmark datasets. Our implicit differentiation vector transformation is evaluated through numerical comparisons; the overall method is evaluated through exploration examples and use cases.", "keywords": "High-dimensional data visualization,dimensionality reduction,local linear subspaces,user interaction", "link": "http://dx.doi.org/10.1109/TVCG.2020.3030368", "refList": ["10.3844/jcssp.2018.613.622", "10.1016/j.aci.2018.08.003", "10.3390/info9030065", "10.1016/j.visinf.2018.09.003", "10.1371/journal.pone.0118432", "10.1016/s0893-6080(05)80023-1", "10.1109/tvcg.2020.2986996", "10.1109/icst.2012.56", "10.1007/s10844-013-0250-y", "10.1109/tbdata.2018", "10.1145/1125451.1125659", "10.1109/tvcg.2013.125", "10.1177/1473871611412817", "10.1145/3290605.3300911", "10.1111/cgf.14034", "10.1007/s13721-013-0034-x", "10.1016/j.procs.2017.05.216", "10.1016/j.ins.2009.08.025", "10.1109/tvcg.2013.124", "10.1109/tvcg.2018.2864499", "10.1109/tvcg.2018.2864475", "10.1080/10447318.2020.1741118", "10.1016/j.imu.2019.100203", "10.1109/tvcg.2018.2865240", "10.1186/s12864-019-6413-7", "10.1109/tvcg.2015.2467551", "10.1002/widm.1249", "10.1007/978-3-319-66429-3\\_29", "10.1109/tvcg.2014.2346481", "10.1109/tvcg.2018.2864825", "10.1177/1473871620904671", "10.1109/tvcg.2019.2934267", "10.1136/bmjopen-2016-012799", "10.1109/smartgridcomm.2017.8340682", "10.1007/s10664-015-9401-9", "10.1145/1143844.1143874", "10.1111/cgf.12389", "10.1109/tvcg.2018.2872577", "10.1007/978-981-13-5802-9\\_20", "10.1016/j.ipm.2009.03.002", "10.5220/0006431602160222", "10.1109/mcg.2015.50", "10.1109/tvcg.2014.2346574", "10.1007/bf02289565", "10.1109/tvcg.2017.2744378", "10.1016/j.patrec.2008.08.010", "10.1023/a:1010933404324", "10.9735/2229-3981"], "wos": 1, "children": [], "len": 1}, {"doi": "10.1109/tvcg.2020.3030465", "title": "Visual Causality Analysis of Event Sequence Data", "year": "2020", "conferenceName": "VAST", "authors": "Zhuochen Jin;Shunan Guo;Nan Chen;Daniel Weiskopf;David Gotz;Nan Cao", "citationCount": "0", "affiliation": "Cao, N (Corresponding Author), Tongji Univ, IDVx Lab, Shanghai, Peoples R China. Jin, Zhuochen; Guo, Shunan; Chen, Nan; Cao, Nan, Tongji Univ, IDVx Lab, Shanghai, Peoples R China. Weiskopf, Daniel, Univ Stuttgart, Stuttgart, Germany. Gotz, David, Univ N Carolina, Chapel Hill, NC 27515 USA.", "countries": "USA;Germany;China", "abstract": "Causality is crucial to understanding the mechanisms behind complex systems and making decisions that lead to intended outcomes. Event sequence data is widely collected from many real-world processes, such as electronic health records, web clickstreams, and financial transactions, which transmit a great deal of information reflecting the causal relations among event types. Unfortunately, recovering causalities from observational event sequences is challenging, as the heterogeneous and high-dimensional event variables are often connected to rather complex underlying event excitation mechanisms that are hard to infer from limited observations. Many existing automated causal analysis techniques suffer from poor explainability and fail to include an adequate amount of human knowledge. In this paper, we introduce a visual analytics method for recovering causalities in event sequence data. We extend the Granger causality analysis algorithm on Hawkes processes to incorporate user feedback into causal model refinement. The visualization system includes an interactive causal analysis framework that supports bottom-up causal exploration, iterative causal verification and refinement, and causal comparison through a set of novel visualizations and interactions. We report two forms of evaluation: a quantitative evaluation of the model improvements resulting from the user-feedback mechanism, and a qualitative evaluation through case studies in different application domains to demonstrate the usefulness of the system.", "keywords": "Event sequence data,causality analysis,visual analytics", "link": "http://dx.doi.org/10.1109/TVCG.2020.3030465", "refList": ["10.5555/1642718", "10.1109/tvcg.2018.2865022", "10.5555/2074094.2074151", "10.1109/tvcg.2016.2618797", "10.1073/pnas.1320645111", "10.1109/tvcg.2017.2744843", "10.1109/iv.2017.69", "10.1109/tvcg.2019.2934399", "10.1145/3172944.3173007", "10.5555/1795555", "10.1109/mcg.2005.102", "10.1145/381641.381653", "10.1162/153244301753344614", "10.1111/cgf.14034", "10.1111/cgf.13198", "10.1017/cbo9780511519857", "10.1007/s10462-016-9475-9", "10.1075/ssol.2.2.07bor", "10.1007/978-1-4614-3223-4\\_3", "10.1109/infvis.2003.1249025", "10.1007/978-94-007-6094-313", "10.1145/2858036.2858387", "10.1109/tvcg.2007.70528", "10.1109/tvcg.2017.2674958", "10.1147/sj.454.0801", "10.1109/tvcg.2013.119", "10.1145/3173574.3173711", "10.1016/j.erss.2017.06.034", "10.1109/visual.2019.8933695", "10.1007/s11665-016-2173-6", "10.1016/0377-0427(87)90125-7", "10.2307/3601125", "10.1016/b978-0-444-88738-2.50018-x", "10.1109/mcg.2006.70", "10.1109/tvcg.2018.2865145", "10.1017/s1351324997001502", "10.1109/tvcg.2010.179", "10.1214/aos/1176344552", "10.1109/mcg.2009.22", "10.1007/978-3-319-26633-6\\_13", "10.1080/10447318.2014.905422", "10.1016/j.visinf.2019.03.004", "10.1057/palgrave.ivs.9500074", "10.1007/978-1-4614-3223-4"], "wos": 1, "children": [], "len": 1}], "len": 5}], "len": 7}, {"doi": "10.1109/tvcg.2019.2934657", "title": "OD Morphing: Balancing Simplicity with Faithfulness for OD Bundling", "year": "2019", "conferenceName": "VAST", "authors": "Yan Lyu;Xu Liu;Hanyi Chen;Arpan Mangal;Kai Liu;Chao Chen 0004;Brian Y. Lim", "citationCount": "0", "affiliation": "Lyu, Y (Corresponding Author), Natl Univ Singapore, Singapore, Singapore. Lyu, Yan; Lim, Brian, Natl Univ Singapore, Singapore, Singapore. Liu, Xu, Southeast Univ, Nanjing, Peoples R China. Chen, Hanyi, Zhejiang Univ, Hangzhou, Peoples R China. Mangal, Arpan, Indian Inst Technol, Delhi, India. Liu, Kai; Chen, Chao, Chongqing Univ, Chongqing, Peoples R China.", "countries": "India;China;Singapore", "abstract": "OD bundling is a promising method to identify key origin-destination (OD) patterns, but the bundling can mislead the interpretation of actual trajectories traveled. We present OD Morphing, an interactive OD bundling technique that improves geographical faithfulness to actual trajectories while preserving visual simplicity for OD patterns. OD Morphing iteratively identifies critical waypoints from the actual trajectory network with a min-cut algorithm and transitions OD bundles to pass through the identified waypoints with a smooth morphing method. Furthermore, we extend OD Morphing to support bundling at interaction speeds to enable users to interactively transition between degrees of faithfulness to aid sensemaking. We introduce metrics for faithfulness and simplicity to evaluate their trade-off achieved by OD morphed bundling. We demonstrate OD Morphing on real-world city-scale taxi trajectory and USA domestic planned flight datasets.", "keywords": "OD Visualization,Edge Bundling,Trajectory", "link": "http://dx.doi.org/10.1109/TVCG.2019.2934657", "refList": ["10.1109/tvcg.2008.135", "10.1145/2833165.2833168", "10.1111/cgf.13213", "10.1109/tvcg.2018.2864503", "10.1109/tvcg.2010.44", "10.1145/1653771.1653820", "10.1016/j.comgeo.2015.10.005", "10.1109/tvcg.2014.2337333", "10.1016/j.sbspro.2014.12.218", "10.1109/tvcg.2016.2535234", "10.1109/pacificvis.2011.5742386", "10.1145/321694.321699", "10.1109/tvcg.2013.246", "10.1111/cgf.12881", "10.1111/j.1467-8659.2009.01700.x", "10.1109/tvcg.2015.2467771", "10.1109/tvcg.2011.233", "10.1109/infvis.2003.1249008", "10.1109/itsc.2011.6082850", "10.1111/j.1467-8659.2009.01680.x", "10.1109/tvcg.2014.2346271", "10.1109/tvcg.2015.2467691", "10.1109/tvcg.2016.2515611", "10.1016/j.physa.2006.12.003", "10.1147/sj.41.0025", "10.1007/978-3-642-00304-2\\_1", "10.1109/tvcg.2006.147", "10.1109/tvcg.2016.2598958", "10.1109/tpami.2004.60", "10.1109/tvcg.2011.223", "10.1109/tits.2018.2817282", "10.1111/j.1467-8659.2012.03079.x", "10.1109/tvcg.2007.70539", "10.1109/tvcg.2017.2744338", "10.1109/pacificvis.2017.8031594", "10.1179/000870410x12658023467367", "10.1145/2030112.2030126", "10.1109/tvcg.2011.104", "10.1145/2133416.2146416", "10.1109/tvcg.2011.190", "10.1142/s0218195995000064", "10.1002/cnm.1630040603", "10.1109/pacificvis.2011.5742389", "10.1109/pacificvis.2015.7156354", "10.1111/cgf.12778", "10.1109/dsnw.2011.5958797", "10.1109/cvprw.2008.4563095", "10.1109/tvcg.2016.2598885", "10.1109/tvcg.2017.2744322", "10.1111/j.1467-8659.2009.01450.x", "10.1109/tvcg.2016.2598416", "10.1109/cce.2012.6315867"], "wos": 1, "children": [], "len": 1}, {"doi": "10.1109/tvcg.2019.2934655", "title": "Visual Analytics for Electromagnetic Situation Awareness in Radio Monitoring and Management", "year": "2019", "conferenceName": "VAST", "authors": "Ying Zhao;Xiaobo Luo;Xiaoru Lin;Hairong Wang;Xiaoyan Kui;Fangfang Zhou;Jinsong Wang;Yi Chen 0007;Wei Chen", "citationCount": "3", "affiliation": "Kui, XY; Zhou, FF (Corresponding Author), Cent S Univ, Sch Comp Sci \\& Engn, Changsha, Hunan, Peoples R China. Zhao, Ying; Luo, Xiaobo; Lin, Xiaoru; Kui, Xiaoyan; Zhou, Fangfang, Cent S Univ, Sch Comp Sci \\& Engn, Changsha, Hunan, Peoples R China. Wang, Hairong, Cent S Univ, Sch Automat, Changsha, Hunan, Peoples R China. Wang, Jinsong, Southwest Elect \\& Telecom Engn Inst, Shanghai, Peoples R China. Chen, Yi, Beijing Technol \\& Business Univ, Beijing Key Lab Big Data Technol Food Safety, Beijing, Peoples R China. Chen, Wei, Zhejiang Univ, Key Lab CAD \\& CG, Hangzhou, Zhejiang, Peoples R China.", "countries": "China", "abstract": "Traditional radio monitoring and management largely depend on radio spectrum data analysis, which requires considerable domain experience and heavy cognition effort and frequently results in incorrect signal judgment and incomprehensive situation awareness. Faced with increasingly complicated electromagnetic environments, radio supervisors urgently need additional data sources and advanced analytical technologies to enhance their situation awareness ability. This paper introduces a visual analytics approach for electromagnetic situation awareness. Guided by a detailed scenario and requirement analysis, we first propose a signal clustering method to process radio signal data and a situation assessment model to obtain qualitative and quantitative descriptions of the electromagnetic situations. We then design a two-module interface with a set of visualization views and interactions to help radio supervisors perceive and understand the electromagnetic situations by a joint analysis of radio signal data and radio spectrum data. Evaluations on real-world data sets and an interview with actual users demonstrate the effectiveness of our prototype system. Finally, we discuss the limitations of the proposed approach and provide future work directions.", "keywords": "Radio monitoring and management,radio signal data,radio spectrum data,situation awareness,visual analytics", "link": "http://dx.doi.org/10.1109/TVCG.2019.2934655", "refList": ["10.1016/j.newast.2010.07.009", "10.1109/tvcg.2017.2744459", "10.1109/tvcg.2018.2864503", "10.1145/1029208.1029219", "10.1109/pacificvis.2014.54", "10.1109/tvcg.2018.2829750", "10.1016/j.jvlc.2017.11.004", "10.1109/tcyb.2015.2448236", "10.1016/j.patrec.2017.11.011", "10.1109/tvcg.2015.2505305", "10.1109/vast.2014.7042528", "10.1007/s12650-018-0530-2", "10.1109/tvcg.2018.2816203", "10.1109/tmm.2016.2614220", "10.1109/tvcg.2017.2745180", "10.1109/mcg.2018.2879067", "10.1109/tvcg.2018.2859973", "10.1109/tvcg.2016.2598460", "10.1109/infvis.2005.1532134", "10.1109/tvcg.2018.2851227", "10.1155/2012/920671", "10.1109/vast.2014.7042479", "10.1109/tvcg.2013.228", "10.1109/tvcg.2018.2865077", "10.1016/j.csda.2005.10.001", "10.1109/tvcg.2018.2865028", "10.1109/tvcg.2011.239", "10.1145/3173574.3174237", "10.1007/s13042-016-0603-2", "10.1109/tvcg.2018.2865020", "10.1017/s1041610219000024", "10.1109/2945.981848", "10.1109/tvcg.2010.193", "10.1109/tvcg.2018.2802520", "10.1145/3200766", "10.1109/wcncw.2015.7122557", "10.1145/3006299.3006312", "10.1109/icsssm.2007.4280175", "10.1126/science.1242072", "10.1109/tvcg.2017.2744098", "10.1109/tvcg.2015.2467196", "10.1109/tvcg.2016.2598619", "10.1109/tvcg.2016.2598664", "10.1109/tvcg.2013.196", "10.1109/comst.2016.2631080", "10.1109/tvcg.2018.2865029", "10.1007/s10816-016-9307-x", "10.1109/tvcg.2008.166", "10.1109/tvcg.2017.2758362", "10.1109/vizsec.2005.1532072", "10.1518/001872095779049543", "10.1109/tvcg.2007.70415", "10.1016/j.ins.2018.01.013", "10.1109/tvcg.2014.2346911", "10.1109/mim.2013.6616284", "10.1109/jsyst.2014.2358997", "10.1111/cgf.12910", "10.1109/isi.2009.5137305", "10.1109/tvcg.2011.179", "10.1007/s11277-015-2631-8", "10.1111/cgf.12396", "10.1109/tvcg.2013.2297933", "10.1109/tvcg.2014.2346926", "10.1109/tvcg.2014.2346913", "10.1109/pacificvis.2018.00030", "10.1109/tvcg.2014.2346433", "10.1109/tvcg.2016.2614803"], "wos": 1, "children": [{"doi": "10.1109/tvcg.2020.3030443", "title": "CAVA: A Visual Analytics System for Exploratory Columnar Data Augmentation Using Knowledge Graphs", "year": "2020", "conferenceName": "VAST", "authors": "Dylan Cashman;Shenyu Xu;Subhajit Das;Florian Heimerl;Cong Liu;Shah Rukh Humayoun;Michael Gleicher;Alex Endert;Remco Chang", "citationCount": "0", "affiliation": "Cashman, D (Corresponding Author), Tufts Univ, Medford, MA 02155 USA. Cashman, Dylan; Liu, Cong; Chang, Remco, Tufts Univ, Medford, MA 02155 USA. Xu, Shenyu; Das, Subhajit; Endert, Alex, Georgia Tech, Atlanta, GA USA. Heimerl, Florian; Gleicher, Michael, Univ Wisconsin, Madison, WI 53706 USA. Humayoun, Shah Rukh, San Francisco State Univ, San Francisco, CA 94132 USA.", "countries": "USA", "abstract": "Most visual analytics systems assume that all foraging for data happens before the analytics process; once analysis begins, the set of data attributes considered is fixed. Such separation of data construction from analysis precludes iteration that can enable foraging informed by the needs that arise in-situ during the analysis. The separation of the foraging loop from the data analysis tasks can limit the pace and scope of analysis. In this paper, we present CAVA, a system that integrates data curation and data augmentation with the traditional data exploration and analysis tasks, enabling information foraging in-situ during analysis. Identifying attributes to add to the dataset is difficult because it requires human knowledge to determine which available attributes will be helpful for the ensuing analytical tasks. CAVA crawls knowledge graphs to provide users with a a broad set of attributes drawn from external data to choose from. Users can then specify complex operations on knowledge graphs to construct additional attributes. CAVA shows how visual analytics can help users forage for attributes by letting users visually explore the set of available data, and by serving as an interface for query construction. It also provides visualizations of the knowledge graph itself to help users understand complex joins such as multi-hop aggregations. We assess the ability of our system to enable users to perform complex data combinations without programming in a user study over two datasets. We then demonstrate the generalizability of CAVA through two additional usage scenarios. The results of the evaluation confirm that CAVA is effective in helping the user perform data foraging that leads to improved analysis outcomes, and offer evidence in support of integrating data augmentation as a part of the visual analytics pipeline.", "keywords": "Visual Analytics,Information Foraging,Data Augmentation", "link": "http://dx.doi.org/10.1109/TVCG.2020.3030443", "refList": ["10.1057/palgrave.ivs.9500122", "10.1109/tvcg.2016.2598867", "10.1111/cgf.13708", "10.1109/tvcg.2019.2934799", "10.1109/tvcg.2019.2934541", "10.1109/tvcg.2013.65", "10.1109/tvcg.2018.2875702", "10.1109/iv.2004.1320207", "10.1068/p260471", "10.1145/1778765.1778816", "10.1109/tvcg.2018.2808489", "10.1109/tvcg.2018.2864912", "10.1016/j.apgeog.2015.12.006", "10.1111/j.1467-8659.2011.01960.x", "10.1109/tvcg.2018.2864843", "10.1109/pacificvis.2010.5429604", "10.1109/tvcg.2014.2346898", "10.1109/5.726791", "10.1177/1475090214540874", "10.1109/icde.2016.7498287", "10.1145/1556262.1556289", "10.1109/tvcg.2007.70535", "10.1109/vast.2012.6400489", "10.1145/1056808.1056914", "10.1016/j.neucom.2014.09.063", "10.1145/7529.8927", "10.1109/tvcg.2016.2598495", "10.1109/tvcg.2016.2607204", "10.1109/vast47406.2019.8986943", "10.3758/bf03205986", "10.1109/infvis.2005.1532142", "10.1145/1150402.1150479", "10.1109/tvcg.2017.2674978", "10.1109/tvcg.2019.2945960", "10.1109/tvcg.2017.2744098", "10.1109/tvcg.2017.2674999", "10.1109/tvcg.2011.279", "10.1109/tvcg.2014.2346594", "10.1109/tvcg.2017.2744184", "10.1111/cgf.12876", "10.1007/s4095-020-0191-7", "10.1007/s11390-015-1535-0", "10.1111/cgf.12640", "10.1109/tvcg.2016.2598667", "10.1111/cgf.13683", "10.1109/tvcg.2013.153", "10.1109/tvcg.2019.2934208", "10.1109/tvcg.2019.2934655", "10.1111/cgf.12655", "10.1007/s11023-010-9221-z", "10.1109/vast.2012.6400487", "10.1145/2702123.2702585", "10.1007/bf00310175", "10.1109/tvcg.2017.2744378", "10.1103/physreve.64.061907", "10.1109/ldav.2017.8231848", "10.1109/tvcg.2016.2598831"], "wos": 1, "children": [], "len": 1}, {"doi": "10.1109/tvcg.2020.3030432", "title": "Evaluation of Sampling Methods for Scatterplots", "year": "2020", "conferenceName": "VAST", "authors": "Jun Yuan;Shouxing Xiang;Jiazhi Xia;Lingyun Yu;Shixia Liu", "citationCount": "0", "affiliation": "Liu, SX (Corresponding Author), Tsinghua Univ, BNRist, Beijing, Peoples R China. Yuan, Jun; Xiang, Shouxing; Liu, Shixia, Tsinghua Univ, BNRist, Beijing, Peoples R China. Xia, Jiazhi, Cent South Univ, Changsha, Peoples R China. Yu, Lingyun, Xian Jiaotong Liverpool Univ, Suzhou, Peoples R China.", "countries": "China", "abstract": "Given a scatterplot with tens of thousands of points or even more, a natural question is which sampling method should be used to create a small but \u201cgood\u201d scatterplot for a better abstraction. We present the results of a user study that investigates the influence of different sampling strategies on multi-class scatterplots. The main goal of this study is to understand the capability of sampling methods in preserving the density, outliers, and overall shape of a scatterplot. To this end, we comprehensively review the literature and select seven typical sampling strategies as well as eight representative datasets. We then design four experiments to understand the performance of different strategies in maintaining: 1) region density; 2) class density; 3) outliers; and 4) overall shape in the sampling results. The results show that: 1) random sampling is preferred for preserving region density; 2) blue noise sampling and random sampling have comparable performance with the three multi-class sampling strategies in preserving class density; 3) outlier biased density based sampling, recursive subdivision based sampling, and blue noise sampling perform the best in keeping outliers; and 4) blue noise sampling outperforms the others in maintaining the overall shape of a scatterplot.", "keywords": "Scatterplot,data sampling,empirical evaluation", "link": "http://dx.doi.org/10.1109/TVCG.2020.3030432", "refList": ["10.1057/palgrave.ivs.9500122", "10.1109/tvcg.2016.2598867", "10.1109/tvcg.2015.2467591", "10.1111/cgf.13708", "10.1109/tvcg.2019.2934799", "10.1109/tvcg.2019.2934541", "10.1109/tvcg.2013.65", "10.1109/iv.2004.1320207", "10.1068/p260471", "10.1145/1778765.1778816", "10.1109/tvcg.2018.2808489", "10.1109/tvcg.2018.2864912", "10.1016/j.apgeog.2015.12.006", "10.1111/j.1467-8659.2011.01960.x", "10.1109/tvcg.2018.2864843", "10.1109/pacificvis.2010.5429604", "10.1109/tvcg.2014.2346898", "10.1109/5.726791", "10.1177/1475090214540874", "10.1145/1556262.1556289", "10.1109/tvcg.2007.70535", "10.1109/vast.2012.6400489", "10.1145/1056808.1056914", "10.1016/j.neucom.2014.09.063", "10.1145/7529.8927", "10.1109/tvcg.2016.2607204", "10.1109/vast47406.2019.8986943", "10.3758/bf03205986", "10.1109/infvis.2005.1532142", "10.1145/1150402.1150479", "10.1109/tvcg.2017.2674978", "10.1109/tvcg.2017.2744098", "10.1109/tvcg.2017.2674999", "10.1109/tvcg.2011.279", "10.1109/tvcg.2014.2346594", "10.1109/tvcg.2017.2744184", "10.1111/cgf.12876", "10.1109/1011101.2019.2945960", "10.1007/s4095-020-0191-7", "10.1007/s11390-015-1535-0", "10.1111/cgf.12640", "10.1109/tvcg.2016.2598667", "10.1111/cgf.13683", "10.1109/tvcg.2013.153", "10.1109/tvcg.2019.2934208", "10.1109/tvcg.2019.2934655", "10.1111/cgf.12655", "10.1007/s11023-010-9221-z", "10.1109/vast.2012.6400487", "10.1145/2702123.2702585", "10.1007/bf00310175", "10.1109/tvcg.2017.2744378", "10.1103/physreve.64.061907", "10.1109/ldav.2017.8231848", "10.1109/tvcg.2016.2598831"], "wos": 1, "children": [], "len": 1}], "len": 5}, {"doi": "10.1109/tvcg.2020.3030440", "title": "Context-aware Sampling of Large Networks via Graph Representation Learning", "year": "2020", "conferenceName": "InfoVis", "authors": "Zhiguang Zhou;Chen Shi;Xilong Shen;Lihong Cai;Haoxuan Wang;Yuhua Liu;Ying Zhao;Wei Chen", "citationCount": "0", "affiliation": "Zhao, Y (Corresponding Author), Cent South Univ, Changsha, Peoples R China. Chen, W (Corresponding Author), Zhejiang Univ, State Key Lab CAD \\& CG, Hangzhou, Peoples R China. Zhou, Zhiguang; Shi, Chen; Shen, Xilong; Cai, Lihong; Wang, Haoxuan; Liu, Yuhua, Zhejiang Univ Finance \\& Econ, Sch Informat, Hangzhou, Peoples R China. Zhao, Ying, Cent South Univ, Changsha, Peoples R China. Chen, Wei, Zhejiang Univ, State Key Lab CAD \\& CG, Hangzhou, Peoples R China.", "countries": "China", "abstract": "Numerous sampling strategies have been proposed to simplify large-scale networks for highly readable visualizations. It is of great challenge to preserve contextual structures formed by nodes and edges with tight relationships in a sampled graph, because they are easily overlooked during the process of sampling due to their irregular distribution and immunity to scale. In this paper, a new graph sampling method is proposed oriented to the preservation of contextual structures. We first utilize a graph representation learning (GRL) model to transform nodes into vectors so that the contextual structures in a network can be effectively extracted and organized. Then, we propose a multi-objective blue noise sampling model to select a subset of nodes in the vectorized space to preserve contextual structures with the retention of relative data and cluster densities in addition to those features of significance, such as bridging nodes and graph connections. We also design a set of visual interfaces enabling users to interactively conduct context-aware sampling, visually compare results with various sampling strategies, and deeply explore large networks. Case studies and quantitative comparisons based on real-world datasets have demonstrated the effectiveness of our method in the abstraction and exploration of large networks.", "keywords": "Graph sampling,Graph representation learning,Blue noise sampling,Graph evaluation", "link": "http://dx.doi.org/10.1109/TVCG.2020.3030440", "refList": ["10.1145/2491159.2491168", "10.1016/j.physa.2015.04.035", "10.1145/1830252.1830274", "10.1109/icdmw.2007.91", "10.1002/net.21834", "10.1109/tvcg.2018.2864503", "10.1016/j.cag.2018.01.010", "10.1109/icc.2016.7511156", "10.1111/cgf.13444", "10.1145/956750.956831", "10.1145/364099.364331", "10.1007/s00180-016-0663-5", "10.1109/tvcg.2013.223", "10.1007/s12650-018-0530-2", "10.1103/physreve.73.016102", "10.1109/access.2018.2870684", "10.1007/978-3-319-06793-3\\_1", "10.2312/vissym/eurovis05/239-246", "10.1016/j.ins.2015.02.014", "10.1145/2339530.2339723", "10.1109/icde.2015.7113345", "10.1109/tvcg.2011.233", "10.14778/2809974.2809980", "10.1109/glocom.2015.7417471", "10.1145/2578153.2578175", "10.1214/aoms/1177705148", "10.1109/tvcg.2008.130", "10.14232/actacyb.20.1.2011.6", "10.1504/ijitm.2019.099809", "10.1109/tvcg.2018.2865020", "10.1145/956750", "10.1002/cpe.4330060203", "10.1145/1150402.1150479", "10.1103/physreve.72.036118", "10.1109/tvcg.2017.2744098", "10.1145/2020408.2020512", "10.1142/s0129183114400075", "10.1109/jsac.2011.111005", "10.1016/j.camwa.2011.11.057", "10.1145/2470654.2466444", "10.1109/tvcg.2017.2674999", "10.1214/aos/1013203451", "10.1109/icdcsw.2011.34", "10.1016/j.physa.2013.11.015", "10.1145/1081870.1081893", "10.1109/tnet.2008.2001730", "10.1109/access.2016.2633485", "10.1145/1879141.1879192", "10.1371/journal.pone.0098679", "10.1126/science.220.4598.671", "10.1109/pacificvis.2015.7156355", "10.1088/1475-7516/2011/08/011", "10.1007/978-3-319-27261-0\\_41", "10.1111/cgf.13410", "10.1109/tvcg.2018.2865139", "10.1109/tvcg.2016.2598831", "10.1016/j.physa.2014.06.065"], "wos": 1, "children": [], "len": 1}, {"doi": "10.1109/tvcg.2020.3030469", "title": "Topology Density Map for Urban Data Visualization and Analysis", "year": "2020", "conferenceName": "VAST", "authors": "Zezheng Feng;Haotian Li;Wei Zeng 0004;Shuang-Hua Yang;Huamin Qu", "citationCount": "0", "affiliation": "Zeng, W (Corresponding Author), Chinese Acad Sci, Shenzhen Inst Adv Technol, Shenzhen, Peoples R China. Feng, Zezheng; Li, Haotian; Qu, Huamin, Hong Kong Univ Sci \\& Technol, Hong Kong, Peoples R China. Zeng, Wei, Chinese Acad Sci, Shenzhen Inst Adv Technol, Shenzhen, Peoples R China. Yang, Shuang-Hua, Southern Univ Sci \\& Technol, Shenzhen, Peoples R China.", "countries": "China", "abstract": "Density map is an effective visualization technique for depicting the scalar field distribution in 2D space. Conventional methods for constructing density maps are mainly based on Euclidean distance, limiting their applicability in urban analysis that shall consider road network and urban traffic. In this work, we propose a new method named Topology Density Map, targeting for accurate and intuitive density maps in the context of urban environment. Based on the various constraints of road connections and traffic conditions, the method first constructs a directed acyclic graph (DAG) that propagates nonlinear scalar fields along 1D road networks. Next, the method extends the scalar fields to a 2D space by identifying key intersecting points in the DAG and calculating the scalar fields for every point, yielding a weighted Voronoi diagram like effect of space division. Two case studies demonstrate that the Topology Density Map supplies accurate information to users and provides an intuitive visualization for decision making. An interview with domain experts demonstrates the feasibility, usability, and effectiveness of our method.", "keywords": "Density map,network topology,urban data", "link": "http://dx.doi.org/10.1109/TVCG.2020.3030469", "refList": ["10.1109/vast.2009.5332584", "10.1109/tvcg.2013.193", "10.1080/03081060.2013.844903", "10.1109/tvcg.2018.2864503", "10.1145/2702123.2702419", "10.1109/tvcg.2019.2934670", "10.1109/tits.2015.2496783", "10.1177/1473871615581216", "10.3141/1617-02", "10.1145/2024156.2024169", "10.1111/cgf.13712", "10.1016/j.ejor.2007.02.005", "10.1109/tvcg.2014.2346893", "10.1007/11871842\\_29", "10.1109/vast.2010.5652478", "10.1016/j.visinf.2019.10.002", "10.1109/tvcg.2016.2616404", "10.1109/vl.1996.545307", "10.1145/2629592", "10.1155/2018/2696037", "10.1061/(asce)0733-947x(1998)124:4(368", "10.3141/1899-21", "10.1023/a:1026123329433", "10.1109/mcg.2010.79", "10.1057/palgrave.ivs.9500174", "10.1109/tcyb.2019.2963681", "10.1109/tvcg.2015.2467554", "10.1111/cgf.12114", "10.1145/2814575", "10.1016/j.jcps.2014.08.002", "10.1109/2945.981847", "10.1080/03052150210909", "10.1109/tciaig.2012.2186810", "10.1109/tits.2017.2683539", "10.1109/iv.2004.1320137", "10.1016/0377-2217(80)90126-5", "10.1109/tvcg.2016.2640960", "10.1109/tvcg.2015.2467196", "10.1145/3097983.3098056", "10.1007/s11432-018-9801-4", "10.1109/vast.2014.7042490", "10.1061/(asce)0733-947x(2006)132:2(122", "10.1016/j.tra.2008.03.011", "10.1109/tits.2014.2298892", "10.1016/j.trb.2005.12.003", "10.1007/bf01840357", "10.1109/vast.2011.6102454", "10.1109/tvcg.2013.145", "10.1007/bf02289588", "10.1109/pacificvis.2014.56", "10.1109/mcg.2018.053491730", "10.1109/tvcg.2009.111", "10.1057/palgrave.ivs.9500184", "10.1109/tvcg.2013.173", "10.1109/tvcg.2016.2598432", "10.1007/978-0-85729-079-3"], "wos": 1, "children": [], "len": 1}], "len": 33}, {"doi": "10.1109/tvcg.2020.3030443", "title": "CAVA: A Visual Analytics System for Exploratory Columnar Data Augmentation Using Knowledge Graphs", "year": "2020", "conferenceName": "VAST", "authors": "Dylan Cashman;Shenyu Xu;Subhajit Das;Florian Heimerl;Cong Liu;Shah Rukh Humayoun;Michael Gleicher;Alex Endert;Remco Chang", "citationCount": "0", "affiliation": "Cashman, D (Corresponding Author), Tufts Univ, Medford, MA 02155 USA. Cashman, Dylan; Liu, Cong; Chang, Remco, Tufts Univ, Medford, MA 02155 USA. Xu, Shenyu; Das, Subhajit; Endert, Alex, Georgia Tech, Atlanta, GA USA. Heimerl, Florian; Gleicher, Michael, Univ Wisconsin, Madison, WI 53706 USA. Humayoun, Shah Rukh, San Francisco State Univ, San Francisco, CA 94132 USA.", "countries": "USA", "abstract": "Most visual analytics systems assume that all foraging for data happens before the analytics process; once analysis begins, the set of data attributes considered is fixed. Such separation of data construction from analysis precludes iteration that can enable foraging informed by the needs that arise in-situ during the analysis. The separation of the foraging loop from the data analysis tasks can limit the pace and scope of analysis. In this paper, we present CAVA, a system that integrates data curation and data augmentation with the traditional data exploration and analysis tasks, enabling information foraging in-situ during analysis. Identifying attributes to add to the dataset is difficult because it requires human knowledge to determine which available attributes will be helpful for the ensuing analytical tasks. CAVA crawls knowledge graphs to provide users with a a broad set of attributes drawn from external data to choose from. Users can then specify complex operations on knowledge graphs to construct additional attributes. CAVA shows how visual analytics can help users forage for attributes by letting users visually explore the set of available data, and by serving as an interface for query construction. It also provides visualizations of the knowledge graph itself to help users understand complex joins such as multi-hop aggregations. We assess the ability of our system to enable users to perform complex data combinations without programming in a user study over two datasets. We then demonstrate the generalizability of CAVA through two additional usage scenarios. The results of the evaluation confirm that CAVA is effective in helping the user perform data foraging that leads to improved analysis outcomes, and offer evidence in support of integrating data augmentation as a part of the visual analytics pipeline.", "keywords": "Visual Analytics,Information Foraging,Data Augmentation", "link": "http://dx.doi.org/10.1109/TVCG.2020.3030443", "refList": ["10.1057/palgrave.ivs.9500122", "10.1109/tvcg.2016.2598867", "10.1111/cgf.13708", "10.1109/tvcg.2019.2934799", "10.1109/tvcg.2019.2934541", "10.1109/tvcg.2013.65", "10.1109/tvcg.2018.2875702", "10.1109/iv.2004.1320207", "10.1068/p260471", "10.1145/1778765.1778816", "10.1109/tvcg.2018.2808489", "10.1109/tvcg.2018.2864912", "10.1016/j.apgeog.2015.12.006", "10.1111/j.1467-8659.2011.01960.x", "10.1109/tvcg.2018.2864843", "10.1109/pacificvis.2010.5429604", "10.1109/tvcg.2014.2346898", "10.1109/5.726791", "10.1177/1475090214540874", "10.1109/icde.2016.7498287", "10.1145/1556262.1556289", "10.1109/tvcg.2007.70535", "10.1109/vast.2012.6400489", "10.1145/1056808.1056914", "10.1016/j.neucom.2014.09.063", "10.1145/7529.8927", "10.1109/tvcg.2016.2598495", "10.1109/tvcg.2016.2607204", "10.1109/vast47406.2019.8986943", "10.3758/bf03205986", "10.1109/infvis.2005.1532142", "10.1145/1150402.1150479", "10.1109/tvcg.2017.2674978", "10.1109/tvcg.2019.2945960", "10.1109/tvcg.2017.2744098", "10.1109/tvcg.2017.2674999", "10.1109/tvcg.2011.279", "10.1109/tvcg.2014.2346594", "10.1109/tvcg.2017.2744184", "10.1111/cgf.12876", "10.1007/s4095-020-0191-7", "10.1007/s11390-015-1535-0", "10.1111/cgf.12640", "10.1109/tvcg.2016.2598667", "10.1111/cgf.13683", "10.1109/tvcg.2013.153", "10.1109/tvcg.2019.2934208", "10.1109/tvcg.2019.2934655", "10.1111/cgf.12655", "10.1007/s11023-010-9221-z", "10.1109/vast.2012.6400487", "10.1145/2702123.2702585", "10.1007/bf00310175", "10.1109/tvcg.2017.2744378", "10.1103/physreve.64.061907", "10.1109/ldav.2017.8231848", "10.1109/tvcg.2016.2598831"], "wos": 1, "children": [], "len": 1}, {"doi": "10.1109/tvcg.2020.3030432", "title": "Evaluation of Sampling Methods for Scatterplots", "year": "2020", "conferenceName": "VAST", "authors": "Jun Yuan;Shouxing Xiang;Jiazhi Xia;Lingyun Yu;Shixia Liu", "citationCount": "0", "affiliation": "Liu, SX (Corresponding Author), Tsinghua Univ, BNRist, Beijing, Peoples R China. Yuan, Jun; Xiang, Shouxing; Liu, Shixia, Tsinghua Univ, BNRist, Beijing, Peoples R China. Xia, Jiazhi, Cent South Univ, Changsha, Peoples R China. Yu, Lingyun, Xian Jiaotong Liverpool Univ, Suzhou, Peoples R China.", "countries": "China", "abstract": "Given a scatterplot with tens of thousands of points or even more, a natural question is which sampling method should be used to create a small but \u201cgood\u201d scatterplot for a better abstraction. We present the results of a user study that investigates the influence of different sampling strategies on multi-class scatterplots. The main goal of this study is to understand the capability of sampling methods in preserving the density, outliers, and overall shape of a scatterplot. To this end, we comprehensively review the literature and select seven typical sampling strategies as well as eight representative datasets. We then design four experiments to understand the performance of different strategies in maintaining: 1) region density; 2) class density; 3) outliers; and 4) overall shape in the sampling results. The results show that: 1) random sampling is preferred for preserving region density; 2) blue noise sampling and random sampling have comparable performance with the three multi-class sampling strategies in preserving class density; 3) outlier biased density based sampling, recursive subdivision based sampling, and blue noise sampling perform the best in keeping outliers; and 4) blue noise sampling outperforms the others in maintaining the overall shape of a scatterplot.", "keywords": "Scatterplot,data sampling,empirical evaluation", "link": "http://dx.doi.org/10.1109/TVCG.2020.3030432", "refList": ["10.1057/palgrave.ivs.9500122", "10.1109/tvcg.2016.2598867", "10.1109/tvcg.2015.2467591", "10.1111/cgf.13708", "10.1109/tvcg.2019.2934799", "10.1109/tvcg.2019.2934541", "10.1109/tvcg.2013.65", "10.1109/iv.2004.1320207", "10.1068/p260471", "10.1145/1778765.1778816", "10.1109/tvcg.2018.2808489", "10.1109/tvcg.2018.2864912", "10.1016/j.apgeog.2015.12.006", "10.1111/j.1467-8659.2011.01960.x", "10.1109/tvcg.2018.2864843", "10.1109/pacificvis.2010.5429604", "10.1109/tvcg.2014.2346898", "10.1109/5.726791", "10.1177/1475090214540874", "10.1145/1556262.1556289", "10.1109/tvcg.2007.70535", "10.1109/vast.2012.6400489", "10.1145/1056808.1056914", "10.1016/j.neucom.2014.09.063", "10.1145/7529.8927", "10.1109/tvcg.2016.2607204", "10.1109/vast47406.2019.8986943", "10.3758/bf03205986", "10.1109/infvis.2005.1532142", "10.1145/1150402.1150479", "10.1109/tvcg.2017.2674978", "10.1109/tvcg.2017.2744098", "10.1109/tvcg.2017.2674999", "10.1109/tvcg.2011.279", "10.1109/tvcg.2014.2346594", "10.1109/tvcg.2017.2744184", "10.1111/cgf.12876", "10.1109/1011101.2019.2945960", "10.1007/s4095-020-0191-7", "10.1007/s11390-015-1535-0", "10.1111/cgf.12640", "10.1109/tvcg.2016.2598667", "10.1111/cgf.13683", "10.1109/tvcg.2013.153", "10.1109/tvcg.2019.2934208", "10.1109/tvcg.2019.2934655", "10.1111/cgf.12655", "10.1007/s11023-010-9221-z", "10.1109/vast.2012.6400487", "10.1145/2702123.2702585", "10.1007/bf00310175", "10.1109/tvcg.2017.2744378", "10.1103/physreve.64.061907", "10.1109/ldav.2017.8231848", "10.1109/tvcg.2016.2598831"], "wos": 1, "children": [], "len": 1}, {"doi": "10.1111/cgf.13417", "year": "2018", "title": "Interactive Analysis of Word Vector Embeddings", "conferenceName": "EuroVis", "authors": "Florian Heimerl;Michael Gleicher", "citationCount": "6", "affiliation": "Heimerl, F (Corresponding Author), Univ Wisconsin Madison, Dept Comp Sci, Madison, WI 53706 USA.\nHeimerl, F.; Gleicher, M., Univ Wisconsin Madison, Dept Comp Sci, Madison, WI 53706 USA.", "countries": "USA", "abstract": "Word vector embeddings are an emerging tool for natural language processing. They have proven beneficial for a wide variety of language processing tasks. Their utility stems from the ability to encode word relationships within the vector space. Applications range from components in natural language processing systems to tools for linguistic analysis in the study of language and literature. In many of these applications, interpreting embeddings and understanding the encoded grammatical and semantic relations between words is useful, but challenging. Visualization can aid in such interpretation of embeddings. In this paper, we examine the role for visualization in working with word vector embeddings. We provide a literature survey to catalogue the range of tasks where the embeddings are employed across a broad range of applications. Based on this survey, we identify key tasks and their characteristics. Then, we present visual interactive designs that address many of these tasks. The designs integrate into an exploration and analysis environment for embeddings. Finally, we provide example use cases for them and discuss domain user feedback.", "keywords": "", "link": "https://doi.org/10.1111/cgf.13417", "refList": ["10.1109/vast.2014.7042493", "10.18653/v1/d16-1100", "10.1109/vast.2016.7883507", "10.1109/vast.2009.5333443", "10.1109/tvcg.2017.2744938", "10.1109/tvcg.2008.172", "10.3115/v1/w14-1618", "10.1109/tvcg.2009.165", "10.1145/365628.365657", "10.1109/vl.1996.545307", "10.1089/big.2016.0007", "10.1109/tvcg.2013.212", "10.1186/s12859-015-0564-6", "10.1111/j.1467-8659.2009.01439.x", "10.1109/jcdl.2014.6970173", "10.1109/tvcg.2016.2515592", "10.1162/tacl\\_a\\_00106", "10.1109/tvcg.2013.157", "10.1109/tvcg.2015.2467615", "10.1145/166117.166126", "10.1109/tvcg.2017.2745141", "10.18653/v1/w17-1003", "10.18653/v1/d15-1036", "10.1145/302979.303148", "10.1109/tvcg.2015.2467618", "10.1162/jmlr.2003.3.4-5.951", "10.1109/tvcg.2012.277", "10.1057/palgrave.ivs.9500180", "10.1109/tvcg.2017.2744878", "10.18653/v1/w16-2507", "10.1109/tvcg.2012.213", "10.1109/tvcg.2016.2598667", "10.3115/v1/d14-1162", "10.1109/tvcg.2017.2785807", "10.1109/tvcg.2013.120", "10.1145/2858036.2858535", "10.1109/tvcg.2016.2598831", "10.1109/vast.2011.6102453"], "wos": 1, "children": [{"doi": "10.1111/cgf.13681", "year": "2019", "title": "A User-based Visual Analytics Workflow for Exploratory Model Analysis", "conferenceName": "EuroVis", "authors": "Dylan Cashman;Shah Rukh Humayoun;Florian Heimerl;Kendall Park;Subhajit Das;John Thompson;Bahador Saket;Abigail Mosca;John T. Stasko;Alex Endert;Michael Gleicher;Remco Chang", "citationCount": "6", "affiliation": "Cashman, D; Humayoun, SR (Corresponding Author), Tufts Univ, Medford, MA 02155 USA.\nCashman, Dylan; Humayoun, Shah Rukh; Mosca, Abigail; Chang, Remco, Tufts Univ, Medford, MA 02155 USA.\nHeimerl, Florian; Park, Kendall; Gleicher, Michael, Georgia Tech, Atlanta, GA USA.\nDas, Subhajit; Thompson, John; Saket, Bahador; Stasko, John; Endert, Alex, Univ Wisconsin, Madison, WI USA.", "countries": "USA", "abstract": "Many visual analytics systems allow users to interact with machine learning models towards the goals of data exploration and insight generation on a given dataset. However, in some situations, insights may be less important than the production of an accurate predictive model for future use. In that case, users are more interested in generating of diverse and robust predictive models, verifying their performance on holdout data, and selecting the most suitable model for their usage scenario. In this paper, we consider the concept of Exploratory Model Analysis (EMA), which is defined as the process of discovering and selecting relevant models that can be used to make predictions on a data source. We delineate the differences between EMA and the well-known term exploratory data analysis in terms of the desired outcome of the analytic process: insights into the data or a set of deployable models. The contributions of this work are a visual analytics system workflow for EMA, a user study, and two use cases validating the effectiveness of the workflow. We found that our system workflow enabled users to generate complex models, to assess them for various qualities, and to select the most relevant model for their task.", "keywords": "", "link": "https://doi.org/10.1111/cgf.13681", "refList": ["10.1109/tvcg.2017.2744683", "10.1111/cgf.12639", "10.1007/s11390-016-1663-1", "10.1109/tvcg.2017.2744938", "10.1117/12.2007316", "10.1109/tvcg.2017.2745178", "10.1145/2702123.2702509", "10.1080/02701367.1992.10608764", "10.1109/tvcg.2016.2598828", "10.1109/tvcg.2011.185", "10.1088/1749-4699/8/1/014008", "10.1109/tvcg.2013.125", "10.1109/mcse.2007.55", "10.1007/978-3-540-70956-5", "10.1109/vl.1996.545307", "10.1901/jeab.1979.31-433", "10.1111/j.1467-8659.2009.01475.x", "10.1016/j.visinf.2017.01.006", "10.1109/tvcg.2012.65", "10.1145/1835804.1835827", "10.1109/tvcg.2017.2745085", "10.1145/2939672.2939778", "10.1109/tvcg.2017.2745158", "10.1109/tvcg.2017.2744805", "10.1145/2487575.2487629", "10.1109/tvcg.2013.157", "10.1109/tvcg.2015.2467551", "10.1109/tvcg.2017.2744199", "10.1109/tvcg.2014.2346481", "10.1109/tvcg.2011.209", "10.1109/vast.2012.6400490", "10.1109/tvcg.2015.2513410", "10.1007/978-3-540-79347-2\\_3", "10.1109/tvcg.2014.2346431", "10.1109/tvcg.2018.2864477", "10.1109/tvcg.2012.277", "10.1109/infvis.1998.729560", "10.1109/infvis.2004.64", "10.1109/mcg.2006.70", "10.1109/tvcg.2012.260", "10.1109/tvcg.2014.2346660", "10.1145/1743546.1743567", "10.1111/cgf.13417", "10.1109/tvcg.2014.2346325", "10.1109/tvcg.2018.2864838", "10.1109/tvcg.2017.2744158", "10.1109/tvcg.2003.1207445", "10.1109/vast.2010.5652443", "10.1145/2641190.2641198", "10.1109/tvcg.2016.2598830", "10.1109/tvcg.2017.2744378", "10.1111/cgf.13324", "10.1109/mcg.2009.22", "10.1109/tvcg.2016.2599030", "10.1109/vast.2012.6400486", "10.1109/tvcg.2016.2598831", "10.1109/vast.2011.6102453"], "wos": 1, "children": [{"doi": "10.1109/tvcg.2019.2934261", "title": "Ablate, Variate, and Contemplate: Visual Analytics for Discovering Neural Architectures", "year": "2019", "conferenceName": "VAST", "authors": "Dylan Cashman;Adam Perer;Remco Chang;Hendrik Strobelt", "citationCount": "1", "affiliation": "Cashman, D (Corresponding Author), Tufts Univ, Medford, MA 02155 USA. Cashman, Dylan; Chang, Remco, Tufts Univ, Medford, MA 02155 USA. Perer, Adam, Carnegie Mellon Univ, Pittsburgh, PA 15213 USA. Strobelt, Hendrik, MIT IBM Watson AI Lab, Cambridge, MA USA.", "countries": "USA", "abstract": "The performance of deep learning models is dependent on the precise configuration of many layers and parameters. However, there are currently few systematic guidelines for how to configure a successful model. This means model builders often have to experiment with different configurations by manually programming different architectures (which is tedious and time consuming) or rely on purely automated approaches to generate and train the architectures (which is expensive). In this paper, we present Rapid Exploration of Model Architectures and Parameters, or REMAP, a visual analytics tool that allows a model builder to discover a deep learning model quickly via exploration and rapid experimentation of neural network architectures. In REMAP, the user explores the large and complex parameter space for neural network architectures using a combination of global inspection and local experimentation. Through a visual overview of a set of models, the user identifies interesting clusters of architectures. Based on their findings, the user can run ablation and variation experiments to identify the effects of adding, removing, or replacing layers in a given architecture and generate new models accordingly. They can also handcraft new models using a simple graphical interface. As a result, a model builder can build deep learning models quickly, efficiently, and without manual programming. We inform the design of REMAP through a design study with four deep learning model builders. Through a use case, we demonstrate that REMAP allows users to discover performant neural network architectures efficiently using visual exploration and user-defined semi-automated searches through the model space.", "keywords": "visual analytics,neural networks,parameter space exploration", "link": "http://dx.doi.org/10.1109/TVCG.2019.2934261", "refList": ["10.1109/mcg.2018.2878902", "10.1111/cgf.12639", "10.1109/tvcg.2017.2744938", "10.1117/12.2007316", "10.1109/cvpr.2014.81", "10.1016/j.csda.2008.02.031", "10.1080/00994480.2000.10748487", "10.1088/1749-4699/8/1/014008", "10.1109/tvcg.2013.125", "10.1109/cvpr.2015.7298594", "10.1111/j.1467-8659.2009.01475.x", "10.1109/tvcg.2012.65", "10.1109/tvcg.2017.2745085", "10.1109/tvcg.2017.2745158", "10.1109/tvcg.2017.2744805", "10.1145/2487575.2487629", "10.1109/tvcg.2018.2865044", "10.23915/distill.00010", "10.1109/72.279181", "10.1109/tvcg.2017.2744199", "10.1007/s13398-014-0173-7.2", "10.1109/tvcg.2018.2864504", "10.1109/vast.2012.6400490", "10.1007/978-3-319-10590-1\\_53", "10.1109/tvcg.2018.2864477", "10.1109/tvcg.2014.2346321", "10.1094/pdis-11-11-0999-pdn", "10.1109/ijcnn.2015.7280767", "10.1109/tvcg.2017.2744878", "10.5555/3326943.3327130", "10.1109/tvcg.2017.2744718", "10.1109/iccv.2015.169", "10.1109/tvcg.2018.2864500", "10.1109/tvcg.2017.2744158", "10.1109/cvpr.2014.223", "10.1109/cvpr.2016.90", "10.1109/vast.2010.5652443", "10.1111/cgf.13681", "10.1109/tvcg.2016.2598831", "10.1109/vast.2011.6102453"], "wos": 1, "children": [{"doi": "10.1109/tvcg.2020.3028888", "title": "A Visual Analytics Framework for Explaining and Diagnosing Transfer Learning Processes", "year": "2020", "conferenceName": "VAST", "authors": "Yuxin Ma;Arlen Fan;Jingrui He;Arun Reddy Nelakurthi;Ross Maciejewski", "citationCount": "0", "affiliation": "Ma, YX (Corresponding Author), Arizona State Univ, Tempe, AZ 85287 USA. Ma, Yuxin; Fan, Arlen; Maciejewski, Ross, Arizona State Univ, Tempe, AZ 85287 USA. He, Jingrui, Univ Illinois, Champaign, IL USA. Nelakurthi, Arun Reddy, Samsung Res Amer, Mountain View, CA USA.", "countries": "USA", "abstract": "Many statistical learning models hold an assumption that the training data and the future unlabeled data are drawn from the same distribution. However, this assumption is difficult to fulfill in real-world scenarios and creates barriers in reusing existing labels from similar application domains. Transfer Learning is intended to relax this assumption by modeling relationships between domains, and is often applied in deep learning applications to reduce the demand for labeled data and training time. Despite recent advances in exploring deep learning models with visual analytics tools, little work has explored the issue of explaining and diagnosing the knowledge transfer process between deep learning models. In this paper, we present a visual analytics framework for the multi-level exploration of the transfer learning processes when training deep neural networks. Our framework establishes a multi-aspect design to explain how the learned knowledge from the existing model is transferred into the new learning task when training deep neural networks. Based on a comprehensive requirement and task analysis, we employ descriptive visualization with performance measures and detailed inspections of model behaviors from the statistical, instance, feature, and model structure levels. We demonstrate our framework through two case studies on image classification by fine-tuning AlexNets to illustrate how analysts can utilize our framework.", "keywords": "Transfer learning,deep learning,visual analytics", "link": "http://dx.doi.org/10.1109/TVCG.2020.3028888", "refList": ["10.1109/tvcg.2014.2346578", "10.1109/tvcg.2019.2934629", "10.1109/tvcg.2017.2744683", "10.1109/tvcg.2016.2598838", "10.1109/tvcg.2017.2744938", "10.1109/tvcg.2019.2934262", "10.1109/tpami.2018.2868685", "10.1145/2702123.2702509", "10.1109/vast.2017.8585721", "10.1109/tvcg.2018.2843369", "10.1109/tvcg.2016.2598828", "10.1111/j.1467-8659.2011.01898.x", "10.1109/tvcg.2013.65", "10.1145/2976749.2978318", "10.1007/978-3-030-01424-7\\_27", "10.1109/tvcg.2019.2934261", "10.1007/s11704-016-6028-y", "10.1016/j.visinf.2017.01.006", "10.1145/2858036.2858529", "10.1109/iccv.2015.279", "10.1109/mci.2018.2840738", "10.1109/tvcg.2019.2892483", "10.1109/vast.2018.8802509", "10.1109/tvcg.2013.124", "10.1186/s40537-016-0043-6", "10.1109/tvcg.2018.2864475", "10.1145/3200489", "10.1109/tvcg.2018.2865044", "10.1111/cgf.13210", "10.1109/tvcg.2018.2816223", "10.23915/distill.00007", "10.1109/tvcg.2017.2744199", "10.1109/tkde.2018.2876857", "10.1109/tvcg.2019.2934631", "10.1109/tvcg.2018.2864504", "10.1109/tvcg.2014.2346482", "10.1109/tvcg.2015.2467618", "10.1109/tvcg.2014.2346594", "10.1109/tvcg.2011.188", "10.1007/978-3-642-15561-1\\_16", "10.1109/tvcg.2018.2864812", "10.1109/mcg.2019.2919033", "10.1109/tvcg.2017.2744718", "10.1109/tvcg.2017.2744878", "10.1109/tvcg.2016.2598541", "10.1109/tkde.2009.191", "10.1145/3065386", "10.1016/j.ins.2016.03.021", "10.1109/tvcg.2019.2903943", "10.1007/s10994-009-5152-4", "10.1109/tvcg.2019.2934659", "10.1109/tvcg.2018.2864500", "10.1109/iccv.2017.74", "10.1109/tvcg.2017.2744158", "10.1109/tvcg.2012.207", "10.1111/cgf.13092", "10.1109/tvcg.2018.2865027", "10.1109/tvcg.2017.2744378", "10.1109/tvcg.2017.2744358", "10.1109/tvcg.2019.2934619", "10.1109/tvcg.2018.2864499", "10.1109/tvcg.2017.2754480", "10.1109/tvcg.2016.2598831"], "wos": 1, "children": [], "len": 1}, {"doi": "10.1111/cgf.14034", "year": "2020", "title": "The State of the Art in Enhancing Trust in Machine Learning Models with the Use of Visualizations", "conferenceName": "EuroVis", "authors": "Angelos Chatzimparmpas;Rafael Messias Martins;Ilir Jusufi;Kostiantyn Kucher;Fabrice Rossi;Andreas Kerren", "citationCount": "2", "affiliation": "Chatzimparmpas, A (Corresponding Author), Linnaeus Univ, Dept Comp Sci \\& Media Technol, Vaxjo, Sweden.\nChatzimparmpas, A.; Martins, R. M.; Jusufi, I.; Kucher, K.; Kerren, A., Linnaeus Univ, Dept Comp Sci \\& Media Technol, Vaxjo, Sweden.\nRossi, F., PSL Univ, Univ Paris Dauphine, Ceremade, Paris, France.", "countries": "Sweden;France", "abstract": "Machine learning (ML) models are nowadays used in complex applications in various domains, such as medicine, bioinformatics, and other sciences. Due to their black box nature, however, it may sometimes be hard to understand and trust the results they provide. This has increased the demand for reliable visualization tools related to enhancing trust in ML models, which has become a prominent topic of research in the visualization community over the past decades. To provide an overview and present the frontiers of current research on the topic, we present a State-of-the-Art Report (STAR) on enhancing trust in ML models with the use of interactive visualization. We define and describe the background of the topic, introduce a categorization for visualization techniques that aim to accomplish this goal, and discuss insights and opportunities for future research directions. Among our contributions is a categorization of trust against different facets of interactive ML, expanded and improved from previous research. Our results are investigated from different analytical perspectives: (a) providing a statistical overview, (b) summarizing key findings, (c) performing topic analyses, and (d) exploring the data sets used in the individual papers, all with the support of an interactive web-based survey browser. We intend this survey to be beneficial for visualization researchers whose interests involve making ML models more trustworthy, as well as researchers and practitioners from other disciplines in their search for effective visualization techniques suitable for solving their tasks with confidence and conveying meaning to their data.", "keywords": "trustworthy machine learning; visualization; interpretable machine learning; explainable machine learning", "link": "https://doi.org/10.1111/cgf.14034", "refList": ["10.1109/mcg.2018.2878902", "10.1109/tvcg.2008.153", "10.2312/mlvis.20181130", "10.1109/tvcg.2016.2598828", "10.1145/3290605.3300911", "10.1145/2993901.2993909", "10.2312/mlvis.20191158", "10.1109/tvcg.2016.2598446", "10.1111/j.1467-8659.2009.01475.x", "10.1145/3290605.3300809", "10.1109/pacificvis.2018.00031", "10.1055/s-0029-1216348", "10.1007/978-3-319-90403-0\\_13", "10.1109/tvcg.2017.2745085", "10.1111/j.1467-8659.2011.01938.x", "10.1007/978-3-319-54024-5\\_6", "10.1016/s0167-9473(01)00065-2", "10.1111/cgf.12895", "10.2312/eurovisshort.20141152.17", "10.2312/eurova.20151098.22", "10.1111/cgf.13667", "10.3115/1072228.1072378", "10.1109/tbdata.2018.2877350.16", "10.1109/lars.2009.5418323.25", "10.1109/tvcg.2017.2744878", "10.1016/j.combustflame.2005.09.018", "10.1016/j.cag.2014.01.006", "10.1109/tvcg.2016.2570755", "10.2312/mlvis.20191158.1,19", "10.1518/hfes.46.1.50.30392", "10.1145/3301275.3302280", "10.1145/3351095.3372834.1", "10.1016/s0377-2217(01)00264-8", "10.1111/cgf.13424", "10.1007/978-3-319-23485-4\\_53", "10.1007/978-94-007-0753-5\\_3623", "10.1109/tvcg.2013.101", "10.1111/cgf.12884", "10.1111/j.1467-8659.2010.01835.x", "10.1021/ci9901338", "10.4230/lipics.itcs:2017", "10.1109/mis.2013.24", "10.1109/tvcg.2014.2346482", "10.1109/tvcg.2018.2865230", "10.1073/pnas.1807180116", "10.1109/dsaa.2018.00018", "10.1109/tvcg.2009.153", "10.3115/1219840.1219855", "10.1109/tvcg.2018.2864812", "10.1109/tvcg.2018.2872577", "10.2312/trvis.20191183", "10.1109/cvpr:2004.383", "10.1109/vast.2008.4677350", "10.1145/302979.303001", "10.1109/tvcg.2018.2864499", "10.1111/cgf.13672", "10.1109/tvcg.2014.2346626", "10.23915/distill.00010.18", "10.1109/tvcg.2017.2744805", "10.2312/mlvis:20191160.18", "10.23915/distill:00016", "10.1109/pacificvis.2016.7465260", "10.1111/cgf.13683", "10.23915/distill.00016.19", "10.1145/32906053.300803.22", "10.1109/tvcg.2014.2346574", "10.1177/1473871615600010", "10.1109/tvcg.2016.2598831", "10.1145/3230623", "10.1109/visual.2019.8933744", "10.1145/2993901.2993915", "10.1016/j.visinf.2017.01.006", "10.1145/2993901.2993914", "10.1109/tvcg.2014.2346984", "10.1109/5.726791", "10.23915/distill.00010", "10.1109/tvcg.2018.2864825", "10.2307/2394164", "10.1109/tvcg.2017.2744458", "10.1145/2993901.2993917.28", "10.1111/cgf.13711", "10.1109/tvcg.2016.2598664", "10.2307/2530428", "10.1109/icdar.1997.620583", "10.1109/tvcg.2017.2744718", "10.1111/cgf.13425", "10.1109/tvcg.2019.2903943", "10.1145/1518701.1518895", "10.1109/tvcg.2018.2864838", "10.1145/62038.62043", "10.1111/j.1467-8659.2011.01920.x", "10.1145/3025171.3025208", "10.1145/355112.355124", "10.1109/vast.2010.5652398", "10.1109/tvcg.2014.2346578", "10.1145/3173574.3174209", "10.4178/epih/e2014008", "10.1109/beliv.2018.8634201.25,28", "10.1016/j.eswa.2007.12.020", "10.1111/cgf:13406", "10.1109/mcg.2011.103", "10.1631/fitee.1700808", "10.1109/tvcg.2017.2745158", "10.1073/pnas.0307752101", "10.1109/tvcg.2018.2816223", "10.1109/tvcg.2017.2745141", "10.1145/32232.32234", "10.1109/tvcg.2019.2934267", "10.1109/tvcg.2018.2864477", "10.1145/3132169", "10.2312/eurova.20151100.19", "10.1145/3172944.3172964", "10.1145/2601248.2601268", "10.1109/isai-nlp.2018.8693002.1", "10.1111/cgf.13404", "10.1007/s100320200071", "10.2312/trvis.20191183.16", "10.1111/cgf.12755", "10.1145/2702123.2702509", "10.1145/1401890.1402008.25", "10.1109/tvcg.2012.65", "10.1177/1473871617733996", "10.2312/trvis.20191187.7", "10.21236/ada273556", "10.1109/vast.2010.5652450", "10.1111/j.1467-8659.2011.01940.x", "10.1177/875647939000600106", "10.1109/tvcg.2017.2711030", "10.1016/j.immuni.2016.04.014", "10.1109/tvcg.2019.2934209", "10.1016/0095-0696(78)90006-2", "10.1016/j.jclinepi.2015.04.014", "10.1016/j.ress.2013.02.013", "10.1111/cgf.12640", "10.1145/1015330.1015388.25", "10.1111/j.1467-8659.2009.01468.x", "10.1145/1541880.1541882", "10.1109/vast.2011.6102453", "10.1016/s0008-8846(98)00165-3", "10.2312/trvis.20191186.7", "10.1007/s13748-013-0040-3", "10.1109/tvcg.2015.2467757", "10.1109/tbdata.2018.2877350", "10.1109/vast.2017.8585613", "10.1080/10556789208805504", "10.1109/vast.2012.6400484", "10.1145/3025171.3025181", "10.1007/978-3-319-90403-0\\_12", "10.1109/mcg.2019.2922592", "10.1021/ci000392t", "10.1109/vast.2007.4389000", "10.1111/cgf.13406.16", "10.1111/cgf.13684", "10.2312/eurovisshort.20161166.17", "10.2312/evs:20191168", "10.1145/3041021.3055135", "10.1145/3301275.3302265", "10.1613/jair.4135", "10.1109/tvcg.2018.2864500", "10.1109/tvcg.2017.2744158", "10.1109/ssci.2015.33", "10.1111/cgf.13453", "10.2312/pe/eurovast/eurova11/049-052", "10.1145/3025171.3025181.13", "10.1145/371920.372094", "10.1109/tvcg.2017.2744938", "10.1111/j.1467-8659.2012.03108.x", "10.1109/tvcg.2019.2934251", "10.1145/3290605.3300809.18", "10.1109/ldav.2016.7874305", "10.1109/vast.2016.7883514", "10.1109/iccv.2015.425", "10.1145/3301275.3302324", "10.1109/tnnls.2013.2292894", "10.1109/tvcg.2018.2865044", "10.1109/tvcg.2013.157", "10.1371/journal.pcbi.0020161", "10.1186/s12916-019-1426-2", "10.1109/10.867928", "10.1111/cgf.13217", "10.1109/mcg.2019.2919033", "10.1145/2993901.2993910", "10.1109/tvcg.2017.2744738", "10.2307/258792", "10.1111/cgf.12655", "10.1016/j.dss.2014.03.001", "10.1109/tvcg.2019.2904069", "10.1111/cgf.13205", "10.1002/mds.22340", "10.1109/tvcg.2019.2934595", "10.1287/inte.2018.0957", "10.1109/cvpr.2007.382974", "10.1109/tvcg.2012.280", "10.1145/2678025.2701399.13", "10.2312/mlvis.20181130.13", "10.2312/eurova.20181106.16", "10.1109/tvcg.2018.2864475", "10.2312/mlvis.20191160.18,22", "10.1007/978-1-4612-4026-6.25", "10.1109/cvpr.2006.42", "10.1145/3172944.3172950", "10.1109/cvpr.2004.383.25", "10.1109/tvcg.2019.2934812", "10.1609/aimag.v35i4.2513", "10.2312/trvis.20191185.7", "10.1111/j.1467-8659.2009.01684.x", "10.1371/journal.pone.0129126", "10.1111/cgf.13092", "10.1162/coli\\_a\\_00237", "10.1109/tvcg.2017.2744818", "10.1109/vast.2011.6102448", "10.1109/tvcg.2009.111", "10.1109/tvcg.2019.2934619", "10.1016/s0377-2217(01)00264-8.25", "10.1111/cgf.12639", "10.1109/access.2019.2919343", "10.1186/s12874-019-0681-4", "10.1109/pacificvis.2015.7156366", "10.1109/pacificvis.2018.00029", "10.1109/tvcg.2019.2934261", "10.1080/13506280444000102.http://www.uvt.nl/ticc", "10.1109/vast.2018.8802509", "10.1111/cgf.13212", "10.1145/3200489", "10.1111/cgf.13176", "10.1177/1473871620904671", "10.1007/978-3-319-10590-1\\_53", "10.1111/j.1467-8659.2012.03126.x", "10.1111/cgf.13172", "10.1145/3025171.3025208.6,21", "10.1111/cgf.12366", "10.1109/tvcg.2019.2934659", "10.1109/cvprw.2009.5206848", "10.1016/j.media.2014.11.010", "10.1109/tvcg.2017.2744683", "10.1109/tvcg.2019.2934262", "10.1016/j.neucom.2006.11.018", "10.1177/1473871615571951", "10.1371/journal.pcbi.0020161.25", "10.1177/1473871611415994", "10.2312/trvis20191187", "10.2312/eurova", "10.1145/2858036.2858529", "10.1145/2207676.2207738", "10.1007/s11042-009-0417-2", "10.1145/3301275.3302317", "10.1038/s41746-019-0148-3", "10.1145/3351095.3372834", "10.1080/10691898.2011.11889627", "10.1109/tvcg.2018.2864504", "10.1109/vast.2017.8585720", "10.1109/mcg.2018.053491732", "10.1007/s10994-010-5207-6", "10.1109/tvcg.2019.2934433", "10.1016/j.cag.2017.05.005", "10.1109/tvcg.2012.279", "10.1145/3231622.3231641.19,20", "10.1145/1562849.1562851", "10.1007/11564126\\_", "10.1109/tvcg.2018.2846735", "10.3115/1225403.1225421", "10.1109/vast.2012.6400486", "10.2312/eurova.20191116.22", "10.1109/tvcg.2007.70443", "10.1080/027868291009242", "10.2312/eurova.20151100", "10.1145/2939502.2939503.19", "10.1016/j.cag.2014.02.004", "10.1145/2939672.2939778", "10.1109/vast.2010.5652484", "10.1111/cgf.12641", "10.1145/3301275.3302289", "10.1109/visual.2019.8933619", "10.1109/tvcg.2017.2672987", "10.1109/vast.2016.7883517.20", "10.1109/igarss.2017.8127684", "10.1016/j.jcae.2010.04.002", "10.1109/vast.2010.5652885", "10.1016/j.visinf.2019.03.002", "10.1007/s00371-018-1500-3", "10.1109/mcg.2018.042731661", "10.1109/34.598228", "10.1109/tvcg.2018.2865027", "10.1016/j.neucom.2017.01.105", "10.1111/cgf.12389", "10.1109/tvcg.2019.2934591", "10.1109/vast.2010.5652392.16", "10.1111/cgf.13416", "10.1080/02701367.1992.10608764", "10.1109/vast.2017.8585721", "10.1109/tvcg.2018.2843369", "10.1109/sbes.2010.27", "10.1109/vast.2015.7347637", "10.1145/1401890.1402008", "10.1016/j.bpj.2010.04.064", "10.1109/tvcg.2013.125", "10.1109/isai-nlp.2018.8693002", "10.1371/journal.pone.0160127", "10.1145/2856767.2856779", "10.1145/2678025.2701399", "10.1109/vast.2011.6102451", "10.1109/mcg.2010.18", "10.1021/ci4000213", "10.1109/vast.2012.6400492", "10.1007/11564126-49.25", "10.2312/eurova.20171114", "10.1109/vast.2010.5652443", "10.1145/3134599", "10.2312/pe/eurovast/eurovast10/013-018.19", "10.1109/tvcg.2019.2903946", "10.1109/tvcg.2015.2467717", "10.1177/1473871612460526", "10.1016/j.cag.2018.09.018", "10.1109/tvcg.2016.2598838", "10.1145/3172944.3172964.14", "10.1109/vast.2009.5333428", "10.1109/vast.2014.7042480", "10.2312/pe/eurovast/eurovast10/013-018", "10.1177/0962280215588241", "10.1145/2993901.2993917", "10.1109/cvpr.2008:4587581", "10.1109/tvcg.2015.2467551", "10.1016/j.visinf.2018.09.001", "10.1126/science.290.5500.2319", "10.2312/eurova.20151107", "10.1109/visual.2019.8933695", "10.13140/2.1.2393.1847", "10.1197/jamia.m1929", "10.1109/cvpr.2008.4587581.25", "10.1145/1518701.1518895.16", "10.1109/vds.2017.8573444", "10.2312/trvis:20191185", "10.1145/3359786", "10.13140/2.1.1341.1520", "10.2312/pe/eurovast/eurova11/049-052.17", "10.1109/tvcg.2014.2346660", "10.1145/3185517", "10.1109/adprl.2011.5967372", "10.1109/tvcg.2015.2467591", "10.1111/j.1751-9004.2009.00232.x", "10.1136/qshc.2004.010033", "10.1109/vast.2012.6400493", "10.1109/tvcg.2019.2934266", "10.1145/2971763.2971775", "10.1111/cgf.13730", "10.1109/vast.2012.6400488", "10.1111/cgf.13210", "10.1109/tvcg.2019.2934631", "10.1145/3172944.3172965", "10.1057/ivs.2010.2", "10.1109/tvcg.2017.2745258", "10.1016/j.jbusres.2019.07.039", "10.1162/jmlr.2003.3.4-5.993", "10.1109/pacificvis.2019.00044", "10.2312/pe/eurovast/eurova12/037-041", "10.1109/tvcg.2019.2934629", "10.1177/0018720814547570", "10.1145/3292500.3330908", "10.1111/j.1467-8659.2009.01467.x", "10.2312/eurova.20151098", "10.1177/1473871617713337", "10.1109/lars:2009.5418323", "10.1109/vast.2011.6102437", "10.1111/cgf.12878", "10.1561/1500000001", "10.1145/3025171.3025222", "10.1007/s11704-016-6028-y", "10.1016/j.procs.2017.05.216", "10.1109/cvpr.2007.382974.25", "10.1080/10447318.2020.1741118", "10.1109/vast.2012.6400489", "10.1145/3025171.3025172", "10.1109/tvcg.2017.2744098", "10.1109/tvcg.2005.66", "10.1016/j.dss.2009.05.016", "10.1007/978-1-4612-4026-6", "10.2312/evs.20191168.16,20,28", "10.2312/pe/eurovast/eurova12/037-041.17", "10.1145/3290605.3300803", "10.1145/1015330.1015388", "10.1111/cgf.13197", "10.1016/b978-1-55860-377-6.50048-7", "10.1111/cgf.13681", "10.1109/tvcg.2017.2744378", "10.1109/tvcg.2017.2744358", "10.1109/vast.2008.4677352"], "wos": 1, "children": [{"doi": "10.1109/tvcg.2020.3030368", "title": "Implicit Multidimensional Projection of Local Subspaces", "year": "2020", "conferenceName": "InfoVis", "authors": "Rongzheng Bian;Yumeng Xue;Liang Zhou;Jian Zhang 0070;Baoquan Chen;Daniel Weiskopf;Yunhai Wang", "citationCount": "1", "affiliation": "Wang, YH (Corresponding Author), Shandong Univ, Qingdao, Peoples R China. Zhou, L (Corresponding Author), Univ Utah, Salt Lake City, UT 84112 USA. Bian, Rongzheng; Xue, Yumeng; Wang, Yunhai, Shandong Univ, Qingdao, Peoples R China. Chen, Baoquan, Peking Univ, Beijing, Peoples R China. Zhang, Jian, Chinese Acad Sci, CNIC, Beijing, Peoples R China. Zhou, Liang, Univ Utah, Salt Lake City, UT 84112 USA. Weiskopf, Daniel, Univ Stuttgart, Stuttgart, Germany.", "countries": "USA;Germany;China", "abstract": "We propose a visualization method to understand the effect of multidimensional projection on local subspaces, using implicit function differentiation. Here, we understand the local subspace as the multidimensional local neighborhood of data points. Existing methods focus on the projection of multidimensional data points, and the neighborhood information is ignored. Our method is able to analyze the shape and directional information of the local subspace to gain more insights into the global structure of the data through the perception of local structures. Local subspaces are fitted by multidimensional ellipses that are spanned by basis vectors. An accurate and efficient vector transformation method is proposed based on analytical differentiation of multidimensional projections formulated as implicit functions. The results are visualized as glyphs and analyzed using a full set of specifically-designed interactions supported in our efficient web-based visualization tool. The usefulness of our method is demonstrated using various multi- and high-dimensional benchmark datasets. Our implicit differentiation vector transformation is evaluated through numerical comparisons; the overall method is evaluated through exploration examples and use cases.", "keywords": "High-dimensional data visualization,dimensionality reduction,local linear subspaces,user interaction", "link": "http://dx.doi.org/10.1109/TVCG.2020.3030368", "refList": ["10.3844/jcssp.2018.613.622", "10.1016/j.aci.2018.08.003", "10.3390/info9030065", "10.1016/j.visinf.2018.09.003", "10.1371/journal.pone.0118432", "10.1016/s0893-6080(05)80023-1", "10.1109/tvcg.2020.2986996", "10.1109/icst.2012.56", "10.1007/s10844-013-0250-y", "10.1109/tbdata.2018", "10.1145/1125451.1125659", "10.1109/tvcg.2013.125", "10.1177/1473871611412817", "10.1145/3290605.3300911", "10.1111/cgf.14034", "10.1007/s13721-013-0034-x", "10.1016/j.procs.2017.05.216", "10.1016/j.ins.2009.08.025", "10.1109/tvcg.2013.124", "10.1109/tvcg.2018.2864499", "10.1109/tvcg.2018.2864475", "10.1080/10447318.2020.1741118", "10.1016/j.imu.2019.100203", "10.1109/tvcg.2018.2865240", "10.1186/s12864-019-6413-7", "10.1109/tvcg.2015.2467551", "10.1002/widm.1249", "10.1007/978-3-319-66429-3\\_29", "10.1109/tvcg.2014.2346481", "10.1109/tvcg.2018.2864825", "10.1177/1473871620904671", "10.1109/tvcg.2019.2934267", "10.1136/bmjopen-2016-012799", "10.1109/smartgridcomm.2017.8340682", "10.1007/s10664-015-9401-9", "10.1145/1143844.1143874", "10.1111/cgf.12389", "10.1109/tvcg.2018.2872577", "10.1007/978-981-13-5802-9\\_20", "10.1016/j.ipm.2009.03.002", "10.5220/0006431602160222", "10.1109/mcg.2015.50", "10.1109/tvcg.2014.2346574", "10.1007/bf02289565", "10.1109/tvcg.2017.2744378", "10.1016/j.patrec.2008.08.010", "10.1023/a:1010933404324", "10.9735/2229-3981"], "wos": 1, "children": [], "len": 1}, {"doi": "10.1109/tvcg.2020.3030465", "title": "Visual Causality Analysis of Event Sequence Data", "year": "2020", "conferenceName": "VAST", "authors": "Zhuochen Jin;Shunan Guo;Nan Chen;Daniel Weiskopf;David Gotz;Nan Cao", "citationCount": "0", "affiliation": "Cao, N (Corresponding Author), Tongji Univ, IDVx Lab, Shanghai, Peoples R China. Jin, Zhuochen; Guo, Shunan; Chen, Nan; Cao, Nan, Tongji Univ, IDVx Lab, Shanghai, Peoples R China. Weiskopf, Daniel, Univ Stuttgart, Stuttgart, Germany. Gotz, David, Univ N Carolina, Chapel Hill, NC 27515 USA.", "countries": "USA;Germany;China", "abstract": "Causality is crucial to understanding the mechanisms behind complex systems and making decisions that lead to intended outcomes. Event sequence data is widely collected from many real-world processes, such as electronic health records, web clickstreams, and financial transactions, which transmit a great deal of information reflecting the causal relations among event types. Unfortunately, recovering causalities from observational event sequences is challenging, as the heterogeneous and high-dimensional event variables are often connected to rather complex underlying event excitation mechanisms that are hard to infer from limited observations. Many existing automated causal analysis techniques suffer from poor explainability and fail to include an adequate amount of human knowledge. In this paper, we introduce a visual analytics method for recovering causalities in event sequence data. We extend the Granger causality analysis algorithm on Hawkes processes to incorporate user feedback into causal model refinement. The visualization system includes an interactive causal analysis framework that supports bottom-up causal exploration, iterative causal verification and refinement, and causal comparison through a set of novel visualizations and interactions. We report two forms of evaluation: a quantitative evaluation of the model improvements resulting from the user-feedback mechanism, and a qualitative evaluation through case studies in different application domains to demonstrate the usefulness of the system.", "keywords": "Event sequence data,causality analysis,visual analytics", "link": "http://dx.doi.org/10.1109/TVCG.2020.3030465", "refList": ["10.5555/1642718", "10.1109/tvcg.2018.2865022", "10.5555/2074094.2074151", "10.1109/tvcg.2016.2618797", "10.1073/pnas.1320645111", "10.1109/tvcg.2017.2744843", "10.1109/iv.2017.69", "10.1109/tvcg.2019.2934399", "10.1145/3172944.3173007", "10.5555/1795555", "10.1109/mcg.2005.102", "10.1145/381641.381653", "10.1162/153244301753344614", "10.1111/cgf.14034", "10.1111/cgf.13198", "10.1017/cbo9780511519857", "10.1007/s10462-016-9475-9", "10.1075/ssol.2.2.07bor", "10.1007/978-1-4614-3223-4\\_3", "10.1109/infvis.2003.1249025", "10.1007/978-94-007-6094-313", "10.1145/2858036.2858387", "10.1109/tvcg.2007.70528", "10.1109/tvcg.2017.2674958", "10.1147/sj.454.0801", "10.1109/tvcg.2013.119", "10.1145/3173574.3173711", "10.1016/j.erss.2017.06.034", "10.1109/visual.2019.8933695", "10.1007/s11665-016-2173-6", "10.1016/0377-0427(87)90125-7", "10.2307/3601125", "10.1016/b978-0-444-88738-2.50018-x", "10.1109/mcg.2006.70", "10.1109/tvcg.2018.2865145", "10.1017/s1351324997001502", "10.1109/tvcg.2010.179", "10.1214/aos/1176344552", "10.1109/mcg.2009.22", "10.1007/978-3-319-26633-6\\_13", "10.1080/10447318.2014.905422", "10.1016/j.visinf.2019.03.004", "10.1057/palgrave.ivs.9500074", "10.1007/978-1-4614-3223-4"], "wos": 1, "children": [], "len": 1}], "len": 5}], "len": 9}, {"doi": "10.1111/cgf.14034", "year": "2020", "title": "The State of the Art in Enhancing Trust in Machine Learning Models with the Use of Visualizations", "conferenceName": "EuroVis", "authors": "Angelos Chatzimparmpas;Rafael Messias Martins;Ilir Jusufi;Kostiantyn Kucher;Fabrice Rossi;Andreas Kerren", "citationCount": "2", "affiliation": "Chatzimparmpas, A (Corresponding Author), Linnaeus Univ, Dept Comp Sci \\& Media Technol, Vaxjo, Sweden.\nChatzimparmpas, A.; Martins, R. M.; Jusufi, I.; Kucher, K.; Kerren, A., Linnaeus Univ, Dept Comp Sci \\& Media Technol, Vaxjo, Sweden.\nRossi, F., PSL Univ, Univ Paris Dauphine, Ceremade, Paris, France.", "countries": "Sweden;France", "abstract": "Machine learning (ML) models are nowadays used in complex applications in various domains, such as medicine, bioinformatics, and other sciences. Due to their black box nature, however, it may sometimes be hard to understand and trust the results they provide. This has increased the demand for reliable visualization tools related to enhancing trust in ML models, which has become a prominent topic of research in the visualization community over the past decades. To provide an overview and present the frontiers of current research on the topic, we present a State-of-the-Art Report (STAR) on enhancing trust in ML models with the use of interactive visualization. We define and describe the background of the topic, introduce a categorization for visualization techniques that aim to accomplish this goal, and discuss insights and opportunities for future research directions. Among our contributions is a categorization of trust against different facets of interactive ML, expanded and improved from previous research. Our results are investigated from different analytical perspectives: (a) providing a statistical overview, (b) summarizing key findings, (c) performing topic analyses, and (d) exploring the data sets used in the individual papers, all with the support of an interactive web-based survey browser. We intend this survey to be beneficial for visualization researchers whose interests involve making ML models more trustworthy, as well as researchers and practitioners from other disciplines in their search for effective visualization techniques suitable for solving their tasks with confidence and conveying meaning to their data.", "keywords": "trustworthy machine learning; visualization; interpretable machine learning; explainable machine learning", "link": "https://doi.org/10.1111/cgf.14034", "refList": ["10.1109/mcg.2018.2878902", "10.1109/tvcg.2008.153", "10.2312/mlvis.20181130", "10.1109/tvcg.2016.2598828", "10.1145/3290605.3300911", "10.1145/2993901.2993909", "10.2312/mlvis.20191158", "10.1109/tvcg.2016.2598446", "10.1111/j.1467-8659.2009.01475.x", "10.1145/3290605.3300809", "10.1109/pacificvis.2018.00031", "10.1055/s-0029-1216348", "10.1007/978-3-319-90403-0\\_13", "10.1109/tvcg.2017.2745085", "10.1111/j.1467-8659.2011.01938.x", "10.1007/978-3-319-54024-5\\_6", "10.1016/s0167-9473(01)00065-2", "10.1111/cgf.12895", "10.2312/eurovisshort.20141152.17", "10.2312/eurova.20151098.22", "10.1111/cgf.13667", "10.3115/1072228.1072378", "10.1109/tbdata.2018.2877350.16", "10.1109/lars.2009.5418323.25", "10.1109/tvcg.2017.2744878", "10.1016/j.combustflame.2005.09.018", "10.1016/j.cag.2014.01.006", "10.1109/tvcg.2016.2570755", "10.2312/mlvis.20191158.1,19", "10.1518/hfes.46.1.50.30392", "10.1145/3301275.3302280", "10.1145/3351095.3372834.1", "10.1016/s0377-2217(01)00264-8", "10.1111/cgf.13424", "10.1007/978-3-319-23485-4\\_53", "10.1007/978-94-007-0753-5\\_3623", "10.1109/tvcg.2013.101", "10.1111/cgf.12884", "10.1111/j.1467-8659.2010.01835.x", "10.1021/ci9901338", "10.4230/lipics.itcs:2017", "10.1109/mis.2013.24", "10.1109/tvcg.2014.2346482", "10.1109/tvcg.2018.2865230", "10.1073/pnas.1807180116", "10.1109/dsaa.2018.00018", "10.1109/tvcg.2009.153", "10.3115/1219840.1219855", "10.1109/tvcg.2018.2864812", "10.1109/tvcg.2018.2872577", "10.2312/trvis.20191183", "10.1109/cvpr:2004.383", "10.1109/vast.2008.4677350", "10.1145/302979.303001", "10.1109/tvcg.2018.2864499", "10.1111/cgf.13672", "10.1109/tvcg.2014.2346626", "10.23915/distill.00010.18", "10.1109/tvcg.2017.2744805", "10.2312/mlvis:20191160.18", "10.23915/distill:00016", "10.1109/pacificvis.2016.7465260", "10.1111/cgf.13683", "10.23915/distill.00016.19", "10.1145/32906053.300803.22", "10.1109/tvcg.2014.2346574", "10.1177/1473871615600010", "10.1109/tvcg.2016.2598831", "10.1145/3230623", "10.1109/visual.2019.8933744", "10.1145/2993901.2993915", "10.1016/j.visinf.2017.01.006", "10.1145/2993901.2993914", "10.1109/tvcg.2014.2346984", "10.1109/5.726791", "10.23915/distill.00010", "10.1109/tvcg.2018.2864825", "10.2307/2394164", "10.1109/tvcg.2017.2744458", "10.1145/2993901.2993917.28", "10.1111/cgf.13711", "10.1109/tvcg.2016.2598664", "10.2307/2530428", "10.1109/icdar.1997.620583", "10.1109/tvcg.2017.2744718", "10.1111/cgf.13425", "10.1109/tvcg.2019.2903943", "10.1145/1518701.1518895", "10.1109/tvcg.2018.2864838", "10.1145/62038.62043", "10.1111/j.1467-8659.2011.01920.x", "10.1145/3025171.3025208", "10.1145/355112.355124", "10.1109/vast.2010.5652398", "10.1109/tvcg.2014.2346578", "10.1145/3173574.3174209", "10.4178/epih/e2014008", "10.1109/beliv.2018.8634201.25,28", "10.1016/j.eswa.2007.12.020", "10.1111/cgf:13406", "10.1109/mcg.2011.103", "10.1631/fitee.1700808", "10.1109/tvcg.2017.2745158", "10.1073/pnas.0307752101", "10.1109/tvcg.2018.2816223", "10.1109/tvcg.2017.2745141", "10.1145/32232.32234", "10.1109/tvcg.2019.2934267", "10.1109/tvcg.2018.2864477", "10.1145/3132169", "10.2312/eurova.20151100.19", "10.1145/3172944.3172964", "10.1145/2601248.2601268", "10.1109/isai-nlp.2018.8693002.1", "10.1111/cgf.13404", "10.1007/s100320200071", "10.2312/trvis.20191183.16", "10.1111/cgf.12755", "10.1145/2702123.2702509", "10.1145/1401890.1402008.25", "10.1109/tvcg.2012.65", "10.1177/1473871617733996", "10.2312/trvis.20191187.7", "10.21236/ada273556", "10.1109/vast.2010.5652450", "10.1111/j.1467-8659.2011.01940.x", "10.1177/875647939000600106", "10.1109/tvcg.2017.2711030", "10.1016/j.immuni.2016.04.014", "10.1109/tvcg.2019.2934209", "10.1016/0095-0696(78)90006-2", "10.1016/j.jclinepi.2015.04.014", "10.1016/j.ress.2013.02.013", "10.1111/cgf.12640", "10.1145/1015330.1015388.25", "10.1111/j.1467-8659.2009.01468.x", "10.1145/1541880.1541882", "10.1109/vast.2011.6102453", "10.1016/s0008-8846(98)00165-3", "10.2312/trvis.20191186.7", "10.1007/s13748-013-0040-3", "10.1109/tvcg.2015.2467757", "10.1109/tbdata.2018.2877350", "10.1109/vast.2017.8585613", "10.1080/10556789208805504", "10.1109/vast.2012.6400484", "10.1145/3025171.3025181", "10.1007/978-3-319-90403-0\\_12", "10.1109/mcg.2019.2922592", "10.1021/ci000392t", "10.1109/vast.2007.4389000", "10.1111/cgf.13406.16", "10.1111/cgf.13684", "10.2312/eurovisshort.20161166.17", "10.2312/evs:20191168", "10.1145/3041021.3055135", "10.1145/3301275.3302265", "10.1613/jair.4135", "10.1109/tvcg.2018.2864500", "10.1109/tvcg.2017.2744158", "10.1109/ssci.2015.33", "10.1111/cgf.13453", "10.2312/pe/eurovast/eurova11/049-052", "10.1145/3025171.3025181.13", "10.1145/371920.372094", "10.1109/tvcg.2017.2744938", "10.1111/j.1467-8659.2012.03108.x", "10.1109/tvcg.2019.2934251", "10.1145/3290605.3300809.18", "10.1109/ldav.2016.7874305", "10.1109/vast.2016.7883514", "10.1109/iccv.2015.425", "10.1145/3301275.3302324", "10.1109/tnnls.2013.2292894", "10.1109/tvcg.2018.2865044", "10.1109/tvcg.2013.157", "10.1371/journal.pcbi.0020161", "10.1186/s12916-019-1426-2", "10.1109/10.867928", "10.1111/cgf.13217", "10.1109/mcg.2019.2919033", "10.1145/2993901.2993910", "10.1109/tvcg.2017.2744738", "10.2307/258792", "10.1111/cgf.12655", "10.1016/j.dss.2014.03.001", "10.1109/tvcg.2019.2904069", "10.1111/cgf.13205", "10.1002/mds.22340", "10.1109/tvcg.2019.2934595", "10.1287/inte.2018.0957", "10.1109/cvpr.2007.382974", "10.1109/tvcg.2012.280", "10.1145/2678025.2701399.13", "10.2312/mlvis.20181130.13", "10.2312/eurova.20181106.16", "10.1109/tvcg.2018.2864475", "10.2312/mlvis.20191160.18,22", "10.1007/978-1-4612-4026-6.25", "10.1109/cvpr.2006.42", "10.1145/3172944.3172950", "10.1109/cvpr.2004.383.25", "10.1109/tvcg.2019.2934812", "10.1609/aimag.v35i4.2513", "10.2312/trvis.20191185.7", "10.1111/j.1467-8659.2009.01684.x", "10.1371/journal.pone.0129126", "10.1111/cgf.13092", "10.1162/coli\\_a\\_00237", "10.1109/tvcg.2017.2744818", "10.1109/vast.2011.6102448", "10.1109/tvcg.2009.111", "10.1109/tvcg.2019.2934619", "10.1016/s0377-2217(01)00264-8.25", "10.1111/cgf.12639", "10.1109/access.2019.2919343", "10.1186/s12874-019-0681-4", "10.1109/pacificvis.2015.7156366", "10.1109/pacificvis.2018.00029", "10.1109/tvcg.2019.2934261", "10.1080/13506280444000102.http://www.uvt.nl/ticc", "10.1109/vast.2018.8802509", "10.1111/cgf.13212", "10.1145/3200489", "10.1111/cgf.13176", "10.1177/1473871620904671", "10.1007/978-3-319-10590-1\\_53", "10.1111/j.1467-8659.2012.03126.x", "10.1111/cgf.13172", "10.1145/3025171.3025208.6,21", "10.1111/cgf.12366", "10.1109/tvcg.2019.2934659", "10.1109/cvprw.2009.5206848", "10.1016/j.media.2014.11.010", "10.1109/tvcg.2017.2744683", "10.1109/tvcg.2019.2934262", "10.1016/j.neucom.2006.11.018", "10.1177/1473871615571951", "10.1371/journal.pcbi.0020161.25", "10.1177/1473871611415994", "10.2312/trvis20191187", "10.2312/eurova", "10.1145/2858036.2858529", "10.1145/2207676.2207738", "10.1007/s11042-009-0417-2", "10.1145/3301275.3302317", "10.1038/s41746-019-0148-3", "10.1145/3351095.3372834", "10.1080/10691898.2011.11889627", "10.1109/tvcg.2018.2864504", "10.1109/vast.2017.8585720", "10.1109/mcg.2018.053491732", "10.1007/s10994-010-5207-6", "10.1109/tvcg.2019.2934433", "10.1016/j.cag.2017.05.005", "10.1109/tvcg.2012.279", "10.1145/3231622.3231641.19,20", "10.1145/1562849.1562851", "10.1007/11564126\\_", "10.1109/tvcg.2018.2846735", "10.3115/1225403.1225421", "10.1109/vast.2012.6400486", "10.2312/eurova.20191116.22", "10.1109/tvcg.2007.70443", "10.1080/027868291009242", "10.2312/eurova.20151100", "10.1145/2939502.2939503.19", "10.1016/j.cag.2014.02.004", "10.1145/2939672.2939778", "10.1109/vast.2010.5652484", "10.1111/cgf.12641", "10.1145/3301275.3302289", "10.1109/visual.2019.8933619", "10.1109/tvcg.2017.2672987", "10.1109/vast.2016.7883517.20", "10.1109/igarss.2017.8127684", "10.1016/j.jcae.2010.04.002", "10.1109/vast.2010.5652885", "10.1016/j.visinf.2019.03.002", "10.1007/s00371-018-1500-3", "10.1109/mcg.2018.042731661", "10.1109/34.598228", "10.1109/tvcg.2018.2865027", "10.1016/j.neucom.2017.01.105", "10.1111/cgf.12389", "10.1109/tvcg.2019.2934591", "10.1109/vast.2010.5652392.16", "10.1111/cgf.13416", "10.1080/02701367.1992.10608764", "10.1109/vast.2017.8585721", "10.1109/tvcg.2018.2843369", "10.1109/sbes.2010.27", "10.1109/vast.2015.7347637", "10.1145/1401890.1402008", "10.1016/j.bpj.2010.04.064", "10.1109/tvcg.2013.125", "10.1109/isai-nlp.2018.8693002", "10.1371/journal.pone.0160127", "10.1145/2856767.2856779", "10.1145/2678025.2701399", "10.1109/vast.2011.6102451", "10.1109/mcg.2010.18", "10.1021/ci4000213", "10.1109/vast.2012.6400492", "10.1007/11564126-49.25", "10.2312/eurova.20171114", "10.1109/vast.2010.5652443", "10.1145/3134599", "10.2312/pe/eurovast/eurovast10/013-018.19", "10.1109/tvcg.2019.2903946", "10.1109/tvcg.2015.2467717", "10.1177/1473871612460526", "10.1016/j.cag.2018.09.018", "10.1109/tvcg.2016.2598838", "10.1145/3172944.3172964.14", "10.1109/vast.2009.5333428", "10.1109/vast.2014.7042480", "10.2312/pe/eurovast/eurovast10/013-018", "10.1177/0962280215588241", "10.1145/2993901.2993917", "10.1109/cvpr.2008:4587581", "10.1109/tvcg.2015.2467551", "10.1016/j.visinf.2018.09.001", "10.1126/science.290.5500.2319", "10.2312/eurova.20151107", "10.1109/visual.2019.8933695", "10.13140/2.1.2393.1847", "10.1197/jamia.m1929", "10.1109/cvpr.2008.4587581.25", "10.1145/1518701.1518895.16", "10.1109/vds.2017.8573444", "10.2312/trvis:20191185", "10.1145/3359786", "10.13140/2.1.1341.1520", "10.2312/pe/eurovast/eurova11/049-052.17", "10.1109/tvcg.2014.2346660", "10.1145/3185517", "10.1109/adprl.2011.5967372", "10.1109/tvcg.2015.2467591", "10.1111/j.1751-9004.2009.00232.x", "10.1136/qshc.2004.010033", "10.1109/vast.2012.6400493", "10.1109/tvcg.2019.2934266", "10.1145/2971763.2971775", "10.1111/cgf.13730", "10.1109/vast.2012.6400488", "10.1111/cgf.13210", "10.1109/tvcg.2019.2934631", "10.1145/3172944.3172965", "10.1057/ivs.2010.2", "10.1109/tvcg.2017.2745258", "10.1016/j.jbusres.2019.07.039", "10.1162/jmlr.2003.3.4-5.993", "10.1109/pacificvis.2019.00044", "10.2312/pe/eurovast/eurova12/037-041", "10.1109/tvcg.2019.2934629", "10.1177/0018720814547570", "10.1145/3292500.3330908", "10.1111/j.1467-8659.2009.01467.x", "10.2312/eurova.20151098", "10.1177/1473871617713337", "10.1109/lars:2009.5418323", "10.1109/vast.2011.6102437", "10.1111/cgf.12878", "10.1561/1500000001", "10.1145/3025171.3025222", "10.1007/s11704-016-6028-y", "10.1016/j.procs.2017.05.216", "10.1109/cvpr.2007.382974.25", "10.1080/10447318.2020.1741118", "10.1109/vast.2012.6400489", "10.1145/3025171.3025172", "10.1109/tvcg.2017.2744098", "10.1109/tvcg.2005.66", "10.1016/j.dss.2009.05.016", "10.1007/978-1-4612-4026-6", "10.2312/evs.20191168.16,20,28", "10.2312/pe/eurovast/eurova12/037-041.17", "10.1145/3290605.3300803", "10.1145/1015330.1015388", "10.1111/cgf.13197", "10.1016/b978-1-55860-377-6.50048-7", "10.1111/cgf.13681", "10.1109/tvcg.2017.2744378", "10.1109/tvcg.2017.2744358", "10.1109/vast.2008.4677352"], "wos": 1, "children": [{"doi": "10.1109/tvcg.2020.3030368", "title": "Implicit Multidimensional Projection of Local Subspaces", "year": "2020", "conferenceName": "InfoVis", "authors": "Rongzheng Bian;Yumeng Xue;Liang Zhou;Jian Zhang 0070;Baoquan Chen;Daniel Weiskopf;Yunhai Wang", "citationCount": "1", "affiliation": "Wang, YH (Corresponding Author), Shandong Univ, Qingdao, Peoples R China. Zhou, L (Corresponding Author), Univ Utah, Salt Lake City, UT 84112 USA. Bian, Rongzheng; Xue, Yumeng; Wang, Yunhai, Shandong Univ, Qingdao, Peoples R China. Chen, Baoquan, Peking Univ, Beijing, Peoples R China. Zhang, Jian, Chinese Acad Sci, CNIC, Beijing, Peoples R China. Zhou, Liang, Univ Utah, Salt Lake City, UT 84112 USA. Weiskopf, Daniel, Univ Stuttgart, Stuttgart, Germany.", "countries": "USA;Germany;China", "abstract": "We propose a visualization method to understand the effect of multidimensional projection on local subspaces, using implicit function differentiation. Here, we understand the local subspace as the multidimensional local neighborhood of data points. Existing methods focus on the projection of multidimensional data points, and the neighborhood information is ignored. Our method is able to analyze the shape and directional information of the local subspace to gain more insights into the global structure of the data through the perception of local structures. Local subspaces are fitted by multidimensional ellipses that are spanned by basis vectors. An accurate and efficient vector transformation method is proposed based on analytical differentiation of multidimensional projections formulated as implicit functions. The results are visualized as glyphs and analyzed using a full set of specifically-designed interactions supported in our efficient web-based visualization tool. The usefulness of our method is demonstrated using various multi- and high-dimensional benchmark datasets. Our implicit differentiation vector transformation is evaluated through numerical comparisons; the overall method is evaluated through exploration examples and use cases.", "keywords": "High-dimensional data visualization,dimensionality reduction,local linear subspaces,user interaction", "link": "http://dx.doi.org/10.1109/TVCG.2020.3030368", "refList": ["10.3844/jcssp.2018.613.622", "10.1016/j.aci.2018.08.003", "10.3390/info9030065", "10.1016/j.visinf.2018.09.003", "10.1371/journal.pone.0118432", "10.1016/s0893-6080(05)80023-1", "10.1109/tvcg.2020.2986996", "10.1109/icst.2012.56", "10.1007/s10844-013-0250-y", "10.1109/tbdata.2018", "10.1145/1125451.1125659", "10.1109/tvcg.2013.125", "10.1177/1473871611412817", "10.1145/3290605.3300911", "10.1111/cgf.14034", "10.1007/s13721-013-0034-x", "10.1016/j.procs.2017.05.216", "10.1016/j.ins.2009.08.025", "10.1109/tvcg.2013.124", "10.1109/tvcg.2018.2864499", "10.1109/tvcg.2018.2864475", "10.1080/10447318.2020.1741118", "10.1016/j.imu.2019.100203", "10.1109/tvcg.2018.2865240", "10.1186/s12864-019-6413-7", "10.1109/tvcg.2015.2467551", "10.1002/widm.1249", "10.1007/978-3-319-66429-3\\_29", "10.1109/tvcg.2014.2346481", "10.1109/tvcg.2018.2864825", "10.1177/1473871620904671", "10.1109/tvcg.2019.2934267", "10.1136/bmjopen-2016-012799", "10.1109/smartgridcomm.2017.8340682", "10.1007/s10664-015-9401-9", "10.1145/1143844.1143874", "10.1111/cgf.12389", "10.1109/tvcg.2018.2872577", "10.1007/978-981-13-5802-9\\_20", "10.1016/j.ipm.2009.03.002", "10.5220/0006431602160222", "10.1109/mcg.2015.50", "10.1109/tvcg.2014.2346574", "10.1007/bf02289565", "10.1109/tvcg.2017.2744378", "10.1016/j.patrec.2008.08.010", "10.1023/a:1010933404324", "10.9735/2229-3981"], "wos": 1, "children": [], "len": 1}, {"doi": "10.1109/tvcg.2020.3030465", "title": "Visual Causality Analysis of Event Sequence Data", "year": "2020", "conferenceName": "VAST", "authors": "Zhuochen Jin;Shunan Guo;Nan Chen;Daniel Weiskopf;David Gotz;Nan Cao", "citationCount": "0", "affiliation": "Cao, N (Corresponding Author), Tongji Univ, IDVx Lab, Shanghai, Peoples R China. Jin, Zhuochen; Guo, Shunan; Chen, Nan; Cao, Nan, Tongji Univ, IDVx Lab, Shanghai, Peoples R China. Weiskopf, Daniel, Univ Stuttgart, Stuttgart, Germany. Gotz, David, Univ N Carolina, Chapel Hill, NC 27515 USA.", "countries": "USA;Germany;China", "abstract": "Causality is crucial to understanding the mechanisms behind complex systems and making decisions that lead to intended outcomes. Event sequence data is widely collected from many real-world processes, such as electronic health records, web clickstreams, and financial transactions, which transmit a great deal of information reflecting the causal relations among event types. Unfortunately, recovering causalities from observational event sequences is challenging, as the heterogeneous and high-dimensional event variables are often connected to rather complex underlying event excitation mechanisms that are hard to infer from limited observations. Many existing automated causal analysis techniques suffer from poor explainability and fail to include an adequate amount of human knowledge. In this paper, we introduce a visual analytics method for recovering causalities in event sequence data. We extend the Granger causality analysis algorithm on Hawkes processes to incorporate user feedback into causal model refinement. The visualization system includes an interactive causal analysis framework that supports bottom-up causal exploration, iterative causal verification and refinement, and causal comparison through a set of novel visualizations and interactions. We report two forms of evaluation: a quantitative evaluation of the model improvements resulting from the user-feedback mechanism, and a qualitative evaluation through case studies in different application domains to demonstrate the usefulness of the system.", "keywords": "Event sequence data,causality analysis,visual analytics", "link": "http://dx.doi.org/10.1109/TVCG.2020.3030465", "refList": ["10.5555/1642718", "10.1109/tvcg.2018.2865022", "10.5555/2074094.2074151", "10.1109/tvcg.2016.2618797", "10.1073/pnas.1320645111", "10.1109/tvcg.2017.2744843", "10.1109/iv.2017.69", "10.1109/tvcg.2019.2934399", "10.1145/3172944.3173007", "10.5555/1795555", "10.1109/mcg.2005.102", "10.1145/381641.381653", "10.1162/153244301753344614", "10.1111/cgf.14034", "10.1111/cgf.13198", "10.1017/cbo9780511519857", "10.1007/s10462-016-9475-9", "10.1075/ssol.2.2.07bor", "10.1007/978-1-4614-3223-4\\_3", "10.1109/infvis.2003.1249025", "10.1007/978-94-007-6094-313", "10.1145/2858036.2858387", "10.1109/tvcg.2007.70528", "10.1109/tvcg.2017.2674958", "10.1147/sj.454.0801", "10.1109/tvcg.2013.119", "10.1145/3173574.3173711", "10.1016/j.erss.2017.06.034", "10.1109/visual.2019.8933695", "10.1007/s11665-016-2173-6", "10.1016/0377-0427(87)90125-7", "10.2307/3601125", "10.1016/b978-0-444-88738-2.50018-x", "10.1109/mcg.2006.70", "10.1109/tvcg.2018.2865145", "10.1017/s1351324997001502", "10.1109/tvcg.2010.179", "10.1214/aos/1176344552", "10.1109/mcg.2009.22", "10.1007/978-3-319-26633-6\\_13", "10.1080/10447318.2014.905422", "10.1016/j.visinf.2019.03.004", "10.1057/palgrave.ivs.9500074", "10.1007/978-1-4614-3223-4"], "wos": 1, "children": [], "len": 1}], "len": 5}, {"doi": "10.1111/cgf.13970", "year": "2020", "title": "QUESTO: Interactive Construction of Objective Functions for Classification Tasks", "conferenceName": "EuroVis", "authors": "Subhajit Das;Shenyu Xu;Michael Gleicher;Remco Chang;Alex Endert", "citationCount": "0", "affiliation": "Das, S (Corresponding Author), Georgia Inst Technol, Atlanta, GA 30332 USA.\nDas, Subhajit; Xu, Shenyu; Endert, Alex, Georgia Inst Technol, Atlanta, GA 30332 USA.\nGleicher, Michael, Univ Wisconsin, Madison, WI USA.\nChang, Remco, Tufts Univ, Medford, MA 02155 USA.", "countries": "USA", "abstract": "Building effective classifiers requires providing the modeling algorithms with information about the training data and modeling goals in order to create a model that makes proper tradeoffs. Machine learning algorithms allow for flexible specification of such meta-information through the design of the objective functions that they solve. However, such objective functions are hard for users to specify as they are a specific mathematical formulation of their intents. In this paper, we present an approach that allows users to generate objective functions for classification problems through an interactive visual interface. Our approach adopts a semantic interaction design in that user interactions over data elements in the visualization are translated into objective function terms. The generated objective functions are solved by a machine learning solver that provides candidate models, which can be inspected by the user, and used to suggest refinements to the specifications. We demonstrate a visual analytics system QUESTO for users to manipulate objective functions to define domain-specific constraints. Through a user study we show that QUESTO helps users create various objective functions that satisfy their goals.", "keywords": "", "link": "https://doi.org/10.1111/cgf.13970", "refList": ["10.1016/j.neucom.2017.01.105", "10.1371/journal.pone.0050474", "10.1109/tvcg.2016.2598839", "10.1007/978-3-642-21530-8\\_14", "10.1109/tvcg.2016.2598828", "10.5555/2969442.2969547", "10.1007/s00371-015-1132-9", "10.1145/2851581.2856492", "10.1126/scirobotics.aao6760", "10.1109/vast.2011.6102453", "10.1109/vast.2011.6102449", "10.1088/1749-4699/8/1/014008", "10.1109/tvcg.2016.2598446", "10.1145/359784.360332", "10.1111/j.1467-8659.2009.01475.x", "10.1016/j.visinf.2017.01.006", "10.1109/tvcg.2016.2598460", "10.1109/tevc.2015.2472283", "10.1145/2207676.2207741", "10.1109/tvcg.2017.2745085", "10.1145/2939672.2939778", "10.1145/1866029.1866038", "10.1145/2487575.2487629", "10.1145/3077257.3077259", "10.2312/eurova.20171123", "10.1145/2983924", "10.1109/mcg.2013.53", "10.1109/tvcg.2015.2467615", "10.1109/vast.2014.7042492", "10.1145/2675133.2675214", "10.1109/tvcg.2014.2346482", "10.1145/3180308.3180362", "10.1109/tvcg.2014.2346321", "10.24963/ijcai.2017/202", "10.1109/tvcg.2014.2346291", "10.1109/tbme.2012.2212278", "10.1007/s40708-016-0042-6", "10.1609/aimag.v35i4.2513", "10.1016/j.ijhcs.2009.03.004", "10.1109/tevc.2012.2225064", "10.1016/s0890-6955(02)00074-3", "10.1109/icmlde.2018.00014", "10.1111/cgf.13681", "10.1109/tvcg.2013.173", "10.1145/3025171.3025208", "10.1145/3025453.3026044", "10.1109/cec.2017.7969334", "10.1109/vast.2012.6400486", "10.1109/tvcg.2016.2598831", "10.1109/tcyb.2014.2310651"], "wos": 1, "children": [], "len": 1}, {"doi": "10.1111/cgf.13972", "year": "2020", "title": "Boxer: Interactive Comparison of Classifier Results", "conferenceName": "EuroVis", "authors": "Michael Gleicher;Aditya Barve;Xinyi Yu;Florian Heimerl", "citationCount": "0", "affiliation": "Gleicher, M (Corresponding Author), Univ Wisconsin, Madison, WI 53706 USA.\nGleicher, Michael; Barve, Aditya; Yu, Xinyi; Heimerl, Florian, Univ Wisconsin, Madison, WI 53706 USA.", "countries": "USA", "abstract": "Machine learning practitioners often compare the results of different classifiers to help select, diagnose and tune models. We present Boxer, a system to enable such comparison. Our system facilitates interactive exploration of the experimental results obtained by applying multiple classifiers to a common set of model inputs. The approach focuses on allowing the user to identify interesting subsets of training and testing instances and comparing performance of the classifiers on these subsets. The system couples standard visual designs with set algebra interactions and comparative elements. This allows the user to compose and coordinate views to specify subsets and assess classifier performance on them. The flexibility of these compositions allow the user to address a wide range of scenarios in developing and assessing classifiers. We demonstrate Boxer in use cases including model selection, tuning, fairness assessment, and data quality diagnosis.", "keywords": "", "link": "https://doi.org/10.1111/cgf.13972", "refList": ["10.1109/tvcg.2019.2934629", "10.1109/tvcg.2017.2744359", "10.1109/tvcg.2016.2598838", "10.1007/s10618-014-0368-8", "10.1109/tvcg.2017.2744938", "10.1109/tvcg.2019.2934262", "10.1145/3287560.3287589", "10.1109/vast.2017.8585721", "10.1109/tvcg.2016.2598828", "10.1109/tvcg.2009.128", "10.1109/tvcg.2017.2744018", "10.1080/00994480.2000.10748487", "10.5555/3305890.3306024", "10.1109/iccv.2015.329", "10.1109/tvcg.2013.125", "10.1089/big.2016.0007", "10.1109/memsys.2019.8870817", "10.1145/2939672.2939778", "10.1007/s11104-019-04156-0", "10.1371/journal.pone.0181142", "10.1145/3301275.3302324", "10.1109/tvcg.2017.2745158", "10.1109/tvcg.2018.2865044", "10.1023/a:1010933404324", "10.1145/2487575.2487579", "10.1109/tvcg.2013.157", "10.1145/2783258.2788613", "10.1109/tvcg.2017.2744199", "10.1109/tvcg.2019.2934631", "10.1016/s0304-3800(02)00064-9", "10.1007/s10115-013-0679-x", "10.1109/tvcg.2019.2934267", "10.1007/978-3-319-10590-1\\_53", "10.1109/vast.2017.8585720", "10.1016/0004-3702(80)90021-1", "10.1109/tvcg.2015.2467618", "10.1109/tvcg.2018.2864477", "10.1109/tvcg.2009.84", "10.1007/s11263-016-0911-8", "10.1111/cgf.12918", "10.1111/cgf.12373", "10.1109/tvcg.2017.2744878", "10.1109/tvcg.2018.2864812", "10.1109/mcg.2019.2919033", "10.1080/00207176808905715", "10.1002/er.3827", "10.1109/tvcg.2014.2346660", "10.1111/cgf.13417", "10.1109/tvcg.2019.2934659", "10.1109/tvcg.2017.2744158", "10.1016/b978-0-12-815849-4.00004-9", "10.1097/ede.0b013e3181c30fb2", "10.1111/cgf.13681", "10.1016/j.ejor.2006.04.051", "10.1109/tvcg.2019.2934619", "10.1109/tvcg.2016.2598468", "10.9735/2229-3981", "10.1109/tvcg.2016.2598831"], "wos": 1, "children": [], "len": 1}], "len": 21}, {"doi": "10.1111/cgf.13672", "year": "2019", "title": "Latent Space Cartography: Visual Analysis of Vector Space Embeddings", "conferenceName": "EuroVis", "authors": "Yang Liu;Eunice Jun;Qisheng Li;Jeffrey Heer", "citationCount": "3", "affiliation": "Liu, Y (Corresponding Author), Univ Washington, Paul G Allen Sch Comp Sci \\& Engn, Seattle, WA 98195 USA.\nLiu, Yang; Jun, Eunice; Li, Qisheng; Heer, Jeffrey, Univ Washington, Paul G Allen Sch Comp Sci \\& Engn, Seattle, WA 98195 USA.", "countries": "USA", "abstract": "Latent spaces-reduced-dimensionality vector space embeddings of data, fit via machine learning-have been shown to capture interesting semantic properties and support data analysis and synthesis within a domain. Interpretation of latent spaces is challenging because prior knowledge, sometimes subtle and implicit, is essential to the process. We contribute methods for latent space cartography, the process of mapping and comparing meaningful semantic dimensions within latent spaces. We first perform a literature survey of relevant machine learning, natural language processing, and scientific research to distill common tasks and propose a workflow process. Next, we present an integrated visual analysis system for supporting this workflow, enabling users to discover, define, and verify meaningful relationships among data points, encoded within latent space dimensions. Three case studies demonstrate how users of our system can compare latent space variants in image generation, challenge existing findings on cancer transcriptomes, and assess a word embedding benchmark.", "keywords": "", "link": "https://doi.org/10.1111/cgf.13672", "refList": ["10.1145/371920.372094", "10.1109/tvcg.2016.2570755", "10.1109/tvcg.2017.2744938", "10.1007/s10994-011-5273-4", "10.2307/2289444", "10.1109/tvcg.2018.2843369", "10.1109/tvcg.2016.2598828", "10.1111/cgf.12878", "10.1021/acscentsci.7b00572", "10.1103/physreve.96.022140", "10.1051/0004-6361/201630240", "10.1109/wacv.2017.131", "10.1109/tvcg.2017.2745141", "10.1109/tvcg.2013.157", "10.1109/tvcg.2015.2467615", "10.1007/978-3-319-10590-1\\_53", "10.1162/jmlr.2003.3.4-5.951", "10.1109/tvcg.2017.2744878", "10.1109/cvpr.2017.90", "10.1080/09637486.2018.1446916", "10.1613/jair.4135", "10.1111/cgf.13417", "10.3115/v1/d14-1162", "10.1016/b978-0-12-079050-0.50020-5", "10.1109/visual.1990.146402", "10.1109/cvpr.2017.575", "10.1007/978-3-642-04898-2\\_455", "10.1038/nature14236", "10.1162/coli\\_a\\_00237", "10.1007/978-3-319-46493-0\\_47", "10.1109/tpami.2013.50", "10.1162/tacl\\_a\\_00065", "10.1109/tvcg.2017.2744358", "10.1145/3159652.3159703", "10.1109/tvcg.2016.2598831"], "wos": 1, "children": [{"doi": "10.1111/cgf.14034", "year": "2020", "title": "The State of the Art in Enhancing Trust in Machine Learning Models with the Use of Visualizations", "conferenceName": "EuroVis", "authors": "Angelos Chatzimparmpas;Rafael Messias Martins;Ilir Jusufi;Kostiantyn Kucher;Fabrice Rossi;Andreas Kerren", "citationCount": "2", "affiliation": "Chatzimparmpas, A (Corresponding Author), Linnaeus Univ, Dept Comp Sci \\& Media Technol, Vaxjo, Sweden.\nChatzimparmpas, A.; Martins, R. M.; Jusufi, I.; Kucher, K.; Kerren, A., Linnaeus Univ, Dept Comp Sci \\& Media Technol, Vaxjo, Sweden.\nRossi, F., PSL Univ, Univ Paris Dauphine, Ceremade, Paris, France.", "countries": "Sweden;France", "abstract": "Machine learning (ML) models are nowadays used in complex applications in various domains, such as medicine, bioinformatics, and other sciences. Due to their black box nature, however, it may sometimes be hard to understand and trust the results they provide. This has increased the demand for reliable visualization tools related to enhancing trust in ML models, which has become a prominent topic of research in the visualization community over the past decades. To provide an overview and present the frontiers of current research on the topic, we present a State-of-the-Art Report (STAR) on enhancing trust in ML models with the use of interactive visualization. We define and describe the background of the topic, introduce a categorization for visualization techniques that aim to accomplish this goal, and discuss insights and opportunities for future research directions. Among our contributions is a categorization of trust against different facets of interactive ML, expanded and improved from previous research. Our results are investigated from different analytical perspectives: (a) providing a statistical overview, (b) summarizing key findings, (c) performing topic analyses, and (d) exploring the data sets used in the individual papers, all with the support of an interactive web-based survey browser. We intend this survey to be beneficial for visualization researchers whose interests involve making ML models more trustworthy, as well as researchers and practitioners from other disciplines in their search for effective visualization techniques suitable for solving their tasks with confidence and conveying meaning to their data.", "keywords": "trustworthy machine learning; visualization; interpretable machine learning; explainable machine learning", "link": "https://doi.org/10.1111/cgf.14034", "refList": ["10.1109/mcg.2018.2878902", "10.1109/tvcg.2008.153", "10.2312/mlvis.20181130", "10.1109/tvcg.2016.2598828", "10.1145/3290605.3300911", "10.1145/2993901.2993909", "10.2312/mlvis.20191158", "10.1109/tvcg.2016.2598446", "10.1111/j.1467-8659.2009.01475.x", "10.1145/3290605.3300809", "10.1109/pacificvis.2018.00031", "10.1055/s-0029-1216348", "10.1007/978-3-319-90403-0\\_13", "10.1109/tvcg.2017.2745085", "10.1111/j.1467-8659.2011.01938.x", "10.1007/978-3-319-54024-5\\_6", "10.1016/s0167-9473(01)00065-2", "10.1111/cgf.12895", "10.2312/eurovisshort.20141152.17", "10.2312/eurova.20151098.22", "10.1111/cgf.13667", "10.3115/1072228.1072378", "10.1109/tbdata.2018.2877350.16", "10.1109/lars.2009.5418323.25", "10.1109/tvcg.2017.2744878", "10.1016/j.combustflame.2005.09.018", "10.1016/j.cag.2014.01.006", "10.1109/tvcg.2016.2570755", "10.2312/mlvis.20191158.1,19", "10.1518/hfes.46.1.50.30392", "10.1145/3301275.3302280", "10.1145/3351095.3372834.1", "10.1016/s0377-2217(01)00264-8", "10.1111/cgf.13424", "10.1007/978-3-319-23485-4\\_53", "10.1007/978-94-007-0753-5\\_3623", "10.1109/tvcg.2013.101", "10.1111/cgf.12884", "10.1111/j.1467-8659.2010.01835.x", "10.1021/ci9901338", "10.4230/lipics.itcs:2017", "10.1109/mis.2013.24", "10.1109/tvcg.2014.2346482", "10.1109/tvcg.2018.2865230", "10.1073/pnas.1807180116", "10.1109/dsaa.2018.00018", "10.1109/tvcg.2009.153", "10.3115/1219840.1219855", "10.1109/tvcg.2018.2864812", "10.1109/tvcg.2018.2872577", "10.2312/trvis.20191183", "10.1109/cvpr:2004.383", "10.1109/vast.2008.4677350", "10.1145/302979.303001", "10.1109/tvcg.2018.2864499", "10.1111/cgf.13672", "10.1109/tvcg.2014.2346626", "10.23915/distill.00010.18", "10.1109/tvcg.2017.2744805", "10.2312/mlvis:20191160.18", "10.23915/distill:00016", "10.1109/pacificvis.2016.7465260", "10.1111/cgf.13683", "10.23915/distill.00016.19", "10.1145/32906053.300803.22", "10.1109/tvcg.2014.2346574", "10.1177/1473871615600010", "10.1109/tvcg.2016.2598831", "10.1145/3230623", "10.1109/visual.2019.8933744", "10.1145/2993901.2993915", "10.1016/j.visinf.2017.01.006", "10.1145/2993901.2993914", "10.1109/tvcg.2014.2346984", "10.1109/5.726791", "10.23915/distill.00010", "10.1109/tvcg.2018.2864825", "10.2307/2394164", "10.1109/tvcg.2017.2744458", "10.1145/2993901.2993917.28", "10.1111/cgf.13711", "10.1109/tvcg.2016.2598664", "10.2307/2530428", "10.1109/icdar.1997.620583", "10.1109/tvcg.2017.2744718", "10.1111/cgf.13425", "10.1109/tvcg.2019.2903943", "10.1145/1518701.1518895", "10.1109/tvcg.2018.2864838", "10.1145/62038.62043", "10.1111/j.1467-8659.2011.01920.x", "10.1145/3025171.3025208", "10.1145/355112.355124", "10.1109/vast.2010.5652398", "10.1109/tvcg.2014.2346578", "10.1145/3173574.3174209", "10.4178/epih/e2014008", "10.1109/beliv.2018.8634201.25,28", "10.1016/j.eswa.2007.12.020", "10.1111/cgf:13406", "10.1109/mcg.2011.103", "10.1631/fitee.1700808", "10.1109/tvcg.2017.2745158", "10.1073/pnas.0307752101", "10.1109/tvcg.2018.2816223", "10.1109/tvcg.2017.2745141", "10.1145/32232.32234", "10.1109/tvcg.2019.2934267", "10.1109/tvcg.2018.2864477", "10.1145/3132169", "10.2312/eurova.20151100.19", "10.1145/3172944.3172964", "10.1145/2601248.2601268", "10.1109/isai-nlp.2018.8693002.1", "10.1111/cgf.13404", "10.1007/s100320200071", "10.2312/trvis.20191183.16", "10.1111/cgf.12755", "10.1145/2702123.2702509", "10.1145/1401890.1402008.25", "10.1109/tvcg.2012.65", "10.1177/1473871617733996", "10.2312/trvis.20191187.7", "10.21236/ada273556", "10.1109/vast.2010.5652450", "10.1111/j.1467-8659.2011.01940.x", "10.1177/875647939000600106", "10.1109/tvcg.2017.2711030", "10.1016/j.immuni.2016.04.014", "10.1109/tvcg.2019.2934209", "10.1016/0095-0696(78)90006-2", "10.1016/j.jclinepi.2015.04.014", "10.1016/j.ress.2013.02.013", "10.1111/cgf.12640", "10.1145/1015330.1015388.25", "10.1111/j.1467-8659.2009.01468.x", "10.1145/1541880.1541882", "10.1109/vast.2011.6102453", "10.1016/s0008-8846(98)00165-3", "10.2312/trvis.20191186.7", "10.1007/s13748-013-0040-3", "10.1109/tvcg.2015.2467757", "10.1109/tbdata.2018.2877350", "10.1109/vast.2017.8585613", "10.1080/10556789208805504", "10.1109/vast.2012.6400484", "10.1145/3025171.3025181", "10.1007/978-3-319-90403-0\\_12", "10.1109/mcg.2019.2922592", "10.1021/ci000392t", "10.1109/vast.2007.4389000", "10.1111/cgf.13406.16", "10.1111/cgf.13684", "10.2312/eurovisshort.20161166.17", "10.2312/evs:20191168", "10.1145/3041021.3055135", "10.1145/3301275.3302265", "10.1613/jair.4135", "10.1109/tvcg.2018.2864500", "10.1109/tvcg.2017.2744158", "10.1109/ssci.2015.33", "10.1111/cgf.13453", "10.2312/pe/eurovast/eurova11/049-052", "10.1145/3025171.3025181.13", "10.1145/371920.372094", "10.1109/tvcg.2017.2744938", "10.1111/j.1467-8659.2012.03108.x", "10.1109/tvcg.2019.2934251", "10.1145/3290605.3300809.18", "10.1109/ldav.2016.7874305", "10.1109/vast.2016.7883514", "10.1109/iccv.2015.425", "10.1145/3301275.3302324", "10.1109/tnnls.2013.2292894", "10.1109/tvcg.2018.2865044", "10.1109/tvcg.2013.157", "10.1371/journal.pcbi.0020161", "10.1186/s12916-019-1426-2", "10.1109/10.867928", "10.1111/cgf.13217", "10.1109/mcg.2019.2919033", "10.1145/2993901.2993910", "10.1109/tvcg.2017.2744738", "10.2307/258792", "10.1111/cgf.12655", "10.1016/j.dss.2014.03.001", "10.1109/tvcg.2019.2904069", "10.1111/cgf.13205", "10.1002/mds.22340", "10.1109/tvcg.2019.2934595", "10.1287/inte.2018.0957", "10.1109/cvpr.2007.382974", "10.1109/tvcg.2012.280", "10.1145/2678025.2701399.13", "10.2312/mlvis.20181130.13", "10.2312/eurova.20181106.16", "10.1109/tvcg.2018.2864475", "10.2312/mlvis.20191160.18,22", "10.1007/978-1-4612-4026-6.25", "10.1109/cvpr.2006.42", "10.1145/3172944.3172950", "10.1109/cvpr.2004.383.25", "10.1109/tvcg.2019.2934812", "10.1609/aimag.v35i4.2513", "10.2312/trvis.20191185.7", "10.1111/j.1467-8659.2009.01684.x", "10.1371/journal.pone.0129126", "10.1111/cgf.13092", "10.1162/coli\\_a\\_00237", "10.1109/tvcg.2017.2744818", "10.1109/vast.2011.6102448", "10.1109/tvcg.2009.111", "10.1109/tvcg.2019.2934619", "10.1016/s0377-2217(01)00264-8.25", "10.1111/cgf.12639", "10.1109/access.2019.2919343", "10.1186/s12874-019-0681-4", "10.1109/pacificvis.2015.7156366", "10.1109/pacificvis.2018.00029", "10.1109/tvcg.2019.2934261", "10.1080/13506280444000102.http://www.uvt.nl/ticc", "10.1109/vast.2018.8802509", "10.1111/cgf.13212", "10.1145/3200489", "10.1111/cgf.13176", "10.1177/1473871620904671", "10.1007/978-3-319-10590-1\\_53", "10.1111/j.1467-8659.2012.03126.x", "10.1111/cgf.13172", "10.1145/3025171.3025208.6,21", "10.1111/cgf.12366", "10.1109/tvcg.2019.2934659", "10.1109/cvprw.2009.5206848", "10.1016/j.media.2014.11.010", "10.1109/tvcg.2017.2744683", "10.1109/tvcg.2019.2934262", "10.1016/j.neucom.2006.11.018", "10.1177/1473871615571951", "10.1371/journal.pcbi.0020161.25", "10.1177/1473871611415994", "10.2312/trvis20191187", "10.2312/eurova", "10.1145/2858036.2858529", "10.1145/2207676.2207738", "10.1007/s11042-009-0417-2", "10.1145/3301275.3302317", "10.1038/s41746-019-0148-3", "10.1145/3351095.3372834", "10.1080/10691898.2011.11889627", "10.1109/tvcg.2018.2864504", "10.1109/vast.2017.8585720", "10.1109/mcg.2018.053491732", "10.1007/s10994-010-5207-6", "10.1109/tvcg.2019.2934433", "10.1016/j.cag.2017.05.005", "10.1109/tvcg.2012.279", "10.1145/3231622.3231641.19,20", "10.1145/1562849.1562851", "10.1007/11564126\\_", "10.1109/tvcg.2018.2846735", "10.3115/1225403.1225421", "10.1109/vast.2012.6400486", "10.2312/eurova.20191116.22", "10.1109/tvcg.2007.70443", "10.1080/027868291009242", "10.2312/eurova.20151100", "10.1145/2939502.2939503.19", "10.1016/j.cag.2014.02.004", "10.1145/2939672.2939778", "10.1109/vast.2010.5652484", "10.1111/cgf.12641", "10.1145/3301275.3302289", "10.1109/visual.2019.8933619", "10.1109/tvcg.2017.2672987", "10.1109/vast.2016.7883517.20", "10.1109/igarss.2017.8127684", "10.1016/j.jcae.2010.04.002", "10.1109/vast.2010.5652885", "10.1016/j.visinf.2019.03.002", "10.1007/s00371-018-1500-3", "10.1109/mcg.2018.042731661", "10.1109/34.598228", "10.1109/tvcg.2018.2865027", "10.1016/j.neucom.2017.01.105", "10.1111/cgf.12389", "10.1109/tvcg.2019.2934591", "10.1109/vast.2010.5652392.16", "10.1111/cgf.13416", "10.1080/02701367.1992.10608764", "10.1109/vast.2017.8585721", "10.1109/tvcg.2018.2843369", "10.1109/sbes.2010.27", "10.1109/vast.2015.7347637", "10.1145/1401890.1402008", "10.1016/j.bpj.2010.04.064", "10.1109/tvcg.2013.125", "10.1109/isai-nlp.2018.8693002", "10.1371/journal.pone.0160127", "10.1145/2856767.2856779", "10.1145/2678025.2701399", "10.1109/vast.2011.6102451", "10.1109/mcg.2010.18", "10.1021/ci4000213", "10.1109/vast.2012.6400492", "10.1007/11564126-49.25", "10.2312/eurova.20171114", "10.1109/vast.2010.5652443", "10.1145/3134599", "10.2312/pe/eurovast/eurovast10/013-018.19", "10.1109/tvcg.2019.2903946", "10.1109/tvcg.2015.2467717", "10.1177/1473871612460526", "10.1016/j.cag.2018.09.018", "10.1109/tvcg.2016.2598838", "10.1145/3172944.3172964.14", "10.1109/vast.2009.5333428", "10.1109/vast.2014.7042480", "10.2312/pe/eurovast/eurovast10/013-018", "10.1177/0962280215588241", "10.1145/2993901.2993917", "10.1109/cvpr.2008:4587581", "10.1109/tvcg.2015.2467551", "10.1016/j.visinf.2018.09.001", "10.1126/science.290.5500.2319", "10.2312/eurova.20151107", "10.1109/visual.2019.8933695", "10.13140/2.1.2393.1847", "10.1197/jamia.m1929", "10.1109/cvpr.2008.4587581.25", "10.1145/1518701.1518895.16", "10.1109/vds.2017.8573444", "10.2312/trvis:20191185", "10.1145/3359786", "10.13140/2.1.1341.1520", "10.2312/pe/eurovast/eurova11/049-052.17", "10.1109/tvcg.2014.2346660", "10.1145/3185517", "10.1109/adprl.2011.5967372", "10.1109/tvcg.2015.2467591", "10.1111/j.1751-9004.2009.00232.x", "10.1136/qshc.2004.010033", "10.1109/vast.2012.6400493", "10.1109/tvcg.2019.2934266", "10.1145/2971763.2971775", "10.1111/cgf.13730", "10.1109/vast.2012.6400488", "10.1111/cgf.13210", "10.1109/tvcg.2019.2934631", "10.1145/3172944.3172965", "10.1057/ivs.2010.2", "10.1109/tvcg.2017.2745258", "10.1016/j.jbusres.2019.07.039", "10.1162/jmlr.2003.3.4-5.993", "10.1109/pacificvis.2019.00044", "10.2312/pe/eurovast/eurova12/037-041", "10.1109/tvcg.2019.2934629", "10.1177/0018720814547570", "10.1145/3292500.3330908", "10.1111/j.1467-8659.2009.01467.x", "10.2312/eurova.20151098", "10.1177/1473871617713337", "10.1109/lars:2009.5418323", "10.1109/vast.2011.6102437", "10.1111/cgf.12878", "10.1561/1500000001", "10.1145/3025171.3025222", "10.1007/s11704-016-6028-y", "10.1016/j.procs.2017.05.216", "10.1109/cvpr.2007.382974.25", "10.1080/10447318.2020.1741118", "10.1109/vast.2012.6400489", "10.1145/3025171.3025172", "10.1109/tvcg.2017.2744098", "10.1109/tvcg.2005.66", "10.1016/j.dss.2009.05.016", "10.1007/978-1-4612-4026-6", "10.2312/evs.20191168.16,20,28", "10.2312/pe/eurovast/eurova12/037-041.17", "10.1145/3290605.3300803", "10.1145/1015330.1015388", "10.1111/cgf.13197", "10.1016/b978-1-55860-377-6.50048-7", "10.1111/cgf.13681", "10.1109/tvcg.2017.2744378", "10.1109/tvcg.2017.2744358", "10.1109/vast.2008.4677352"], "wos": 1, "children": [{"doi": "10.1109/tvcg.2020.3030368", "title": "Implicit Multidimensional Projection of Local Subspaces", "year": "2020", "conferenceName": "InfoVis", "authors": "Rongzheng Bian;Yumeng Xue;Liang Zhou;Jian Zhang 0070;Baoquan Chen;Daniel Weiskopf;Yunhai Wang", "citationCount": "1", "affiliation": "Wang, YH (Corresponding Author), Shandong Univ, Qingdao, Peoples R China. Zhou, L (Corresponding Author), Univ Utah, Salt Lake City, UT 84112 USA. Bian, Rongzheng; Xue, Yumeng; Wang, Yunhai, Shandong Univ, Qingdao, Peoples R China. Chen, Baoquan, Peking Univ, Beijing, Peoples R China. Zhang, Jian, Chinese Acad Sci, CNIC, Beijing, Peoples R China. Zhou, Liang, Univ Utah, Salt Lake City, UT 84112 USA. Weiskopf, Daniel, Univ Stuttgart, Stuttgart, Germany.", "countries": "USA;Germany;China", "abstract": "We propose a visualization method to understand the effect of multidimensional projection on local subspaces, using implicit function differentiation. Here, we understand the local subspace as the multidimensional local neighborhood of data points. Existing methods focus on the projection of multidimensional data points, and the neighborhood information is ignored. Our method is able to analyze the shape and directional information of the local subspace to gain more insights into the global structure of the data through the perception of local structures. Local subspaces are fitted by multidimensional ellipses that are spanned by basis vectors. An accurate and efficient vector transformation method is proposed based on analytical differentiation of multidimensional projections formulated as implicit functions. The results are visualized as glyphs and analyzed using a full set of specifically-designed interactions supported in our efficient web-based visualization tool. The usefulness of our method is demonstrated using various multi- and high-dimensional benchmark datasets. Our implicit differentiation vector transformation is evaluated through numerical comparisons; the overall method is evaluated through exploration examples and use cases.", "keywords": "High-dimensional data visualization,dimensionality reduction,local linear subspaces,user interaction", "link": "http://dx.doi.org/10.1109/TVCG.2020.3030368", "refList": ["10.3844/jcssp.2018.613.622", "10.1016/j.aci.2018.08.003", "10.3390/info9030065", "10.1016/j.visinf.2018.09.003", "10.1371/journal.pone.0118432", "10.1016/s0893-6080(05)80023-1", "10.1109/tvcg.2020.2986996", "10.1109/icst.2012.56", "10.1007/s10844-013-0250-y", "10.1109/tbdata.2018", "10.1145/1125451.1125659", "10.1109/tvcg.2013.125", "10.1177/1473871611412817", "10.1145/3290605.3300911", "10.1111/cgf.14034", "10.1007/s13721-013-0034-x", "10.1016/j.procs.2017.05.216", "10.1016/j.ins.2009.08.025", "10.1109/tvcg.2013.124", "10.1109/tvcg.2018.2864499", "10.1109/tvcg.2018.2864475", "10.1080/10447318.2020.1741118", "10.1016/j.imu.2019.100203", "10.1109/tvcg.2018.2865240", "10.1186/s12864-019-6413-7", "10.1109/tvcg.2015.2467551", "10.1002/widm.1249", "10.1007/978-3-319-66429-3\\_29", "10.1109/tvcg.2014.2346481", "10.1109/tvcg.2018.2864825", "10.1177/1473871620904671", "10.1109/tvcg.2019.2934267", "10.1136/bmjopen-2016-012799", "10.1109/smartgridcomm.2017.8340682", "10.1007/s10664-015-9401-9", "10.1145/1143844.1143874", "10.1111/cgf.12389", "10.1109/tvcg.2018.2872577", "10.1007/978-981-13-5802-9\\_20", "10.1016/j.ipm.2009.03.002", "10.5220/0006431602160222", "10.1109/mcg.2015.50", "10.1109/tvcg.2014.2346574", "10.1007/bf02289565", "10.1109/tvcg.2017.2744378", "10.1016/j.patrec.2008.08.010", "10.1023/a:1010933404324", "10.9735/2229-3981"], "wos": 1, "children": [], "len": 1}, {"doi": "10.1109/tvcg.2020.3030465", "title": "Visual Causality Analysis of Event Sequence Data", "year": "2020", "conferenceName": "VAST", "authors": "Zhuochen Jin;Shunan Guo;Nan Chen;Daniel Weiskopf;David Gotz;Nan Cao", "citationCount": "0", "affiliation": "Cao, N (Corresponding Author), Tongji Univ, IDVx Lab, Shanghai, Peoples R China. Jin, Zhuochen; Guo, Shunan; Chen, Nan; Cao, Nan, Tongji Univ, IDVx Lab, Shanghai, Peoples R China. Weiskopf, Daniel, Univ Stuttgart, Stuttgart, Germany. Gotz, David, Univ N Carolina, Chapel Hill, NC 27515 USA.", "countries": "USA;Germany;China", "abstract": "Causality is crucial to understanding the mechanisms behind complex systems and making decisions that lead to intended outcomes. Event sequence data is widely collected from many real-world processes, such as electronic health records, web clickstreams, and financial transactions, which transmit a great deal of information reflecting the causal relations among event types. Unfortunately, recovering causalities from observational event sequences is challenging, as the heterogeneous and high-dimensional event variables are often connected to rather complex underlying event excitation mechanisms that are hard to infer from limited observations. Many existing automated causal analysis techniques suffer from poor explainability and fail to include an adequate amount of human knowledge. In this paper, we introduce a visual analytics method for recovering causalities in event sequence data. We extend the Granger causality analysis algorithm on Hawkes processes to incorporate user feedback into causal model refinement. The visualization system includes an interactive causal analysis framework that supports bottom-up causal exploration, iterative causal verification and refinement, and causal comparison through a set of novel visualizations and interactions. We report two forms of evaluation: a quantitative evaluation of the model improvements resulting from the user-feedback mechanism, and a qualitative evaluation through case studies in different application domains to demonstrate the usefulness of the system.", "keywords": "Event sequence data,causality analysis,visual analytics", "link": "http://dx.doi.org/10.1109/TVCG.2020.3030465", "refList": ["10.5555/1642718", "10.1109/tvcg.2018.2865022", "10.5555/2074094.2074151", "10.1109/tvcg.2016.2618797", "10.1073/pnas.1320645111", "10.1109/tvcg.2017.2744843", "10.1109/iv.2017.69", "10.1109/tvcg.2019.2934399", "10.1145/3172944.3173007", "10.5555/1795555", "10.1109/mcg.2005.102", "10.1145/381641.381653", "10.1162/153244301753344614", "10.1111/cgf.14034", "10.1111/cgf.13198", "10.1017/cbo9780511519857", "10.1007/s10462-016-9475-9", "10.1075/ssol.2.2.07bor", "10.1007/978-1-4614-3223-4\\_3", "10.1109/infvis.2003.1249025", "10.1007/978-94-007-6094-313", "10.1145/2858036.2858387", "10.1109/tvcg.2007.70528", "10.1109/tvcg.2017.2674958", "10.1147/sj.454.0801", "10.1109/tvcg.2013.119", "10.1145/3173574.3173711", "10.1016/j.erss.2017.06.034", "10.1109/visual.2019.8933695", "10.1007/s11665-016-2173-6", "10.1016/0377-0427(87)90125-7", "10.2307/3601125", "10.1016/b978-0-444-88738-2.50018-x", "10.1109/mcg.2006.70", "10.1109/tvcg.2018.2865145", "10.1017/s1351324997001502", "10.1109/tvcg.2010.179", "10.1214/aos/1176344552", "10.1109/mcg.2009.22", "10.1007/978-3-319-26633-6\\_13", "10.1080/10447318.2014.905422", "10.1016/j.visinf.2019.03.004", "10.1057/palgrave.ivs.9500074", "10.1007/978-1-4614-3223-4"], "wos": 1, "children": [], "len": 1}], "len": 5}, {"doi": "10.1111/cgf.14031", "year": "2020", "title": "The State of the Art in Map-Like Visualization", "conferenceName": "EuroVis", "authors": "Marius Hogr{\\\"{a}}fer;Magnus Heitzler;Hans{-}J{\\\"{o}}rg Schulz", "citationCount": "0", "affiliation": "Hografer, M (Corresponding Author), Aarhus Univ, Dept Comp Sci, Aarhus, Denmark.\nHografer, Marius; Schulz, Hans-Jorg, Aarhus Univ, Dept Comp Sci, Aarhus, Denmark.\nHeitzler, Magnus, Swiss Fed Inst Technol, Inst Cartog \\& Geoinformat, Zurich, Switzerland.", "countries": "Switzerland;Denmark", "abstract": "Cartographic maps have been shown to provide cognitive benefits when interpreting data in relation to a geographic location. In visualization, the term map-like describes techniques that incorporate characteristics of cartographic maps in their representation of abstract data. However, the field of map-like visualization is vast and currently lacks a clear classification of the existing techniques. Moreover, choosing the right technique to support a particular visualization task is further complicated, as techniques are scattered across different domains, with each considering different characteristics as map-like. In this paper, we give an overview of the literature on map-like visualization and provide a hierarchical classification of existing techniques along two general perspectives: imitation and schematization of cartographic maps. Each perspective is further divided into four principal categories that group common map-like techniques along the visual primitives they affect. We further discuss this classification from a task-centered view and highlight open research questions.", "keywords": "", "link": "https://doi.org/10.1111/cgf.14031", "refList": ["10.1111/j.0020-2754.1998.00269.x.21", "10.1109/iv.2005.26", "10.2307/2980460", "10.1109/tvcg.2017.2743959", "10.1016/j.jvlc.2011.11.004", "10.1145/2501988.2502046", "10.1559/1523040042742402", "10.1007/s00779-011-0500-3", "10.1111/cgf.12932", "10.1109/tvcg.2010.89", "10.1111/cgf.13200", "10.1080/15230406.2016.1160797", "10.1179/000870410x12825500202896", "10.1109/tvcg.2007.70596", "10.5167/80972.19uzh-80972", "10.1007/978-3-319-11593-1\\_2", "10.1037/aca0000175", "10.1080/17538947.2014.923942", "10.1109/tvcg.2015.2467321", "10.1109/vissof.2005.1684299", "10.1559/152304098782383034", "10.1007/978-3-642-36763-2\\_38", "10.1109/tvcg.2013.130", "10.1109/tvcg.2014.2346274", "10.1111/cgf.12648", "10.1111/0004-5608.00242", "10.1177/1473871617724212", "10.1109/iv.2004.1320123", "10.1371/journal.pcbi.1006907", "10.1109/tvcg.2016.2599030", "10.1559/1523040042742411", "10.3390/informatics5030031", "10.1111/cgf.13079", "10.1109/tvcg.2015.2467811", "10.1016/j.tics.2003.12.004", "10.1007/s00799-016-0168-4", "10.1109/infvis.2004.57", "10.1007/s10021-007-9038-7", "10.1109/pacificvis.2015.7156366", "10.1007/978-3-319-27261-0\\_1", "10.1007/978-1-4471-2804-5\\_6", "10.1109/access.2019.2939977", "10.1109/tvcg.2017.2747545", "10.1109/icdm.2003.1250978", "10.1111/cgf.13167", "10.1016/0010-0285(78)90006-3", "10.3138/nj8v-8514-871t-221k", "10.1016/j.cag.2009.06.002", "10.1111/j.1467-8659.2011.01937.x", "10.1016/b978-044451020-4/50035-9", "10.1111/1467-8659.00566", "10.5220/0006618101080119", "10.1109/pacificvis.2012.6183571", "10.1145/2038558.2038579", "10.1109/tvcg.2010.191", "10.1111/j.0033-0124.1985.00075.x", "10.1109/tvcg.2004.1260761", "10.1007/978-3-642-34848-8\\_6", "10.1145/2968220.2968239", "10.1145/3002151.3002160", "10.1109/tst.2013.6509098", "10.1109/tvcg.2013.91", "10.1177/1473871615597077", "10.1016/j.jvlc.2011.02.001", "10.1080/17445647.2014.935502", "10.1177/1687814017740710", "10.1111/1744-7917.12601", "10.1073/pnas.0400280101", "10.1111/cgf.13672", "10.1109/mcg.2006.90", "10.1002/asi.21712", "10.1007/978-3-642-33024-7\\_3", "10.1145/2801040.2801056", "10.1109/mcg.2010.101", "10.1179/003962607x165041", "10.1057/palgrave.ivs.9500039", "10.1109/vast.2016.7883510", "10.1559/152304009788988288", "10.1080/23729333.2017.1301346", "10.1109/tvcg.2013.66", "10.1111/j.1467-8659.2012.03085.x", "10.1109/tvcg.2011.288", "10.3390/ijgi9040253", "10.1109/infvis.2005.1532150", "10.1145/2254556.2254636", "10.20382//jocg.v4i1a9", "10.1016/0010-0285(81)90016-5", "10.1145/2556288.2557224", "10.1109/iv.2001.942043", "10.1021/ed1000203", "10.1016/0169-7439(87)80084-9", "10.1109/tvcg.2010.154", "10.1016/j.jvlc.2015.10.003", "10.1109/tvcg.2019.2903945", "10.1109/tvcg.2013.120", "10.1109/tvcg.2019.2934263", "10.1146/annurev-ecolsys-102209-144718", "10.1109/tvcg.2008.165", "10.3138/a477-3202-7876-n514", "10.1080/23729333.2017.1288535", "10.1111/j.0020-2754.1998.00269.x", "10.1109/mcg.2004.41", "10.1109/vast.2009.5332593", "10.1002/smr.414", "10.1007/s12650-019-00584-3", "10.1145/22949.22950", "10.1179/1743277413y.0000000036", "10.1080/15230406.2016.1262280", "10.1016/s0341-8162(01)00164-3", "10.22224/gistbok/2017.3.8", "10.1109/tvcg.2008.155", "10.1057/ivs.2008.31", "10.1016/j.cag.2004.03.012", "10.1179/1743277412y.0000000007", "10.1016/j.soncn.2011.02.001", "10.1179/caj.1987.24.1.27", "10.3138/carto.48.3.1691", "10.5220/0004267205150524", "10.1109/38.974518", "10.1145/102377.115768", "10.1057/palgrave.ivs.9500186", "10.1109/5.58325", "10.5167/80972.uzh-80972", "10.1177/030913339602000204", "10.1007/978-3-642-22300-6\\_14", "10.1109/iv.2004.1320189", "10.1111/cgf.13447", "10.1007/s11192-017-2596-3", "10.1559/1523040053722150", "10.1007/978-3-662-45803-7\\_34"], "wos": 1, "children": [], "len": 1}], "len": 9}, {"doi": "10.1111/cgf.13972", "year": "2020", "title": "Boxer: Interactive Comparison of Classifier Results", "conferenceName": "EuroVis", "authors": "Michael Gleicher;Aditya Barve;Xinyi Yu;Florian Heimerl", "citationCount": "0", "affiliation": "Gleicher, M (Corresponding Author), Univ Wisconsin, Madison, WI 53706 USA.\nGleicher, Michael; Barve, Aditya; Yu, Xinyi; Heimerl, Florian, Univ Wisconsin, Madison, WI 53706 USA.", "countries": "USA", "abstract": "Machine learning practitioners often compare the results of different classifiers to help select, diagnose and tune models. We present Boxer, a system to enable such comparison. Our system facilitates interactive exploration of the experimental results obtained by applying multiple classifiers to a common set of model inputs. The approach focuses on allowing the user to identify interesting subsets of training and testing instances and comparing performance of the classifiers on these subsets. The system couples standard visual designs with set algebra interactions and comparative elements. This allows the user to compose and coordinate views to specify subsets and assess classifier performance on them. The flexibility of these compositions allow the user to address a wide range of scenarios in developing and assessing classifiers. We demonstrate Boxer in use cases including model selection, tuning, fairness assessment, and data quality diagnosis.", "keywords": "", "link": "https://doi.org/10.1111/cgf.13972", "refList": ["10.1109/tvcg.2019.2934629", "10.1109/tvcg.2017.2744359", "10.1109/tvcg.2016.2598838", "10.1007/s10618-014-0368-8", "10.1109/tvcg.2017.2744938", "10.1109/tvcg.2019.2934262", "10.1145/3287560.3287589", "10.1109/vast.2017.8585721", "10.1109/tvcg.2016.2598828", "10.1109/tvcg.2009.128", "10.1109/tvcg.2017.2744018", "10.1080/00994480.2000.10748487", "10.5555/3305890.3306024", "10.1109/iccv.2015.329", "10.1109/tvcg.2013.125", "10.1089/big.2016.0007", "10.1109/memsys.2019.8870817", "10.1145/2939672.2939778", "10.1007/s11104-019-04156-0", "10.1371/journal.pone.0181142", "10.1145/3301275.3302324", "10.1109/tvcg.2017.2745158", "10.1109/tvcg.2018.2865044", "10.1023/a:1010933404324", "10.1145/2487575.2487579", "10.1109/tvcg.2013.157", "10.1145/2783258.2788613", "10.1109/tvcg.2017.2744199", "10.1109/tvcg.2019.2934631", "10.1016/s0304-3800(02)00064-9", "10.1007/s10115-013-0679-x", "10.1109/tvcg.2019.2934267", "10.1007/978-3-319-10590-1\\_53", "10.1109/vast.2017.8585720", "10.1016/0004-3702(80)90021-1", "10.1109/tvcg.2015.2467618", "10.1109/tvcg.2018.2864477", "10.1109/tvcg.2009.84", "10.1007/s11263-016-0911-8", "10.1111/cgf.12918", "10.1111/cgf.12373", "10.1109/tvcg.2017.2744878", "10.1109/tvcg.2018.2864812", "10.1109/mcg.2019.2919033", "10.1080/00207176808905715", "10.1002/er.3827", "10.1109/tvcg.2014.2346660", "10.1111/cgf.13417", "10.1109/tvcg.2019.2934659", "10.1109/tvcg.2017.2744158", "10.1016/b978-0-12-815849-4.00004-9", "10.1097/ede.0b013e3181c30fb2", "10.1111/cgf.13681", "10.1016/j.ejor.2006.04.051", "10.1109/tvcg.2019.2934619", "10.1109/tvcg.2016.2598468", "10.9735/2229-3981", "10.1109/tvcg.2016.2598831"], "wos": 1, "children": [], "len": 1}], "len": 35}], "len": 187}, {"doi": "10.1109/vast.2016.7883511", "title": "How ideas flow across multiple social groups", "year": "2016", "conferenceName": "VAST", "authors": "Xiting Wang;Shixia Liu;Yang Chen;Tai-Quan Peng;Jing Su;Jing Yang;Baining Guo", "citationCount": "19", "affiliation": "Liu, SX (Corresponding Author), Tsinghua Univ, Sch Software, Beijing, Peoples R China. Wang, Xiting; Liu, Shixia; Chen, Yang, Tsinghua Univ, Sch Software, Beijing, Peoples R China. Peng, Tai-Quan, Michigan State Univ, E Lansing, MI 48824 USA. Su, Jing, Tsinghua Univ, Beijing, Peoples R China.", "countries": "USA;China", "abstract": "Tracking how correlated ideas flow within and across multiple social groups facilitates the understanding of the transfer of information, opinions, and thoughts on social media. In this paper, we present IdeaFlow, a visual analytics system for analyzing the lead-lag changes within and across pre-defined social groups regarding a specific set of correlated ideas, each of which is described by a set of words. To model idea flows accurately, we develop a random-walk-based correlation model and integrate it with Bayesian conditional cointegration and a tensor-based technique. To convey complex lead-lag relationships over time, IdeaFlow combines the strengths of a bubble tree, a flow map, and a timeline. In particular, we develop a Voronoi-treemap-based bubble tree to help users get an overview of a set of ideas quickly. A correlated-clustering-based layout algorithm is used to simultaneously generate multiple flow maps with less ambiguity. We also introduce a focus+context timeline to explore huge amounts of temporal data at different levels of time granularity. Quantitative evaluation and case studies demonstrate the accuracy and effectiveness of IdeaFlow.", "keywords": "", "link": "http://dx.doi.org/10.1109/VAST.2016.7883511", "refList": ["10.1109/tvcg.2015.2509990", "10.1007/s00371-013-0892-3", "10.1145/2505515.2505554", "10.1109/tvcg.2015.2467757", "10.1109/tkde.2014.2324581", "10.1109/tvcg.2015.2392771", "10.1145/129902.129906", "10.1109/tvcg.2013.221", "10.1109/infvis.2005.1532152", "10.4018/9781930708-29-7.ch002", "10.1145/2089094.2089101", "10.1109/tvcg.2012.212", "10.1109/tvcg.2013.254", "10.1007/s11390-013-1383-8", "10.1109/tvcg.2010.129", "10.1109/vast.2010.5652931", "10.1109/tvcg.2013.162", "10.1109/tvcg.2014.2346920", "10.1109/tvcg.2011.239", "10.1109/icdm.2005.77", "10.1109/tvcg.2015.2467554", "10.1109/tvcg.2015.2467691", "10.1109/tvcg.2015.2467991", "10.1109/tvcg.2010.225", "10.1109/infvis.2005.1532150", "10.1109/tvcg.2014.2388208", "10.1145/860435.860485", "10.1109/tvcg.2015.2467992", "10.1109/tvcg.2013.196", "10.1007/978-3-642-04898-2\\_110", "10.1109/vast.2012.6400485", "10.1109/infvis.2005.1532128", "10.1109/tvcg.2011.202", "10.1111/j.1533-8525.2011.01198.x", "10.1109/vast.2011.6102461", "10.1109/tkde.2015.2397432", "10.1093/bioinformatics/bts595", "10.1007/s12650-014-0246-x", "10.1109/tkde.2014.2373384", "10.1109/tvcg.2009.111", "10.1111/j.1467-8659.2009.01450.x", "10.1109/tvcg.2014.2346919", "10.1109/tvcg.2014.2346433"], "wos": 1, "children": [{"doi": "10.1109/vast.2017.8585638", "title": "E-Map: A Visual Analytics Approach for Exploring Significant Event Evolutions in Social Media", "year": "2017", "conferenceName": "VAST", "authors": "Siming Chen;Shuai Chen;Lijing Lin;Xiaoru Yuan;Jie Liang 0004;Xiaolong Zhang", "citationCount": "10", "affiliation": "Yuan, XR (Corresponding Author), Peking Univ, Key Lab Machine Percept, Minist Educ, Beijing, Peoples R China. Yuan, XR (Corresponding Author), Peking Univ, Sch EECS, Beijing, Peoples R China. Chen, Siming; Chen, Shuai; Lin, Lijing; Yuan, Xiaoru, Peking Univ, Key Lab Machine Percept, Minist Educ, Beijing, Peoples R China. Chen, Siming; Chen, Shuai; Lin, Lijing; Yuan, Xiaoru, Peking Univ, Sch EECS, Beijing, Peoples R China. Liang, Jie, Univ Technol, Fac Engn \\& Informat Technol, Sydney, NSW, Australia. Zhang, Xiaolong, Penn State Univ, Coll Informat Sci \\& Technol, University Pk, PA 16802 USA.", "countries": "USA;China;Australia", "abstract": "Significant events are often discussed and spread through social media, involving many people. Reposting activities and opinions expressed in social media offer good opportunities to understand the evolution of events. However, the dynamics of reposting activities and the diversity of user comments pose challenges to understand event-related social media data. We propose E-Map, a visual analytics approach that uses map-like visualization tools to help multi-faceted analysis of social media data on a significant event and in-depth understanding of the development of the event. E-Map transforms extracted keywords, messages, and reposting behaviors into map features such as cities, towns, and rivers to build a structured and semantic space for users to explore. It also visualizes complex posting and reposting behaviors as simple trajectories and connections that can be easily followed. By supporting multi-level spatial temporal exploration, E-Map helps to reveal the patterns of event development and key players in an event, disclosing the ways they shape and affect the development of the event. Two cases analysing real-world events confirm the capacities of E-Map in facilitating the analysis of event evolution with social media data.", "keywords": "Social Media,Event Analysis,Map-like Visual Metaphor,Spatial Temporal Visual Analytics", "link": "http://dx.doi.org/10.1109/VAST.2017.8585638", "refList": ["10.1109/tvcg.2007.70582", "10.1109/tvcg.2016.2598919", "10.1109/pacificvis.2010.5429590", "10.1057/ivs.2008.23", "10.1109/vast.2014.7042496", "10.1016/j.cag.2013.11.003", "10.1109/vast.2011.6102456", "10.1109/tvcg.2013.221", "10.1109/tvcg.2011.185", "10.1109/vast.2016.7883510", "10.1111/j.1467-8659.2012.03120.x", "10.1109/tvcg.2013.186", "10.1109/tmm.2016.2614220", "10.7155/jgaa.00302", "10.1109/mc.2012.430", "10.1109/tvcg.2015.2467619", "10.1109/tvcg.2010.129", "10.1016/s0341-8162(01)00164-3", "10.1109/tvcg.2016.2598590", "10.1145/2065023.2065041", "10.1111/cgf.13211", "10.1109/tvcg.2013.162", "10.1109/tvcg.2011.288", "10.1145/1963405.1963504", "10.5670/oceanog.2016.66", "10.1109/tvcg.2015.2467554", "10.1109/tvcg.2015.2467691", "10.1016/j.cag.2013.10.008", "10.1109/mcg.2015.73", "10.1109/vast.2012.6400557", "10.1109/tvcg.2016.2539960", "10.1109/tit.1982.1056489", "10.1109/pacificvis.2012.6183572", "10.1109/tvcg.2014.2346922", "10.1109/tmm.2014.2384912", "10.1109/vast.2016.7883511", "10.1002/spe.4380211102", "10.1145/2488388.2488504", "10.2312/eurovisstar.20141176", "10.1109/bigdata.2013.6691714", "10.1109/tvcg.2009.171", "10.1109/tvcg.2013.196", "10.1109/vast.2008.4677356", "10.1145/2207676.2208672", "10.1111/j.1467-8659.2011.01955.x", "10.1109/pacificvis.2014.38", "10.1109/tvcg.2012.291", "10.1109/vast.2012.6400485", "10.1109/pacificvis.2015.7156376", "10.1145/1348549.1348556", "10.1109/vast.2015.7347632", "10.1109/tvcg.2014.2346919", "10.1109/tvcg.2014.2346433"], "wos": 1, "children": [{"doi": "10.1109/tvcg.2019.2934263", "title": "R-Map: A Map Metaphor for Visualizing Information Reposting Process in Social Media", "year": "2019", "conferenceName": "VAST", "authors": "Shuai Chen;Sihang Li;Siming Chen;Xiaoru Yuan", "citationCount": "0", "affiliation": "Yuan, XR (Corresponding Author), Peking Univ, Natl Engn Lab Big Data Anal \\& Applicat, Beijing, Peoples R China. Chen, Shuai; Li, Sihang, Peking Univ, Sch EECS, Minist Educ, Key Lab Machine Petrept, Beijing, Peoples R China. Yuan, Xiaoru, Peking Univ, Natl Engn Lab Big Data Anal \\& Applicat, Beijing, Peoples R China. Chen, Siming, Fraunhofer Inst IAIS, St Augustin, Germany. Chen, Siming, Univ Bonn, Bonn, Germany.", "countries": "Germany;China", "abstract": "We propose R-Map (Reposting Map), a visual analytical approach with a map metaphor to support interactive exploration and analysis of the information reposting process in social media. A single original social media post can cause large cascades of repostings (i.e., retweets) on online networks, involving thousands, even millions of people with different opinions. Such reposting behaviors form the reposting tree, in which a node represents a message and a link represents the reposting relation. In R-Map, the reposting tree structure can be spatialized with highlighted key players and tiled nodes. The important reposting behaviors, the following relations and the semantics relations are represented as rivers, routes and bridges, respectively, in a virtual geographical space. R-Map supports a scalable overview of a large number of information repostings with semantics. Additional interactions on the map are provided to support the investigation of temporal patterns and user behaviors in the information diffusion process. We evaluate the usability and effectiveness of our system with two use cases and a formal user study.", "keywords": "Social Media,Information Diffusion,Map-like Visual Metaphor", "link": "http://dx.doi.org/10.1109/TVCG.2019.2934263", "refList": ["10.1109/infvis.2000.885091", "10.1109/pacificvis.2010.5429590", "10.1111/j.0020-2754.1998.00269.x", "10.1109/vast.2017.8585638", "10.1145/2700398", "10.1109/tmm.2016.2614229", "10.1109/visual.1991.175815", "10.1145/3183347", "10.1109/infvis.2001.963290", "10.1109/vast.2016.7883510", "10.1109/access.2016.2605009", "10.1109/mcg.2011.103", "10.1145/1124772.1124851", "10.1109/tmm.2016.2614220", "10.1109/tvcg.2010.79", "10.1109/infvis.2000.885095", "10.1111/cgf.13211", "10.1109/tvcg.2014.2346920", "10.1002/(sici)1097-0266(199606)17:6", "10.5670/oceanog.2016.66", "10.1559/152304003100011081", "10.1109/tit.1982.1056489", "10.1559/152304098782383034", "10.1109/tvcg.2014.2346922", "10.1007/978-3-540-85567-5\\_9", "10.1145/2488388.2488504", "10.1109/38.974518", "10.1109/bigdata.2013.6691714", "10.1109/pacificvis.2014.38", "10.1109/tvcg.2012.291", "10.1109/infvis.2005.1532128", "10.2307/2685881", "10.1007/1-4020-4179-9\\_91", "10.1109/infvis.1999.801860", "10.1109/asonam.2011.37"], "wos": 1, "children": [{"doi": "10.1111/cgf.14031", "year": "2020", "title": "The State of the Art in Map-Like Visualization", "conferenceName": "EuroVis", "authors": "Marius Hogr{\\\"{a}}fer;Magnus Heitzler;Hans{-}J{\\\"{o}}rg Schulz", "citationCount": "0", "affiliation": "Hografer, M (Corresponding Author), Aarhus Univ, Dept Comp Sci, Aarhus, Denmark.\nHografer, Marius; Schulz, Hans-Jorg, Aarhus Univ, Dept Comp Sci, Aarhus, Denmark.\nHeitzler, Magnus, Swiss Fed Inst Technol, Inst Cartog \\& Geoinformat, Zurich, Switzerland.", "countries": "Switzerland;Denmark", "abstract": "Cartographic maps have been shown to provide cognitive benefits when interpreting data in relation to a geographic location. In visualization, the term map-like describes techniques that incorporate characteristics of cartographic maps in their representation of abstract data. However, the field of map-like visualization is vast and currently lacks a clear classification of the existing techniques. Moreover, choosing the right technique to support a particular visualization task is further complicated, as techniques are scattered across different domains, with each considering different characteristics as map-like. In this paper, we give an overview of the literature on map-like visualization and provide a hierarchical classification of existing techniques along two general perspectives: imitation and schematization of cartographic maps. Each perspective is further divided into four principal categories that group common map-like techniques along the visual primitives they affect. We further discuss this classification from a task-centered view and highlight open research questions.", "keywords": "", "link": "https://doi.org/10.1111/cgf.14031", "refList": ["10.1111/j.0020-2754.1998.00269.x.21", "10.1109/iv.2005.26", "10.2307/2980460", "10.1109/tvcg.2017.2743959", "10.1016/j.jvlc.2011.11.004", "10.1145/2501988.2502046", "10.1559/1523040042742402", "10.1007/s00779-011-0500-3", "10.1111/cgf.12932", "10.1109/tvcg.2010.89", "10.1111/cgf.13200", "10.1080/15230406.2016.1160797", "10.1179/000870410x12825500202896", "10.1109/tvcg.2007.70596", "10.5167/80972.19uzh-80972", "10.1007/978-3-319-11593-1\\_2", "10.1037/aca0000175", "10.1080/17538947.2014.923942", "10.1109/tvcg.2015.2467321", "10.1109/vissof.2005.1684299", "10.1559/152304098782383034", "10.1007/978-3-642-36763-2\\_38", "10.1109/tvcg.2013.130", "10.1109/tvcg.2014.2346274", "10.1111/cgf.12648", "10.1111/0004-5608.00242", "10.1177/1473871617724212", "10.1109/iv.2004.1320123", "10.1371/journal.pcbi.1006907", "10.1109/tvcg.2016.2599030", "10.1559/1523040042742411", "10.3390/informatics5030031", "10.1111/cgf.13079", "10.1109/tvcg.2015.2467811", "10.1016/j.tics.2003.12.004", "10.1007/s00799-016-0168-4", "10.1109/infvis.2004.57", "10.1007/s10021-007-9038-7", "10.1109/pacificvis.2015.7156366", "10.1007/978-3-319-27261-0\\_1", "10.1007/978-1-4471-2804-5\\_6", "10.1109/access.2019.2939977", "10.1109/tvcg.2017.2747545", "10.1109/icdm.2003.1250978", "10.1111/cgf.13167", "10.1016/0010-0285(78)90006-3", "10.3138/nj8v-8514-871t-221k", "10.1016/j.cag.2009.06.002", "10.1111/j.1467-8659.2011.01937.x", "10.1016/b978-044451020-4/50035-9", "10.1111/1467-8659.00566", "10.5220/0006618101080119", "10.1109/pacificvis.2012.6183571", "10.1145/2038558.2038579", "10.1109/tvcg.2010.191", "10.1111/j.0033-0124.1985.00075.x", "10.1109/tvcg.2004.1260761", "10.1007/978-3-642-34848-8\\_6", "10.1145/2968220.2968239", "10.1145/3002151.3002160", "10.1109/tst.2013.6509098", "10.1109/tvcg.2013.91", "10.1177/1473871615597077", "10.1016/j.jvlc.2011.02.001", "10.1080/17445647.2014.935502", "10.1177/1687814017740710", "10.1111/1744-7917.12601", "10.1073/pnas.0400280101", "10.1111/cgf.13672", "10.1109/mcg.2006.90", "10.1002/asi.21712", "10.1007/978-3-642-33024-7\\_3", "10.1145/2801040.2801056", "10.1109/mcg.2010.101", "10.1179/003962607x165041", "10.1057/palgrave.ivs.9500039", "10.1109/vast.2016.7883510", "10.1559/152304009788988288", "10.1080/23729333.2017.1301346", "10.1109/tvcg.2013.66", "10.1111/j.1467-8659.2012.03085.x", "10.1109/tvcg.2011.288", "10.3390/ijgi9040253", "10.1109/infvis.2005.1532150", "10.1145/2254556.2254636", "10.20382//jocg.v4i1a9", "10.1016/0010-0285(81)90016-5", "10.1145/2556288.2557224", "10.1109/iv.2001.942043", "10.1021/ed1000203", "10.1016/0169-7439(87)80084-9", "10.1109/tvcg.2010.154", "10.1016/j.jvlc.2015.10.003", "10.1109/tvcg.2019.2903945", "10.1109/tvcg.2013.120", "10.1109/tvcg.2019.2934263", "10.1146/annurev-ecolsys-102209-144718", "10.1109/tvcg.2008.165", "10.3138/a477-3202-7876-n514", "10.1080/23729333.2017.1288535", "10.1111/j.0020-2754.1998.00269.x", "10.1109/mcg.2004.41", "10.1109/vast.2009.5332593", "10.1002/smr.414", "10.1007/s12650-019-00584-3", "10.1145/22949.22950", "10.1179/1743277413y.0000000036", "10.1080/15230406.2016.1262280", "10.1016/s0341-8162(01)00164-3", "10.22224/gistbok/2017.3.8", "10.1109/tvcg.2008.155", "10.1057/ivs.2008.31", "10.1016/j.cag.2004.03.012", "10.1179/1743277412y.0000000007", "10.1016/j.soncn.2011.02.001", "10.1179/caj.1987.24.1.27", "10.3138/carto.48.3.1691", "10.5220/0004267205150524", "10.1109/38.974518", "10.1145/102377.115768", "10.1057/palgrave.ivs.9500186", "10.1109/5.58325", "10.5167/80972.uzh-80972", "10.1177/030913339602000204", "10.1007/978-3-642-22300-6\\_14", "10.1109/iv.2004.1320189", "10.1111/cgf.13447", "10.1007/s11192-017-2596-3", "10.1559/1523040053722150", "10.1007/978-3-662-45803-7\\_34"], "wos": 1, "children": [], "len": 1}], "len": 3}, {"doi": "10.1109/tvcg.2020.3030411", "title": "Co-Bridges: Pair-wise Visual Connection and Comparison for Multi-item Data Streams", "year": "2020", "conferenceName": "VAST", "authors": "Siming Chen;Natalia V. Andrienko;Gennady L. Andrienko;Jie Li 0006;Xiaoru Yuan", "citationCount": "0", "affiliation": "Yuan, XR (Corresponding Author), Peking Univ, Beijing, Peoples R China. Chen, Siming, Fudan Univ, Sch Data Sci, Shanghai, Peoples R China. Chen, Siming; Andrienko, Natalia; Andrienko, Gennady, Fraunhofer Inst IAIS, St Augustin, Germany. Andrienko, Natalia; Andrienko, Gennady, City Univ London, London, England. Li, Jie, Tianjin Univ, Tianjin, Peoples R China. Yuan, Xiaoru, Peking Univ, Beijing, Peoples R China.", "countries": "Germany;China;England", "abstract": "In various domains, there are abundant streams or sequences of multi-item data of various kinds, e.g. streams of news and social media texts, sequences of genes and sports events, etc. Comparison is an important and general task in data analysis. For comparing data streams involving multiple items (e.g., words in texts, actors or action types in action sequences, visited places in itineraries, etc.), we propose Co-Bridges, a visual design involving connection and comparison techniques that reveal similarities and differences between two streams. Co-Bridges use river and bridge metaphors, where two sides of a river represent data streams, and bridges connect temporally or sequentially aligned segments of streams. Commonalities and differences between these segments in terms of involvement of various items are shown on the bridges. Interactive query tools support the selection of particular stream subsets for focused exploration. The visualization supports both qualitative (common and distinct items) and quantitative (stream volume, amount of item involvement) comparisons. We further propose Comparison-of-Comparisons, in which two or more Co-Bridges corresponding to different selections are juxtaposed. We test the applicability of the Co-Bridges in different domains, including social media text streams and sports event sequences. We perform an evaluation of the users' capability to understand and use Co-Bridges. The results confirm that Co-Bridges is effective for supporting pair-wise visual comparisons in a wide range of applications.", "keywords": "Visual Comparison,Pair-wise Analysis,Multi-item Data Stream,Social Media", "link": "http://dx.doi.org/10.1109/TVCG.2020.3030411", "refList": ["10.1109/tvcg.2014.2346753", "10.1109/pacificvis.2010.5429590", "10.1109/vast.2009.5333443", "10.1101/gr.2289704", "10.1177/1473871611416549", "10.1057/palgrave.ivs.9500099", "10.1109/vast.2017.8585638", "10.1109/vast.2014.7042496", "10.1109/tvcg.2017.2764459", "10.1109/tvcg.2013.221", "10.1109/vast.2011.6102439", "10.1109/tvcg.2013.213", "10.1109/tmm.2016.2614220", "10.1109/tvcg.2016.2598797", "10.1145/2207676.2208556", "10.1145/1835804.1835827", "10.1109/tvcg.2013.124", "10.2312/conf/eg2013/stars/039-063", "10.1111/cgf.13211", "10.1109/tvcg.2014.2346920", "10.1109/tvcg.2011.239", "10.1016/j.jvlc.2018.08.008", "10.1109/mcg.2018.032421661", "10.1109/tvcg.2017.2744199", "10.1109/tvcg.2019.2934535", "10.1109/tvcg.2018.2864526", "10.1007/978-0-85729-436-4\\_9", "10.1109/vast.2016.7883511", "10.1109/tvcg.2014.2346682", "10.1109/tvcg.2015.2467618", "10.1145/2566486.2567977", "10.1109/tvcg.2017.2745320", "10.1080/136588199241247", "10.1111/cgf.13401", "10.1109/tvcg.2018.2864884", "10.1109/tvcg.2012.291", "10.1109/vast.2012.6400485", "10.1109/pacificvis.2016.7465266", "10.1109/tvcg.2011.232", "10.1109/tvcg.2017.2745083", "10.1109/tvcg.2012.253", "10.1007/s12650-014-0246-x", "10.1109/tvcg.2010.20", "10.1109/tvcg.2014.2346919", "10.1109/visual.2019.8933646", "10.1007/978-0-85729-079-3"], "wos": 1, "children": [], "len": 1}], "len": 7}, {"doi": "10.1109/tvcg.2019.2934289", "title": "STBins: Visual Tracking and Comparison of Multiple Data Sequences Using Temporal Binning", "year": "2019", "conferenceName": "VAST", "authors": "Ji Qi;Vincent Bloemen;Shihan Wang;Jarke J. van Wijk;Huub van de Wetering", "citationCount": "0", "affiliation": "Qi, J (Corresponding Author), Eindhoven Univ Technol, Dept Math \\& Comp Sci, Eindhoven, Netherlands. Qi, Ji; van Wijk, Jarke; van de Wetering, Huub, Eindhoven Univ Technol, Dept Math \\& Comp Sci, Eindhoven, Netherlands. Bloemen, Vincent, Univ Twente, Fac Elect Engn Math Comp Sci, Enschede, Netherlands. Wang, Shihan, Univ Amsterdam, Amsterdam, Netherlands.", "countries": "Netherlands", "abstract": "While analyzing multiple data sequences, the following questions typically arise: how does a single sequence change over time, how do multiple sequences compare within a period, and how does such comparison change over time. This paper presents a visual technique named STBins to answer these questions. STBins is designed for visual tracking of individual data sequences and also for comparison of sequences. The latter is done by showing the similarity of sequences within temporal windows. A perception study is conducted to examine the readability of alternative visual designs based on sequence tracking and comparison tasks. Also, two case studies based on real-world datasets are presented in detail to demonstrate usage of our technique.", "keywords": "Visualization,time series data,data sequence", "link": "http://dx.doi.org/10.1109/TVCG.2019.2934289", "refList": ["10.1109/tvcg.2012.189", "10.1177/1473871611416549", "10.1145/2702123.2702419", "10.1145/2483977.2483989", "10.1109/vast.2016.7883512", "10.1109/tvcg.2016.2598797", "10.1016/j.eswa.2016.03.050", "10.1109/tvcg.2014.2346433", "10.1109/tvcg.2013.124", "10.1111/j.1469-8137.1912.tb05611.x", "10.1186/1753-6561-8-s2-s9", "10.1145/2851141.2851161", "10.1109/tvcg.2011.239", "10.1109/tvcg.2018.2864885", "10.2307/3001913", "10.1007/978-0-85729-079-3", "10.1109/tvcg.2009.117", "10.1109/tvcg.2013.200", "10.1109/tvcg.2017.2744199", "10.1109/tvcg.2016.2539960", "10.1145/2557500.2557508", "10.1109/tvcg.2012.225", "10.1186/1753-6561-8-s2-s8", "10.1109/vast.2016.7883511", "10.1109/tvcg.2014.2346682", "10.1016/j.intcom.2012.01.003", "10.1111/cgf.13264", "10.1109/tvcg.2011.232", "10.1111/cgf.12653", "10.1002/asi.21489", "10.1109/tvcg.2014.2346919", "10.1145/2254556.2254670"], "wos": 1, "children": [], "len": 1}, {"doi": "10.1109/tvcg.2020.3030411", "title": "Co-Bridges: Pair-wise Visual Connection and Comparison for Multi-item Data Streams", "year": "2020", "conferenceName": "VAST", "authors": "Siming Chen;Natalia V. Andrienko;Gennady L. Andrienko;Jie Li 0006;Xiaoru Yuan", "citationCount": "0", "affiliation": "Yuan, XR (Corresponding Author), Peking Univ, Beijing, Peoples R China. Chen, Siming, Fudan Univ, Sch Data Sci, Shanghai, Peoples R China. Chen, Siming; Andrienko, Natalia; Andrienko, Gennady, Fraunhofer Inst IAIS, St Augustin, Germany. Andrienko, Natalia; Andrienko, Gennady, City Univ London, London, England. Li, Jie, Tianjin Univ, Tianjin, Peoples R China. Yuan, Xiaoru, Peking Univ, Beijing, Peoples R China.", "countries": "Germany;China;England", "abstract": "In various domains, there are abundant streams or sequences of multi-item data of various kinds, e.g. streams of news and social media texts, sequences of genes and sports events, etc. Comparison is an important and general task in data analysis. For comparing data streams involving multiple items (e.g., words in texts, actors or action types in action sequences, visited places in itineraries, etc.), we propose Co-Bridges, a visual design involving connection and comparison techniques that reveal similarities and differences between two streams. Co-Bridges use river and bridge metaphors, where two sides of a river represent data streams, and bridges connect temporally or sequentially aligned segments of streams. Commonalities and differences between these segments in terms of involvement of various items are shown on the bridges. Interactive query tools support the selection of particular stream subsets for focused exploration. The visualization supports both qualitative (common and distinct items) and quantitative (stream volume, amount of item involvement) comparisons. We further propose Comparison-of-Comparisons, in which two or more Co-Bridges corresponding to different selections are juxtaposed. We test the applicability of the Co-Bridges in different domains, including social media text streams and sports event sequences. We perform an evaluation of the users' capability to understand and use Co-Bridges. The results confirm that Co-Bridges is effective for supporting pair-wise visual comparisons in a wide range of applications.", "keywords": "Visual Comparison,Pair-wise Analysis,Multi-item Data Stream,Social Media", "link": "http://dx.doi.org/10.1109/TVCG.2020.3030411", "refList": ["10.1109/tvcg.2014.2346753", "10.1109/pacificvis.2010.5429590", "10.1109/vast.2009.5333443", "10.1101/gr.2289704", "10.1177/1473871611416549", "10.1057/palgrave.ivs.9500099", "10.1109/vast.2017.8585638", "10.1109/vast.2014.7042496", "10.1109/tvcg.2017.2764459", "10.1109/tvcg.2013.221", "10.1109/vast.2011.6102439", "10.1109/tvcg.2013.213", "10.1109/tmm.2016.2614220", "10.1109/tvcg.2016.2598797", "10.1145/2207676.2208556", "10.1145/1835804.1835827", "10.1109/tvcg.2013.124", "10.2312/conf/eg2013/stars/039-063", "10.1111/cgf.13211", "10.1109/tvcg.2014.2346920", "10.1109/tvcg.2011.239", "10.1016/j.jvlc.2018.08.008", "10.1109/mcg.2018.032421661", "10.1109/tvcg.2017.2744199", "10.1109/tvcg.2019.2934535", "10.1109/tvcg.2018.2864526", "10.1007/978-0-85729-436-4\\_9", "10.1109/vast.2016.7883511", "10.1109/tvcg.2014.2346682", "10.1109/tvcg.2015.2467618", "10.1145/2566486.2567977", "10.1109/tvcg.2017.2745320", "10.1080/136588199241247", "10.1111/cgf.13401", "10.1109/tvcg.2018.2864884", "10.1109/tvcg.2012.291", "10.1109/vast.2012.6400485", "10.1109/pacificvis.2016.7465266", "10.1109/tvcg.2011.232", "10.1109/tvcg.2017.2745083", "10.1109/tvcg.2012.253", "10.1007/s12650-014-0246-x", "10.1109/tvcg.2010.20", "10.1109/tvcg.2014.2346919", "10.1109/visual.2019.8933646", "10.1007/978-0-85729-079-3"], "wos": 1, "children": [], "len": 1}, {"doi": "10.1109/pacificvis.2018.00032", "year": "2018", "title": "TagNet: Toward Tag-Based Sentiment Analysis of Large Social Media Data", "conferenceName": "PacificVis", "authors": "Yang Chen", "citationCount": "2", "affiliation": "", "countries": "usa;china", "abstract": "Hashtags and replies, originally introduced on Twitter, have become the most popular ways to tag short messages in social networks. While the primary uses of these human-labeled metadata are still for message retrieval and clustering, there have been increasing attempts to use them as subject or topic indicators in measuring people's continuous sentiments in large message corpora. However, conducting the analysis for large social media data is still challenging due to the message volume, heterogeneity, and temporal dependence. In this paper, we present TagNet, a novel visualization approach tailored to the tag-based sentiment analysis. TagNet combines traditional tag clouds with an improved node-link diagram to represent the time-varying heterogeneous information with reduced visual clutter. A force model is leveraged to generate layout aesthetics from which the temporal patterns of tags can be easily compared across different subsets of data. It is enhanced by visual encodings for quickly estimating the time-varying sentiment. Interaction tools are provided to improve the scalability for exploring large corpora. An example Twitter corpus illustrates the applicability and usefulness of TagNet.", "keywords": "Human-centered computing; Visualization; Visualization application domains; Visual analytics; Human-centered computing; Visualization; Visualization design and evaluation methods", "link": "https://doi.org/10.1109/PacificVis.2018.00032", "refList": ["10.1109/tvcg.2012.252", "10.1109/pacificvis.2011.5742389", "10.1198/016214506000000302", "10.1145/2063576.2063726", "10.1109/vast.2009.5333443", "10.1109/vast.2016.7883511", "10.1007/978-3-319-39931-7\\_28", "10.1109/tvcg.2017.2746018", "10.1109/tvcg.2003.1196005", "10.1109/tvcg.2010.194", "10.1126/science.220.4598.671", "10.1007/978-3-642-40669-0\\_31", "10.1007/s13278-013-0108-x", "10.1145/1520340.1520584", "10.1145/2254556.2254701", "10.1109/pacificvis.2011.5742388"], "wos": 1, "children": [], "len": 1}], "len": 15}, {"doi": "10.1109/vast.2016.7883520", "title": "Visual analysis and coding of data-rich user behavior", "year": "2016", "conferenceName": "VAST", "authors": "Tanja Blascheck;Fabian Beck;Sebastian Baltes;Thomas Ertl;Daniel Weiskopf", "citationCount": "7", "affiliation": "Blascheck, T (Corresponding Author), Univ Stuttgart, Stuttgart, Germany. Blascheck, Tanja; Beck, Fabian; Ertl, Thomas; Weiskopf, Daniel, Univ Stuttgart, Stuttgart, Germany. Baltes, Sebastian, Univ Trier, Trier, Germany.", "countries": "Germany", "abstract": "Investigating user behavior involves abstracting low-level events to higher-level concepts. This requires an analyst to study individual user activities, assign codes which categorize behavior, and develop a consistent classification scheme. To better support this reasoning process of an analyst, we suggest a novel visual analytics approach which integrates rich user data including transcripts, videos, eye movement data, and interaction logs. Word-sized visualizations embedded into a tabular representation provide a space-efficient and detailed overview of user activities. An analyst assigns codes, grouped into code categories, as part of an interactive process. Filtering and searching helps to select specific activities and focus an analysis. A comparison visualization summarizes results of coding and reveals relationships between codes. Editing features support efficient assignment, refinement, and aggregation of codes. We demonstrate the practical applicability and usefulness of our approach in a case study and describe expert feedback.", "keywords": "", "link": "http://dx.doi.org/10.1109/VAST.2016.7883520", "refList": ["10.1109/mcg.2006.5", "10.1111/cgf.12722", "10.1109/tvcg.2008.137", "10.1007/bf00988593", "10.1145/355017.355022", "10.2307/1269768", "10.1109/vast.2009.5333443", "10.1007/978-3-642-54894-9\\_3", "10.1109/tvcg.2015.2467757", "10.1109/tvcg.2011.226", "10.1109/tvcg.2014.2346452", "10.1111/j.1467-8659.2008.01214.x", "10.1002/asi.23053", "10.1111/j.1365-2427.1994.tb01742.x", "10.1007/978-3-540-70956-5", "10.1109/mcg.2009.53", "10.1371/journal.pone.0008694", "10.1007/bf01187020", "10.1109/cmv.2007.20", "10.1177/1558689809334210", "10.1111/j.1467-8659.2012.03093.x", "10.1109/tvcg.2013.124", "10.1109/tvcg.2015.2467611", "10.1109/mcg.2009.49", "10.1057/ivs.2008.31", "10.1145/2702613.2732778", "10.1109/tvcg.2005.53", "10.1145/2857491.2857523", "10.1109/tvcg.2011.279", "10.1109/tvcg.2014.2346677", "10.1111/cgf.12512", "10.1109/mcg.2006.70", "10.1109/iv.2014.72", "10.1109/tsmc.1981.4308636", "10.1145/1377966.1377974", "10.1109/visual.1990.146402", "10.1109/tse.2010.111", "10.1145/642611.642681", "10.1145/2168556.2168573", "10.2312/eurovisstar.20141173", "10.1109/tvcg.2010.194", "10.1179/000870403235002042", "10.1109/tvcg.2006.76"], "wos": 1, "children": [{"doi": "10.1109/tvcg.2018.2864843", "title": "An Interactive Method to Improve Crowdsourced Annotations", "year": "2018", "conferenceName": "VAST", "authors": "Shixia Liu;Changjian Chen;Yafeng Lu;Fang-Xin Ou-Yang;Bin Wang 0021", "citationCount": "7", "affiliation": "Liu, SX (Corresponding Author), Tsinghua Univ, Sch Software, Beijing, Peoples R China. Liu, Shixia; Chen, Changjian; Ouyang, Fangxin; Wang, Bin, Tsinghua Univ, Sch Software, Beijing, Peoples R China. Lu, Yafeng, Arizona State Univ, Tempe, AZ 85287 USA.", "countries": "USA;China", "abstract": "In order to effectively infer correct labels from noisy crowdsourced annotations, learning-from-crowds models have introduced expert validation. However, little research has been done on facilitating the validation procedure. In this paper, we propose an interactive method to assist experts in verifying uncertain instance labels and unreliable workers. Given the instance labels and worker reliability inferred from a learning-from-crowds model, candidate instances and workers are selected for expert validation. The influence of verified results is propagated to relevant instances and workers through the learning-from-crowds model. To facilitate the validation of annotations, we have developed a confusion visualization to indicate the confusing classes for further exploration, a constrained projection method to show the uncertain labels in context, and a scatter-plot-based visualization to illustrate worker reliability. The three visualizations are tightly integrated with the learning-from-crowds model to provide an iterative and progressive environment for data validation. Two case studies were conducted that demonstrate our approach offers an efficient method for validating and improving crowdsourced annotations.", "keywords": "Crowdsourcing,learning-from-crowds,interactive visualization,focus + context", "link": "http://dx.doi.org/10.1109/TVCG.2018.2864843", "refList": ["10.1109/tvcg.2015.2467622", "10.1109/tvcg.2017.2744938", "10.1007/s00371-013-0892-3", "10.1109/cvpr.2014.81", "10.1109/icdm.2001.989520", "10.1109/tvcg.2016.2598445", "10.1145/2254556.2254659", "10.1177/1753193413501588", "10.1109/tvcg.2009.139", "10.1145/2408736.2408740", "10.1145/1978942.1979444", "10.1145/2089094.2089101", "10.1109/vast.2014.7042480", "10.1016/j.visinf.2017.01.006", "10.1109/vast.2016.7883508", "10.1109/vast.2016.7883514", "10.1109/pacificvis.2015.7156379", "10.1109/tvcg.2013.212", "10.1109/tvcg.2012.64", "10.1007/s11263-015-0816-y", "10.1145/2723372.2723731", "10.1109/tvcg.2016.2515592", "10.1109/tvcg.2011.239", "10.1111/cgf.12935", "10.1109/tvcg.2015.2467554", "10.1145/2063576.2063860", "10.1109/iccv.2011.6126474", "10.1109/vast.2016.7883520", "10.1016/j.infsof.2008.09.005", "10.1109/tvcg.2018.2834341", "10.1109/tvcg.2014.2331979", "10.1109/tvcg.2014.2346594", "10.1109/tvcg.2012.277", "10.1109/tvcg.2017.2744685", "10.1109/tvcg.2017.2745078", "10.1109/tvcg.2017.2744378", "10.1109/iv.2013.21", "10.1109/tvcg.2016.2598829", "10.1109/vast.2012.6400492", "10.1016/s0169-7552(98)00110-x", "10.1109/mcg.2018.042731661", "10.1109/tvcg.2013.164", "10.1109/tvcg.2011.202", "10.1109/tvcg.2016.2598592", "10.1145/775047.775126", "10.1111/j.1467-8659.2011.01918.x", "10.1109/cvprw.2009.5206848", "10.1111/cgf.13092", "10.1109/tvcg.2017.2744818", "10.1111/j.1467-8659.2009.01450.x", "10.1007/bf02288367", "10.1109/tvcg.2016.2598831"], "wos": 1, "children": [{"doi": "10.1109/vast47406.2019.8986943", "title": "Interactive Correction of Mislabeled Training Data", "year": "2019", "conferenceName": "VAST", "authors": "Shouxing Xiang;Xi Ye;Jiazhi Xia;Jing Wu;Yang Chen;Shixia Liu", "citationCount": "4", "affiliation": "Liu, SX (Corresponding Author), Tsinghua Univ, Sch Software, BNRist, Beijing, Peoples R China. Xiang, Shouxing; Ye, Xi; Chen, Yang; Liu, Shixia, Tsinghua Univ, Sch Software, BNRist, Beijing, Peoples R China. Xia, Jiazhi, Cent South Univ, Sch Comp Sci \\& Engn, Changsha, Peoples R China. Wu, Jing, Cardiff Univ, Sch Comp Sci \\& Informat, Cardiff, Wales.", "countries": "Wales;China", "abstract": "In this paper, we develop a visual analysis method for interactively improving the quality of labeled data, which is essential to the success of supervised and semi-supervised learning. The quality improvement is achieved through the use of user-selected trusted items. We employ a bi-level optimization model to accurately match the labels of the trusted items and to minimize the training loss. Based on this model, a scalable data correction algorithm is developed to handle tens of thousands of labeled data efficiently. The selection of the trusted items is facilitated by an incremental tSNE with improved computational efficiency and layout stability to ensure a smooth transition between different levels. We evaluated our method on real-world datasets through quantitative evaluation and case studies, and the results were generally favorable.", "keywords": "Labeled data debugging,trusted item,tSNE", "link": "http://dx.doi.org/10.1109/VAST47406.2019.8986943", "refList": ["10.1109/tvcg.2017.2744683", "10.1109/tvcg.2016.2570755", "10.1109/tvcg.2017.2744938", "10.1145/2254556.2254659", "10.1109/tvcg.2017.2744419", "10.1007/s12008-018-0488-2", "10.1023/b:aire.0000045502.10941.a9", "10.1111/cgf.12878", "10.1137/0108011", "10.1109/vl.1996.545307", "10.1109/tvcg.2018.2864843", "10.1007/978-3-642-21602-2\\_67", "10.1145/3190578", "10.1145/2637748.2638423", "10.1109/tnnls.2013.2292894", "10.1109/tvcg.2018.2865026", "10.1145/7529.8927", "10.1016/j.infsof.2008.09.005", "10.1145/2669557.2669578", "10.1109/tvcg.2014.2346594", "10.1109/tvcg.2009.84", "10.1109/tvcg.2017.2744685", "10.1142/s0218001415510088", "10.1109/vast.2012.6400492", "10.1007/s00371-018-1500-3", "10.1111/cgf.13406", "10.1007/s10462-010-9156-z", "10.1109/cvpr.2014.483", "10.1109/tvcg.2016.2598592", "10.1109/tvcg.2018.2846735", "10.1109/tvcg.2014.2346574", "10.1109/tvcg.2017.2744818", "10.1016/j.cag.2013.10.006", "10.1109/tvcg.2016.2598831"], "wos": 1, "children": [{"doi": "10.1109/tvcg.2020.3030443", "title": "CAVA: A Visual Analytics System for Exploratory Columnar Data Augmentation Using Knowledge Graphs", "year": "2020", "conferenceName": "VAST", "authors": "Dylan Cashman;Shenyu Xu;Subhajit Das;Florian Heimerl;Cong Liu;Shah Rukh Humayoun;Michael Gleicher;Alex Endert;Remco Chang", "citationCount": "0", "affiliation": "Cashman, D (Corresponding Author), Tufts Univ, Medford, MA 02155 USA. Cashman, Dylan; Liu, Cong; Chang, Remco, Tufts Univ, Medford, MA 02155 USA. Xu, Shenyu; Das, Subhajit; Endert, Alex, Georgia Tech, Atlanta, GA USA. Heimerl, Florian; Gleicher, Michael, Univ Wisconsin, Madison, WI 53706 USA. Humayoun, Shah Rukh, San Francisco State Univ, San Francisco, CA 94132 USA.", "countries": "USA", "abstract": "Most visual analytics systems assume that all foraging for data happens before the analytics process; once analysis begins, the set of data attributes considered is fixed. Such separation of data construction from analysis precludes iteration that can enable foraging informed by the needs that arise in-situ during the analysis. The separation of the foraging loop from the data analysis tasks can limit the pace and scope of analysis. In this paper, we present CAVA, a system that integrates data curation and data augmentation with the traditional data exploration and analysis tasks, enabling information foraging in-situ during analysis. Identifying attributes to add to the dataset is difficult because it requires human knowledge to determine which available attributes will be helpful for the ensuing analytical tasks. CAVA crawls knowledge graphs to provide users with a a broad set of attributes drawn from external data to choose from. Users can then specify complex operations on knowledge graphs to construct additional attributes. CAVA shows how visual analytics can help users forage for attributes by letting users visually explore the set of available data, and by serving as an interface for query construction. It also provides visualizations of the knowledge graph itself to help users understand complex joins such as multi-hop aggregations. We assess the ability of our system to enable users to perform complex data combinations without programming in a user study over two datasets. We then demonstrate the generalizability of CAVA through two additional usage scenarios. The results of the evaluation confirm that CAVA is effective in helping the user perform data foraging that leads to improved analysis outcomes, and offer evidence in support of integrating data augmentation as a part of the visual analytics pipeline.", "keywords": "Visual Analytics,Information Foraging,Data Augmentation", "link": "http://dx.doi.org/10.1109/TVCG.2020.3030443", "refList": ["10.1057/palgrave.ivs.9500122", "10.1109/tvcg.2016.2598867", "10.1111/cgf.13708", "10.1109/tvcg.2019.2934799", "10.1109/tvcg.2019.2934541", "10.1109/tvcg.2013.65", "10.1109/tvcg.2018.2875702", "10.1109/iv.2004.1320207", "10.1068/p260471", "10.1145/1778765.1778816", "10.1109/tvcg.2018.2808489", "10.1109/tvcg.2018.2864912", "10.1016/j.apgeog.2015.12.006", "10.1111/j.1467-8659.2011.01960.x", "10.1109/tvcg.2018.2864843", "10.1109/pacificvis.2010.5429604", "10.1109/tvcg.2014.2346898", "10.1109/5.726791", "10.1177/1475090214540874", "10.1109/icde.2016.7498287", "10.1145/1556262.1556289", "10.1109/tvcg.2007.70535", "10.1109/vast.2012.6400489", "10.1145/1056808.1056914", "10.1016/j.neucom.2014.09.063", "10.1145/7529.8927", "10.1109/tvcg.2016.2598495", "10.1109/tvcg.2016.2607204", "10.1109/vast47406.2019.8986943", "10.3758/bf03205986", "10.1109/infvis.2005.1532142", "10.1145/1150402.1150479", "10.1109/tvcg.2017.2674978", "10.1109/tvcg.2019.2945960", "10.1109/tvcg.2017.2744098", "10.1109/tvcg.2017.2674999", "10.1109/tvcg.2011.279", "10.1109/tvcg.2014.2346594", "10.1109/tvcg.2017.2744184", "10.1111/cgf.12876", "10.1007/s4095-020-0191-7", "10.1007/s11390-015-1535-0", "10.1111/cgf.12640", "10.1109/tvcg.2016.2598667", "10.1111/cgf.13683", "10.1109/tvcg.2013.153", "10.1109/tvcg.2019.2934208", "10.1109/tvcg.2019.2934655", "10.1111/cgf.12655", "10.1007/s11023-010-9221-z", "10.1109/vast.2012.6400487", "10.1145/2702123.2702585", "10.1007/bf00310175", "10.1109/tvcg.2017.2744378", "10.1103/physreve.64.061907", "10.1109/ldav.2017.8231848", "10.1109/tvcg.2016.2598831"], "wos": 1, "children": [], "len": 1}, {"doi": "10.1109/tvcg.2020.3030432", "title": "Evaluation of Sampling Methods for Scatterplots", "year": "2020", "conferenceName": "VAST", "authors": "Jun Yuan;Shouxing Xiang;Jiazhi Xia;Lingyun Yu;Shixia Liu", "citationCount": "0", "affiliation": "Liu, SX (Corresponding Author), Tsinghua Univ, BNRist, Beijing, Peoples R China. Yuan, Jun; Xiang, Shouxing; Liu, Shixia, Tsinghua Univ, BNRist, Beijing, Peoples R China. Xia, Jiazhi, Cent South Univ, Changsha, Peoples R China. Yu, Lingyun, Xian Jiaotong Liverpool Univ, Suzhou, Peoples R China.", "countries": "China", "abstract": "Given a scatterplot with tens of thousands of points or even more, a natural question is which sampling method should be used to create a small but \u201cgood\u201d scatterplot for a better abstraction. We present the results of a user study that investigates the influence of different sampling strategies on multi-class scatterplots. The main goal of this study is to understand the capability of sampling methods in preserving the density, outliers, and overall shape of a scatterplot. To this end, we comprehensively review the literature and select seven typical sampling strategies as well as eight representative datasets. We then design four experiments to understand the performance of different strategies in maintaining: 1) region density; 2) class density; 3) outliers; and 4) overall shape in the sampling results. The results show that: 1) random sampling is preferred for preserving region density; 2) blue noise sampling and random sampling have comparable performance with the three multi-class sampling strategies in preserving class density; 3) outlier biased density based sampling, recursive subdivision based sampling, and blue noise sampling perform the best in keeping outliers; and 4) blue noise sampling outperforms the others in maintaining the overall shape of a scatterplot.", "keywords": "Scatterplot,data sampling,empirical evaluation", "link": "http://dx.doi.org/10.1109/TVCG.2020.3030432", "refList": ["10.1057/palgrave.ivs.9500122", "10.1109/tvcg.2016.2598867", "10.1109/tvcg.2015.2467591", "10.1111/cgf.13708", "10.1109/tvcg.2019.2934799", "10.1109/tvcg.2019.2934541", "10.1109/tvcg.2013.65", "10.1109/iv.2004.1320207", "10.1068/p260471", "10.1145/1778765.1778816", "10.1109/tvcg.2018.2808489", "10.1109/tvcg.2018.2864912", "10.1016/j.apgeog.2015.12.006", "10.1111/j.1467-8659.2011.01960.x", "10.1109/tvcg.2018.2864843", "10.1109/pacificvis.2010.5429604", "10.1109/tvcg.2014.2346898", "10.1109/5.726791", "10.1177/1475090214540874", "10.1145/1556262.1556289", "10.1109/tvcg.2007.70535", "10.1109/vast.2012.6400489", "10.1145/1056808.1056914", "10.1016/j.neucom.2014.09.063", "10.1145/7529.8927", "10.1109/tvcg.2016.2607204", "10.1109/vast47406.2019.8986943", "10.3758/bf03205986", "10.1109/infvis.2005.1532142", "10.1145/1150402.1150479", "10.1109/tvcg.2017.2674978", "10.1109/tvcg.2017.2744098", "10.1109/tvcg.2017.2674999", "10.1109/tvcg.2011.279", "10.1109/tvcg.2014.2346594", "10.1109/tvcg.2017.2744184", "10.1111/cgf.12876", "10.1109/1011101.2019.2945960", "10.1007/s4095-020-0191-7", "10.1007/s11390-015-1535-0", "10.1111/cgf.12640", "10.1109/tvcg.2016.2598667", "10.1111/cgf.13683", "10.1109/tvcg.2013.153", "10.1109/tvcg.2019.2934208", "10.1109/tvcg.2019.2934655", "10.1111/cgf.12655", "10.1007/s11023-010-9221-z", "10.1109/vast.2012.6400487", "10.1145/2702123.2702585", "10.1007/bf00310175", "10.1109/tvcg.2017.2744378", "10.1103/physreve.64.061907", "10.1109/ldav.2017.8231848", "10.1109/tvcg.2016.2598831"], "wos": 1, "children": [], "len": 1}], "len": 5}, {"doi": "10.1109/tvcg.2019.2934591", "title": "NNVA: Neural Network Assisted Visual Analysis of Yeast Cell Polarization Simulation", "year": "2019", "conferenceName": "VAST", "authors": "Subhashis Hazarika;Haoyu Li;Ko-Chih Wang;Han-Wei Shen;Ching-Shan Chou", "citationCount": "0", "affiliation": "Hazarika, S (Corresponding Author), Ohio State Univ, Dept Comp Sci, Columbus, OH 43210 USA. Hazarika, Subhashis; Li, Haoyu; Wang, Ko-Chih; Shen, Han-Wei, Ohio State Univ, Dept Comp Sci, Columbus, OH 43210 USA. Chou, Ching-Shan, Ohio State Univ, Dept Math, 231 W 18th Ave, Columbus, OH 43210 USA.", "countries": "USA", "abstract": "Complex computational models are often designed to simulate real-world physical phenomena in many scientific disciplines. However, these simulation models tend to be computationally very expensive and involve a large number of simulation input parameters, which need to be analyzed and properly calibrated before the models can be applied for real scientific studies. We propose a visual analysis system to facilitate interactive exploratory analysis of high-dimensional input parameter space for a complex yeast cell polarization simulation. The proposed system can assist the computational biologists, who designed the simulation model, to visually calibrate the input parameters by modifying the parameter values and immediately visualizing the predicted simulation outcome without having the need to run the original expensive simulation for every instance. Our proposed visual analysis system is driven by a trained neural network-based surrogate model as the backend analysis framework. In this work, we demonstrate the advantage of using neural networks as surrogate models for visual analysis by incorporating some of the recent advances in the field of uncertainty quantification, interpretability and explainability of neural network-based models. We utilize the trained network to perform interactive parameter sensitivity analysis of the original simulation as well as recommend optimal parameter configurations using the activation maximization framework of neural networks. We also facilitate detail analysis of the trained network to extract useful insights about the simulation model, learned by the network, during the training process. We performed two case studies, and discovered multiple new parameter configurations, which can trigger high cell polarization results in the original simulation model. We evaluated our results by comparing with the original simulation model outcomes as well as the findings from previous parameter analysis performed by our experts.", "keywords": "Surrogate modeling,Neural networks,Computational biology,Visual analysis,Parameter analysis", "link": "http://dx.doi.org/10.1109/TVCG.2019.2934591", "refList": ["10.1080/13685538.2018.1484443", "10.1016/j.swevo.2011.05.001", "10.1109/tvcg.2017.2744683", "10.1109/21.97458", "10.1109/tvcg.2018.2864503", "10.1109/tvcg.2018.2864887", "10.1109/vast.2017.8585721", "10.3354/cr01213", "10.1016/j.paerosci.2005.02.001", "10.1038/nbt.3300", "10.1038/nature02771", "10.1111/j.1467-8659.2012.03108.x", "10.1145/2089094.2089101", "10.1109/tvcg.2013.147", "10.1016/j.ins.2012.10.039", "10.1109/tvcg.2018.2864843", "10.1109/tvcg.2018.2865051", "10.1029/2011wr011527", "10.1109/tvcg.2018.2864499", "10.1007/bf00547132", "10.1109/tvcg.2018.2865044", "10.1109/tvcg.2018.2816223", "10.1109/tvcg.2018.2865026", "10.1109/tvcg.2018.2864504", "10.1111/j.1467-8659.2011.01940.x", "10.1016/j.dsp.2017.10.011", "10.1109/tvcg.2014.2346321", "10.1007/978-3-319-14445-0\\_9", "10.1038/89044", "10.1109/tvcg.2018.2865029", "10.1109/tvcg.2017.2764895", "10.1109/tvcg.2017.2744718", "10.1109/tvcg.2017.2744878", "10.1080/14786435.2010.546377", "10.1177/003754979205800610", "10.5555/3045390.3045502", "10.1109/tvcg.2019.2903943", "10.1109/tvcg.2018.2864500", "10.1109/tvcg.2017.2744158", "10.1109/iccv.2013.8", "10.1016/j.jneumeth.2016.10.008", "10.1111/j.1467-8659.2009.01684.x", "10.1111/cgf.13092", "10.1145/1081870.1081886", "10.1109/tvcg.2016.2598830", "10.1109/tvcg.2009.23", "10.1109/tvcg.2016.2598869", "10.1038/ncomms13890", "10.1109/tvcg.2016.2598831"], "wos": 1, "children": [{"doi": "10.1111/cgf.14034", "year": "2020", "title": "The State of the Art in Enhancing Trust in Machine Learning Models with the Use of Visualizations", "conferenceName": "EuroVis", "authors": "Angelos Chatzimparmpas;Rafael Messias Martins;Ilir Jusufi;Kostiantyn Kucher;Fabrice Rossi;Andreas Kerren", "citationCount": "2", "affiliation": "Chatzimparmpas, A (Corresponding Author), Linnaeus Univ, Dept Comp Sci \\& Media Technol, Vaxjo, Sweden.\nChatzimparmpas, A.; Martins, R. M.; Jusufi, I.; Kucher, K.; Kerren, A., Linnaeus Univ, Dept Comp Sci \\& Media Technol, Vaxjo, Sweden.\nRossi, F., PSL Univ, Univ Paris Dauphine, Ceremade, Paris, France.", "countries": "Sweden;France", "abstract": "Machine learning (ML) models are nowadays used in complex applications in various domains, such as medicine, bioinformatics, and other sciences. Due to their black box nature, however, it may sometimes be hard to understand and trust the results they provide. This has increased the demand for reliable visualization tools related to enhancing trust in ML models, which has become a prominent topic of research in the visualization community over the past decades. To provide an overview and present the frontiers of current research on the topic, we present a State-of-the-Art Report (STAR) on enhancing trust in ML models with the use of interactive visualization. We define and describe the background of the topic, introduce a categorization for visualization techniques that aim to accomplish this goal, and discuss insights and opportunities for future research directions. Among our contributions is a categorization of trust against different facets of interactive ML, expanded and improved from previous research. Our results are investigated from different analytical perspectives: (a) providing a statistical overview, (b) summarizing key findings, (c) performing topic analyses, and (d) exploring the data sets used in the individual papers, all with the support of an interactive web-based survey browser. We intend this survey to be beneficial for visualization researchers whose interests involve making ML models more trustworthy, as well as researchers and practitioners from other disciplines in their search for effective visualization techniques suitable for solving their tasks with confidence and conveying meaning to their data.", "keywords": "trustworthy machine learning; visualization; interpretable machine learning; explainable machine learning", "link": "https://doi.org/10.1111/cgf.14034", "refList": ["10.1109/mcg.2018.2878902", "10.1109/tvcg.2008.153", "10.2312/mlvis.20181130", "10.1109/tvcg.2016.2598828", "10.1145/3290605.3300911", "10.1145/2993901.2993909", "10.2312/mlvis.20191158", "10.1109/tvcg.2016.2598446", "10.1111/j.1467-8659.2009.01475.x", "10.1145/3290605.3300809", "10.1109/pacificvis.2018.00031", "10.1055/s-0029-1216348", "10.1007/978-3-319-90403-0\\_13", "10.1109/tvcg.2017.2745085", "10.1111/j.1467-8659.2011.01938.x", "10.1007/978-3-319-54024-5\\_6", "10.1016/s0167-9473(01)00065-2", "10.1111/cgf.12895", "10.2312/eurovisshort.20141152.17", "10.2312/eurova.20151098.22", "10.1111/cgf.13667", "10.3115/1072228.1072378", "10.1109/tbdata.2018.2877350.16", "10.1109/lars.2009.5418323.25", "10.1109/tvcg.2017.2744878", "10.1016/j.combustflame.2005.09.018", "10.1016/j.cag.2014.01.006", "10.1109/tvcg.2016.2570755", "10.2312/mlvis.20191158.1,19", "10.1518/hfes.46.1.50.30392", "10.1145/3301275.3302280", "10.1145/3351095.3372834.1", "10.1016/s0377-2217(01)00264-8", "10.1111/cgf.13424", "10.1007/978-3-319-23485-4\\_53", "10.1007/978-94-007-0753-5\\_3623", "10.1109/tvcg.2013.101", "10.1111/cgf.12884", "10.1111/j.1467-8659.2010.01835.x", "10.1021/ci9901338", "10.4230/lipics.itcs:2017", "10.1109/mis.2013.24", "10.1109/tvcg.2014.2346482", "10.1109/tvcg.2018.2865230", "10.1073/pnas.1807180116", "10.1109/dsaa.2018.00018", "10.1109/tvcg.2009.153", "10.3115/1219840.1219855", "10.1109/tvcg.2018.2864812", "10.1109/tvcg.2018.2872577", "10.2312/trvis.20191183", "10.1109/cvpr:2004.383", "10.1109/vast.2008.4677350", "10.1145/302979.303001", "10.1109/tvcg.2018.2864499", "10.1111/cgf.13672", "10.1109/tvcg.2014.2346626", "10.23915/distill.00010.18", "10.1109/tvcg.2017.2744805", "10.2312/mlvis:20191160.18", "10.23915/distill:00016", "10.1109/pacificvis.2016.7465260", "10.1111/cgf.13683", "10.23915/distill.00016.19", "10.1145/32906053.300803.22", "10.1109/tvcg.2014.2346574", "10.1177/1473871615600010", "10.1109/tvcg.2016.2598831", "10.1145/3230623", "10.1109/visual.2019.8933744", "10.1145/2993901.2993915", "10.1016/j.visinf.2017.01.006", "10.1145/2993901.2993914", "10.1109/tvcg.2014.2346984", "10.1109/5.726791", "10.23915/distill.00010", "10.1109/tvcg.2018.2864825", "10.2307/2394164", "10.1109/tvcg.2017.2744458", "10.1145/2993901.2993917.28", "10.1111/cgf.13711", "10.1109/tvcg.2016.2598664", "10.2307/2530428", "10.1109/icdar.1997.620583", "10.1109/tvcg.2017.2744718", "10.1111/cgf.13425", "10.1109/tvcg.2019.2903943", "10.1145/1518701.1518895", "10.1109/tvcg.2018.2864838", "10.1145/62038.62043", "10.1111/j.1467-8659.2011.01920.x", "10.1145/3025171.3025208", "10.1145/355112.355124", "10.1109/vast.2010.5652398", "10.1109/tvcg.2014.2346578", "10.1145/3173574.3174209", "10.4178/epih/e2014008", "10.1109/beliv.2018.8634201.25,28", "10.1016/j.eswa.2007.12.020", "10.1111/cgf:13406", "10.1109/mcg.2011.103", "10.1631/fitee.1700808", "10.1109/tvcg.2017.2745158", "10.1073/pnas.0307752101", "10.1109/tvcg.2018.2816223", "10.1109/tvcg.2017.2745141", "10.1145/32232.32234", "10.1109/tvcg.2019.2934267", "10.1109/tvcg.2018.2864477", "10.1145/3132169", "10.2312/eurova.20151100.19", "10.1145/3172944.3172964", "10.1145/2601248.2601268", "10.1109/isai-nlp.2018.8693002.1", "10.1111/cgf.13404", "10.1007/s100320200071", "10.2312/trvis.20191183.16", "10.1111/cgf.12755", "10.1145/2702123.2702509", "10.1145/1401890.1402008.25", "10.1109/tvcg.2012.65", "10.1177/1473871617733996", "10.2312/trvis.20191187.7", "10.21236/ada273556", "10.1109/vast.2010.5652450", "10.1111/j.1467-8659.2011.01940.x", "10.1177/875647939000600106", "10.1109/tvcg.2017.2711030", "10.1016/j.immuni.2016.04.014", "10.1109/tvcg.2019.2934209", "10.1016/0095-0696(78)90006-2", "10.1016/j.jclinepi.2015.04.014", "10.1016/j.ress.2013.02.013", "10.1111/cgf.12640", "10.1145/1015330.1015388.25", "10.1111/j.1467-8659.2009.01468.x", "10.1145/1541880.1541882", "10.1109/vast.2011.6102453", "10.1016/s0008-8846(98)00165-3", "10.2312/trvis.20191186.7", "10.1007/s13748-013-0040-3", "10.1109/tvcg.2015.2467757", "10.1109/tbdata.2018.2877350", "10.1109/vast.2017.8585613", "10.1080/10556789208805504", "10.1109/vast.2012.6400484", "10.1145/3025171.3025181", "10.1007/978-3-319-90403-0\\_12", "10.1109/mcg.2019.2922592", "10.1021/ci000392t", "10.1109/vast.2007.4389000", "10.1111/cgf.13406.16", "10.1111/cgf.13684", "10.2312/eurovisshort.20161166.17", "10.2312/evs:20191168", "10.1145/3041021.3055135", "10.1145/3301275.3302265", "10.1613/jair.4135", "10.1109/tvcg.2018.2864500", "10.1109/tvcg.2017.2744158", "10.1109/ssci.2015.33", "10.1111/cgf.13453", "10.2312/pe/eurovast/eurova11/049-052", "10.1145/3025171.3025181.13", "10.1145/371920.372094", "10.1109/tvcg.2017.2744938", "10.1111/j.1467-8659.2012.03108.x", "10.1109/tvcg.2019.2934251", "10.1145/3290605.3300809.18", "10.1109/ldav.2016.7874305", "10.1109/vast.2016.7883514", "10.1109/iccv.2015.425", "10.1145/3301275.3302324", "10.1109/tnnls.2013.2292894", "10.1109/tvcg.2018.2865044", "10.1109/tvcg.2013.157", "10.1371/journal.pcbi.0020161", "10.1186/s12916-019-1426-2", "10.1109/10.867928", "10.1111/cgf.13217", "10.1109/mcg.2019.2919033", "10.1145/2993901.2993910", "10.1109/tvcg.2017.2744738", "10.2307/258792", "10.1111/cgf.12655", "10.1016/j.dss.2014.03.001", "10.1109/tvcg.2019.2904069", "10.1111/cgf.13205", "10.1002/mds.22340", "10.1109/tvcg.2019.2934595", "10.1287/inte.2018.0957", "10.1109/cvpr.2007.382974", "10.1109/tvcg.2012.280", "10.1145/2678025.2701399.13", "10.2312/mlvis.20181130.13", "10.2312/eurova.20181106.16", "10.1109/tvcg.2018.2864475", "10.2312/mlvis.20191160.18,22", "10.1007/978-1-4612-4026-6.25", "10.1109/cvpr.2006.42", "10.1145/3172944.3172950", "10.1109/cvpr.2004.383.25", "10.1109/tvcg.2019.2934812", "10.1609/aimag.v35i4.2513", "10.2312/trvis.20191185.7", "10.1111/j.1467-8659.2009.01684.x", "10.1371/journal.pone.0129126", "10.1111/cgf.13092", "10.1162/coli\\_a\\_00237", "10.1109/tvcg.2017.2744818", "10.1109/vast.2011.6102448", "10.1109/tvcg.2009.111", "10.1109/tvcg.2019.2934619", "10.1016/s0377-2217(01)00264-8.25", "10.1111/cgf.12639", "10.1109/access.2019.2919343", "10.1186/s12874-019-0681-4", "10.1109/pacificvis.2015.7156366", "10.1109/pacificvis.2018.00029", "10.1109/tvcg.2019.2934261", "10.1080/13506280444000102.http://www.uvt.nl/ticc", "10.1109/vast.2018.8802509", "10.1111/cgf.13212", "10.1145/3200489", "10.1111/cgf.13176", "10.1177/1473871620904671", "10.1007/978-3-319-10590-1\\_53", "10.1111/j.1467-8659.2012.03126.x", "10.1111/cgf.13172", "10.1145/3025171.3025208.6,21", "10.1111/cgf.12366", "10.1109/tvcg.2019.2934659", "10.1109/cvprw.2009.5206848", "10.1016/j.media.2014.11.010", "10.1109/tvcg.2017.2744683", "10.1109/tvcg.2019.2934262", "10.1016/j.neucom.2006.11.018", "10.1177/1473871615571951", "10.1371/journal.pcbi.0020161.25", "10.1177/1473871611415994", "10.2312/trvis20191187", "10.2312/eurova", "10.1145/2858036.2858529", "10.1145/2207676.2207738", "10.1007/s11042-009-0417-2", "10.1145/3301275.3302317", "10.1038/s41746-019-0148-3", "10.1145/3351095.3372834", "10.1080/10691898.2011.11889627", "10.1109/tvcg.2018.2864504", "10.1109/vast.2017.8585720", "10.1109/mcg.2018.053491732", "10.1007/s10994-010-5207-6", "10.1109/tvcg.2019.2934433", "10.1016/j.cag.2017.05.005", "10.1109/tvcg.2012.279", "10.1145/3231622.3231641.19,20", "10.1145/1562849.1562851", "10.1007/11564126\\_", "10.1109/tvcg.2018.2846735", "10.3115/1225403.1225421", "10.1109/vast.2012.6400486", "10.2312/eurova.20191116.22", "10.1109/tvcg.2007.70443", "10.1080/027868291009242", "10.2312/eurova.20151100", "10.1145/2939502.2939503.19", "10.1016/j.cag.2014.02.004", "10.1145/2939672.2939778", "10.1109/vast.2010.5652484", "10.1111/cgf.12641", "10.1145/3301275.3302289", "10.1109/visual.2019.8933619", "10.1109/tvcg.2017.2672987", "10.1109/vast.2016.7883517.20", "10.1109/igarss.2017.8127684", "10.1016/j.jcae.2010.04.002", "10.1109/vast.2010.5652885", "10.1016/j.visinf.2019.03.002", "10.1007/s00371-018-1500-3", "10.1109/mcg.2018.042731661", "10.1109/34.598228", "10.1109/tvcg.2018.2865027", "10.1016/j.neucom.2017.01.105", "10.1111/cgf.12389", "10.1109/tvcg.2019.2934591", "10.1109/vast.2010.5652392.16", "10.1111/cgf.13416", "10.1080/02701367.1992.10608764", "10.1109/vast.2017.8585721", "10.1109/tvcg.2018.2843369", "10.1109/sbes.2010.27", "10.1109/vast.2015.7347637", "10.1145/1401890.1402008", "10.1016/j.bpj.2010.04.064", "10.1109/tvcg.2013.125", "10.1109/isai-nlp.2018.8693002", "10.1371/journal.pone.0160127", "10.1145/2856767.2856779", "10.1145/2678025.2701399", "10.1109/vast.2011.6102451", "10.1109/mcg.2010.18", "10.1021/ci4000213", "10.1109/vast.2012.6400492", "10.1007/11564126-49.25", "10.2312/eurova.20171114", "10.1109/vast.2010.5652443", "10.1145/3134599", "10.2312/pe/eurovast/eurovast10/013-018.19", "10.1109/tvcg.2019.2903946", "10.1109/tvcg.2015.2467717", "10.1177/1473871612460526", "10.1016/j.cag.2018.09.018", "10.1109/tvcg.2016.2598838", "10.1145/3172944.3172964.14", "10.1109/vast.2009.5333428", "10.1109/vast.2014.7042480", "10.2312/pe/eurovast/eurovast10/013-018", "10.1177/0962280215588241", "10.1145/2993901.2993917", "10.1109/cvpr.2008:4587581", "10.1109/tvcg.2015.2467551", "10.1016/j.visinf.2018.09.001", "10.1126/science.290.5500.2319", "10.2312/eurova.20151107", "10.1109/visual.2019.8933695", "10.13140/2.1.2393.1847", "10.1197/jamia.m1929", "10.1109/cvpr.2008.4587581.25", "10.1145/1518701.1518895.16", "10.1109/vds.2017.8573444", "10.2312/trvis:20191185", "10.1145/3359786", "10.13140/2.1.1341.1520", "10.2312/pe/eurovast/eurova11/049-052.17", "10.1109/tvcg.2014.2346660", "10.1145/3185517", "10.1109/adprl.2011.5967372", "10.1109/tvcg.2015.2467591", "10.1111/j.1751-9004.2009.00232.x", "10.1136/qshc.2004.010033", "10.1109/vast.2012.6400493", "10.1109/tvcg.2019.2934266", "10.1145/2971763.2971775", "10.1111/cgf.13730", "10.1109/vast.2012.6400488", "10.1111/cgf.13210", "10.1109/tvcg.2019.2934631", "10.1145/3172944.3172965", "10.1057/ivs.2010.2", "10.1109/tvcg.2017.2745258", "10.1016/j.jbusres.2019.07.039", "10.1162/jmlr.2003.3.4-5.993", "10.1109/pacificvis.2019.00044", "10.2312/pe/eurovast/eurova12/037-041", "10.1109/tvcg.2019.2934629", "10.1177/0018720814547570", "10.1145/3292500.3330908", "10.1111/j.1467-8659.2009.01467.x", "10.2312/eurova.20151098", "10.1177/1473871617713337", "10.1109/lars:2009.5418323", "10.1109/vast.2011.6102437", "10.1111/cgf.12878", "10.1561/1500000001", "10.1145/3025171.3025222", "10.1007/s11704-016-6028-y", "10.1016/j.procs.2017.05.216", "10.1109/cvpr.2007.382974.25", "10.1080/10447318.2020.1741118", "10.1109/vast.2012.6400489", "10.1145/3025171.3025172", "10.1109/tvcg.2017.2744098", "10.1109/tvcg.2005.66", "10.1016/j.dss.2009.05.016", "10.1007/978-1-4612-4026-6", "10.2312/evs.20191168.16,20,28", "10.2312/pe/eurovast/eurova12/037-041.17", "10.1145/3290605.3300803", "10.1145/1015330.1015388", "10.1111/cgf.13197", "10.1016/b978-1-55860-377-6.50048-7", "10.1111/cgf.13681", "10.1109/tvcg.2017.2744378", "10.1109/tvcg.2017.2744358", "10.1109/vast.2008.4677352"], "wos": 1, "children": [{"doi": "10.1109/tvcg.2020.3030368", "title": "Implicit Multidimensional Projection of Local Subspaces", "year": "2020", "conferenceName": "InfoVis", "authors": "Rongzheng Bian;Yumeng Xue;Liang Zhou;Jian Zhang 0070;Baoquan Chen;Daniel Weiskopf;Yunhai Wang", "citationCount": "1", "affiliation": "Wang, YH (Corresponding Author), Shandong Univ, Qingdao, Peoples R China. Zhou, L (Corresponding Author), Univ Utah, Salt Lake City, UT 84112 USA. Bian, Rongzheng; Xue, Yumeng; Wang, Yunhai, Shandong Univ, Qingdao, Peoples R China. Chen, Baoquan, Peking Univ, Beijing, Peoples R China. Zhang, Jian, Chinese Acad Sci, CNIC, Beijing, Peoples R China. Zhou, Liang, Univ Utah, Salt Lake City, UT 84112 USA. Weiskopf, Daniel, Univ Stuttgart, Stuttgart, Germany.", "countries": "USA;Germany;China", "abstract": "We propose a visualization method to understand the effect of multidimensional projection on local subspaces, using implicit function differentiation. Here, we understand the local subspace as the multidimensional local neighborhood of data points. Existing methods focus on the projection of multidimensional data points, and the neighborhood information is ignored. Our method is able to analyze the shape and directional information of the local subspace to gain more insights into the global structure of the data through the perception of local structures. Local subspaces are fitted by multidimensional ellipses that are spanned by basis vectors. An accurate and efficient vector transformation method is proposed based on analytical differentiation of multidimensional projections formulated as implicit functions. The results are visualized as glyphs and analyzed using a full set of specifically-designed interactions supported in our efficient web-based visualization tool. The usefulness of our method is demonstrated using various multi- and high-dimensional benchmark datasets. Our implicit differentiation vector transformation is evaluated through numerical comparisons; the overall method is evaluated through exploration examples and use cases.", "keywords": "High-dimensional data visualization,dimensionality reduction,local linear subspaces,user interaction", "link": "http://dx.doi.org/10.1109/TVCG.2020.3030368", "refList": ["10.3844/jcssp.2018.613.622", "10.1016/j.aci.2018.08.003", "10.3390/info9030065", "10.1016/j.visinf.2018.09.003", "10.1371/journal.pone.0118432", "10.1016/s0893-6080(05)80023-1", "10.1109/tvcg.2020.2986996", "10.1109/icst.2012.56", "10.1007/s10844-013-0250-y", "10.1109/tbdata.2018", "10.1145/1125451.1125659", "10.1109/tvcg.2013.125", "10.1177/1473871611412817", "10.1145/3290605.3300911", "10.1111/cgf.14034", "10.1007/s13721-013-0034-x", "10.1016/j.procs.2017.05.216", "10.1016/j.ins.2009.08.025", "10.1109/tvcg.2013.124", "10.1109/tvcg.2018.2864499", "10.1109/tvcg.2018.2864475", "10.1080/10447318.2020.1741118", "10.1016/j.imu.2019.100203", "10.1109/tvcg.2018.2865240", "10.1186/s12864-019-6413-7", "10.1109/tvcg.2015.2467551", "10.1002/widm.1249", "10.1007/978-3-319-66429-3\\_29", "10.1109/tvcg.2014.2346481", "10.1109/tvcg.2018.2864825", "10.1177/1473871620904671", "10.1109/tvcg.2019.2934267", "10.1136/bmjopen-2016-012799", "10.1109/smartgridcomm.2017.8340682", "10.1007/s10664-015-9401-9", "10.1145/1143844.1143874", "10.1111/cgf.12389", "10.1109/tvcg.2018.2872577", "10.1007/978-981-13-5802-9\\_20", "10.1016/j.ipm.2009.03.002", "10.5220/0006431602160222", "10.1109/mcg.2015.50", "10.1109/tvcg.2014.2346574", "10.1007/bf02289565", "10.1109/tvcg.2017.2744378", "10.1016/j.patrec.2008.08.010", "10.1023/a:1010933404324", "10.9735/2229-3981"], "wos": 1, "children": [], "len": 1}, {"doi": "10.1109/tvcg.2020.3030465", "title": "Visual Causality Analysis of Event Sequence Data", "year": "2020", "conferenceName": "VAST", "authors": "Zhuochen Jin;Shunan Guo;Nan Chen;Daniel Weiskopf;David Gotz;Nan Cao", "citationCount": "0", "affiliation": "Cao, N (Corresponding Author), Tongji Univ, IDVx Lab, Shanghai, Peoples R China. Jin, Zhuochen; Guo, Shunan; Chen, Nan; Cao, Nan, Tongji Univ, IDVx Lab, Shanghai, Peoples R China. Weiskopf, Daniel, Univ Stuttgart, Stuttgart, Germany. Gotz, David, Univ N Carolina, Chapel Hill, NC 27515 USA.", "countries": "USA;Germany;China", "abstract": "Causality is crucial to understanding the mechanisms behind complex systems and making decisions that lead to intended outcomes. Event sequence data is widely collected from many real-world processes, such as electronic health records, web clickstreams, and financial transactions, which transmit a great deal of information reflecting the causal relations among event types. Unfortunately, recovering causalities from observational event sequences is challenging, as the heterogeneous and high-dimensional event variables are often connected to rather complex underlying event excitation mechanisms that are hard to infer from limited observations. Many existing automated causal analysis techniques suffer from poor explainability and fail to include an adequate amount of human knowledge. In this paper, we introduce a visual analytics method for recovering causalities in event sequence data. We extend the Granger causality analysis algorithm on Hawkes processes to incorporate user feedback into causal model refinement. The visualization system includes an interactive causal analysis framework that supports bottom-up causal exploration, iterative causal verification and refinement, and causal comparison through a set of novel visualizations and interactions. We report two forms of evaluation: a quantitative evaluation of the model improvements resulting from the user-feedback mechanism, and a qualitative evaluation through case studies in different application domains to demonstrate the usefulness of the system.", "keywords": "Event sequence data,causality analysis,visual analytics", "link": "http://dx.doi.org/10.1109/TVCG.2020.3030465", "refList": ["10.5555/1642718", "10.1109/tvcg.2018.2865022", "10.5555/2074094.2074151", "10.1109/tvcg.2016.2618797", "10.1073/pnas.1320645111", "10.1109/tvcg.2017.2744843", "10.1109/iv.2017.69", "10.1109/tvcg.2019.2934399", "10.1145/3172944.3173007", "10.5555/1795555", "10.1109/mcg.2005.102", "10.1145/381641.381653", "10.1162/153244301753344614", "10.1111/cgf.14034", "10.1111/cgf.13198", "10.1017/cbo9780511519857", "10.1007/s10462-016-9475-9", "10.1075/ssol.2.2.07bor", "10.1007/978-1-4614-3223-4\\_3", "10.1109/infvis.2003.1249025", "10.1007/978-94-007-6094-313", "10.1145/2858036.2858387", "10.1109/tvcg.2007.70528", "10.1109/tvcg.2017.2674958", "10.1147/sj.454.0801", "10.1109/tvcg.2013.119", "10.1145/3173574.3173711", "10.1016/j.erss.2017.06.034", "10.1109/visual.2019.8933695", "10.1007/s11665-016-2173-6", "10.1016/0377-0427(87)90125-7", "10.2307/3601125", "10.1016/b978-0-444-88738-2.50018-x", "10.1109/mcg.2006.70", "10.1109/tvcg.2018.2865145", "10.1017/s1351324997001502", "10.1109/tvcg.2010.179", "10.1214/aos/1176344552", "10.1109/mcg.2009.22", "10.1007/978-3-319-26633-6\\_13", "10.1080/10447318.2014.905422", "10.1016/j.visinf.2019.03.004", "10.1057/palgrave.ivs.9500074", "10.1007/978-1-4614-3223-4"], "wos": 1, "children": [], "len": 1}], "len": 5}], "len": 7}, {"doi": "10.1109/tvcg.2019.2934264", "title": "The Validity, Generalizability and Feasibility of Summative Evaluation Methods in Visual Analytics", "year": "2019", "conferenceName": "VAST", "authors": "Mosab Khayat;Morteza Karimzadeh;David S. Ebert;Arif Ghafoor", "citationCount": "1", "affiliation": "Khayat, M (Corresponding Author), Purdue Univ, W Lafayette, IN 47907 USA. Khayat, Mosab; Karimzadeh, Morteza; Ebert, David S.; Ghafoor, Arif, Purdue Univ, W Lafayette, IN 47907 USA. Karimzadeh, Morteza, Univ Colorado, Boulder, CO 80309 USA.", "countries": "USA", "abstract": "Many evaluation methods have been used to assess the usefulness of Visual Analytics (VA) solutions. These methods stem from a variety of origins with different assumptions and goals, which cause confusion about their proofing capabilities. Moreover, the lack of discussion about the evaluation processes may limit our potential to develop new evaluation methods specialized for VA. In this paper, we present an analysis of evaluation methods that have been used to summatively evaluate VA solutions. We provide a survey and taxonomy of the evaluation methods that have appeared in the VAST literature in the past two years. We then analyze these methods in terms of validity and generalizability of their findings, as well as the feasibility of using them. We propose a new metric called summative quality to compare evaluation methods according to their ability to prove usefulness, and make recommendations for selecting evaluation methods based on their summative quality in the VA domain.", "keywords": "Summative evaluation,usefulness,evaluation process,taxonomy,visual analytics", "link": "http://dx.doi.org/10.1109/TVCG.2019.2934264", "refList": ["10.1109/tvcg.2017.2744478", "10.1109/tvcg.2018.2865025", "10.1109/tvcg.2006.85", "10.1109/tvcg.2014.2346331", "10.1109/beliv.2018.8634420", "10.1109/tvcg.2017.2745181", "10.1111/cgf.13677", "10.1109/tvcg.2018.2864844", "10.1109/tvcg.2013.126", "10.1109/tvcg.2018.2864811", "10.1109/infvis.2005.1532147", "10.1177/0956797613504966", "10.1145/2669557.2669579", "10.1109/mcg.2005.102", "10.1109/visual.2003.1250426", "10.1136/bmj.39489.470347.ad", "10.1109/tvcg.2017.2744080", "10.1109/mcg.2009.53", "10.1111/j.1467-8527.2005.00307.x", "10.1109/tvcg.2010.132", "10.1109/tvcg.2018.2864886", "10.1109/tvcg.2018.2864843", "10.1109/tvcg.2018.2865028", "10.1109/tvcg.2018.2865051", "10.1109/tvcg.2018.2865044", "10.1109/tvcg.2018.2865026", "10.1007/978-3-540-71080-6\\_6", "10.1109/tvcg.2018.2865020", "10.1177/1473871611407399", "10.1109/tvcg.2018.2864504", "10.1109/tvcg.2018.2864526", "10.1109/tvcg.2005.53", "10.1109/tvcg.2018.2864905", "10.1049/sej.1991.0040", "10.1109/tvcg.2015.2513410", "10.1109/tvcg.2017.2711030", "10.1109/tvcg.2011.279", "10.1109/vast.2017.8585505", "10.1147/jrd.2010.2042914", "10.1016/s0378-7206(98)00044-5", "10.1145/2993901.2993913", "10.1109/tvcg.2018.2865041", "10.1109/tvcg.2018.2864812", "10.1109/tvcg.2017.2744758", "10.1145/1168149.1168158", "10.1109/tvcg.2017.2745279", "10.1109/tvcg.2012.213", "10.1109/tvcg.2017.2744738", "10.1109/tvcg.2017.2745083", "10.1109/tvcg.2018.2864826", "10.1145/1377966.1377974", "10.1109/apec.2009.4802646", "10.1145/1168149.1168152", "10.1016/j.jss.2008.03.059", "10.1109/vast.2017.8585484", "10.1109/tvcg.2017.2744818", "10.1109/tvcg.2017.2744358", "10.1109/tvcg.2018.2864499", "10.1109/tvcg.2018.2865042", "10.1109/tvcg.2017.2744898"], "wos": 1, "children": [{"doi": "10.1109/tvcg.2020.3030388", "title": "Visualization of Human Spine Biomechanics for Spinal Surgery", "year": "2020", "conferenceName": "SciVis", "authors": "Pepe Eulzer;Sabine Bauer;Francis Kilian;Kai Lawonn", "citationCount": "0", "affiliation": "Eulzer, P (Corresponding Author), Univ Jena, Jena, Germany. Eulzer, Pepe; Lawonn, Kai, Univ Jena, Jena, Germany. Bauer, Sabine, Univ Koblenz Landau, Koblenz, Germany. Kilian, Francis, Cath Clin Koblenz Montabaur, Dept Spine Surg, Koblenz, Germany.", "countries": "Germany", "abstract": "We propose a visualization application, designed for the exploration of human spine simulation data. Our goal is to support research in biomechanical spine simulation and advance efforts to implement simulation-backed analysis in surgical applications. Biomechanical simulation is a state-of-the-art technique for analyzing load distributions of spinal structures. Through the inclusion of patient-specific data, such simulations may facilitate personalized treatment and customized surgical interventions. Difficulties in spine modelling and simulation can be partly attributed to poor result representation, which may also be a hindrance when introducing such techniques into a clinical environment. Comparisons of measurements across multiple similar anatomical structures and the integration of temporal data make commonly available diagrams and charts insufficient for an intuitive and systematic display of results. Therefore, we facilitate methods such as multiple coordinated views, abstraction and focus and context to display simulation outcomes in a dedicated tool. $\\mathrm{By}$ linking the result data with patient-specific anatomy, we make relevant parameters tangible for clinicians. Furthermore, we introduce new concepts to show the directions of impact force vectors, which were not accessible before. We integrated our toolset into a spine segmentation and simulation pipeline and evaluated our methods with both surgeons and biomechanical researchers. When comparing our methods against standard representations that are currently in use, we found increases in accuracy and speed in data exploration tasks. $\\mathrm{in}$ a qualitative review, domain experts deemed the tool highly useful when dealing with simulation result data, which typically combines time-dependent patient movement and the resulting force distributions on spinal structures.", "keywords": "Medical visualization,bioinformatics,coordinated views,focus and context,biomechanical simulation", "link": "http://dx.doi.org/10.1109/TVCG.2020.3030388", "refList": ["10.1109/tvcg.2018.2864903", "10.1177/1473871613510429", "10.1093/ehjqcco/qcz052", "10.1109/tvcg.2007.70594", "10.1109/tvcg.2018.2865076", "10.1055/s-0039-1687862", "10.1109/visual.1990.146375", "10.1109/tvcg.2017.2744198", "10.1016/j.ijmedinf.2014.10.001", "10.1109/tvcg.2013.124", "10.1016/j.jacc", "10.1111/cgf.13167", "10.17705/1thci.00055", "10.1136/bmjqs.2009.037895", "10.1109/tvcg.2013.238", "10.1109/tvcg.2018.2865240", "10.1186/1471-2261-6-34", "10.1109/tvcg.2019.2934264", "10.1109/tvcg.2013.200", "10.1109/tvcg.2011.209", "10.1109/tvcg.2014.2346682", "10.1109/tvcg.2015.2467091", "10.1136/bmjopen-2019-033208", "10.1109/beliv.2018.8634027", "10.1109/tvcg.2012.213", "10.1109/tvcg.2015.2467191", "10.1109/tvcg.2015.2467325", "10.1145/2133806.2133821", "10.1145/1806799.1806866", "10.1108/02635570610688869", "10.1002/hbm.20701", "10.1561/1100000039", "10.1145/3025453.3025645", "10.1109/tvcg.2009.111", "10.1109/tvcg.2013.120", "10.1109/tvcg.2016.2599030"], "wos": 1, "children": [], "len": 1}], "len": 3}, {"doi": "10.1109/tvcg.2020.3030443", "title": "CAVA: A Visual Analytics System for Exploratory Columnar Data Augmentation Using Knowledge Graphs", "year": "2020", "conferenceName": "VAST", "authors": "Dylan Cashman;Shenyu Xu;Subhajit Das;Florian Heimerl;Cong Liu;Shah Rukh Humayoun;Michael Gleicher;Alex Endert;Remco Chang", "citationCount": "0", "affiliation": "Cashman, D (Corresponding Author), Tufts Univ, Medford, MA 02155 USA. Cashman, Dylan; Liu, Cong; Chang, Remco, Tufts Univ, Medford, MA 02155 USA. Xu, Shenyu; Das, Subhajit; Endert, Alex, Georgia Tech, Atlanta, GA USA. Heimerl, Florian; Gleicher, Michael, Univ Wisconsin, Madison, WI 53706 USA. Humayoun, Shah Rukh, San Francisco State Univ, San Francisco, CA 94132 USA.", "countries": "USA", "abstract": "Most visual analytics systems assume that all foraging for data happens before the analytics process; once analysis begins, the set of data attributes considered is fixed. Such separation of data construction from analysis precludes iteration that can enable foraging informed by the needs that arise in-situ during the analysis. The separation of the foraging loop from the data analysis tasks can limit the pace and scope of analysis. In this paper, we present CAVA, a system that integrates data curation and data augmentation with the traditional data exploration and analysis tasks, enabling information foraging in-situ during analysis. Identifying attributes to add to the dataset is difficult because it requires human knowledge to determine which available attributes will be helpful for the ensuing analytical tasks. CAVA crawls knowledge graphs to provide users with a a broad set of attributes drawn from external data to choose from. Users can then specify complex operations on knowledge graphs to construct additional attributes. CAVA shows how visual analytics can help users forage for attributes by letting users visually explore the set of available data, and by serving as an interface for query construction. It also provides visualizations of the knowledge graph itself to help users understand complex joins such as multi-hop aggregations. We assess the ability of our system to enable users to perform complex data combinations without programming in a user study over two datasets. We then demonstrate the generalizability of CAVA through two additional usage scenarios. The results of the evaluation confirm that CAVA is effective in helping the user perform data foraging that leads to improved analysis outcomes, and offer evidence in support of integrating data augmentation as a part of the visual analytics pipeline.", "keywords": "Visual Analytics,Information Foraging,Data Augmentation", "link": "http://dx.doi.org/10.1109/TVCG.2020.3030443", "refList": ["10.1057/palgrave.ivs.9500122", "10.1109/tvcg.2016.2598867", "10.1111/cgf.13708", "10.1109/tvcg.2019.2934799", "10.1109/tvcg.2019.2934541", "10.1109/tvcg.2013.65", "10.1109/tvcg.2018.2875702", "10.1109/iv.2004.1320207", "10.1068/p260471", "10.1145/1778765.1778816", "10.1109/tvcg.2018.2808489", "10.1109/tvcg.2018.2864912", "10.1016/j.apgeog.2015.12.006", "10.1111/j.1467-8659.2011.01960.x", "10.1109/tvcg.2018.2864843", "10.1109/pacificvis.2010.5429604", "10.1109/tvcg.2014.2346898", "10.1109/5.726791", "10.1177/1475090214540874", "10.1109/icde.2016.7498287", "10.1145/1556262.1556289", "10.1109/tvcg.2007.70535", "10.1109/vast.2012.6400489", "10.1145/1056808.1056914", "10.1016/j.neucom.2014.09.063", "10.1145/7529.8927", "10.1109/tvcg.2016.2598495", "10.1109/tvcg.2016.2607204", "10.1109/vast47406.2019.8986943", "10.3758/bf03205986", "10.1109/infvis.2005.1532142", "10.1145/1150402.1150479", "10.1109/tvcg.2017.2674978", "10.1109/tvcg.2019.2945960", "10.1109/tvcg.2017.2744098", "10.1109/tvcg.2017.2674999", "10.1109/tvcg.2011.279", "10.1109/tvcg.2014.2346594", "10.1109/tvcg.2017.2744184", "10.1111/cgf.12876", "10.1007/s4095-020-0191-7", "10.1007/s11390-015-1535-0", "10.1111/cgf.12640", "10.1109/tvcg.2016.2598667", "10.1111/cgf.13683", "10.1109/tvcg.2013.153", "10.1109/tvcg.2019.2934208", "10.1109/tvcg.2019.2934655", "10.1111/cgf.12655", "10.1007/s11023-010-9221-z", "10.1109/vast.2012.6400487", "10.1145/2702123.2702585", "10.1007/bf00310175", "10.1109/tvcg.2017.2744378", "10.1103/physreve.64.061907", "10.1109/ldav.2017.8231848", "10.1109/tvcg.2016.2598831"], "wos": 1, "children": [], "len": 1}, {"doi": "10.1109/tvcg.2020.3030432", "title": "Evaluation of Sampling Methods for Scatterplots", "year": "2020", "conferenceName": "VAST", "authors": "Jun Yuan;Shouxing Xiang;Jiazhi Xia;Lingyun Yu;Shixia Liu", "citationCount": "0", "affiliation": "Liu, SX (Corresponding Author), Tsinghua Univ, BNRist, Beijing, Peoples R China. Yuan, Jun; Xiang, Shouxing; Liu, Shixia, Tsinghua Univ, BNRist, Beijing, Peoples R China. Xia, Jiazhi, Cent South Univ, Changsha, Peoples R China. Yu, Lingyun, Xian Jiaotong Liverpool Univ, Suzhou, Peoples R China.", "countries": "China", "abstract": "Given a scatterplot with tens of thousands of points or even more, a natural question is which sampling method should be used to create a small but \u201cgood\u201d scatterplot for a better abstraction. We present the results of a user study that investigates the influence of different sampling strategies on multi-class scatterplots. The main goal of this study is to understand the capability of sampling methods in preserving the density, outliers, and overall shape of a scatterplot. To this end, we comprehensively review the literature and select seven typical sampling strategies as well as eight representative datasets. We then design four experiments to understand the performance of different strategies in maintaining: 1) region density; 2) class density; 3) outliers; and 4) overall shape in the sampling results. The results show that: 1) random sampling is preferred for preserving region density; 2) blue noise sampling and random sampling have comparable performance with the three multi-class sampling strategies in preserving class density; 3) outlier biased density based sampling, recursive subdivision based sampling, and blue noise sampling perform the best in keeping outliers; and 4) blue noise sampling outperforms the others in maintaining the overall shape of a scatterplot.", "keywords": "Scatterplot,data sampling,empirical evaluation", "link": "http://dx.doi.org/10.1109/TVCG.2020.3030432", "refList": ["10.1057/palgrave.ivs.9500122", "10.1109/tvcg.2016.2598867", "10.1109/tvcg.2015.2467591", "10.1111/cgf.13708", "10.1109/tvcg.2019.2934799", "10.1109/tvcg.2019.2934541", "10.1109/tvcg.2013.65", "10.1109/iv.2004.1320207", "10.1068/p260471", "10.1145/1778765.1778816", "10.1109/tvcg.2018.2808489", "10.1109/tvcg.2018.2864912", "10.1016/j.apgeog.2015.12.006", "10.1111/j.1467-8659.2011.01960.x", "10.1109/tvcg.2018.2864843", "10.1109/pacificvis.2010.5429604", "10.1109/tvcg.2014.2346898", "10.1109/5.726791", "10.1177/1475090214540874", "10.1145/1556262.1556289", "10.1109/tvcg.2007.70535", "10.1109/vast.2012.6400489", "10.1145/1056808.1056914", "10.1016/j.neucom.2014.09.063", "10.1145/7529.8927", "10.1109/tvcg.2016.2607204", "10.1109/vast47406.2019.8986943", "10.3758/bf03205986", "10.1109/infvis.2005.1532142", "10.1145/1150402.1150479", "10.1109/tvcg.2017.2674978", "10.1109/tvcg.2017.2744098", "10.1109/tvcg.2017.2674999", "10.1109/tvcg.2011.279", "10.1109/tvcg.2014.2346594", "10.1109/tvcg.2017.2744184", "10.1111/cgf.12876", "10.1109/1011101.2019.2945960", "10.1007/s4095-020-0191-7", "10.1007/s11390-015-1535-0", "10.1111/cgf.12640", "10.1109/tvcg.2016.2598667", "10.1111/cgf.13683", "10.1109/tvcg.2013.153", "10.1109/tvcg.2019.2934208", "10.1109/tvcg.2019.2934655", "10.1111/cgf.12655", "10.1007/s11023-010-9221-z", "10.1109/vast.2012.6400487", "10.1145/2702123.2702585", "10.1007/bf00310175", "10.1109/tvcg.2017.2744378", "10.1103/physreve.64.061907", "10.1109/ldav.2017.8231848", "10.1109/tvcg.2016.2598831"], "wos": 1, "children": [], "len": 1}, {"doi": "10.1111/cgf.13973", "year": "2020", "title": "Classifier-Guided Visual Correction of Noisy Labels for Image Classification Tasks", "conferenceName": "EuroVis", "authors": "Alex B{\\\"{a}}uerle;Heiko Neumann;Timo Ropinski", "citationCount": "0", "affiliation": "Bauerle, A (Corresponding Author), Ulm Univ, Ulm, Germany.\nBaeuerle, A.; Neumann, H.; Ropinski, T., Ulm Univ, Ulm, Germany.", "countries": "Germany", "abstract": "Training data plays an essential role in modern applications of machine learning. However, gathering labeled training data is time-consuming. Therefore, labeling is often outsourced to less experienced users, or completely automated. This can introduce errors, which compromise valuable training data, and lead to suboptimal training results. We thus propose a novel approach that uses the power of pretrained classifiers to visually guide users to noisy labels, and let them interactively check error candidates, to iteratively improve the training data set. To systematically investigate training data, we propose a categorization of labeling errors into three different types, based on an analysis of potential pitfalls in label acquisition processes. For each of these types, we present approaches to detect, reason about, and resolve error candidates, as we propose measures and visual guidance techniques to support machine learning users. Our approach has been used to spot errors in well-known machine learning benchmark data sets, and we tested its usability during a user evaluation. While initially developed for images, the techniques presented in this paper are independent of the classification algorithm, and can also be extended to many other types of training data.", "keywords": "", "link": "https://doi.org/10.1111/cgf.13973", "refList": ["10.1109/tvcg.2017.2744683", "10.1145/2818048.2820016", "10.1145/2441776.2441848", "10.1109/tvcg.2016.2598828", "10.1145/2254556.2254659", "10.1002/acp.3140", "10.1109/cvpr.2018.00582", "10.1145/130385.130417", "10.1109/vast.2016.7883508", "10.1109/tvcg.2018.2864843", "10.1145/1401890.1401965", "10.1007/s10618-013-0306-1", "10.1145/2702123.2702553", "10.1109/cvpr.2018.00571", "10.1109/tvcg.2012.277", "10.1109/tip.2003.819861", "10.1111/cgf.13406", "10.1007/978-3-319-63859-1\\_1", "10.1109/tvcg.2013.164", "10.1007/s10462-010-9156-z", "10.1109/tvcg.2014.2346660", "10.1109/cbms.2006.65", "10.1109/itsc.2019.8917021", "10.1145/3025453.3026044"], "wos": 1, "children": [], "len": 1}], "len": 25}, {"doi": "10.1111/cgf.14035", "year": "2020", "title": "Survey on the Analysis of User Interactions and Visualization Provenance", "conferenceName": "EuroVis", "authors": "Kai Xu;Alvitta Ottley;Conny Walchshofer;Marc Streit;Remco Chang;John E. Wenskovitch", "citationCount": "0", "affiliation": "Xu, K (Corresponding Author), Middlesex Univ, London, England.\nXu, Kai, Middlesex Univ, London, England.\nOttley, Alvitta, Washington Univ, St Louis, MO 63110 USA.\nWalchshofer, Conny; Streit, Marc, Johannes Kepler Univ Linz, Linz, Austria.\nChang, Remco, Tufts Univ, Medford, MA 02155 USA.\nWenskovitch, John, Virginia Tech, Blacksburg, VA USA.", "countries": "USA;England;Austria", "abstract": "There is fast-growing literature on provenance-related research, covering aspects such as its theoretical framework, use cases, and techniques for capturing, visualizing, and analyzing provenance data. As a result, there is an increasing need to identify and taxonomize the existing scholarship. Such an organization of the research landscape will provide a complete picture of the current state of inquiry and identify knowledge gaps or possible avenues for further investigation. In this STAR, we aim to produce a comprehensive survey of work in the data visualization and visual analytics field that focus on the analysis of user interaction and provenance data. We structure our survey around three primary questions: (1) WHY analyze provenance data, (2) WHAT provenance data to encode and how to encode it, and (3) HOW to analyze provenance data. A concluding discussion provides evidence-based guidelines and highlights concrete opportunities for future development in this emerging area. The survey and papers discussed can be explored online interactively at https://provenance-survey.caleydo.org.", "keywords": "", "link": "https://doi.org/10.1111/cgf.14035", "refList": ["10.1145/3186266", "10.1145/3185524", "10.1109/tvcg.2014.2346575", "10.1109/tvcg.2016.2598471", "10.1109/tvcg.2016.2598446", "10.1145/2856767.2856779", "10.1109/tvcg.2017.2745278", "10.1109/tvcg.2015.2467871", "10.1109/tvcg.2019.2934668", "10.1145/3301275.3302307", "10.1145/2207676.2208293", "10.1111/cgf.13402", "10.1111/cgf.12895", "10.1145/1084805.1084812", "10.1145/2983923", "10.1007/978-1-4419-5874-7\\_12", "10.1109/mcg.2010.18", "10.1109/tvcg.2015.2467153", "10.1109/tvcg.2013.211", "10.1145/3172944.3172964", "10.1145/3290605.3300360", "10.1109/tvcg.2009.199", "10.1109/vast.2016.7883515", "10.1145/2207676.2208412", "10.1145/1979742.1979570", "10.1145/2207676.2208565", "10.1109/tvcg.2017.2745078", "10.1109/tvcg.2013.226", "10.1145/3301275.3302270", "10.1145/2882903.2882919", "10.1109/tvcg.2013.132", "10.1007/978-1-4614-3223-4\\_6", "10.1007/978-1-4899-7993-3\\_80747-1", "10.1145/2449396.2449439", "10.4230/dagrep.8.11.35", "10.1111/cgf.13424", "10.1109/tvcg.2015.2467613", "10.1109/mcse.2007.106", "10.1109/vast.2014.7042486", "10.1145/3126594.3126653", "10.1145/2591510", "10.1109/vast.2017.8585665", "10.1109/tvcg.2017.2744684", "10.1109/vast.2009.5333564", "10.1111/cgf.12631", "10.1145/2702123.2702262", "10.1111/cgf.13717", "10.2312/evs.20191181", "10.1111/cgf.12925", "10.1145/2702123.2702590", "10.1109/tvcg.2015.2467551", "10.1145/3025171.3025187", "10.1145/3316416.3316418", "10.1109/tvcg.2015.2468078", "10.1109/mcg.2014.73", "10.1109/tvcg.2017.2744479", "10.1109/tvcg.2018.2859969", "10.1109/tvcg.2014.2346321", "10.1109/tvcg.2007.70589", "10.1007/s13218-012-0167-6", "10.1111/cgf.13670", "10.1145/2807442.2807478", "10.1111/cgf.13715", "10.1109/tvcg.2012.23", "10.1109/tvcg.2017.2745279", "10.1109/tvcg.2013.164", "10.1109/vast.2008.4677365", "10.1145/3301275.3302291", "10.1109/tvcg.2012.260", "10.1109/tvcg.2010.177", "10.1109/tvcg.2018.2865024", "10.1109/mcg.2015.51", "10.1145/2240236.2240260", "10.1109/tvcg.2016.2599030.2", "10.1109/tvcg.2007.70515", "10.1109/tvcg.2012.175", "10.1109/mcg.2019.2941856", "10.1109/tvcg.2008.137", "10.1016/j.visinf.2018.09.003", "10.4304/jmm.9.5.635-643", "10.1109/tvcg.2017.2744843", "10.1111/cgf.13405", "10.1145/2633043", "10.1109/tvcg.2009.129", "10.1109/tvcg.2019.2934609", "10.1111/cgf.12924", "10.1145/2702123.2702376", "10.1109/vast.2017.8585669", "10.1145/1502650.1502695", "10.1111/cgf.13730", "10.1109/tvcg.2013.124", "10.1109/tvcg.2017.2744805", "10.1109/mcg.2009.49", "10.1109/vast.2015.7347625", "10.1145/3009973", "10.1145/2470654.2470723", "10.1109/vast.2016.7883520", "10.1109/vast.2014.7042492", "10.1145/2984511.2984588", "10.1111/cgf.12391", "10.1561/1900000006", "10.1007/s00778-017-0486-1", "10.1109/vast.2009.5333020", "10.1145/1926385.1926423", "10.1145/1057977.1057978", "10.1145/3290605.3300892", "10.1111/j.1467-8659.2011.01928.x", "10.1109/tvcg.2013.188", "10.1109/tvcg.2015.2467191", "10.1109/iccicct.2014.6993023", "10.1145/3290605.3300874", "10.1145/2557500.2557524", "10.1109/mcg.2015.91", "10.1109/vast.2012.6400494", "10.1109/tvcg.2013.220", "10.1109/mcg.2019.2945378", "10.1109/vast.2012.6400486", "10.1109/tvcg.2018.2865158", "10.1109/tvcg.2016.2598839", "10.1145/1142473.1142574", "10.1177/1555343416672782", "10.1109/vast.2011.6102449", "10.1111/cgf.12090", "10.1109/vast.2016.7883518", "10.1111/cgf.13678", "10.1109/mcg.2009.53", "10.1109/tvcg.2014.2346250", "10.1109/tvcg.2016.2598797", "10.1111/cgf.13400", "10.1109/tvcg.2014.2346573", "10.1080/01431160600746456", "10.1145/2642918.2647378", "10.1109/mcg.2019.2945720", "10.1145/2207676.2207741", "10.1145/3025171.3025189", "10.1145/634067.634292", "10.1109/tvcg.2015.2467611", "10.1109/tit.1982.1056489", "10.1109/tvcg.2018.2865117", "10.1109/vast.2009.5333023", "10.1145/3332165.3347866", "10.1109/mcg.2019.2933419", "10.1145/3184900", "10.1109/tvcg.2012.273", "10.1109/vast.2010.5652885", "10.1109/vast.2015.7347627", "10.1145/3290605.3300803", "10.1109/tvcg.2012.258", "10.1109/mcg.2009.87", "10.1109/tvcg.2019.2934556", "10.1145/1869397.1869399", "10.1109/mcg.2015.50", "10.1145/3172944.3172979", "10.1111/cgf.13208", "10.1111/cgf.12619", "10.1145/3290605.3300358", "10.1109/vast.2008.4677352", "10.1109/tvcg.2016.2598468", "10.1109/vast.2016.7883519", "10.1109/mcse.2008.79"], "wos": 1, "children": [], "len": 1}, {"doi": "10.1111/cgf.13170", "year": "2017", "title": "Visual Comparison of Eye Movement Patterns", "conferenceName": "EuroVis", "authors": "Tanja Blascheck;Markus Schweizer;Fabian Beck;Thomas Ertl", "citationCount": "3", "affiliation": "Blascheck, T (Corresponding Author), Univ Stuttgart, Inst Visualizat \\& Interact Syst, Stuttgart, Germany.\nBlascheck, Tanja; Schweizer, Markus; Ertl, Thomas, Univ Stuttgart, Inst Visualizat \\& Interact Syst, Stuttgart, Germany.\nBeck, Fabian, Univ Duisburg Essen, Inst Comp Sci \\& Business Informat Syst, Essen, Germany.", "countries": "Germany", "abstract": "In eye tracking research, finding eye movement patterns and similar strategies between participants' eye movements is important to understand task solving strategies and obstacles. In this application paper, we present a graph comparison method using radial graphs that show Areas of Interest (AOIs) and their transitions. An analyst investigates a single graph based on dwell times, directed transitions, and temporal AOI sequences. Two graphs can be compared directly and temporal changes may be analyzed. A list and matrix approach facilitate the analyst to contrast more than two graphs guided by visually encoded graph similarities. We evaluated our approach in case studies with three eye tracking and visualization experts. They identified temporal transition patterns of eye movements across participants, groups of participants, and outliers.", "keywords": "", "link": "https://doi.org/10.1111/cgf.13170", "refList": ["10.1145/2857491.2857524", "10.1109/tvcg.2008.117", "10.1177/1473871611416549", "10.1109/tvcg.2015.2468111", "10.1111/cgf.12791", "10.1109/iv.2011.49", "10.1109/tvcg.2012.276", "10.1109/infvis.2001.963281", "10.1111/j.1467-8659.2011.01898.x", "10.1109/tvcg.2013.263", "10.1109/tvcg.2009.181", "10.1080/13875868.2016.1226839", "10.1109/tvcg.2015.2467871", "10.1109/vissoft.2013.6650549", "10.1145/2578153.2578175", "10.1109/iv.2009.108", "10.1177/1473871612455983", "10.1145/1743666.1743721", "10.1109/vast.2016.7883520", "10.1007/978-3-319-47024-5\\_7", "10.1016/b978-044451020-4/50035-9", "10.1109/iv.2016.28", "10.1109/tvcg.2014.2346677", "10.1145/2470654.2470724", "10.1016/s0169-8141(98)00068-7", "10.1109/tvcg.2007.70521", "10.1111/cgf.12115", "10.1145/2509315.2509326", "10.1109/pacificvis.2016.7465266", "10.1145/2669557.2669558", "10.1109/tvcg.2010.149", "10.1109/tvcg.2009.150", "10.1179/000870403235002042"], "wos": 1, "children": [{"doi": "10.1109/pacificvis.2019.00037", "year": "2019", "title": "A Visual Approach for the Comparative Analysis of Character Networks in Narrative Texts", "conferenceName": "PacificVis", "authors": "Markus John;Martin Baumann", "citationCount": "1", "affiliation": "John, M (Corresponding Author), Univ Stuttgart, Inst Visualizat \\& Interact Syst VIS, Stuttgart, Germany.\nJohn, Markus; Baumann, Martin; Schuetz, David; Koch, Steffen; Ertl, Thomas, Univ Stuttgart, Inst Visualizat \\& Interact Syst VIS, Stuttgart, Germany.", "countries": "Germany", "abstract": "The analysis of a novel's plot and characters are challenging and time-consuming tasks in literary criticism. Typically, humanities scholars want to describe and compare characters' personality traits, their roles, their relationships, and the evolution of these aspects over the course of a novel. Nowadays, due to the digitization of literature, humanities scholars can be supported in these endeavors with computational methods. In this paper, we present an approach that offers several means to analyze the plot and characters of a novel visually. Analysts can easily switch between an adjacency matrix and a node-link representation, which provide an overview of the characters and the relationships between them. Both views enable analysts to select different text ranges of the novel for studying the commonalities and differences of the character constellations within these ranges. We offer interactive visual representations to help investigate the relationships between the characters in more detail. Additionally, we link the visual representations with the novels' texts to support the inspection and verification of previously generated ideas and hypotheses. To demonstrate the benefits and limitations of our approach, we present two usage scenarios. The first one is based on a fictitious analysis and the second one discusses applications that were carried out during joint workshops with humanities scholars. Finally, we present and discuss the insights gained by an expert study and the design decisions of our approach.", "keywords": "Visual text analysis; document analysis; close reading; distant reading; digital humanities; graph comparison", "link": "https://doi.org/10.1109/PacificVis.2019.00037", "refList": ["10.1177/1473871611416549", "10.1145/2702123.2702476", "10.1111/cgf.13181", "10.1111/cgf.12791", "10.1111/cgf.13170", "10.1111/j.1467-8659.2011.01898.x", "10.1109/tvcg.2011.185", "10.1109/vast.2009.5333248", "10.1109/tvcg.2015.2467971", "10.1080/10447318.2010.516722", "10.1136/qshc.2004.010033", "10.1109/tvcg.2011.169", "10.3115/v1/p14-5010", "10.1109/tmm.2016.2614184", "10.1109/tvcg.2009.106", "10.1111/cgf.12124", "10.1109/iv.2016.28", "10.1145/2470654.2470724", "10.1057/palgrave.ivs.9500180", "10.1109/pacificvis.2011.5742388", "10.2190/ec.44.1.a", "10.13140/2.1.1341.1520", "10.1109/tvcg.2011.232", "10.1109/vast.2007.4389004", "10.1057/palgrave.ivs.9500092", "10.1007/978-0-85729-079-3"], "wos": 1, "children": [], "len": 1}], "len": 3}], "len": 33}, {"doi": "10.1109/tvcg.2018.2865022", "title": "VIS Author Profiles: Interactive Descriptions of Publication Records Combining Text and Visualization", "year": "2018", "conferenceName": "VAST", "authors": "Shahid Latif;Fabian Beck", "citationCount": "5", "affiliation": "Latif, S (Corresponding Author), Univ Duisburg Essen, Paluno, Duisburg, Germany. Latif, Shahid; Beck, Fabian, Univ Duisburg Essen, Paluno, Duisburg, Germany.", "countries": "Germany", "abstract": "Publication records and collaboration networks are important for assessing the expertise and experience of researchers. Existing digital libraries show the raw publication lists in author profiles, whereas visualization techniques focus on specific subproblems. Instead, we look at publication records from various perspectives mixing low-level publication data with high-level abstractions and background information. This work presents VIS Author Profiles, a novel approach to generate integrated textual and visual descriptions to highlight patterns in publication records. We leverage template-based natural language generation to summarize notable publication statistics, evolution of research topics, and collaboration relationships. Seamlessly integrated visualizations augment the textual description and are interactively connected with each other and the text. The underlying publication data and detailed explanations of the analysis are available on demand. We compare our approach to existing systems by taking into account information needs of users and demonstrate its usefulness in two realistic application examples.", "keywords": "Natural language generation,document visualization,interactive documents,sparklines,digital libraries", "link": "http://dx.doi.org/10.1109/TVCG.2018.2865022", "refList": ["10.1109/tvcg.2007.70582", "10.1109/tvcg.2014.2346435", "10.4304/jetwi.4.1.3-14", "10.1109/tvcg.2015.2467757", "10.1109/tvcg.2016.2610422", "10.1057/palgrave.ivs.9500156", "10.1016/0004-3702(93)90022-4", "10.1109/tvcg.2013.167", "10.3138/chr.694", "10.1109/tvcg.2012.252", "10.1007/978-94-009-7798-3\\_15", "10.1109/tvcg.2015.2468151", "10.1109/vissoft.2017.11", "10.1109/pacificvis.2016.7465279", "10.1109/tvcg.2017.2674958", "10.1109/icvrv.2016.88", "10.1109/tvcg.2015.2465151", "10.1145/2470654.2481374", "10.1613/jair.5477", "10.1109/tfuzz.2014.2328011", "10.1145/3025453.3025631", "10.1007/978-3-642-59830-2", "10.1109/tvcg.2014.2383380", "10.1162/coli\\_a\\_00091", "10.1063/1.4975416", "10.1109/cgiv.2006.20", "10.1002/int.21835", "10.1109/vast.2015.7347632", "10.1145/642611.642681", "10.1145/3173574.3174012", "10.2312/eurovisshort.20181084"], "wos": 1, "children": [{"doi": "10.1109/tvcg.2019.2934669", "title": "Exploranative Code Quality Documents", "year": "2019", "conferenceName": "VAST", "authors": "Haris Mumtaz;Shahid Latif;Fabian Beck;Daniel Weiskopf", "citationCount": "0", "affiliation": "Mumtaz, H (Corresponding Author), Univ Stuttgart, VISUS, Stuttgart, Germany. Mumtaz, Haris; Weiskopf, Daniel, Univ Stuttgart, VISUS, Stuttgart, Germany. Latif, Shahid; Beck, Fabian, Univ Duisburg Essen, Paluno, Duisburg, Germany.", "countries": "Germany", "abstract": "Good code quality is a prerequisite for efficiently developing maintainable software. In this paper, we present a novel approach to generate exploranative (explanatory and exploratory) data-driven documents that report code quality in an interactive, exploratory environment. We employ a template-based natural language generation method to create textual explanations about the code quality, dependent on data from software metrics. The interactive document is enriched by different kinds of visualization, including parallel coordinates plots and scatterplots for data exploration and graphics embedded into text. We devise an interaction model that allows users to explore code quality with consistent linking between text and visualizations; through integrated explanatory text, users are taught background knowledge about code quality aspects. Our approach to interactive documents was developed in a design study process that included software engineering and visual analytics experts. Although the solution is specific to the software engineering scenario, we discuss how the concept could generalize to multivariate data and report lessons learned in a broader scope.", "keywords": "Code quality,interactive documents,natural language generation,sparklines", "link": "http://dx.doi.org/10.1109/TVCG.2019.2934669", "refList": ["10.1109/tvcg.2014.2346435", "10.1109/tvcg.2018.2865022", "10.1016/j.jvlc.2018.10.001", "10.1002/smr.521", "10.1109/tvcg.2006.69", "10.1016/0004-3702(93)90022-4", "10.1145/3173574.3174106", "10.1007/s10648-010-9136-5", "10.3115/974557.974594", "10.1109/vl.1996.545307", "10.1109/tse.1976.233837", "10.1109/vissoft.2018.00010", "10.2312/vissym/vissym04/261-266", "10.1046/j.1365-2575.2002.00117.x", "10.1109/wcre.2002.1173068", "10.1109/icpc.2013.6613830", "10.1145/1985362.1985365", "10.3115/v1/w14-4401", "10.1007/s00766-007-0054-0", "10.1109/vissoft.2017.11", "10.1007/s10515-011-0098-8", "10.1109/vissof.2011", "10.1109/tvcg.2017.2674958", "10.1002/smr.404", "10.1109/32.979986", "10.1016/b978-0-12-397174-6.00010-6", "10.1145/3242587.3242617", "10.1109/mcg.2018.032421649", "10.1613/jair.5477", "10.1109/tfuzz.2014.2328011", "10.1145/2095654.2095665", "10.1109/icpc.2013.6613834", "10.1109/tvcg.2018.2865145", "10.1145/2597008.2597149", "10.1109/live.2013.6617345", "10.1145/1985793.1985868", "10.1002/int.21835", "10.1145/3139295.3139312", "10.1109/32.295895", "10.1109/scam.2014.14", "10.5281/zenodo.3336019", "10.1016/j.visinf.2019.03.004", "10.1109/aswec.2010.18", "10.2312/eurovisshort.20181084"], "wos": 1, "children": [], "len": 1}, {"doi": "10.1109/tvcg.2019.2934667", "title": "Galex: Exploring the Evolution and Intersection of Disciplines", "year": "2019", "conferenceName": "VAST", "authors": "Zeyu Li;Changhong Zhang;Shichao Jia;Jiawan Zhang", "citationCount": "0", "affiliation": "Zhang, JW (Corresponding Author), Tianjin Univ, Coll Intelligence \\& Comp, Tianjin, Peoples R China. Zhang, JW (Corresponding Author), State Adm Cultural Heritage, Tianjin Cultural Heritage Conservat \\& Inheritance, Beijing, Peoples R China. Zhang, JW (Corresponding Author), State Adm Cultural Heritage, Key Res Ctr Surface Monitoring \\& Anal Rel, Beijing, Peoples R China. Li, Zeyu; Zhang, Changhong; Jia, Shichao; Zhang, Jiawan, Tianjin Univ, Coll Intelligence \\& Comp, Tianjin, Peoples R China. Zhang, Jiawan, State Adm Cultural Heritage, Tianjin Cultural Heritage Conservat \\& Inheritance, Beijing, Peoples R China. Zhang, Jiawan, State Adm Cultural Heritage, Key Res Ctr Surface Monitoring \\& Anal Rel, Beijing, Peoples R China.", "countries": "China", "abstract": "Revealing the evolution of science and the intersections among its sub-fields is extremely important to understand the characteristics of disciplines, discover new topics, and predict the future. The current work focuses on either building the skeleton of science, lacking interaction, detailed exploration and interpretation or on the lower topic level, missing high-level macro-perspective. To fill this gap, we design and implement Galaxy Evolution Explorer (Galex), a hierarchical visual analysis system, in combination with advanced text mining technologies, that could help analysts to comprehend the evolution and intersection of one discipline rapidly. We divide Galex into three progressively fine-grained levels: discipline, area, and institution levels. The combination of interactions enables analysts to explore an arbitrary piece of history and an arbitrary part of the knowledge space of one discipline. Using a flexible spotlight component, analysts could freely select and quickly understand an exploration region. A tree metaphor allows analysts to perceive the expansion, decline, and intersection of topics intuitively. A synchronous spotlight interaction aids in comparing research contents among institutions easily. Three cases demonstrate the effectiveness of our system.", "keywords": "Science evolution,science mapping,interdisciplinary,knowledge domain visualization,visual analysis", "link": "http://dx.doi.org/10.1109/TVCG.2019.2934667", "refList": ["10.1109/pacificvis.2010.5429590", "10.1109/tvcg.2016.2615308", "10.1007/s11192-005-0255-6", "10.1109/tvcg.2018.2865022", "10.1109/vast.2016.7883507", "10.1145/1456650.1456652", "10.1109/vast.2009.5333443", "10.1002/asi.20991", "10.1109/pacificvis.2014.47", "10.1111/cgf.12376", "10.1371/journal.pone.0018209", "10.1007/s11192-011-0428-4", "10.1109/tvcg.2016.2610422", "10.1016/0306-4573(88)90021-0", "10.1016/j.respol.2014.02.005", "10.1002/asi.20317", "10.1109/visual.1996.568118", "10.14778/2735508.2735519", "10.1007/s11192-009-0146-3", "10.1109/tvcg.2013.167", "10.1007/978-3-642-37456-2\\_14", "10.1109/tvcg.2015.2467621", "10.1145/2089094.2089101", "10.1109/vl.1996.545307", "10.1111/cgf.12871", "10.1002/asi.22652", "10.1109/mcg.2011.91", "10.1371/journal.pone.0008694", "10.1145/1056808.1057069", "10.1126/science.1237825", "10.1145/2207676.2207738", "10.1023/a:1008690008856", "10.1073/pnas.0307654100", "10.1109/tvcg.2013.162", "10.1109/tvcg.2016.2598827", "10.1109/tvcg.2011.239", "10.1145/2740908.2742760", "10.1109/icdm.2014.24", "10.1179/000870403235002042", "10.1137/1.9781611972801.37", "10.1109/2945.981848", "10.1002/asi.22990", "10.1109/vast.2014.7042494", "10.1109/infvis.1995.528686", "10.1515/secm-2017-0114", "10.1145/2872427.2883041", "10.1126/science.aao0185", "10.1002/asi.10227", "10.1057/palgrave.ivs.9500180", "10.1109/vast.2012.6400485", "10.1145/2362364.2362367", "10.1002/aris.1440370106", "10.1016/j.joi.2014.07.006", "10.1073/pnas.0307626100", "10.1126/science.aaf5239", "10.3115/1117729.1117730", "10.1007/s12650-015-0323-9", "10.1073/pnas.0307513100"], "wos": 1, "children": [], "len": 1}, {"doi": "10.1109/vast47406.2019.8986934", "title": "Influence Flowers of Academic Entities", "year": "2019", "conferenceName": "VAST", "authors": "Minjeong Shin;Alexander Soen;Benjamin T. Readshaw;Stephen M. Blackburn;Mitchell Whitelaw;Lexing Xie", "citationCount": "0", "affiliation": "Shin, M (Corresponding Author), Australian Natl Univ, Canberra, ACT, Australia. Shin, Minjeong; Soen, Alexander; Readshaw, Benjamin T.; Blackburn, Stephen M.; Whitelaw, Mitchell; Xie, Lexing, Australian Natl Univ, Canberra, ACT, Australia.", "countries": "Australia", "abstract": "We present the Influence Flower, a new visual metaphor for the influence profile of academic entities, including people, projects, institutions, conferences, and journals. While many tools quantify influence, we aim to expose the flow of influence between entities. The Influence Flower is an ego-centric graph, with a query entity placed in the centre. The petals are styled to reflect the strength of influence to and from other entities of the same or different type. For example, one can break down the incoming and outgoing influences of a research lab by research topics. The Influence Flower uses a recent snapshot of Microsoft Academic Graph, consisting of 212 million authors, their 176 million publications, and 1.2 billion citations. An interactive web app, Influence Map, is constructed around this central metaphor for searching and curating visualisations. We also propose a visual comparison method that highlights change in influence patterns over time. We demonstrate through several case studies that the Influence Flower supports data-driven inquiries about the following: researchers' careers over time; paper(s) and projects, including those with delayed recognition; the interdisciplinary profile of a research institution; and the shifting topical trends in conferences. We also use this tool on influence data beyond academic citations, by contrasting the academic and Twitter activities of a researcher.", "keywords": "Human-centered computing,Visualization,Visualisation application domains,Visual analytics,Visualization systems and tools,Empirical studies in visualization", "link": "http://dx.doi.org/10.1109/VAST47406.2019.8986934", "refList": ["10.1109/tvcg.2018.2865022", "10.4304/jetwi.4.1.3-14", "10.1145/3132744", "10.1007/s11192-017-2454-3", "10.1057/palgrave.ivs.9500156", "10.1038/504211a", "10.1145/1401890.1402008", "10.1371/journal.pbio.1002542", "10.1109/tvcg.2011.185", "10.1002/asi.20317", "10.1016/0370-2693(86)90375-8", "10.1109/tvcg.2012.252", "10.1038/s41467-018-07034-y", "10.1145/3332803", "10.1038/550029a", "10.1145/1056808.1057069", "10.1109/tvcg.2015.2468151", "10.1523/jneurosci.0003-08.2008", "10.1007/s11192-017-2535-3", "10.1109/pacificvis.2016.7465279", "10.1038/s41586-019-0941-9", "10.1111/j.1467-8659.2011.01921.x", "10.1109/tvcg.2015.2465151", "10.1007/s11192-017-2247-8", "10.1145/2740908.2742839", "10.1007/s11192-011-0436-4", "10.1126/science.aao0185", "10.1109/tvcg.2014.2383380", "10.1073/pnas.1424329112", "10.1007/s11192-005-0281-4", "10.1145/2858036.2858488", "10.1023/b:scie.0000018543.82441.f1", "10.1109/vast.2015.7347632", "10.1126/science.aaf5239", "10.1145/2500892", "10.1073/pnas.0706851105", "10.1073/pnas.0307513100", "10.1038/520429a"], "wos": 1, "children": [], "len": 1}, {"doi": "10.1109/tvcg.2020.3030465", "title": "Visual Causality Analysis of Event Sequence Data", "year": "2020", "conferenceName": "VAST", "authors": "Zhuochen Jin;Shunan Guo;Nan Chen;Daniel Weiskopf;David Gotz;Nan Cao", "citationCount": "0", "affiliation": "Cao, N (Corresponding Author), Tongji Univ, IDVx Lab, Shanghai, Peoples R China. Jin, Zhuochen; Guo, Shunan; Chen, Nan; Cao, Nan, Tongji Univ, IDVx Lab, Shanghai, Peoples R China. Weiskopf, Daniel, Univ Stuttgart, Stuttgart, Germany. Gotz, David, Univ N Carolina, Chapel Hill, NC 27515 USA.", "countries": "USA;Germany;China", "abstract": "Causality is crucial to understanding the mechanisms behind complex systems and making decisions that lead to intended outcomes. Event sequence data is widely collected from many real-world processes, such as electronic health records, web clickstreams, and financial transactions, which transmit a great deal of information reflecting the causal relations among event types. Unfortunately, recovering causalities from observational event sequences is challenging, as the heterogeneous and high-dimensional event variables are often connected to rather complex underlying event excitation mechanisms that are hard to infer from limited observations. Many existing automated causal analysis techniques suffer from poor explainability and fail to include an adequate amount of human knowledge. In this paper, we introduce a visual analytics method for recovering causalities in event sequence data. We extend the Granger causality analysis algorithm on Hawkes processes to incorporate user feedback into causal model refinement. The visualization system includes an interactive causal analysis framework that supports bottom-up causal exploration, iterative causal verification and refinement, and causal comparison through a set of novel visualizations and interactions. We report two forms of evaluation: a quantitative evaluation of the model improvements resulting from the user-feedback mechanism, and a qualitative evaluation through case studies in different application domains to demonstrate the usefulness of the system.", "keywords": "Event sequence data,causality analysis,visual analytics", "link": "http://dx.doi.org/10.1109/TVCG.2020.3030465", "refList": ["10.5555/1642718", "10.1109/tvcg.2018.2865022", "10.5555/2074094.2074151", "10.1109/tvcg.2016.2618797", "10.1073/pnas.1320645111", "10.1109/tvcg.2017.2744843", "10.1109/iv.2017.69", "10.1109/tvcg.2019.2934399", "10.1145/3172944.3173007", "10.5555/1795555", "10.1109/mcg.2005.102", "10.1145/381641.381653", "10.1162/153244301753344614", "10.1111/cgf.14034", "10.1111/cgf.13198", "10.1017/cbo9780511519857", "10.1007/s10462-016-9475-9", "10.1075/ssol.2.2.07bor", "10.1007/978-1-4614-3223-4\\_3", "10.1109/infvis.2003.1249025", "10.1007/978-94-007-6094-313", "10.1145/2858036.2858387", "10.1109/tvcg.2007.70528", "10.1109/tvcg.2017.2674958", "10.1147/sj.454.0801", "10.1109/tvcg.2013.119", "10.1145/3173574.3173711", "10.1016/j.erss.2017.06.034", "10.1109/visual.2019.8933695", "10.1007/s11665-016-2173-6", "10.1016/0377-0427(87)90125-7", "10.2307/3601125", "10.1016/b978-0-444-88738-2.50018-x", "10.1109/mcg.2006.70", "10.1109/tvcg.2018.2865145", "10.1017/s1351324997001502", "10.1109/tvcg.2010.179", "10.1214/aos/1176344552", "10.1109/mcg.2009.22", "10.1007/978-3-319-26633-6\\_13", "10.1080/10447318.2014.905422", "10.1016/j.visinf.2019.03.004", "10.1057/palgrave.ivs.9500074", "10.1007/978-1-4614-3223-4"], "wos": 1, "children": [], "len": 1}], "len": 9}, {"doi": "10.1109/tvcg.2020.3028956", "title": "A Visual Analytics Approach for Ecosystem Dynamics based on Empirical Dynamic Modeling", "year": "2020", "conferenceName": "VAST", "authors": "Hiroaki Natsukawa;Ethan R. Deyle;Gerald M. Pao;Koji Koyamada;George Sugihara", "citationCount": "0", "affiliation": "Natsukawa, H (Corresponding Author), Kyoto Univ, Kyoto, Japan. Natsukawa, Hiroaki; Koyamada, Koji, Kyoto Univ, Kyoto, Japan. Deyle, Ethan R., Boston Univ, Boston, MA 02215 USA. Deyle, Ethan R.; Sugihara, George, Univ Calif San Diego, Scripps Inst Oceanog, San Diego, CA 92103 USA. Pao, Gerald M., Salk Inst Biol Sci, San Diego, CA USA.", "countries": "Japan;USA", "abstract": "An important approach for scientific inquiry across many disciplines involves using observational time series data to understand the relationships between key variables to gain mechanistic insights into the underlying rules that govern the given system. In real systems, such as those found in ecology, the relationships between time series variables are generally not static; instead, these relationships are dynamical and change in a nonlinear or state-dependent manner. To further understand such systems, we investigate integrating methods that appropriately characterize these dynamics (i.e., methods that measure interactions as they change with time-varying system states) with visualization techniques that can help analyze the behavior of the system. Here, we focus on empirical dynamic modeling (EDM) as a state-of-the-art method that specifically identifies causal variables and measures changing state-dependent relationships between time series variables. Instead of using approaches centered on parametric equations, EDM is an equation-free approach that studies systems based on their dynamic attractors. We propose a visual analytics system to support the identification and mechanistic interpretation of system states using an EDM-constructed dynamic graph. This work, as detailed in four analysis tasks and demonstrated with a GUI, provides a novel synthesis of EDM and visualization techniques such as brush-link visualization and visual summarization to interpret dynamic graphs representing ecosystem dynamics. We applied our proposed system to ecological simulation data and real data from a marine mesocosm study as two key use cases. Our case studies show that our visual analytics tools support the identification and interpretation of the system state by the user, and enable us to discover both confirmatory and new findings in ecosystem dynamics. Overall, we demonstrated that our system can facilitate an understanding of how systems function beyond the intuitive analysis of high-dimensional information based on specific domain knowledge.", "keywords": "Visual analytics,empirical dynamic modeling,dynamic network,exploratory data analysis", "link": "http://dx.doi.org/10.1109/TVCG.2020.3028956", "refList": ["10.1145/1835449.1835643", "10.1145/642611.642616.{[}cr0ssref", "10.1145/2890510", "10.1162/tacl\\_a\\_00051", "10.3233/ida-163209", "10.1109/tvcg.2018.2864903", "10.2200/s00174ed1v01y200901icr003", "10.5555/2999792.2999959", "10.1109/tvcg.2015.2467757", "10.1145/3240323.3240351", "10.1145/1864708.1864761", "10.1145/1125451.1125659", "10.2307/2529310", "10.1109/tvcg.2007.70594", "10.1007/s13740-016-0060-9", "10.1109/mcg.2019.2924636", "10.1007/978-3-540-78582-8\\_18", "10.1016/j.eswa.2016.02.013", "10.1109/vl.1996.545307", "10.1007/978-0-387-85820-3\\_3", "10.1007/s11042-015-3206-0", "10.1145/1352793.1352837", "10.1007/s11257-011-9118-4", "10.1145/3190616", "10.1145/2882903.2899389", "10.1109/vast.2014.7042511", "10.1145/1282280.1282359", "10.1145/642611.642616", "10.1109/tvcg.2018.2865240", "10.1177/001316446002000104", "10.1002/(sici)1097-4571(199009)41:6", "10.1037/h0031619", "10.1007/978-981-10-2857-1\\_20", "10.1109/tvcg.2007.70577", "10.1145/3092931.3092937", "10.1109/tvcg.2014.2346978", "10.1007/s11257-018-9206-9", "10.1109/18.61115", "10.1162/jmlr.2003.3.4-5.993", "10.1145/3298689.3347047", "10.1073/pnas.0307750100", "10.3115/v1/d14-1162", "10.1108/00220410410560582", "10.1016/j.fss.2008.03.017", "10.1007/978-0-387-85820-3\\_8", "10.1109/tvcg.2014.2346325", "10.1007/s11257-011-9112-x", "10.1109/sequen.1997.666900", "10.1145/642611.642681", "10.1007/s11257-018-9215-8", "10.1145/3290605.3300358", "10.1111/cgf.12387", "10.1109/tvcg.2016.2599030"], "wos": 1, "children": [], "len": 1}, {"doi": "10.1111/cgf.12932", "year": "2016", "title": "The State of the Art in Cartograms", "conferenceName": "EuroVis", "authors": "Sabrina Nusrat;Stephen G. Kobourov", "citationCount": "22", "affiliation": "Nusrat, S (Corresponding Author), Univ Arizona, Dept Comp Sci, Tucson, AZ 85721 USA.\nNusrat, Sabrina; Kobourov, Stephen, Univ Arizona, Dept Comp Sci, Tucson, AZ 85721 USA.", "countries": "USA", "abstract": "Cartograms combine statistical and geographical information in thematic maps, where areas of geographical regions (e.g., countries, states) are scaled in proportion to some statistic (e.g., population, income). Cartograms make it possible to gain insight into patterns and trends in the World around us and have been very popular visualizations for geo-referenced data for over a century. This Work surveys cartogram research in visualization, cartography and geometry, covering a broad spectrum of different cartogram types: from the traditional rectangular and table cartograms, to Dorling and diffusion cartograms. A particular focus is the study of the major cartogram dimensions: statistical accuracy, geographical accuracy, and topological accuracy. We review the history of cartograms, describe the algorithms for generating them, and consider task taxonomies. We also review quantitative and qualitative evaluations, and we use these to arrive at design guidelines and research challenges.", "keywords": "", "link": "https://doi.org/10.1111/cgf.12932", "refList": ["10.1559/152304083783948258", "10.1073/pnas.0400280101", "10.2307/4592353", "10.1016/j.disc.2007.12.087", "10.5194/gmd-5-245-2012", "10.1073/pnas.0510525103", "10.1080/17445647.2012.722792", "10.1080/13658810801958885", "10.1007/978-3-642-33024-7\\_3", "10.1109/tvcg.2015.2467757", "10.1179/caj.1978.15.1.36", "10.1111/j.0033-0124.1976.00371.x", "10.1111/j.0033-0124.1968.00402.x", "10.1145/220279.220290", "10.1559/152304075784313278", "10.1109/tvcg.2011.185", "10.1109/infvis.2004.57", "10.1109/pacificvis.2013.6596121", "10.1073/pnas.32.4.94", "10.1057/palgrave.ivs.9500039", "10.1177/1473871613480061", "10.1016/j.marpol.2013.01.022", "10.1109/iv.2004.1320136", "10.1007/978-3-642-40450-4\\_36", "10.2307/208794", "10.1109/visual.1998.745303", "10.14714/cp13.1000", "10.2307/1420573", "10.1559/1523040054738936", "10.1109/tvcg.2013.124", "10.2307/2277880", "10.1016/j.comgeo.2006.06.002", "10.1109/infvis.2005.1532136", "10.3138/cart0.44.3.iii", "10.1007/978-3-642-15300-6\\_12", "10.1109/mcg.2005.64", "10.1080/00385417.1960.10769885", "10.2307/2288400", "10.1111/j.1467-8306.2004.09401004.x", "10.1109/tvcg.2013.130", "10.1007/s00454-013-9521-1", "10.3138/carto.44.3.139", "10.1016/s1473-3099(04)01043-6", "10.1073/pnas.0801921105", "10.1080/13658810802705723", "10.1559/152304092783721231", "10.1111/cgf.12648", "10.1080/00330124.2011.639613", "10.1142/s0218195915500077", "10.1109/mcg.2006.70", "10.1111/j.0033-0124.1985.00075.x", "10.1179/000870409x12525737905169", "10.1007/bf02299827", "10.1016/0277-9536(88)90242-0", "10.1111/j.1467-8306.1968.tb01647.x", "10.2307/2287708", "10.1109/tvcg.2013.234", "10.1007/978-3-642-25591-5\\_30", "10.1086/368480", "10.1559/152304006777681698", "10.1109/tvcg.2004.1260761", "10.1111/j.0033-0124.1953.5511.x", "10.1111/j.1749-6632.1973.tb41401.x", "10.1038/nature12060", "10.1142/s0218195910003268", "10.1080/00221349608978925", "10.1109/tvcg.2007.70515", "10.2307/1790933", "10.1109/tvcg.2013.120", "10.1559/152304087783875318", "10.1080/13658816.2012.709247"], "wos": 1, "children": [{"doi": "10.1109/tvcg.2019.2934807", "title": "A Comparison of Visualizations for Identifying Correlation over Space and Time", "year": "2019", "conferenceName": "InfoVis", "authors": "Vanessa Pe\u00f1a Araya;Emmanuel Pietriga;Anastasia Bezerianos", "citationCount": "0", "affiliation": "Pena-Araya, V (Corresponding Author), Univ Paris Saclay, Univ Paris Sud, INRIA, CNRS, Paris, France. Pena-Araya, Vanessa; Pietriga, Emmanuel; Bezerianos, Anastasia, Univ Paris Saclay, Univ Paris Sud, INRIA, CNRS, Paris, France.", "countries": "France", "abstract": "Observing the relationship between two or more variables over space and time is essential in many domains. For instance, looking, for different countries, at the evolution of both the life expectancy at birth and the fertility rate will give an overview of their demographics. The choice of visual representation for such multivariate data is key to enabling analysts to extract patterns and trends. Prior work has compared geo-temporal visualization techniques for a single thematic variable that evolves over space and time, or for two variables at a specific point in time. But how effective visualization techniques are at communicating correlation between two variables that evolve over space and time remains to be investigated. We report on a study comparing three techniques that are representative of different strategies to visualize geo-temporal multivariate data: either juxtaposing all locations for a given time step, or juxtaposing all time steps for a given location; and encoding thematic attributes either using symbols overlaid on top of map features, or using visual channels of the map features themselves. Participants performed a series of tasks that required them to identify if two variables were correlated over time and if there was a pattern in their evolution. Tasks varied in granularity for both dimensions: time (all time steps, a subrange of steps, one step only) and space (all locations, locations in a subregion, one location only). Our results show that a visualization's effectiveness depends strongly on the task to be carried out. Based on these findings we present a set of design guidelines about geo-temporal visualization techniques for communicating correlation.", "keywords": "geo-temporal data,bivariate maps,correlation,controlled study,bar chart,Dorling cartogram,small multiples", "link": "http://dx.doi.org/10.1109/TVCG.2019.2934807", "refList": ["10.1111/j.1467-9671.2010.01194.x", "10.3390/ijgi2030817", "10.1109/tvcg.2018.2865141", "10.3390/ijgi7080288", "10.1080/00045608.2010.485449", "10.1109/pacificvis.2014.13", "10.1109/tvcg.2014.2346979", "10.1080/00045608.2015.1064510", "10.1111/cgf.12647", "10.1111/j.1467-8659.2009.01694.x", "10.1109/mcg.2003.1242376", "10.1080/09585192.2016.1278253", "10.1177/0956797613504966", "10.1109/tvcg.2011.185", "10.1006/ijhc.2002.1017", "10.1111/j.1467-8306.1994.tb01869.x", "10.1080/00045608.2011.577364", "10.1109/tvcg.2007.70623", "10.1111/cgf.12932", "10.1109/iv.2014.69", "10.1006/ijhc.1017", "10.1109/iv.2004.1320136", "10.1145/2801040.2801062", "10.1007/s00371-017-1461-y", "10.1111/j.1467-8659.2012.03093.x", "10.1109/tvcg.2013.66", "10.1007/s00779-018-1120-y", "10.1109/tvcg.2015.2467199", "10.1109/tvcg.2016.2642109", "10.1109/tvcg.2015.2467671", "10.1109/tvcg.2016.2598862", "10.1109/tvcg.2011.194", "10.3758/s13423-016-1174-7", "10.1109/tvcg.2017.2765330", "10.1109/iv.2004.1320137", "10.1038/nmeth.2659", "10.2312/cgvc.20181221", "10.1109/tvcg.2013.130", "10.3138/carto.42.4.349", "10.1111/j.1467-8306.2006.00514.x", "10.1117/12.912192", "10.1109/tvcg.2015.2467091", "10.1109/iv.2005.3", "10.1559/15230406384350", "10.1145/2909132.2909255", "10.1109/iv.2018.00056", "10.1109/tvcg.2008.125", "10.1109/2945.537309", "10.1109/tvcg.2018.2810918", "10.3390/ijgi6060180", "10.1145/3025453.3025801", "10.1080/14498596.2018.1440649", "10.1179/000870409x12525737905169", "10.2307/2284077", "10.1109/tvcg.2006.84", "10.1002/9780470979587.ch33", "10.1007/978-3-319-26633-6\\_13", "10.1136/bmj.316.7139.1236", "10.1145/2801040.2801061", "10.1037/0003-066x.60.2.170", "10.1145/989863.989940"], "wos": 1, "children": [], "len": 1}, {"doi": "10.1111/cgf.13446", "year": "2018", "title": "Quality Metrics for Information Visualization", "conferenceName": "EuroVis", "authors": "Michael Behrisch;Michael Blumenschein;Nam Wook Kim;Lin Shao;Mennatallah El{-}Assady;Johannes Fuchs;Daniel Seebacher;Alexandra Diehl;Ulrik Brandes;Hanspeter Pfister;Tobias Schreck;Daniel Weiskopf;Daniel A. Keim", "citationCount": "25", "affiliation": "Behrisch, M (Corresponding Author), Harvard Univ, Cambridge, MA 02138 USA.\nBehrisch, M.; Kim, N. W.; Pfister, H., Harvard Univ, Cambridge, MA 02138 USA.\nBlumenschein, M.; El-Assady, M.; Fuchs, J.; Seebacher, D.; Diehl, A.; Keim, D. A., Univ Konstanz, Constance, Germany.\nShao, L.; Schreck, T., Graz Univ Technol, Graz, Austria.\nBrandes, U., Swiss Fed Inst Technol, Zurich, Switzerland.\nWeiskopf, D., Univ Stuttgart, Stuttgart, Germany.", "countries": "Switzerland;Germany;USA;Austria", "abstract": "The visualization community has developed to date many intuitions and understandings of how to judge the quality of views in visualizing data. The computation of a visualization's quality and usefulness ranges from measuring clutter and overlap, up to the existence and perception of specific (visual) patterns. This survey attempts to report, categorize and unify the diverse understandings and aims to establish a common vocabulary that will enable a wide audience to understand their differences and subtleties. For this purpose, we present a commonly applicable quality metric formalization that should detail and relate all constituting parts of a quality metric. We organize our corpus of reviewed research papers along the data types established in the information visualization community: multi- and high-dimensional, relational, sequential, geospatial and text data. For each data type, we select the visualization subdomains in which quality metrics are an active research field and report their findings, reason on the underlying concepts, describe goals and outline the constraints and requirements. One central goal of this survey is to provide guidance on future research opportunities for the field and outline how different visualization communities could benefit from each other by applying or transferring knowledge to their respective subdomain. Additionally, we aim to motivate the visualization community to compare computed measures to the perception of humans.", "keywords": "", "link": "https://doi.org/10.1111/cgf.13446", "refList": ["10.2307/276978", "10.1057/ivs.2009.10", "10.1109/tvcg.2015.2467732", "10.1109/tvcg.2014.2346420", "10.1016/j.cag.2018.01.010", "10.1109/tvcg.2017.2743959", "10.1109/tvcg.2011.127", "10.1109/tvcg.2015.2467759", "10.1109/tvcg.2013.187", "10.1109/tvcg.2007.70594", "10.1186/1471-2105-9-155", "10.1145/2702123.2702545", "10.1145/1645953.1646023", "10.1093/bioinformatics/btm312", "10.1109/pacificvis.2016.7465245", "10.1145/3038462.3038463", "10.1007/978-3-540-70956-5", "10.1109/tvcg.2017.2743939", "10.1111/cgf.12932", "10.1111/j.1467-8659.2012.03106.x", "10.1145/1133265.1133318", "10.1109/tvcg.2010.186", "10.1109/iv.2013.101", "10.1109/tvcg.2016.2598590", "10.2312/conf/eg2013/stars/039-063", "10.3758/bf03201236", "10.1111/cgf.12935", "10.1145/1056808.1056914", "10.1007/bf01898350", "10.2307/1390686", "10.1109/2945.981848", "10.1109/hicss.2008.422", "10.1109/tvcg.2011.201", "10.1109/pacificvis.2011.5742390", "10.2307/2288400", "10.1111/cgf.12872", "10.1109/tvcg.2017.2674999", "10.1109/tvcg.2006.163", "10.1109/tvcg.2013.150", "10.1109/tvcg.2009.171", "10.1109/tvcg.2017.2723397", "10.1117/12.2079841", "10.1109/pacificvis.2009.4906838", "10.1109/infvis.2004.1", "10.1109/tvcg.2008.166", "10.1287/opre.20.5.993", "10.7155/jgaa.00370", "10.1111/j.1467-8659.2008.01240.x", "10.1109/inf0vis.2005.14", "10.1109/tvcg.2009.23", "10.1109/infvis.1998.729559", "10.1177/0165551506078083", "10.1109/t-c.1974.224051", "10.1109/tvcg.2017.2744339", "10.1109/tvcg.2014.2346433", "10.1145/989863.989940", "10.1109/tvcg.2015.2509990", "10.2307/2288843", "10.1016/j.neucom.2017.01.105", "10.1073/pnas.43.10.923", "10.1111/cgf.12647", "10.1016/j.rse.2017.06.031", "10.1109/infvis.2005.1532145", "10.1109/2945.841121", "10.1109/tvcg.2011.229", "10.2312/eurova.20141140", "10.1111/j.2044-8317.1974.tb00534.x", "10.1109/pacificvis.2015.7156366", "10.1109/vast.2009.5332628", "10.1109/vast.2014.7042480", "10.1145/2993901.2993907", "10.1177/0951692899011001004", "10.1007/978-3-642-03655-2\\_43", "10.1198/106186008x320465", "10.1109/visual.1997.663916", "10.1111/cgf.12125", "10.1109/infvis.2003.1249009", "10.1109/icdm.2003.1250978", "10.1109/tvcg.2017.2745919", "10.1109/tvcg.2012.128", "10.1109/vast.2010.5652450", "10.1109/tvcg.2006.161", "10.1145/571647.571649", "10.1109/tvcg.2011.193", "10.1111/cgf.12633", "10.1109/tvcg.2017.2674978", "10.1109/vast.2010.5652433", "10.1109/tvcg.2017.2745978", "10.1515/itit-2014-1070", "10.1145/1374489.1374501", "10.1109/tvcg.2009.153", "10.2312/eurovisshort.20171128", "10.2312/eurovisshort.20151130", "10.1016/0925-7721(94)00014-x", "10.1057/palgrave.ivs.95000/3", "10.1145/302979.303030", "10.1002/widm.1071", "10.1109/pacificvis.2014.42", "10.1109/tvcg.2016.2598467", "10.1111/j.1467-8659.2009.01667.x", "10.2307/2287708", "10.1177/1473871613477091", "10.1145/967900.968153", "10.1109/tvcg.2010.162", "10.1145/568522.568523", "10.1016/j.cag.2004.03.022", "10.1109/tvcg.2015.2466992", "10.1145/2993901.2993903", "10.1147/jrd.2015.2411412", "10.1177/154193120504900508", "10.1109/tvcg.2006.138", "10.1111/cgf.13168", "10.1111/cgf.12380", "10.2312/conf/eg2013/stars/095-116", "10.1109/tvcg.2017.2745859", "10.1109/tvcg.2017.2701829", "10.1109/tvcg.2007.70529", "10.1007/bf01199431", "10.1117/12.697548", "10.1109/tvcg.2017.2653106", "10.1207/s15327906mbr2701\\_4", "10.1109/vl.1996.545307", "10.1109/tvcg.2017.2745140", "10.1111/j.1467-8659.2012.03069.x", "10.1111/j.1467-8659.2011.01961.x", "10.1109/pacificvis.2016.7465244", "10.1109/tvcg.2013.124", "10.1057/ivs.2008.13", "10.2312/vissym/eurovis06/195-202", "10.2312/vissym/eurovis07/163-170", "10.1109/tvcg.2015.2467324", "10.1109/tvcg.2011.167", "10.1109/pacificvis.2014.40", "10.1109/pacificvis.2012.6183570", "10.1111/j.1467-8659.2012.03125.x", "10.1075/idj.20.1.02bei", "10.1111/1467-8306.00061", "10.1145/2858036.2858155", "10.1109/tvcg.2012.108", "10.2312/vmv.20171261", "10.1109/tvcg.2015.2467531", "10.1145/1379092.1379130", "10.1109/tpami.1979.4766909", "10.1080/13875860903039172", "10.1109/mcg.2006.70", "10.1109/tvcg.2010.242", "10.1109/vast.2007.4389004", "10.1109/tvcg.2015.2467191", "10.2312/cgvc.20171276", "10.1016/0169-7439(87)80084-9", "10.2312/pe/eurovisshort/eurovisshort2012/097-101", "10.1016/j.neucom.2014.07.073", "10.2307/2685263", "10.1145/996546.996554", "10.1111/j.1467-8659.2009.01666.x", "10.1117/12.2083444", "10.1109/tvcg.2014.2346572", "10.1007/978-0-387-39940-9\\_262", "10.1007/bf00988593", "10.1145/1054972.1055078", "10.1111/j.1467-8659.2009.01467.x", "10.1111/cgf.13181", "10.1145/502512.502530", "10.1109/pacificvis.2010.5429600", "10.1111/j.1467-8659.2011.01923.x", "10.1109/mcg.2004.41", "10.1109/tvcg.2015.2467971", "10.1111/j.1467-8659.2011.01919.x", "10.1002/sam.10071", "10.1109/tvcg.2010.184", "10.1007/978-3-642-27848-8\\_648-1", "10.1109/tvcg.2010.132", "10.1145/22949.22950", "10.1145/1842993.1843002", "10.1109/infvis.2000.885096", "10.1016/j.ins.2015.04.017", "10.1109/iv.2009.43", "10.1016/j.visinf.2017.11.001", "10.1109/tvcg.2011.239", "10.1109/infovis.2005.40", "10.1111/cgf.12641", "10.1109/pacificvis.2016.7465262", "10.1145/2470654.2466443", "10.1007/s10844-011-0157-4", "10.1111/cgf.12919", "10.1016/j.jvlc.2016.07.003", "10.1109/tvcg.2016.2549018", "10.1057/palgrave.ivs.9500166", "10.3406/colan.1981.1409.1", "10.1093/bioinformatics/bti141", "10.1111/j.1467-8306.2004.09401004.x", "10.1145/1168149.1168168", "10.1109/tvcg.2017.2744184", "10.1117/12.2079420", "10.1109/iv.2005.62", "10.1145/102377.115768", "10.1109/tvcg.2014.2346677", "10.1109/tvcg.2014.2346426", "10.1111/j.1467-8659.2012.03107.x", "10.5220/0006097400400051", "10.2991/978-94-6239-186-4", "10.2307/2284077", "10.1109/iv.2008.89", "10.1016/j.jvlc.2015.12.001", "10.1109/pacificvis.2013.6596147", "10.1145/1242572.1242826", "10.1016/j.cag.2007.01.030", "10.1111/cgf.12632", "10.2312/eurovisstar.20151113", "10.1559/152304009788188808"], "wos": 1, "children": [{"doi": "10.1109/vast.2018.8802486", "title": "SMARTexplore: Simplifying High-Dimensional Data Analysis through a Table-Based Visual Analytics Approach", "year": "2018", "conferenceName": "VAST", "authors": "Michael Blumenschein;Michael Behrisch;Stefanie Schmid;Simon Butscher;Deborah Wahl;Karoline Villinger;Britta Renner;Harald Reiterer;Daniel A. Keim", "citationCount": "0", "affiliation": "Blumenschein, M (Corresponding Author), Univ Konstanz, Constance, Germany. Blumenschein, Michael; Schmid, Stefanie; Butscher, Simon; Wahl, Deborah R.; Villinger, Karoline; Renner, Britta; Reiterer, Harald; Keim, Daniel A., Univ Konstanz, Constance, Germany. Behrisch, Michael, Harvard Univ, Cambridge, MA 02138 USA.", "countries": "Germany;USA", "abstract": "We present SMARTEXPLORE, a novel visual analytics technique that simplifies the identification and understanding of clusters, correlations, and complex patterns in high-dimensional data. The analysis is integrated into an interactive table-based visualization that maintains a consistent and familiar representation throughout the analysis. The visualization is tightly coupled with pattern matching, subspace analysis, reordering, and layout algorithms. To increase the analyst's trust in the revealed patterns, SMARTEXPLORE automatically selects and computes statistical measures based on dimension and data properties. While existing approaches to analyzing high-dimensional data (e.g., planar projections and Parallel coordinates) have proven effective, they typically have steep learning curves for non-visualization experts. Our evaluation, based on three expert case studies, confirms that non-visualization experts successfully reveal patterns in high-dimensional data when using SMARTEXPLORE.", "keywords": "High-dimensional data,visual exploration,pattern-driven analysis,tabular visualization,subspace,aggregation", "link": "http://dx.doi.org/10.1109/VAST.2018.8802486", "refList": ["10.1177/1473871612460526", "10.1109/tvcg.2015.2489649", "10.1111/j.1467-8659.2008.01241.x", "10.1007/978-3-319-25087-8\\_29", "10.1007/b98835", "10.13140/rg.2.2.16570.90567", "10.1109/tvcg.2014.2346260", "10.1109/vast.2009.5332628", "10.2307/2528823", "10.1109/tvcg.2010.184", "10.1145/1133265.1133318", "10.1057/palgrave.ivs.9500072", "10.1111/j.1467-8659.2012.03110.x", "10.1145/1007730.1007731", "10.1057/palgrave.ivs.9500086", "10.1111/cgf.12935", "10.1109/tvcg.2014.2346279", "10.1007/bf01898350", "10.1109/tvcg.2013.173", "10.1109/tvcg.2017.2672987", "10.1109/tvcg.2014.2346248", "10.1109/infvis.2004.46", "10.1109/vast.2010.5652433", "10.1109/vast.2009.5332611", "10.1109/tvcg.2015.2467553", "10.1109/tvcg.2015.2468078", "10.1109/tvcg.2017.2744098", "10.1109/tvcg.2013.150", "10.1109/tvcg.2016.2640960", "10.1111/cgf.12630", "10.1007/978-1-4757-1904-8", "10.1109/tvcg.2011.188", "10.1109/tvcg.2010.138", "10.1109/tvcg.2017.2745078", "10.1109/tvcg.2017.2743978", "10.1111/cgf.12879", "10.1109/iv.2008.33", "10.1111/cgf.13446", "10.1007/s00371-018-1483-0", "10.1109/infvis.1998.729559", "10.1145/2669557.2669572", "10.1111/j.1467-8659.2008.01239.x"], "wos": 1, "children": [], "len": 1}, {"doi": "10.1109/tvcg.2019.2934541", "title": "A Recursive Subdivision Technique for Sampling Multi-class Scatterplots", "year": "2019", "conferenceName": "InfoVis", "authors": "Xin Chen;Tong Ge;Jian Zhang 0070;Baoquan Chen;Chi-Wing Fu;Oliver Deussen;Yunhai Wang", "citationCount": "5", "affiliation": "Chen, X (Corresponding Author), Shandong Univ, Jinan, Shandong, Peoples R China. Chen, Xin; Ge, Tong; Wang, Yunhai, Shandong Univ, Jinan, Shandong, Peoples R China. Chen, Baoquan, Peking Univ, Beijing, Peoples R China. Fu, Chi-Wing, Chinese Univ Hong Kong, Hong Kong, Peoples R China. Fu, Chi-Wing, SIAT, Guangdong Prov Key Lab CV \\& VR Tech, Shenzhen, Guangdong, Peoples R China. Zhang, Jian, Chinese Acad Sci, CNIC, Beijing, Peoples R China. Deussen, Oliver, Konstanz Univ, Constance, Germany. Deussen, Oliver, SIAT, Shenzhen VIsuCA Key Lab, Shenzhen, Guangdong, Peoples R China.", "countries": "Germany;China", "abstract": "We present a non-uniform recursive sampling technique for multi-class scatterplots, with the specific goal of faithfully presenting relative data and class densities, while preserving major outliers in the plots. Our technique is based on a customized binary kd-tree, in which leaf nodes are created by recursively subdividing the underlying multi-class density map. By backtracking, we merge leaf nodes until they encompass points of all classes for our subsequently applied outlier-aware multi-class sampling strategy. A quantitative evaluation shows that our approach can better preserve outliers and at the same time relative densities in multi-class scatterplots compared to the previous approaches, several case studies demonstrate the effectiveness of our approach in exploring complex and real world data.", "keywords": "Scatterplot,multi-class sampling,kd-tree,outlier,relative density", "link": "http://dx.doi.org/10.1109/TVCG.2019.2934541", "refList": ["10.1057/palgrave.ivs.9500122", "10.1109/tvcg.2006.170", "10.1109/tvcg.2008.119", "10.1109/tvcg.2007.70580", "10.2307/2289444", "10.1145/1964921.1964943", "10.1109/tvcg.2013.65", "10.1109/tvcg.2011.229", "10.1109/iv.2004.1320207", "10.1109/itoec.2018.8740621", "10.1145/1778765.1778816", "10.1109/tvcg.2010.197", "10.1201/b17511", "10.1109/tvcg.2018.2864912", "10.1007/0-387-28695-0", "10.1109/5.726791", "10.1109/visual.1998.745301", "10.1016/j.physa.2011.12.004", "10.1145/1556262.1556289", "10.1109/tvcg.2007.70535", "10.1109/tvcg.2017.2674978", "10.1109/tvcg.2004.1272729", "10.1145/335191.335388", "10.1109/tvcg.2014.2346594", "10.1109/tvcg.2017.2744184", "10.1109/iv.2002.1028760", "10.1145/1842993.1842999", "10.1109/tvcg.2018.2869149", "10.1038/nmeth.2490", "10.1109/tvcg.2013.153", "10.1111/cgf.13446", "10.1109/tvcg.2010.176", "10.1145/2702123.2702585", "10.1057/ivs.2009.34"], "wos": 1, "children": [{"doi": "10.1109/tvcg.2020.3030443", "title": "CAVA: A Visual Analytics System for Exploratory Columnar Data Augmentation Using Knowledge Graphs", "year": "2020", "conferenceName": "VAST", "authors": "Dylan Cashman;Shenyu Xu;Subhajit Das;Florian Heimerl;Cong Liu;Shah Rukh Humayoun;Michael Gleicher;Alex Endert;Remco Chang", "citationCount": "0", "affiliation": "Cashman, D (Corresponding Author), Tufts Univ, Medford, MA 02155 USA. Cashman, Dylan; Liu, Cong; Chang, Remco, Tufts Univ, Medford, MA 02155 USA. Xu, Shenyu; Das, Subhajit; Endert, Alex, Georgia Tech, Atlanta, GA USA. Heimerl, Florian; Gleicher, Michael, Univ Wisconsin, Madison, WI 53706 USA. Humayoun, Shah Rukh, San Francisco State Univ, San Francisco, CA 94132 USA.", "countries": "USA", "abstract": "Most visual analytics systems assume that all foraging for data happens before the analytics process; once analysis begins, the set of data attributes considered is fixed. Such separation of data construction from analysis precludes iteration that can enable foraging informed by the needs that arise in-situ during the analysis. The separation of the foraging loop from the data analysis tasks can limit the pace and scope of analysis. In this paper, we present CAVA, a system that integrates data curation and data augmentation with the traditional data exploration and analysis tasks, enabling information foraging in-situ during analysis. Identifying attributes to add to the dataset is difficult because it requires human knowledge to determine which available attributes will be helpful for the ensuing analytical tasks. CAVA crawls knowledge graphs to provide users with a a broad set of attributes drawn from external data to choose from. Users can then specify complex operations on knowledge graphs to construct additional attributes. CAVA shows how visual analytics can help users forage for attributes by letting users visually explore the set of available data, and by serving as an interface for query construction. It also provides visualizations of the knowledge graph itself to help users understand complex joins such as multi-hop aggregations. We assess the ability of our system to enable users to perform complex data combinations without programming in a user study over two datasets. We then demonstrate the generalizability of CAVA through two additional usage scenarios. The results of the evaluation confirm that CAVA is effective in helping the user perform data foraging that leads to improved analysis outcomes, and offer evidence in support of integrating data augmentation as a part of the visual analytics pipeline.", "keywords": "Visual Analytics,Information Foraging,Data Augmentation", "link": "http://dx.doi.org/10.1109/TVCG.2020.3030443", "refList": ["10.1057/palgrave.ivs.9500122", "10.1109/tvcg.2016.2598867", "10.1111/cgf.13708", "10.1109/tvcg.2019.2934799", "10.1109/tvcg.2019.2934541", "10.1109/tvcg.2013.65", "10.1109/tvcg.2018.2875702", "10.1109/iv.2004.1320207", "10.1068/p260471", "10.1145/1778765.1778816", "10.1109/tvcg.2018.2808489", "10.1109/tvcg.2018.2864912", "10.1016/j.apgeog.2015.12.006", "10.1111/j.1467-8659.2011.01960.x", "10.1109/tvcg.2018.2864843", "10.1109/pacificvis.2010.5429604", "10.1109/tvcg.2014.2346898", "10.1109/5.726791", "10.1177/1475090214540874", "10.1109/icde.2016.7498287", "10.1145/1556262.1556289", "10.1109/tvcg.2007.70535", "10.1109/vast.2012.6400489", "10.1145/1056808.1056914", "10.1016/j.neucom.2014.09.063", "10.1145/7529.8927", "10.1109/tvcg.2016.2598495", "10.1109/tvcg.2016.2607204", "10.1109/vast47406.2019.8986943", "10.3758/bf03205986", "10.1109/infvis.2005.1532142", "10.1145/1150402.1150479", "10.1109/tvcg.2017.2674978", "10.1109/tvcg.2019.2945960", "10.1109/tvcg.2017.2744098", "10.1109/tvcg.2017.2674999", "10.1109/tvcg.2011.279", "10.1109/tvcg.2014.2346594", "10.1109/tvcg.2017.2744184", "10.1111/cgf.12876", "10.1007/s4095-020-0191-7", "10.1007/s11390-015-1535-0", "10.1111/cgf.12640", "10.1109/tvcg.2016.2598667", "10.1111/cgf.13683", "10.1109/tvcg.2013.153", "10.1109/tvcg.2019.2934208", "10.1109/tvcg.2019.2934655", "10.1111/cgf.12655", "10.1007/s11023-010-9221-z", "10.1109/vast.2012.6400487", "10.1145/2702123.2702585", "10.1007/bf00310175", "10.1109/tvcg.2017.2744378", "10.1103/physreve.64.061907", "10.1109/ldav.2017.8231848", "10.1109/tvcg.2016.2598831"], "wos": 1, "children": [], "len": 1}, {"doi": "10.1109/tvcg.2020.3030432", "title": "Evaluation of Sampling Methods for Scatterplots", "year": "2020", "conferenceName": "VAST", "authors": "Jun Yuan;Shouxing Xiang;Jiazhi Xia;Lingyun Yu;Shixia Liu", "citationCount": "0", "affiliation": "Liu, SX (Corresponding Author), Tsinghua Univ, BNRist, Beijing, Peoples R China. Yuan, Jun; Xiang, Shouxing; Liu, Shixia, Tsinghua Univ, BNRist, Beijing, Peoples R China. Xia, Jiazhi, Cent South Univ, Changsha, Peoples R China. Yu, Lingyun, Xian Jiaotong Liverpool Univ, Suzhou, Peoples R China.", "countries": "China", "abstract": "Given a scatterplot with tens of thousands of points or even more, a natural question is which sampling method should be used to create a small but \u201cgood\u201d scatterplot for a better abstraction. We present the results of a user study that investigates the influence of different sampling strategies on multi-class scatterplots. The main goal of this study is to understand the capability of sampling methods in preserving the density, outliers, and overall shape of a scatterplot. To this end, we comprehensively review the literature and select seven typical sampling strategies as well as eight representative datasets. We then design four experiments to understand the performance of different strategies in maintaining: 1) region density; 2) class density; 3) outliers; and 4) overall shape in the sampling results. The results show that: 1) random sampling is preferred for preserving region density; 2) blue noise sampling and random sampling have comparable performance with the three multi-class sampling strategies in preserving class density; 3) outlier biased density based sampling, recursive subdivision based sampling, and blue noise sampling perform the best in keeping outliers; and 4) blue noise sampling outperforms the others in maintaining the overall shape of a scatterplot.", "keywords": "Scatterplot,data sampling,empirical evaluation", "link": "http://dx.doi.org/10.1109/TVCG.2020.3030432", "refList": ["10.1057/palgrave.ivs.9500122", "10.1109/tvcg.2016.2598867", "10.1109/tvcg.2015.2467591", "10.1111/cgf.13708", "10.1109/tvcg.2019.2934799", "10.1109/tvcg.2019.2934541", "10.1109/tvcg.2013.65", "10.1109/iv.2004.1320207", "10.1068/p260471", "10.1145/1778765.1778816", "10.1109/tvcg.2018.2808489", "10.1109/tvcg.2018.2864912", "10.1016/j.apgeog.2015.12.006", "10.1111/j.1467-8659.2011.01960.x", "10.1109/tvcg.2018.2864843", "10.1109/pacificvis.2010.5429604", "10.1109/tvcg.2014.2346898", "10.1109/5.726791", "10.1177/1475090214540874", "10.1145/1556262.1556289", "10.1109/tvcg.2007.70535", "10.1109/vast.2012.6400489", "10.1145/1056808.1056914", "10.1016/j.neucom.2014.09.063", "10.1145/7529.8927", "10.1109/tvcg.2016.2607204", "10.1109/vast47406.2019.8986943", "10.3758/bf03205986", "10.1109/infvis.2005.1532142", "10.1145/1150402.1150479", "10.1109/tvcg.2017.2674978", "10.1109/tvcg.2017.2744098", "10.1109/tvcg.2017.2674999", "10.1109/tvcg.2011.279", "10.1109/tvcg.2014.2346594", "10.1109/tvcg.2017.2744184", "10.1111/cgf.12876", "10.1109/1011101.2019.2945960", "10.1007/s4095-020-0191-7", "10.1007/s11390-015-1535-0", "10.1111/cgf.12640", "10.1109/tvcg.2016.2598667", "10.1111/cgf.13683", "10.1109/tvcg.2013.153", "10.1109/tvcg.2019.2934208", "10.1109/tvcg.2019.2934655", "10.1111/cgf.12655", "10.1007/s11023-010-9221-z", "10.1109/vast.2012.6400487", "10.1145/2702123.2702585", "10.1007/bf00310175", "10.1109/tvcg.2017.2744378", "10.1103/physreve.64.061907", "10.1109/ldav.2017.8231848", "10.1109/tvcg.2016.2598831"], "wos": 1, "children": [], "len": 1}, {"doi": "10.1109/tvcg.2020.3030365", "title": "Modeling the Influence of Visual Density on Cluster Perception in Scatterplots Using Topology", "year": "2020", "conferenceName": "InfoVis", "authors": "Ghulam Jilani Quadri;Paul Rosen", "citationCount": "0", "affiliation": "Quadri, GJ (Corresponding Author), Univ S Florida, Tampa, FL 33620 USA. Quadri, Ghulam Jilani; Rosen, Paul, Univ S Florida, Tampa, FL 33620 USA.", "countries": "USA", "abstract": "Scatterplots are used for a variety of visual analytics tasks, including cluster identification, and the visual encodings used on a scatterplot play a deciding role on the level of visual separation of clusters. For visualization designers, optimizing the visual encodings is crucial to maximizing the clarity of data. This requires accurately modeling human perception of cluster separation, which remains challenging. We present a multi-stage user study focusing on four factors-distribution size of clusters, number of points, size of points, and opacity of points-that influence cluster identification in scatterplots. From these parameters, we have constructed two models, a distance-based model, and a density-based model, using the merge tree data structure from Topological Data Analysis. Our analysis demonstrates that these factors play an important role in the number of clusters perceived, and it verifies that the distance-based and density-based models can reasonably estimate the number of clusters a user observes. Finally, we demonstrate how these models can be used to optimize visual encodings on real-world data.", "keywords": "Scatterplot,clustering,perception,empirical evaluation,visual encoding,crowdsourcing,topological data analysis", "link": "http://dx.doi.org/10.1109/TVCG.2020.3030365", "refList": ["10.1109/tvcg.2017.2744359", "10.1145/1778765", "10.1109/tvcg.2019.2934799", "10.1111/cgf.12889", "10.1109/tvcg.2011.127", "10.1111/cgf.13444", "10.1145/1964897.1964910", "10.1167/8.7.6", "10.1145/3173574.3173991", "10.1145/1556262.1556289", "10.1145/1056808.1056914", "10.2307/2288400", "10.1109/tvcg.2014.2346594", "10.1109/iv.2002.1028760", "10.1177/001316447303300111", "10.1007/bf02289823", "10.1109/tvcg.2017.2744339", "10.1111/j.1467-8659.2009.01694.x", "10.1109/tvcg.2014.2346979", "10.1090/mbk/069", "10.1109/tvcg.2013.65", "10.1109/mcg.2012.37", "10.1109/pacificvis.2010.5429604", "10.1002/acp.2350050106", "10.1109/infvis.2005.1532136", "10.1177/1473871612465214", "10.1109/tvcg.2017.2674978", "10.1002/jhbs.20078", "10.1007/978-3-642-35142-6\\_14", "10.1007/978-3-319-71507-0", "10.1109/mcg.201.7.6", "10.3758/bf03193961", "10.1364/josa.49.000280", "10.1145/3025453.3025905", "10.1109/tvcg.201.9.2934541", "10.1109/tvcg.2018.2829750", "10.1177/1473871615606187", "10.1111/cgf.13408", "10.1109/pacificvis.2016.7465252", "10.1109/pacificvis.2016.7465244", "10.1109/inevis.2005.1532142", "10.1111/cgf.13414", "10.1111/j.1467-8659.2012.03125.x", "10.1167/16.5.11", "10.1109/infvis.2005.1532142", "10.1145/2858036.2858155", "10.1038/nmeth1210-941", "10.1177/1473871616638892", "10.1109/tcbb.2014.2306840", "10.1111/cgf.13684", "10.1177/0301006615602599", "10.1214/aoms/1177731915", "10.1145/2702123.2702585", "10.1109/tvcg.2013.183", "10.1109/tvcg.2014.2346572", "10.1109/tvcg.2018.2875702", "10.1109/tvcg.2017.2754480", "10.1109/vast.2014.7042493", "10.1057/palgrave.ivs.9500122", "10.1109/tvcg.2014.2330617", "10.1109/tvcg.2019.2934541", "10.1068/p030033", "10.1140/epjds/s13688-017-0109-5", "10.1201/b17511", "10.1016/s0925-7721(02)00093-7", "10.1109/pacificvis.2012.6183557", "10.1109/tvcg.2014.2346983", "10.1109/5.726791", "10.1080/01621459.1926.10502165", "10.1109/tvcg.2007.70535", "10.1109/tvcg.2018.2864907", "10.1111/cgf.12109", "10.1109/tvcg.2017.2744184", "10.1146/annurev-statistics-031017-100045", "10.1111/cgf.13409", "10.1145/3002151.3002162", "10.1016/s0378-4371(98)00494-4", "10.3138/y308-2422-8615-1233", "10.1111/cgf.12632", "10.1145/3290605.3300771"], "wos": 1, "children": [], "len": 1}, {"doi": "10.1111/cgf.14001", "year": "2020", "title": "Sunspot Plots: Model-based Structure Enhancement for Dense Scatter Plots", "conferenceName": "EuroVis", "authors": "Thomas Trautner;Fabian Bolte;Sergej Stoppel;Stefan Bruckner", "citationCount": "0", "affiliation": "Trautner, T (Corresponding Author), Univ Bergen, Bergen, Norway.\nTrautner, T.; Bolte, F.; Stoppel, S.; Bruckner, S., Univ Bergen, Bergen, Norway.", "countries": "Norway", "abstract": "Scatter plots are a powerful and well-established technique for visualizing the relationships between two variables as a collection of discrete points. However, especially when dealing with large and dense data, scatter plots often exhibit problems such as overplotting, making the data interpretation arduous. Density plots are able to overcome these limitations in highly populated regions, but fail to provide accurate information of individual data points. This is particularly problematic in sparse regions where the density estimate may not provide a good representation of the underlying data. In this paper, we present sunspot plots, a visualization technique that communicates dense data as a continuous data distribution, while preserving the discrete nature of data samples in sparsely populated areas. We furthermore demonstrate the advantages of our approach on typical failure cases of scatter plots within synthetic and real-world data sets and validate its effectiveness in a user study.", "keywords": "", "link": "https://doi.org/10.1111/cgf.14001", "refList": ["10.1057/palgrave.ivs.9500122", "10.2312/eggh/hpg12/097-103", "10.1109/tvcg.2008.119", "10.1109/pacificvis.2011.5742387", "10.1038/331163a0", "10.1109/visual.2019.8933620", "10.2307/2683294", "10.1201/9781351072304", "10.2307/2289444", "10.1109/tvcg.2019.2934541", "10.1080/00949657508810123", "10.1109/tvcg.2013.65", "10.1109/infvis.1997.636789", "10.1109/2945.841121", "10.1109/mcse.2007.55", "10.1109/tvcg.2010.197", "10.1111/cgf.12871", "10.1109/infvis.2003.1249018", "10.1145/3173574.3173991", "10.1109/tvcg.2012.238", "10.1007/0-387-28695-0", "10.1109/pacificvis.2010.5429604", "10.18637/jss.v008.i03", "10.1109/tvcg.2007.70596", "10.1109/visual.1998.745301", "10.1007/0-387-37977-0\\_3", "10.1145/1556262.1556289", "10.2312/wiced.20161094", "10.1109/tvcg.2007.70535", "10.1145/1056808.1056914", "10.1109/tvcg.2003.1196007", "10.1109/iv.2004.1320190", "10.1111/cgf.12877", "10.1162/leon.2007.40.2.202a", "10.1109/tvcg.2017.2674978", "10.1057/ivs.2010.4", "10.1016/j.cag.2018.02.008", "10.1201/9781315140919", "10.1109/visual.2000.885677", "10.1002/jhbs.20078", "10.1109/tvcg.2014.2346594", "10.1109/tvcg.2017.2744184", "10.1109/visual.2001.964495", "10.1109/iv.2002.1028760", "10.1111/cgf.13684", "10.1109/hicss.2013.197", "10.1109/tvcg.2019.2903956", "10.1093/mnras/stt961", "10.1109/tvcg.2017.2668409", "10.1111/j.1467-8659.2009.01478.x", "10.1145/2702123.2702585", "10.2307/1418003", "10.2307/1390742", "10.1145/360825.360839", "10.1109/pacificvis.2009.4906843", "10.1057/ivs.2009.34", "10.2307/2288711"], "wos": 1, "children": [], "len": 1}], "len": 9}, {"doi": "10.1109/tvcg.2019.2934284", "title": "Color Crafting: Automating the Construction of Designer Quality Color Ramps", "year": "2019", "conferenceName": "InfoVis", "authors": "Stephen Smart;Keke Wu;Danielle Albers Szafir", "citationCount": "3", "affiliation": "Smart, S (Corresponding Author), Univ Colorado, Boulder, CO 80309 USA. Smart, Stephen; Wu, Keke; Szafir, Danielle Albers, Univ Colorado, Boulder, CO 80309 USA.", "countries": "USA", "abstract": "Visualizations often encode numeric data using sequential and diverging color ramps. Effective ramps use colors that are sufficiently discriminable, align well with the data, and are aesthetically pleasing. Designers rely on years of experience to create high-quality color ramps. However, it is challenging for novice visualization developers that lack this experience to craft effective ramps as most guidelines for constructing ramps are loosely defined qualitative heuristics that are often difficult to apply. Our goal is to enable visualization developers to readily create effective color encodings using a single seed color. We do this using an algorithmic approach that models designer practices by analyzing patterns in the structure of designer-crafted color ramps. We construct these models from a corpus of 222 expert-designed color ramps, and use the results to automatically generate ramps that mimic designer practices. We evaluate our approach through an empirical study comparing the outputs of our approach with designer-crafted color ramps. Our models produce ramps that support accurate and aesthetically pleasing visualizations at least as well as designer ramps and that outperform conventional mathematical approaches.", "keywords": "Visualization,Aesthetics in Visualization,Color Perception,Visual Design,Design Mining", "link": "http://dx.doi.org/10.1109/TVCG.2019.2934284", "refList": ["10.1145/3009924", "10.1109/tvcg.2015.2489649", "10.1109/tvcg.2017.2744359", "10.1002/(sici)1098-1098(199622)7:2", "10.1016/s0734-189x(83)80046-2", "10.1109/tvcg.2016.2599106", "10.1364/josaa.29.000313", "10.1109/tvcg.2016.2598918", "10.2307/2683294", "10.1109/tvcg.2017.2653106", "10.1016/j.ijhcs.2010.05.006", "10.1016/0146-664x(81)90006-x", "10.1007/978-3-642-10520-3\\_9", "10.1109/38.135886", "10.1146/annurev-psych-120710-100504", "10.1016/j.csda.2008.11.033", "10.1145/2461912.2461988", "10.1016/j.cub.2007.06.022", "10.1016/s0146-664x(79)80040-4", "10.1109/mcg.2004.1297012", "10.1109/iv.2009.94", "10.1109/tpami.2010.184", "10.3758/s13414-010-0027-0", "10.1145/22949.22950", "10.1109/visual.1995.480803", "10.1109/tvcg.2014.2346277", "10.2307/2684111", "10.1109/tvcg.2018.2865240", "10.1111/cgf.12633", "10.1109/38.7760", "10.1016/j.jspi.2015.04.007", "10.1109/iv.2008.24", "10.1145/2939502.2939506", "10.1111/cgf.12127", "10.1016/j.cag.2010.11.015", "10.1145/3025453.3026041", "10.1109/tvcg.2012.315", "10.2307/2288400", "10.1511/2005.5.436", "10.1016/s0097-8493(96)00072-6", "10.1109/mcg.2018.011461525", "10.1145/2470654.2466420", "10.1109/tvcg.2012.279", "10.1109/tvcg.2014.2346978", "10.1109/tvcg.2017.2743978", "10.1145/3406601.3406602", "10.1117/12.2084548", "10.1109/tvcg.2018.2865147", "10.1109/tvcg.2015.2467191", "10.1111/cgf.13446", "10.1109/tvcg.2017.2744320", "10.1111/j.1467-8659.2008.01203.x", "10.1145/2702613.2702975", "10.1007/978-3-319-26633-6\\_13", "10.1145/2207676.2208547", "10.1109/tvcg.2008.174", "10.1179/000870403235002042"], "wos": 1, "children": [{"doi": "10.1109/tvcg.2020.3028891", "title": "A Structured Review of Data Management Technology for Interactive Visualization and Analysis", "year": "2020", "conferenceName": "InfoVis", "authors": "Leilani Battle;Carlos Scheidegger", "citationCount": "0", "affiliation": "Battle, L (Corresponding Author), Univ Maryland, Dept Comp Sci, College Pk, MD 20742 USA. Battle, Leilani, Univ Maryland, Dept Comp Sci, College Pk, MD 20742 USA. Scheidegger, Carlos, Univ Arizona, Dept Comp Sci, HDC Lab, Tucson, AZ 85721 USA.", "countries": "USA", "abstract": "In the last two decades, interactive visualization and analysis have become a central tool in data-driven decision making. Concurrently to the contributions in data visualization, research in data management has produced technology that directly benefits interactive analysis. Here, we contribute a systematic review of 30 years of work in this adjacent field, and highlight techniques and principles we believe to be underappreciated in visualization work. We structure our review along two axes. First, we use task taxonomies from the visualization literature to structure the space of interactions in usual systems. Second, we created a categorization of data management work that strikes a balance between specificity and generality. Concretely, we contribute a characterization of 131 research papers along these two axes. We find that five notions in data management venues fit interactive visualization systems well: materialized views, approximate query processing, user modeling and query prediction, muiti-query optimization, lineage techniques, and indexing techniques. In addition, we find a preponderance of work in materialized views and approximate query processing, most targeting a limited subset of the interaction tasks in the taxonomy we used. This suggests natural avenues of future research both in visualization and data management. Our categorization both changes how we visualization researchers design and build our systems, and highlights where future work is necessary.", "keywords": "", "link": "http://dx.doi.org/10.1109/TVCG.2020.3028891", "refList": ["10.1109/tvcg.2012.233", "10.1016/s0022-5371(74)80015-0", "10.1109/tvcg.2017.2744359", "10.1037/0096-3445.136.4.623", "10.1109/tvcg.2015.2467732", "10.1109/tvcg.2012.196", "10.1037/a0029856", "10.1109/tvcg.2014.2346979", "10.1037/h0030300", "10.1109/tvcg.2016.2598918", "10.1109/beliv.2018.8634420", "10.1109/tvcg.2018.2864909", "10.1111/cgf.13079", "10.3389/fpsyg.2012.00355", "10.1145/2858036.2858465", "10.1080/01621459.1989.10478821", "10.1037/0278-7393.24.3.732", "10.1109/tvcg.2011.127", "10.1145/2858036.2858063", "10.4249/scholarpedia.3325", "10.4324/9781410611949", "10.1111/cgf.13444", "10.1145/2993901.2993909", "10.1037/0033-295x.96.2.267", "10.1006/ijhc.1017", "10.1086/405615", "10.1109/tvcg.2019.2934801", "10.1038/17953", "10.1037/xhp0000314", "10.1109/tvcg.2019.2934400", "10.1145/2470654.2470723", "10.1037/0096-1523.16.2.332", "10.1167/16.5.11", "10.3758/s13423-016-1174-7", "10.3758/bf03207704", "10.1146/annurev.psych.55.090902.141415", "10.2307/2288400", "10.3758/bf03204258", "10.1109/tvcg.2011.279", "10.1109/vissoft.2014.36", "10.3758/s13423-011-0055-3", "10.1145/3025453.3025922", "10.1109/tvcg.2019.2934284", "10.3758/bf03210498", "10.3758/bf03200774", "10.2307/1419876", "10.1038/s41562-017-0058", "10.1109/tvcg.2010.237", "10.1109/pacificvis.2012.6183556", "10.1109/infvis.1997.636792", "10.1093/acprof:oso/9780198523192.003.0005", "10.1073/pnas.1117465109", "10.1109/tvcg.2013.234", "10.1038/nn.3655", "10.1111/cgf.12379", "10.1146/annurev-psych-010416-044232", "10.1111/cgf.13695", "10.1037/0033-295x.107.3.500", "10.1109/tvcg.2013.183", "10.1146/annurev.psych.53.100901.135125", "10.1037//0022-3514.79.6.995", "10.1559/152304003100010929", "10.1109/tvcg.2018.2865147", "10.1037/0096-1523.18.3.849", "10.1111/j.1467-8659.2009.01694.x", "10.1145/3290605.3300771"], "wos": 1, "children": [], "len": 1}], "len": 3}, {"doi": "10.1109/tvcg.2019.2934799", "title": "Data Sampling in Multi-view and Multi-class Scatterplots via Set Cover Optimization", "year": "2019", "conferenceName": "InfoVis", "authors": "Ruizhen Hu;Tingkai Sha;Oliver van Kaick;Oliver Deussen;Hui Huang 0004", "citationCount": "4", "affiliation": "Hu, RZ (Corresponding Author), Shenzhen Univ, Visual Comp Res Ctr, Shenzhen, Guangdong, Peoples R China. Hu, Ruizhen; Sha, Tingkai; Huang, Hui, Shenzhen Univ, Visual Comp Res Ctr, Shenzhen, Guangdong, Peoples R China. van Kaick, Oliver, Carleton Univ, Sch Comp Sci, Ottawa, ON, Canada. Deussen, Oliver, Konstanz Univ, Constance, Germany. Deussen, Oliver, SIAT, Shenzhen VisuCA Key Lab, Shenzhen, Guangdong, Peoples R China.", "countries": "Canada;Germany;China", "abstract": "We present a method for data sampling in scatterplots by jointly optimizing point selection for different views or classes. Our method uses space-filling curves (Z-order curves) that partition a point set into subsets that, when covered each by one sample, provide a sampling or coreset with good approximation guarantees in relation to the original point set. For scatterplot matrices with multiple views, different views provide different space-filling curves, leading to different partitions of the given point set. For multi-class scatterplots, the focus on either per-class distribution or global distribution provides two different partitions of the given point set that need to be considered in the selection of the coreset. For both cases, we convert the coreset selection problem into an Exact Cover Problem (ECP), and demonstrate with quantitative and qualitative evaluations that an approximate solution that solves the ECP efficiently is able to provide high-quality samplings.", "keywords": "Sampling,Scatterplot,SPLOM,Exact Cover Problem", "link": "http://dx.doi.org/10.1109/TVCG.2019.2934799", "refList": ["10.1057/palgrave.ivs.9500122", "10.1109/tvcg.2006.170", "10.1109/tvcg.2008.119", "10.1111/j.1467-8659.2009.01467.x", "10.2307/2289444", "10.1109/tvcg.2013.65", "10.1109/tvcg.2011.229", "10.1109/iv.2004.1320207", "10.1109/itoec.2018.8740621", "10.1145/1778765.1778816", "10.1109/tvcg.2018.2864912", "10.1007/0-387-28695-0", "10.1109/visual.1998.745301", "10.1287/moor.4.3.233", "10.1145/1556262.1556289", "10.1109/tvcg.2007.70535", "10.2307/2284239", "10.1109/tvcg.2017.2674978", "10.1016/j.dss.2009.05.016", "10.1109/tvcg.2014.2346594", "10.1109/vds.2017.8573446", "10.1007/978-1-4684-2001-2\\_9", "10.1109/iv.2002.1028760", "10.1145/1842993.1842999", "10.1038/nmeth.2490", "10.1109/tvcg.2013.153", "10.1111/cgf.13446", "10.1109/tvcg.2010.176", "10.1145/2702123.2702585", "10.1057/ivs.2009.34", "10.1179/000870403235002042"], "wos": 1, "children": [{"doi": "10.1109/tvcg.2020.3030443", "title": "CAVA: A Visual Analytics System for Exploratory Columnar Data Augmentation Using Knowledge Graphs", "year": "2020", "conferenceName": "VAST", "authors": "Dylan Cashman;Shenyu Xu;Subhajit Das;Florian Heimerl;Cong Liu;Shah Rukh Humayoun;Michael Gleicher;Alex Endert;Remco Chang", "citationCount": "0", "affiliation": "Cashman, D (Corresponding Author), Tufts Univ, Medford, MA 02155 USA. Cashman, Dylan; Liu, Cong; Chang, Remco, Tufts Univ, Medford, MA 02155 USA. Xu, Shenyu; Das, Subhajit; Endert, Alex, Georgia Tech, Atlanta, GA USA. Heimerl, Florian; Gleicher, Michael, Univ Wisconsin, Madison, WI 53706 USA. Humayoun, Shah Rukh, San Francisco State Univ, San Francisco, CA 94132 USA.", "countries": "USA", "abstract": "Most visual analytics systems assume that all foraging for data happens before the analytics process; once analysis begins, the set of data attributes considered is fixed. Such separation of data construction from analysis precludes iteration that can enable foraging informed by the needs that arise in-situ during the analysis. The separation of the foraging loop from the data analysis tasks can limit the pace and scope of analysis. In this paper, we present CAVA, a system that integrates data curation and data augmentation with the traditional data exploration and analysis tasks, enabling information foraging in-situ during analysis. Identifying attributes to add to the dataset is difficult because it requires human knowledge to determine which available attributes will be helpful for the ensuing analytical tasks. CAVA crawls knowledge graphs to provide users with a a broad set of attributes drawn from external data to choose from. Users can then specify complex operations on knowledge graphs to construct additional attributes. CAVA shows how visual analytics can help users forage for attributes by letting users visually explore the set of available data, and by serving as an interface for query construction. It also provides visualizations of the knowledge graph itself to help users understand complex joins such as multi-hop aggregations. We assess the ability of our system to enable users to perform complex data combinations without programming in a user study over two datasets. We then demonstrate the generalizability of CAVA through two additional usage scenarios. The results of the evaluation confirm that CAVA is effective in helping the user perform data foraging that leads to improved analysis outcomes, and offer evidence in support of integrating data augmentation as a part of the visual analytics pipeline.", "keywords": "Visual Analytics,Information Foraging,Data Augmentation", "link": "http://dx.doi.org/10.1109/TVCG.2020.3030443", "refList": ["10.1057/palgrave.ivs.9500122", "10.1109/tvcg.2016.2598867", "10.1111/cgf.13708", "10.1109/tvcg.2019.2934799", "10.1109/tvcg.2019.2934541", "10.1109/tvcg.2013.65", "10.1109/tvcg.2018.2875702", "10.1109/iv.2004.1320207", "10.1068/p260471", "10.1145/1778765.1778816", "10.1109/tvcg.2018.2808489", "10.1109/tvcg.2018.2864912", "10.1016/j.apgeog.2015.12.006", "10.1111/j.1467-8659.2011.01960.x", "10.1109/tvcg.2018.2864843", "10.1109/pacificvis.2010.5429604", "10.1109/tvcg.2014.2346898", "10.1109/5.726791", "10.1177/1475090214540874", "10.1109/icde.2016.7498287", "10.1145/1556262.1556289", "10.1109/tvcg.2007.70535", "10.1109/vast.2012.6400489", "10.1145/1056808.1056914", "10.1016/j.neucom.2014.09.063", "10.1145/7529.8927", "10.1109/tvcg.2016.2598495", "10.1109/tvcg.2016.2607204", "10.1109/vast47406.2019.8986943", "10.3758/bf03205986", "10.1109/infvis.2005.1532142", "10.1145/1150402.1150479", "10.1109/tvcg.2017.2674978", "10.1109/tvcg.2019.2945960", "10.1109/tvcg.2017.2744098", "10.1109/tvcg.2017.2674999", "10.1109/tvcg.2011.279", "10.1109/tvcg.2014.2346594", "10.1109/tvcg.2017.2744184", "10.1111/cgf.12876", "10.1007/s4095-020-0191-7", "10.1007/s11390-015-1535-0", "10.1111/cgf.12640", "10.1109/tvcg.2016.2598667", "10.1111/cgf.13683", "10.1109/tvcg.2013.153", "10.1109/tvcg.2019.2934208", "10.1109/tvcg.2019.2934655", "10.1111/cgf.12655", "10.1007/s11023-010-9221-z", "10.1109/vast.2012.6400487", "10.1145/2702123.2702585", "10.1007/bf00310175", "10.1109/tvcg.2017.2744378", "10.1103/physreve.64.061907", "10.1109/ldav.2017.8231848", "10.1109/tvcg.2016.2598831"], "wos": 1, "children": [], "len": 1}, {"doi": "10.1109/tvcg.2020.3030432", "title": "Evaluation of Sampling Methods for Scatterplots", "year": "2020", "conferenceName": "VAST", "authors": "Jun Yuan;Shouxing Xiang;Jiazhi Xia;Lingyun Yu;Shixia Liu", "citationCount": "0", "affiliation": "Liu, SX (Corresponding Author), Tsinghua Univ, BNRist, Beijing, Peoples R China. Yuan, Jun; Xiang, Shouxing; Liu, Shixia, Tsinghua Univ, BNRist, Beijing, Peoples R China. Xia, Jiazhi, Cent South Univ, Changsha, Peoples R China. Yu, Lingyun, Xian Jiaotong Liverpool Univ, Suzhou, Peoples R China.", "countries": "China", "abstract": "Given a scatterplot with tens of thousands of points or even more, a natural question is which sampling method should be used to create a small but \u201cgood\u201d scatterplot for a better abstraction. We present the results of a user study that investigates the influence of different sampling strategies on multi-class scatterplots. The main goal of this study is to understand the capability of sampling methods in preserving the density, outliers, and overall shape of a scatterplot. To this end, we comprehensively review the literature and select seven typical sampling strategies as well as eight representative datasets. We then design four experiments to understand the performance of different strategies in maintaining: 1) region density; 2) class density; 3) outliers; and 4) overall shape in the sampling results. The results show that: 1) random sampling is preferred for preserving region density; 2) blue noise sampling and random sampling have comparable performance with the three multi-class sampling strategies in preserving class density; 3) outlier biased density based sampling, recursive subdivision based sampling, and blue noise sampling perform the best in keeping outliers; and 4) blue noise sampling outperforms the others in maintaining the overall shape of a scatterplot.", "keywords": "Scatterplot,data sampling,empirical evaluation", "link": "http://dx.doi.org/10.1109/TVCG.2020.3030432", "refList": ["10.1057/palgrave.ivs.9500122", "10.1109/tvcg.2016.2598867", "10.1109/tvcg.2015.2467591", "10.1111/cgf.13708", "10.1109/tvcg.2019.2934799", "10.1109/tvcg.2019.2934541", "10.1109/tvcg.2013.65", "10.1109/iv.2004.1320207", "10.1068/p260471", "10.1145/1778765.1778816", "10.1109/tvcg.2018.2808489", "10.1109/tvcg.2018.2864912", "10.1016/j.apgeog.2015.12.006", "10.1111/j.1467-8659.2011.01960.x", "10.1109/tvcg.2018.2864843", "10.1109/pacificvis.2010.5429604", "10.1109/tvcg.2014.2346898", "10.1109/5.726791", "10.1177/1475090214540874", "10.1145/1556262.1556289", "10.1109/tvcg.2007.70535", "10.1109/vast.2012.6400489", "10.1145/1056808.1056914", "10.1016/j.neucom.2014.09.063", "10.1145/7529.8927", "10.1109/tvcg.2016.2607204", "10.1109/vast47406.2019.8986943", "10.3758/bf03205986", "10.1109/infvis.2005.1532142", "10.1145/1150402.1150479", "10.1109/tvcg.2017.2674978", "10.1109/tvcg.2017.2744098", "10.1109/tvcg.2017.2674999", "10.1109/tvcg.2011.279", "10.1109/tvcg.2014.2346594", "10.1109/tvcg.2017.2744184", "10.1111/cgf.12876", "10.1109/1011101.2019.2945960", "10.1007/s4095-020-0191-7", "10.1007/s11390-015-1535-0", "10.1111/cgf.12640", "10.1109/tvcg.2016.2598667", "10.1111/cgf.13683", "10.1109/tvcg.2013.153", "10.1109/tvcg.2019.2934208", "10.1109/tvcg.2019.2934655", "10.1111/cgf.12655", "10.1007/s11023-010-9221-z", "10.1109/vast.2012.6400487", "10.1145/2702123.2702585", "10.1007/bf00310175", "10.1109/tvcg.2017.2744378", "10.1103/physreve.64.061907", "10.1109/ldav.2017.8231848", "10.1109/tvcg.2016.2598831"], "wos": 1, "children": [], "len": 1}, {"doi": "10.1109/tvcg.2020.3030365", "title": "Modeling the Influence of Visual Density on Cluster Perception in Scatterplots Using Topology", "year": "2020", "conferenceName": "InfoVis", "authors": "Ghulam Jilani Quadri;Paul Rosen", "citationCount": "0", "affiliation": "Quadri, GJ (Corresponding Author), Univ S Florida, Tampa, FL 33620 USA. Quadri, Ghulam Jilani; Rosen, Paul, Univ S Florida, Tampa, FL 33620 USA.", "countries": "USA", "abstract": "Scatterplots are used for a variety of visual analytics tasks, including cluster identification, and the visual encodings used on a scatterplot play a deciding role on the level of visual separation of clusters. For visualization designers, optimizing the visual encodings is crucial to maximizing the clarity of data. This requires accurately modeling human perception of cluster separation, which remains challenging. We present a multi-stage user study focusing on four factors-distribution size of clusters, number of points, size of points, and opacity of points-that influence cluster identification in scatterplots. From these parameters, we have constructed two models, a distance-based model, and a density-based model, using the merge tree data structure from Topological Data Analysis. Our analysis demonstrates that these factors play an important role in the number of clusters perceived, and it verifies that the distance-based and density-based models can reasonably estimate the number of clusters a user observes. Finally, we demonstrate how these models can be used to optimize visual encodings on real-world data.", "keywords": "Scatterplot,clustering,perception,empirical evaluation,visual encoding,crowdsourcing,topological data analysis", "link": "http://dx.doi.org/10.1109/TVCG.2020.3030365", "refList": ["10.1109/tvcg.2017.2744359", "10.1145/1778765", "10.1109/tvcg.2019.2934799", "10.1111/cgf.12889", "10.1109/tvcg.2011.127", "10.1111/cgf.13444", "10.1145/1964897.1964910", "10.1167/8.7.6", "10.1145/3173574.3173991", "10.1145/1556262.1556289", "10.1145/1056808.1056914", "10.2307/2288400", "10.1109/tvcg.2014.2346594", "10.1109/iv.2002.1028760", "10.1177/001316447303300111", "10.1007/bf02289823", "10.1109/tvcg.2017.2744339", "10.1111/j.1467-8659.2009.01694.x", "10.1109/tvcg.2014.2346979", "10.1090/mbk/069", "10.1109/tvcg.2013.65", "10.1109/mcg.2012.37", "10.1109/pacificvis.2010.5429604", "10.1002/acp.2350050106", "10.1109/infvis.2005.1532136", "10.1177/1473871612465214", "10.1109/tvcg.2017.2674978", "10.1002/jhbs.20078", "10.1007/978-3-642-35142-6\\_14", "10.1007/978-3-319-71507-0", "10.1109/mcg.201.7.6", "10.3758/bf03193961", "10.1364/josa.49.000280", "10.1145/3025453.3025905", "10.1109/tvcg.201.9.2934541", "10.1109/tvcg.2018.2829750", "10.1177/1473871615606187", "10.1111/cgf.13408", "10.1109/pacificvis.2016.7465252", "10.1109/pacificvis.2016.7465244", "10.1109/inevis.2005.1532142", "10.1111/cgf.13414", "10.1111/j.1467-8659.2012.03125.x", "10.1167/16.5.11", "10.1109/infvis.2005.1532142", "10.1145/2858036.2858155", "10.1038/nmeth1210-941", "10.1177/1473871616638892", "10.1109/tcbb.2014.2306840", "10.1111/cgf.13684", "10.1177/0301006615602599", "10.1214/aoms/1177731915", "10.1145/2702123.2702585", "10.1109/tvcg.2013.183", "10.1109/tvcg.2014.2346572", "10.1109/tvcg.2018.2875702", "10.1109/tvcg.2017.2754480", "10.1109/vast.2014.7042493", "10.1057/palgrave.ivs.9500122", "10.1109/tvcg.2014.2330617", "10.1109/tvcg.2019.2934541", "10.1068/p030033", "10.1140/epjds/s13688-017-0109-5", "10.1201/b17511", "10.1016/s0925-7721(02)00093-7", "10.1109/pacificvis.2012.6183557", "10.1109/tvcg.2014.2346983", "10.1109/5.726791", "10.1080/01621459.1926.10502165", "10.1109/tvcg.2007.70535", "10.1109/tvcg.2018.2864907", "10.1111/cgf.12109", "10.1109/tvcg.2017.2744184", "10.1146/annurev-statistics-031017-100045", "10.1111/cgf.13409", "10.1145/3002151.3002162", "10.1016/s0378-4371(98)00494-4", "10.3138/y308-2422-8615-1233", "10.1111/cgf.12632", "10.1145/3290605.3300771"], "wos": 1, "children": [], "len": 1}], "len": 7}, {"doi": "10.1109/tvcg.2019.2934432", "title": "Discriminability Tests for Visualization Effectiveness and Scalability", "year": "2019", "conferenceName": "InfoVis", "authors": "Rafael Veras;Christopher Collins", "citationCount": "1", "affiliation": "Veras, R (Corresponding Author), Ontario Tech Univ, Oshawa, ON, Canada. Veras, Rafael; Collins, Christopher, Ontario Tech Univ, Oshawa, ON, Canada.", "countries": "Canada", "abstract": "The scalability of a particular visualization approach is limited by the ability for people to discern differences between plots made with different datasets. Ideally, when the data changes, the visualization changes in perceptible ways. This relation breaks down when there is a mismatch between the encoding and the character of the dataset being viewed. Unfortunately, visualizations are often designed and evaluated without fully exploring how they will respond to a wide variety of datasets. We explore the use of an image similarity measure, the Multi-Scale Structural Similarity Index (MS-SSIM), for testing the discriminability of a data visualization across a variety of datasets. MS-SSIM is able to capture the similarity of two visualizations across multiple scales, including low level granular changes and high level patterns. Significant data changes that are not captured by the MS-SSIM indicate visualizations of low discriminability and effectiveness. The measure's utility is demonstrated with two empirical studies. In the first, we compare human similarity judgments and MS-SSIM scores for a collection of scatterplots. In the second, we compute the discriminability values for a set of basic visualizations and compare them with empirical measurements of effectiveness. In both cases, the analyses show that the computational measure is able to approximate empirical results. Our approach can be used to rank competing encodings on their discriminability and to aid in selecting visualizations for a particular type of data distribution.", "keywords": "Scalability,Discriminability,Simulation,Perception", "link": "http://dx.doi.org/10.1109/TVCG.2019.2934432", "refList": ["10.1109/tvcg.2012.233", "10.1109/tvcg.2017.2744359", "10.1109/tvcg.2012.230", "10.1111/cgf.12647", "10.1109/tvcg.2016.2598918", "10.1109/tvcg.2007.70529", "10.1145/2858036.2858435", "10.1109/vast.2009.5332628", "10.1145/3025453.3025912", "10.1145/1133265.1133318", "10.1109/tip.2010.2092435", "10.1109/tvcg.2010.132", "10.1109/tvcg.2018.2865264", "10.1175/jtech-d-11-00103.1", "10.1145/1190036.1190039", "10.1111/cgf.12127", "10.1109/infvis.2005.1532142", "10.1145/2858036.2858155", "10.1109/mcg.2014.18", "10.1145/3173574.3174172", "10.1109/tvcg.2009.153", "10.1057/palgrave.ivs.9500070", "10.1109/tvcg.2018.2790961", "10.1109/tvcg.2014.2346978", "10.1109/tvcg.2018.2810918", "10.1111/cgf.13409", "10.1109/tip.2003.819861", "10.1145/2642918.2647411", "10.1080/15230406.2016.1140074", "10.1109/jstsp.2009.2015374", "10.1109/tvcg.2010.237", "10.1109/mcg.2009.6", "10.1111/j.1467-8659.2009.01667.x", "10.1109/tvcg.2010.161", "10.1111/cgf.13446", "10.1109/tvcg.2014.2346325", "10.1109/tvcg.2009.111", "10.1147/jrd.2015.2411412"], "wos": 1, "children": [{"doi": "10.1109/tvcg.2020.3030394", "title": "Direct Volume Rendering with Nonparametric Models of Uncertainty", "year": "2020", "conferenceName": "SciVis", "authors": "Tushar M. Athawale;Bo Ma 0002;Elham Sakhaee;Christopher R. Johnson;Alireza Entezari", "citationCount": "0", "affiliation": "Athawale, TM (Corresponding Author), Univ Utah, Sci Comp \\& Imaging SCI Inst, Salt Lake City, UT 84112 USA. Athawale, Tushar M.; Johnson, Chris R., Univ Utah, Sci Comp \\& Imaging SCI Inst, Salt Lake City, UT 84112 USA. Ma, Bo; Sakhaee, Elham; Entezari, Alireza, Univ Florida, Dept CISE, Gainesville, FL 32611 USA.", "countries": "USA", "abstract": "We present a nonparametric statistical framework for the quantification, analysis, and propagation of data uncertainty in direct volume rendering (DVR). The state-of-the-art statistical DVR framework allows for preserving the transfer function (TF) of the ground truth function when visualizing uncertain data; however, the existing framework is restricted to parametric models of uncertainty. In this paper, we address the limitations of the existing DVR framework by extending the DVR framework for nonparametric distributions. We exploit the quantile interpolation technique to derive probability distributions representing uncertainty in viewing-ray sample intensities in closed form, which allows for accurate and efficient computation. We evaluate our proposed nonparametric statistical models through qualitative and quantitative comparisons with the mean-field and parametric statistical models, such as uniform and Gaussian, as well as Gaussian mixtures. In addition, we present an extension of the state-of-the-art rendering parametric framework to 2D TFs for improved DVR classifications. We show the applicability of our uncertainty quantification framework to ensemble, downsampled, and bivariate versions of scalar field datasets.", "keywords": "Volumes,uncertainty,nonparametric,2D transfer function", "link": "http://dx.doi.org/10.1109/TVCG.2020.3030394", "refList": ["10.1109/icdm.2012.80", "10.1145/1401890.1401904", "10.1109/tvcg.2017.2745139", "10.18128/d030.v6.0", "10.1111/cgf.12142", "10.1109/tvcg.2009.114", "10.1111/j.1467-8659.2009.01677.x", "10.1109/mcse.2007.55", "10.1109/icde.2012.16", "10.1198/106186008x320465", "10.1145/1835804.1835868", "10.1559/1523040054738936", "10.1109/tvcg.2019.2934432", "10.1109/34.1000236", "10.1109/infvis.2005.1532136", "10.1109/tvcg.2012.128", "10.1109/pacificvis.2017.8031573", "10.1109/tvcg.2016.2598920", "10.1109/tvcg.2018.2865021", "10.1109/infvis.2005.1532142", "10.1145/2858036.2858155", "10.1109/sp.2009.22", "10.1109/tvcg.2017.2744184", "10.1145/773153.773173", "10.1145/2660267.2660348", "10.1109/icdmw.2009.93", "10.1016/j.jtrangeo.2015.09.001", "10.1109/icde.2010.5447831", "10.1007/11681878\\_14", "10.1111/cgf.13409", "10.1007/s13278-014-0205-5", "10.1109/tvcg.2011.163", "10.1145/3035918.3035940", "10.1109/sp.2008.33", "10.1145/2882903.2882931"], "wos": 1, "children": [], "len": 1}], "len": 3}, {"doi": "10.1109/tvcg.2019.2934208", "title": "Evaluating Perceptual Bias During Geometric Scaling of Scatterplots", "year": "2019", "conferenceName": "VAST", "authors": "Yating Wei;Honghui Mei;Ying Zhao;Shuyue Zhou;Bingru Lin;Haojing Jiang;Wei Chen", "citationCount": "5", "affiliation": "Chen, W (Corresponding Author), Zhejiang Univ, State Key Lab CAD \\& CG, Hangzhou 310058, Zhejiang, Peoples R China. Zhao, Y (Corresponding Author), Cent South Univ, Sch Comp Sci \\& Engn, Changsha 410083, Hunan, Peoples R China. Wei, Yating; Mei, Honghui; Zhou, Shuyue; Lin, Bingru; Chen, Wei, Zhejiang Univ, State Key Lab CAD \\& CG, Hangzhou 310058, Zhejiang, Peoples R China. Zhao, Ying; Jiang, Haojing, Cent South Univ, Sch Comp Sci \\& Engn, Changsha 410083, Hunan, Peoples R China.", "countries": "China", "abstract": "Scatterplots are frequently scaled to fit display areas in multi-view and multi-device data analysis environments. A common method used for scaling is to enlarge or shrink the entire scatterplot together with the inside points synchronously and proportionally. This process is called geometric scaling. However, geometric scaling of scatterplots may cause a perceptual bias, that is, the perceived and physical values of visual features may be dissociated with respect to geometric scaling. For example, if a scatterplot is projected from a laptop to a large projector screen, then observers may feel that the scatterplot shown on the projector has fewer points than that viewed on the laptop. This paper presents an evaluation study on the perceptual bias of visual features in scatterplots caused by geometric scaling. The study focuses on three fundamental visual features (i.e., numerosity, correlation, and cluster separation) and three hypotheses that are formulated on the basis of our experience. We carefully design three controlled experiments by using well-prepared synthetic data and recruit participants to complete the experiments on the basis of their subjective experience. With a detailed analysis of the experimental results, we obtain a set of instructive findings. First, geometric scaling causes a bias that has a linear relationship with the scale ratio. Second, no significant difference exists between the biases measured from normally and uniformly distributed scatterplots. Third, changing the point radius can correct the bias to a certain extent. These findings can be used to inspire the design decisions of scatterplots in various scenarios.", "keywords": "Evaluation,scatterplot,geometric scaling,bias,perceptual consistency", "link": "http://dx.doi.org/10.1109/TVCG.2019.2934208", "refList": ["10.2307/2288843", "10.1109/tvcg.2017.2744359", "10.1109/tvcg.2015.2467732", "10.1109/tvcg.2014.2346979", "10.1126/science.216.4550.1138", "10.1109/tvcg.2017.2744138", "10.1111/j.1467-8659.2009.01467.x", "10.1145/2491568.2491577", "10.1109/mwc.2018.1700325", "10.1145/2449396.2449439", "10.1109/tvcg.2011.127", "10.1109/tvcg.2011.229", "10.1167/15.5.4", "10.1073/pnas.1113195108", "10.1145/2702123.2702545", "10.1109/vast.2009.5332628", "10.1109/tvcg.2018.2800013", "10.1007/s12650-018-0530-2", "10.1016/s0042-6989(97)00340-4", "10.1109/vast.2010.5652460", "10.1109/mcg.2018.2879067", "10.1109/tvcg.2018.2864912", "10.1109/pacificvis.2010.5429604", "10.1109/tcst.2018.2819965", "10.1167/10.2.10", "10.1145/2470654.2481318", "10.1145/1842993.1843002", "10.1167/12.6.8", "10.1109/tvcg.2013.124", "10.1057/ivs.2008.13", "10.1109/tvcg.2007.70596", "10.1109/tvcg.2018.2865266", "10.1145/3173574.3173664", "10.1109/tvcg.2015.2467671", "10.1016/j.cag.2017.07.004", "10.1177/0956797613501520", "10.1109/tvcg.2018.2865020", "10.1111/j.1467-8659.2012.03125.x", "10.3758/bf03205986", "10.3758/s13423-016-1174-7", "10.1109/tvcg.2017.2680452", "10.1109/mc.2006.109", "10.1109/tvcg.2017.2744098", "10.1038/srep32810", "10.1016/j.visres.2013.06.006", "10.1002/jhbs.20078", "10.1109/tvcg.2006.163", "10.1109/tvcg.2014.2346594", "10.1109/tvcg.2017.2744184", "10.1016/j.cognition.2007.10.009", "10.1109/tvcg.2018.2865142", "10.3758/app.72.7.1839", "10.1109/tvcg.2018.2810918", "10.1016/j.jvlc.2017.10.001", "10.1145/2682623", "10.1109/tvcg.2018.2864884", "10.1145/3025453.3025984", "10.1109/tvcg.2006.184", "10.1109/tvcg.2013.153", "10.1016/j.jvlc.2018.08.003", "10.1109/tvcg.2016.2520921", "10.1111/cgf.13446", "10.1017/s0022381612000187", "10.1145/2702123.2702406", "10.1109/vast.2012.6400487", "10.1109/tvcg.2013.183", "10.1177/1473871611415997", "10.1145/2702123.2702585", "10.1145/2993901.2993903", "10.1109/tvcg.2013.120", "10.1111/cgf.12632", "10.1145/1385569.1385602", "10.1109/tvcg.2017.2754480", "10.1111/j.1467-8659.2009.01694.x"], "wos": 1, "children": [{"doi": "10.1109/tvcg.2020.3030456", "title": "Cartographic Relief Shading with Neural Networks", "year": "2020", "conferenceName": "InfoVis", "authors": "Bernhard Jenny;Magnus Heitzler;Dilpreet Singh;Marianna Farmakis-Serebryakova;Jeffery Chieh Liu;Lorenz Hurni", "citationCount": "4", "affiliation": "Jenny, B (Corresponding Author), Monash Univ, Melbourne, Vic, Australia. Jenny, Bernhard; Singh, Dilpreet; Liu, Jeffery Chieh, Monash Univ, Melbourne, Vic, Australia. Heitzler, Magnus; Farmakis-Serebryakova, Marianna; Hurni, Lorenz, Swiss Fed Inst Technol, Inst Cartog \\& Geoinformat, Zurich, Switzerland.", "countries": "Switzerland;Australia", "abstract": "Shaded relief is an effective method for visualising terrain on topographic maps, especially when the direction of illumination is adapted locally to emphasise individual terrain features. However, digital shading algorithms are unable to fully match the expressiveness of hand-crafted masterpieces, which are created through a laborious process by highly specialised cartographers. We replicate hand-drawn relief shading using U-Net neural networks. The deep neural networks are trained with manual shaded relief images of the Swiss topographic map series and terrain models of the same area. The networks generate shaded relief that closely resemble hand-drawn shaded relief art. The networks learn essential design principles from manual relief shading such as removing unnecessary terrain details, locally adjusting the illumination direction to accentuate individual terrain features, and varying brightness to emphasise larger landforms. Neural network shadings are generated from digital elevation models in a few seconds, and a study with 18 relief shading experts found that they are of high quality.", "keywords": "Relief shading,shaded relief,hillshade,neural rendering,illustrative visualisation,image-to-image translation", "link": "http://dx.doi.org/10.1109/TVCG.2020.3030456", "refList": ["10.1145/1456650.1456652", "10.1145/1145/1556262.1556270", "10.1145/345513.345271", "10.1109/tvcg.2019.2934803", "10.1145/3180658", "10.1109/tridui.2006.1618264", "10.3389/fict.2018.00015", "10.1109/vr.2018.8447558", "10.1518/hfes.45.1.160.27234", "10.1145/3290605.3300377", "10.1089/cpb.2006.9.157", "10.1007/s00779-011-0500-3", "10.1109/vl.1996.545307", "10.1109/tvcg.2019.2934415", "10.1109/5.726791", "10.1145/3290605.3300288", "10.1109/tvcg.2017.2745941", "10.1109/vr.2001.913779", "10.1145/586081.586086", "10.18637/jss.v067.i01", "10.1145/1502800.1502805", "10.1145/1165734.1165736", "10.1145/3126594.3126613", "10.1109/tvcg.2008.109", "10.1109/tvcg.2017.2744184", "10.1016/j.cola.2019.100937", "10.1109/visual.2019.8933545", "10.1145/3290605.3300555", "10.1111/cgf.13431", "10.1109/tvcg.2019.2934395", "10.1109/vr.2019.8798340", "10.1145/3025453.3026046", "10.1109/vr.2019.8797871", "10.1145/3290605.3300752", "10.1109/tvcg.2016.2520921", "10.1109/tvcg.2018.2865191", "10.1145/1970378.1970384", "10.1109/tvcg.2019.2934208", "10.18637/jss.v069.i01", "10.1162/105474698565659", "10.1145/1124772.1124775", "10.1109/vrais.1997.583043"], "wos": 1, "children": [], "len": 1}, {"doi": "10.1109/tvcg.2020.3030443", "title": "CAVA: A Visual Analytics System for Exploratory Columnar Data Augmentation Using Knowledge Graphs", "year": "2020", "conferenceName": "VAST", "authors": "Dylan Cashman;Shenyu Xu;Subhajit Das;Florian Heimerl;Cong Liu;Shah Rukh Humayoun;Michael Gleicher;Alex Endert;Remco Chang", "citationCount": "0", "affiliation": "Cashman, D (Corresponding Author), Tufts Univ, Medford, MA 02155 USA. Cashman, Dylan; Liu, Cong; Chang, Remco, Tufts Univ, Medford, MA 02155 USA. Xu, Shenyu; Das, Subhajit; Endert, Alex, Georgia Tech, Atlanta, GA USA. Heimerl, Florian; Gleicher, Michael, Univ Wisconsin, Madison, WI 53706 USA. Humayoun, Shah Rukh, San Francisco State Univ, San Francisco, CA 94132 USA.", "countries": "USA", "abstract": "Most visual analytics systems assume that all foraging for data happens before the analytics process; once analysis begins, the set of data attributes considered is fixed. Such separation of data construction from analysis precludes iteration that can enable foraging informed by the needs that arise in-situ during the analysis. The separation of the foraging loop from the data analysis tasks can limit the pace and scope of analysis. In this paper, we present CAVA, a system that integrates data curation and data augmentation with the traditional data exploration and analysis tasks, enabling information foraging in-situ during analysis. Identifying attributes to add to the dataset is difficult because it requires human knowledge to determine which available attributes will be helpful for the ensuing analytical tasks. CAVA crawls knowledge graphs to provide users with a a broad set of attributes drawn from external data to choose from. Users can then specify complex operations on knowledge graphs to construct additional attributes. CAVA shows how visual analytics can help users forage for attributes by letting users visually explore the set of available data, and by serving as an interface for query construction. It also provides visualizations of the knowledge graph itself to help users understand complex joins such as multi-hop aggregations. We assess the ability of our system to enable users to perform complex data combinations without programming in a user study over two datasets. We then demonstrate the generalizability of CAVA through two additional usage scenarios. The results of the evaluation confirm that CAVA is effective in helping the user perform data foraging that leads to improved analysis outcomes, and offer evidence in support of integrating data augmentation as a part of the visual analytics pipeline.", "keywords": "Visual Analytics,Information Foraging,Data Augmentation", "link": "http://dx.doi.org/10.1109/TVCG.2020.3030443", "refList": ["10.1057/palgrave.ivs.9500122", "10.1109/tvcg.2016.2598867", "10.1111/cgf.13708", "10.1109/tvcg.2019.2934799", "10.1109/tvcg.2019.2934541", "10.1109/tvcg.2013.65", "10.1109/tvcg.2018.2875702", "10.1109/iv.2004.1320207", "10.1068/p260471", "10.1145/1778765.1778816", "10.1109/tvcg.2018.2808489", "10.1109/tvcg.2018.2864912", "10.1016/j.apgeog.2015.12.006", "10.1111/j.1467-8659.2011.01960.x", "10.1109/tvcg.2018.2864843", "10.1109/pacificvis.2010.5429604", "10.1109/tvcg.2014.2346898", "10.1109/5.726791", "10.1177/1475090214540874", "10.1109/icde.2016.7498287", "10.1145/1556262.1556289", "10.1109/tvcg.2007.70535", "10.1109/vast.2012.6400489", "10.1145/1056808.1056914", "10.1016/j.neucom.2014.09.063", "10.1145/7529.8927", "10.1109/tvcg.2016.2598495", "10.1109/tvcg.2016.2607204", "10.1109/vast47406.2019.8986943", "10.3758/bf03205986", "10.1109/infvis.2005.1532142", "10.1145/1150402.1150479", "10.1109/tvcg.2017.2674978", "10.1109/tvcg.2019.2945960", "10.1109/tvcg.2017.2744098", "10.1109/tvcg.2017.2674999", "10.1109/tvcg.2011.279", "10.1109/tvcg.2014.2346594", "10.1109/tvcg.2017.2744184", "10.1111/cgf.12876", "10.1007/s4095-020-0191-7", "10.1007/s11390-015-1535-0", "10.1111/cgf.12640", "10.1109/tvcg.2016.2598667", "10.1111/cgf.13683", "10.1109/tvcg.2013.153", "10.1109/tvcg.2019.2934208", "10.1109/tvcg.2019.2934655", "10.1111/cgf.12655", "10.1007/s11023-010-9221-z", "10.1109/vast.2012.6400487", "10.1145/2702123.2702585", "10.1007/bf00310175", "10.1109/tvcg.2017.2744378", "10.1103/physreve.64.061907", "10.1109/ldav.2017.8231848", "10.1109/tvcg.2016.2598831"], "wos": 1, "children": [], "len": 1}, {"doi": "10.1109/tvcg.2020.3030432", "title": "Evaluation of Sampling Methods for Scatterplots", "year": "2020", "conferenceName": "VAST", "authors": "Jun Yuan;Shouxing Xiang;Jiazhi Xia;Lingyun Yu;Shixia Liu", "citationCount": "0", "affiliation": "Liu, SX (Corresponding Author), Tsinghua Univ, BNRist, Beijing, Peoples R China. Yuan, Jun; Xiang, Shouxing; Liu, Shixia, Tsinghua Univ, BNRist, Beijing, Peoples R China. Xia, Jiazhi, Cent South Univ, Changsha, Peoples R China. Yu, Lingyun, Xian Jiaotong Liverpool Univ, Suzhou, Peoples R China.", "countries": "China", "abstract": "Given a scatterplot with tens of thousands of points or even more, a natural question is which sampling method should be used to create a small but \u201cgood\u201d scatterplot for a better abstraction. We present the results of a user study that investigates the influence of different sampling strategies on multi-class scatterplots. The main goal of this study is to understand the capability of sampling methods in preserving the density, outliers, and overall shape of a scatterplot. To this end, we comprehensively review the literature and select seven typical sampling strategies as well as eight representative datasets. We then design four experiments to understand the performance of different strategies in maintaining: 1) region density; 2) class density; 3) outliers; and 4) overall shape in the sampling results. The results show that: 1) random sampling is preferred for preserving region density; 2) blue noise sampling and random sampling have comparable performance with the three multi-class sampling strategies in preserving class density; 3) outlier biased density based sampling, recursive subdivision based sampling, and blue noise sampling perform the best in keeping outliers; and 4) blue noise sampling outperforms the others in maintaining the overall shape of a scatterplot.", "keywords": "Scatterplot,data sampling,empirical evaluation", "link": "http://dx.doi.org/10.1109/TVCG.2020.3030432", "refList": ["10.1057/palgrave.ivs.9500122", "10.1109/tvcg.2016.2598867", "10.1109/tvcg.2015.2467591", "10.1111/cgf.13708", "10.1109/tvcg.2019.2934799", "10.1109/tvcg.2019.2934541", "10.1109/tvcg.2013.65", "10.1109/iv.2004.1320207", "10.1068/p260471", "10.1145/1778765.1778816", "10.1109/tvcg.2018.2808489", "10.1109/tvcg.2018.2864912", "10.1016/j.apgeog.2015.12.006", "10.1111/j.1467-8659.2011.01960.x", "10.1109/tvcg.2018.2864843", "10.1109/pacificvis.2010.5429604", "10.1109/tvcg.2014.2346898", "10.1109/5.726791", "10.1177/1475090214540874", "10.1145/1556262.1556289", "10.1109/tvcg.2007.70535", "10.1109/vast.2012.6400489", "10.1145/1056808.1056914", "10.1016/j.neucom.2014.09.063", "10.1145/7529.8927", "10.1109/tvcg.2016.2607204", "10.1109/vast47406.2019.8986943", "10.3758/bf03205986", "10.1109/infvis.2005.1532142", "10.1145/1150402.1150479", "10.1109/tvcg.2017.2674978", "10.1109/tvcg.2017.2744098", "10.1109/tvcg.2017.2674999", "10.1109/tvcg.2011.279", "10.1109/tvcg.2014.2346594", "10.1109/tvcg.2017.2744184", "10.1111/cgf.12876", "10.1109/1011101.2019.2945960", "10.1007/s4095-020-0191-7", "10.1007/s11390-015-1535-0", "10.1111/cgf.12640", "10.1109/tvcg.2016.2598667", "10.1111/cgf.13683", "10.1109/tvcg.2013.153", "10.1109/tvcg.2019.2934208", "10.1109/tvcg.2019.2934655", "10.1111/cgf.12655", "10.1007/s11023-010-9221-z", "10.1109/vast.2012.6400487", "10.1145/2702123.2702585", "10.1007/bf00310175", "10.1109/tvcg.2017.2744378", "10.1103/physreve.64.061907", "10.1109/ldav.2017.8231848", "10.1109/tvcg.2016.2598831"], "wos": 1, "children": [], "len": 1}], "len": 7}, {"doi": "10.1109/tvcg.2019.2934300", "title": "GUIRO: User-Guided Matrix Reordering", "year": "2019", "conferenceName": "VAST", "authors": "Michael Behrisch;Tobias Schreck;Hanspeter Pfister", "citationCount": "1", "affiliation": "Behrisch, M (Corresponding Author), Harvard Univ, Sch Engn \\& Appl Sci, Cambridge, MA 02138 USA. Behrisch, Michael; Pfister, Hanspeter, Harvard Univ, Sch Engn \\& Appl Sci, Cambridge, MA 02138 USA. Schreck, Tobias, Graz Univ Technol, Graz, Austria.", "countries": "USA;Austria", "abstract": "Matrix representations are one of the main established and empirically proven to be effective visualization techniques for relational (or network) data. However, matrices\u2014similar to node-link diagrams\u2014are most effective if their layout reveals the underlying data topology. Given the many developed algorithms, a practical problem arises: \u201cWhich matrix reordering algorithm should I choose for my dataset at hand?\u201d To make matters worse, different reordering algorithms applied to the same dataset may let significantly different visual matrix patterns emerge. This leads to the question of trustworthiness and explainability of these fully automated, often heuristic, black-box processes. We present GUIRO, a Visual Analytics system that helps novices, network analysts, and algorithm designers to open the black-box. Users can investigate the usefulness and expressiveness of 70 accessible matrix reordering algorithms. For network analysts, we introduce a novel model space representation and two interaction techniques for a user-guided reordering of rows or columns, and especially groups thereof (submatrix reordering). These novel techniques contribute to the understanding of the global and local dataset topology. We support algorithm designers by giving them access to 16 reordering quality metrics and visual exploration means for comparing reordering implementations on a row/column permutation level. We evaluated GUIRO in a guided explorative user study with 12 subjects, a case study demonstrating its usefulness in a real-world scenario, and through an expert study gathering feedback on our design decisions. We found that our proposed methods help even inexperienced users to understand matrix patterns and allow a user-guided steering of reordering algorithms. GUIRO helps to increase the transparency of matrix reordering algorithms, thus helping a broad range of users to get a better insight into the complex reordering process, in turn supporting data and reordering algorithm insights.", "keywords": "Visual Analytics,matrix,black-box algorithms,seriation,ordering,sorting,steerable algorithm,interaction,2D projection", "link": "http://dx.doi.org/10.1109/TVCG.2019.2934300", "refList": ["10.1109/tvcg.2007.70582", "10.2307/276978", "10.1109/tvcg.2008.61", "10.3390/su10040973", "10.1101/121889", "10.1145/1345448.1345453", "10.1186/s12879-014-0695-9", "10.1186/1471-2105-9-155", "10.1145/1124772.1124891", "10.1109/tvcg.2010.159", "10.1111/j.2044-8317.1974.tb00534.x", "10.1109/tpami.2015.2470671", "10.1198/000313005x22770", "10.1109/tvcg.2012.219", "10.1002/sam.10071", "10.1016/j.ejor.2016.08.066", "10.1007/s00265-003-0651-y", "10.1109/biovis.2013.6664342", "10.3115/v1/p14-1062", "10.3389/fpsyg.2017.01349", "10.1109/tpami.2004.1265866", "10.1057/palgrave.ivs.9500086", "10.1007/s004260000031", "10.1111/cgf.12935", "10.1145/800195.805928", "10.1109/tvcg.2014.2346279", "10.2312/eurovisstar.20141174", "10.1109/tvcg.2012.256", "10.1093/bioinformatics/17.suppl\\_1.s22", "10.1109/infvis.2004.46", "10.1007/978-3-319-06793-3\\_5", "10.1109/tvcg.2006.147", "10.1109/tvcg.2015.2468078", "10.1093/bioinformatics/bti141", "10.1145/1168149.1168168", "10.1109/tvcg.2017.2745978", "10.1177/1473871613513228", "10.1109/mcg.2014.62", "10.1109/tvcg.2006.166", "10.1145/2470654.2470724", "10.1177/154193120605000909", "10.1109/sibgrapi.2007.21", "10.1145/3065386", "10.1109/tvcg.2006.160", "10.1287/opre.20.5.993", "10.1111/cgf.13446", "10.1057/palgrave.ivs.9500092", "10.1145/568522.568523", "10.1109/mcg.2013.66", "10.1109/tvcg.2018.2865940", "10.1109/tvcg.2012.208"], "wos": 1, "children": [{"doi": "10.1109/tvcg.2020.3030471", "title": "Visual Analysis of Discrimination in Machine Learning", "year": "2020", "conferenceName": "InfoVis", "authors": "Qianwen Wang;Zhenhua Xu;Zhutian Chen;Yong Wang;Shixia Liu;Huamin Qu", "citationCount": "0", "affiliation": "Wang, QW (Corresponding Author), Hong Kong Univ Sci \\& Technol, Hong Kong, Peoples R China. Wang, Qianwen; Xu, Zhenhua; Chen, Zhutian; Wang, Yong; Qu, Huamin, Hong Kong Univ Sci \\& Technol, Hong Kong, Peoples R China. Liu, Shixia, Tsinghua Univ, Beijing, Peoples R China.", "countries": "China", "abstract": "The growing use of automated decision-making in critical applications, such as crime prediction and college admission, has raised questions about fairness in machine learning. How can we decide whether different treatments are reasonable or discriminatory? In this paper, we investigate discrimination in machine learning from a visual analytics perspective and propose an interactive visualization tool, DiscriLens, to support a more comprehensive analysis. To reveal detailed information on algorithmic discrimination, DiscriLens identifies a collection of potentially discriminatory itemsets based on causal modeling and classification rules mining. By combining an extended Euler diagram with a matrix-based visualization, we develop a novel set visualization to facilitate the exploration and interpretation of discriminatory itemsets. A user study shows that users can interpret the visually encoded information in DiscriLens quickly and accurately. Use cases demonstrate that DiscriLens provides informative guidance in understanding and reducing algorithmic discrimination.", "keywords": "Machine Learning,Discrimination,Data Visualization", "link": "http://dx.doi.org/10.1109/TVCG.2020.3030471", "refList": ["10.1109/tvcg.2019.2934396", "10.2312/eurovisstar.20141170", "10.1145/3357384.3357910", "10.1111/cgf.12791", "10.1109/tvcg.2018.2861397", "10.1111/j.1467-8659.2011.01898.x", "10.1145/2702123.2702237", "10.1109/tvcg.2019.2934798", "10.1109/mcg.2017.21", "10.1109/tvcg.2019.2934300", "10.1109/tvcg.2017.2745085", "10.1109/tvcg.2018.2859997", "10.1145/3173574.3174237", "10.1109/tvcg.2018.2865126", "10.1145/1718487.1718520", "10.1109/tvcg.2017.2743858", "10.1109/pacificvis.2015.7156392", "10.1109/tvcg.2018.2864477", "10.1145/324133.324140", "10.1137/140976649", "10.1145/3219819.3220088", "10.1109/tvcg.2019.2934805", "10.1145/1134271.1134277", "10.1137/090772745", "10.1016/j.jelectrocard.2010.09.003", "10.1109/tvcg.2012.253", "10.1145/2556612", "10.1109/tvcg.2013.173", "10.1109/tvcg.2019.2934619", "10.1109/tvcg.2017.2745078"], "wos": 1, "children": [], "len": 1}], "len": 3}, {"doi": "10.1109/tvcg.2019.2934796", "title": "Improving the Robustness of Scagnostics", "year": "2019", "conferenceName": "InfoVis", "authors": "Yunhai Wang;Zeyu Wang 0005;Tingting Liu;Michael Correll;Zhanglin Cheng;Oliver Deussen;Michael Sedlmair", "citationCount": "1", "affiliation": "Wang, YH (Corresponding Author), Shandong Univ, Jinan, Peoples R China. Wang, Yunhai; Wang, Zeyu; Liu, Tingting, Shandong Univ, Jinan, Peoples R China. Wang, Zeyu; Cheng, Zhanglin; Deussen, Oliver, SIAT, Shenzhen VisuCA Key Lab, Shenzhen, Peoples R China. Correll, Michael, Tableau Res, Seattle, WA USA. Deussen, Oliver, Konstanz Univ, Constance, Germany. Sedlmair, Michael, Univ Stuttgart, VISUS, Stuttgart, Germany.", "countries": "USA;Germany;China", "abstract": "In this paper, we examine the robustness of scagnostics through a series of theoretical and empirical studies. First, we investigate the sensitivity of scagnostics by employing perturbing operations on more than 60M synthetic and real-world scatterplots. We found that two scagnostic measures, Outlying and Clumpy, are overly sensitive to data binning. To understand how these measures align with human judgments of visual features, we conducted a study with 24 participants, which reveals that i) humans are not sensitive to small perturbations of the data that cause large changes in both measures, and ii) the perception of clumpiness heavily depends on per-cluster topologies and structures. Motivated by these results, we propose Robust Scagnostics (RScag) by combining adaptive binning with a hierarchy-based form of scagnostics. An analysis shows that RScag improves on the robustness of original scagnostics, aligns better with human judgments, and is equally fast as the traditional scagnostic measures.", "keywords": "Scagnostics,scatterplots,sensitivity analysis,Robust Scagnostics", "link": "http://dx.doi.org/10.1109/TVCG.2019.2934796", "refList": ["10.1057/palgrave.ivs.9500122", "10.1109/tvcg.2014.2346979", "10.1111/j.1467-8659.2009.01467.x", "10.1109/vast.2008.4677368", "10.2307/2289444", "10.1109/tvcg.2011.229", "10.1109/iv.2004.1320207", "10.1109/vast.2009.5332628", "10.1111/insr.12095\\_11", "10.1109/tvcg.2010.184", "10.1109/tvcg.2015.2467323", "10.1109/vast.2010.5652460", "10.1111/j.1467-8659.2012.03069.x", "10.1145/1842993.1843002", "10.1198/106186008x320465", "10.1109/pacificvis.2016.7465244", "10.1109/tvcg.2013.20", "10.1111/cgf.12641", "10.1109/tvcg.2012.128", "10.1109/tvcg.2015.2467671", "10.1057/palgrave.ivs.9500091", "10.1007/978-1-4612-4400-4", "10.1111/cgf.13176", "10.1002/0470870958", "10.1109/tvcg.2018.2864907", "10.1111/j.1467-8659.2012.03125.x", "10.1109/vast.2012.6400490", "10.1109/infvis.2005.1532142", "10.1109/vast.2010.5652433", "10.1109/vast.2009.5332611", "10.1201/9781315140919", "10.1145/2858036.2858155", "10.1109/ldav.2013.6675164", "10.1515/itit-2014-1070", "10.1111/cgf.13684", "10.1109/tpami.1979.4766909", "10.2307/2289936", "10.1109/pacificvis.2014.42", "10.1109/tvcg.2016.2598467", "10.1109/tvcg.2013.153", "10.1111/cgf.13446", "10.1109/tvcg.2006.94", "10.1109/tvcg.2014.2346572", "10.1111/cgf.12632", "10.1109/tvcg.2017.2744339"], "wos": 1, "children": [], "len": 1}, {"doi": "10.1109/vast47406.2019.8986917", "title": "VIANA: Visual Interactive Annotation of Argumentation", "year": "2019", "conferenceName": "VAST", "authors": "Fabian Sperrle;Rita Sevastjanova;Rebecca Kehlbeck;Mennatallah El-Assady", "citationCount": "0", "affiliation": "Sperrle, F (Corresponding Author), Univ Konstanz, Constance, Germany. Sperrle, Fabian; Sevastjanova, Rita; Kehlbeck, Rebecca; El-Assady, Mennatallah, Univ Konstanz, Constance, Germany.", "countries": "Germany", "abstract": "Argumentation Mining addresses the challenging tasks of identifying boundaries of argumentative text fragments and extracting their relationships. Fully automated solutions do not reach satisfactory accuracy due to their insufficient incorporation of semantics and domain knowledge. Therefore, experts currently rely on time-consuming manual annotations. In this paper, we present a visual analytics system that augments the manual annotation process by automatically suggesting which text fragments to annotate next. The accuracy of those suggestions is improved over time by incorporating linguistic knowledge and language modeling to learn a measure of argument similarity from user interactions. Based on a long-term collaboration with domain experts, we identify and model five high-level analysis tasks. We enable close reading and note-taking, annotation of arguments, argument reconstruction, extraction of argument relations, and exploration of argument graphs. To avoid context switches, we transition between all views through seamless morphing, visually anchoring all text- and graph-based layers. We evaluate our system with a two-stage expert user study based on a corpus of presidential debates. The results show that experts prefer our system over existing solutions due to the speedup provided by the automatic suggestions and the tight integration between text and graph views.", "keywords": "Argumentation annotation,machine learning,user interaction,layered interfaces,semantic transitions", "link": "http://dx.doi.org/10.1109/VAST47406.2019.8986917", "refList": ["10.1007/978-3-642-40624-9\\_1", "10.3233/978-1-61499-436-7-185", "10.1145/371920.372071", "10.3233/978-1-61499-906-5-4", "10.1109/tvcg.2015.2467759", "10.18653/v1/d15-1050", "10.2307/2529310", "10.1109/mic.2003.1167344", "10.1145/312624.312682", "10.1145/2850417", "10.18653/v1/p17-2039", "10.1016/j.eswa.2016.02.013", "10.1007/978-0-387-85820-3\\_3", "10.1007/s11412-009-9080-x", "10.1109/tvcg.2008.127", "10.1145/2207676.2207741", "10.1109/cit.2012.217", "10.3233/aac-170022", "10.1109/tvcg.2017.2745080", "10.1007/978-3-319-44039-2\\_6", "10.1145/3290605.3300233", "10.1007/978-94-017-0431-1", "10.3233/978-1-61499-906-5-313", "10.1142/s0218213004001922", "10.1109/tvcg.2012.262", "10.1177/001316446002000104", "10.1109/tvcg.2018.2834341", "10.3233/978-1-61499-436-7-463", "10.1145/1772690.1772773", "10.1109/tvcg.2014.2346677", "10.1145/2523813", "10.1162/153244303322533223", "10.1109/tvcg.2007.70539", "10.1109/tvcg.2015.2467531", "10.1109/tvcg.2018.2864769", "10.1007/978-3-319-90092-6\\_14", "10.1137/1.9781611972801.19", "10.1109/vast.2012.6400485", "10.1007/s10579-013-9215-6", "10.3115/v1/d14-1162", "10.1111/cgf.13446", "10.1109/tvcg.2006.156", "10.1111/cgf.13092", "10.1145/2645710.2645759", "10.1109/bigdata.2017.8258140", "10.1145/2669557.2669572", "10.2312/eurovisstar.20151113"], "wos": 1, "children": [], "len": 1}, {"doi": "10.1109/tvcg.2020.3030376", "title": "Insight Beyond Numbers: The Impact of Qualitative Factors on Visual Data Analysis", "year": "2020", "conferenceName": "VAST", "authors": "Benjamin Karer;Hans Hagen;Dirk J. Lehmann", "citationCount": "0", "affiliation": "Karer, B (Corresponding Author), Fed Criminal Police Off Germany, Wiesbaden, Germany. Karer, Benjamin, Fed Criminal Police Off Germany, Wiesbaden, Germany. Hagen, Hans, TU Kaiserslautern, Kaiserslautern, Germany. Lehmann, Dirk J., Ostfalia Univ Appl Sci, Wolfenbuttel, Germany. Lehmann, Dirk J., IAV GmbH, Berlin, Germany.", "countries": "Germany", "abstract": "As of today, data analysis focuses primarily on the findings to be made inside the data and concentrates less on how those findings relate to the domain of investigation. Contemporary visualization as a field of research shows a strong tendency to adopt this data-centrism. Despite their decisive influence on the analysis result, qualitative aspects of the analysis process such as the structure, soundness, and complexity of the applied reasoning strategy are rarely discussed explicitly. We argue that if the purpose of visualization is the provision of domain insight rather than the depiction of data analysis results, a holistic perspective requires a qualitative component to to be added to the discussion of quantitative and human factors. To support this point, we demonstrate how considerations of qualitative factors in visual analysis can be applied to obtain explanations and possible solutions for a number of practical limitations inherent to the data-centric perspective on analysis. Based on this discussion of what we call qualitative visual analysis, we develop an inside-outside principle of nested levels of context that can serve as a conceptual basis for the development of visualization systems that optimally support the emergence of insight during analysis.", "keywords": "Visualization,Reasoning,Qualitative Aspects", "link": "http://dx.doi.org/10.1109/TVCG.2020.3030376", "refList": ["10.1057/ivs.2009.22", "10.1109/tvcg.2015.2467732", "10.1109/infvis.2000.885092", "10.1109/vast.2014.7042482", "10.1145/1498700.1498704", "10.1109/tvcg.2009.108", "10.1109/tvcg.2018.2829750", "10.1037/0033-295x.111.4.1036", "10.1109/tvcg.2012.199", "10.1109/38.267476", "10.1007/978-3-540-70956-5\\_2", "10.1109/tvcg.2015.2467613", "10.1109/tvcg.2015.2467195", "10.1109/tvcg.2014.2346419", "10.1109/vast.2017.8585669", "10.1109/tvcg.2010.132", "10.1145/22949.22950", "10.1109/tvcg.2014.2346984", "10.1017/cbo9780511816772", "10.1109/mcg.2003.1231171", "10.1111/coin.12227", "10.1109/tvcg.2018.2865138", "10.1109/38.788803", "10.1109/tvcg.2018.2864849", "10.1109/mcg.2012.120", "10.1109/tvcg.2007.70535", "10.1162/neco.2008.12-06-420", "10.1109/tvcg.2018.2865240", "10.1089/tmj.2010.0114", "10.1109/beliv.2018.8634267", "10.1109/tvcg.2014.2346481", "10.1207/s15327809jls0402\\_2", "10.1109/tvcg.2006.80", "10.1145/2858036.2858280", "10.1109/tvcg.2017.2674978", "10.1109/tvcg.2011.52", "10.1016/j.cag.2014.03.002", "10.1109/tvcg.2015.2513410", "10.1111/j.1756-8765.2011.01150.x", "10.1109/infvis.2005.1532142", "10.1002/spe.4380211102", "10.1186/s41235-018-0120-9", "10.1073/pnas.1807180116", "10.1109/tvcg.2012.133", "10.1109/tvcg.2012.273", "10.1111/j.1467-8659.2011.01928.x", "10.1145/353485.353486", "10.1109/tvcg.2015.2462356", "10.1109/mcg.2019.2923483", "10.1111/cgf.13264", "10.1057/palgrave.ivs.9500070", "10.1145/1168149.1168158", "10.1109/mcg.2019.2961716", "10.1016/s0167-739x(96)00029-5", "10.1111/j.1467-8659.2009.01667.x", "10.1177/1473871611415989", "10.1109/tvcg.2013.234", "10.1109/iv.2012.33", "10.1111/cgf.13446", "10.1057/ivs.2008.28", "10.1111/cgf.12379", "10.1037/0033-295x.112.1.159", "10.1109/tvcg.2010.161", "10.1109/tvcg.2017.2744319", "10.1145/989863.989880", "10.1007/s11390-016-1663-1", "10.1177/1473871615609787", "10.1016/j.cola.2019.100911"], "wos": 1, "children": [], "len": 1}, {"doi": "10.1109/tvcg.2020.3030395", "title": "Towards Modeling Visualization Processes as Dynamic Bayesian Networks", "year": "2020", "conferenceName": "InfoVis", "authors": "Christian Heine 0002", "citationCount": "0", "affiliation": "Heine, C (Corresponding Author), Univ Leipzig, Leipzig, Germany. Heine, Christian, Univ Leipzig, Leipzig, Germany.", "countries": "Germany", "abstract": "Visualization designs typically need to be evaluated with user studies, because their suitability for a particular task is hard to predict. What the field of visualization is currently lacking are theories and models that can be used to explain why certain designs work and others do not. This paper outlines a general framework for modeling visualization processes that can serve as the first step towards such a theory. It surveys related research in mathematical and computational psychology and argues for the use of dynamic Bayesian networks to describe these time-dependent, probabilistic processes. It is discussed how these models could be used to aid in design evaluation. The development of concrete models will be a long process. Thus, the paper outlines a research program sketching how to develop prototypes and their extensions from existing models, controlled experiments, and observational studies.", "keywords": "Visualization,model building,perception,cognition,dynamic Bayesian networks", "link": "http://dx.doi.org/10.1109/TVCG.2020.3030395", "refList": ["10.1057/ivs.2009.22", "10.1109/tvcg.2015.2467732", "10.1109/infvis.2000.885092", "10.1109/vast.2014.7042482", "10.1145/1498700.1498704", "10.1109/tvcg.2009.108", "10.1109/tvcg.2018.2829750", "10.1037/0033-295x.111.4.1036", "10.1109/tvcg.2012.199", "10.1111/cgf.13899", "10.1109/38.267476", "10.1007/978-3-540-70956-5\\_2", "10.1109/tvcg.2015.2467613", "10.1109/tvcg.2015.2467195", "10.1109/tvcg.2014.2346419", "10.1145/3290605.3300562", "10.1109/vl.1996.545307", "10.1109/vast.2017.8585669", "10.1109/infvis.2003.1249004", "10.1109/tvcg.2010.132", "10.1145/22949.22950", "10.1109/tvcg.2014.2346984", "10.1145/3290605.3300418", "10.1017/cbo9780511816772", "10.1109/mcg.2003.1231171", "10.1111/coin.12227", "10.1109/tvcg.2018.2865138", "10.1109/38.788803", "10.1109/tvcg.2018.2864849", "10.1109/mcg.2012.120", "10.1109/tvcg.2007.70535", "10.1162/neco.2008.12-06-420", "10.1109/tvcg.2018.2865240", "10.1089/tmj.2010.0114", "10.1109/beliv.2018.8634267", "10.1109/tvcg.2014.2346481", "10.1207/s15327809jls0402\\_2", "10.1109/tvcg.2006.80", "10.1145/2858036.2858280", "10.1109/tvcg.2017.2674978", "10.1109/tvcg.2011.52", "10.1016/j.cag.2014.03.002", "10.1109/tvcg.2015.2513410", "10.1111/j.1756-8765.2011.01150.x", "10.1109/infvis.2005.1532142", "10.1002/spe.4380211102", "10.1186/s41235-018-0120-9", "10.1073/pnas.1807180116", "10.1109/tvcg.2012.133", "10.1109/tvcg.2012.273", "10.1111/j.1467-8659.2011.01928.x", "10.1145/353485.353486", "10.1109/tvcg.2015.2462356", "10.1109/mcg.2019.2923483", "10.1111/cgf.13264", "10.1057/palgrave.ivs.9500070", "10.1145/1168149.1168158", "10.1109/mcg.2019.2961716", "10.1016/s0167-739x(96)00029-5", "10.1111/j.1467-8659.2009.01667.x", "10.1177/1473871611415989", "10.1109/tvcg.2013.234", "10.1109/iv.2012.33", "10.1111/cgf.13446", "10.1057/ivs.2008.28", "10.1111/cgf.12379", "10.1037/0033-295x.112.1.159", "10.1017/cb09781139033916.005", "10.1109/tvcg.2010.161", "10.1109/tvcg.2017.2744319", "10.1145/989863.989880", "10.1007/s11390-016-1663-1", "10.1177/1473871615609787", "10.1016/j.cola.2019.100911", "10.1057/palgrave.ivs.9500025"], "wos": 1, "children": [], "len": 1}, {"doi": "10.1109/pacificvis48177.2020.8199", "year": "2020", "title": "Efficient Morphing of Shape-preserving Star Coordinates", "conferenceName": "PacificVis", "authors": "Vladimir Molchanov;Sagad Hamid;Lars Linsen", "citationCount": "0", "affiliation": "Molchanov, V (Corresponding Author), Westfalische Wilhelms Univ Munster, Munster, Germany.\nMolchanov, Vladimir; Hamid, Sagad; Linsen, Lars, Westfalische Wilhelms Univ Munster, Munster, Germany.", "countries": "Germany", "abstract": "Data tours follow an exploratory multi-dimensional data visualization concept that provides animations of projections of the multidimensional data to a 2D visual space. To create an animation, a sequence of key projections is provided and morphings between each pair of consecutive key projections are computed, which then can be stitched together to form the data tour. The morphings should be smooth so that a user can easily follow the transformations, and their computations shall be fast to allow for their integration into an interactive visual exploration process. Moreover, if the key projections are chosen to satisfy additional conditions, it is desirable that these conditions are maintained during morphing. Shape preservation is such a desirable condition, as it avoids shape distortions that may otherwise be caused by a projection. We develop a novel efficient morphing algorithms for computing shape-preserving data tours, i.e., data tours constructed for a sequence of shape-preserving linear projections. We propose a stepping strategy for the morphing to avoid discontinuities in the evolution of the projections, where we represent the linear projections using a star-coordinates system. Our algorithms are less computationally involved, produce smoother morphings, and require less user-defined parameter settings than existing state-of-the-art approaches.", "keywords": "Human-centered computing; Visualization; Visualization techniques", "link": "https://doi.org/10.1109/PacificVis48177.2020.8199", "refList": ["10.2312/eurovisshort.20141152", "10.1109/tvcg.2013.182", "10.1109/tvcg.2008.153", "10.1109/tvcg.2015.2467591", "10.4135/9781412985130", "10.1111/cgf.12878", "10.1016/j.cag.2016.08.007", "10.1080/10618600.1995.10474674", "10.1109/infvis.2003.1249004", "10.1002/9781118445112.stat06472", "10.1109/visual.1997.663916", "10.1111/cgf.12117", "10.1137/0906011", "10.1109/tvcg.2018.2865118", "10.1126/science.290.5500.2319", "10.1111/cgf.12845", "10.1111/j.1467-8659.2012.03125.x", "10.1109/tvcg.2017.2705189", "10.1002/0471725293", "10.1111/cgf.12876", "10.1111/cgf.13404", "10.2307/2289161", "10.1111/cgf.13446", "10.1198/106186008x318440", "10.2307/1390747", "10.1109/tvcg.2012.35", "10.1109/tvcg.2015.2467132", "10.1109/tvcg.2006.94", "10.1109/t-c.1974.224051", "10.1109/pacificvis.2019.00018", "10.1109/tvcg.2017.2744339", "10.1109/tsmcb.2005.850151"], "wos": 1, "children": [], "len": 1}, {"doi": "10.1109/pacificvis.2019.00018", "year": "2019", "title": "Scatterplot Summarization by Constructing Fast and Robust Principal Graphs from Skeletons", "conferenceName": "PacificVis", "authors": "Jos{\\'{e}} Matute;Marcel Fischer;Alexandru C. Telea;Lars Linsen", "citationCount": "1", "affiliation": "Matute, J (Corresponding Author), Univ Munster, Munster, Germany.\nMatute, Jose; Fischer, Marcel; Linsen, Lars, Univ Munster, Munster, Germany.\nTelea, Alexandru C., Univ Groningen, Groningen, Netherlands.", "countries": "Germany;Netherlands", "abstract": "Principal curves are a long-standing and well-known method for summarizing large scatterplots. They are defined as self-consistent curves (or curve sets in the more general case) that locally pass through the middle of the scatterplot data. However, computing principal curves that capture well complex scatterplot topologies and are robust to noise is hard and/or slow for large scatterplots. We present a fast and robust approach for computing principal graphs (a generalization of principal curves for more complex topologies) inspired by the similarity to medial descriptors (curves locally centered in a shape). Compared to state-of-the-art methods for computing principal graphs, we outperform these in terms of computational scalability and robustness to noise and resolution. We also demonstrate the advantages of our method over other scatterplot summarization approaches.", "keywords": "", "link": "https://doi.org/10.1109/PacificVis.2019.00018", "refList": ["10.1016/j.cag.2014.01.006", "10.1016/s0167-8655(02)00032-6", "10.1006/jmva.2000.1917", "10.1111/cgf.12386", "10.1109/vast.2008.4677367", "10.1109/tpami.2004.1261076", "10.1111/cgf.12865", "10.1109/tvcg.2010.213", "10.1109/tvcg.2014.2346455", "10.1109/tvcg.2011.233", "10.1111/j.1467-8659.2009.01680.x", "10.1109/tvcg.2016.2515611", "10.1109/tit.1982.1056489", "10.1109/34.899944", "10.1007/bf01889678", "10.1137/s0036144599352836", "10.1145/2858036.2858155", "10.1002/jhbs.20078", "10.1198/jcgs.2011.09224", "10.1109/tvcg.2017.2744184", "10.1057/ivs.2010.2", "10.1111/j.1467-8659.2012.03107.x", "10.2307/2289936", "10.1109/pacificvis.2014.42", "10.1109/tpami.2008.21", "10.1111/cgf.13446", "10.2307/2290446", "10.1109/34.982884", "10.1109/tvcg.2006.94", "10.2307/2288711", "10.1117/12.304651", "10.5201/ipol.2013.87", "10.1109/mlsp.2008.4685520"], "wos": 1, "children": [{"doi": "10.1109/pacificvis48177.2020.8199", "year": "2020", "title": "Efficient Morphing of Shape-preserving Star Coordinates", "conferenceName": "PacificVis", "authors": "Vladimir Molchanov;Sagad Hamid;Lars Linsen", "citationCount": "0", "affiliation": "Molchanov, V (Corresponding Author), Westfalische Wilhelms Univ Munster, Munster, Germany.\nMolchanov, Vladimir; Hamid, Sagad; Linsen, Lars, Westfalische Wilhelms Univ Munster, Munster, Germany.", "countries": "Germany", "abstract": "Data tours follow an exploratory multi-dimensional data visualization concept that provides animations of projections of the multidimensional data to a 2D visual space. To create an animation, a sequence of key projections is provided and morphings between each pair of consecutive key projections are computed, which then can be stitched together to form the data tour. The morphings should be smooth so that a user can easily follow the transformations, and their computations shall be fast to allow for their integration into an interactive visual exploration process. Moreover, if the key projections are chosen to satisfy additional conditions, it is desirable that these conditions are maintained during morphing. Shape preservation is such a desirable condition, as it avoids shape distortions that may otherwise be caused by a projection. We develop a novel efficient morphing algorithms for computing shape-preserving data tours, i.e., data tours constructed for a sequence of shape-preserving linear projections. We propose a stepping strategy for the morphing to avoid discontinuities in the evolution of the projections, where we represent the linear projections using a star-coordinates system. Our algorithms are less computationally involved, produce smoother morphings, and require less user-defined parameter settings than existing state-of-the-art approaches.", "keywords": "Human-centered computing; Visualization; Visualization techniques", "link": "https://doi.org/10.1109/PacificVis48177.2020.8199", "refList": ["10.2312/eurovisshort.20141152", "10.1109/tvcg.2013.182", "10.1109/tvcg.2008.153", "10.1109/tvcg.2015.2467591", "10.4135/9781412985130", "10.1111/cgf.12878", "10.1016/j.cag.2016.08.007", "10.1080/10618600.1995.10474674", "10.1109/infvis.2003.1249004", "10.1002/9781118445112.stat06472", "10.1109/visual.1997.663916", "10.1111/cgf.12117", "10.1137/0906011", "10.1109/tvcg.2018.2865118", "10.1126/science.290.5500.2319", "10.1111/cgf.12845", "10.1111/j.1467-8659.2012.03125.x", "10.1109/tvcg.2017.2705189", "10.1002/0471725293", "10.1111/cgf.12876", "10.1111/cgf.13404", "10.2307/2289161", "10.1111/cgf.13446", "10.1198/106186008x318440", "10.2307/1390747", "10.1109/tvcg.2012.35", "10.1109/tvcg.2015.2467132", "10.1109/tvcg.2006.94", "10.1109/t-c.1974.224051", "10.1109/pacificvis.2019.00018", "10.1109/tvcg.2017.2744339", "10.1109/tsmcb.2005.850151"], "wos": 1, "children": [], "len": 1}], "len": 3}, {"doi": "10.1111/cgf.13684", "year": "2019", "title": "ClustMe: A Visual Quality Measure for Ranking Monochrome Scatterplots based on Cluster Patterns", "conferenceName": "EuroVis", "authors": "Mostafa M. Abbas;Micha{\\\"{e}}l Aupetit;Michael Sedlmair;Halima Bensmail", "citationCount": "4", "affiliation": "Abbas, MM (Corresponding Author), HBKU, QCRI, Doha, Qatar.\nAbbas, Mostafa M.; Aupetit, Michael; Bensmail, Halima, HBKU, QCRI, Doha, Qatar.\nSedlmair, Michael, Univ Stuttgart, VISUS, Stuttgart, Germany.", "countries": "Qatar;Germany", "abstract": "We propose ClustMe, a new visual quality measure to rank monochrome scatterplots based on cluster patterns. ClustMe is based on data collected from a human-subjects study, in which 34 participants judged synthetically generated cluster patterns in 1000 scatterplots. We generated these patterns by carefully varying the free parameters of a simple Gaussian Mixture Model with two components, and asked the participants to count the number of clusters they could see (1 or more than 1). Based on the results, we form ClustMe by selecting the model that best predicts these human judgments among 7 different state-of-the-art merging techniques (Demp). To quantitatively evaluate ClustMe, we conducted a second study, in which 31 human subjects ranked 435 pairs of scatterplots of real and synthetic data in terms of cluster patterns complexity. We use this data to compare ClustMe's performance to 4 other state-of-the-art clustering measures, including the well-known Clumpiness scagnostics. We found that of all measures, ClustMe is in strongest agreement with the human rankings.", "keywords": "", "link": "https://doi.org/10.1111/cgf.13684", "refList": ["10.1109/tvcg.2014.2330617", "10.1109/tvcg.2014.2346979", "10.1109/tvcg.2017.2744138", "10.1109/tvcg.2017.2701829", "10.2307/2529310", "10.1109/tvcg.2011.229", "10.1109/vast.2011.6102437", "10.1068/p030033", "10.1016/j.jvcir.2011.01.005", "10.1109/tnn.2005.845141", "10.1145/2669557.2669559", "10.1167/8.7.6", "10.1145/2993901.2993907", "10.1145/2803140.2803143", "10.1145/1842993.1843002", "10.1109/pacificvis.2016.7465244", "10.1109/tvcg.2013.124", "10.1057/ivs.2008.13", "10.1109/vast.2012.6400488", "10.1111/j.1467-9574.2008.00412.x", "10.1214/aos/1176344136", "10.1109/tvcg.2015.2467671", "10.3138/y308-2422-8615-1233", "10.1111/j.1467-8659.2012.03125.x", "10.1177/001316446002000104", "10.1145/2858036.2858155", "10.1007/s11634-010-0058-3", "10.1214/009053605000000417", "10.1109/tvcg.2009.153", "10.1023/a:1018510926151", "10.1109/tvcg.2014.2346978", "10.1007/s10816-016-9307-x", "10.1177/0301006615602599", "10.1109/pacificvis.2014.42", "10.1162/neco.1991.3.2.246", "10.1007/3-540-44491-2\\_3", "10.1109/tvcg.2013.153", "10.1111/cgf.13446", "10.1109/tvcg.2018.2846735", "10.2307/2291604", "10.1109/inf0vis.2005.14", "10.1198/016214502760047131", "10.1007/s00180-008-0119-7", "10.1109/t-c.1974.224051", "10.1111/cgf.12632", "10.1109/tvcg.2017.2744339", "10.1111/j.1467-8659.2009.01694.x"], "wos": 1, "children": [{"doi": "10.1109/tvcg.2019.2934796", "title": "Improving the Robustness of Scagnostics", "year": "2019", "conferenceName": "InfoVis", "authors": "Yunhai Wang;Zeyu Wang 0005;Tingting Liu;Michael Correll;Zhanglin Cheng;Oliver Deussen;Michael Sedlmair", "citationCount": "1", "affiliation": "Wang, YH (Corresponding Author), Shandong Univ, Jinan, Peoples R China. Wang, Yunhai; Wang, Zeyu; Liu, Tingting, Shandong Univ, Jinan, Peoples R China. Wang, Zeyu; Cheng, Zhanglin; Deussen, Oliver, SIAT, Shenzhen VisuCA Key Lab, Shenzhen, Peoples R China. Correll, Michael, Tableau Res, Seattle, WA USA. Deussen, Oliver, Konstanz Univ, Constance, Germany. Sedlmair, Michael, Univ Stuttgart, VISUS, Stuttgart, Germany.", "countries": "USA;Germany;China", "abstract": "In this paper, we examine the robustness of scagnostics through a series of theoretical and empirical studies. First, we investigate the sensitivity of scagnostics by employing perturbing operations on more than 60M synthetic and real-world scatterplots. We found that two scagnostic measures, Outlying and Clumpy, are overly sensitive to data binning. To understand how these measures align with human judgments of visual features, we conducted a study with 24 participants, which reveals that i) humans are not sensitive to small perturbations of the data that cause large changes in both measures, and ii) the perception of clumpiness heavily depends on per-cluster topologies and structures. Motivated by these results, we propose Robust Scagnostics (RScag) by combining adaptive binning with a hierarchy-based form of scagnostics. An analysis shows that RScag improves on the robustness of original scagnostics, aligns better with human judgments, and is equally fast as the traditional scagnostic measures.", "keywords": "Scagnostics,scatterplots,sensitivity analysis,Robust Scagnostics", "link": "http://dx.doi.org/10.1109/TVCG.2019.2934796", "refList": ["10.1057/palgrave.ivs.9500122", "10.1109/tvcg.2014.2346979", "10.1111/j.1467-8659.2009.01467.x", "10.1109/vast.2008.4677368", "10.2307/2289444", "10.1109/tvcg.2011.229", "10.1109/iv.2004.1320207", "10.1109/vast.2009.5332628", "10.1111/insr.12095\\_11", "10.1109/tvcg.2010.184", "10.1109/tvcg.2015.2467323", "10.1109/vast.2010.5652460", "10.1111/j.1467-8659.2012.03069.x", "10.1145/1842993.1843002", "10.1198/106186008x320465", "10.1109/pacificvis.2016.7465244", "10.1109/tvcg.2013.20", "10.1111/cgf.12641", "10.1109/tvcg.2012.128", "10.1109/tvcg.2015.2467671", "10.1057/palgrave.ivs.9500091", "10.1007/978-1-4612-4400-4", "10.1111/cgf.13176", "10.1002/0470870958", "10.1109/tvcg.2018.2864907", "10.1111/j.1467-8659.2012.03125.x", "10.1109/vast.2012.6400490", "10.1109/infvis.2005.1532142", "10.1109/vast.2010.5652433", "10.1109/vast.2009.5332611", "10.1201/9781315140919", "10.1145/2858036.2858155", "10.1109/ldav.2013.6675164", "10.1515/itit-2014-1070", "10.1111/cgf.13684", "10.1109/tpami.1979.4766909", "10.2307/2289936", "10.1109/pacificvis.2014.42", "10.1109/tvcg.2016.2598467", "10.1109/tvcg.2013.153", "10.1111/cgf.13446", "10.1109/tvcg.2006.94", "10.1109/tvcg.2014.2346572", "10.1111/cgf.12632", "10.1109/tvcg.2017.2744339"], "wos": 1, "children": [], "len": 1}, {"doi": "10.1109/tvcg.2020.3030365", "title": "Modeling the Influence of Visual Density on Cluster Perception in Scatterplots Using Topology", "year": "2020", "conferenceName": "InfoVis", "authors": "Ghulam Jilani Quadri;Paul Rosen", "citationCount": "0", "affiliation": "Quadri, GJ (Corresponding Author), Univ S Florida, Tampa, FL 33620 USA. Quadri, Ghulam Jilani; Rosen, Paul, Univ S Florida, Tampa, FL 33620 USA.", "countries": "USA", "abstract": "Scatterplots are used for a variety of visual analytics tasks, including cluster identification, and the visual encodings used on a scatterplot play a deciding role on the level of visual separation of clusters. For visualization designers, optimizing the visual encodings is crucial to maximizing the clarity of data. This requires accurately modeling human perception of cluster separation, which remains challenging. We present a multi-stage user study focusing on four factors-distribution size of clusters, number of points, size of points, and opacity of points-that influence cluster identification in scatterplots. From these parameters, we have constructed two models, a distance-based model, and a density-based model, using the merge tree data structure from Topological Data Analysis. Our analysis demonstrates that these factors play an important role in the number of clusters perceived, and it verifies that the distance-based and density-based models can reasonably estimate the number of clusters a user observes. Finally, we demonstrate how these models can be used to optimize visual encodings on real-world data.", "keywords": "Scatterplot,clustering,perception,empirical evaluation,visual encoding,crowdsourcing,topological data analysis", "link": "http://dx.doi.org/10.1109/TVCG.2020.3030365", "refList": ["10.1109/tvcg.2017.2744359", "10.1145/1778765", "10.1109/tvcg.2019.2934799", "10.1111/cgf.12889", "10.1109/tvcg.2011.127", "10.1111/cgf.13444", "10.1145/1964897.1964910", "10.1167/8.7.6", "10.1145/3173574.3173991", "10.1145/1556262.1556289", "10.1145/1056808.1056914", "10.2307/2288400", "10.1109/tvcg.2014.2346594", "10.1109/iv.2002.1028760", "10.1177/001316447303300111", "10.1007/bf02289823", "10.1109/tvcg.2017.2744339", "10.1111/j.1467-8659.2009.01694.x", "10.1109/tvcg.2014.2346979", "10.1090/mbk/069", "10.1109/tvcg.2013.65", "10.1109/mcg.2012.37", "10.1109/pacificvis.2010.5429604", "10.1002/acp.2350050106", "10.1109/infvis.2005.1532136", "10.1177/1473871612465214", "10.1109/tvcg.2017.2674978", "10.1002/jhbs.20078", "10.1007/978-3-642-35142-6\\_14", "10.1007/978-3-319-71507-0", "10.1109/mcg.201.7.6", "10.3758/bf03193961", "10.1364/josa.49.000280", "10.1145/3025453.3025905", "10.1109/tvcg.201.9.2934541", "10.1109/tvcg.2018.2829750", "10.1177/1473871615606187", "10.1111/cgf.13408", "10.1109/pacificvis.2016.7465252", "10.1109/pacificvis.2016.7465244", "10.1109/inevis.2005.1532142", "10.1111/cgf.13414", "10.1111/j.1467-8659.2012.03125.x", "10.1167/16.5.11", "10.1109/infvis.2005.1532142", "10.1145/2858036.2858155", "10.1038/nmeth1210-941", "10.1177/1473871616638892", "10.1109/tcbb.2014.2306840", "10.1111/cgf.13684", "10.1177/0301006615602599", "10.1214/aoms/1177731915", "10.1145/2702123.2702585", "10.1109/tvcg.2013.183", "10.1109/tvcg.2014.2346572", "10.1109/tvcg.2018.2875702", "10.1109/tvcg.2017.2754480", "10.1109/vast.2014.7042493", "10.1057/palgrave.ivs.9500122", "10.1109/tvcg.2014.2330617", "10.1109/tvcg.2019.2934541", "10.1068/p030033", "10.1140/epjds/s13688-017-0109-5", "10.1201/b17511", "10.1016/s0925-7721(02)00093-7", "10.1109/pacificvis.2012.6183557", "10.1109/tvcg.2014.2346983", "10.1109/5.726791", "10.1080/01621459.1926.10502165", "10.1109/tvcg.2007.70535", "10.1109/tvcg.2018.2864907", "10.1111/cgf.12109", "10.1109/tvcg.2017.2744184", "10.1146/annurev-statistics-031017-100045", "10.1111/cgf.13409", "10.1145/3002151.3002162", "10.1016/s0378-4371(98)00494-4", "10.3138/y308-2422-8615-1233", "10.1111/cgf.12632", "10.1145/3290605.3300771"], "wos": 1, "children": [], "len": 1}, {"doi": "10.1111/cgf.14034", "year": "2020", "title": "The State of the Art in Enhancing Trust in Machine Learning Models with the Use of Visualizations", "conferenceName": "EuroVis", "authors": "Angelos Chatzimparmpas;Rafael Messias Martins;Ilir Jusufi;Kostiantyn Kucher;Fabrice Rossi;Andreas Kerren", "citationCount": "2", "affiliation": "Chatzimparmpas, A (Corresponding Author), Linnaeus Univ, Dept Comp Sci \\& Media Technol, Vaxjo, Sweden.\nChatzimparmpas, A.; Martins, R. M.; Jusufi, I.; Kucher, K.; Kerren, A., Linnaeus Univ, Dept Comp Sci \\& Media Technol, Vaxjo, Sweden.\nRossi, F., PSL Univ, Univ Paris Dauphine, Ceremade, Paris, France.", "countries": "Sweden;France", "abstract": "Machine learning (ML) models are nowadays used in complex applications in various domains, such as medicine, bioinformatics, and other sciences. Due to their black box nature, however, it may sometimes be hard to understand and trust the results they provide. This has increased the demand for reliable visualization tools related to enhancing trust in ML models, which has become a prominent topic of research in the visualization community over the past decades. To provide an overview and present the frontiers of current research on the topic, we present a State-of-the-Art Report (STAR) on enhancing trust in ML models with the use of interactive visualization. We define and describe the background of the topic, introduce a categorization for visualization techniques that aim to accomplish this goal, and discuss insights and opportunities for future research directions. Among our contributions is a categorization of trust against different facets of interactive ML, expanded and improved from previous research. Our results are investigated from different analytical perspectives: (a) providing a statistical overview, (b) summarizing key findings, (c) performing topic analyses, and (d) exploring the data sets used in the individual papers, all with the support of an interactive web-based survey browser. We intend this survey to be beneficial for visualization researchers whose interests involve making ML models more trustworthy, as well as researchers and practitioners from other disciplines in their search for effective visualization techniques suitable for solving their tasks with confidence and conveying meaning to their data.", "keywords": "trustworthy machine learning; visualization; interpretable machine learning; explainable machine learning", "link": "https://doi.org/10.1111/cgf.14034", "refList": ["10.1109/mcg.2018.2878902", "10.1109/tvcg.2008.153", "10.2312/mlvis.20181130", "10.1109/tvcg.2016.2598828", "10.1145/3290605.3300911", "10.1145/2993901.2993909", "10.2312/mlvis.20191158", "10.1109/tvcg.2016.2598446", "10.1111/j.1467-8659.2009.01475.x", "10.1145/3290605.3300809", "10.1109/pacificvis.2018.00031", "10.1055/s-0029-1216348", "10.1007/978-3-319-90403-0\\_13", "10.1109/tvcg.2017.2745085", "10.1111/j.1467-8659.2011.01938.x", "10.1007/978-3-319-54024-5\\_6", "10.1016/s0167-9473(01)00065-2", "10.1111/cgf.12895", "10.2312/eurovisshort.20141152.17", "10.2312/eurova.20151098.22", "10.1111/cgf.13667", "10.3115/1072228.1072378", "10.1109/tbdata.2018.2877350.16", "10.1109/lars.2009.5418323.25", "10.1109/tvcg.2017.2744878", "10.1016/j.combustflame.2005.09.018", "10.1016/j.cag.2014.01.006", "10.1109/tvcg.2016.2570755", "10.2312/mlvis.20191158.1,19", "10.1518/hfes.46.1.50.30392", "10.1145/3301275.3302280", "10.1145/3351095.3372834.1", "10.1016/s0377-2217(01)00264-8", "10.1111/cgf.13424", "10.1007/978-3-319-23485-4\\_53", "10.1007/978-94-007-0753-5\\_3623", "10.1109/tvcg.2013.101", "10.1111/cgf.12884", "10.1111/j.1467-8659.2010.01835.x", "10.1021/ci9901338", "10.4230/lipics.itcs:2017", "10.1109/mis.2013.24", "10.1109/tvcg.2014.2346482", "10.1109/tvcg.2018.2865230", "10.1073/pnas.1807180116", "10.1109/dsaa.2018.00018", "10.1109/tvcg.2009.153", "10.3115/1219840.1219855", "10.1109/tvcg.2018.2864812", "10.1109/tvcg.2018.2872577", "10.2312/trvis.20191183", "10.1109/cvpr:2004.383", "10.1109/vast.2008.4677350", "10.1145/302979.303001", "10.1109/tvcg.2018.2864499", "10.1111/cgf.13672", "10.1109/tvcg.2014.2346626", "10.23915/distill.00010.18", "10.1109/tvcg.2017.2744805", "10.2312/mlvis:20191160.18", "10.23915/distill:00016", "10.1109/pacificvis.2016.7465260", "10.1111/cgf.13683", "10.23915/distill.00016.19", "10.1145/32906053.300803.22", "10.1109/tvcg.2014.2346574", "10.1177/1473871615600010", "10.1109/tvcg.2016.2598831", "10.1145/3230623", "10.1109/visual.2019.8933744", "10.1145/2993901.2993915", "10.1016/j.visinf.2017.01.006", "10.1145/2993901.2993914", "10.1109/tvcg.2014.2346984", "10.1109/5.726791", "10.23915/distill.00010", "10.1109/tvcg.2018.2864825", "10.2307/2394164", "10.1109/tvcg.2017.2744458", "10.1145/2993901.2993917.28", "10.1111/cgf.13711", "10.1109/tvcg.2016.2598664", "10.2307/2530428", "10.1109/icdar.1997.620583", "10.1109/tvcg.2017.2744718", "10.1111/cgf.13425", "10.1109/tvcg.2019.2903943", "10.1145/1518701.1518895", "10.1109/tvcg.2018.2864838", "10.1145/62038.62043", "10.1111/j.1467-8659.2011.01920.x", "10.1145/3025171.3025208", "10.1145/355112.355124", "10.1109/vast.2010.5652398", "10.1109/tvcg.2014.2346578", "10.1145/3173574.3174209", "10.4178/epih/e2014008", "10.1109/beliv.2018.8634201.25,28", "10.1016/j.eswa.2007.12.020", "10.1111/cgf:13406", "10.1109/mcg.2011.103", "10.1631/fitee.1700808", "10.1109/tvcg.2017.2745158", "10.1073/pnas.0307752101", "10.1109/tvcg.2018.2816223", "10.1109/tvcg.2017.2745141", "10.1145/32232.32234", "10.1109/tvcg.2019.2934267", "10.1109/tvcg.2018.2864477", "10.1145/3132169", "10.2312/eurova.20151100.19", "10.1145/3172944.3172964", "10.1145/2601248.2601268", "10.1109/isai-nlp.2018.8693002.1", "10.1111/cgf.13404", "10.1007/s100320200071", "10.2312/trvis.20191183.16", "10.1111/cgf.12755", "10.1145/2702123.2702509", "10.1145/1401890.1402008.25", "10.1109/tvcg.2012.65", "10.1177/1473871617733996", "10.2312/trvis.20191187.7", "10.21236/ada273556", "10.1109/vast.2010.5652450", "10.1111/j.1467-8659.2011.01940.x", "10.1177/875647939000600106", "10.1109/tvcg.2017.2711030", "10.1016/j.immuni.2016.04.014", "10.1109/tvcg.2019.2934209", "10.1016/0095-0696(78)90006-2", "10.1016/j.jclinepi.2015.04.014", "10.1016/j.ress.2013.02.013", "10.1111/cgf.12640", "10.1145/1015330.1015388.25", "10.1111/j.1467-8659.2009.01468.x", "10.1145/1541880.1541882", "10.1109/vast.2011.6102453", "10.1016/s0008-8846(98)00165-3", "10.2312/trvis.20191186.7", "10.1007/s13748-013-0040-3", "10.1109/tvcg.2015.2467757", "10.1109/tbdata.2018.2877350", "10.1109/vast.2017.8585613", "10.1080/10556789208805504", "10.1109/vast.2012.6400484", "10.1145/3025171.3025181", "10.1007/978-3-319-90403-0\\_12", "10.1109/mcg.2019.2922592", "10.1021/ci000392t", "10.1109/vast.2007.4389000", "10.1111/cgf.13406.16", "10.1111/cgf.13684", "10.2312/eurovisshort.20161166.17", "10.2312/evs:20191168", "10.1145/3041021.3055135", "10.1145/3301275.3302265", "10.1613/jair.4135", "10.1109/tvcg.2018.2864500", "10.1109/tvcg.2017.2744158", "10.1109/ssci.2015.33", "10.1111/cgf.13453", "10.2312/pe/eurovast/eurova11/049-052", "10.1145/3025171.3025181.13", "10.1145/371920.372094", "10.1109/tvcg.2017.2744938", "10.1111/j.1467-8659.2012.03108.x", "10.1109/tvcg.2019.2934251", "10.1145/3290605.3300809.18", "10.1109/ldav.2016.7874305", "10.1109/vast.2016.7883514", "10.1109/iccv.2015.425", "10.1145/3301275.3302324", "10.1109/tnnls.2013.2292894", "10.1109/tvcg.2018.2865044", "10.1109/tvcg.2013.157", "10.1371/journal.pcbi.0020161", "10.1186/s12916-019-1426-2", "10.1109/10.867928", "10.1111/cgf.13217", "10.1109/mcg.2019.2919033", "10.1145/2993901.2993910", "10.1109/tvcg.2017.2744738", "10.2307/258792", "10.1111/cgf.12655", "10.1016/j.dss.2014.03.001", "10.1109/tvcg.2019.2904069", "10.1111/cgf.13205", "10.1002/mds.22340", "10.1109/tvcg.2019.2934595", "10.1287/inte.2018.0957", "10.1109/cvpr.2007.382974", "10.1109/tvcg.2012.280", "10.1145/2678025.2701399.13", "10.2312/mlvis.20181130.13", "10.2312/eurova.20181106.16", "10.1109/tvcg.2018.2864475", "10.2312/mlvis.20191160.18,22", "10.1007/978-1-4612-4026-6.25", "10.1109/cvpr.2006.42", "10.1145/3172944.3172950", "10.1109/cvpr.2004.383.25", "10.1109/tvcg.2019.2934812", "10.1609/aimag.v35i4.2513", "10.2312/trvis.20191185.7", "10.1111/j.1467-8659.2009.01684.x", "10.1371/journal.pone.0129126", "10.1111/cgf.13092", "10.1162/coli\\_a\\_00237", "10.1109/tvcg.2017.2744818", "10.1109/vast.2011.6102448", "10.1109/tvcg.2009.111", "10.1109/tvcg.2019.2934619", "10.1016/s0377-2217(01)00264-8.25", "10.1111/cgf.12639", "10.1109/access.2019.2919343", "10.1186/s12874-019-0681-4", "10.1109/pacificvis.2015.7156366", "10.1109/pacificvis.2018.00029", "10.1109/tvcg.2019.2934261", "10.1080/13506280444000102.http://www.uvt.nl/ticc", "10.1109/vast.2018.8802509", "10.1111/cgf.13212", "10.1145/3200489", "10.1111/cgf.13176", "10.1177/1473871620904671", "10.1007/978-3-319-10590-1\\_53", "10.1111/j.1467-8659.2012.03126.x", "10.1111/cgf.13172", "10.1145/3025171.3025208.6,21", "10.1111/cgf.12366", "10.1109/tvcg.2019.2934659", "10.1109/cvprw.2009.5206848", "10.1016/j.media.2014.11.010", "10.1109/tvcg.2017.2744683", "10.1109/tvcg.2019.2934262", "10.1016/j.neucom.2006.11.018", "10.1177/1473871615571951", "10.1371/journal.pcbi.0020161.25", "10.1177/1473871611415994", "10.2312/trvis20191187", "10.2312/eurova", "10.1145/2858036.2858529", "10.1145/2207676.2207738", "10.1007/s11042-009-0417-2", "10.1145/3301275.3302317", "10.1038/s41746-019-0148-3", "10.1145/3351095.3372834", "10.1080/10691898.2011.11889627", "10.1109/tvcg.2018.2864504", "10.1109/vast.2017.8585720", "10.1109/mcg.2018.053491732", "10.1007/s10994-010-5207-6", "10.1109/tvcg.2019.2934433", "10.1016/j.cag.2017.05.005", "10.1109/tvcg.2012.279", "10.1145/3231622.3231641.19,20", "10.1145/1562849.1562851", "10.1007/11564126\\_", "10.1109/tvcg.2018.2846735", "10.3115/1225403.1225421", "10.1109/vast.2012.6400486", "10.2312/eurova.20191116.22", "10.1109/tvcg.2007.70443", "10.1080/027868291009242", "10.2312/eurova.20151100", "10.1145/2939502.2939503.19", "10.1016/j.cag.2014.02.004", "10.1145/2939672.2939778", "10.1109/vast.2010.5652484", "10.1111/cgf.12641", "10.1145/3301275.3302289", "10.1109/visual.2019.8933619", "10.1109/tvcg.2017.2672987", "10.1109/vast.2016.7883517.20", "10.1109/igarss.2017.8127684", "10.1016/j.jcae.2010.04.002", "10.1109/vast.2010.5652885", "10.1016/j.visinf.2019.03.002", "10.1007/s00371-018-1500-3", "10.1109/mcg.2018.042731661", "10.1109/34.598228", "10.1109/tvcg.2018.2865027", "10.1016/j.neucom.2017.01.105", "10.1111/cgf.12389", "10.1109/tvcg.2019.2934591", "10.1109/vast.2010.5652392.16", "10.1111/cgf.13416", "10.1080/02701367.1992.10608764", "10.1109/vast.2017.8585721", "10.1109/tvcg.2018.2843369", "10.1109/sbes.2010.27", "10.1109/vast.2015.7347637", "10.1145/1401890.1402008", "10.1016/j.bpj.2010.04.064", "10.1109/tvcg.2013.125", "10.1109/isai-nlp.2018.8693002", "10.1371/journal.pone.0160127", "10.1145/2856767.2856779", "10.1145/2678025.2701399", "10.1109/vast.2011.6102451", "10.1109/mcg.2010.18", "10.1021/ci4000213", "10.1109/vast.2012.6400492", "10.1007/11564126-49.25", "10.2312/eurova.20171114", "10.1109/vast.2010.5652443", "10.1145/3134599", "10.2312/pe/eurovast/eurovast10/013-018.19", "10.1109/tvcg.2019.2903946", "10.1109/tvcg.2015.2467717", "10.1177/1473871612460526", "10.1016/j.cag.2018.09.018", "10.1109/tvcg.2016.2598838", "10.1145/3172944.3172964.14", "10.1109/vast.2009.5333428", "10.1109/vast.2014.7042480", "10.2312/pe/eurovast/eurovast10/013-018", "10.1177/0962280215588241", "10.1145/2993901.2993917", "10.1109/cvpr.2008:4587581", "10.1109/tvcg.2015.2467551", "10.1016/j.visinf.2018.09.001", "10.1126/science.290.5500.2319", "10.2312/eurova.20151107", "10.1109/visual.2019.8933695", "10.13140/2.1.2393.1847", "10.1197/jamia.m1929", "10.1109/cvpr.2008.4587581.25", "10.1145/1518701.1518895.16", "10.1109/vds.2017.8573444", "10.2312/trvis:20191185", "10.1145/3359786", "10.13140/2.1.1341.1520", "10.2312/pe/eurovast/eurova11/049-052.17", "10.1109/tvcg.2014.2346660", "10.1145/3185517", "10.1109/adprl.2011.5967372", "10.1109/tvcg.2015.2467591", "10.1111/j.1751-9004.2009.00232.x", "10.1136/qshc.2004.010033", "10.1109/vast.2012.6400493", "10.1109/tvcg.2019.2934266", "10.1145/2971763.2971775", "10.1111/cgf.13730", "10.1109/vast.2012.6400488", "10.1111/cgf.13210", "10.1109/tvcg.2019.2934631", "10.1145/3172944.3172965", "10.1057/ivs.2010.2", "10.1109/tvcg.2017.2745258", "10.1016/j.jbusres.2019.07.039", "10.1162/jmlr.2003.3.4-5.993", "10.1109/pacificvis.2019.00044", "10.2312/pe/eurovast/eurova12/037-041", "10.1109/tvcg.2019.2934629", "10.1177/0018720814547570", "10.1145/3292500.3330908", "10.1111/j.1467-8659.2009.01467.x", "10.2312/eurova.20151098", "10.1177/1473871617713337", "10.1109/lars:2009.5418323", "10.1109/vast.2011.6102437", "10.1111/cgf.12878", "10.1561/1500000001", "10.1145/3025171.3025222", "10.1007/s11704-016-6028-y", "10.1016/j.procs.2017.05.216", "10.1109/cvpr.2007.382974.25", "10.1080/10447318.2020.1741118", "10.1109/vast.2012.6400489", "10.1145/3025171.3025172", "10.1109/tvcg.2017.2744098", "10.1109/tvcg.2005.66", "10.1016/j.dss.2009.05.016", "10.1007/978-1-4612-4026-6", "10.2312/evs.20191168.16,20,28", "10.2312/pe/eurovast/eurova12/037-041.17", "10.1145/3290605.3300803", "10.1145/1015330.1015388", "10.1111/cgf.13197", "10.1016/b978-1-55860-377-6.50048-7", "10.1111/cgf.13681", "10.1109/tvcg.2017.2744378", "10.1109/tvcg.2017.2744358", "10.1109/vast.2008.4677352"], "wos": 1, "children": [{"doi": "10.1109/tvcg.2020.3030368", "title": "Implicit Multidimensional Projection of Local Subspaces", "year": "2020", "conferenceName": "InfoVis", "authors": "Rongzheng Bian;Yumeng Xue;Liang Zhou;Jian Zhang 0070;Baoquan Chen;Daniel Weiskopf;Yunhai Wang", "citationCount": "1", "affiliation": "Wang, YH (Corresponding Author), Shandong Univ, Qingdao, Peoples R China. Zhou, L (Corresponding Author), Univ Utah, Salt Lake City, UT 84112 USA. Bian, Rongzheng; Xue, Yumeng; Wang, Yunhai, Shandong Univ, Qingdao, Peoples R China. Chen, Baoquan, Peking Univ, Beijing, Peoples R China. Zhang, Jian, Chinese Acad Sci, CNIC, Beijing, Peoples R China. Zhou, Liang, Univ Utah, Salt Lake City, UT 84112 USA. Weiskopf, Daniel, Univ Stuttgart, Stuttgart, Germany.", "countries": "USA;Germany;China", "abstract": "We propose a visualization method to understand the effect of multidimensional projection on local subspaces, using implicit function differentiation. Here, we understand the local subspace as the multidimensional local neighborhood of data points. Existing methods focus on the projection of multidimensional data points, and the neighborhood information is ignored. Our method is able to analyze the shape and directional information of the local subspace to gain more insights into the global structure of the data through the perception of local structures. Local subspaces are fitted by multidimensional ellipses that are spanned by basis vectors. An accurate and efficient vector transformation method is proposed based on analytical differentiation of multidimensional projections formulated as implicit functions. The results are visualized as glyphs and analyzed using a full set of specifically-designed interactions supported in our efficient web-based visualization tool. The usefulness of our method is demonstrated using various multi- and high-dimensional benchmark datasets. Our implicit differentiation vector transformation is evaluated through numerical comparisons; the overall method is evaluated through exploration examples and use cases.", "keywords": "High-dimensional data visualization,dimensionality reduction,local linear subspaces,user interaction", "link": "http://dx.doi.org/10.1109/TVCG.2020.3030368", "refList": ["10.3844/jcssp.2018.613.622", "10.1016/j.aci.2018.08.003", "10.3390/info9030065", "10.1016/j.visinf.2018.09.003", "10.1371/journal.pone.0118432", "10.1016/s0893-6080(05)80023-1", "10.1109/tvcg.2020.2986996", "10.1109/icst.2012.56", "10.1007/s10844-013-0250-y", "10.1109/tbdata.2018", "10.1145/1125451.1125659", "10.1109/tvcg.2013.125", "10.1177/1473871611412817", "10.1145/3290605.3300911", "10.1111/cgf.14034", "10.1007/s13721-013-0034-x", "10.1016/j.procs.2017.05.216", "10.1016/j.ins.2009.08.025", "10.1109/tvcg.2013.124", "10.1109/tvcg.2018.2864499", "10.1109/tvcg.2018.2864475", "10.1080/10447318.2020.1741118", "10.1016/j.imu.2019.100203", "10.1109/tvcg.2018.2865240", "10.1186/s12864-019-6413-7", "10.1109/tvcg.2015.2467551", "10.1002/widm.1249", "10.1007/978-3-319-66429-3\\_29", "10.1109/tvcg.2014.2346481", "10.1109/tvcg.2018.2864825", "10.1177/1473871620904671", "10.1109/tvcg.2019.2934267", "10.1136/bmjopen-2016-012799", "10.1109/smartgridcomm.2017.8340682", "10.1007/s10664-015-9401-9", "10.1145/1143844.1143874", "10.1111/cgf.12389", "10.1109/tvcg.2018.2872577", "10.1007/978-981-13-5802-9\\_20", "10.1016/j.ipm.2009.03.002", "10.5220/0006431602160222", "10.1109/mcg.2015.50", "10.1109/tvcg.2014.2346574", "10.1007/bf02289565", "10.1109/tvcg.2017.2744378", "10.1016/j.patrec.2008.08.010", "10.1023/a:1010933404324", "10.9735/2229-3981"], "wos": 1, "children": [], "len": 1}, {"doi": "10.1109/tvcg.2020.3030465", "title": "Visual Causality Analysis of Event Sequence Data", "year": "2020", "conferenceName": "VAST", "authors": "Zhuochen Jin;Shunan Guo;Nan Chen;Daniel Weiskopf;David Gotz;Nan Cao", "citationCount": "0", "affiliation": "Cao, N (Corresponding Author), Tongji Univ, IDVx Lab, Shanghai, Peoples R China. Jin, Zhuochen; Guo, Shunan; Chen, Nan; Cao, Nan, Tongji Univ, IDVx Lab, Shanghai, Peoples R China. Weiskopf, Daniel, Univ Stuttgart, Stuttgart, Germany. Gotz, David, Univ N Carolina, Chapel Hill, NC 27515 USA.", "countries": "USA;Germany;China", "abstract": "Causality is crucial to understanding the mechanisms behind complex systems and making decisions that lead to intended outcomes. Event sequence data is widely collected from many real-world processes, such as electronic health records, web clickstreams, and financial transactions, which transmit a great deal of information reflecting the causal relations among event types. Unfortunately, recovering causalities from observational event sequences is challenging, as the heterogeneous and high-dimensional event variables are often connected to rather complex underlying event excitation mechanisms that are hard to infer from limited observations. Many existing automated causal analysis techniques suffer from poor explainability and fail to include an adequate amount of human knowledge. In this paper, we introduce a visual analytics method for recovering causalities in event sequence data. We extend the Granger causality analysis algorithm on Hawkes processes to incorporate user feedback into causal model refinement. The visualization system includes an interactive causal analysis framework that supports bottom-up causal exploration, iterative causal verification and refinement, and causal comparison through a set of novel visualizations and interactions. We report two forms of evaluation: a quantitative evaluation of the model improvements resulting from the user-feedback mechanism, and a qualitative evaluation through case studies in different application domains to demonstrate the usefulness of the system.", "keywords": "Event sequence data,causality analysis,visual analytics", "link": "http://dx.doi.org/10.1109/TVCG.2020.3030465", "refList": ["10.5555/1642718", "10.1109/tvcg.2018.2865022", "10.5555/2074094.2074151", "10.1109/tvcg.2016.2618797", "10.1073/pnas.1320645111", "10.1109/tvcg.2017.2744843", "10.1109/iv.2017.69", "10.1109/tvcg.2019.2934399", "10.1145/3172944.3173007", "10.5555/1795555", "10.1109/mcg.2005.102", "10.1145/381641.381653", "10.1162/153244301753344614", "10.1111/cgf.14034", "10.1111/cgf.13198", "10.1017/cbo9780511519857", "10.1007/s10462-016-9475-9", "10.1075/ssol.2.2.07bor", "10.1007/978-1-4614-3223-4\\_3", "10.1109/infvis.2003.1249025", "10.1007/978-94-007-6094-313", "10.1145/2858036.2858387", "10.1109/tvcg.2007.70528", "10.1109/tvcg.2017.2674958", "10.1147/sj.454.0801", "10.1109/tvcg.2013.119", "10.1145/3173574.3173711", "10.1016/j.erss.2017.06.034", "10.1109/visual.2019.8933695", "10.1007/s11665-016-2173-6", "10.1016/0377-0427(87)90125-7", "10.2307/3601125", "10.1016/b978-0-444-88738-2.50018-x", "10.1109/mcg.2006.70", "10.1109/tvcg.2018.2865145", "10.1017/s1351324997001502", "10.1109/tvcg.2010.179", "10.1214/aos/1176344552", "10.1109/mcg.2009.22", "10.1007/978-3-319-26633-6\\_13", "10.1080/10447318.2014.905422", "10.1016/j.visinf.2019.03.004", "10.1057/palgrave.ivs.9500074", "10.1007/978-1-4614-3223-4"], "wos": 1, "children": [], "len": 1}], "len": 5}, {"doi": "10.1111/cgf.14001", "year": "2020", "title": "Sunspot Plots: Model-based Structure Enhancement for Dense Scatter Plots", "conferenceName": "EuroVis", "authors": "Thomas Trautner;Fabian Bolte;Sergej Stoppel;Stefan Bruckner", "citationCount": "0", "affiliation": "Trautner, T (Corresponding Author), Univ Bergen, Bergen, Norway.\nTrautner, T.; Bolte, F.; Stoppel, S.; Bruckner, S., Univ Bergen, Bergen, Norway.", "countries": "Norway", "abstract": "Scatter plots are a powerful and well-established technique for visualizing the relationships between two variables as a collection of discrete points. However, especially when dealing with large and dense data, scatter plots often exhibit problems such as overplotting, making the data interpretation arduous. Density plots are able to overcome these limitations in highly populated regions, but fail to provide accurate information of individual data points. This is particularly problematic in sparse regions where the density estimate may not provide a good representation of the underlying data. In this paper, we present sunspot plots, a visualization technique that communicates dense data as a continuous data distribution, while preserving the discrete nature of data samples in sparsely populated areas. We furthermore demonstrate the advantages of our approach on typical failure cases of scatter plots within synthetic and real-world data sets and validate its effectiveness in a user study.", "keywords": "", "link": "https://doi.org/10.1111/cgf.14001", "refList": ["10.1057/palgrave.ivs.9500122", "10.2312/eggh/hpg12/097-103", "10.1109/tvcg.2008.119", "10.1109/pacificvis.2011.5742387", "10.1038/331163a0", "10.1109/visual.2019.8933620", "10.2307/2683294", "10.1201/9781351072304", "10.2307/2289444", "10.1109/tvcg.2019.2934541", "10.1080/00949657508810123", "10.1109/tvcg.2013.65", "10.1109/infvis.1997.636789", "10.1109/2945.841121", "10.1109/mcse.2007.55", "10.1109/tvcg.2010.197", "10.1111/cgf.12871", "10.1109/infvis.2003.1249018", "10.1145/3173574.3173991", "10.1109/tvcg.2012.238", "10.1007/0-387-28695-0", "10.1109/pacificvis.2010.5429604", "10.18637/jss.v008.i03", "10.1109/tvcg.2007.70596", "10.1109/visual.1998.745301", "10.1007/0-387-37977-0\\_3", "10.1145/1556262.1556289", "10.2312/wiced.20161094", "10.1109/tvcg.2007.70535", "10.1145/1056808.1056914", "10.1109/tvcg.2003.1196007", "10.1109/iv.2004.1320190", "10.1111/cgf.12877", "10.1162/leon.2007.40.2.202a", "10.1109/tvcg.2017.2674978", "10.1057/ivs.2010.4", "10.1016/j.cag.2018.02.008", "10.1201/9781315140919", "10.1109/visual.2000.885677", "10.1002/jhbs.20078", "10.1109/tvcg.2014.2346594", "10.1109/tvcg.2017.2744184", "10.1109/visual.2001.964495", "10.1109/iv.2002.1028760", "10.1111/cgf.13684", "10.1109/hicss.2013.197", "10.1109/tvcg.2019.2903956", "10.1093/mnras/stt961", "10.1109/tvcg.2017.2668409", "10.1111/j.1467-8659.2009.01478.x", "10.1145/2702123.2702585", "10.2307/1418003", "10.2307/1390742", "10.1145/360825.360839", "10.1109/pacificvis.2009.4906843", "10.1057/ivs.2009.34", "10.2307/2288711"], "wos": 1, "children": [], "len": 1}], "len": 13}, {"doi": "10.1111/cgf.14000", "year": "2020", "title": "Evaluating Reordering Strategies for Cluster Identification in Parallel Coordinates", "conferenceName": "EuroVis", "authors": "Michael Blumenschein;Xuan Zhang;David Pomerenke;Daniel A. Keim;Johannes Fuchs", "citationCount": "0", "affiliation": "Blumenschein, M (Corresponding Author), Univ Konstanz, Constance, Germany.\nBlumenschein, Michael; Pomerenke, David; Keim, Daniel A.; Fuchs, Johannes, Univ Konstanz, Constance, Germany.\nZhang, Xuan, Rhein Westfal TH Aachen, Aachen, Germany.", "countries": "Germany", "abstract": "The ability to perceive patterns in parallel coordinates plots (PCPs) is heavily influenced by the ordering of the dimensions. While the community has proposed over 30 automatic ordering strategies, we still lack empirical guidance for choosing an appropriate strategy for a given task. In this paper, we first propose a classification of tasks and patterns and analyze which PCP reordering strategies help in detecting them. Based on our classification, we then conduct an empirical user study with 31 participants to evaluate reordering strategies for cluster identification tasks. We particularly measure time, identification quality, and the users' confidence for two different strategies using both synthetic and real-world datasets. Our results show that, somewhat unexpectedly, participants tend to focus on dissimilar rather than similar dimension pairs when detecting clusters, and are more confident in their answers. This is especially true when increasing the amount of clutter in the data. As a result of these findings, we propose a new reordering strategy based on the dissimilarity of neighboring dimension pairs.", "keywords": "", "link": "https://doi.org/10.1111/cgf.14000", "refList": ["10.1111/j.1467-8659.2008.01241.x", "10.2312/conf/eg2013/stars/095-116", "10.1109/tvcg.2014.2346979", "10.1117/12.838819", "10.2307/2290001", "10.1111/cgf.12638", "10.1007/978-3-642-30217-6\\_42", "10.1109/sc.2005.47", "10.1002/wics.145", "10.1109/tvcg.2011.229", "10.1109/vast.2009.5332628", "10.1109/vast.2017.8585613", "10.1145/2993901.2993907", "10.1007/bf00410640", "10.1109/tvcg.2010.184", "10.11591/ijece.v5i6", "10.1111/j.1467-8659.2011.01961.x", "10.1109/visual.1997.663916", "10.1111/j.1467-8659.2012.03129.x", "10.1109/visual.1999.809866", "10.1057/ivs.2008.13", "10.1016/j.visinf.2017.11.001", "10.2307/2282967", "10.1007/978-0-387-68628-8\\_10", "10.5888/pcd9.120082", "10.1109/tvcg.2007.70535", "10.1109/vast.2010.5652450", "10.1007/bf01898350", "10.1016/0010-0285(91)90009-d", "10.1007/978-3-642-24958-7\\_12", "10.1109/infvis.2005.1532142", "10.1057/palgrave.ivs.9500166", "10.1111/j.1467-8659.2008.01239.x", "10.1109/mcse.2015.55", "10.2312/pe/eurovast/eurova12/007-011.7", "10.1109/tvcg.2009.153", "10.1198/jcgs.2010.09136", "10.1145/2463676.2463696", "10.1109/infvis.2005.1532138", "10.1109/tvcg.2010.242", "10.5220/0006097400400051", "10.1109/visual.2019.8933706", "10.1109/atc.2015.7388338", "10.2312/pe/eurovast/eurova12/007-011", "10.5120/5044-7370", "10.1111/cgf.13446", "10.1109/icmla.2012.148", "10.1016/j.jvlc.2015.12.001", "10.1109/tvcg.2015.2466992", "10.1111/j.1467-8659.2009.01666.x", "10.5169/seals-266450", "10.1109/infvis.1998.729559", "10.1016/j.jvlc.2017.10.003", "10.1109/visual.1995.485139", "10.1007/978-0-387-39940-9\\_262", "10.1109/tvcg.2006.138"], "wos": 1, "children": [], "len": 1}], "len": 71}, {"doi": "10.1111/cgf.14031", "year": "2020", "title": "The State of the Art in Map-Like Visualization", "conferenceName": "EuroVis", "authors": "Marius Hogr{\\\"{a}}fer;Magnus Heitzler;Hans{-}J{\\\"{o}}rg Schulz", "citationCount": "0", "affiliation": "Hografer, M (Corresponding Author), Aarhus Univ, Dept Comp Sci, Aarhus, Denmark.\nHografer, Marius; Schulz, Hans-Jorg, Aarhus Univ, Dept Comp Sci, Aarhus, Denmark.\nHeitzler, Magnus, Swiss Fed Inst Technol, Inst Cartog \\& Geoinformat, Zurich, Switzerland.", "countries": "Switzerland;Denmark", "abstract": "Cartographic maps have been shown to provide cognitive benefits when interpreting data in relation to a geographic location. In visualization, the term map-like describes techniques that incorporate characteristics of cartographic maps in their representation of abstract data. However, the field of map-like visualization is vast and currently lacks a clear classification of the existing techniques. Moreover, choosing the right technique to support a particular visualization task is further complicated, as techniques are scattered across different domains, with each considering different characteristics as map-like. In this paper, we give an overview of the literature on map-like visualization and provide a hierarchical classification of existing techniques along two general perspectives: imitation and schematization of cartographic maps. Each perspective is further divided into four principal categories that group common map-like techniques along the visual primitives they affect. We further discuss this classification from a task-centered view and highlight open research questions.", "keywords": "", "link": "https://doi.org/10.1111/cgf.14031", "refList": ["10.1111/j.0020-2754.1998.00269.x.21", "10.1109/iv.2005.26", "10.2307/2980460", "10.1109/tvcg.2017.2743959", "10.1016/j.jvlc.2011.11.004", "10.1145/2501988.2502046", "10.1559/1523040042742402", "10.1007/s00779-011-0500-3", "10.1111/cgf.12932", "10.1109/tvcg.2010.89", "10.1111/cgf.13200", "10.1080/15230406.2016.1160797", "10.1179/000870410x12825500202896", "10.1109/tvcg.2007.70596", "10.5167/80972.19uzh-80972", "10.1007/978-3-319-11593-1\\_2", "10.1037/aca0000175", "10.1080/17538947.2014.923942", "10.1109/tvcg.2015.2467321", "10.1109/vissof.2005.1684299", "10.1559/152304098782383034", "10.1007/978-3-642-36763-2\\_38", "10.1109/tvcg.2013.130", "10.1109/tvcg.2014.2346274", "10.1111/cgf.12648", "10.1111/0004-5608.00242", "10.1177/1473871617724212", "10.1109/iv.2004.1320123", "10.1371/journal.pcbi.1006907", "10.1109/tvcg.2016.2599030", "10.1559/1523040042742411", "10.3390/informatics5030031", "10.1111/cgf.13079", "10.1109/tvcg.2015.2467811", "10.1016/j.tics.2003.12.004", "10.1007/s00799-016-0168-4", "10.1109/infvis.2004.57", "10.1007/s10021-007-9038-7", "10.1109/pacificvis.2015.7156366", "10.1007/978-3-319-27261-0\\_1", "10.1007/978-1-4471-2804-5\\_6", "10.1109/access.2019.2939977", "10.1109/tvcg.2017.2747545", "10.1109/icdm.2003.1250978", "10.1111/cgf.13167", "10.1016/0010-0285(78)90006-3", "10.3138/nj8v-8514-871t-221k", "10.1016/j.cag.2009.06.002", "10.1111/j.1467-8659.2011.01937.x", "10.1016/b978-044451020-4/50035-9", "10.1111/1467-8659.00566", "10.5220/0006618101080119", "10.1109/pacificvis.2012.6183571", "10.1145/2038558.2038579", "10.1109/tvcg.2010.191", "10.1111/j.0033-0124.1985.00075.x", "10.1109/tvcg.2004.1260761", "10.1007/978-3-642-34848-8\\_6", "10.1145/2968220.2968239", "10.1145/3002151.3002160", "10.1109/tst.2013.6509098", "10.1109/tvcg.2013.91", "10.1177/1473871615597077", "10.1016/j.jvlc.2011.02.001", "10.1080/17445647.2014.935502", "10.1177/1687814017740710", "10.1111/1744-7917.12601", "10.1073/pnas.0400280101", "10.1111/cgf.13672", "10.1109/mcg.2006.90", "10.1002/asi.21712", "10.1007/978-3-642-33024-7\\_3", "10.1145/2801040.2801056", "10.1109/mcg.2010.101", "10.1179/003962607x165041", "10.1057/palgrave.ivs.9500039", "10.1109/vast.2016.7883510", "10.1559/152304009788988288", "10.1080/23729333.2017.1301346", "10.1109/tvcg.2013.66", "10.1111/j.1467-8659.2012.03085.x", "10.1109/tvcg.2011.288", "10.3390/ijgi9040253", "10.1109/infvis.2005.1532150", "10.1145/2254556.2254636", "10.20382//jocg.v4i1a9", "10.1016/0010-0285(81)90016-5", "10.1145/2556288.2557224", "10.1109/iv.2001.942043", "10.1021/ed1000203", "10.1016/0169-7439(87)80084-9", "10.1109/tvcg.2010.154", "10.1016/j.jvlc.2015.10.003", "10.1109/tvcg.2019.2903945", "10.1109/tvcg.2013.120", "10.1109/tvcg.2019.2934263", "10.1146/annurev-ecolsys-102209-144718", "10.1109/tvcg.2008.165", "10.3138/a477-3202-7876-n514", "10.1080/23729333.2017.1288535", "10.1111/j.0020-2754.1998.00269.x", "10.1109/mcg.2004.41", "10.1109/vast.2009.5332593", "10.1002/smr.414", "10.1007/s12650-019-00584-3", "10.1145/22949.22950", "10.1179/1743277413y.0000000036", "10.1080/15230406.2016.1262280", "10.1016/s0341-8162(01)00164-3", "10.22224/gistbok/2017.3.8", "10.1109/tvcg.2008.155", "10.1057/ivs.2008.31", "10.1016/j.cag.2004.03.012", "10.1179/1743277412y.0000000007", "10.1016/j.soncn.2011.02.001", "10.1179/caj.1987.24.1.27", "10.3138/carto.48.3.1691", "10.5220/0004267205150524", "10.1109/38.974518", "10.1145/102377.115768", "10.1057/palgrave.ivs.9500186", "10.1109/5.58325", "10.5167/80972.uzh-80972", "10.1177/030913339602000204", "10.1007/978-3-642-22300-6\\_14", "10.1109/iv.2004.1320189", "10.1111/cgf.13447", "10.1007/s11192-017-2596-3", "10.1559/1523040053722150", "10.1007/978-3-662-45803-7\\_34"], "wos": 1, "children": [], "len": 1}, {"doi": "10.1111/cgf.13212", "year": "2017", "title": "Survey of Surveys (SoS) - Mapping The Landscape of Survey Papers in Information Visualization", "conferenceName": "EuroVis", "authors": "Liam McNabb;Robert S. Laramee", "citationCount": "18", "affiliation": "McNabb, L (Corresponding Author), Swansea Univ, Dept Comp Sci, Swansea, W Glam, Wales.\nMcNabb, Liam; Laramee, Robert S., Swansea Univ, Dept Comp Sci, Swansea, W Glam, Wales.", "countries": "Wales", "abstract": "Information visualization as a field is growing rapidly in popularity since the first information visualization conference in 1995. However, as a consequence of its growth, it is increasingly difficult to follow the growing body of literature within the field. Survey papers and literature reviews are valuable tools for managing the great volume of previously published research papers, and the quantity of survey papers in visualization has reached a critical mass. To this end, this survey paper takes a quantum step forward by surveying and classifying literature survey papers in order to help researchers understand the current landscape of Information Visualization. It is, to our knowledge, the first survey of survey papers (SoS) in Information Visualization. This paper classifies survey papers into natural topic clusters which enables readers to find relevant literature and develops the first classification of classifications. The paper also enables researchers to identify both mature and less developed research directions as well as identify future directions. It is a valuable resource for both newcomers and experienced researchers in and outside the field of Information Visualization and Visual Analytics.", "keywords": "", "link": "https://doi.org/10.1111/cgf.13212", "refList": ["10.2312/eurovisstar.20151110", "10.1109/tvcg.2013.126", "10.1111/cgf.12932", "10.1006/jvlc.1993.1015", "10.1109/iv.2010.21", "10.2312/conf/eg2013/stars/039-063", "10.1111/cgf.12935", "10.1109/2945.981847", "10.1109/tits.2015.2436897", "10.1109/tits.2016.2530146", "10.1109/tvcg.2003.1207445", "10.1109/vissof.2007.4290693", "10.1016/s1386-5056(02)00072-2", "10.1109/tvcg.2009.23", "10.3145/epi.2014.may.02", "10.1007/s003710050111", "10.1111/cgf.12931", "10.1109/tvcg.2011.229", "10.1109/pacificvis.2015.7156366", "10.1007/978-1-4471-2804-5\\_6", "10.1016/j.cag.2012.07.006", "10.1109/tvcg.2010.79", "10.1109/tvcg.2011.144", "10.1109/tvcg.2013.238", "10.1109/38.708564", "10.1145/2994310.2994327", "10.1145/2543581.2543589", "10.1109/vast.2012.6400554", "10.1080/10447310701702402", "10.1109/tvcg.2014.2346665", "10.1002/widm.1071", "10.2312/eurovisstar.20151114", "10.1109/tvcg.2015.2466992", "10.1111/cgf.12936", "10.1109/tst.2013.6509098", "10.1016/j.ijhcs.2013.08.004", "10.1109/infvis.2000.885092", "10.1177/1473871611416549", "10.2312/conf/eg2013/stars/095-116", "10.2312/eurovisstar.20141170", "10.1111/j.1467-8659.2012.03094.x", "10.1109/tvcg.2015.2424889", "10.1016/j.jfs.2016.01.006", "10.1109/tvcg.2013.124", "10.1111/j.1467-8659.2012.03125.x", "10.2312/eurovisstar.20151109", "10.1109/tvcg.2011.279", "10.1109/tvcg.2009.84", "10.1111/j.1467-8659.2012.03184.x", "10.1057/palgrave.ivs.9500182", "10.2200/s00685ed1v01y201512vis005", "10.1145/22627.22349", "10.2312/eurovisshort.20141149", "10.1109/tvcg.2013.120", "10.1109/tvcg.2016.2615308", "10.1007/s11390-016-1663-1", "10.1007/s00371-013-0892-3", "10.1109/vast.2012.6400552", "10.1111/j.1467-8659.2011.01898.x", "10.2312/pe.eurovisshort.eurovisshort2013.019-023", "10.1080/10618600.1996.10474696", "10.1007/s11704-016-6028-y", "10.1109/cmv.2007.20", "10.1007/s11390-013-1383-8", "10.1109/2945.841119", "10.1002/wics.1285", "10.1057/ivs.2008.31", "10.1145/2993901.2993906", "10.1109/tvcg.2007.70535", "10.1177/1473871611424815", "10.1016/j.soncn.2011.02.001", "10.1111/j.1467-8306.2004.09401004.x", "10.1145/180171.180173", "10.1006/s1045-926x(02)00028-9", "10.1109/pacificvis.2012.6183556", "10.1136/amiajnl-2014-002955", "10.1109/tvcg.2013.153", "10.1016/s1045-926x(05)80036-9", "10.1109/tvcg.2010.110", "10.1561/1100000039", "10.1145/22339.22349", "10.2312/eurovisstar.20151113"], "wos": 1, "children": [{"doi": "10.1111/cgf.14034", "year": "2020", "title": "The State of the Art in Enhancing Trust in Machine Learning Models with the Use of Visualizations", "conferenceName": "EuroVis", "authors": "Angelos Chatzimparmpas;Rafael Messias Martins;Ilir Jusufi;Kostiantyn Kucher;Fabrice Rossi;Andreas Kerren", "citationCount": "2", "affiliation": "Chatzimparmpas, A (Corresponding Author), Linnaeus Univ, Dept Comp Sci \\& Media Technol, Vaxjo, Sweden.\nChatzimparmpas, A.; Martins, R. M.; Jusufi, I.; Kucher, K.; Kerren, A., Linnaeus Univ, Dept Comp Sci \\& Media Technol, Vaxjo, Sweden.\nRossi, F., PSL Univ, Univ Paris Dauphine, Ceremade, Paris, France.", "countries": "Sweden;France", "abstract": "Machine learning (ML) models are nowadays used in complex applications in various domains, such as medicine, bioinformatics, and other sciences. Due to their black box nature, however, it may sometimes be hard to understand and trust the results they provide. This has increased the demand for reliable visualization tools related to enhancing trust in ML models, which has become a prominent topic of research in the visualization community over the past decades. To provide an overview and present the frontiers of current research on the topic, we present a State-of-the-Art Report (STAR) on enhancing trust in ML models with the use of interactive visualization. We define and describe the background of the topic, introduce a categorization for visualization techniques that aim to accomplish this goal, and discuss insights and opportunities for future research directions. Among our contributions is a categorization of trust against different facets of interactive ML, expanded and improved from previous research. Our results are investigated from different analytical perspectives: (a) providing a statistical overview, (b) summarizing key findings, (c) performing topic analyses, and (d) exploring the data sets used in the individual papers, all with the support of an interactive web-based survey browser. We intend this survey to be beneficial for visualization researchers whose interests involve making ML models more trustworthy, as well as researchers and practitioners from other disciplines in their search for effective visualization techniques suitable for solving their tasks with confidence and conveying meaning to their data.", "keywords": "trustworthy machine learning; visualization; interpretable machine learning; explainable machine learning", "link": "https://doi.org/10.1111/cgf.14034", "refList": ["10.1109/mcg.2018.2878902", "10.1109/tvcg.2008.153", "10.2312/mlvis.20181130", "10.1109/tvcg.2016.2598828", "10.1145/3290605.3300911", "10.1145/2993901.2993909", "10.2312/mlvis.20191158", "10.1109/tvcg.2016.2598446", "10.1111/j.1467-8659.2009.01475.x", "10.1145/3290605.3300809", "10.1109/pacificvis.2018.00031", "10.1055/s-0029-1216348", "10.1007/978-3-319-90403-0\\_13", "10.1109/tvcg.2017.2745085", "10.1111/j.1467-8659.2011.01938.x", "10.1007/978-3-319-54024-5\\_6", "10.1016/s0167-9473(01)00065-2", "10.1111/cgf.12895", "10.2312/eurovisshort.20141152.17", "10.2312/eurova.20151098.22", "10.1111/cgf.13667", "10.3115/1072228.1072378", "10.1109/tbdata.2018.2877350.16", "10.1109/lars.2009.5418323.25", "10.1109/tvcg.2017.2744878", "10.1016/j.combustflame.2005.09.018", "10.1016/j.cag.2014.01.006", "10.1109/tvcg.2016.2570755", "10.2312/mlvis.20191158.1,19", "10.1518/hfes.46.1.50.30392", "10.1145/3301275.3302280", "10.1145/3351095.3372834.1", "10.1016/s0377-2217(01)00264-8", "10.1111/cgf.13424", "10.1007/978-3-319-23485-4\\_53", "10.1007/978-94-007-0753-5\\_3623", "10.1109/tvcg.2013.101", "10.1111/cgf.12884", "10.1111/j.1467-8659.2010.01835.x", "10.1021/ci9901338", "10.4230/lipics.itcs:2017", "10.1109/mis.2013.24", "10.1109/tvcg.2014.2346482", "10.1109/tvcg.2018.2865230", "10.1073/pnas.1807180116", "10.1109/dsaa.2018.00018", "10.1109/tvcg.2009.153", "10.3115/1219840.1219855", "10.1109/tvcg.2018.2864812", "10.1109/tvcg.2018.2872577", "10.2312/trvis.20191183", "10.1109/cvpr:2004.383", "10.1109/vast.2008.4677350", "10.1145/302979.303001", "10.1109/tvcg.2018.2864499", "10.1111/cgf.13672", "10.1109/tvcg.2014.2346626", "10.23915/distill.00010.18", "10.1109/tvcg.2017.2744805", "10.2312/mlvis:20191160.18", "10.23915/distill:00016", "10.1109/pacificvis.2016.7465260", "10.1111/cgf.13683", "10.23915/distill.00016.19", "10.1145/32906053.300803.22", "10.1109/tvcg.2014.2346574", "10.1177/1473871615600010", "10.1109/tvcg.2016.2598831", "10.1145/3230623", "10.1109/visual.2019.8933744", "10.1145/2993901.2993915", "10.1016/j.visinf.2017.01.006", "10.1145/2993901.2993914", "10.1109/tvcg.2014.2346984", "10.1109/5.726791", "10.23915/distill.00010", "10.1109/tvcg.2018.2864825", "10.2307/2394164", "10.1109/tvcg.2017.2744458", "10.1145/2993901.2993917.28", "10.1111/cgf.13711", "10.1109/tvcg.2016.2598664", "10.2307/2530428", "10.1109/icdar.1997.620583", "10.1109/tvcg.2017.2744718", "10.1111/cgf.13425", "10.1109/tvcg.2019.2903943", "10.1145/1518701.1518895", "10.1109/tvcg.2018.2864838", "10.1145/62038.62043", "10.1111/j.1467-8659.2011.01920.x", "10.1145/3025171.3025208", "10.1145/355112.355124", "10.1109/vast.2010.5652398", "10.1109/tvcg.2014.2346578", "10.1145/3173574.3174209", "10.4178/epih/e2014008", "10.1109/beliv.2018.8634201.25,28", "10.1016/j.eswa.2007.12.020", "10.1111/cgf:13406", "10.1109/mcg.2011.103", "10.1631/fitee.1700808", "10.1109/tvcg.2017.2745158", "10.1073/pnas.0307752101", "10.1109/tvcg.2018.2816223", "10.1109/tvcg.2017.2745141", "10.1145/32232.32234", "10.1109/tvcg.2019.2934267", "10.1109/tvcg.2018.2864477", "10.1145/3132169", "10.2312/eurova.20151100.19", "10.1145/3172944.3172964", "10.1145/2601248.2601268", "10.1109/isai-nlp.2018.8693002.1", "10.1111/cgf.13404", "10.1007/s100320200071", "10.2312/trvis.20191183.16", "10.1111/cgf.12755", "10.1145/2702123.2702509", "10.1145/1401890.1402008.25", "10.1109/tvcg.2012.65", "10.1177/1473871617733996", "10.2312/trvis.20191187.7", "10.21236/ada273556", "10.1109/vast.2010.5652450", "10.1111/j.1467-8659.2011.01940.x", "10.1177/875647939000600106", "10.1109/tvcg.2017.2711030", "10.1016/j.immuni.2016.04.014", "10.1109/tvcg.2019.2934209", "10.1016/0095-0696(78)90006-2", "10.1016/j.jclinepi.2015.04.014", "10.1016/j.ress.2013.02.013", "10.1111/cgf.12640", "10.1145/1015330.1015388.25", "10.1111/j.1467-8659.2009.01468.x", "10.1145/1541880.1541882", "10.1109/vast.2011.6102453", "10.1016/s0008-8846(98)00165-3", "10.2312/trvis.20191186.7", "10.1007/s13748-013-0040-3", "10.1109/tvcg.2015.2467757", "10.1109/tbdata.2018.2877350", "10.1109/vast.2017.8585613", "10.1080/10556789208805504", "10.1109/vast.2012.6400484", "10.1145/3025171.3025181", "10.1007/978-3-319-90403-0\\_12", "10.1109/mcg.2019.2922592", "10.1021/ci000392t", "10.1109/vast.2007.4389000", "10.1111/cgf.13406.16", "10.1111/cgf.13684", "10.2312/eurovisshort.20161166.17", "10.2312/evs:20191168", "10.1145/3041021.3055135", "10.1145/3301275.3302265", "10.1613/jair.4135", "10.1109/tvcg.2018.2864500", "10.1109/tvcg.2017.2744158", "10.1109/ssci.2015.33", "10.1111/cgf.13453", "10.2312/pe/eurovast/eurova11/049-052", "10.1145/3025171.3025181.13", "10.1145/371920.372094", "10.1109/tvcg.2017.2744938", "10.1111/j.1467-8659.2012.03108.x", "10.1109/tvcg.2019.2934251", "10.1145/3290605.3300809.18", "10.1109/ldav.2016.7874305", "10.1109/vast.2016.7883514", "10.1109/iccv.2015.425", "10.1145/3301275.3302324", "10.1109/tnnls.2013.2292894", "10.1109/tvcg.2018.2865044", "10.1109/tvcg.2013.157", "10.1371/journal.pcbi.0020161", "10.1186/s12916-019-1426-2", "10.1109/10.867928", "10.1111/cgf.13217", "10.1109/mcg.2019.2919033", "10.1145/2993901.2993910", "10.1109/tvcg.2017.2744738", "10.2307/258792", "10.1111/cgf.12655", "10.1016/j.dss.2014.03.001", "10.1109/tvcg.2019.2904069", "10.1111/cgf.13205", "10.1002/mds.22340", "10.1109/tvcg.2019.2934595", "10.1287/inte.2018.0957", "10.1109/cvpr.2007.382974", "10.1109/tvcg.2012.280", "10.1145/2678025.2701399.13", "10.2312/mlvis.20181130.13", "10.2312/eurova.20181106.16", "10.1109/tvcg.2018.2864475", "10.2312/mlvis.20191160.18,22", "10.1007/978-1-4612-4026-6.25", "10.1109/cvpr.2006.42", "10.1145/3172944.3172950", "10.1109/cvpr.2004.383.25", "10.1109/tvcg.2019.2934812", "10.1609/aimag.v35i4.2513", "10.2312/trvis.20191185.7", "10.1111/j.1467-8659.2009.01684.x", "10.1371/journal.pone.0129126", "10.1111/cgf.13092", "10.1162/coli\\_a\\_00237", "10.1109/tvcg.2017.2744818", "10.1109/vast.2011.6102448", "10.1109/tvcg.2009.111", "10.1109/tvcg.2019.2934619", "10.1016/s0377-2217(01)00264-8.25", "10.1111/cgf.12639", "10.1109/access.2019.2919343", "10.1186/s12874-019-0681-4", "10.1109/pacificvis.2015.7156366", "10.1109/pacificvis.2018.00029", "10.1109/tvcg.2019.2934261", "10.1080/13506280444000102.http://www.uvt.nl/ticc", "10.1109/vast.2018.8802509", "10.1111/cgf.13212", "10.1145/3200489", "10.1111/cgf.13176", "10.1177/1473871620904671", "10.1007/978-3-319-10590-1\\_53", "10.1111/j.1467-8659.2012.03126.x", "10.1111/cgf.13172", "10.1145/3025171.3025208.6,21", "10.1111/cgf.12366", "10.1109/tvcg.2019.2934659", "10.1109/cvprw.2009.5206848", "10.1016/j.media.2014.11.010", "10.1109/tvcg.2017.2744683", "10.1109/tvcg.2019.2934262", "10.1016/j.neucom.2006.11.018", "10.1177/1473871615571951", "10.1371/journal.pcbi.0020161.25", "10.1177/1473871611415994", "10.2312/trvis20191187", "10.2312/eurova", "10.1145/2858036.2858529", "10.1145/2207676.2207738", "10.1007/s11042-009-0417-2", "10.1145/3301275.3302317", "10.1038/s41746-019-0148-3", "10.1145/3351095.3372834", "10.1080/10691898.2011.11889627", "10.1109/tvcg.2018.2864504", "10.1109/vast.2017.8585720", "10.1109/mcg.2018.053491732", "10.1007/s10994-010-5207-6", "10.1109/tvcg.2019.2934433", "10.1016/j.cag.2017.05.005", "10.1109/tvcg.2012.279", "10.1145/3231622.3231641.19,20", "10.1145/1562849.1562851", "10.1007/11564126\\_", "10.1109/tvcg.2018.2846735", "10.3115/1225403.1225421", "10.1109/vast.2012.6400486", "10.2312/eurova.20191116.22", "10.1109/tvcg.2007.70443", "10.1080/027868291009242", "10.2312/eurova.20151100", "10.1145/2939502.2939503.19", "10.1016/j.cag.2014.02.004", "10.1145/2939672.2939778", "10.1109/vast.2010.5652484", "10.1111/cgf.12641", "10.1145/3301275.3302289", "10.1109/visual.2019.8933619", "10.1109/tvcg.2017.2672987", "10.1109/vast.2016.7883517.20", "10.1109/igarss.2017.8127684", "10.1016/j.jcae.2010.04.002", "10.1109/vast.2010.5652885", "10.1016/j.visinf.2019.03.002", "10.1007/s00371-018-1500-3", "10.1109/mcg.2018.042731661", "10.1109/34.598228", "10.1109/tvcg.2018.2865027", "10.1016/j.neucom.2017.01.105", "10.1111/cgf.12389", "10.1109/tvcg.2019.2934591", "10.1109/vast.2010.5652392.16", "10.1111/cgf.13416", "10.1080/02701367.1992.10608764", "10.1109/vast.2017.8585721", "10.1109/tvcg.2018.2843369", "10.1109/sbes.2010.27", "10.1109/vast.2015.7347637", "10.1145/1401890.1402008", "10.1016/j.bpj.2010.04.064", "10.1109/tvcg.2013.125", "10.1109/isai-nlp.2018.8693002", "10.1371/journal.pone.0160127", "10.1145/2856767.2856779", "10.1145/2678025.2701399", "10.1109/vast.2011.6102451", "10.1109/mcg.2010.18", "10.1021/ci4000213", "10.1109/vast.2012.6400492", "10.1007/11564126-49.25", "10.2312/eurova.20171114", "10.1109/vast.2010.5652443", "10.1145/3134599", "10.2312/pe/eurovast/eurovast10/013-018.19", "10.1109/tvcg.2019.2903946", "10.1109/tvcg.2015.2467717", "10.1177/1473871612460526", "10.1016/j.cag.2018.09.018", "10.1109/tvcg.2016.2598838", "10.1145/3172944.3172964.14", "10.1109/vast.2009.5333428", "10.1109/vast.2014.7042480", "10.2312/pe/eurovast/eurovast10/013-018", "10.1177/0962280215588241", "10.1145/2993901.2993917", "10.1109/cvpr.2008:4587581", "10.1109/tvcg.2015.2467551", "10.1016/j.visinf.2018.09.001", "10.1126/science.290.5500.2319", "10.2312/eurova.20151107", "10.1109/visual.2019.8933695", "10.13140/2.1.2393.1847", "10.1197/jamia.m1929", "10.1109/cvpr.2008.4587581.25", "10.1145/1518701.1518895.16", "10.1109/vds.2017.8573444", "10.2312/trvis:20191185", "10.1145/3359786", "10.13140/2.1.1341.1520", "10.2312/pe/eurovast/eurova11/049-052.17", "10.1109/tvcg.2014.2346660", "10.1145/3185517", "10.1109/adprl.2011.5967372", "10.1109/tvcg.2015.2467591", "10.1111/j.1751-9004.2009.00232.x", "10.1136/qshc.2004.010033", "10.1109/vast.2012.6400493", "10.1109/tvcg.2019.2934266", "10.1145/2971763.2971775", "10.1111/cgf.13730", "10.1109/vast.2012.6400488", "10.1111/cgf.13210", "10.1109/tvcg.2019.2934631", "10.1145/3172944.3172965", "10.1057/ivs.2010.2", "10.1109/tvcg.2017.2745258", "10.1016/j.jbusres.2019.07.039", "10.1162/jmlr.2003.3.4-5.993", "10.1109/pacificvis.2019.00044", "10.2312/pe/eurovast/eurova12/037-041", "10.1109/tvcg.2019.2934629", "10.1177/0018720814547570", "10.1145/3292500.3330908", "10.1111/j.1467-8659.2009.01467.x", "10.2312/eurova.20151098", "10.1177/1473871617713337", "10.1109/lars:2009.5418323", "10.1109/vast.2011.6102437", "10.1111/cgf.12878", "10.1561/1500000001", "10.1145/3025171.3025222", "10.1007/s11704-016-6028-y", "10.1016/j.procs.2017.05.216", "10.1109/cvpr.2007.382974.25", "10.1080/10447318.2020.1741118", "10.1109/vast.2012.6400489", "10.1145/3025171.3025172", "10.1109/tvcg.2017.2744098", "10.1109/tvcg.2005.66", "10.1016/j.dss.2009.05.016", "10.1007/978-1-4612-4026-6", "10.2312/evs.20191168.16,20,28", "10.2312/pe/eurovast/eurova12/037-041.17", "10.1145/3290605.3300803", "10.1145/1015330.1015388", "10.1111/cgf.13197", "10.1016/b978-1-55860-377-6.50048-7", "10.1111/cgf.13681", "10.1109/tvcg.2017.2744378", "10.1109/tvcg.2017.2744358", "10.1109/vast.2008.4677352"], "wos": 1, "children": [{"doi": "10.1109/tvcg.2020.3030368", "title": "Implicit Multidimensional Projection of Local Subspaces", "year": "2020", "conferenceName": "InfoVis", "authors": "Rongzheng Bian;Yumeng Xue;Liang Zhou;Jian Zhang 0070;Baoquan Chen;Daniel Weiskopf;Yunhai Wang", "citationCount": "1", "affiliation": "Wang, YH (Corresponding Author), Shandong Univ, Qingdao, Peoples R China. Zhou, L (Corresponding Author), Univ Utah, Salt Lake City, UT 84112 USA. Bian, Rongzheng; Xue, Yumeng; Wang, Yunhai, Shandong Univ, Qingdao, Peoples R China. Chen, Baoquan, Peking Univ, Beijing, Peoples R China. Zhang, Jian, Chinese Acad Sci, CNIC, Beijing, Peoples R China. Zhou, Liang, Univ Utah, Salt Lake City, UT 84112 USA. Weiskopf, Daniel, Univ Stuttgart, Stuttgart, Germany.", "countries": "USA;Germany;China", "abstract": "We propose a visualization method to understand the effect of multidimensional projection on local subspaces, using implicit function differentiation. Here, we understand the local subspace as the multidimensional local neighborhood of data points. Existing methods focus on the projection of multidimensional data points, and the neighborhood information is ignored. Our method is able to analyze the shape and directional information of the local subspace to gain more insights into the global structure of the data through the perception of local structures. Local subspaces are fitted by multidimensional ellipses that are spanned by basis vectors. An accurate and efficient vector transformation method is proposed based on analytical differentiation of multidimensional projections formulated as implicit functions. The results are visualized as glyphs and analyzed using a full set of specifically-designed interactions supported in our efficient web-based visualization tool. The usefulness of our method is demonstrated using various multi- and high-dimensional benchmark datasets. Our implicit differentiation vector transformation is evaluated through numerical comparisons; the overall method is evaluated through exploration examples and use cases.", "keywords": "High-dimensional data visualization,dimensionality reduction,local linear subspaces,user interaction", "link": "http://dx.doi.org/10.1109/TVCG.2020.3030368", "refList": ["10.3844/jcssp.2018.613.622", "10.1016/j.aci.2018.08.003", "10.3390/info9030065", "10.1016/j.visinf.2018.09.003", "10.1371/journal.pone.0118432", "10.1016/s0893-6080(05)80023-1", "10.1109/tvcg.2020.2986996", "10.1109/icst.2012.56", "10.1007/s10844-013-0250-y", "10.1109/tbdata.2018", "10.1145/1125451.1125659", "10.1109/tvcg.2013.125", "10.1177/1473871611412817", "10.1145/3290605.3300911", "10.1111/cgf.14034", "10.1007/s13721-013-0034-x", "10.1016/j.procs.2017.05.216", "10.1016/j.ins.2009.08.025", "10.1109/tvcg.2013.124", "10.1109/tvcg.2018.2864499", "10.1109/tvcg.2018.2864475", "10.1080/10447318.2020.1741118", "10.1016/j.imu.2019.100203", "10.1109/tvcg.2018.2865240", "10.1186/s12864-019-6413-7", "10.1109/tvcg.2015.2467551", "10.1002/widm.1249", "10.1007/978-3-319-66429-3\\_29", "10.1109/tvcg.2014.2346481", "10.1109/tvcg.2018.2864825", "10.1177/1473871620904671", "10.1109/tvcg.2019.2934267", "10.1136/bmjopen-2016-012799", "10.1109/smartgridcomm.2017.8340682", "10.1007/s10664-015-9401-9", "10.1145/1143844.1143874", "10.1111/cgf.12389", "10.1109/tvcg.2018.2872577", "10.1007/978-981-13-5802-9\\_20", "10.1016/j.ipm.2009.03.002", "10.5220/0006431602160222", "10.1109/mcg.2015.50", "10.1109/tvcg.2014.2346574", "10.1007/bf02289565", "10.1109/tvcg.2017.2744378", "10.1016/j.patrec.2008.08.010", "10.1023/a:1010933404324", "10.9735/2229-3981"], "wos": 1, "children": [], "len": 1}, {"doi": "10.1109/tvcg.2020.3030465", "title": "Visual Causality Analysis of Event Sequence Data", "year": "2020", "conferenceName": "VAST", "authors": "Zhuochen Jin;Shunan Guo;Nan Chen;Daniel Weiskopf;David Gotz;Nan Cao", "citationCount": "0", "affiliation": "Cao, N (Corresponding Author), Tongji Univ, IDVx Lab, Shanghai, Peoples R China. Jin, Zhuochen; Guo, Shunan; Chen, Nan; Cao, Nan, Tongji Univ, IDVx Lab, Shanghai, Peoples R China. Weiskopf, Daniel, Univ Stuttgart, Stuttgart, Germany. Gotz, David, Univ N Carolina, Chapel Hill, NC 27515 USA.", "countries": "USA;Germany;China", "abstract": "Causality is crucial to understanding the mechanisms behind complex systems and making decisions that lead to intended outcomes. Event sequence data is widely collected from many real-world processes, such as electronic health records, web clickstreams, and financial transactions, which transmit a great deal of information reflecting the causal relations among event types. Unfortunately, recovering causalities from observational event sequences is challenging, as the heterogeneous and high-dimensional event variables are often connected to rather complex underlying event excitation mechanisms that are hard to infer from limited observations. Many existing automated causal analysis techniques suffer from poor explainability and fail to include an adequate amount of human knowledge. In this paper, we introduce a visual analytics method for recovering causalities in event sequence data. We extend the Granger causality analysis algorithm on Hawkes processes to incorporate user feedback into causal model refinement. The visualization system includes an interactive causal analysis framework that supports bottom-up causal exploration, iterative causal verification and refinement, and causal comparison through a set of novel visualizations and interactions. We report two forms of evaluation: a quantitative evaluation of the model improvements resulting from the user-feedback mechanism, and a qualitative evaluation through case studies in different application domains to demonstrate the usefulness of the system.", "keywords": "Event sequence data,causality analysis,visual analytics", "link": "http://dx.doi.org/10.1109/TVCG.2020.3030465", "refList": ["10.5555/1642718", "10.1109/tvcg.2018.2865022", "10.5555/2074094.2074151", "10.1109/tvcg.2016.2618797", "10.1073/pnas.1320645111", "10.1109/tvcg.2017.2744843", "10.1109/iv.2017.69", "10.1109/tvcg.2019.2934399", "10.1145/3172944.3173007", "10.5555/1795555", "10.1109/mcg.2005.102", "10.1145/381641.381653", "10.1162/153244301753344614", "10.1111/cgf.14034", "10.1111/cgf.13198", "10.1017/cbo9780511519857", "10.1007/s10462-016-9475-9", "10.1075/ssol.2.2.07bor", "10.1007/978-1-4614-3223-4\\_3", "10.1109/infvis.2003.1249025", "10.1007/978-94-007-6094-313", "10.1145/2858036.2858387", "10.1109/tvcg.2007.70528", "10.1109/tvcg.2017.2674958", "10.1147/sj.454.0801", "10.1109/tvcg.2013.119", "10.1145/3173574.3173711", "10.1016/j.erss.2017.06.034", "10.1109/visual.2019.8933695", "10.1007/s11665-016-2173-6", "10.1016/0377-0427(87)90125-7", "10.2307/3601125", "10.1016/b978-0-444-88738-2.50018-x", "10.1109/mcg.2006.70", "10.1109/tvcg.2018.2865145", "10.1017/s1351324997001502", "10.1109/tvcg.2010.179", "10.1214/aos/1176344552", "10.1109/mcg.2009.22", "10.1007/978-3-319-26633-6\\_13", "10.1080/10447318.2014.905422", "10.1016/j.visinf.2019.03.004", "10.1057/palgrave.ivs.9500074", "10.1007/978-1-4614-3223-4"], "wos": 1, "children": [], "len": 1}], "len": 5}], "len": 7}], "len": 85}, {"doi": "10.1111/cgf.14034", "year": "2020", "title": "The State of the Art in Enhancing Trust in Machine Learning Models with the Use of Visualizations", "conferenceName": "EuroVis", "authors": "Angelos Chatzimparmpas;Rafael Messias Martins;Ilir Jusufi;Kostiantyn Kucher;Fabrice Rossi;Andreas Kerren", "citationCount": "2", "affiliation": "Chatzimparmpas, A (Corresponding Author), Linnaeus Univ, Dept Comp Sci \\& Media Technol, Vaxjo, Sweden.\nChatzimparmpas, A.; Martins, R. M.; Jusufi, I.; Kucher, K.; Kerren, A., Linnaeus Univ, Dept Comp Sci \\& Media Technol, Vaxjo, Sweden.\nRossi, F., PSL Univ, Univ Paris Dauphine, Ceremade, Paris, France.", "countries": "Sweden;France", "abstract": "Machine learning (ML) models are nowadays used in complex applications in various domains, such as medicine, bioinformatics, and other sciences. Due to their black box nature, however, it may sometimes be hard to understand and trust the results they provide. This has increased the demand for reliable visualization tools related to enhancing trust in ML models, which has become a prominent topic of research in the visualization community over the past decades. To provide an overview and present the frontiers of current research on the topic, we present a State-of-the-Art Report (STAR) on enhancing trust in ML models with the use of interactive visualization. We define and describe the background of the topic, introduce a categorization for visualization techniques that aim to accomplish this goal, and discuss insights and opportunities for future research directions. Among our contributions is a categorization of trust against different facets of interactive ML, expanded and improved from previous research. Our results are investigated from different analytical perspectives: (a) providing a statistical overview, (b) summarizing key findings, (c) performing topic analyses, and (d) exploring the data sets used in the individual papers, all with the support of an interactive web-based survey browser. We intend this survey to be beneficial for visualization researchers whose interests involve making ML models more trustworthy, as well as researchers and practitioners from other disciplines in their search for effective visualization techniques suitable for solving their tasks with confidence and conveying meaning to their data.", "keywords": "trustworthy machine learning; visualization; interpretable machine learning; explainable machine learning", "link": "https://doi.org/10.1111/cgf.14034", "refList": ["10.1109/mcg.2018.2878902", "10.1109/tvcg.2008.153", "10.2312/mlvis.20181130", "10.1109/tvcg.2016.2598828", "10.1145/3290605.3300911", "10.1145/2993901.2993909", "10.2312/mlvis.20191158", "10.1109/tvcg.2016.2598446", "10.1111/j.1467-8659.2009.01475.x", "10.1145/3290605.3300809", "10.1109/pacificvis.2018.00031", "10.1055/s-0029-1216348", "10.1007/978-3-319-90403-0\\_13", "10.1109/tvcg.2017.2745085", "10.1111/j.1467-8659.2011.01938.x", "10.1007/978-3-319-54024-5\\_6", "10.1016/s0167-9473(01)00065-2", "10.1111/cgf.12895", "10.2312/eurovisshort.20141152.17", "10.2312/eurova.20151098.22", "10.1111/cgf.13667", "10.3115/1072228.1072378", "10.1109/tbdata.2018.2877350.16", "10.1109/lars.2009.5418323.25", "10.1109/tvcg.2017.2744878", "10.1016/j.combustflame.2005.09.018", "10.1016/j.cag.2014.01.006", "10.1109/tvcg.2016.2570755", "10.2312/mlvis.20191158.1,19", "10.1518/hfes.46.1.50.30392", "10.1145/3301275.3302280", "10.1145/3351095.3372834.1", "10.1016/s0377-2217(01)00264-8", "10.1111/cgf.13424", "10.1007/978-3-319-23485-4\\_53", "10.1007/978-94-007-0753-5\\_3623", "10.1109/tvcg.2013.101", "10.1111/cgf.12884", "10.1111/j.1467-8659.2010.01835.x", "10.1021/ci9901338", "10.4230/lipics.itcs:2017", "10.1109/mis.2013.24", "10.1109/tvcg.2014.2346482", "10.1109/tvcg.2018.2865230", "10.1073/pnas.1807180116", "10.1109/dsaa.2018.00018", "10.1109/tvcg.2009.153", "10.3115/1219840.1219855", "10.1109/tvcg.2018.2864812", "10.1109/tvcg.2018.2872577", "10.2312/trvis.20191183", "10.1109/cvpr:2004.383", "10.1109/vast.2008.4677350", "10.1145/302979.303001", "10.1109/tvcg.2018.2864499", "10.1111/cgf.13672", "10.1109/tvcg.2014.2346626", "10.23915/distill.00010.18", "10.1109/tvcg.2017.2744805", "10.2312/mlvis:20191160.18", "10.23915/distill:00016", "10.1109/pacificvis.2016.7465260", "10.1111/cgf.13683", "10.23915/distill.00016.19", "10.1145/32906053.300803.22", "10.1109/tvcg.2014.2346574", "10.1177/1473871615600010", "10.1109/tvcg.2016.2598831", "10.1145/3230623", "10.1109/visual.2019.8933744", "10.1145/2993901.2993915", "10.1016/j.visinf.2017.01.006", "10.1145/2993901.2993914", "10.1109/tvcg.2014.2346984", "10.1109/5.726791", "10.23915/distill.00010", "10.1109/tvcg.2018.2864825", "10.2307/2394164", "10.1109/tvcg.2017.2744458", "10.1145/2993901.2993917.28", "10.1111/cgf.13711", "10.1109/tvcg.2016.2598664", "10.2307/2530428", "10.1109/icdar.1997.620583", "10.1109/tvcg.2017.2744718", "10.1111/cgf.13425", "10.1109/tvcg.2019.2903943", "10.1145/1518701.1518895", "10.1109/tvcg.2018.2864838", "10.1145/62038.62043", "10.1111/j.1467-8659.2011.01920.x", "10.1145/3025171.3025208", "10.1145/355112.355124", "10.1109/vast.2010.5652398", "10.1109/tvcg.2014.2346578", "10.1145/3173574.3174209", "10.4178/epih/e2014008", "10.1109/beliv.2018.8634201.25,28", "10.1016/j.eswa.2007.12.020", "10.1111/cgf:13406", "10.1109/mcg.2011.103", "10.1631/fitee.1700808", "10.1109/tvcg.2017.2745158", "10.1073/pnas.0307752101", "10.1109/tvcg.2018.2816223", "10.1109/tvcg.2017.2745141", "10.1145/32232.32234", "10.1109/tvcg.2019.2934267", "10.1109/tvcg.2018.2864477", "10.1145/3132169", "10.2312/eurova.20151100.19", "10.1145/3172944.3172964", "10.1145/2601248.2601268", "10.1109/isai-nlp.2018.8693002.1", "10.1111/cgf.13404", "10.1007/s100320200071", "10.2312/trvis.20191183.16", "10.1111/cgf.12755", "10.1145/2702123.2702509", "10.1145/1401890.1402008.25", "10.1109/tvcg.2012.65", "10.1177/1473871617733996", "10.2312/trvis.20191187.7", "10.21236/ada273556", "10.1109/vast.2010.5652450", "10.1111/j.1467-8659.2011.01940.x", "10.1177/875647939000600106", "10.1109/tvcg.2017.2711030", "10.1016/j.immuni.2016.04.014", "10.1109/tvcg.2019.2934209", "10.1016/0095-0696(78)90006-2", "10.1016/j.jclinepi.2015.04.014", "10.1016/j.ress.2013.02.013", "10.1111/cgf.12640", "10.1145/1015330.1015388.25", "10.1111/j.1467-8659.2009.01468.x", "10.1145/1541880.1541882", "10.1109/vast.2011.6102453", "10.1016/s0008-8846(98)00165-3", "10.2312/trvis.20191186.7", "10.1007/s13748-013-0040-3", "10.1109/tvcg.2015.2467757", "10.1109/tbdata.2018.2877350", "10.1109/vast.2017.8585613", "10.1080/10556789208805504", "10.1109/vast.2012.6400484", "10.1145/3025171.3025181", "10.1007/978-3-319-90403-0\\_12", "10.1109/mcg.2019.2922592", "10.1021/ci000392t", "10.1109/vast.2007.4389000", "10.1111/cgf.13406.16", "10.1111/cgf.13684", "10.2312/eurovisshort.20161166.17", "10.2312/evs:20191168", "10.1145/3041021.3055135", "10.1145/3301275.3302265", "10.1613/jair.4135", "10.1109/tvcg.2018.2864500", "10.1109/tvcg.2017.2744158", "10.1109/ssci.2015.33", "10.1111/cgf.13453", "10.2312/pe/eurovast/eurova11/049-052", "10.1145/3025171.3025181.13", "10.1145/371920.372094", "10.1109/tvcg.2017.2744938", "10.1111/j.1467-8659.2012.03108.x", "10.1109/tvcg.2019.2934251", "10.1145/3290605.3300809.18", "10.1109/ldav.2016.7874305", "10.1109/vast.2016.7883514", "10.1109/iccv.2015.425", "10.1145/3301275.3302324", "10.1109/tnnls.2013.2292894", "10.1109/tvcg.2018.2865044", "10.1109/tvcg.2013.157", "10.1371/journal.pcbi.0020161", "10.1186/s12916-019-1426-2", "10.1109/10.867928", "10.1111/cgf.13217", "10.1109/mcg.2019.2919033", "10.1145/2993901.2993910", "10.1109/tvcg.2017.2744738", "10.2307/258792", "10.1111/cgf.12655", "10.1016/j.dss.2014.03.001", "10.1109/tvcg.2019.2904069", "10.1111/cgf.13205", "10.1002/mds.22340", "10.1109/tvcg.2019.2934595", "10.1287/inte.2018.0957", "10.1109/cvpr.2007.382974", "10.1109/tvcg.2012.280", "10.1145/2678025.2701399.13", "10.2312/mlvis.20181130.13", "10.2312/eurova.20181106.16", "10.1109/tvcg.2018.2864475", "10.2312/mlvis.20191160.18,22", "10.1007/978-1-4612-4026-6.25", "10.1109/cvpr.2006.42", "10.1145/3172944.3172950", "10.1109/cvpr.2004.383.25", "10.1109/tvcg.2019.2934812", "10.1609/aimag.v35i4.2513", "10.2312/trvis.20191185.7", "10.1111/j.1467-8659.2009.01684.x", "10.1371/journal.pone.0129126", "10.1111/cgf.13092", "10.1162/coli\\_a\\_00237", "10.1109/tvcg.2017.2744818", "10.1109/vast.2011.6102448", "10.1109/tvcg.2009.111", "10.1109/tvcg.2019.2934619", "10.1016/s0377-2217(01)00264-8.25", "10.1111/cgf.12639", "10.1109/access.2019.2919343", "10.1186/s12874-019-0681-4", "10.1109/pacificvis.2015.7156366", "10.1109/pacificvis.2018.00029", "10.1109/tvcg.2019.2934261", "10.1080/13506280444000102.http://www.uvt.nl/ticc", "10.1109/vast.2018.8802509", "10.1111/cgf.13212", "10.1145/3200489", "10.1111/cgf.13176", "10.1177/1473871620904671", "10.1007/978-3-319-10590-1\\_53", "10.1111/j.1467-8659.2012.03126.x", "10.1111/cgf.13172", "10.1145/3025171.3025208.6,21", "10.1111/cgf.12366", "10.1109/tvcg.2019.2934659", "10.1109/cvprw.2009.5206848", "10.1016/j.media.2014.11.010", "10.1109/tvcg.2017.2744683", "10.1109/tvcg.2019.2934262", "10.1016/j.neucom.2006.11.018", "10.1177/1473871615571951", "10.1371/journal.pcbi.0020161.25", "10.1177/1473871611415994", "10.2312/trvis20191187", "10.2312/eurova", "10.1145/2858036.2858529", "10.1145/2207676.2207738", "10.1007/s11042-009-0417-2", "10.1145/3301275.3302317", "10.1038/s41746-019-0148-3", "10.1145/3351095.3372834", "10.1080/10691898.2011.11889627", "10.1109/tvcg.2018.2864504", "10.1109/vast.2017.8585720", "10.1109/mcg.2018.053491732", "10.1007/s10994-010-5207-6", "10.1109/tvcg.2019.2934433", "10.1016/j.cag.2017.05.005", "10.1109/tvcg.2012.279", "10.1145/3231622.3231641.19,20", "10.1145/1562849.1562851", "10.1007/11564126\\_", "10.1109/tvcg.2018.2846735", "10.3115/1225403.1225421", "10.1109/vast.2012.6400486", "10.2312/eurova.20191116.22", "10.1109/tvcg.2007.70443", "10.1080/027868291009242", "10.2312/eurova.20151100", "10.1145/2939502.2939503.19", "10.1016/j.cag.2014.02.004", "10.1145/2939672.2939778", "10.1109/vast.2010.5652484", "10.1111/cgf.12641", "10.1145/3301275.3302289", "10.1109/visual.2019.8933619", "10.1109/tvcg.2017.2672987", "10.1109/vast.2016.7883517.20", "10.1109/igarss.2017.8127684", "10.1016/j.jcae.2010.04.002", "10.1109/vast.2010.5652885", "10.1016/j.visinf.2019.03.002", "10.1007/s00371-018-1500-3", "10.1109/mcg.2018.042731661", "10.1109/34.598228", "10.1109/tvcg.2018.2865027", "10.1016/j.neucom.2017.01.105", "10.1111/cgf.12389", "10.1109/tvcg.2019.2934591", "10.1109/vast.2010.5652392.16", "10.1111/cgf.13416", "10.1080/02701367.1992.10608764", "10.1109/vast.2017.8585721", "10.1109/tvcg.2018.2843369", "10.1109/sbes.2010.27", "10.1109/vast.2015.7347637", "10.1145/1401890.1402008", "10.1016/j.bpj.2010.04.064", "10.1109/tvcg.2013.125", "10.1109/isai-nlp.2018.8693002", "10.1371/journal.pone.0160127", "10.1145/2856767.2856779", "10.1145/2678025.2701399", "10.1109/vast.2011.6102451", "10.1109/mcg.2010.18", "10.1021/ci4000213", "10.1109/vast.2012.6400492", "10.1007/11564126-49.25", "10.2312/eurova.20171114", "10.1109/vast.2010.5652443", "10.1145/3134599", "10.2312/pe/eurovast/eurovast10/013-018.19", "10.1109/tvcg.2019.2903946", "10.1109/tvcg.2015.2467717", "10.1177/1473871612460526", "10.1016/j.cag.2018.09.018", "10.1109/tvcg.2016.2598838", "10.1145/3172944.3172964.14", "10.1109/vast.2009.5333428", "10.1109/vast.2014.7042480", "10.2312/pe/eurovast/eurovast10/013-018", "10.1177/0962280215588241", "10.1145/2993901.2993917", "10.1109/cvpr.2008:4587581", "10.1109/tvcg.2015.2467551", "10.1016/j.visinf.2018.09.001", "10.1126/science.290.5500.2319", "10.2312/eurova.20151107", "10.1109/visual.2019.8933695", "10.13140/2.1.2393.1847", "10.1197/jamia.m1929", "10.1109/cvpr.2008.4587581.25", "10.1145/1518701.1518895.16", "10.1109/vds.2017.8573444", "10.2312/trvis:20191185", "10.1145/3359786", "10.13140/2.1.1341.1520", "10.2312/pe/eurovast/eurova11/049-052.17", "10.1109/tvcg.2014.2346660", "10.1145/3185517", "10.1109/adprl.2011.5967372", "10.1109/tvcg.2015.2467591", "10.1111/j.1751-9004.2009.00232.x", "10.1136/qshc.2004.010033", "10.1109/vast.2012.6400493", "10.1109/tvcg.2019.2934266", "10.1145/2971763.2971775", "10.1111/cgf.13730", "10.1109/vast.2012.6400488", "10.1111/cgf.13210", "10.1109/tvcg.2019.2934631", "10.1145/3172944.3172965", "10.1057/ivs.2010.2", "10.1109/tvcg.2017.2745258", "10.1016/j.jbusres.2019.07.039", "10.1162/jmlr.2003.3.4-5.993", "10.1109/pacificvis.2019.00044", "10.2312/pe/eurovast/eurova12/037-041", "10.1109/tvcg.2019.2934629", "10.1177/0018720814547570", "10.1145/3292500.3330908", "10.1111/j.1467-8659.2009.01467.x", "10.2312/eurova.20151098", "10.1177/1473871617713337", "10.1109/lars:2009.5418323", "10.1109/vast.2011.6102437", "10.1111/cgf.12878", "10.1561/1500000001", "10.1145/3025171.3025222", "10.1007/s11704-016-6028-y", "10.1016/j.procs.2017.05.216", "10.1109/cvpr.2007.382974.25", "10.1080/10447318.2020.1741118", "10.1109/vast.2012.6400489", "10.1145/3025171.3025172", "10.1109/tvcg.2017.2744098", "10.1109/tvcg.2005.66", "10.1016/j.dss.2009.05.016", "10.1007/978-1-4612-4026-6", "10.2312/evs.20191168.16,20,28", "10.2312/pe/eurovast/eurova12/037-041.17", "10.1145/3290605.3300803", "10.1145/1015330.1015388", "10.1111/cgf.13197", "10.1016/b978-1-55860-377-6.50048-7", "10.1111/cgf.13681", "10.1109/tvcg.2017.2744378", "10.1109/tvcg.2017.2744358", "10.1109/vast.2008.4677352"], "wos": 1, "children": [{"doi": "10.1109/tvcg.2020.3030368", "title": "Implicit Multidimensional Projection of Local Subspaces", "year": "2020", "conferenceName": "InfoVis", "authors": "Rongzheng Bian;Yumeng Xue;Liang Zhou;Jian Zhang 0070;Baoquan Chen;Daniel Weiskopf;Yunhai Wang", "citationCount": "1", "affiliation": "Wang, YH (Corresponding Author), Shandong Univ, Qingdao, Peoples R China. Zhou, L (Corresponding Author), Univ Utah, Salt Lake City, UT 84112 USA. Bian, Rongzheng; Xue, Yumeng; Wang, Yunhai, Shandong Univ, Qingdao, Peoples R China. Chen, Baoquan, Peking Univ, Beijing, Peoples R China. Zhang, Jian, Chinese Acad Sci, CNIC, Beijing, Peoples R China. Zhou, Liang, Univ Utah, Salt Lake City, UT 84112 USA. Weiskopf, Daniel, Univ Stuttgart, Stuttgart, Germany.", "countries": "USA;Germany;China", "abstract": "We propose a visualization method to understand the effect of multidimensional projection on local subspaces, using implicit function differentiation. Here, we understand the local subspace as the multidimensional local neighborhood of data points. Existing methods focus on the projection of multidimensional data points, and the neighborhood information is ignored. Our method is able to analyze the shape and directional information of the local subspace to gain more insights into the global structure of the data through the perception of local structures. Local subspaces are fitted by multidimensional ellipses that are spanned by basis vectors. An accurate and efficient vector transformation method is proposed based on analytical differentiation of multidimensional projections formulated as implicit functions. The results are visualized as glyphs and analyzed using a full set of specifically-designed interactions supported in our efficient web-based visualization tool. The usefulness of our method is demonstrated using various multi- and high-dimensional benchmark datasets. Our implicit differentiation vector transformation is evaluated through numerical comparisons; the overall method is evaluated through exploration examples and use cases.", "keywords": "High-dimensional data visualization,dimensionality reduction,local linear subspaces,user interaction", "link": "http://dx.doi.org/10.1109/TVCG.2020.3030368", "refList": ["10.3844/jcssp.2018.613.622", "10.1016/j.aci.2018.08.003", "10.3390/info9030065", "10.1016/j.visinf.2018.09.003", "10.1371/journal.pone.0118432", "10.1016/s0893-6080(05)80023-1", "10.1109/tvcg.2020.2986996", "10.1109/icst.2012.56", "10.1007/s10844-013-0250-y", "10.1109/tbdata.2018", "10.1145/1125451.1125659", "10.1109/tvcg.2013.125", "10.1177/1473871611412817", "10.1145/3290605.3300911", "10.1111/cgf.14034", "10.1007/s13721-013-0034-x", "10.1016/j.procs.2017.05.216", "10.1016/j.ins.2009.08.025", "10.1109/tvcg.2013.124", "10.1109/tvcg.2018.2864499", "10.1109/tvcg.2018.2864475", "10.1080/10447318.2020.1741118", "10.1016/j.imu.2019.100203", "10.1109/tvcg.2018.2865240", "10.1186/s12864-019-6413-7", "10.1109/tvcg.2015.2467551", "10.1002/widm.1249", "10.1007/978-3-319-66429-3\\_29", "10.1109/tvcg.2014.2346481", "10.1109/tvcg.2018.2864825", "10.1177/1473871620904671", "10.1109/tvcg.2019.2934267", "10.1136/bmjopen-2016-012799", "10.1109/smartgridcomm.2017.8340682", "10.1007/s10664-015-9401-9", "10.1145/1143844.1143874", "10.1111/cgf.12389", "10.1109/tvcg.2018.2872577", "10.1007/978-981-13-5802-9\\_20", "10.1016/j.ipm.2009.03.002", "10.5220/0006431602160222", "10.1109/mcg.2015.50", "10.1109/tvcg.2014.2346574", "10.1007/bf02289565", "10.1109/tvcg.2017.2744378", "10.1016/j.patrec.2008.08.010", "10.1023/a:1010933404324", "10.9735/2229-3981"], "wos": 1, "children": [], "len": 1}, {"doi": "10.1109/tvcg.2020.3030465", "title": "Visual Causality Analysis of Event Sequence Data", "year": "2020", "conferenceName": "VAST", "authors": "Zhuochen Jin;Shunan Guo;Nan Chen;Daniel Weiskopf;David Gotz;Nan Cao", "citationCount": "0", "affiliation": "Cao, N (Corresponding Author), Tongji Univ, IDVx Lab, Shanghai, Peoples R China. Jin, Zhuochen; Guo, Shunan; Chen, Nan; Cao, Nan, Tongji Univ, IDVx Lab, Shanghai, Peoples R China. Weiskopf, Daniel, Univ Stuttgart, Stuttgart, Germany. Gotz, David, Univ N Carolina, Chapel Hill, NC 27515 USA.", "countries": "USA;Germany;China", "abstract": "Causality is crucial to understanding the mechanisms behind complex systems and making decisions that lead to intended outcomes. Event sequence data is widely collected from many real-world processes, such as electronic health records, web clickstreams, and financial transactions, which transmit a great deal of information reflecting the causal relations among event types. Unfortunately, recovering causalities from observational event sequences is challenging, as the heterogeneous and high-dimensional event variables are often connected to rather complex underlying event excitation mechanisms that are hard to infer from limited observations. Many existing automated causal analysis techniques suffer from poor explainability and fail to include an adequate amount of human knowledge. In this paper, we introduce a visual analytics method for recovering causalities in event sequence data. We extend the Granger causality analysis algorithm on Hawkes processes to incorporate user feedback into causal model refinement. The visualization system includes an interactive causal analysis framework that supports bottom-up causal exploration, iterative causal verification and refinement, and causal comparison through a set of novel visualizations and interactions. We report two forms of evaluation: a quantitative evaluation of the model improvements resulting from the user-feedback mechanism, and a qualitative evaluation through case studies in different application domains to demonstrate the usefulness of the system.", "keywords": "Event sequence data,causality analysis,visual analytics", "link": "http://dx.doi.org/10.1109/TVCG.2020.3030465", "refList": ["10.5555/1642718", "10.1109/tvcg.2018.2865022", "10.5555/2074094.2074151", "10.1109/tvcg.2016.2618797", "10.1073/pnas.1320645111", "10.1109/tvcg.2017.2744843", "10.1109/iv.2017.69", "10.1109/tvcg.2019.2934399", "10.1145/3172944.3173007", "10.5555/1795555", "10.1109/mcg.2005.102", "10.1145/381641.381653", "10.1162/153244301753344614", "10.1111/cgf.14034", "10.1111/cgf.13198", "10.1017/cbo9780511519857", "10.1007/s10462-016-9475-9", "10.1075/ssol.2.2.07bor", "10.1007/978-1-4614-3223-4\\_3", "10.1109/infvis.2003.1249025", "10.1007/978-94-007-6094-313", "10.1145/2858036.2858387", "10.1109/tvcg.2007.70528", "10.1109/tvcg.2017.2674958", "10.1147/sj.454.0801", "10.1109/tvcg.2013.119", "10.1145/3173574.3173711", "10.1016/j.erss.2017.06.034", "10.1109/visual.2019.8933695", "10.1007/s11665-016-2173-6", "10.1016/0377-0427(87)90125-7", "10.2307/3601125", "10.1016/b978-0-444-88738-2.50018-x", "10.1109/mcg.2006.70", "10.1109/tvcg.2018.2865145", "10.1017/s1351324997001502", "10.1109/tvcg.2010.179", "10.1214/aos/1176344552", "10.1109/mcg.2009.22", "10.1007/978-3-319-26633-6\\_13", "10.1080/10447318.2014.905422", "10.1016/j.visinf.2019.03.004", "10.1057/palgrave.ivs.9500074", "10.1007/978-1-4614-3223-4"], "wos": 1, "children": [], "len": 1}], "len": 5}], "len": 343}, {"doi": "10.1109/tvcg.2016.2598590", "title": "Visualizing Social Media Content with SentenTree", "year": "2016", "conferenceName": "InfoVis", "authors": "Mengdie Hu;Krist Wongsuphasawat;John T. Stasko", "citationCount": "20", "affiliation": "Hu, MD (Corresponding Author), Georgia Inst Technol, Atlanta, GA 30332 USA. Hu, Mengdie; Stasko, John, Georgia Inst Technol, Atlanta, GA 30332 USA. Hu, Mengdie; Wongsuphasawat, Krist, Twitter Inc, San Francisco, CA USA.", "countries": "USA", "abstract": "We introduce SentenTree, a novel technique for visualizing the content of unstructured social media text. SentenTree displays frequent sentence patterns abstracted from a corpus of social media posts. The technique employs design ideas from word clouds and the Word Tree, but overcomes a number of limitations of both those visualizations. SentenTree displays a node-link diagram where nodes are words and links indicate word co-occurrence within the same sentence. The spatial arrangement of nodes gives cues to the syntactic ordering of words while the size of nodes gives cues to their frequency of occurrence. SentenTree can help people gain a rapid understanding of key concepts and opinions in a large social media text collection. It is implemented as a lightweight application that runs in the browser.", "keywords": "text visualization;social media;natural language processing;word cloud;Twitter", "link": "http://dx.doi.org/10.1109/TVCG.2016.2598590", "refList": ["10.1017/s1368980010003733", "10.1109/iv.2010.24", "10.1177/1473871613493996", "10.1109/tvcg.2013.221", "10.1111/j.1467-8659.2011.01923.x", "10.1109/pacificvis.2015.7156366", "10.1109/tvcg.2009.165", "10.1109/vl.1996.545307", "10.1007/978-3-319-07959-2\\_21", "10.1145/2207676.2207738", "10.1145/1835804.1835827", "10.1109/tvcg.2014.2346920", "10.1109/tvcg.2011.239", "10.1145/1963405.1963504", "10.1109/tvcg.2012.96", "10.1109/vast.2011.6102488", "10.1109/tvcg.2015.2467991", "10.1109/2945.981848", "10.1109/infvis.1995.528686", "10.1109/mcg.2010.102", "10.1109/tvcg.2010.194", "10.1145/1374489.1374501", "10.1109/tvcg.2009.171", "10.1145/2207676.2208672", "10.1111/j.1467-8659.2012.03107.x", "10.1109/vast.2012.6400485", "10.3366/cor.2015.0067", "10.1145/2362364.2362367", "10.1109/pacificvis.2011.5742382", "10.1007/978", "10.1109/tvcg.2010.154", "10.1109/tvcg.2006.156", "10.1007/978-3-319-07821-2\\_11", "10.1109/tvcg.2012.324", "10.1109/tvcg.2011.179", "10.1109/tvcg.2008.172"], "wos": 1, "children": [{"doi": "10.1109/vast.2017.8585638", "title": "E-Map: A Visual Analytics Approach for Exploring Significant Event Evolutions in Social Media", "year": "2017", "conferenceName": "VAST", "authors": "Siming Chen;Shuai Chen;Lijing Lin;Xiaoru Yuan;Jie Liang 0004;Xiaolong Zhang", "citationCount": "10", "affiliation": "Yuan, XR (Corresponding Author), Peking Univ, Key Lab Machine Percept, Minist Educ, Beijing, Peoples R China. Yuan, XR (Corresponding Author), Peking Univ, Sch EECS, Beijing, Peoples R China. Chen, Siming; Chen, Shuai; Lin, Lijing; Yuan, Xiaoru, Peking Univ, Key Lab Machine Percept, Minist Educ, Beijing, Peoples R China. Chen, Siming; Chen, Shuai; Lin, Lijing; Yuan, Xiaoru, Peking Univ, Sch EECS, Beijing, Peoples R China. Liang, Jie, Univ Technol, Fac Engn \\& Informat Technol, Sydney, NSW, Australia. Zhang, Xiaolong, Penn State Univ, Coll Informat Sci \\& Technol, University Pk, PA 16802 USA.", "countries": "USA;China;Australia", "abstract": "Significant events are often discussed and spread through social media, involving many people. Reposting activities and opinions expressed in social media offer good opportunities to understand the evolution of events. However, the dynamics of reposting activities and the diversity of user comments pose challenges to understand event-related social media data. We propose E-Map, a visual analytics approach that uses map-like visualization tools to help multi-faceted analysis of social media data on a significant event and in-depth understanding of the development of the event. E-Map transforms extracted keywords, messages, and reposting behaviors into map features such as cities, towns, and rivers to build a structured and semantic space for users to explore. It also visualizes complex posting and reposting behaviors as simple trajectories and connections that can be easily followed. By supporting multi-level spatial temporal exploration, E-Map helps to reveal the patterns of event development and key players in an event, disclosing the ways they shape and affect the development of the event. Two cases analysing real-world events confirm the capacities of E-Map in facilitating the analysis of event evolution with social media data.", "keywords": "Social Media,Event Analysis,Map-like Visual Metaphor,Spatial Temporal Visual Analytics", "link": "http://dx.doi.org/10.1109/VAST.2017.8585638", "refList": ["10.1109/tvcg.2007.70582", "10.1109/tvcg.2016.2598919", "10.1109/pacificvis.2010.5429590", "10.1057/ivs.2008.23", "10.1109/vast.2014.7042496", "10.1016/j.cag.2013.11.003", "10.1109/vast.2011.6102456", "10.1109/tvcg.2013.221", "10.1109/tvcg.2011.185", "10.1109/vast.2016.7883510", "10.1111/j.1467-8659.2012.03120.x", "10.1109/tvcg.2013.186", "10.1109/tmm.2016.2614220", "10.7155/jgaa.00302", "10.1109/mc.2012.430", "10.1109/tvcg.2015.2467619", "10.1109/tvcg.2010.129", "10.1016/s0341-8162(01)00164-3", "10.1109/tvcg.2016.2598590", "10.1145/2065023.2065041", "10.1111/cgf.13211", "10.1109/tvcg.2013.162", "10.1109/tvcg.2011.288", "10.1145/1963405.1963504", "10.5670/oceanog.2016.66", "10.1109/tvcg.2015.2467554", "10.1109/tvcg.2015.2467691", "10.1016/j.cag.2013.10.008", "10.1109/mcg.2015.73", "10.1109/vast.2012.6400557", "10.1109/tvcg.2016.2539960", "10.1109/tit.1982.1056489", "10.1109/pacificvis.2012.6183572", "10.1109/tvcg.2014.2346922", "10.1109/tmm.2014.2384912", "10.1109/vast.2016.7883511", "10.1002/spe.4380211102", "10.1145/2488388.2488504", "10.2312/eurovisstar.20141176", "10.1109/bigdata.2013.6691714", "10.1109/tvcg.2009.171", "10.1109/tvcg.2013.196", "10.1109/vast.2008.4677356", "10.1145/2207676.2208672", "10.1111/j.1467-8659.2011.01955.x", "10.1109/pacificvis.2014.38", "10.1109/tvcg.2012.291", "10.1109/vast.2012.6400485", "10.1109/pacificvis.2015.7156376", "10.1145/1348549.1348556", "10.1109/vast.2015.7347632", "10.1109/tvcg.2014.2346919", "10.1109/tvcg.2014.2346433"], "wos": 1, "children": [{"doi": "10.1109/tvcg.2019.2934263", "title": "R-Map: A Map Metaphor for Visualizing Information Reposting Process in Social Media", "year": "2019", "conferenceName": "VAST", "authors": "Shuai Chen;Sihang Li;Siming Chen;Xiaoru Yuan", "citationCount": "0", "affiliation": "Yuan, XR (Corresponding Author), Peking Univ, Natl Engn Lab Big Data Anal \\& Applicat, Beijing, Peoples R China. Chen, Shuai; Li, Sihang, Peking Univ, Sch EECS, Minist Educ, Key Lab Machine Petrept, Beijing, Peoples R China. Yuan, Xiaoru, Peking Univ, Natl Engn Lab Big Data Anal \\& Applicat, Beijing, Peoples R China. Chen, Siming, Fraunhofer Inst IAIS, St Augustin, Germany. Chen, Siming, Univ Bonn, Bonn, Germany.", "countries": "Germany;China", "abstract": "We propose R-Map (Reposting Map), a visual analytical approach with a map metaphor to support interactive exploration and analysis of the information reposting process in social media. A single original social media post can cause large cascades of repostings (i.e., retweets) on online networks, involving thousands, even millions of people with different opinions. Such reposting behaviors form the reposting tree, in which a node represents a message and a link represents the reposting relation. In R-Map, the reposting tree structure can be spatialized with highlighted key players and tiled nodes. The important reposting behaviors, the following relations and the semantics relations are represented as rivers, routes and bridges, respectively, in a virtual geographical space. R-Map supports a scalable overview of a large number of information repostings with semantics. Additional interactions on the map are provided to support the investigation of temporal patterns and user behaviors in the information diffusion process. We evaluate the usability and effectiveness of our system with two use cases and a formal user study.", "keywords": "Social Media,Information Diffusion,Map-like Visual Metaphor", "link": "http://dx.doi.org/10.1109/TVCG.2019.2934263", "refList": ["10.1109/infvis.2000.885091", "10.1109/pacificvis.2010.5429590", "10.1111/j.0020-2754.1998.00269.x", "10.1109/vast.2017.8585638", "10.1145/2700398", "10.1109/tmm.2016.2614229", "10.1109/visual.1991.175815", "10.1145/3183347", "10.1109/infvis.2001.963290", "10.1109/vast.2016.7883510", "10.1109/access.2016.2605009", "10.1109/mcg.2011.103", "10.1145/1124772.1124851", "10.1109/tmm.2016.2614220", "10.1109/tvcg.2010.79", "10.1109/infvis.2000.885095", "10.1111/cgf.13211", "10.1109/tvcg.2014.2346920", "10.1002/(sici)1097-0266(199606)17:6", "10.5670/oceanog.2016.66", "10.1559/152304003100011081", "10.1109/tit.1982.1056489", "10.1559/152304098782383034", "10.1109/tvcg.2014.2346922", "10.1007/978-3-540-85567-5\\_9", "10.1145/2488388.2488504", "10.1109/38.974518", "10.1109/bigdata.2013.6691714", "10.1109/pacificvis.2014.38", "10.1109/tvcg.2012.291", "10.1109/infvis.2005.1532128", "10.2307/2685881", "10.1007/1-4020-4179-9\\_91", "10.1109/infvis.1999.801860", "10.1109/asonam.2011.37"], "wos": 1, "children": [{"doi": "10.1111/cgf.14031", "year": "2020", "title": "The State of the Art in Map-Like Visualization", "conferenceName": "EuroVis", "authors": "Marius Hogr{\\\"{a}}fer;Magnus Heitzler;Hans{-}J{\\\"{o}}rg Schulz", "citationCount": "0", "affiliation": "Hografer, M (Corresponding Author), Aarhus Univ, Dept Comp Sci, Aarhus, Denmark.\nHografer, Marius; Schulz, Hans-Jorg, Aarhus Univ, Dept Comp Sci, Aarhus, Denmark.\nHeitzler, Magnus, Swiss Fed Inst Technol, Inst Cartog \\& Geoinformat, Zurich, Switzerland.", "countries": "Switzerland;Denmark", "abstract": "Cartographic maps have been shown to provide cognitive benefits when interpreting data in relation to a geographic location. In visualization, the term map-like describes techniques that incorporate characteristics of cartographic maps in their representation of abstract data. However, the field of map-like visualization is vast and currently lacks a clear classification of the existing techniques. Moreover, choosing the right technique to support a particular visualization task is further complicated, as techniques are scattered across different domains, with each considering different characteristics as map-like. In this paper, we give an overview of the literature on map-like visualization and provide a hierarchical classification of existing techniques along two general perspectives: imitation and schematization of cartographic maps. Each perspective is further divided into four principal categories that group common map-like techniques along the visual primitives they affect. We further discuss this classification from a task-centered view and highlight open research questions.", "keywords": "", "link": "https://doi.org/10.1111/cgf.14031", "refList": ["10.1111/j.0020-2754.1998.00269.x.21", "10.1109/iv.2005.26", "10.2307/2980460", "10.1109/tvcg.2017.2743959", "10.1016/j.jvlc.2011.11.004", "10.1145/2501988.2502046", "10.1559/1523040042742402", "10.1007/s00779-011-0500-3", "10.1111/cgf.12932", "10.1109/tvcg.2010.89", "10.1111/cgf.13200", "10.1080/15230406.2016.1160797", "10.1179/000870410x12825500202896", "10.1109/tvcg.2007.70596", "10.5167/80972.19uzh-80972", "10.1007/978-3-319-11593-1\\_2", "10.1037/aca0000175", "10.1080/17538947.2014.923942", "10.1109/tvcg.2015.2467321", "10.1109/vissof.2005.1684299", "10.1559/152304098782383034", "10.1007/978-3-642-36763-2\\_38", "10.1109/tvcg.2013.130", "10.1109/tvcg.2014.2346274", "10.1111/cgf.12648", "10.1111/0004-5608.00242", "10.1177/1473871617724212", "10.1109/iv.2004.1320123", "10.1371/journal.pcbi.1006907", "10.1109/tvcg.2016.2599030", "10.1559/1523040042742411", "10.3390/informatics5030031", "10.1111/cgf.13079", "10.1109/tvcg.2015.2467811", "10.1016/j.tics.2003.12.004", "10.1007/s00799-016-0168-4", "10.1109/infvis.2004.57", "10.1007/s10021-007-9038-7", "10.1109/pacificvis.2015.7156366", "10.1007/978-3-319-27261-0\\_1", "10.1007/978-1-4471-2804-5\\_6", "10.1109/access.2019.2939977", "10.1109/tvcg.2017.2747545", "10.1109/icdm.2003.1250978", "10.1111/cgf.13167", "10.1016/0010-0285(78)90006-3", "10.3138/nj8v-8514-871t-221k", "10.1016/j.cag.2009.06.002", "10.1111/j.1467-8659.2011.01937.x", "10.1016/b978-044451020-4/50035-9", "10.1111/1467-8659.00566", "10.5220/0006618101080119", "10.1109/pacificvis.2012.6183571", "10.1145/2038558.2038579", "10.1109/tvcg.2010.191", "10.1111/j.0033-0124.1985.00075.x", "10.1109/tvcg.2004.1260761", "10.1007/978-3-642-34848-8\\_6", "10.1145/2968220.2968239", "10.1145/3002151.3002160", "10.1109/tst.2013.6509098", "10.1109/tvcg.2013.91", "10.1177/1473871615597077", "10.1016/j.jvlc.2011.02.001", "10.1080/17445647.2014.935502", "10.1177/1687814017740710", "10.1111/1744-7917.12601", "10.1073/pnas.0400280101", "10.1111/cgf.13672", "10.1109/mcg.2006.90", "10.1002/asi.21712", "10.1007/978-3-642-33024-7\\_3", "10.1145/2801040.2801056", "10.1109/mcg.2010.101", "10.1179/003962607x165041", "10.1057/palgrave.ivs.9500039", "10.1109/vast.2016.7883510", "10.1559/152304009788988288", "10.1080/23729333.2017.1301346", "10.1109/tvcg.2013.66", "10.1111/j.1467-8659.2012.03085.x", "10.1109/tvcg.2011.288", "10.3390/ijgi9040253", "10.1109/infvis.2005.1532150", "10.1145/2254556.2254636", "10.20382//jocg.v4i1a9", "10.1016/0010-0285(81)90016-5", "10.1145/2556288.2557224", "10.1109/iv.2001.942043", "10.1021/ed1000203", "10.1016/0169-7439(87)80084-9", "10.1109/tvcg.2010.154", "10.1016/j.jvlc.2015.10.003", "10.1109/tvcg.2019.2903945", "10.1109/tvcg.2013.120", "10.1109/tvcg.2019.2934263", "10.1146/annurev-ecolsys-102209-144718", "10.1109/tvcg.2008.165", "10.3138/a477-3202-7876-n514", "10.1080/23729333.2017.1288535", "10.1111/j.0020-2754.1998.00269.x", "10.1109/mcg.2004.41", "10.1109/vast.2009.5332593", "10.1002/smr.414", "10.1007/s12650-019-00584-3", "10.1145/22949.22950", "10.1179/1743277413y.0000000036", "10.1080/15230406.2016.1262280", "10.1016/s0341-8162(01)00164-3", "10.22224/gistbok/2017.3.8", "10.1109/tvcg.2008.155", "10.1057/ivs.2008.31", "10.1016/j.cag.2004.03.012", "10.1179/1743277412y.0000000007", "10.1016/j.soncn.2011.02.001", "10.1179/caj.1987.24.1.27", "10.3138/carto.48.3.1691", "10.5220/0004267205150524", "10.1109/38.974518", "10.1145/102377.115768", "10.1057/palgrave.ivs.9500186", "10.1109/5.58325", "10.5167/80972.uzh-80972", "10.1177/030913339602000204", "10.1007/978-3-642-22300-6\\_14", "10.1109/iv.2004.1320189", "10.1111/cgf.13447", "10.1007/s11192-017-2596-3", "10.1559/1523040053722150", "10.1007/978-3-662-45803-7\\_34"], "wos": 1, "children": [], "len": 1}], "len": 3}, {"doi": "10.1109/tvcg.2020.3030411", "title": "Co-Bridges: Pair-wise Visual Connection and Comparison for Multi-item Data Streams", "year": "2020", "conferenceName": "VAST", "authors": "Siming Chen;Natalia V. Andrienko;Gennady L. Andrienko;Jie Li 0006;Xiaoru Yuan", "citationCount": "0", "affiliation": "Yuan, XR (Corresponding Author), Peking Univ, Beijing, Peoples R China. Chen, Siming, Fudan Univ, Sch Data Sci, Shanghai, Peoples R China. Chen, Siming; Andrienko, Natalia; Andrienko, Gennady, Fraunhofer Inst IAIS, St Augustin, Germany. Andrienko, Natalia; Andrienko, Gennady, City Univ London, London, England. Li, Jie, Tianjin Univ, Tianjin, Peoples R China. Yuan, Xiaoru, Peking Univ, Beijing, Peoples R China.", "countries": "Germany;China;England", "abstract": "In various domains, there are abundant streams or sequences of multi-item data of various kinds, e.g. streams of news and social media texts, sequences of genes and sports events, etc. Comparison is an important and general task in data analysis. For comparing data streams involving multiple items (e.g., words in texts, actors or action types in action sequences, visited places in itineraries, etc.), we propose Co-Bridges, a visual design involving connection and comparison techniques that reveal similarities and differences between two streams. Co-Bridges use river and bridge metaphors, where two sides of a river represent data streams, and bridges connect temporally or sequentially aligned segments of streams. Commonalities and differences between these segments in terms of involvement of various items are shown on the bridges. Interactive query tools support the selection of particular stream subsets for focused exploration. The visualization supports both qualitative (common and distinct items) and quantitative (stream volume, amount of item involvement) comparisons. We further propose Comparison-of-Comparisons, in which two or more Co-Bridges corresponding to different selections are juxtaposed. We test the applicability of the Co-Bridges in different domains, including social media text streams and sports event sequences. We perform an evaluation of the users' capability to understand and use Co-Bridges. The results confirm that Co-Bridges is effective for supporting pair-wise visual comparisons in a wide range of applications.", "keywords": "Visual Comparison,Pair-wise Analysis,Multi-item Data Stream,Social Media", "link": "http://dx.doi.org/10.1109/TVCG.2020.3030411", "refList": ["10.1109/tvcg.2014.2346753", "10.1109/pacificvis.2010.5429590", "10.1109/vast.2009.5333443", "10.1101/gr.2289704", "10.1177/1473871611416549", "10.1057/palgrave.ivs.9500099", "10.1109/vast.2017.8585638", "10.1109/vast.2014.7042496", "10.1109/tvcg.2017.2764459", "10.1109/tvcg.2013.221", "10.1109/vast.2011.6102439", "10.1109/tvcg.2013.213", "10.1109/tmm.2016.2614220", "10.1109/tvcg.2016.2598797", "10.1145/2207676.2208556", "10.1145/1835804.1835827", "10.1109/tvcg.2013.124", "10.2312/conf/eg2013/stars/039-063", "10.1111/cgf.13211", "10.1109/tvcg.2014.2346920", "10.1109/tvcg.2011.239", "10.1016/j.jvlc.2018.08.008", "10.1109/mcg.2018.032421661", "10.1109/tvcg.2017.2744199", "10.1109/tvcg.2019.2934535", "10.1109/tvcg.2018.2864526", "10.1007/978-0-85729-436-4\\_9", "10.1109/vast.2016.7883511", "10.1109/tvcg.2014.2346682", "10.1109/tvcg.2015.2467618", "10.1145/2566486.2567977", "10.1109/tvcg.2017.2745320", "10.1080/136588199241247", "10.1111/cgf.13401", "10.1109/tvcg.2018.2864884", "10.1109/tvcg.2012.291", "10.1109/vast.2012.6400485", "10.1109/pacificvis.2016.7465266", "10.1109/tvcg.2011.232", "10.1109/tvcg.2017.2745083", "10.1109/tvcg.2012.253", "10.1007/s12650-014-0246-x", "10.1109/tvcg.2010.20", "10.1109/tvcg.2014.2346919", "10.1109/visual.2019.8933646", "10.1007/978-0-85729-079-3"], "wos": 1, "children": [], "len": 1}], "len": 7}, {"doi": "10.1111/cgf.13446", "year": "2018", "title": "Quality Metrics for Information Visualization", "conferenceName": "EuroVis", "authors": "Michael Behrisch;Michael Blumenschein;Nam Wook Kim;Lin Shao;Mennatallah El{-}Assady;Johannes Fuchs;Daniel Seebacher;Alexandra Diehl;Ulrik Brandes;Hanspeter Pfister;Tobias Schreck;Daniel Weiskopf;Daniel A. Keim", "citationCount": "25", "affiliation": "Behrisch, M (Corresponding Author), Harvard Univ, Cambridge, MA 02138 USA.\nBehrisch, M.; Kim, N. W.; Pfister, H., Harvard Univ, Cambridge, MA 02138 USA.\nBlumenschein, M.; El-Assady, M.; Fuchs, J.; Seebacher, D.; Diehl, A.; Keim, D. A., Univ Konstanz, Constance, Germany.\nShao, L.; Schreck, T., Graz Univ Technol, Graz, Austria.\nBrandes, U., Swiss Fed Inst Technol, Zurich, Switzerland.\nWeiskopf, D., Univ Stuttgart, Stuttgart, Germany.", "countries": "Switzerland;Germany;USA;Austria", "abstract": "The visualization community has developed to date many intuitions and understandings of how to judge the quality of views in visualizing data. The computation of a visualization's quality and usefulness ranges from measuring clutter and overlap, up to the existence and perception of specific (visual) patterns. This survey attempts to report, categorize and unify the diverse understandings and aims to establish a common vocabulary that will enable a wide audience to understand their differences and subtleties. For this purpose, we present a commonly applicable quality metric formalization that should detail and relate all constituting parts of a quality metric. We organize our corpus of reviewed research papers along the data types established in the information visualization community: multi- and high-dimensional, relational, sequential, geospatial and text data. For each data type, we select the visualization subdomains in which quality metrics are an active research field and report their findings, reason on the underlying concepts, describe goals and outline the constraints and requirements. One central goal of this survey is to provide guidance on future research opportunities for the field and outline how different visualization communities could benefit from each other by applying or transferring knowledge to their respective subdomain. Additionally, we aim to motivate the visualization community to compare computed measures to the perception of humans.", "keywords": "", "link": "https://doi.org/10.1111/cgf.13446", "refList": ["10.2307/276978", "10.1057/ivs.2009.10", "10.1109/tvcg.2015.2467732", "10.1109/tvcg.2014.2346420", "10.1016/j.cag.2018.01.010", "10.1109/tvcg.2017.2743959", "10.1109/tvcg.2011.127", "10.1109/tvcg.2015.2467759", "10.1109/tvcg.2013.187", "10.1109/tvcg.2007.70594", "10.1186/1471-2105-9-155", "10.1145/2702123.2702545", "10.1145/1645953.1646023", "10.1093/bioinformatics/btm312", "10.1109/pacificvis.2016.7465245", "10.1145/3038462.3038463", "10.1007/978-3-540-70956-5", "10.1109/tvcg.2017.2743939", "10.1111/cgf.12932", "10.1111/j.1467-8659.2012.03106.x", "10.1145/1133265.1133318", "10.1109/tvcg.2010.186", "10.1109/iv.2013.101", "10.1109/tvcg.2016.2598590", "10.2312/conf/eg2013/stars/039-063", "10.3758/bf03201236", "10.1111/cgf.12935", "10.1145/1056808.1056914", "10.1007/bf01898350", "10.2307/1390686", "10.1109/2945.981848", "10.1109/hicss.2008.422", "10.1109/tvcg.2011.201", "10.1109/pacificvis.2011.5742390", "10.2307/2288400", "10.1111/cgf.12872", "10.1109/tvcg.2017.2674999", "10.1109/tvcg.2006.163", "10.1109/tvcg.2013.150", "10.1109/tvcg.2009.171", "10.1109/tvcg.2017.2723397", "10.1117/12.2079841", "10.1109/pacificvis.2009.4906838", "10.1109/infvis.2004.1", "10.1109/tvcg.2008.166", "10.1287/opre.20.5.993", "10.7155/jgaa.00370", "10.1111/j.1467-8659.2008.01240.x", "10.1109/inf0vis.2005.14", "10.1109/tvcg.2009.23", "10.1109/infvis.1998.729559", "10.1177/0165551506078083", "10.1109/t-c.1974.224051", "10.1109/tvcg.2017.2744339", "10.1109/tvcg.2014.2346433", "10.1145/989863.989940", "10.1109/tvcg.2015.2509990", "10.2307/2288843", "10.1016/j.neucom.2017.01.105", "10.1073/pnas.43.10.923", "10.1111/cgf.12647", "10.1016/j.rse.2017.06.031", "10.1109/infvis.2005.1532145", "10.1109/2945.841121", "10.1109/tvcg.2011.229", "10.2312/eurova.20141140", "10.1111/j.2044-8317.1974.tb00534.x", "10.1109/pacificvis.2015.7156366", "10.1109/vast.2009.5332628", "10.1109/vast.2014.7042480", "10.1145/2993901.2993907", "10.1177/0951692899011001004", "10.1007/978-3-642-03655-2\\_43", "10.1198/106186008x320465", "10.1109/visual.1997.663916", "10.1111/cgf.12125", "10.1109/infvis.2003.1249009", "10.1109/icdm.2003.1250978", "10.1109/tvcg.2017.2745919", "10.1109/tvcg.2012.128", "10.1109/vast.2010.5652450", "10.1109/tvcg.2006.161", "10.1145/571647.571649", "10.1109/tvcg.2011.193", "10.1111/cgf.12633", "10.1109/tvcg.2017.2674978", "10.1109/vast.2010.5652433", "10.1109/tvcg.2017.2745978", "10.1515/itit-2014-1070", "10.1145/1374489.1374501", "10.1109/tvcg.2009.153", "10.2312/eurovisshort.20171128", "10.2312/eurovisshort.20151130", "10.1016/0925-7721(94)00014-x", "10.1057/palgrave.ivs.95000/3", "10.1145/302979.303030", "10.1002/widm.1071", "10.1109/pacificvis.2014.42", "10.1109/tvcg.2016.2598467", "10.1111/j.1467-8659.2009.01667.x", "10.2307/2287708", "10.1177/1473871613477091", "10.1145/967900.968153", "10.1109/tvcg.2010.162", "10.1145/568522.568523", "10.1016/j.cag.2004.03.022", "10.1109/tvcg.2015.2466992", "10.1145/2993901.2993903", "10.1147/jrd.2015.2411412", "10.1177/154193120504900508", "10.1109/tvcg.2006.138", "10.1111/cgf.13168", "10.1111/cgf.12380", "10.2312/conf/eg2013/stars/095-116", "10.1109/tvcg.2017.2745859", "10.1109/tvcg.2017.2701829", "10.1109/tvcg.2007.70529", "10.1007/bf01199431", "10.1117/12.697548", "10.1109/tvcg.2017.2653106", "10.1207/s15327906mbr2701\\_4", "10.1109/vl.1996.545307", "10.1109/tvcg.2017.2745140", "10.1111/j.1467-8659.2012.03069.x", "10.1111/j.1467-8659.2011.01961.x", "10.1109/pacificvis.2016.7465244", "10.1109/tvcg.2013.124", "10.1057/ivs.2008.13", "10.2312/vissym/eurovis06/195-202", "10.2312/vissym/eurovis07/163-170", "10.1109/tvcg.2015.2467324", "10.1109/tvcg.2011.167", "10.1109/pacificvis.2014.40", "10.1109/pacificvis.2012.6183570", "10.1111/j.1467-8659.2012.03125.x", "10.1075/idj.20.1.02bei", "10.1111/1467-8306.00061", "10.1145/2858036.2858155", "10.1109/tvcg.2012.108", "10.2312/vmv.20171261", "10.1109/tvcg.2015.2467531", "10.1145/1379092.1379130", "10.1109/tpami.1979.4766909", "10.1080/13875860903039172", "10.1109/mcg.2006.70", "10.1109/tvcg.2010.242", "10.1109/vast.2007.4389004", "10.1109/tvcg.2015.2467191", "10.2312/cgvc.20171276", "10.1016/0169-7439(87)80084-9", "10.2312/pe/eurovisshort/eurovisshort2012/097-101", "10.1016/j.neucom.2014.07.073", "10.2307/2685263", "10.1145/996546.996554", "10.1111/j.1467-8659.2009.01666.x", "10.1117/12.2083444", "10.1109/tvcg.2014.2346572", "10.1007/978-0-387-39940-9\\_262", "10.1007/bf00988593", "10.1145/1054972.1055078", "10.1111/j.1467-8659.2009.01467.x", "10.1111/cgf.13181", "10.1145/502512.502530", "10.1109/pacificvis.2010.5429600", "10.1111/j.1467-8659.2011.01923.x", "10.1109/mcg.2004.41", "10.1109/tvcg.2015.2467971", "10.1111/j.1467-8659.2011.01919.x", "10.1002/sam.10071", "10.1109/tvcg.2010.184", "10.1007/978-3-642-27848-8\\_648-1", "10.1109/tvcg.2010.132", "10.1145/22949.22950", "10.1145/1842993.1843002", "10.1109/infvis.2000.885096", "10.1016/j.ins.2015.04.017", "10.1109/iv.2009.43", "10.1016/j.visinf.2017.11.001", "10.1109/tvcg.2011.239", "10.1109/infovis.2005.40", "10.1111/cgf.12641", "10.1109/pacificvis.2016.7465262", "10.1145/2470654.2466443", "10.1007/s10844-011-0157-4", "10.1111/cgf.12919", "10.1016/j.jvlc.2016.07.003", "10.1109/tvcg.2016.2549018", "10.1057/palgrave.ivs.9500166", "10.3406/colan.1981.1409.1", "10.1093/bioinformatics/bti141", "10.1111/j.1467-8306.2004.09401004.x", "10.1145/1168149.1168168", "10.1109/tvcg.2017.2744184", "10.1117/12.2079420", "10.1109/iv.2005.62", "10.1145/102377.115768", "10.1109/tvcg.2014.2346677", "10.1109/tvcg.2014.2346426", "10.1111/j.1467-8659.2012.03107.x", "10.5220/0006097400400051", "10.2991/978-94-6239-186-4", "10.2307/2284077", "10.1109/iv.2008.89", "10.1016/j.jvlc.2015.12.001", "10.1109/pacificvis.2013.6596147", "10.1145/1242572.1242826", "10.1016/j.cag.2007.01.030", "10.1111/cgf.12632", "10.2312/eurovisstar.20151113", "10.1559/152304009788188808"], "wos": 1, "children": [{"doi": "10.1109/vast.2018.8802486", "title": "SMARTexplore: Simplifying High-Dimensional Data Analysis through a Table-Based Visual Analytics Approach", "year": "2018", "conferenceName": "VAST", "authors": "Michael Blumenschein;Michael Behrisch;Stefanie Schmid;Simon Butscher;Deborah Wahl;Karoline Villinger;Britta Renner;Harald Reiterer;Daniel A. Keim", "citationCount": "0", "affiliation": "Blumenschein, M (Corresponding Author), Univ Konstanz, Constance, Germany. Blumenschein, Michael; Schmid, Stefanie; Butscher, Simon; Wahl, Deborah R.; Villinger, Karoline; Renner, Britta; Reiterer, Harald; Keim, Daniel A., Univ Konstanz, Constance, Germany. Behrisch, Michael, Harvard Univ, Cambridge, MA 02138 USA.", "countries": "Germany;USA", "abstract": "We present SMARTEXPLORE, a novel visual analytics technique that simplifies the identification and understanding of clusters, correlations, and complex patterns in high-dimensional data. The analysis is integrated into an interactive table-based visualization that maintains a consistent and familiar representation throughout the analysis. The visualization is tightly coupled with pattern matching, subspace analysis, reordering, and layout algorithms. To increase the analyst's trust in the revealed patterns, SMARTEXPLORE automatically selects and computes statistical measures based on dimension and data properties. While existing approaches to analyzing high-dimensional data (e.g., planar projections and Parallel coordinates) have proven effective, they typically have steep learning curves for non-visualization experts. Our evaluation, based on three expert case studies, confirms that non-visualization experts successfully reveal patterns in high-dimensional data when using SMARTEXPLORE.", "keywords": "High-dimensional data,visual exploration,pattern-driven analysis,tabular visualization,subspace,aggregation", "link": "http://dx.doi.org/10.1109/VAST.2018.8802486", "refList": ["10.1177/1473871612460526", "10.1109/tvcg.2015.2489649", "10.1111/j.1467-8659.2008.01241.x", "10.1007/978-3-319-25087-8\\_29", "10.1007/b98835", "10.13140/rg.2.2.16570.90567", "10.1109/tvcg.2014.2346260", "10.1109/vast.2009.5332628", "10.2307/2528823", "10.1109/tvcg.2010.184", "10.1145/1133265.1133318", "10.1057/palgrave.ivs.9500072", "10.1111/j.1467-8659.2012.03110.x", "10.1145/1007730.1007731", "10.1057/palgrave.ivs.9500086", "10.1111/cgf.12935", "10.1109/tvcg.2014.2346279", "10.1007/bf01898350", "10.1109/tvcg.2013.173", "10.1109/tvcg.2017.2672987", "10.1109/tvcg.2014.2346248", "10.1109/infvis.2004.46", "10.1109/vast.2010.5652433", "10.1109/vast.2009.5332611", "10.1109/tvcg.2015.2467553", "10.1109/tvcg.2015.2468078", "10.1109/tvcg.2017.2744098", "10.1109/tvcg.2013.150", "10.1109/tvcg.2016.2640960", "10.1111/cgf.12630", "10.1007/978-1-4757-1904-8", "10.1109/tvcg.2011.188", "10.1109/tvcg.2010.138", "10.1109/tvcg.2017.2745078", "10.1109/tvcg.2017.2743978", "10.1111/cgf.12879", "10.1109/iv.2008.33", "10.1111/cgf.13446", "10.1007/s00371-018-1483-0", "10.1109/infvis.1998.729559", "10.1145/2669557.2669572", "10.1111/j.1467-8659.2008.01239.x"], "wos": 1, "children": [], "len": 1}, {"doi": "10.1109/tvcg.2019.2934541", "title": "A Recursive Subdivision Technique for Sampling Multi-class Scatterplots", "year": "2019", "conferenceName": "InfoVis", "authors": "Xin Chen;Tong Ge;Jian Zhang 0070;Baoquan Chen;Chi-Wing Fu;Oliver Deussen;Yunhai Wang", "citationCount": "5", "affiliation": "Chen, X (Corresponding Author), Shandong Univ, Jinan, Shandong, Peoples R China. Chen, Xin; Ge, Tong; Wang, Yunhai, Shandong Univ, Jinan, Shandong, Peoples R China. Chen, Baoquan, Peking Univ, Beijing, Peoples R China. Fu, Chi-Wing, Chinese Univ Hong Kong, Hong Kong, Peoples R China. Fu, Chi-Wing, SIAT, Guangdong Prov Key Lab CV \\& VR Tech, Shenzhen, Guangdong, Peoples R China. Zhang, Jian, Chinese Acad Sci, CNIC, Beijing, Peoples R China. Deussen, Oliver, Konstanz Univ, Constance, Germany. Deussen, Oliver, SIAT, Shenzhen VIsuCA Key Lab, Shenzhen, Guangdong, Peoples R China.", "countries": "Germany;China", "abstract": "We present a non-uniform recursive sampling technique for multi-class scatterplots, with the specific goal of faithfully presenting relative data and class densities, while preserving major outliers in the plots. Our technique is based on a customized binary kd-tree, in which leaf nodes are created by recursively subdividing the underlying multi-class density map. By backtracking, we merge leaf nodes until they encompass points of all classes for our subsequently applied outlier-aware multi-class sampling strategy. A quantitative evaluation shows that our approach can better preserve outliers and at the same time relative densities in multi-class scatterplots compared to the previous approaches, several case studies demonstrate the effectiveness of our approach in exploring complex and real world data.", "keywords": "Scatterplot,multi-class sampling,kd-tree,outlier,relative density", "link": "http://dx.doi.org/10.1109/TVCG.2019.2934541", "refList": ["10.1057/palgrave.ivs.9500122", "10.1109/tvcg.2006.170", "10.1109/tvcg.2008.119", "10.1109/tvcg.2007.70580", "10.2307/2289444", "10.1145/1964921.1964943", "10.1109/tvcg.2013.65", "10.1109/tvcg.2011.229", "10.1109/iv.2004.1320207", "10.1109/itoec.2018.8740621", "10.1145/1778765.1778816", "10.1109/tvcg.2010.197", "10.1201/b17511", "10.1109/tvcg.2018.2864912", "10.1007/0-387-28695-0", "10.1109/5.726791", "10.1109/visual.1998.745301", "10.1016/j.physa.2011.12.004", "10.1145/1556262.1556289", "10.1109/tvcg.2007.70535", "10.1109/tvcg.2017.2674978", "10.1109/tvcg.2004.1272729", "10.1145/335191.335388", "10.1109/tvcg.2014.2346594", "10.1109/tvcg.2017.2744184", "10.1109/iv.2002.1028760", "10.1145/1842993.1842999", "10.1109/tvcg.2018.2869149", "10.1038/nmeth.2490", "10.1109/tvcg.2013.153", "10.1111/cgf.13446", "10.1109/tvcg.2010.176", "10.1145/2702123.2702585", "10.1057/ivs.2009.34"], "wos": 1, "children": [{"doi": "10.1109/tvcg.2020.3030443", "title": "CAVA: A Visual Analytics System for Exploratory Columnar Data Augmentation Using Knowledge Graphs", "year": "2020", "conferenceName": "VAST", "authors": "Dylan Cashman;Shenyu Xu;Subhajit Das;Florian Heimerl;Cong Liu;Shah Rukh Humayoun;Michael Gleicher;Alex Endert;Remco Chang", "citationCount": "0", "affiliation": "Cashman, D (Corresponding Author), Tufts Univ, Medford, MA 02155 USA. Cashman, Dylan; Liu, Cong; Chang, Remco, Tufts Univ, Medford, MA 02155 USA. Xu, Shenyu; Das, Subhajit; Endert, Alex, Georgia Tech, Atlanta, GA USA. Heimerl, Florian; Gleicher, Michael, Univ Wisconsin, Madison, WI 53706 USA. Humayoun, Shah Rukh, San Francisco State Univ, San Francisco, CA 94132 USA.", "countries": "USA", "abstract": "Most visual analytics systems assume that all foraging for data happens before the analytics process; once analysis begins, the set of data attributes considered is fixed. Such separation of data construction from analysis precludes iteration that can enable foraging informed by the needs that arise in-situ during the analysis. The separation of the foraging loop from the data analysis tasks can limit the pace and scope of analysis. In this paper, we present CAVA, a system that integrates data curation and data augmentation with the traditional data exploration and analysis tasks, enabling information foraging in-situ during analysis. Identifying attributes to add to the dataset is difficult because it requires human knowledge to determine which available attributes will be helpful for the ensuing analytical tasks. CAVA crawls knowledge graphs to provide users with a a broad set of attributes drawn from external data to choose from. Users can then specify complex operations on knowledge graphs to construct additional attributes. CAVA shows how visual analytics can help users forage for attributes by letting users visually explore the set of available data, and by serving as an interface for query construction. It also provides visualizations of the knowledge graph itself to help users understand complex joins such as multi-hop aggregations. We assess the ability of our system to enable users to perform complex data combinations without programming in a user study over two datasets. We then demonstrate the generalizability of CAVA through two additional usage scenarios. The results of the evaluation confirm that CAVA is effective in helping the user perform data foraging that leads to improved analysis outcomes, and offer evidence in support of integrating data augmentation as a part of the visual analytics pipeline.", "keywords": "Visual Analytics,Information Foraging,Data Augmentation", "link": "http://dx.doi.org/10.1109/TVCG.2020.3030443", "refList": ["10.1057/palgrave.ivs.9500122", "10.1109/tvcg.2016.2598867", "10.1111/cgf.13708", "10.1109/tvcg.2019.2934799", "10.1109/tvcg.2019.2934541", "10.1109/tvcg.2013.65", "10.1109/tvcg.2018.2875702", "10.1109/iv.2004.1320207", "10.1068/p260471", "10.1145/1778765.1778816", "10.1109/tvcg.2018.2808489", "10.1109/tvcg.2018.2864912", "10.1016/j.apgeog.2015.12.006", "10.1111/j.1467-8659.2011.01960.x", "10.1109/tvcg.2018.2864843", "10.1109/pacificvis.2010.5429604", "10.1109/tvcg.2014.2346898", "10.1109/5.726791", "10.1177/1475090214540874", "10.1109/icde.2016.7498287", "10.1145/1556262.1556289", "10.1109/tvcg.2007.70535", "10.1109/vast.2012.6400489", "10.1145/1056808.1056914", "10.1016/j.neucom.2014.09.063", "10.1145/7529.8927", "10.1109/tvcg.2016.2598495", "10.1109/tvcg.2016.2607204", "10.1109/vast47406.2019.8986943", "10.3758/bf03205986", "10.1109/infvis.2005.1532142", "10.1145/1150402.1150479", "10.1109/tvcg.2017.2674978", "10.1109/tvcg.2019.2945960", "10.1109/tvcg.2017.2744098", "10.1109/tvcg.2017.2674999", "10.1109/tvcg.2011.279", "10.1109/tvcg.2014.2346594", "10.1109/tvcg.2017.2744184", "10.1111/cgf.12876", "10.1007/s4095-020-0191-7", "10.1007/s11390-015-1535-0", "10.1111/cgf.12640", "10.1109/tvcg.2016.2598667", "10.1111/cgf.13683", "10.1109/tvcg.2013.153", "10.1109/tvcg.2019.2934208", "10.1109/tvcg.2019.2934655", "10.1111/cgf.12655", "10.1007/s11023-010-9221-z", "10.1109/vast.2012.6400487", "10.1145/2702123.2702585", "10.1007/bf00310175", "10.1109/tvcg.2017.2744378", "10.1103/physreve.64.061907", "10.1109/ldav.2017.8231848", "10.1109/tvcg.2016.2598831"], "wos": 1, "children": [], "len": 1}, {"doi": "10.1109/tvcg.2020.3030432", "title": "Evaluation of Sampling Methods for Scatterplots", "year": "2020", "conferenceName": "VAST", "authors": "Jun Yuan;Shouxing Xiang;Jiazhi Xia;Lingyun Yu;Shixia Liu", "citationCount": "0", "affiliation": "Liu, SX (Corresponding Author), Tsinghua Univ, BNRist, Beijing, Peoples R China. Yuan, Jun; Xiang, Shouxing; Liu, Shixia, Tsinghua Univ, BNRist, Beijing, Peoples R China. Xia, Jiazhi, Cent South Univ, Changsha, Peoples R China. Yu, Lingyun, Xian Jiaotong Liverpool Univ, Suzhou, Peoples R China.", "countries": "China", "abstract": "Given a scatterplot with tens of thousands of points or even more, a natural question is which sampling method should be used to create a small but \u201cgood\u201d scatterplot for a better abstraction. We present the results of a user study that investigates the influence of different sampling strategies on multi-class scatterplots. The main goal of this study is to understand the capability of sampling methods in preserving the density, outliers, and overall shape of a scatterplot. To this end, we comprehensively review the literature and select seven typical sampling strategies as well as eight representative datasets. We then design four experiments to understand the performance of different strategies in maintaining: 1) region density; 2) class density; 3) outliers; and 4) overall shape in the sampling results. The results show that: 1) random sampling is preferred for preserving region density; 2) blue noise sampling and random sampling have comparable performance with the three multi-class sampling strategies in preserving class density; 3) outlier biased density based sampling, recursive subdivision based sampling, and blue noise sampling perform the best in keeping outliers; and 4) blue noise sampling outperforms the others in maintaining the overall shape of a scatterplot.", "keywords": "Scatterplot,data sampling,empirical evaluation", "link": "http://dx.doi.org/10.1109/TVCG.2020.3030432", "refList": ["10.1057/palgrave.ivs.9500122", "10.1109/tvcg.2016.2598867", "10.1109/tvcg.2015.2467591", "10.1111/cgf.13708", "10.1109/tvcg.2019.2934799", "10.1109/tvcg.2019.2934541", "10.1109/tvcg.2013.65", "10.1109/iv.2004.1320207", "10.1068/p260471", "10.1145/1778765.1778816", "10.1109/tvcg.2018.2808489", "10.1109/tvcg.2018.2864912", "10.1016/j.apgeog.2015.12.006", "10.1111/j.1467-8659.2011.01960.x", "10.1109/tvcg.2018.2864843", "10.1109/pacificvis.2010.5429604", "10.1109/tvcg.2014.2346898", "10.1109/5.726791", "10.1177/1475090214540874", "10.1145/1556262.1556289", "10.1109/tvcg.2007.70535", "10.1109/vast.2012.6400489", "10.1145/1056808.1056914", "10.1016/j.neucom.2014.09.063", "10.1145/7529.8927", "10.1109/tvcg.2016.2607204", "10.1109/vast47406.2019.8986943", "10.3758/bf03205986", "10.1109/infvis.2005.1532142", "10.1145/1150402.1150479", "10.1109/tvcg.2017.2674978", "10.1109/tvcg.2017.2744098", "10.1109/tvcg.2017.2674999", "10.1109/tvcg.2011.279", "10.1109/tvcg.2014.2346594", "10.1109/tvcg.2017.2744184", "10.1111/cgf.12876", "10.1109/1011101.2019.2945960", "10.1007/s4095-020-0191-7", "10.1007/s11390-015-1535-0", "10.1111/cgf.12640", "10.1109/tvcg.2016.2598667", "10.1111/cgf.13683", "10.1109/tvcg.2013.153", "10.1109/tvcg.2019.2934208", "10.1109/tvcg.2019.2934655", "10.1111/cgf.12655", "10.1007/s11023-010-9221-z", "10.1109/vast.2012.6400487", "10.1145/2702123.2702585", "10.1007/bf00310175", "10.1109/tvcg.2017.2744378", "10.1103/physreve.64.061907", "10.1109/ldav.2017.8231848", "10.1109/tvcg.2016.2598831"], "wos": 1, "children": [], "len": 1}, {"doi": "10.1109/tvcg.2020.3030365", "title": "Modeling the Influence of Visual Density on Cluster Perception in Scatterplots Using Topology", "year": "2020", "conferenceName": "InfoVis", "authors": "Ghulam Jilani Quadri;Paul Rosen", "citationCount": "0", "affiliation": "Quadri, GJ (Corresponding Author), Univ S Florida, Tampa, FL 33620 USA. Quadri, Ghulam Jilani; Rosen, Paul, Univ S Florida, Tampa, FL 33620 USA.", "countries": "USA", "abstract": "Scatterplots are used for a variety of visual analytics tasks, including cluster identification, and the visual encodings used on a scatterplot play a deciding role on the level of visual separation of clusters. For visualization designers, optimizing the visual encodings is crucial to maximizing the clarity of data. This requires accurately modeling human perception of cluster separation, which remains challenging. We present a multi-stage user study focusing on four factors-distribution size of clusters, number of points, size of points, and opacity of points-that influence cluster identification in scatterplots. From these parameters, we have constructed two models, a distance-based model, and a density-based model, using the merge tree data structure from Topological Data Analysis. Our analysis demonstrates that these factors play an important role in the number of clusters perceived, and it verifies that the distance-based and density-based models can reasonably estimate the number of clusters a user observes. Finally, we demonstrate how these models can be used to optimize visual encodings on real-world data.", "keywords": "Scatterplot,clustering,perception,empirical evaluation,visual encoding,crowdsourcing,topological data analysis", "link": "http://dx.doi.org/10.1109/TVCG.2020.3030365", "refList": ["10.1109/tvcg.2017.2744359", "10.1145/1778765", "10.1109/tvcg.2019.2934799", "10.1111/cgf.12889", "10.1109/tvcg.2011.127", "10.1111/cgf.13444", "10.1145/1964897.1964910", "10.1167/8.7.6", "10.1145/3173574.3173991", "10.1145/1556262.1556289", "10.1145/1056808.1056914", "10.2307/2288400", "10.1109/tvcg.2014.2346594", "10.1109/iv.2002.1028760", "10.1177/001316447303300111", "10.1007/bf02289823", "10.1109/tvcg.2017.2744339", "10.1111/j.1467-8659.2009.01694.x", "10.1109/tvcg.2014.2346979", "10.1090/mbk/069", "10.1109/tvcg.2013.65", "10.1109/mcg.2012.37", "10.1109/pacificvis.2010.5429604", "10.1002/acp.2350050106", "10.1109/infvis.2005.1532136", "10.1177/1473871612465214", "10.1109/tvcg.2017.2674978", "10.1002/jhbs.20078", "10.1007/978-3-642-35142-6\\_14", "10.1007/978-3-319-71507-0", "10.1109/mcg.201.7.6", "10.3758/bf03193961", "10.1364/josa.49.000280", "10.1145/3025453.3025905", "10.1109/tvcg.201.9.2934541", "10.1109/tvcg.2018.2829750", "10.1177/1473871615606187", "10.1111/cgf.13408", "10.1109/pacificvis.2016.7465252", "10.1109/pacificvis.2016.7465244", "10.1109/inevis.2005.1532142", "10.1111/cgf.13414", "10.1111/j.1467-8659.2012.03125.x", "10.1167/16.5.11", "10.1109/infvis.2005.1532142", "10.1145/2858036.2858155", "10.1038/nmeth1210-941", "10.1177/1473871616638892", "10.1109/tcbb.2014.2306840", "10.1111/cgf.13684", "10.1177/0301006615602599", "10.1214/aoms/1177731915", "10.1145/2702123.2702585", "10.1109/tvcg.2013.183", "10.1109/tvcg.2014.2346572", "10.1109/tvcg.2018.2875702", "10.1109/tvcg.2017.2754480", "10.1109/vast.2014.7042493", "10.1057/palgrave.ivs.9500122", "10.1109/tvcg.2014.2330617", "10.1109/tvcg.2019.2934541", "10.1068/p030033", "10.1140/epjds/s13688-017-0109-5", "10.1201/b17511", "10.1016/s0925-7721(02)00093-7", "10.1109/pacificvis.2012.6183557", "10.1109/tvcg.2014.2346983", "10.1109/5.726791", "10.1080/01621459.1926.10502165", "10.1109/tvcg.2007.70535", "10.1109/tvcg.2018.2864907", "10.1111/cgf.12109", "10.1109/tvcg.2017.2744184", "10.1146/annurev-statistics-031017-100045", "10.1111/cgf.13409", "10.1145/3002151.3002162", "10.1016/s0378-4371(98)00494-4", "10.3138/y308-2422-8615-1233", "10.1111/cgf.12632", "10.1145/3290605.3300771"], "wos": 1, "children": [], "len": 1}, {"doi": "10.1111/cgf.14001", "year": "2020", "title": "Sunspot Plots: Model-based Structure Enhancement for Dense Scatter Plots", "conferenceName": "EuroVis", "authors": "Thomas Trautner;Fabian Bolte;Sergej Stoppel;Stefan Bruckner", "citationCount": "0", "affiliation": "Trautner, T (Corresponding Author), Univ Bergen, Bergen, Norway.\nTrautner, T.; Bolte, F.; Stoppel, S.; Bruckner, S., Univ Bergen, Bergen, Norway.", "countries": "Norway", "abstract": "Scatter plots are a powerful and well-established technique for visualizing the relationships between two variables as a collection of discrete points. However, especially when dealing with large and dense data, scatter plots often exhibit problems such as overplotting, making the data interpretation arduous. Density plots are able to overcome these limitations in highly populated regions, but fail to provide accurate information of individual data points. This is particularly problematic in sparse regions where the density estimate may not provide a good representation of the underlying data. In this paper, we present sunspot plots, a visualization technique that communicates dense data as a continuous data distribution, while preserving the discrete nature of data samples in sparsely populated areas. We furthermore demonstrate the advantages of our approach on typical failure cases of scatter plots within synthetic and real-world data sets and validate its effectiveness in a user study.", "keywords": "", "link": "https://doi.org/10.1111/cgf.14001", "refList": ["10.1057/palgrave.ivs.9500122", "10.2312/eggh/hpg12/097-103", "10.1109/tvcg.2008.119", "10.1109/pacificvis.2011.5742387", "10.1038/331163a0", "10.1109/visual.2019.8933620", "10.2307/2683294", "10.1201/9781351072304", "10.2307/2289444", "10.1109/tvcg.2019.2934541", "10.1080/00949657508810123", "10.1109/tvcg.2013.65", "10.1109/infvis.1997.636789", "10.1109/2945.841121", "10.1109/mcse.2007.55", "10.1109/tvcg.2010.197", "10.1111/cgf.12871", "10.1109/infvis.2003.1249018", "10.1145/3173574.3173991", "10.1109/tvcg.2012.238", "10.1007/0-387-28695-0", "10.1109/pacificvis.2010.5429604", "10.18637/jss.v008.i03", "10.1109/tvcg.2007.70596", "10.1109/visual.1998.745301", "10.1007/0-387-37977-0\\_3", "10.1145/1556262.1556289", "10.2312/wiced.20161094", "10.1109/tvcg.2007.70535", "10.1145/1056808.1056914", "10.1109/tvcg.2003.1196007", "10.1109/iv.2004.1320190", "10.1111/cgf.12877", "10.1162/leon.2007.40.2.202a", "10.1109/tvcg.2017.2674978", "10.1057/ivs.2010.4", "10.1016/j.cag.2018.02.008", "10.1201/9781315140919", "10.1109/visual.2000.885677", "10.1002/jhbs.20078", "10.1109/tvcg.2014.2346594", "10.1109/tvcg.2017.2744184", "10.1109/visual.2001.964495", "10.1109/iv.2002.1028760", "10.1111/cgf.13684", "10.1109/hicss.2013.197", "10.1109/tvcg.2019.2903956", "10.1093/mnras/stt961", "10.1109/tvcg.2017.2668409", "10.1111/j.1467-8659.2009.01478.x", "10.1145/2702123.2702585", "10.2307/1418003", "10.2307/1390742", "10.1145/360825.360839", "10.1109/pacificvis.2009.4906843", "10.1057/ivs.2009.34", "10.2307/2288711"], "wos": 1, "children": [], "len": 1}], "len": 9}, {"doi": "10.1109/tvcg.2019.2934284", "title": "Color Crafting: Automating the Construction of Designer Quality Color Ramps", "year": "2019", "conferenceName": "InfoVis", "authors": "Stephen Smart;Keke Wu;Danielle Albers Szafir", "citationCount": "3", "affiliation": "Smart, S (Corresponding Author), Univ Colorado, Boulder, CO 80309 USA. Smart, Stephen; Wu, Keke; Szafir, Danielle Albers, Univ Colorado, Boulder, CO 80309 USA.", "countries": "USA", "abstract": "Visualizations often encode numeric data using sequential and diverging color ramps. Effective ramps use colors that are sufficiently discriminable, align well with the data, and are aesthetically pleasing. Designers rely on years of experience to create high-quality color ramps. However, it is challenging for novice visualization developers that lack this experience to craft effective ramps as most guidelines for constructing ramps are loosely defined qualitative heuristics that are often difficult to apply. Our goal is to enable visualization developers to readily create effective color encodings using a single seed color. We do this using an algorithmic approach that models designer practices by analyzing patterns in the structure of designer-crafted color ramps. We construct these models from a corpus of 222 expert-designed color ramps, and use the results to automatically generate ramps that mimic designer practices. We evaluate our approach through an empirical study comparing the outputs of our approach with designer-crafted color ramps. Our models produce ramps that support accurate and aesthetically pleasing visualizations at least as well as designer ramps and that outperform conventional mathematical approaches.", "keywords": "Visualization,Aesthetics in Visualization,Color Perception,Visual Design,Design Mining", "link": "http://dx.doi.org/10.1109/TVCG.2019.2934284", "refList": ["10.1145/3009924", "10.1109/tvcg.2015.2489649", "10.1109/tvcg.2017.2744359", "10.1002/(sici)1098-1098(199622)7:2", "10.1016/s0734-189x(83)80046-2", "10.1109/tvcg.2016.2599106", "10.1364/josaa.29.000313", "10.1109/tvcg.2016.2598918", "10.2307/2683294", "10.1109/tvcg.2017.2653106", "10.1016/j.ijhcs.2010.05.006", "10.1016/0146-664x(81)90006-x", "10.1007/978-3-642-10520-3\\_9", "10.1109/38.135886", "10.1146/annurev-psych-120710-100504", "10.1016/j.csda.2008.11.033", "10.1145/2461912.2461988", "10.1016/j.cub.2007.06.022", "10.1016/s0146-664x(79)80040-4", "10.1109/mcg.2004.1297012", "10.1109/iv.2009.94", "10.1109/tpami.2010.184", "10.3758/s13414-010-0027-0", "10.1145/22949.22950", "10.1109/visual.1995.480803", "10.1109/tvcg.2014.2346277", "10.2307/2684111", "10.1109/tvcg.2018.2865240", "10.1111/cgf.12633", "10.1109/38.7760", "10.1016/j.jspi.2015.04.007", "10.1109/iv.2008.24", "10.1145/2939502.2939506", "10.1111/cgf.12127", "10.1016/j.cag.2010.11.015", "10.1145/3025453.3026041", "10.1109/tvcg.2012.315", "10.2307/2288400", "10.1511/2005.5.436", "10.1016/s0097-8493(96)00072-6", "10.1109/mcg.2018.011461525", "10.1145/2470654.2466420", "10.1109/tvcg.2012.279", "10.1109/tvcg.2014.2346978", "10.1109/tvcg.2017.2743978", "10.1145/3406601.3406602", "10.1117/12.2084548", "10.1109/tvcg.2018.2865147", "10.1109/tvcg.2015.2467191", "10.1111/cgf.13446", "10.1109/tvcg.2017.2744320", "10.1111/j.1467-8659.2008.01203.x", "10.1145/2702613.2702975", "10.1007/978-3-319-26633-6\\_13", "10.1145/2207676.2208547", "10.1109/tvcg.2008.174", "10.1179/000870403235002042"], "wos": 1, "children": [{"doi": "10.1109/tvcg.2020.3028891", "title": "A Structured Review of Data Management Technology for Interactive Visualization and Analysis", "year": "2020", "conferenceName": "InfoVis", "authors": "Leilani Battle;Carlos Scheidegger", "citationCount": "0", "affiliation": "Battle, L (Corresponding Author), Univ Maryland, Dept Comp Sci, College Pk, MD 20742 USA. Battle, Leilani, Univ Maryland, Dept Comp Sci, College Pk, MD 20742 USA. Scheidegger, Carlos, Univ Arizona, Dept Comp Sci, HDC Lab, Tucson, AZ 85721 USA.", "countries": "USA", "abstract": "In the last two decades, interactive visualization and analysis have become a central tool in data-driven decision making. Concurrently to the contributions in data visualization, research in data management has produced technology that directly benefits interactive analysis. Here, we contribute a systematic review of 30 years of work in this adjacent field, and highlight techniques and principles we believe to be underappreciated in visualization work. We structure our review along two axes. First, we use task taxonomies from the visualization literature to structure the space of interactions in usual systems. Second, we created a categorization of data management work that strikes a balance between specificity and generality. Concretely, we contribute a characterization of 131 research papers along these two axes. We find that five notions in data management venues fit interactive visualization systems well: materialized views, approximate query processing, user modeling and query prediction, muiti-query optimization, lineage techniques, and indexing techniques. In addition, we find a preponderance of work in materialized views and approximate query processing, most targeting a limited subset of the interaction tasks in the taxonomy we used. This suggests natural avenues of future research both in visualization and data management. Our categorization both changes how we visualization researchers design and build our systems, and highlights where future work is necessary.", "keywords": "", "link": "http://dx.doi.org/10.1109/TVCG.2020.3028891", "refList": ["10.1109/tvcg.2012.233", "10.1016/s0022-5371(74)80015-0", "10.1109/tvcg.2017.2744359", "10.1037/0096-3445.136.4.623", "10.1109/tvcg.2015.2467732", "10.1109/tvcg.2012.196", "10.1037/a0029856", "10.1109/tvcg.2014.2346979", "10.1037/h0030300", "10.1109/tvcg.2016.2598918", "10.1109/beliv.2018.8634420", "10.1109/tvcg.2018.2864909", "10.1111/cgf.13079", "10.3389/fpsyg.2012.00355", "10.1145/2858036.2858465", "10.1080/01621459.1989.10478821", "10.1037/0278-7393.24.3.732", "10.1109/tvcg.2011.127", "10.1145/2858036.2858063", "10.4249/scholarpedia.3325", "10.4324/9781410611949", "10.1111/cgf.13444", "10.1145/2993901.2993909", "10.1037/0033-295x.96.2.267", "10.1006/ijhc.1017", "10.1086/405615", "10.1109/tvcg.2019.2934801", "10.1038/17953", "10.1037/xhp0000314", "10.1109/tvcg.2019.2934400", "10.1145/2470654.2470723", "10.1037/0096-1523.16.2.332", "10.1167/16.5.11", "10.3758/s13423-016-1174-7", "10.3758/bf03207704", "10.1146/annurev.psych.55.090902.141415", "10.2307/2288400", "10.3758/bf03204258", "10.1109/tvcg.2011.279", "10.1109/vissoft.2014.36", "10.3758/s13423-011-0055-3", "10.1145/3025453.3025922", "10.1109/tvcg.2019.2934284", "10.3758/bf03210498", "10.3758/bf03200774", "10.2307/1419876", "10.1038/s41562-017-0058", "10.1109/tvcg.2010.237", "10.1109/pacificvis.2012.6183556", "10.1109/infvis.1997.636792", "10.1093/acprof:oso/9780198523192.003.0005", "10.1073/pnas.1117465109", "10.1109/tvcg.2013.234", "10.1038/nn.3655", "10.1111/cgf.12379", "10.1146/annurev-psych-010416-044232", "10.1111/cgf.13695", "10.1037/0033-295x.107.3.500", "10.1109/tvcg.2013.183", "10.1146/annurev.psych.53.100901.135125", "10.1037//0022-3514.79.6.995", "10.1559/152304003100010929", "10.1109/tvcg.2018.2865147", "10.1037/0096-1523.18.3.849", "10.1111/j.1467-8659.2009.01694.x", "10.1145/3290605.3300771"], "wos": 1, "children": [], "len": 1}], "len": 3}, {"doi": "10.1109/tvcg.2019.2934799", "title": "Data Sampling in Multi-view and Multi-class Scatterplots via Set Cover Optimization", "year": "2019", "conferenceName": "InfoVis", "authors": "Ruizhen Hu;Tingkai Sha;Oliver van Kaick;Oliver Deussen;Hui Huang 0004", "citationCount": "4", "affiliation": "Hu, RZ (Corresponding Author), Shenzhen Univ, Visual Comp Res Ctr, Shenzhen, Guangdong, Peoples R China. Hu, Ruizhen; Sha, Tingkai; Huang, Hui, Shenzhen Univ, Visual Comp Res Ctr, Shenzhen, Guangdong, Peoples R China. van Kaick, Oliver, Carleton Univ, Sch Comp Sci, Ottawa, ON, Canada. Deussen, Oliver, Konstanz Univ, Constance, Germany. Deussen, Oliver, SIAT, Shenzhen VisuCA Key Lab, Shenzhen, Guangdong, Peoples R China.", "countries": "Canada;Germany;China", "abstract": "We present a method for data sampling in scatterplots by jointly optimizing point selection for different views or classes. Our method uses space-filling curves (Z-order curves) that partition a point set into subsets that, when covered each by one sample, provide a sampling or coreset with good approximation guarantees in relation to the original point set. For scatterplot matrices with multiple views, different views provide different space-filling curves, leading to different partitions of the given point set. For multi-class scatterplots, the focus on either per-class distribution or global distribution provides two different partitions of the given point set that need to be considered in the selection of the coreset. For both cases, we convert the coreset selection problem into an Exact Cover Problem (ECP), and demonstrate with quantitative and qualitative evaluations that an approximate solution that solves the ECP efficiently is able to provide high-quality samplings.", "keywords": "Sampling,Scatterplot,SPLOM,Exact Cover Problem", "link": "http://dx.doi.org/10.1109/TVCG.2019.2934799", "refList": ["10.1057/palgrave.ivs.9500122", "10.1109/tvcg.2006.170", "10.1109/tvcg.2008.119", "10.1111/j.1467-8659.2009.01467.x", "10.2307/2289444", "10.1109/tvcg.2013.65", "10.1109/tvcg.2011.229", "10.1109/iv.2004.1320207", "10.1109/itoec.2018.8740621", "10.1145/1778765.1778816", "10.1109/tvcg.2018.2864912", "10.1007/0-387-28695-0", "10.1109/visual.1998.745301", "10.1287/moor.4.3.233", "10.1145/1556262.1556289", "10.1109/tvcg.2007.70535", "10.2307/2284239", "10.1109/tvcg.2017.2674978", "10.1016/j.dss.2009.05.016", "10.1109/tvcg.2014.2346594", "10.1109/vds.2017.8573446", "10.1007/978-1-4684-2001-2\\_9", "10.1109/iv.2002.1028760", "10.1145/1842993.1842999", "10.1038/nmeth.2490", "10.1109/tvcg.2013.153", "10.1111/cgf.13446", "10.1109/tvcg.2010.176", "10.1145/2702123.2702585", "10.1057/ivs.2009.34", "10.1179/000870403235002042"], "wos": 1, "children": [{"doi": "10.1109/tvcg.2020.3030443", "title": "CAVA: A Visual Analytics System for Exploratory Columnar Data Augmentation Using Knowledge Graphs", "year": "2020", "conferenceName": "VAST", "authors": "Dylan Cashman;Shenyu Xu;Subhajit Das;Florian Heimerl;Cong Liu;Shah Rukh Humayoun;Michael Gleicher;Alex Endert;Remco Chang", "citationCount": "0", "affiliation": "Cashman, D (Corresponding Author), Tufts Univ, Medford, MA 02155 USA. Cashman, Dylan; Liu, Cong; Chang, Remco, Tufts Univ, Medford, MA 02155 USA. Xu, Shenyu; Das, Subhajit; Endert, Alex, Georgia Tech, Atlanta, GA USA. Heimerl, Florian; Gleicher, Michael, Univ Wisconsin, Madison, WI 53706 USA. Humayoun, Shah Rukh, San Francisco State Univ, San Francisco, CA 94132 USA.", "countries": "USA", "abstract": "Most visual analytics systems assume that all foraging for data happens before the analytics process; once analysis begins, the set of data attributes considered is fixed. Such separation of data construction from analysis precludes iteration that can enable foraging informed by the needs that arise in-situ during the analysis. The separation of the foraging loop from the data analysis tasks can limit the pace and scope of analysis. In this paper, we present CAVA, a system that integrates data curation and data augmentation with the traditional data exploration and analysis tasks, enabling information foraging in-situ during analysis. Identifying attributes to add to the dataset is difficult because it requires human knowledge to determine which available attributes will be helpful for the ensuing analytical tasks. CAVA crawls knowledge graphs to provide users with a a broad set of attributes drawn from external data to choose from. Users can then specify complex operations on knowledge graphs to construct additional attributes. CAVA shows how visual analytics can help users forage for attributes by letting users visually explore the set of available data, and by serving as an interface for query construction. It also provides visualizations of the knowledge graph itself to help users understand complex joins such as multi-hop aggregations. We assess the ability of our system to enable users to perform complex data combinations without programming in a user study over two datasets. We then demonstrate the generalizability of CAVA through two additional usage scenarios. The results of the evaluation confirm that CAVA is effective in helping the user perform data foraging that leads to improved analysis outcomes, and offer evidence in support of integrating data augmentation as a part of the visual analytics pipeline.", "keywords": "Visual Analytics,Information Foraging,Data Augmentation", "link": "http://dx.doi.org/10.1109/TVCG.2020.3030443", "refList": ["10.1057/palgrave.ivs.9500122", "10.1109/tvcg.2016.2598867", "10.1111/cgf.13708", "10.1109/tvcg.2019.2934799", "10.1109/tvcg.2019.2934541", "10.1109/tvcg.2013.65", "10.1109/tvcg.2018.2875702", "10.1109/iv.2004.1320207", "10.1068/p260471", "10.1145/1778765.1778816", "10.1109/tvcg.2018.2808489", "10.1109/tvcg.2018.2864912", "10.1016/j.apgeog.2015.12.006", "10.1111/j.1467-8659.2011.01960.x", "10.1109/tvcg.2018.2864843", "10.1109/pacificvis.2010.5429604", "10.1109/tvcg.2014.2346898", "10.1109/5.726791", "10.1177/1475090214540874", "10.1109/icde.2016.7498287", "10.1145/1556262.1556289", "10.1109/tvcg.2007.70535", "10.1109/vast.2012.6400489", "10.1145/1056808.1056914", "10.1016/j.neucom.2014.09.063", "10.1145/7529.8927", "10.1109/tvcg.2016.2598495", "10.1109/tvcg.2016.2607204", "10.1109/vast47406.2019.8986943", "10.3758/bf03205986", "10.1109/infvis.2005.1532142", "10.1145/1150402.1150479", "10.1109/tvcg.2017.2674978", "10.1109/tvcg.2019.2945960", "10.1109/tvcg.2017.2744098", "10.1109/tvcg.2017.2674999", "10.1109/tvcg.2011.279", "10.1109/tvcg.2014.2346594", "10.1109/tvcg.2017.2744184", "10.1111/cgf.12876", "10.1007/s4095-020-0191-7", "10.1007/s11390-015-1535-0", "10.1111/cgf.12640", "10.1109/tvcg.2016.2598667", "10.1111/cgf.13683", "10.1109/tvcg.2013.153", "10.1109/tvcg.2019.2934208", "10.1109/tvcg.2019.2934655", "10.1111/cgf.12655", "10.1007/s11023-010-9221-z", "10.1109/vast.2012.6400487", "10.1145/2702123.2702585", "10.1007/bf00310175", "10.1109/tvcg.2017.2744378", "10.1103/physreve.64.061907", "10.1109/ldav.2017.8231848", "10.1109/tvcg.2016.2598831"], "wos": 1, "children": [], "len": 1}, {"doi": "10.1109/tvcg.2020.3030432", "title": "Evaluation of Sampling Methods for Scatterplots", "year": "2020", "conferenceName": "VAST", "authors": "Jun Yuan;Shouxing Xiang;Jiazhi Xia;Lingyun Yu;Shixia Liu", "citationCount": "0", "affiliation": "Liu, SX (Corresponding Author), Tsinghua Univ, BNRist, Beijing, Peoples R China. Yuan, Jun; Xiang, Shouxing; Liu, Shixia, Tsinghua Univ, BNRist, Beijing, Peoples R China. Xia, Jiazhi, Cent South Univ, Changsha, Peoples R China. Yu, Lingyun, Xian Jiaotong Liverpool Univ, Suzhou, Peoples R China.", "countries": "China", "abstract": "Given a scatterplot with tens of thousands of points or even more, a natural question is which sampling method should be used to create a small but \u201cgood\u201d scatterplot for a better abstraction. We present the results of a user study that investigates the influence of different sampling strategies on multi-class scatterplots. The main goal of this study is to understand the capability of sampling methods in preserving the density, outliers, and overall shape of a scatterplot. To this end, we comprehensively review the literature and select seven typical sampling strategies as well as eight representative datasets. We then design four experiments to understand the performance of different strategies in maintaining: 1) region density; 2) class density; 3) outliers; and 4) overall shape in the sampling results. The results show that: 1) random sampling is preferred for preserving region density; 2) blue noise sampling and random sampling have comparable performance with the three multi-class sampling strategies in preserving class density; 3) outlier biased density based sampling, recursive subdivision based sampling, and blue noise sampling perform the best in keeping outliers; and 4) blue noise sampling outperforms the others in maintaining the overall shape of a scatterplot.", "keywords": "Scatterplot,data sampling,empirical evaluation", "link": "http://dx.doi.org/10.1109/TVCG.2020.3030432", "refList": ["10.1057/palgrave.ivs.9500122", "10.1109/tvcg.2016.2598867", "10.1109/tvcg.2015.2467591", "10.1111/cgf.13708", "10.1109/tvcg.2019.2934799", "10.1109/tvcg.2019.2934541", "10.1109/tvcg.2013.65", "10.1109/iv.2004.1320207", "10.1068/p260471", "10.1145/1778765.1778816", "10.1109/tvcg.2018.2808489", "10.1109/tvcg.2018.2864912", "10.1016/j.apgeog.2015.12.006", "10.1111/j.1467-8659.2011.01960.x", "10.1109/tvcg.2018.2864843", "10.1109/pacificvis.2010.5429604", "10.1109/tvcg.2014.2346898", "10.1109/5.726791", "10.1177/1475090214540874", "10.1145/1556262.1556289", "10.1109/tvcg.2007.70535", "10.1109/vast.2012.6400489", "10.1145/1056808.1056914", "10.1016/j.neucom.2014.09.063", "10.1145/7529.8927", "10.1109/tvcg.2016.2607204", "10.1109/vast47406.2019.8986943", "10.3758/bf03205986", "10.1109/infvis.2005.1532142", "10.1145/1150402.1150479", "10.1109/tvcg.2017.2674978", "10.1109/tvcg.2017.2744098", "10.1109/tvcg.2017.2674999", "10.1109/tvcg.2011.279", "10.1109/tvcg.2014.2346594", "10.1109/tvcg.2017.2744184", "10.1111/cgf.12876", "10.1109/1011101.2019.2945960", "10.1007/s4095-020-0191-7", "10.1007/s11390-015-1535-0", "10.1111/cgf.12640", "10.1109/tvcg.2016.2598667", "10.1111/cgf.13683", "10.1109/tvcg.2013.153", "10.1109/tvcg.2019.2934208", "10.1109/tvcg.2019.2934655", "10.1111/cgf.12655", "10.1007/s11023-010-9221-z", "10.1109/vast.2012.6400487", "10.1145/2702123.2702585", "10.1007/bf00310175", "10.1109/tvcg.2017.2744378", "10.1103/physreve.64.061907", "10.1109/ldav.2017.8231848", "10.1109/tvcg.2016.2598831"], "wos": 1, "children": [], "len": 1}, {"doi": "10.1109/tvcg.2020.3030365", "title": "Modeling the Influence of Visual Density on Cluster Perception in Scatterplots Using Topology", "year": "2020", "conferenceName": "InfoVis", "authors": "Ghulam Jilani Quadri;Paul Rosen", "citationCount": "0", "affiliation": "Quadri, GJ (Corresponding Author), Univ S Florida, Tampa, FL 33620 USA. Quadri, Ghulam Jilani; Rosen, Paul, Univ S Florida, Tampa, FL 33620 USA.", "countries": "USA", "abstract": "Scatterplots are used for a variety of visual analytics tasks, including cluster identification, and the visual encodings used on a scatterplot play a deciding role on the level of visual separation of clusters. For visualization designers, optimizing the visual encodings is crucial to maximizing the clarity of data. This requires accurately modeling human perception of cluster separation, which remains challenging. We present a multi-stage user study focusing on four factors-distribution size of clusters, number of points, size of points, and opacity of points-that influence cluster identification in scatterplots. From these parameters, we have constructed two models, a distance-based model, and a density-based model, using the merge tree data structure from Topological Data Analysis. Our analysis demonstrates that these factors play an important role in the number of clusters perceived, and it verifies that the distance-based and density-based models can reasonably estimate the number of clusters a user observes. Finally, we demonstrate how these models can be used to optimize visual encodings on real-world data.", "keywords": "Scatterplot,clustering,perception,empirical evaluation,visual encoding,crowdsourcing,topological data analysis", "link": "http://dx.doi.org/10.1109/TVCG.2020.3030365", "refList": ["10.1109/tvcg.2017.2744359", "10.1145/1778765", "10.1109/tvcg.2019.2934799", "10.1111/cgf.12889", "10.1109/tvcg.2011.127", "10.1111/cgf.13444", "10.1145/1964897.1964910", "10.1167/8.7.6", "10.1145/3173574.3173991", "10.1145/1556262.1556289", "10.1145/1056808.1056914", "10.2307/2288400", "10.1109/tvcg.2014.2346594", "10.1109/iv.2002.1028760", "10.1177/001316447303300111", "10.1007/bf02289823", "10.1109/tvcg.2017.2744339", "10.1111/j.1467-8659.2009.01694.x", "10.1109/tvcg.2014.2346979", "10.1090/mbk/069", "10.1109/tvcg.2013.65", "10.1109/mcg.2012.37", "10.1109/pacificvis.2010.5429604", "10.1002/acp.2350050106", "10.1109/infvis.2005.1532136", "10.1177/1473871612465214", "10.1109/tvcg.2017.2674978", "10.1002/jhbs.20078", "10.1007/978-3-642-35142-6\\_14", "10.1007/978-3-319-71507-0", "10.1109/mcg.201.7.6", "10.3758/bf03193961", "10.1364/josa.49.000280", "10.1145/3025453.3025905", "10.1109/tvcg.201.9.2934541", "10.1109/tvcg.2018.2829750", "10.1177/1473871615606187", "10.1111/cgf.13408", "10.1109/pacificvis.2016.7465252", "10.1109/pacificvis.2016.7465244", "10.1109/inevis.2005.1532142", "10.1111/cgf.13414", "10.1111/j.1467-8659.2012.03125.x", "10.1167/16.5.11", "10.1109/infvis.2005.1532142", "10.1145/2858036.2858155", "10.1038/nmeth1210-941", "10.1177/1473871616638892", "10.1109/tcbb.2014.2306840", "10.1111/cgf.13684", "10.1177/0301006615602599", "10.1214/aoms/1177731915", "10.1145/2702123.2702585", "10.1109/tvcg.2013.183", "10.1109/tvcg.2014.2346572", "10.1109/tvcg.2018.2875702", "10.1109/tvcg.2017.2754480", "10.1109/vast.2014.7042493", "10.1057/palgrave.ivs.9500122", "10.1109/tvcg.2014.2330617", "10.1109/tvcg.2019.2934541", "10.1068/p030033", "10.1140/epjds/s13688-017-0109-5", "10.1201/b17511", "10.1016/s0925-7721(02)00093-7", "10.1109/pacificvis.2012.6183557", "10.1109/tvcg.2014.2346983", "10.1109/5.726791", "10.1080/01621459.1926.10502165", "10.1109/tvcg.2007.70535", "10.1109/tvcg.2018.2864907", "10.1111/cgf.12109", "10.1109/tvcg.2017.2744184", "10.1146/annurev-statistics-031017-100045", "10.1111/cgf.13409", "10.1145/3002151.3002162", "10.1016/s0378-4371(98)00494-4", "10.3138/y308-2422-8615-1233", "10.1111/cgf.12632", "10.1145/3290605.3300771"], "wos": 1, "children": [], "len": 1}], "len": 7}, {"doi": "10.1109/tvcg.2019.2934432", "title": "Discriminability Tests for Visualization Effectiveness and Scalability", "year": "2019", "conferenceName": "InfoVis", "authors": "Rafael Veras;Christopher Collins", "citationCount": "1", "affiliation": "Veras, R (Corresponding Author), Ontario Tech Univ, Oshawa, ON, Canada. Veras, Rafael; Collins, Christopher, Ontario Tech Univ, Oshawa, ON, Canada.", "countries": "Canada", "abstract": "The scalability of a particular visualization approach is limited by the ability for people to discern differences between plots made with different datasets. Ideally, when the data changes, the visualization changes in perceptible ways. This relation breaks down when there is a mismatch between the encoding and the character of the dataset being viewed. Unfortunately, visualizations are often designed and evaluated without fully exploring how they will respond to a wide variety of datasets. We explore the use of an image similarity measure, the Multi-Scale Structural Similarity Index (MS-SSIM), for testing the discriminability of a data visualization across a variety of datasets. MS-SSIM is able to capture the similarity of two visualizations across multiple scales, including low level granular changes and high level patterns. Significant data changes that are not captured by the MS-SSIM indicate visualizations of low discriminability and effectiveness. The measure's utility is demonstrated with two empirical studies. In the first, we compare human similarity judgments and MS-SSIM scores for a collection of scatterplots. In the second, we compute the discriminability values for a set of basic visualizations and compare them with empirical measurements of effectiveness. In both cases, the analyses show that the computational measure is able to approximate empirical results. Our approach can be used to rank competing encodings on their discriminability and to aid in selecting visualizations for a particular type of data distribution.", "keywords": "Scalability,Discriminability,Simulation,Perception", "link": "http://dx.doi.org/10.1109/TVCG.2019.2934432", "refList": ["10.1109/tvcg.2012.233", "10.1109/tvcg.2017.2744359", "10.1109/tvcg.2012.230", "10.1111/cgf.12647", "10.1109/tvcg.2016.2598918", "10.1109/tvcg.2007.70529", "10.1145/2858036.2858435", "10.1109/vast.2009.5332628", "10.1145/3025453.3025912", "10.1145/1133265.1133318", "10.1109/tip.2010.2092435", "10.1109/tvcg.2010.132", "10.1109/tvcg.2018.2865264", "10.1175/jtech-d-11-00103.1", "10.1145/1190036.1190039", "10.1111/cgf.12127", "10.1109/infvis.2005.1532142", "10.1145/2858036.2858155", "10.1109/mcg.2014.18", "10.1145/3173574.3174172", "10.1109/tvcg.2009.153", "10.1057/palgrave.ivs.9500070", "10.1109/tvcg.2018.2790961", "10.1109/tvcg.2014.2346978", "10.1109/tvcg.2018.2810918", "10.1111/cgf.13409", "10.1109/tip.2003.819861", "10.1145/2642918.2647411", "10.1080/15230406.2016.1140074", "10.1109/jstsp.2009.2015374", "10.1109/tvcg.2010.237", "10.1109/mcg.2009.6", "10.1111/j.1467-8659.2009.01667.x", "10.1109/tvcg.2010.161", "10.1111/cgf.13446", "10.1109/tvcg.2014.2346325", "10.1109/tvcg.2009.111", "10.1147/jrd.2015.2411412"], "wos": 1, "children": [{"doi": "10.1109/tvcg.2020.3030394", "title": "Direct Volume Rendering with Nonparametric Models of Uncertainty", "year": "2020", "conferenceName": "SciVis", "authors": "Tushar M. Athawale;Bo Ma 0002;Elham Sakhaee;Christopher R. Johnson;Alireza Entezari", "citationCount": "0", "affiliation": "Athawale, TM (Corresponding Author), Univ Utah, Sci Comp \\& Imaging SCI Inst, Salt Lake City, UT 84112 USA. Athawale, Tushar M.; Johnson, Chris R., Univ Utah, Sci Comp \\& Imaging SCI Inst, Salt Lake City, UT 84112 USA. Ma, Bo; Sakhaee, Elham; Entezari, Alireza, Univ Florida, Dept CISE, Gainesville, FL 32611 USA.", "countries": "USA", "abstract": "We present a nonparametric statistical framework for the quantification, analysis, and propagation of data uncertainty in direct volume rendering (DVR). The state-of-the-art statistical DVR framework allows for preserving the transfer function (TF) of the ground truth function when visualizing uncertain data; however, the existing framework is restricted to parametric models of uncertainty. In this paper, we address the limitations of the existing DVR framework by extending the DVR framework for nonparametric distributions. We exploit the quantile interpolation technique to derive probability distributions representing uncertainty in viewing-ray sample intensities in closed form, which allows for accurate and efficient computation. We evaluate our proposed nonparametric statistical models through qualitative and quantitative comparisons with the mean-field and parametric statistical models, such as uniform and Gaussian, as well as Gaussian mixtures. In addition, we present an extension of the state-of-the-art rendering parametric framework to 2D TFs for improved DVR classifications. We show the applicability of our uncertainty quantification framework to ensemble, downsampled, and bivariate versions of scalar field datasets.", "keywords": "Volumes,uncertainty,nonparametric,2D transfer function", "link": "http://dx.doi.org/10.1109/TVCG.2020.3030394", "refList": ["10.1109/icdm.2012.80", "10.1145/1401890.1401904", "10.1109/tvcg.2017.2745139", "10.18128/d030.v6.0", "10.1111/cgf.12142", "10.1109/tvcg.2009.114", "10.1111/j.1467-8659.2009.01677.x", "10.1109/mcse.2007.55", "10.1109/icde.2012.16", "10.1198/106186008x320465", "10.1145/1835804.1835868", "10.1559/1523040054738936", "10.1109/tvcg.2019.2934432", "10.1109/34.1000236", "10.1109/infvis.2005.1532136", "10.1109/tvcg.2012.128", "10.1109/pacificvis.2017.8031573", "10.1109/tvcg.2016.2598920", "10.1109/tvcg.2018.2865021", "10.1109/infvis.2005.1532142", "10.1145/2858036.2858155", "10.1109/sp.2009.22", "10.1109/tvcg.2017.2744184", "10.1145/773153.773173", "10.1145/2660267.2660348", "10.1109/icdmw.2009.93", "10.1016/j.jtrangeo.2015.09.001", "10.1109/icde.2010.5447831", "10.1007/11681878\\_14", "10.1111/cgf.13409", "10.1007/s13278-014-0205-5", "10.1109/tvcg.2011.163", "10.1145/3035918.3035940", "10.1109/sp.2008.33", "10.1145/2882903.2882931"], "wos": 1, "children": [], "len": 1}], "len": 3}, {"doi": "10.1109/tvcg.2019.2934208", "title": "Evaluating Perceptual Bias During Geometric Scaling of Scatterplots", "year": "2019", "conferenceName": "VAST", "authors": "Yating Wei;Honghui Mei;Ying Zhao;Shuyue Zhou;Bingru Lin;Haojing Jiang;Wei Chen", "citationCount": "5", "affiliation": "Chen, W (Corresponding Author), Zhejiang Univ, State Key Lab CAD \\& CG, Hangzhou 310058, Zhejiang, Peoples R China. Zhao, Y (Corresponding Author), Cent South Univ, Sch Comp Sci \\& Engn, Changsha 410083, Hunan, Peoples R China. Wei, Yating; Mei, Honghui; Zhou, Shuyue; Lin, Bingru; Chen, Wei, Zhejiang Univ, State Key Lab CAD \\& CG, Hangzhou 310058, Zhejiang, Peoples R China. Zhao, Ying; Jiang, Haojing, Cent South Univ, Sch Comp Sci \\& Engn, Changsha 410083, Hunan, Peoples R China.", "countries": "China", "abstract": "Scatterplots are frequently scaled to fit display areas in multi-view and multi-device data analysis environments. A common method used for scaling is to enlarge or shrink the entire scatterplot together with the inside points synchronously and proportionally. This process is called geometric scaling. However, geometric scaling of scatterplots may cause a perceptual bias, that is, the perceived and physical values of visual features may be dissociated with respect to geometric scaling. For example, if a scatterplot is projected from a laptop to a large projector screen, then observers may feel that the scatterplot shown on the projector has fewer points than that viewed on the laptop. This paper presents an evaluation study on the perceptual bias of visual features in scatterplots caused by geometric scaling. The study focuses on three fundamental visual features (i.e., numerosity, correlation, and cluster separation) and three hypotheses that are formulated on the basis of our experience. We carefully design three controlled experiments by using well-prepared synthetic data and recruit participants to complete the experiments on the basis of their subjective experience. With a detailed analysis of the experimental results, we obtain a set of instructive findings. First, geometric scaling causes a bias that has a linear relationship with the scale ratio. Second, no significant difference exists between the biases measured from normally and uniformly distributed scatterplots. Third, changing the point radius can correct the bias to a certain extent. These findings can be used to inspire the design decisions of scatterplots in various scenarios.", "keywords": "Evaluation,scatterplot,geometric scaling,bias,perceptual consistency", "link": "http://dx.doi.org/10.1109/TVCG.2019.2934208", "refList": ["10.2307/2288843", "10.1109/tvcg.2017.2744359", "10.1109/tvcg.2015.2467732", "10.1109/tvcg.2014.2346979", "10.1126/science.216.4550.1138", "10.1109/tvcg.2017.2744138", "10.1111/j.1467-8659.2009.01467.x", "10.1145/2491568.2491577", "10.1109/mwc.2018.1700325", "10.1145/2449396.2449439", "10.1109/tvcg.2011.127", "10.1109/tvcg.2011.229", "10.1167/15.5.4", "10.1073/pnas.1113195108", "10.1145/2702123.2702545", "10.1109/vast.2009.5332628", "10.1109/tvcg.2018.2800013", "10.1007/s12650-018-0530-2", "10.1016/s0042-6989(97)00340-4", "10.1109/vast.2010.5652460", "10.1109/mcg.2018.2879067", "10.1109/tvcg.2018.2864912", "10.1109/pacificvis.2010.5429604", "10.1109/tcst.2018.2819965", "10.1167/10.2.10", "10.1145/2470654.2481318", "10.1145/1842993.1843002", "10.1167/12.6.8", "10.1109/tvcg.2013.124", "10.1057/ivs.2008.13", "10.1109/tvcg.2007.70596", "10.1109/tvcg.2018.2865266", "10.1145/3173574.3173664", "10.1109/tvcg.2015.2467671", "10.1016/j.cag.2017.07.004", "10.1177/0956797613501520", "10.1109/tvcg.2018.2865020", "10.1111/j.1467-8659.2012.03125.x", "10.3758/bf03205986", "10.3758/s13423-016-1174-7", "10.1109/tvcg.2017.2680452", "10.1109/mc.2006.109", "10.1109/tvcg.2017.2744098", "10.1038/srep32810", "10.1016/j.visres.2013.06.006", "10.1002/jhbs.20078", "10.1109/tvcg.2006.163", "10.1109/tvcg.2014.2346594", "10.1109/tvcg.2017.2744184", "10.1016/j.cognition.2007.10.009", "10.1109/tvcg.2018.2865142", "10.3758/app.72.7.1839", "10.1109/tvcg.2018.2810918", "10.1016/j.jvlc.2017.10.001", "10.1145/2682623", "10.1109/tvcg.2018.2864884", "10.1145/3025453.3025984", "10.1109/tvcg.2006.184", "10.1109/tvcg.2013.153", "10.1016/j.jvlc.2018.08.003", "10.1109/tvcg.2016.2520921", "10.1111/cgf.13446", "10.1017/s0022381612000187", "10.1145/2702123.2702406", "10.1109/vast.2012.6400487", "10.1109/tvcg.2013.183", "10.1177/1473871611415997", "10.1145/2702123.2702585", "10.1145/2993901.2993903", "10.1109/tvcg.2013.120", "10.1111/cgf.12632", "10.1145/1385569.1385602", "10.1109/tvcg.2017.2754480", "10.1111/j.1467-8659.2009.01694.x"], "wos": 1, "children": [{"doi": "10.1109/tvcg.2020.3030456", "title": "Cartographic Relief Shading with Neural Networks", "year": "2020", "conferenceName": "InfoVis", "authors": "Bernhard Jenny;Magnus Heitzler;Dilpreet Singh;Marianna Farmakis-Serebryakova;Jeffery Chieh Liu;Lorenz Hurni", "citationCount": "4", "affiliation": "Jenny, B (Corresponding Author), Monash Univ, Melbourne, Vic, Australia. Jenny, Bernhard; Singh, Dilpreet; Liu, Jeffery Chieh, Monash Univ, Melbourne, Vic, Australia. Heitzler, Magnus; Farmakis-Serebryakova, Marianna; Hurni, Lorenz, Swiss Fed Inst Technol, Inst Cartog \\& Geoinformat, Zurich, Switzerland.", "countries": "Switzerland;Australia", "abstract": "Shaded relief is an effective method for visualising terrain on topographic maps, especially when the direction of illumination is adapted locally to emphasise individual terrain features. However, digital shading algorithms are unable to fully match the expressiveness of hand-crafted masterpieces, which are created through a laborious process by highly specialised cartographers. We replicate hand-drawn relief shading using U-Net neural networks. The deep neural networks are trained with manual shaded relief images of the Swiss topographic map series and terrain models of the same area. The networks generate shaded relief that closely resemble hand-drawn shaded relief art. The networks learn essential design principles from manual relief shading such as removing unnecessary terrain details, locally adjusting the illumination direction to accentuate individual terrain features, and varying brightness to emphasise larger landforms. Neural network shadings are generated from digital elevation models in a few seconds, and a study with 18 relief shading experts found that they are of high quality.", "keywords": "Relief shading,shaded relief,hillshade,neural rendering,illustrative visualisation,image-to-image translation", "link": "http://dx.doi.org/10.1109/TVCG.2020.3030456", "refList": ["10.1145/1456650.1456652", "10.1145/1145/1556262.1556270", "10.1145/345513.345271", "10.1109/tvcg.2019.2934803", "10.1145/3180658", "10.1109/tridui.2006.1618264", "10.3389/fict.2018.00015", "10.1109/vr.2018.8447558", "10.1518/hfes.45.1.160.27234", "10.1145/3290605.3300377", "10.1089/cpb.2006.9.157", "10.1007/s00779-011-0500-3", "10.1109/vl.1996.545307", "10.1109/tvcg.2019.2934415", "10.1109/5.726791", "10.1145/3290605.3300288", "10.1109/tvcg.2017.2745941", "10.1109/vr.2001.913779", "10.1145/586081.586086", "10.18637/jss.v067.i01", "10.1145/1502800.1502805", "10.1145/1165734.1165736", "10.1145/3126594.3126613", "10.1109/tvcg.2008.109", "10.1109/tvcg.2017.2744184", "10.1016/j.cola.2019.100937", "10.1109/visual.2019.8933545", "10.1145/3290605.3300555", "10.1111/cgf.13431", "10.1109/tvcg.2019.2934395", "10.1109/vr.2019.8798340", "10.1145/3025453.3026046", "10.1109/vr.2019.8797871", "10.1145/3290605.3300752", "10.1109/tvcg.2016.2520921", "10.1109/tvcg.2018.2865191", "10.1145/1970378.1970384", "10.1109/tvcg.2019.2934208", "10.18637/jss.v069.i01", "10.1162/105474698565659", "10.1145/1124772.1124775", "10.1109/vrais.1997.583043"], "wos": 1, "children": [], "len": 1}, {"doi": "10.1109/tvcg.2020.3030443", "title": "CAVA: A Visual Analytics System for Exploratory Columnar Data Augmentation Using Knowledge Graphs", "year": "2020", "conferenceName": "VAST", "authors": "Dylan Cashman;Shenyu Xu;Subhajit Das;Florian Heimerl;Cong Liu;Shah Rukh Humayoun;Michael Gleicher;Alex Endert;Remco Chang", "citationCount": "0", "affiliation": "Cashman, D (Corresponding Author), Tufts Univ, Medford, MA 02155 USA. Cashman, Dylan; Liu, Cong; Chang, Remco, Tufts Univ, Medford, MA 02155 USA. Xu, Shenyu; Das, Subhajit; Endert, Alex, Georgia Tech, Atlanta, GA USA. Heimerl, Florian; Gleicher, Michael, Univ Wisconsin, Madison, WI 53706 USA. Humayoun, Shah Rukh, San Francisco State Univ, San Francisco, CA 94132 USA.", "countries": "USA", "abstract": "Most visual analytics systems assume that all foraging for data happens before the analytics process; once analysis begins, the set of data attributes considered is fixed. Such separation of data construction from analysis precludes iteration that can enable foraging informed by the needs that arise in-situ during the analysis. The separation of the foraging loop from the data analysis tasks can limit the pace and scope of analysis. In this paper, we present CAVA, a system that integrates data curation and data augmentation with the traditional data exploration and analysis tasks, enabling information foraging in-situ during analysis. Identifying attributes to add to the dataset is difficult because it requires human knowledge to determine which available attributes will be helpful for the ensuing analytical tasks. CAVA crawls knowledge graphs to provide users with a a broad set of attributes drawn from external data to choose from. Users can then specify complex operations on knowledge graphs to construct additional attributes. CAVA shows how visual analytics can help users forage for attributes by letting users visually explore the set of available data, and by serving as an interface for query construction. It also provides visualizations of the knowledge graph itself to help users understand complex joins such as multi-hop aggregations. We assess the ability of our system to enable users to perform complex data combinations without programming in a user study over two datasets. We then demonstrate the generalizability of CAVA through two additional usage scenarios. The results of the evaluation confirm that CAVA is effective in helping the user perform data foraging that leads to improved analysis outcomes, and offer evidence in support of integrating data augmentation as a part of the visual analytics pipeline.", "keywords": "Visual Analytics,Information Foraging,Data Augmentation", "link": "http://dx.doi.org/10.1109/TVCG.2020.3030443", "refList": ["10.1057/palgrave.ivs.9500122", "10.1109/tvcg.2016.2598867", "10.1111/cgf.13708", "10.1109/tvcg.2019.2934799", "10.1109/tvcg.2019.2934541", "10.1109/tvcg.2013.65", "10.1109/tvcg.2018.2875702", "10.1109/iv.2004.1320207", "10.1068/p260471", "10.1145/1778765.1778816", "10.1109/tvcg.2018.2808489", "10.1109/tvcg.2018.2864912", "10.1016/j.apgeog.2015.12.006", "10.1111/j.1467-8659.2011.01960.x", "10.1109/tvcg.2018.2864843", "10.1109/pacificvis.2010.5429604", "10.1109/tvcg.2014.2346898", "10.1109/5.726791", "10.1177/1475090214540874", "10.1109/icde.2016.7498287", "10.1145/1556262.1556289", "10.1109/tvcg.2007.70535", "10.1109/vast.2012.6400489", "10.1145/1056808.1056914", "10.1016/j.neucom.2014.09.063", "10.1145/7529.8927", "10.1109/tvcg.2016.2598495", "10.1109/tvcg.2016.2607204", "10.1109/vast47406.2019.8986943", "10.3758/bf03205986", "10.1109/infvis.2005.1532142", "10.1145/1150402.1150479", "10.1109/tvcg.2017.2674978", "10.1109/tvcg.2019.2945960", "10.1109/tvcg.2017.2744098", "10.1109/tvcg.2017.2674999", "10.1109/tvcg.2011.279", "10.1109/tvcg.2014.2346594", "10.1109/tvcg.2017.2744184", "10.1111/cgf.12876", "10.1007/s4095-020-0191-7", "10.1007/s11390-015-1535-0", "10.1111/cgf.12640", "10.1109/tvcg.2016.2598667", "10.1111/cgf.13683", "10.1109/tvcg.2013.153", "10.1109/tvcg.2019.2934208", "10.1109/tvcg.2019.2934655", "10.1111/cgf.12655", "10.1007/s11023-010-9221-z", "10.1109/vast.2012.6400487", "10.1145/2702123.2702585", "10.1007/bf00310175", "10.1109/tvcg.2017.2744378", "10.1103/physreve.64.061907", "10.1109/ldav.2017.8231848", "10.1109/tvcg.2016.2598831"], "wos": 1, "children": [], "len": 1}, {"doi": "10.1109/tvcg.2020.3030432", "title": "Evaluation of Sampling Methods for Scatterplots", "year": "2020", "conferenceName": "VAST", "authors": "Jun Yuan;Shouxing Xiang;Jiazhi Xia;Lingyun Yu;Shixia Liu", "citationCount": "0", "affiliation": "Liu, SX (Corresponding Author), Tsinghua Univ, BNRist, Beijing, Peoples R China. Yuan, Jun; Xiang, Shouxing; Liu, Shixia, Tsinghua Univ, BNRist, Beijing, Peoples R China. Xia, Jiazhi, Cent South Univ, Changsha, Peoples R China. Yu, Lingyun, Xian Jiaotong Liverpool Univ, Suzhou, Peoples R China.", "countries": "China", "abstract": "Given a scatterplot with tens of thousands of points or even more, a natural question is which sampling method should be used to create a small but \u201cgood\u201d scatterplot for a better abstraction. We present the results of a user study that investigates the influence of different sampling strategies on multi-class scatterplots. The main goal of this study is to understand the capability of sampling methods in preserving the density, outliers, and overall shape of a scatterplot. To this end, we comprehensively review the literature and select seven typical sampling strategies as well as eight representative datasets. We then design four experiments to understand the performance of different strategies in maintaining: 1) region density; 2) class density; 3) outliers; and 4) overall shape in the sampling results. The results show that: 1) random sampling is preferred for preserving region density; 2) blue noise sampling and random sampling have comparable performance with the three multi-class sampling strategies in preserving class density; 3) outlier biased density based sampling, recursive subdivision based sampling, and blue noise sampling perform the best in keeping outliers; and 4) blue noise sampling outperforms the others in maintaining the overall shape of a scatterplot.", "keywords": "Scatterplot,data sampling,empirical evaluation", "link": "http://dx.doi.org/10.1109/TVCG.2020.3030432", "refList": ["10.1057/palgrave.ivs.9500122", "10.1109/tvcg.2016.2598867", "10.1109/tvcg.2015.2467591", "10.1111/cgf.13708", "10.1109/tvcg.2019.2934799", "10.1109/tvcg.2019.2934541", "10.1109/tvcg.2013.65", "10.1109/iv.2004.1320207", "10.1068/p260471", "10.1145/1778765.1778816", "10.1109/tvcg.2018.2808489", "10.1109/tvcg.2018.2864912", "10.1016/j.apgeog.2015.12.006", "10.1111/j.1467-8659.2011.01960.x", "10.1109/tvcg.2018.2864843", "10.1109/pacificvis.2010.5429604", "10.1109/tvcg.2014.2346898", "10.1109/5.726791", "10.1177/1475090214540874", "10.1145/1556262.1556289", "10.1109/tvcg.2007.70535", "10.1109/vast.2012.6400489", "10.1145/1056808.1056914", "10.1016/j.neucom.2014.09.063", "10.1145/7529.8927", "10.1109/tvcg.2016.2607204", "10.1109/vast47406.2019.8986943", "10.3758/bf03205986", "10.1109/infvis.2005.1532142", "10.1145/1150402.1150479", "10.1109/tvcg.2017.2674978", "10.1109/tvcg.2017.2744098", "10.1109/tvcg.2017.2674999", "10.1109/tvcg.2011.279", "10.1109/tvcg.2014.2346594", "10.1109/tvcg.2017.2744184", "10.1111/cgf.12876", "10.1109/1011101.2019.2945960", "10.1007/s4095-020-0191-7", "10.1007/s11390-015-1535-0", "10.1111/cgf.12640", "10.1109/tvcg.2016.2598667", "10.1111/cgf.13683", "10.1109/tvcg.2013.153", "10.1109/tvcg.2019.2934208", "10.1109/tvcg.2019.2934655", "10.1111/cgf.12655", "10.1007/s11023-010-9221-z", "10.1109/vast.2012.6400487", "10.1145/2702123.2702585", "10.1007/bf00310175", "10.1109/tvcg.2017.2744378", "10.1103/physreve.64.061907", "10.1109/ldav.2017.8231848", "10.1109/tvcg.2016.2598831"], "wos": 1, "children": [], "len": 1}], "len": 7}, {"doi": "10.1109/tvcg.2019.2934300", "title": "GUIRO: User-Guided Matrix Reordering", "year": "2019", "conferenceName": "VAST", "authors": "Michael Behrisch;Tobias Schreck;Hanspeter Pfister", "citationCount": "1", "affiliation": "Behrisch, M (Corresponding Author), Harvard Univ, Sch Engn \\& Appl Sci, Cambridge, MA 02138 USA. Behrisch, Michael; Pfister, Hanspeter, Harvard Univ, Sch Engn \\& Appl Sci, Cambridge, MA 02138 USA. Schreck, Tobias, Graz Univ Technol, Graz, Austria.", "countries": "USA;Austria", "abstract": "Matrix representations are one of the main established and empirically proven to be effective visualization techniques for relational (or network) data. However, matrices\u2014similar to node-link diagrams\u2014are most effective if their layout reveals the underlying data topology. Given the many developed algorithms, a practical problem arises: \u201cWhich matrix reordering algorithm should I choose for my dataset at hand?\u201d To make matters worse, different reordering algorithms applied to the same dataset may let significantly different visual matrix patterns emerge. This leads to the question of trustworthiness and explainability of these fully automated, often heuristic, black-box processes. We present GUIRO, a Visual Analytics system that helps novices, network analysts, and algorithm designers to open the black-box. Users can investigate the usefulness and expressiveness of 70 accessible matrix reordering algorithms. For network analysts, we introduce a novel model space representation and two interaction techniques for a user-guided reordering of rows or columns, and especially groups thereof (submatrix reordering). These novel techniques contribute to the understanding of the global and local dataset topology. We support algorithm designers by giving them access to 16 reordering quality metrics and visual exploration means for comparing reordering implementations on a row/column permutation level. We evaluated GUIRO in a guided explorative user study with 12 subjects, a case study demonstrating its usefulness in a real-world scenario, and through an expert study gathering feedback on our design decisions. We found that our proposed methods help even inexperienced users to understand matrix patterns and allow a user-guided steering of reordering algorithms. GUIRO helps to increase the transparency of matrix reordering algorithms, thus helping a broad range of users to get a better insight into the complex reordering process, in turn supporting data and reordering algorithm insights.", "keywords": "Visual Analytics,matrix,black-box algorithms,seriation,ordering,sorting,steerable algorithm,interaction,2D projection", "link": "http://dx.doi.org/10.1109/TVCG.2019.2934300", "refList": ["10.1109/tvcg.2007.70582", "10.2307/276978", "10.1109/tvcg.2008.61", "10.3390/su10040973", "10.1101/121889", "10.1145/1345448.1345453", "10.1186/s12879-014-0695-9", "10.1186/1471-2105-9-155", "10.1145/1124772.1124891", "10.1109/tvcg.2010.159", "10.1111/j.2044-8317.1974.tb00534.x", "10.1109/tpami.2015.2470671", "10.1198/000313005x22770", "10.1109/tvcg.2012.219", "10.1002/sam.10071", "10.1016/j.ejor.2016.08.066", "10.1007/s00265-003-0651-y", "10.1109/biovis.2013.6664342", "10.3115/v1/p14-1062", "10.3389/fpsyg.2017.01349", "10.1109/tpami.2004.1265866", "10.1057/palgrave.ivs.9500086", "10.1007/s004260000031", "10.1111/cgf.12935", "10.1145/800195.805928", "10.1109/tvcg.2014.2346279", "10.2312/eurovisstar.20141174", "10.1109/tvcg.2012.256", "10.1093/bioinformatics/17.suppl\\_1.s22", "10.1109/infvis.2004.46", "10.1007/978-3-319-06793-3\\_5", "10.1109/tvcg.2006.147", "10.1109/tvcg.2015.2468078", "10.1093/bioinformatics/bti141", "10.1145/1168149.1168168", "10.1109/tvcg.2017.2745978", "10.1177/1473871613513228", "10.1109/mcg.2014.62", "10.1109/tvcg.2006.166", "10.1145/2470654.2470724", "10.1177/154193120605000909", "10.1109/sibgrapi.2007.21", "10.1145/3065386", "10.1109/tvcg.2006.160", "10.1287/opre.20.5.993", "10.1111/cgf.13446", "10.1057/palgrave.ivs.9500092", "10.1145/568522.568523", "10.1109/mcg.2013.66", "10.1109/tvcg.2018.2865940", "10.1109/tvcg.2012.208"], "wos": 1, "children": [{"doi": "10.1109/tvcg.2020.3030471", "title": "Visual Analysis of Discrimination in Machine Learning", "year": "2020", "conferenceName": "InfoVis", "authors": "Qianwen Wang;Zhenhua Xu;Zhutian Chen;Yong Wang;Shixia Liu;Huamin Qu", "citationCount": "0", "affiliation": "Wang, QW (Corresponding Author), Hong Kong Univ Sci \\& Technol, Hong Kong, Peoples R China. Wang, Qianwen; Xu, Zhenhua; Chen, Zhutian; Wang, Yong; Qu, Huamin, Hong Kong Univ Sci \\& Technol, Hong Kong, Peoples R China. Liu, Shixia, Tsinghua Univ, Beijing, Peoples R China.", "countries": "China", "abstract": "The growing use of automated decision-making in critical applications, such as crime prediction and college admission, has raised questions about fairness in machine learning. How can we decide whether different treatments are reasonable or discriminatory? In this paper, we investigate discrimination in machine learning from a visual analytics perspective and propose an interactive visualization tool, DiscriLens, to support a more comprehensive analysis. To reveal detailed information on algorithmic discrimination, DiscriLens identifies a collection of potentially discriminatory itemsets based on causal modeling and classification rules mining. By combining an extended Euler diagram with a matrix-based visualization, we develop a novel set visualization to facilitate the exploration and interpretation of discriminatory itemsets. A user study shows that users can interpret the visually encoded information in DiscriLens quickly and accurately. Use cases demonstrate that DiscriLens provides informative guidance in understanding and reducing algorithmic discrimination.", "keywords": "Machine Learning,Discrimination,Data Visualization", "link": "http://dx.doi.org/10.1109/TVCG.2020.3030471", "refList": ["10.1109/tvcg.2019.2934396", "10.2312/eurovisstar.20141170", "10.1145/3357384.3357910", "10.1111/cgf.12791", "10.1109/tvcg.2018.2861397", "10.1111/j.1467-8659.2011.01898.x", "10.1145/2702123.2702237", "10.1109/tvcg.2019.2934798", "10.1109/mcg.2017.21", "10.1109/tvcg.2019.2934300", "10.1109/tvcg.2017.2745085", "10.1109/tvcg.2018.2859997", "10.1145/3173574.3174237", "10.1109/tvcg.2018.2865126", "10.1145/1718487.1718520", "10.1109/tvcg.2017.2743858", "10.1109/pacificvis.2015.7156392", "10.1109/tvcg.2018.2864477", "10.1145/324133.324140", "10.1137/140976649", "10.1145/3219819.3220088", "10.1109/tvcg.2019.2934805", "10.1145/1134271.1134277", "10.1137/090772745", "10.1016/j.jelectrocard.2010.09.003", "10.1109/tvcg.2012.253", "10.1145/2556612", "10.1109/tvcg.2013.173", "10.1109/tvcg.2019.2934619", "10.1109/tvcg.2017.2745078"], "wos": 1, "children": [], "len": 1}], "len": 3}, {"doi": "10.1109/tvcg.2019.2934796", "title": "Improving the Robustness of Scagnostics", "year": "2019", "conferenceName": "InfoVis", "authors": "Yunhai Wang;Zeyu Wang 0005;Tingting Liu;Michael Correll;Zhanglin Cheng;Oliver Deussen;Michael Sedlmair", "citationCount": "1", "affiliation": "Wang, YH (Corresponding Author), Shandong Univ, Jinan, Peoples R China. Wang, Yunhai; Wang, Zeyu; Liu, Tingting, Shandong Univ, Jinan, Peoples R China. Wang, Zeyu; Cheng, Zhanglin; Deussen, Oliver, SIAT, Shenzhen VisuCA Key Lab, Shenzhen, Peoples R China. Correll, Michael, Tableau Res, Seattle, WA USA. Deussen, Oliver, Konstanz Univ, Constance, Germany. Sedlmair, Michael, Univ Stuttgart, VISUS, Stuttgart, Germany.", "countries": "USA;Germany;China", "abstract": "In this paper, we examine the robustness of scagnostics through a series of theoretical and empirical studies. First, we investigate the sensitivity of scagnostics by employing perturbing operations on more than 60M synthetic and real-world scatterplots. We found that two scagnostic measures, Outlying and Clumpy, are overly sensitive to data binning. To understand how these measures align with human judgments of visual features, we conducted a study with 24 participants, which reveals that i) humans are not sensitive to small perturbations of the data that cause large changes in both measures, and ii) the perception of clumpiness heavily depends on per-cluster topologies and structures. Motivated by these results, we propose Robust Scagnostics (RScag) by combining adaptive binning with a hierarchy-based form of scagnostics. An analysis shows that RScag improves on the robustness of original scagnostics, aligns better with human judgments, and is equally fast as the traditional scagnostic measures.", "keywords": "Scagnostics,scatterplots,sensitivity analysis,Robust Scagnostics", "link": "http://dx.doi.org/10.1109/TVCG.2019.2934796", "refList": ["10.1057/palgrave.ivs.9500122", "10.1109/tvcg.2014.2346979", "10.1111/j.1467-8659.2009.01467.x", "10.1109/vast.2008.4677368", "10.2307/2289444", "10.1109/tvcg.2011.229", "10.1109/iv.2004.1320207", "10.1109/vast.2009.5332628", "10.1111/insr.12095\\_11", "10.1109/tvcg.2010.184", "10.1109/tvcg.2015.2467323", "10.1109/vast.2010.5652460", "10.1111/j.1467-8659.2012.03069.x", "10.1145/1842993.1843002", "10.1198/106186008x320465", "10.1109/pacificvis.2016.7465244", "10.1109/tvcg.2013.20", "10.1111/cgf.12641", "10.1109/tvcg.2012.128", "10.1109/tvcg.2015.2467671", "10.1057/palgrave.ivs.9500091", "10.1007/978-1-4612-4400-4", "10.1111/cgf.13176", "10.1002/0470870958", "10.1109/tvcg.2018.2864907", "10.1111/j.1467-8659.2012.03125.x", "10.1109/vast.2012.6400490", "10.1109/infvis.2005.1532142", "10.1109/vast.2010.5652433", "10.1109/vast.2009.5332611", "10.1201/9781315140919", "10.1145/2858036.2858155", "10.1109/ldav.2013.6675164", "10.1515/itit-2014-1070", "10.1111/cgf.13684", "10.1109/tpami.1979.4766909", "10.2307/2289936", "10.1109/pacificvis.2014.42", "10.1109/tvcg.2016.2598467", "10.1109/tvcg.2013.153", "10.1111/cgf.13446", "10.1109/tvcg.2006.94", "10.1109/tvcg.2014.2346572", "10.1111/cgf.12632", "10.1109/tvcg.2017.2744339"], "wos": 1, "children": [], "len": 1}, {"doi": "10.1109/vast47406.2019.8986917", "title": "VIANA: Visual Interactive Annotation of Argumentation", "year": "2019", "conferenceName": "VAST", "authors": "Fabian Sperrle;Rita Sevastjanova;Rebecca Kehlbeck;Mennatallah El-Assady", "citationCount": "0", "affiliation": "Sperrle, F (Corresponding Author), Univ Konstanz, Constance, Germany. Sperrle, Fabian; Sevastjanova, Rita; Kehlbeck, Rebecca; El-Assady, Mennatallah, Univ Konstanz, Constance, Germany.", "countries": "Germany", "abstract": "Argumentation Mining addresses the challenging tasks of identifying boundaries of argumentative text fragments and extracting their relationships. Fully automated solutions do not reach satisfactory accuracy due to their insufficient incorporation of semantics and domain knowledge. Therefore, experts currently rely on time-consuming manual annotations. In this paper, we present a visual analytics system that augments the manual annotation process by automatically suggesting which text fragments to annotate next. The accuracy of those suggestions is improved over time by incorporating linguistic knowledge and language modeling to learn a measure of argument similarity from user interactions. Based on a long-term collaboration with domain experts, we identify and model five high-level analysis tasks. We enable close reading and note-taking, annotation of arguments, argument reconstruction, extraction of argument relations, and exploration of argument graphs. To avoid context switches, we transition between all views through seamless morphing, visually anchoring all text- and graph-based layers. We evaluate our system with a two-stage expert user study based on a corpus of presidential debates. The results show that experts prefer our system over existing solutions due to the speedup provided by the automatic suggestions and the tight integration between text and graph views.", "keywords": "Argumentation annotation,machine learning,user interaction,layered interfaces,semantic transitions", "link": "http://dx.doi.org/10.1109/VAST47406.2019.8986917", "refList": ["10.1007/978-3-642-40624-9\\_1", "10.3233/978-1-61499-436-7-185", "10.1145/371920.372071", "10.3233/978-1-61499-906-5-4", "10.1109/tvcg.2015.2467759", "10.18653/v1/d15-1050", "10.2307/2529310", "10.1109/mic.2003.1167344", "10.1145/312624.312682", "10.1145/2850417", "10.18653/v1/p17-2039", "10.1016/j.eswa.2016.02.013", "10.1007/978-0-387-85820-3\\_3", "10.1007/s11412-009-9080-x", "10.1109/tvcg.2008.127", "10.1145/2207676.2207741", "10.1109/cit.2012.217", "10.3233/aac-170022", "10.1109/tvcg.2017.2745080", "10.1007/978-3-319-44039-2\\_6", "10.1145/3290605.3300233", "10.1007/978-94-017-0431-1", "10.3233/978-1-61499-906-5-313", "10.1142/s0218213004001922", "10.1109/tvcg.2012.262", "10.1177/001316446002000104", "10.1109/tvcg.2018.2834341", "10.3233/978-1-61499-436-7-463", "10.1145/1772690.1772773", "10.1109/tvcg.2014.2346677", "10.1145/2523813", "10.1162/153244303322533223", "10.1109/tvcg.2007.70539", "10.1109/tvcg.2015.2467531", "10.1109/tvcg.2018.2864769", "10.1007/978-3-319-90092-6\\_14", "10.1137/1.9781611972801.19", "10.1109/vast.2012.6400485", "10.1007/s10579-013-9215-6", "10.3115/v1/d14-1162", "10.1111/cgf.13446", "10.1109/tvcg.2006.156", "10.1111/cgf.13092", "10.1145/2645710.2645759", "10.1109/bigdata.2017.8258140", "10.1145/2669557.2669572", "10.2312/eurovisstar.20151113"], "wos": 1, "children": [], "len": 1}, {"doi": "10.1109/tvcg.2020.3030376", "title": "Insight Beyond Numbers: The Impact of Qualitative Factors on Visual Data Analysis", "year": "2020", "conferenceName": "VAST", "authors": "Benjamin Karer;Hans Hagen;Dirk J. Lehmann", "citationCount": "0", "affiliation": "Karer, B (Corresponding Author), Fed Criminal Police Off Germany, Wiesbaden, Germany. Karer, Benjamin, Fed Criminal Police Off Germany, Wiesbaden, Germany. Hagen, Hans, TU Kaiserslautern, Kaiserslautern, Germany. Lehmann, Dirk J., Ostfalia Univ Appl Sci, Wolfenbuttel, Germany. Lehmann, Dirk J., IAV GmbH, Berlin, Germany.", "countries": "Germany", "abstract": "As of today, data analysis focuses primarily on the findings to be made inside the data and concentrates less on how those findings relate to the domain of investigation. Contemporary visualization as a field of research shows a strong tendency to adopt this data-centrism. Despite their decisive influence on the analysis result, qualitative aspects of the analysis process such as the structure, soundness, and complexity of the applied reasoning strategy are rarely discussed explicitly. We argue that if the purpose of visualization is the provision of domain insight rather than the depiction of data analysis results, a holistic perspective requires a qualitative component to to be added to the discussion of quantitative and human factors. To support this point, we demonstrate how considerations of qualitative factors in visual analysis can be applied to obtain explanations and possible solutions for a number of practical limitations inherent to the data-centric perspective on analysis. Based on this discussion of what we call qualitative visual analysis, we develop an inside-outside principle of nested levels of context that can serve as a conceptual basis for the development of visualization systems that optimally support the emergence of insight during analysis.", "keywords": "Visualization,Reasoning,Qualitative Aspects", "link": "http://dx.doi.org/10.1109/TVCG.2020.3030376", "refList": ["10.1057/ivs.2009.22", "10.1109/tvcg.2015.2467732", "10.1109/infvis.2000.885092", "10.1109/vast.2014.7042482", "10.1145/1498700.1498704", "10.1109/tvcg.2009.108", "10.1109/tvcg.2018.2829750", "10.1037/0033-295x.111.4.1036", "10.1109/tvcg.2012.199", "10.1109/38.267476", "10.1007/978-3-540-70956-5\\_2", "10.1109/tvcg.2015.2467613", "10.1109/tvcg.2015.2467195", "10.1109/tvcg.2014.2346419", "10.1109/vast.2017.8585669", "10.1109/tvcg.2010.132", "10.1145/22949.22950", "10.1109/tvcg.2014.2346984", "10.1017/cbo9780511816772", "10.1109/mcg.2003.1231171", "10.1111/coin.12227", "10.1109/tvcg.2018.2865138", "10.1109/38.788803", "10.1109/tvcg.2018.2864849", "10.1109/mcg.2012.120", "10.1109/tvcg.2007.70535", "10.1162/neco.2008.12-06-420", "10.1109/tvcg.2018.2865240", "10.1089/tmj.2010.0114", "10.1109/beliv.2018.8634267", "10.1109/tvcg.2014.2346481", "10.1207/s15327809jls0402\\_2", "10.1109/tvcg.2006.80", "10.1145/2858036.2858280", "10.1109/tvcg.2017.2674978", "10.1109/tvcg.2011.52", "10.1016/j.cag.2014.03.002", "10.1109/tvcg.2015.2513410", "10.1111/j.1756-8765.2011.01150.x", "10.1109/infvis.2005.1532142", "10.1002/spe.4380211102", "10.1186/s41235-018-0120-9", "10.1073/pnas.1807180116", "10.1109/tvcg.2012.133", "10.1109/tvcg.2012.273", "10.1111/j.1467-8659.2011.01928.x", "10.1145/353485.353486", "10.1109/tvcg.2015.2462356", "10.1109/mcg.2019.2923483", "10.1111/cgf.13264", "10.1057/palgrave.ivs.9500070", "10.1145/1168149.1168158", "10.1109/mcg.2019.2961716", "10.1016/s0167-739x(96)00029-5", "10.1111/j.1467-8659.2009.01667.x", "10.1177/1473871611415989", "10.1109/tvcg.2013.234", "10.1109/iv.2012.33", "10.1111/cgf.13446", "10.1057/ivs.2008.28", "10.1111/cgf.12379", "10.1037/0033-295x.112.1.159", "10.1109/tvcg.2010.161", "10.1109/tvcg.2017.2744319", "10.1145/989863.989880", "10.1007/s11390-016-1663-1", "10.1177/1473871615609787", "10.1016/j.cola.2019.100911"], "wos": 1, "children": [], "len": 1}, {"doi": "10.1109/tvcg.2020.3030395", "title": "Towards Modeling Visualization Processes as Dynamic Bayesian Networks", "year": "2020", "conferenceName": "InfoVis", "authors": "Christian Heine 0002", "citationCount": "0", "affiliation": "Heine, C (Corresponding Author), Univ Leipzig, Leipzig, Germany. Heine, Christian, Univ Leipzig, Leipzig, Germany.", "countries": "Germany", "abstract": "Visualization designs typically need to be evaluated with user studies, because their suitability for a particular task is hard to predict. What the field of visualization is currently lacking are theories and models that can be used to explain why certain designs work and others do not. This paper outlines a general framework for modeling visualization processes that can serve as the first step towards such a theory. It surveys related research in mathematical and computational psychology and argues for the use of dynamic Bayesian networks to describe these time-dependent, probabilistic processes. It is discussed how these models could be used to aid in design evaluation. The development of concrete models will be a long process. Thus, the paper outlines a research program sketching how to develop prototypes and their extensions from existing models, controlled experiments, and observational studies.", "keywords": "Visualization,model building,perception,cognition,dynamic Bayesian networks", "link": "http://dx.doi.org/10.1109/TVCG.2020.3030395", "refList": ["10.1057/ivs.2009.22", "10.1109/tvcg.2015.2467732", "10.1109/infvis.2000.885092", "10.1109/vast.2014.7042482", "10.1145/1498700.1498704", "10.1109/tvcg.2009.108", "10.1109/tvcg.2018.2829750", "10.1037/0033-295x.111.4.1036", "10.1109/tvcg.2012.199", "10.1111/cgf.13899", "10.1109/38.267476", "10.1007/978-3-540-70956-5\\_2", "10.1109/tvcg.2015.2467613", "10.1109/tvcg.2015.2467195", "10.1109/tvcg.2014.2346419", "10.1145/3290605.3300562", "10.1109/vl.1996.545307", "10.1109/vast.2017.8585669", "10.1109/infvis.2003.1249004", "10.1109/tvcg.2010.132", "10.1145/22949.22950", "10.1109/tvcg.2014.2346984", "10.1145/3290605.3300418", "10.1017/cbo9780511816772", "10.1109/mcg.2003.1231171", "10.1111/coin.12227", "10.1109/tvcg.2018.2865138", "10.1109/38.788803", "10.1109/tvcg.2018.2864849", "10.1109/mcg.2012.120", "10.1109/tvcg.2007.70535", "10.1162/neco.2008.12-06-420", "10.1109/tvcg.2018.2865240", "10.1089/tmj.2010.0114", "10.1109/beliv.2018.8634267", "10.1109/tvcg.2014.2346481", "10.1207/s15327809jls0402\\_2", "10.1109/tvcg.2006.80", "10.1145/2858036.2858280", "10.1109/tvcg.2017.2674978", "10.1109/tvcg.2011.52", "10.1016/j.cag.2014.03.002", "10.1109/tvcg.2015.2513410", "10.1111/j.1756-8765.2011.01150.x", "10.1109/infvis.2005.1532142", "10.1002/spe.4380211102", "10.1186/s41235-018-0120-9", "10.1073/pnas.1807180116", "10.1109/tvcg.2012.133", "10.1109/tvcg.2012.273", "10.1111/j.1467-8659.2011.01928.x", "10.1145/353485.353486", "10.1109/tvcg.2015.2462356", "10.1109/mcg.2019.2923483", "10.1111/cgf.13264", "10.1057/palgrave.ivs.9500070", "10.1145/1168149.1168158", "10.1109/mcg.2019.2961716", "10.1016/s0167-739x(96)00029-5", "10.1111/j.1467-8659.2009.01667.x", "10.1177/1473871611415989", "10.1109/tvcg.2013.234", "10.1109/iv.2012.33", "10.1111/cgf.13446", "10.1057/ivs.2008.28", "10.1111/cgf.12379", "10.1037/0033-295x.112.1.159", "10.1017/cb09781139033916.005", "10.1109/tvcg.2010.161", "10.1109/tvcg.2017.2744319", "10.1145/989863.989880", "10.1007/s11390-016-1663-1", "10.1177/1473871615609787", "10.1016/j.cola.2019.100911", "10.1057/palgrave.ivs.9500025"], "wos": 1, "children": [], "len": 1}, {"doi": "10.1109/pacificvis48177.2020.8199", "year": "2020", "title": "Efficient Morphing of Shape-preserving Star Coordinates", "conferenceName": "PacificVis", "authors": "Vladimir Molchanov;Sagad Hamid;Lars Linsen", "citationCount": "0", "affiliation": "Molchanov, V (Corresponding Author), Westfalische Wilhelms Univ Munster, Munster, Germany.\nMolchanov, Vladimir; Hamid, Sagad; Linsen, Lars, Westfalische Wilhelms Univ Munster, Munster, Germany.", "countries": "Germany", "abstract": "Data tours follow an exploratory multi-dimensional data visualization concept that provides animations of projections of the multidimensional data to a 2D visual space. To create an animation, a sequence of key projections is provided and morphings between each pair of consecutive key projections are computed, which then can be stitched together to form the data tour. The morphings should be smooth so that a user can easily follow the transformations, and their computations shall be fast to allow for their integration into an interactive visual exploration process. Moreover, if the key projections are chosen to satisfy additional conditions, it is desirable that these conditions are maintained during morphing. Shape preservation is such a desirable condition, as it avoids shape distortions that may otherwise be caused by a projection. We develop a novel efficient morphing algorithms for computing shape-preserving data tours, i.e., data tours constructed for a sequence of shape-preserving linear projections. We propose a stepping strategy for the morphing to avoid discontinuities in the evolution of the projections, where we represent the linear projections using a star-coordinates system. Our algorithms are less computationally involved, produce smoother morphings, and require less user-defined parameter settings than existing state-of-the-art approaches.", "keywords": "Human-centered computing; Visualization; Visualization techniques", "link": "https://doi.org/10.1109/PacificVis48177.2020.8199", "refList": ["10.2312/eurovisshort.20141152", "10.1109/tvcg.2013.182", "10.1109/tvcg.2008.153", "10.1109/tvcg.2015.2467591", "10.4135/9781412985130", "10.1111/cgf.12878", "10.1016/j.cag.2016.08.007", "10.1080/10618600.1995.10474674", "10.1109/infvis.2003.1249004", "10.1002/9781118445112.stat06472", "10.1109/visual.1997.663916", "10.1111/cgf.12117", "10.1137/0906011", "10.1109/tvcg.2018.2865118", "10.1126/science.290.5500.2319", "10.1111/cgf.12845", "10.1111/j.1467-8659.2012.03125.x", "10.1109/tvcg.2017.2705189", "10.1002/0471725293", "10.1111/cgf.12876", "10.1111/cgf.13404", "10.2307/2289161", "10.1111/cgf.13446", "10.1198/106186008x318440", "10.2307/1390747", "10.1109/tvcg.2012.35", "10.1109/tvcg.2015.2467132", "10.1109/tvcg.2006.94", "10.1109/t-c.1974.224051", "10.1109/pacificvis.2019.00018", "10.1109/tvcg.2017.2744339", "10.1109/tsmcb.2005.850151"], "wos": 1, "children": [], "len": 1}, {"doi": "10.1109/pacificvis.2019.00018", "year": "2019", "title": "Scatterplot Summarization by Constructing Fast and Robust Principal Graphs from Skeletons", "conferenceName": "PacificVis", "authors": "Jos{\\'{e}} Matute;Marcel Fischer;Alexandru C. Telea;Lars Linsen", "citationCount": "1", "affiliation": "Matute, J (Corresponding Author), Univ Munster, Munster, Germany.\nMatute, Jose; Fischer, Marcel; Linsen, Lars, Univ Munster, Munster, Germany.\nTelea, Alexandru C., Univ Groningen, Groningen, Netherlands.", "countries": "Germany;Netherlands", "abstract": "Principal curves are a long-standing and well-known method for summarizing large scatterplots. They are defined as self-consistent curves (or curve sets in the more general case) that locally pass through the middle of the scatterplot data. However, computing principal curves that capture well complex scatterplot topologies and are robust to noise is hard and/or slow for large scatterplots. We present a fast and robust approach for computing principal graphs (a generalization of principal curves for more complex topologies) inspired by the similarity to medial descriptors (curves locally centered in a shape). Compared to state-of-the-art methods for computing principal graphs, we outperform these in terms of computational scalability and robustness to noise and resolution. We also demonstrate the advantages of our method over other scatterplot summarization approaches.", "keywords": "", "link": "https://doi.org/10.1109/PacificVis.2019.00018", "refList": ["10.1016/j.cag.2014.01.006", "10.1016/s0167-8655(02)00032-6", "10.1006/jmva.2000.1917", "10.1111/cgf.12386", "10.1109/vast.2008.4677367", "10.1109/tpami.2004.1261076", "10.1111/cgf.12865", "10.1109/tvcg.2010.213", "10.1109/tvcg.2014.2346455", "10.1109/tvcg.2011.233", "10.1111/j.1467-8659.2009.01680.x", "10.1109/tvcg.2016.2515611", "10.1109/tit.1982.1056489", "10.1109/34.899944", "10.1007/bf01889678", "10.1137/s0036144599352836", "10.1145/2858036.2858155", "10.1002/jhbs.20078", "10.1198/jcgs.2011.09224", "10.1109/tvcg.2017.2744184", "10.1057/ivs.2010.2", "10.1111/j.1467-8659.2012.03107.x", "10.2307/2289936", "10.1109/pacificvis.2014.42", "10.1109/tpami.2008.21", "10.1111/cgf.13446", "10.2307/2290446", "10.1109/34.982884", "10.1109/tvcg.2006.94", "10.2307/2288711", "10.1117/12.304651", "10.5201/ipol.2013.87", "10.1109/mlsp.2008.4685520"], "wos": 1, "children": [{"doi": "10.1109/pacificvis48177.2020.8199", "year": "2020", "title": "Efficient Morphing of Shape-preserving Star Coordinates", "conferenceName": "PacificVis", "authors": "Vladimir Molchanov;Sagad Hamid;Lars Linsen", "citationCount": "0", "affiliation": "Molchanov, V (Corresponding Author), Westfalische Wilhelms Univ Munster, Munster, Germany.\nMolchanov, Vladimir; Hamid, Sagad; Linsen, Lars, Westfalische Wilhelms Univ Munster, Munster, Germany.", "countries": "Germany", "abstract": "Data tours follow an exploratory multi-dimensional data visualization concept that provides animations of projections of the multidimensional data to a 2D visual space. To create an animation, a sequence of key projections is provided and morphings between each pair of consecutive key projections are computed, which then can be stitched together to form the data tour. The morphings should be smooth so that a user can easily follow the transformations, and their computations shall be fast to allow for their integration into an interactive visual exploration process. Moreover, if the key projections are chosen to satisfy additional conditions, it is desirable that these conditions are maintained during morphing. Shape preservation is such a desirable condition, as it avoids shape distortions that may otherwise be caused by a projection. We develop a novel efficient morphing algorithms for computing shape-preserving data tours, i.e., data tours constructed for a sequence of shape-preserving linear projections. We propose a stepping strategy for the morphing to avoid discontinuities in the evolution of the projections, where we represent the linear projections using a star-coordinates system. Our algorithms are less computationally involved, produce smoother morphings, and require less user-defined parameter settings than existing state-of-the-art approaches.", "keywords": "Human-centered computing; Visualization; Visualization techniques", "link": "https://doi.org/10.1109/PacificVis48177.2020.8199", "refList": ["10.2312/eurovisshort.20141152", "10.1109/tvcg.2013.182", "10.1109/tvcg.2008.153", "10.1109/tvcg.2015.2467591", "10.4135/9781412985130", "10.1111/cgf.12878", "10.1016/j.cag.2016.08.007", "10.1080/10618600.1995.10474674", "10.1109/infvis.2003.1249004", "10.1002/9781118445112.stat06472", "10.1109/visual.1997.663916", "10.1111/cgf.12117", "10.1137/0906011", "10.1109/tvcg.2018.2865118", "10.1126/science.290.5500.2319", "10.1111/cgf.12845", "10.1111/j.1467-8659.2012.03125.x", "10.1109/tvcg.2017.2705189", "10.1002/0471725293", "10.1111/cgf.12876", "10.1111/cgf.13404", "10.2307/2289161", "10.1111/cgf.13446", "10.1198/106186008x318440", "10.2307/1390747", "10.1109/tvcg.2012.35", "10.1109/tvcg.2015.2467132", "10.1109/tvcg.2006.94", "10.1109/t-c.1974.224051", "10.1109/pacificvis.2019.00018", "10.1109/tvcg.2017.2744339", "10.1109/tsmcb.2005.850151"], "wos": 1, "children": [], "len": 1}], "len": 3}, {"doi": "10.1111/cgf.13684", "year": "2019", "title": "ClustMe: A Visual Quality Measure for Ranking Monochrome Scatterplots based on Cluster Patterns", "conferenceName": "EuroVis", "authors": "Mostafa M. Abbas;Micha{\\\"{e}}l Aupetit;Michael Sedlmair;Halima Bensmail", "citationCount": "4", "affiliation": "Abbas, MM (Corresponding Author), HBKU, QCRI, Doha, Qatar.\nAbbas, Mostafa M.; Aupetit, Michael; Bensmail, Halima, HBKU, QCRI, Doha, Qatar.\nSedlmair, Michael, Univ Stuttgart, VISUS, Stuttgart, Germany.", "countries": "Qatar;Germany", "abstract": "We propose ClustMe, a new visual quality measure to rank monochrome scatterplots based on cluster patterns. ClustMe is based on data collected from a human-subjects study, in which 34 participants judged synthetically generated cluster patterns in 1000 scatterplots. We generated these patterns by carefully varying the free parameters of a simple Gaussian Mixture Model with two components, and asked the participants to count the number of clusters they could see (1 or more than 1). Based on the results, we form ClustMe by selecting the model that best predicts these human judgments among 7 different state-of-the-art merging techniques (Demp). To quantitatively evaluate ClustMe, we conducted a second study, in which 31 human subjects ranked 435 pairs of scatterplots of real and synthetic data in terms of cluster patterns complexity. We use this data to compare ClustMe's performance to 4 other state-of-the-art clustering measures, including the well-known Clumpiness scagnostics. We found that of all measures, ClustMe is in strongest agreement with the human rankings.", "keywords": "", "link": "https://doi.org/10.1111/cgf.13684", "refList": ["10.1109/tvcg.2014.2330617", "10.1109/tvcg.2014.2346979", "10.1109/tvcg.2017.2744138", "10.1109/tvcg.2017.2701829", "10.2307/2529310", "10.1109/tvcg.2011.229", "10.1109/vast.2011.6102437", "10.1068/p030033", "10.1016/j.jvcir.2011.01.005", "10.1109/tnn.2005.845141", "10.1145/2669557.2669559", "10.1167/8.7.6", "10.1145/2993901.2993907", "10.1145/2803140.2803143", "10.1145/1842993.1843002", "10.1109/pacificvis.2016.7465244", "10.1109/tvcg.2013.124", "10.1057/ivs.2008.13", "10.1109/vast.2012.6400488", "10.1111/j.1467-9574.2008.00412.x", "10.1214/aos/1176344136", "10.1109/tvcg.2015.2467671", "10.3138/y308-2422-8615-1233", "10.1111/j.1467-8659.2012.03125.x", "10.1177/001316446002000104", "10.1145/2858036.2858155", "10.1007/s11634-010-0058-3", "10.1214/009053605000000417", "10.1109/tvcg.2009.153", "10.1023/a:1018510926151", "10.1109/tvcg.2014.2346978", "10.1007/s10816-016-9307-x", "10.1177/0301006615602599", "10.1109/pacificvis.2014.42", "10.1162/neco.1991.3.2.246", "10.1007/3-540-44491-2\\_3", "10.1109/tvcg.2013.153", "10.1111/cgf.13446", "10.1109/tvcg.2018.2846735", "10.2307/2291604", "10.1109/inf0vis.2005.14", "10.1198/016214502760047131", "10.1007/s00180-008-0119-7", "10.1109/t-c.1974.224051", "10.1111/cgf.12632", "10.1109/tvcg.2017.2744339", "10.1111/j.1467-8659.2009.01694.x"], "wos": 1, "children": [{"doi": "10.1109/tvcg.2019.2934796", "title": "Improving the Robustness of Scagnostics", "year": "2019", "conferenceName": "InfoVis", "authors": "Yunhai Wang;Zeyu Wang 0005;Tingting Liu;Michael Correll;Zhanglin Cheng;Oliver Deussen;Michael Sedlmair", "citationCount": "1", "affiliation": "Wang, YH (Corresponding Author), Shandong Univ, Jinan, Peoples R China. Wang, Yunhai; Wang, Zeyu; Liu, Tingting, Shandong Univ, Jinan, Peoples R China. Wang, Zeyu; Cheng, Zhanglin; Deussen, Oliver, SIAT, Shenzhen VisuCA Key Lab, Shenzhen, Peoples R China. Correll, Michael, Tableau Res, Seattle, WA USA. Deussen, Oliver, Konstanz Univ, Constance, Germany. Sedlmair, Michael, Univ Stuttgart, VISUS, Stuttgart, Germany.", "countries": "USA;Germany;China", "abstract": "In this paper, we examine the robustness of scagnostics through a series of theoretical and empirical studies. First, we investigate the sensitivity of scagnostics by employing perturbing operations on more than 60M synthetic and real-world scatterplots. We found that two scagnostic measures, Outlying and Clumpy, are overly sensitive to data binning. To understand how these measures align with human judgments of visual features, we conducted a study with 24 participants, which reveals that i) humans are not sensitive to small perturbations of the data that cause large changes in both measures, and ii) the perception of clumpiness heavily depends on per-cluster topologies and structures. Motivated by these results, we propose Robust Scagnostics (RScag) by combining adaptive binning with a hierarchy-based form of scagnostics. An analysis shows that RScag improves on the robustness of original scagnostics, aligns better with human judgments, and is equally fast as the traditional scagnostic measures.", "keywords": "Scagnostics,scatterplots,sensitivity analysis,Robust Scagnostics", "link": "http://dx.doi.org/10.1109/TVCG.2019.2934796", "refList": ["10.1057/palgrave.ivs.9500122", "10.1109/tvcg.2014.2346979", "10.1111/j.1467-8659.2009.01467.x", "10.1109/vast.2008.4677368", "10.2307/2289444", "10.1109/tvcg.2011.229", "10.1109/iv.2004.1320207", "10.1109/vast.2009.5332628", "10.1111/insr.12095\\_11", "10.1109/tvcg.2010.184", "10.1109/tvcg.2015.2467323", "10.1109/vast.2010.5652460", "10.1111/j.1467-8659.2012.03069.x", "10.1145/1842993.1843002", "10.1198/106186008x320465", "10.1109/pacificvis.2016.7465244", "10.1109/tvcg.2013.20", "10.1111/cgf.12641", "10.1109/tvcg.2012.128", "10.1109/tvcg.2015.2467671", "10.1057/palgrave.ivs.9500091", "10.1007/978-1-4612-4400-4", "10.1111/cgf.13176", "10.1002/0470870958", "10.1109/tvcg.2018.2864907", "10.1111/j.1467-8659.2012.03125.x", "10.1109/vast.2012.6400490", "10.1109/infvis.2005.1532142", "10.1109/vast.2010.5652433", "10.1109/vast.2009.5332611", "10.1201/9781315140919", "10.1145/2858036.2858155", "10.1109/ldav.2013.6675164", "10.1515/itit-2014-1070", "10.1111/cgf.13684", "10.1109/tpami.1979.4766909", "10.2307/2289936", "10.1109/pacificvis.2014.42", "10.1109/tvcg.2016.2598467", "10.1109/tvcg.2013.153", "10.1111/cgf.13446", "10.1109/tvcg.2006.94", "10.1109/tvcg.2014.2346572", "10.1111/cgf.12632", "10.1109/tvcg.2017.2744339"], "wos": 1, "children": [], "len": 1}, {"doi": "10.1109/tvcg.2020.3030365", "title": "Modeling the Influence of Visual Density on Cluster Perception in Scatterplots Using Topology", "year": "2020", "conferenceName": "InfoVis", "authors": "Ghulam Jilani Quadri;Paul Rosen", "citationCount": "0", "affiliation": "Quadri, GJ (Corresponding Author), Univ S Florida, Tampa, FL 33620 USA. Quadri, Ghulam Jilani; Rosen, Paul, Univ S Florida, Tampa, FL 33620 USA.", "countries": "USA", "abstract": "Scatterplots are used for a variety of visual analytics tasks, including cluster identification, and the visual encodings used on a scatterplot play a deciding role on the level of visual separation of clusters. For visualization designers, optimizing the visual encodings is crucial to maximizing the clarity of data. This requires accurately modeling human perception of cluster separation, which remains challenging. We present a multi-stage user study focusing on four factors-distribution size of clusters, number of points, size of points, and opacity of points-that influence cluster identification in scatterplots. From these parameters, we have constructed two models, a distance-based model, and a density-based model, using the merge tree data structure from Topological Data Analysis. Our analysis demonstrates that these factors play an important role in the number of clusters perceived, and it verifies that the distance-based and density-based models can reasonably estimate the number of clusters a user observes. Finally, we demonstrate how these models can be used to optimize visual encodings on real-world data.", "keywords": "Scatterplot,clustering,perception,empirical evaluation,visual encoding,crowdsourcing,topological data analysis", "link": "http://dx.doi.org/10.1109/TVCG.2020.3030365", "refList": ["10.1109/tvcg.2017.2744359", "10.1145/1778765", "10.1109/tvcg.2019.2934799", "10.1111/cgf.12889", "10.1109/tvcg.2011.127", "10.1111/cgf.13444", "10.1145/1964897.1964910", "10.1167/8.7.6", "10.1145/3173574.3173991", "10.1145/1556262.1556289", "10.1145/1056808.1056914", "10.2307/2288400", "10.1109/tvcg.2014.2346594", "10.1109/iv.2002.1028760", "10.1177/001316447303300111", "10.1007/bf02289823", "10.1109/tvcg.2017.2744339", "10.1111/j.1467-8659.2009.01694.x", "10.1109/tvcg.2014.2346979", "10.1090/mbk/069", "10.1109/tvcg.2013.65", "10.1109/mcg.2012.37", "10.1109/pacificvis.2010.5429604", "10.1002/acp.2350050106", "10.1109/infvis.2005.1532136", "10.1177/1473871612465214", "10.1109/tvcg.2017.2674978", "10.1002/jhbs.20078", "10.1007/978-3-642-35142-6\\_14", "10.1007/978-3-319-71507-0", "10.1109/mcg.201.7.6", "10.3758/bf03193961", "10.1364/josa.49.000280", "10.1145/3025453.3025905", "10.1109/tvcg.201.9.2934541", "10.1109/tvcg.2018.2829750", "10.1177/1473871615606187", "10.1111/cgf.13408", "10.1109/pacificvis.2016.7465252", "10.1109/pacificvis.2016.7465244", "10.1109/inevis.2005.1532142", "10.1111/cgf.13414", "10.1111/j.1467-8659.2012.03125.x", "10.1167/16.5.11", "10.1109/infvis.2005.1532142", "10.1145/2858036.2858155", "10.1038/nmeth1210-941", "10.1177/1473871616638892", "10.1109/tcbb.2014.2306840", "10.1111/cgf.13684", "10.1177/0301006615602599", "10.1214/aoms/1177731915", "10.1145/2702123.2702585", "10.1109/tvcg.2013.183", "10.1109/tvcg.2014.2346572", "10.1109/tvcg.2018.2875702", "10.1109/tvcg.2017.2754480", "10.1109/vast.2014.7042493", "10.1057/palgrave.ivs.9500122", "10.1109/tvcg.2014.2330617", "10.1109/tvcg.2019.2934541", "10.1068/p030033", "10.1140/epjds/s13688-017-0109-5", "10.1201/b17511", "10.1016/s0925-7721(02)00093-7", "10.1109/pacificvis.2012.6183557", "10.1109/tvcg.2014.2346983", "10.1109/5.726791", "10.1080/01621459.1926.10502165", "10.1109/tvcg.2007.70535", "10.1109/tvcg.2018.2864907", "10.1111/cgf.12109", "10.1109/tvcg.2017.2744184", "10.1146/annurev-statistics-031017-100045", "10.1111/cgf.13409", "10.1145/3002151.3002162", "10.1016/s0378-4371(98)00494-4", "10.3138/y308-2422-8615-1233", "10.1111/cgf.12632", "10.1145/3290605.3300771"], "wos": 1, "children": [], "len": 1}, {"doi": "10.1111/cgf.14034", "year": "2020", "title": "The State of the Art in Enhancing Trust in Machine Learning Models with the Use of Visualizations", "conferenceName": "EuroVis", "authors": "Angelos Chatzimparmpas;Rafael Messias Martins;Ilir Jusufi;Kostiantyn Kucher;Fabrice Rossi;Andreas Kerren", "citationCount": "2", "affiliation": "Chatzimparmpas, A (Corresponding Author), Linnaeus Univ, Dept Comp Sci \\& Media Technol, Vaxjo, Sweden.\nChatzimparmpas, A.; Martins, R. M.; Jusufi, I.; Kucher, K.; Kerren, A., Linnaeus Univ, Dept Comp Sci \\& Media Technol, Vaxjo, Sweden.\nRossi, F., PSL Univ, Univ Paris Dauphine, Ceremade, Paris, France.", "countries": "Sweden;France", "abstract": "Machine learning (ML) models are nowadays used in complex applications in various domains, such as medicine, bioinformatics, and other sciences. Due to their black box nature, however, it may sometimes be hard to understand and trust the results they provide. This has increased the demand for reliable visualization tools related to enhancing trust in ML models, which has become a prominent topic of research in the visualization community over the past decades. To provide an overview and present the frontiers of current research on the topic, we present a State-of-the-Art Report (STAR) on enhancing trust in ML models with the use of interactive visualization. We define and describe the background of the topic, introduce a categorization for visualization techniques that aim to accomplish this goal, and discuss insights and opportunities for future research directions. Among our contributions is a categorization of trust against different facets of interactive ML, expanded and improved from previous research. Our results are investigated from different analytical perspectives: (a) providing a statistical overview, (b) summarizing key findings, (c) performing topic analyses, and (d) exploring the data sets used in the individual papers, all with the support of an interactive web-based survey browser. We intend this survey to be beneficial for visualization researchers whose interests involve making ML models more trustworthy, as well as researchers and practitioners from other disciplines in their search for effective visualization techniques suitable for solving their tasks with confidence and conveying meaning to their data.", "keywords": "trustworthy machine learning; visualization; interpretable machine learning; explainable machine learning", "link": "https://doi.org/10.1111/cgf.14034", "refList": ["10.1109/mcg.2018.2878902", "10.1109/tvcg.2008.153", "10.2312/mlvis.20181130", "10.1109/tvcg.2016.2598828", "10.1145/3290605.3300911", "10.1145/2993901.2993909", "10.2312/mlvis.20191158", "10.1109/tvcg.2016.2598446", "10.1111/j.1467-8659.2009.01475.x", "10.1145/3290605.3300809", "10.1109/pacificvis.2018.00031", "10.1055/s-0029-1216348", "10.1007/978-3-319-90403-0\\_13", "10.1109/tvcg.2017.2745085", "10.1111/j.1467-8659.2011.01938.x", "10.1007/978-3-319-54024-5\\_6", "10.1016/s0167-9473(01)00065-2", "10.1111/cgf.12895", "10.2312/eurovisshort.20141152.17", "10.2312/eurova.20151098.22", "10.1111/cgf.13667", "10.3115/1072228.1072378", "10.1109/tbdata.2018.2877350.16", "10.1109/lars.2009.5418323.25", "10.1109/tvcg.2017.2744878", "10.1016/j.combustflame.2005.09.018", "10.1016/j.cag.2014.01.006", "10.1109/tvcg.2016.2570755", "10.2312/mlvis.20191158.1,19", "10.1518/hfes.46.1.50.30392", "10.1145/3301275.3302280", "10.1145/3351095.3372834.1", "10.1016/s0377-2217(01)00264-8", "10.1111/cgf.13424", "10.1007/978-3-319-23485-4\\_53", "10.1007/978-94-007-0753-5\\_3623", "10.1109/tvcg.2013.101", "10.1111/cgf.12884", "10.1111/j.1467-8659.2010.01835.x", "10.1021/ci9901338", "10.4230/lipics.itcs:2017", "10.1109/mis.2013.24", "10.1109/tvcg.2014.2346482", "10.1109/tvcg.2018.2865230", "10.1073/pnas.1807180116", "10.1109/dsaa.2018.00018", "10.1109/tvcg.2009.153", "10.3115/1219840.1219855", "10.1109/tvcg.2018.2864812", "10.1109/tvcg.2018.2872577", "10.2312/trvis.20191183", "10.1109/cvpr:2004.383", "10.1109/vast.2008.4677350", "10.1145/302979.303001", "10.1109/tvcg.2018.2864499", "10.1111/cgf.13672", "10.1109/tvcg.2014.2346626", "10.23915/distill.00010.18", "10.1109/tvcg.2017.2744805", "10.2312/mlvis:20191160.18", "10.23915/distill:00016", "10.1109/pacificvis.2016.7465260", "10.1111/cgf.13683", "10.23915/distill.00016.19", "10.1145/32906053.300803.22", "10.1109/tvcg.2014.2346574", "10.1177/1473871615600010", "10.1109/tvcg.2016.2598831", "10.1145/3230623", "10.1109/visual.2019.8933744", "10.1145/2993901.2993915", "10.1016/j.visinf.2017.01.006", "10.1145/2993901.2993914", "10.1109/tvcg.2014.2346984", "10.1109/5.726791", "10.23915/distill.00010", "10.1109/tvcg.2018.2864825", "10.2307/2394164", "10.1109/tvcg.2017.2744458", "10.1145/2993901.2993917.28", "10.1111/cgf.13711", "10.1109/tvcg.2016.2598664", "10.2307/2530428", "10.1109/icdar.1997.620583", "10.1109/tvcg.2017.2744718", "10.1111/cgf.13425", "10.1109/tvcg.2019.2903943", "10.1145/1518701.1518895", "10.1109/tvcg.2018.2864838", "10.1145/62038.62043", "10.1111/j.1467-8659.2011.01920.x", "10.1145/3025171.3025208", "10.1145/355112.355124", "10.1109/vast.2010.5652398", "10.1109/tvcg.2014.2346578", "10.1145/3173574.3174209", "10.4178/epih/e2014008", "10.1109/beliv.2018.8634201.25,28", "10.1016/j.eswa.2007.12.020", "10.1111/cgf:13406", "10.1109/mcg.2011.103", "10.1631/fitee.1700808", "10.1109/tvcg.2017.2745158", "10.1073/pnas.0307752101", "10.1109/tvcg.2018.2816223", "10.1109/tvcg.2017.2745141", "10.1145/32232.32234", "10.1109/tvcg.2019.2934267", "10.1109/tvcg.2018.2864477", "10.1145/3132169", "10.2312/eurova.20151100.19", "10.1145/3172944.3172964", "10.1145/2601248.2601268", "10.1109/isai-nlp.2018.8693002.1", "10.1111/cgf.13404", "10.1007/s100320200071", "10.2312/trvis.20191183.16", "10.1111/cgf.12755", "10.1145/2702123.2702509", "10.1145/1401890.1402008.25", "10.1109/tvcg.2012.65", "10.1177/1473871617733996", "10.2312/trvis.20191187.7", "10.21236/ada273556", "10.1109/vast.2010.5652450", "10.1111/j.1467-8659.2011.01940.x", "10.1177/875647939000600106", "10.1109/tvcg.2017.2711030", "10.1016/j.immuni.2016.04.014", "10.1109/tvcg.2019.2934209", "10.1016/0095-0696(78)90006-2", "10.1016/j.jclinepi.2015.04.014", "10.1016/j.ress.2013.02.013", "10.1111/cgf.12640", "10.1145/1015330.1015388.25", "10.1111/j.1467-8659.2009.01468.x", "10.1145/1541880.1541882", "10.1109/vast.2011.6102453", "10.1016/s0008-8846(98)00165-3", "10.2312/trvis.20191186.7", "10.1007/s13748-013-0040-3", "10.1109/tvcg.2015.2467757", "10.1109/tbdata.2018.2877350", "10.1109/vast.2017.8585613", "10.1080/10556789208805504", "10.1109/vast.2012.6400484", "10.1145/3025171.3025181", "10.1007/978-3-319-90403-0\\_12", "10.1109/mcg.2019.2922592", "10.1021/ci000392t", "10.1109/vast.2007.4389000", "10.1111/cgf.13406.16", "10.1111/cgf.13684", "10.2312/eurovisshort.20161166.17", "10.2312/evs:20191168", "10.1145/3041021.3055135", "10.1145/3301275.3302265", "10.1613/jair.4135", "10.1109/tvcg.2018.2864500", "10.1109/tvcg.2017.2744158", "10.1109/ssci.2015.33", "10.1111/cgf.13453", "10.2312/pe/eurovast/eurova11/049-052", "10.1145/3025171.3025181.13", "10.1145/371920.372094", "10.1109/tvcg.2017.2744938", "10.1111/j.1467-8659.2012.03108.x", "10.1109/tvcg.2019.2934251", "10.1145/3290605.3300809.18", "10.1109/ldav.2016.7874305", "10.1109/vast.2016.7883514", "10.1109/iccv.2015.425", "10.1145/3301275.3302324", "10.1109/tnnls.2013.2292894", "10.1109/tvcg.2018.2865044", "10.1109/tvcg.2013.157", "10.1371/journal.pcbi.0020161", "10.1186/s12916-019-1426-2", "10.1109/10.867928", "10.1111/cgf.13217", "10.1109/mcg.2019.2919033", "10.1145/2993901.2993910", "10.1109/tvcg.2017.2744738", "10.2307/258792", "10.1111/cgf.12655", "10.1016/j.dss.2014.03.001", "10.1109/tvcg.2019.2904069", "10.1111/cgf.13205", "10.1002/mds.22340", "10.1109/tvcg.2019.2934595", "10.1287/inte.2018.0957", "10.1109/cvpr.2007.382974", "10.1109/tvcg.2012.280", "10.1145/2678025.2701399.13", "10.2312/mlvis.20181130.13", "10.2312/eurova.20181106.16", "10.1109/tvcg.2018.2864475", "10.2312/mlvis.20191160.18,22", "10.1007/978-1-4612-4026-6.25", "10.1109/cvpr.2006.42", "10.1145/3172944.3172950", "10.1109/cvpr.2004.383.25", "10.1109/tvcg.2019.2934812", "10.1609/aimag.v35i4.2513", "10.2312/trvis.20191185.7", "10.1111/j.1467-8659.2009.01684.x", "10.1371/journal.pone.0129126", "10.1111/cgf.13092", "10.1162/coli\\_a\\_00237", "10.1109/tvcg.2017.2744818", "10.1109/vast.2011.6102448", "10.1109/tvcg.2009.111", "10.1109/tvcg.2019.2934619", "10.1016/s0377-2217(01)00264-8.25", "10.1111/cgf.12639", "10.1109/access.2019.2919343", "10.1186/s12874-019-0681-4", "10.1109/pacificvis.2015.7156366", "10.1109/pacificvis.2018.00029", "10.1109/tvcg.2019.2934261", "10.1080/13506280444000102.http://www.uvt.nl/ticc", "10.1109/vast.2018.8802509", "10.1111/cgf.13212", "10.1145/3200489", "10.1111/cgf.13176", "10.1177/1473871620904671", "10.1007/978-3-319-10590-1\\_53", "10.1111/j.1467-8659.2012.03126.x", "10.1111/cgf.13172", "10.1145/3025171.3025208.6,21", "10.1111/cgf.12366", "10.1109/tvcg.2019.2934659", "10.1109/cvprw.2009.5206848", "10.1016/j.media.2014.11.010", "10.1109/tvcg.2017.2744683", "10.1109/tvcg.2019.2934262", "10.1016/j.neucom.2006.11.018", "10.1177/1473871615571951", "10.1371/journal.pcbi.0020161.25", "10.1177/1473871611415994", "10.2312/trvis20191187", "10.2312/eurova", "10.1145/2858036.2858529", "10.1145/2207676.2207738", "10.1007/s11042-009-0417-2", "10.1145/3301275.3302317", "10.1038/s41746-019-0148-3", "10.1145/3351095.3372834", "10.1080/10691898.2011.11889627", "10.1109/tvcg.2018.2864504", "10.1109/vast.2017.8585720", "10.1109/mcg.2018.053491732", "10.1007/s10994-010-5207-6", "10.1109/tvcg.2019.2934433", "10.1016/j.cag.2017.05.005", "10.1109/tvcg.2012.279", "10.1145/3231622.3231641.19,20", "10.1145/1562849.1562851", "10.1007/11564126\\_", "10.1109/tvcg.2018.2846735", "10.3115/1225403.1225421", "10.1109/vast.2012.6400486", "10.2312/eurova.20191116.22", "10.1109/tvcg.2007.70443", "10.1080/027868291009242", "10.2312/eurova.20151100", "10.1145/2939502.2939503.19", "10.1016/j.cag.2014.02.004", "10.1145/2939672.2939778", "10.1109/vast.2010.5652484", "10.1111/cgf.12641", "10.1145/3301275.3302289", "10.1109/visual.2019.8933619", "10.1109/tvcg.2017.2672987", "10.1109/vast.2016.7883517.20", "10.1109/igarss.2017.8127684", "10.1016/j.jcae.2010.04.002", "10.1109/vast.2010.5652885", "10.1016/j.visinf.2019.03.002", "10.1007/s00371-018-1500-3", "10.1109/mcg.2018.042731661", "10.1109/34.598228", "10.1109/tvcg.2018.2865027", "10.1016/j.neucom.2017.01.105", "10.1111/cgf.12389", "10.1109/tvcg.2019.2934591", "10.1109/vast.2010.5652392.16", "10.1111/cgf.13416", "10.1080/02701367.1992.10608764", "10.1109/vast.2017.8585721", "10.1109/tvcg.2018.2843369", "10.1109/sbes.2010.27", "10.1109/vast.2015.7347637", "10.1145/1401890.1402008", "10.1016/j.bpj.2010.04.064", "10.1109/tvcg.2013.125", "10.1109/isai-nlp.2018.8693002", "10.1371/journal.pone.0160127", "10.1145/2856767.2856779", "10.1145/2678025.2701399", "10.1109/vast.2011.6102451", "10.1109/mcg.2010.18", "10.1021/ci4000213", "10.1109/vast.2012.6400492", "10.1007/11564126-49.25", "10.2312/eurova.20171114", "10.1109/vast.2010.5652443", "10.1145/3134599", "10.2312/pe/eurovast/eurovast10/013-018.19", "10.1109/tvcg.2019.2903946", "10.1109/tvcg.2015.2467717", "10.1177/1473871612460526", "10.1016/j.cag.2018.09.018", "10.1109/tvcg.2016.2598838", "10.1145/3172944.3172964.14", "10.1109/vast.2009.5333428", "10.1109/vast.2014.7042480", "10.2312/pe/eurovast/eurovast10/013-018", "10.1177/0962280215588241", "10.1145/2993901.2993917", "10.1109/cvpr.2008:4587581", "10.1109/tvcg.2015.2467551", "10.1016/j.visinf.2018.09.001", "10.1126/science.290.5500.2319", "10.2312/eurova.20151107", "10.1109/visual.2019.8933695", "10.13140/2.1.2393.1847", "10.1197/jamia.m1929", "10.1109/cvpr.2008.4587581.25", "10.1145/1518701.1518895.16", "10.1109/vds.2017.8573444", "10.2312/trvis:20191185", "10.1145/3359786", "10.13140/2.1.1341.1520", "10.2312/pe/eurovast/eurova11/049-052.17", "10.1109/tvcg.2014.2346660", "10.1145/3185517", "10.1109/adprl.2011.5967372", "10.1109/tvcg.2015.2467591", "10.1111/j.1751-9004.2009.00232.x", "10.1136/qshc.2004.010033", "10.1109/vast.2012.6400493", "10.1109/tvcg.2019.2934266", "10.1145/2971763.2971775", "10.1111/cgf.13730", "10.1109/vast.2012.6400488", "10.1111/cgf.13210", "10.1109/tvcg.2019.2934631", "10.1145/3172944.3172965", "10.1057/ivs.2010.2", "10.1109/tvcg.2017.2745258", "10.1016/j.jbusres.2019.07.039", "10.1162/jmlr.2003.3.4-5.993", "10.1109/pacificvis.2019.00044", "10.2312/pe/eurovast/eurova12/037-041", "10.1109/tvcg.2019.2934629", "10.1177/0018720814547570", "10.1145/3292500.3330908", "10.1111/j.1467-8659.2009.01467.x", "10.2312/eurova.20151098", "10.1177/1473871617713337", "10.1109/lars:2009.5418323", "10.1109/vast.2011.6102437", "10.1111/cgf.12878", "10.1561/1500000001", "10.1145/3025171.3025222", "10.1007/s11704-016-6028-y", "10.1016/j.procs.2017.05.216", "10.1109/cvpr.2007.382974.25", "10.1080/10447318.2020.1741118", "10.1109/vast.2012.6400489", "10.1145/3025171.3025172", "10.1109/tvcg.2017.2744098", "10.1109/tvcg.2005.66", "10.1016/j.dss.2009.05.016", "10.1007/978-1-4612-4026-6", "10.2312/evs.20191168.16,20,28", "10.2312/pe/eurovast/eurova12/037-041.17", "10.1145/3290605.3300803", "10.1145/1015330.1015388", "10.1111/cgf.13197", "10.1016/b978-1-55860-377-6.50048-7", "10.1111/cgf.13681", "10.1109/tvcg.2017.2744378", "10.1109/tvcg.2017.2744358", "10.1109/vast.2008.4677352"], "wos": 1, "children": [{"doi": "10.1109/tvcg.2020.3030368", "title": "Implicit Multidimensional Projection of Local Subspaces", "year": "2020", "conferenceName": "InfoVis", "authors": "Rongzheng Bian;Yumeng Xue;Liang Zhou;Jian Zhang 0070;Baoquan Chen;Daniel Weiskopf;Yunhai Wang", "citationCount": "1", "affiliation": "Wang, YH (Corresponding Author), Shandong Univ, Qingdao, Peoples R China. Zhou, L (Corresponding Author), Univ Utah, Salt Lake City, UT 84112 USA. Bian, Rongzheng; Xue, Yumeng; Wang, Yunhai, Shandong Univ, Qingdao, Peoples R China. Chen, Baoquan, Peking Univ, Beijing, Peoples R China. Zhang, Jian, Chinese Acad Sci, CNIC, Beijing, Peoples R China. Zhou, Liang, Univ Utah, Salt Lake City, UT 84112 USA. Weiskopf, Daniel, Univ Stuttgart, Stuttgart, Germany.", "countries": "USA;Germany;China", "abstract": "We propose a visualization method to understand the effect of multidimensional projection on local subspaces, using implicit function differentiation. Here, we understand the local subspace as the multidimensional local neighborhood of data points. Existing methods focus on the projection of multidimensional data points, and the neighborhood information is ignored. Our method is able to analyze the shape and directional information of the local subspace to gain more insights into the global structure of the data through the perception of local structures. Local subspaces are fitted by multidimensional ellipses that are spanned by basis vectors. An accurate and efficient vector transformation method is proposed based on analytical differentiation of multidimensional projections formulated as implicit functions. The results are visualized as glyphs and analyzed using a full set of specifically-designed interactions supported in our efficient web-based visualization tool. The usefulness of our method is demonstrated using various multi- and high-dimensional benchmark datasets. Our implicit differentiation vector transformation is evaluated through numerical comparisons; the overall method is evaluated through exploration examples and use cases.", "keywords": "High-dimensional data visualization,dimensionality reduction,local linear subspaces,user interaction", "link": "http://dx.doi.org/10.1109/TVCG.2020.3030368", "refList": ["10.3844/jcssp.2018.613.622", "10.1016/j.aci.2018.08.003", "10.3390/info9030065", "10.1016/j.visinf.2018.09.003", "10.1371/journal.pone.0118432", "10.1016/s0893-6080(05)80023-1", "10.1109/tvcg.2020.2986996", "10.1109/icst.2012.56", "10.1007/s10844-013-0250-y", "10.1109/tbdata.2018", "10.1145/1125451.1125659", "10.1109/tvcg.2013.125", "10.1177/1473871611412817", "10.1145/3290605.3300911", "10.1111/cgf.14034", "10.1007/s13721-013-0034-x", "10.1016/j.procs.2017.05.216", "10.1016/j.ins.2009.08.025", "10.1109/tvcg.2013.124", "10.1109/tvcg.2018.2864499", "10.1109/tvcg.2018.2864475", "10.1080/10447318.2020.1741118", "10.1016/j.imu.2019.100203", "10.1109/tvcg.2018.2865240", "10.1186/s12864-019-6413-7", "10.1109/tvcg.2015.2467551", "10.1002/widm.1249", "10.1007/978-3-319-66429-3\\_29", "10.1109/tvcg.2014.2346481", "10.1109/tvcg.2018.2864825", "10.1177/1473871620904671", "10.1109/tvcg.2019.2934267", "10.1136/bmjopen-2016-012799", "10.1109/smartgridcomm.2017.8340682", "10.1007/s10664-015-9401-9", "10.1145/1143844.1143874", "10.1111/cgf.12389", "10.1109/tvcg.2018.2872577", "10.1007/978-981-13-5802-9\\_20", "10.1016/j.ipm.2009.03.002", "10.5220/0006431602160222", "10.1109/mcg.2015.50", "10.1109/tvcg.2014.2346574", "10.1007/bf02289565", "10.1109/tvcg.2017.2744378", "10.1016/j.patrec.2008.08.010", "10.1023/a:1010933404324", "10.9735/2229-3981"], "wos": 1, "children": [], "len": 1}, {"doi": "10.1109/tvcg.2020.3030465", "title": "Visual Causality Analysis of Event Sequence Data", "year": "2020", "conferenceName": "VAST", "authors": "Zhuochen Jin;Shunan Guo;Nan Chen;Daniel Weiskopf;David Gotz;Nan Cao", "citationCount": "0", "affiliation": "Cao, N (Corresponding Author), Tongji Univ, IDVx Lab, Shanghai, Peoples R China. Jin, Zhuochen; Guo, Shunan; Chen, Nan; Cao, Nan, Tongji Univ, IDVx Lab, Shanghai, Peoples R China. Weiskopf, Daniel, Univ Stuttgart, Stuttgart, Germany. Gotz, David, Univ N Carolina, Chapel Hill, NC 27515 USA.", "countries": "USA;Germany;China", "abstract": "Causality is crucial to understanding the mechanisms behind complex systems and making decisions that lead to intended outcomes. Event sequence data is widely collected from many real-world processes, such as electronic health records, web clickstreams, and financial transactions, which transmit a great deal of information reflecting the causal relations among event types. Unfortunately, recovering causalities from observational event sequences is challenging, as the heterogeneous and high-dimensional event variables are often connected to rather complex underlying event excitation mechanisms that are hard to infer from limited observations. Many existing automated causal analysis techniques suffer from poor explainability and fail to include an adequate amount of human knowledge. In this paper, we introduce a visual analytics method for recovering causalities in event sequence data. We extend the Granger causality analysis algorithm on Hawkes processes to incorporate user feedback into causal model refinement. The visualization system includes an interactive causal analysis framework that supports bottom-up causal exploration, iterative causal verification and refinement, and causal comparison through a set of novel visualizations and interactions. We report two forms of evaluation: a quantitative evaluation of the model improvements resulting from the user-feedback mechanism, and a qualitative evaluation through case studies in different application domains to demonstrate the usefulness of the system.", "keywords": "Event sequence data,causality analysis,visual analytics", "link": "http://dx.doi.org/10.1109/TVCG.2020.3030465", "refList": ["10.5555/1642718", "10.1109/tvcg.2018.2865022", "10.5555/2074094.2074151", "10.1109/tvcg.2016.2618797", "10.1073/pnas.1320645111", "10.1109/tvcg.2017.2744843", "10.1109/iv.2017.69", "10.1109/tvcg.2019.2934399", "10.1145/3172944.3173007", "10.5555/1795555", "10.1109/mcg.2005.102", "10.1145/381641.381653", "10.1162/153244301753344614", "10.1111/cgf.14034", "10.1111/cgf.13198", "10.1017/cbo9780511519857", "10.1007/s10462-016-9475-9", "10.1075/ssol.2.2.07bor", "10.1007/978-1-4614-3223-4\\_3", "10.1109/infvis.2003.1249025", "10.1007/978-94-007-6094-313", "10.1145/2858036.2858387", "10.1109/tvcg.2007.70528", "10.1109/tvcg.2017.2674958", "10.1147/sj.454.0801", "10.1109/tvcg.2013.119", "10.1145/3173574.3173711", "10.1016/j.erss.2017.06.034", "10.1109/visual.2019.8933695", "10.1007/s11665-016-2173-6", "10.1016/0377-0427(87)90125-7", "10.2307/3601125", "10.1016/b978-0-444-88738-2.50018-x", "10.1109/mcg.2006.70", "10.1109/tvcg.2018.2865145", "10.1017/s1351324997001502", "10.1109/tvcg.2010.179", "10.1214/aos/1176344552", "10.1109/mcg.2009.22", "10.1007/978-3-319-26633-6\\_13", "10.1080/10447318.2014.905422", "10.1016/j.visinf.2019.03.004", "10.1057/palgrave.ivs.9500074", "10.1007/978-1-4614-3223-4"], "wos": 1, "children": [], "len": 1}], "len": 5}, {"doi": "10.1111/cgf.14001", "year": "2020", "title": "Sunspot Plots: Model-based Structure Enhancement for Dense Scatter Plots", "conferenceName": "EuroVis", "authors": "Thomas Trautner;Fabian Bolte;Sergej Stoppel;Stefan Bruckner", "citationCount": "0", "affiliation": "Trautner, T (Corresponding Author), Univ Bergen, Bergen, Norway.\nTrautner, T.; Bolte, F.; Stoppel, S.; Bruckner, S., Univ Bergen, Bergen, Norway.", "countries": "Norway", "abstract": "Scatter plots are a powerful and well-established technique for visualizing the relationships between two variables as a collection of discrete points. However, especially when dealing with large and dense data, scatter plots often exhibit problems such as overplotting, making the data interpretation arduous. Density plots are able to overcome these limitations in highly populated regions, but fail to provide accurate information of individual data points. This is particularly problematic in sparse regions where the density estimate may not provide a good representation of the underlying data. In this paper, we present sunspot plots, a visualization technique that communicates dense data as a continuous data distribution, while preserving the discrete nature of data samples in sparsely populated areas. We furthermore demonstrate the advantages of our approach on typical failure cases of scatter plots within synthetic and real-world data sets and validate its effectiveness in a user study.", "keywords": "", "link": "https://doi.org/10.1111/cgf.14001", "refList": ["10.1057/palgrave.ivs.9500122", "10.2312/eggh/hpg12/097-103", "10.1109/tvcg.2008.119", "10.1109/pacificvis.2011.5742387", "10.1038/331163a0", "10.1109/visual.2019.8933620", "10.2307/2683294", "10.1201/9781351072304", "10.2307/2289444", "10.1109/tvcg.2019.2934541", "10.1080/00949657508810123", "10.1109/tvcg.2013.65", "10.1109/infvis.1997.636789", "10.1109/2945.841121", "10.1109/mcse.2007.55", "10.1109/tvcg.2010.197", "10.1111/cgf.12871", "10.1109/infvis.2003.1249018", "10.1145/3173574.3173991", "10.1109/tvcg.2012.238", "10.1007/0-387-28695-0", "10.1109/pacificvis.2010.5429604", "10.18637/jss.v008.i03", "10.1109/tvcg.2007.70596", "10.1109/visual.1998.745301", "10.1007/0-387-37977-0\\_3", "10.1145/1556262.1556289", "10.2312/wiced.20161094", "10.1109/tvcg.2007.70535", "10.1145/1056808.1056914", "10.1109/tvcg.2003.1196007", "10.1109/iv.2004.1320190", "10.1111/cgf.12877", "10.1162/leon.2007.40.2.202a", "10.1109/tvcg.2017.2674978", "10.1057/ivs.2010.4", "10.1016/j.cag.2018.02.008", "10.1201/9781315140919", "10.1109/visual.2000.885677", "10.1002/jhbs.20078", "10.1109/tvcg.2014.2346594", "10.1109/tvcg.2017.2744184", "10.1109/visual.2001.964495", "10.1109/iv.2002.1028760", "10.1111/cgf.13684", "10.1109/hicss.2013.197", "10.1109/tvcg.2019.2903956", "10.1093/mnras/stt961", "10.1109/tvcg.2017.2668409", "10.1111/j.1467-8659.2009.01478.x", "10.1145/2702123.2702585", "10.2307/1418003", "10.2307/1390742", "10.1145/360825.360839", "10.1109/pacificvis.2009.4906843", "10.1057/ivs.2009.34", "10.2307/2288711"], "wos": 1, "children": [], "len": 1}], "len": 13}, {"doi": "10.1111/cgf.14000", "year": "2020", "title": "Evaluating Reordering Strategies for Cluster Identification in Parallel Coordinates", "conferenceName": "EuroVis", "authors": "Michael Blumenschein;Xuan Zhang;David Pomerenke;Daniel A. Keim;Johannes Fuchs", "citationCount": "0", "affiliation": "Blumenschein, M (Corresponding Author), Univ Konstanz, Constance, Germany.\nBlumenschein, Michael; Pomerenke, David; Keim, Daniel A.; Fuchs, Johannes, Univ Konstanz, Constance, Germany.\nZhang, Xuan, Rhein Westfal TH Aachen, Aachen, Germany.", "countries": "Germany", "abstract": "The ability to perceive patterns in parallel coordinates plots (PCPs) is heavily influenced by the ordering of the dimensions. While the community has proposed over 30 automatic ordering strategies, we still lack empirical guidance for choosing an appropriate strategy for a given task. In this paper, we first propose a classification of tasks and patterns and analyze which PCP reordering strategies help in detecting them. Based on our classification, we then conduct an empirical user study with 31 participants to evaluate reordering strategies for cluster identification tasks. We particularly measure time, identification quality, and the users' confidence for two different strategies using both synthetic and real-world datasets. Our results show that, somewhat unexpectedly, participants tend to focus on dissimilar rather than similar dimension pairs when detecting clusters, and are more confident in their answers. This is especially true when increasing the amount of clutter in the data. As a result of these findings, we propose a new reordering strategy based on the dissimilarity of neighboring dimension pairs.", "keywords": "", "link": "https://doi.org/10.1111/cgf.14000", "refList": ["10.1111/j.1467-8659.2008.01241.x", "10.2312/conf/eg2013/stars/095-116", "10.1109/tvcg.2014.2346979", "10.1117/12.838819", "10.2307/2290001", "10.1111/cgf.12638", "10.1007/978-3-642-30217-6\\_42", "10.1109/sc.2005.47", "10.1002/wics.145", "10.1109/tvcg.2011.229", "10.1109/vast.2009.5332628", "10.1109/vast.2017.8585613", "10.1145/2993901.2993907", "10.1007/bf00410640", "10.1109/tvcg.2010.184", "10.11591/ijece.v5i6", "10.1111/j.1467-8659.2011.01961.x", "10.1109/visual.1997.663916", "10.1111/j.1467-8659.2012.03129.x", "10.1109/visual.1999.809866", "10.1057/ivs.2008.13", "10.1016/j.visinf.2017.11.001", "10.2307/2282967", "10.1007/978-0-387-68628-8\\_10", "10.5888/pcd9.120082", "10.1109/tvcg.2007.70535", "10.1109/vast.2010.5652450", "10.1007/bf01898350", "10.1016/0010-0285(91)90009-d", "10.1007/978-3-642-24958-7\\_12", "10.1109/infvis.2005.1532142", "10.1057/palgrave.ivs.9500166", "10.1111/j.1467-8659.2008.01239.x", "10.1109/mcse.2015.55", "10.2312/pe/eurovast/eurova12/007-011.7", "10.1109/tvcg.2009.153", "10.1198/jcgs.2010.09136", "10.1145/2463676.2463696", "10.1109/infvis.2005.1532138", "10.1109/tvcg.2010.242", "10.5220/0006097400400051", "10.1109/visual.2019.8933706", "10.1109/atc.2015.7388338", "10.2312/pe/eurovast/eurova12/007-011", "10.5120/5044-7370", "10.1111/cgf.13446", "10.1109/icmla.2012.148", "10.1016/j.jvlc.2015.12.001", "10.1109/tvcg.2015.2466992", "10.1111/j.1467-8659.2009.01666.x", "10.5169/seals-266450", "10.1109/infvis.1998.729559", "10.1016/j.jvlc.2017.10.003", "10.1109/visual.1995.485139", "10.1007/978-0-387-39940-9\\_262", "10.1109/tvcg.2006.138"], "wos": 1, "children": [], "len": 1}], "len": 71}, {"doi": "10.1111/cgf.13401", "year": "2018", "title": "Towards Easy Comparison of Local Businesses Using Online Reviews", "conferenceName": "EuroVis", "authors": "Yong Wang;Hammad Haleem;Conglei Shi;Yanhong Wu;Xun Zhao;Siwei Fu;Huamin Qu", "citationCount": "0", "affiliation": "Wang, Y (Corresponding Author), Hong Kong Univ Sci \\& Technol, Hong Kong, Peoples R China.\nWang, Yong; Haleem, Hammad; Zhao, Xun; Fu, Siwei; Qu, Huamin, Hong Kong Univ Sci \\& Technol, Hong Kong, Peoples R China.\nShi, Conglei, Airbnb Inc, San Francisco, CA USA.\nWu, Yanhong, Vis Res, Palo Alto, CA USA.", "countries": "USA;China", "abstract": "With the rapid development of e-commerce, there is an increasing number of online review websites, such as Yelp, to help customers make better purchase decisions. Viewing online reviews, including the rating score and text comments by other customers, and conducting a comparison between different businesses are the key to making an optimal decision. However, due to the massive amount of online reviews, the potential difference of user rating standards, and the significant variance of review time, length, details and quality, it is difficult for customers to achieve a quick and comprehensive comparison. In this paper, we present E-Comp, a carefully-designed visual analytics system based on online reviews, to help customers compare local businesses at different levels of details. More specifically, intuitive glyphs overlaid on maps are designed for quick candidate selection. Grouped Sankey diagram visualizing the rating difference by common customers is chosen for more reliable comparison of two businesses. Augmented word cloud showing adjective-noun word pairs, combined with a temporal view, is proposed to facilitate in-depth comparison of businesses in terms of different time periods, rating scores and features. The effectiveness and usability of E-Comp are demonstrated through a case study and in-depth user interviews.", "keywords": "", "link": "https://doi.org/10.1111/cgf.13401", "refList": ["10.1007/978-3-211-77280-5\\_4", "10.1177/1473871611416549", "10.1145/2702123.2702476", "10.1145/1014052.1014073", "10.1109/tvcg.2014.2346249", "10.1007/978-3-540-33037-08", "10.1109/tvcg.2007.70570", "10.1016/j.ijhm.2008.06.011", "10.1109/mic.2003.1167344", "10.1177/0047287513481274", "10.1109/iv.2013.5", "10.1111/j.1467-8659.2008.01205.x", "10.1561/1500000001", "10.1007/978-3-319-30319-2\\_13", "10.1109/tvcg.2013.254", "10.1007/978-3-540-33037-0\\_8", "10.1109/tvcg.2013.122", "10.1002/acp.2350050106", "10.1109/tvcg.2016.2598590", "10.2312/eurovisshort.20161167", "10.1007/s11002-013-9278-6", "10.1111/cgf.12888", "10.1145/1134707.1134743", "10.1109/tvcg.2015.2467691", "10.1109/tvcg.2010.183", "10.1109/vast.2009.5333919", "10.1109/tvcg.2017.2744199", "10.1111/cgf.13217", "10.1145/1060745.1060797", "10.1162/jmlr.2003.3.4-5.951", "10.1109/tvcg.2017.2723397", "10.2753/jec1086-4415170204", "10.1287/mksc.1110.0653", "10.1109/tvcg.2012.110", "10.1086/268567", "10.1109/tvcg.2017.2744738", "10.1007/978-3-540", "10.1109/tvcg.2014.2346912", "10.1109/mis.2013.36", "10.1109/tvcg.2013.173", "10.1109/tvcg.2006.76", "10.1109/tvcg.2017.2745298", "10.1559/152304009788188808"], "wos": 1, "children": [{"doi": "10.1109/tvcg.2020.3030411", "title": "Co-Bridges: Pair-wise Visual Connection and Comparison for Multi-item Data Streams", "year": "2020", "conferenceName": "VAST", "authors": "Siming Chen;Natalia V. Andrienko;Gennady L. Andrienko;Jie Li 0006;Xiaoru Yuan", "citationCount": "0", "affiliation": "Yuan, XR (Corresponding Author), Peking Univ, Beijing, Peoples R China. Chen, Siming, Fudan Univ, Sch Data Sci, Shanghai, Peoples R China. Chen, Siming; Andrienko, Natalia; Andrienko, Gennady, Fraunhofer Inst IAIS, St Augustin, Germany. Andrienko, Natalia; Andrienko, Gennady, City Univ London, London, England. Li, Jie, Tianjin Univ, Tianjin, Peoples R China. Yuan, Xiaoru, Peking Univ, Beijing, Peoples R China.", "countries": "Germany;China;England", "abstract": "In various domains, there are abundant streams or sequences of multi-item data of various kinds, e.g. streams of news and social media texts, sequences of genes and sports events, etc. Comparison is an important and general task in data analysis. For comparing data streams involving multiple items (e.g., words in texts, actors or action types in action sequences, visited places in itineraries, etc.), we propose Co-Bridges, a visual design involving connection and comparison techniques that reveal similarities and differences between two streams. Co-Bridges use river and bridge metaphors, where two sides of a river represent data streams, and bridges connect temporally or sequentially aligned segments of streams. Commonalities and differences between these segments in terms of involvement of various items are shown on the bridges. Interactive query tools support the selection of particular stream subsets for focused exploration. The visualization supports both qualitative (common and distinct items) and quantitative (stream volume, amount of item involvement) comparisons. We further propose Comparison-of-Comparisons, in which two or more Co-Bridges corresponding to different selections are juxtaposed. We test the applicability of the Co-Bridges in different domains, including social media text streams and sports event sequences. We perform an evaluation of the users' capability to understand and use Co-Bridges. The results confirm that Co-Bridges is effective for supporting pair-wise visual comparisons in a wide range of applications.", "keywords": "Visual Comparison,Pair-wise Analysis,Multi-item Data Stream,Social Media", "link": "http://dx.doi.org/10.1109/TVCG.2020.3030411", "refList": ["10.1109/tvcg.2014.2346753", "10.1109/pacificvis.2010.5429590", "10.1109/vast.2009.5333443", "10.1101/gr.2289704", "10.1177/1473871611416549", "10.1057/palgrave.ivs.9500099", "10.1109/vast.2017.8585638", "10.1109/vast.2014.7042496", "10.1109/tvcg.2017.2764459", "10.1109/tvcg.2013.221", "10.1109/vast.2011.6102439", "10.1109/tvcg.2013.213", "10.1109/tmm.2016.2614220", "10.1109/tvcg.2016.2598797", "10.1145/2207676.2208556", "10.1145/1835804.1835827", "10.1109/tvcg.2013.124", "10.2312/conf/eg2013/stars/039-063", "10.1111/cgf.13211", "10.1109/tvcg.2014.2346920", "10.1109/tvcg.2011.239", "10.1016/j.jvlc.2018.08.008", "10.1109/mcg.2018.032421661", "10.1109/tvcg.2017.2744199", "10.1109/tvcg.2019.2934535", "10.1109/tvcg.2018.2864526", "10.1007/978-0-85729-436-4\\_9", "10.1109/vast.2016.7883511", "10.1109/tvcg.2014.2346682", "10.1109/tvcg.2015.2467618", "10.1145/2566486.2567977", "10.1109/tvcg.2017.2745320", "10.1080/136588199241247", "10.1111/cgf.13401", "10.1109/tvcg.2018.2864884", "10.1109/tvcg.2012.291", "10.1109/vast.2012.6400485", "10.1109/pacificvis.2016.7465266", "10.1109/tvcg.2011.232", "10.1109/tvcg.2017.2745083", "10.1109/tvcg.2012.253", "10.1007/s12650-014-0246-x", "10.1109/tvcg.2010.20", "10.1109/tvcg.2014.2346919", "10.1109/visual.2019.8933646", "10.1007/978-0-85729-079-3"], "wos": 1, "children": [], "len": 1}, {"doi": "10.1109/tvcg.2020.3030419", "title": "Comparative Layouts Revisited: Design Space, Guidelines, and Future Directions", "year": "2020", "conferenceName": "InfoVis", "authors": "Sehi L'Yi;Jaemin Jo;Jinwook Seo", "citationCount": "0", "affiliation": "L'Yi, S (Corresponding Author), Harvard Med Sch, Boston, MA 02115 USA. L'Yi, Sehi, Harvard Med Sch, Boston, MA 02115 USA. Jo, Jaemin, Sungkyunkwan Univ, Seoul, South Korea. Seo, Jinwook, Seoul Natl Univ, Seoul, South Korea.", "countries": "USA;Korea", "abstract": "We present a systematic review on three comparative layouts-juxtaposition, superposition, and explicit-encoding-which are information visualization (InfoVis) layouts designed to support comparison tasks. For the last decade, these layouts have served as fundamental idioms in designing many visualization systems. However, we found that the layouts have been used with inconsistent terms and confusion, and the lessons from previous studies are fragmented. The goal of our research is to distill the results from previous studies into a consistent and reusable framework. We review 127 research papers, including 15 papers with quantitative user studies, which employed comparative layouts. We first alleviate the ambiguous boundaries in the design space of comparative layouts by suggesting lucid terminology (e.g., chart-wise and item-wise juxtaposition). We then identify the diverse aspects of comparative layouts, such as the advantages and concerns of using each layout in the real-world scenarios and researchers' approaches to overcome the concerns. Building our knowledge on top of the initial insights gained from the Gleicher et al.'s survey [19], we elaborate on relevant empirical evidence that we distilled from our survey (e.g., the actual effectiveness of the layouts in different study settings) and identify novel facets that the original work did not cover (e.g., the familiarity of the layouts to people). Finally, we show the consistent and contradictory results on the performance of comparative layouts and offer practical implications for using the layouts by suggesting trade-offs and seven actionable guidelines.", "keywords": "Comparative layout,visual comparison,literature review,juxtaposition,superposition,explicit-encoding", "link": "http://dx.doi.org/10.1109/TVCG.2020.3030419", "refList": ["10.1109/tvcg.2013.233", "10.1111/cgf.12380", "10.1177/1473871611416549", "10.1145/2702123.2702419", "10.1109/tvcg.2014.2322363", "10.1111/cgf.12791", "10.1145/2702123.2702130", "10.1145/2702123.2702217", "10.1109/tvcg.2012.237", "10.1177/1473871613480062", "10.1109/mcg.2017.377152546", "10.1109/tvcg.2013.213", "10.1111/cgf.12369", "10.1109/tvcg.2017.2744198", "10.1145/3139295.3139309", "10.1109/tvcg.2019.2934801", "10.1109/tvcg.2013.122", "10.1109/tvcg.2017.2747545", "10.1109/tvcg.2015.2413774", "10.1037/0096-1523.24.3.719", "10.1109/tvcg.2014.2346320", "10.1109/tvcg.2007.70535", "10.1109/mcg.2018.032421661", "10.1109/tvcg.2017.2744199", "10.1145/2556288.2557141", "10.1109/tvcg.2013.149", "10.1145/1165734.1165736", "10.5220/0006127502170224", "10.1109/tvcg.2017.2745298", "10.1177/1473871617692841", "10.1190/int-2017-0083.1", "10.1190/int-2014-0283.1", "10.1109/tvcg.2016.2598796", "10.1111/cgf.13401", "10.1016/j.cag.2017.05.005", "10.1177/1473871616667632", "10.1145/3025453.3025882", "10.1145/2470654.2470724", "10.1109/tvcg.2007.70539", "10.1109/tvcg.2018.2864884", "10.1109/tvcg.2010.164", "10.1145/3103010.3103013", "10.1109/pacificvis.2016.7465266", "10.1109/pacificvis.2012.6183556", "10.1109/tvcg.2015.2467751", "10.1109/tvcg.2018.2796557", "10.1111/cgf.13531", "10.1109/tvcg.2013.161", "10.1109/iv.2018.00051", "10.1109/tvcg.2010.162", "10.1109/tvcg.2018.2864510", "10.1109/iv.2017.30", "10.1109/tvcg.2007.70623"], "wos": 1, "children": [], "len": 1}], "len": 5}, {"doi": "10.1111/cgf.13211", "year": "2017", "title": "Social Media Visual Analytics", "conferenceName": "EuroVis", "authors": "Siming Chen;Lijing Lin;Xiaoru Yuan", "citationCount": "29", "affiliation": "Chen, SM (Corresponding Author), Peking Univ, Minist Educ, Key Lab Machine Percept, Beijing, Peoples R China.\nChen, SM (Corresponding Author), Peking Univ, Sch EECS, Beijing, Peoples R China.\nChen, Siming; Lin, Lijing; Yuan, Xiaoru, Peking Univ, Minist Educ, Key Lab Machine Percept, Beijing, Peoples R China.\nChen, Siming; Lin, Lijing; Yuan, Xiaoru, Peking Univ, Sch EECS, Beijing, Peoples R China.", "countries": "China", "abstract": "With the development of social media (e.g. Twitter, Flickr, Foursquare, Sina Weibo, etc.), a large number of people are now using them and post microblogs, messages and multi-media information. The everyday usage of social media results in big open social media data. The data offer fruitful information and reflect social behaviors of people. There is much visualization and visual analytics research on such data. We collect state-of-the-art research and put it into three main categories: social network, spatial temporal information and text analysis. We further summarize the visual analytics pipeline for the social media, combining the above categories and supporting complex tasks. With these techniques, social media analytics can apply to multiple disciplines. We summarize the applications and public tools to further investigate the challenges and trends.", "keywords": "", "link": "https://doi.org/10.1111/cgf.13211", "refList": ["10.1016/j.cag.2013.11.003", "10.1109/vast.2010.5652922", "10.1007/s12650-015-0277-y", "10.1007/978-3-540-70956-5", "10.1007/s00146-014-0549-4", "10.1109/tmm.2014.2340133", "10.1109/tmm.2015.2510329", "10.1057/palgrave.ivs.9500116", "10.1109/tvcg.2010.129", "10.1109/tvcg.2016.2598590", "10.1145/2065023.2065041", "10.1109/tvcg.2013.162", "10.1145/1963405.1963504", "10.1177/1473871613490678", "10.1007/978-0-85729-436-4\\_9", "10.1145/2488388.2488504", "10.1109/bigdata.2015.7363826", "10.1109/tvcg.2009.171", "10.1109/tvcg.2012.291", "10.1109/vast.2012.6400485", "10.1109/tvcg.2014.2371856", "10.1145/2089094.2089102", "10.1109/tvcg.2014.2346919", "10.1109/tvcg.2014.2346433", "10.1109/tvcg.2015.2509990", "10.1109/pacificvis.2015.7156366", "10.1016/j.jocs.2010.12.007", "10.1109/tvcg.2011.169", "10.1109/tvcg.2015.2467619", "10.1016/j.cag.2013.10.008", "10.1007/978-3-319-06793-3\\_3", "10.1109/tmm.2009.2012912", "10.1109/pacificvis.2015.7156367", "10.1109/tvcg.2014.2346922", "10.1371/journal.pone.0101837", "10.1109/tmm.2015.2425143", "10.1145/2493102.2493108", "10.1109/tvcg.2015.2467196", "10.1109/tvcg.2013.196", "10.1109/mcg.2014.61", "10.1109/pacificvis.2016.7465266", "10.1109/tvcg.2006.160", "10.1057/palgrave.ivs.9500092", "10.1016/j.giq.2012.06.002", "10.1016/b978-0-12-382229-1.00002-3", "10.1109/vast.2016.7883510", "10.1111/j.1467-8659.2012.03120.x", "10.1109/tmm.2016.2614220", "10.7155/jgaa.00302", "10.1109/tvcg.2014.2346920", "10.1109/vast.2015.7347631", "10.1371/journal.pone.0095043", "10.1109/vast.2014.7042495", "10.1511/2001.4.344", "10.1109/vast.2012.6400557", "10.1109/pacificvis.2012.6183572", "10.1145/2567948.2577020", "10.1016/j.joi.2014.07.006", "10.1111/j.1467-8659.2009.01687.x", "10.1145/2801040.2801054", "10.1016/j.bushor.2009.09.003", "10.1109/infvis.2000.885098", "10.1109/ldav.2013.6675163", "10.1007/s13218-012-0177-4", "10.1080/13658816.2013.825724", "10.1109/tvcg.2007.70582", "10.1109/mc.2013.152", "10.1109/vast.2014.7042496", "10.1109/vast.2011.6102456", "10.1145/2733373.2806236", "10.1109/tvcg.2013.221", "10.1177/1473871615576925", "10.1109/vast.2016.7883513", "10.1109/tvcg.2013.186", "10.1109/mc.2012.430", "10.1109/tvcg.2015.2467554", "10.1109/pacificvis.2014.48", "10.1145/2212776.2212796", "10.1109/tvcg.2006.107", "10.1109/pacificvis.2014.38", "10.1109/pacificvis.2015.7156376", "10.1109/vast.2014.7042535", "10.1109/tvcg.2014.2359887"], "wos": 1, "children": [{"doi": "10.1109/vast.2017.8585638", "title": "E-Map: A Visual Analytics Approach for Exploring Significant Event Evolutions in Social Media", "year": "2017", "conferenceName": "VAST", "authors": "Siming Chen;Shuai Chen;Lijing Lin;Xiaoru Yuan;Jie Liang 0004;Xiaolong Zhang", "citationCount": "10", "affiliation": "Yuan, XR (Corresponding Author), Peking Univ, Key Lab Machine Percept, Minist Educ, Beijing, Peoples R China. Yuan, XR (Corresponding Author), Peking Univ, Sch EECS, Beijing, Peoples R China. Chen, Siming; Chen, Shuai; Lin, Lijing; Yuan, Xiaoru, Peking Univ, Key Lab Machine Percept, Minist Educ, Beijing, Peoples R China. Chen, Siming; Chen, Shuai; Lin, Lijing; Yuan, Xiaoru, Peking Univ, Sch EECS, Beijing, Peoples R China. Liang, Jie, Univ Technol, Fac Engn \\& Informat Technol, Sydney, NSW, Australia. Zhang, Xiaolong, Penn State Univ, Coll Informat Sci \\& Technol, University Pk, PA 16802 USA.", "countries": "USA;China;Australia", "abstract": "Significant events are often discussed and spread through social media, involving many people. Reposting activities and opinions expressed in social media offer good opportunities to understand the evolution of events. However, the dynamics of reposting activities and the diversity of user comments pose challenges to understand event-related social media data. We propose E-Map, a visual analytics approach that uses map-like visualization tools to help multi-faceted analysis of social media data on a significant event and in-depth understanding of the development of the event. E-Map transforms extracted keywords, messages, and reposting behaviors into map features such as cities, towns, and rivers to build a structured and semantic space for users to explore. It also visualizes complex posting and reposting behaviors as simple trajectories and connections that can be easily followed. By supporting multi-level spatial temporal exploration, E-Map helps to reveal the patterns of event development and key players in an event, disclosing the ways they shape and affect the development of the event. Two cases analysing real-world events confirm the capacities of E-Map in facilitating the analysis of event evolution with social media data.", "keywords": "Social Media,Event Analysis,Map-like Visual Metaphor,Spatial Temporal Visual Analytics", "link": "http://dx.doi.org/10.1109/VAST.2017.8585638", "refList": ["10.1109/tvcg.2007.70582", "10.1109/tvcg.2016.2598919", "10.1109/pacificvis.2010.5429590", "10.1057/ivs.2008.23", "10.1109/vast.2014.7042496", "10.1016/j.cag.2013.11.003", "10.1109/vast.2011.6102456", "10.1109/tvcg.2013.221", "10.1109/tvcg.2011.185", "10.1109/vast.2016.7883510", "10.1111/j.1467-8659.2012.03120.x", "10.1109/tvcg.2013.186", "10.1109/tmm.2016.2614220", "10.7155/jgaa.00302", "10.1109/mc.2012.430", "10.1109/tvcg.2015.2467619", "10.1109/tvcg.2010.129", "10.1016/s0341-8162(01)00164-3", "10.1109/tvcg.2016.2598590", "10.1145/2065023.2065041", "10.1111/cgf.13211", "10.1109/tvcg.2013.162", "10.1109/tvcg.2011.288", "10.1145/1963405.1963504", "10.5670/oceanog.2016.66", "10.1109/tvcg.2015.2467554", "10.1109/tvcg.2015.2467691", "10.1016/j.cag.2013.10.008", "10.1109/mcg.2015.73", "10.1109/vast.2012.6400557", "10.1109/tvcg.2016.2539960", "10.1109/tit.1982.1056489", "10.1109/pacificvis.2012.6183572", "10.1109/tvcg.2014.2346922", "10.1109/tmm.2014.2384912", "10.1109/vast.2016.7883511", "10.1002/spe.4380211102", "10.1145/2488388.2488504", "10.2312/eurovisstar.20141176", "10.1109/bigdata.2013.6691714", "10.1109/tvcg.2009.171", "10.1109/tvcg.2013.196", "10.1109/vast.2008.4677356", "10.1145/2207676.2208672", "10.1111/j.1467-8659.2011.01955.x", "10.1109/pacificvis.2014.38", "10.1109/tvcg.2012.291", "10.1109/vast.2012.6400485", "10.1109/pacificvis.2015.7156376", "10.1145/1348549.1348556", "10.1109/vast.2015.7347632", "10.1109/tvcg.2014.2346919", "10.1109/tvcg.2014.2346433"], "wos": 1, "children": [{"doi": "10.1109/tvcg.2019.2934263", "title": "R-Map: A Map Metaphor for Visualizing Information Reposting Process in Social Media", "year": "2019", "conferenceName": "VAST", "authors": "Shuai Chen;Sihang Li;Siming Chen;Xiaoru Yuan", "citationCount": "0", "affiliation": "Yuan, XR (Corresponding Author), Peking Univ, Natl Engn Lab Big Data Anal \\& Applicat, Beijing, Peoples R China. Chen, Shuai; Li, Sihang, Peking Univ, Sch EECS, Minist Educ, Key Lab Machine Petrept, Beijing, Peoples R China. Yuan, Xiaoru, Peking Univ, Natl Engn Lab Big Data Anal \\& Applicat, Beijing, Peoples R China. Chen, Siming, Fraunhofer Inst IAIS, St Augustin, Germany. Chen, Siming, Univ Bonn, Bonn, Germany.", "countries": "Germany;China", "abstract": "We propose R-Map (Reposting Map), a visual analytical approach with a map metaphor to support interactive exploration and analysis of the information reposting process in social media. A single original social media post can cause large cascades of repostings (i.e., retweets) on online networks, involving thousands, even millions of people with different opinions. Such reposting behaviors form the reposting tree, in which a node represents a message and a link represents the reposting relation. In R-Map, the reposting tree structure can be spatialized with highlighted key players and tiled nodes. The important reposting behaviors, the following relations and the semantics relations are represented as rivers, routes and bridges, respectively, in a virtual geographical space. R-Map supports a scalable overview of a large number of information repostings with semantics. Additional interactions on the map are provided to support the investigation of temporal patterns and user behaviors in the information diffusion process. We evaluate the usability and effectiveness of our system with two use cases and a formal user study.", "keywords": "Social Media,Information Diffusion,Map-like Visual Metaphor", "link": "http://dx.doi.org/10.1109/TVCG.2019.2934263", "refList": ["10.1109/infvis.2000.885091", "10.1109/pacificvis.2010.5429590", "10.1111/j.0020-2754.1998.00269.x", "10.1109/vast.2017.8585638", "10.1145/2700398", "10.1109/tmm.2016.2614229", "10.1109/visual.1991.175815", "10.1145/3183347", "10.1109/infvis.2001.963290", "10.1109/vast.2016.7883510", "10.1109/access.2016.2605009", "10.1109/mcg.2011.103", "10.1145/1124772.1124851", "10.1109/tmm.2016.2614220", "10.1109/tvcg.2010.79", "10.1109/infvis.2000.885095", "10.1111/cgf.13211", "10.1109/tvcg.2014.2346920", "10.1002/(sici)1097-0266(199606)17:6", "10.5670/oceanog.2016.66", "10.1559/152304003100011081", "10.1109/tit.1982.1056489", "10.1559/152304098782383034", "10.1109/tvcg.2014.2346922", "10.1007/978-3-540-85567-5\\_9", "10.1145/2488388.2488504", "10.1109/38.974518", "10.1109/bigdata.2013.6691714", "10.1109/pacificvis.2014.38", "10.1109/tvcg.2012.291", "10.1109/infvis.2005.1532128", "10.2307/2685881", "10.1007/1-4020-4179-9\\_91", "10.1109/infvis.1999.801860", "10.1109/asonam.2011.37"], "wos": 1, "children": [{"doi": "10.1111/cgf.14031", "year": "2020", "title": "The State of the Art in Map-Like Visualization", "conferenceName": "EuroVis", "authors": "Marius Hogr{\\\"{a}}fer;Magnus Heitzler;Hans{-}J{\\\"{o}}rg Schulz", "citationCount": "0", "affiliation": "Hografer, M (Corresponding Author), Aarhus Univ, Dept Comp Sci, Aarhus, Denmark.\nHografer, Marius; Schulz, Hans-Jorg, Aarhus Univ, Dept Comp Sci, Aarhus, Denmark.\nHeitzler, Magnus, Swiss Fed Inst Technol, Inst Cartog \\& Geoinformat, Zurich, Switzerland.", "countries": "Switzerland;Denmark", "abstract": "Cartographic maps have been shown to provide cognitive benefits when interpreting data in relation to a geographic location. In visualization, the term map-like describes techniques that incorporate characteristics of cartographic maps in their representation of abstract data. However, the field of map-like visualization is vast and currently lacks a clear classification of the existing techniques. Moreover, choosing the right technique to support a particular visualization task is further complicated, as techniques are scattered across different domains, with each considering different characteristics as map-like. In this paper, we give an overview of the literature on map-like visualization and provide a hierarchical classification of existing techniques along two general perspectives: imitation and schematization of cartographic maps. Each perspective is further divided into four principal categories that group common map-like techniques along the visual primitives they affect. We further discuss this classification from a task-centered view and highlight open research questions.", "keywords": "", "link": "https://doi.org/10.1111/cgf.14031", "refList": ["10.1111/j.0020-2754.1998.00269.x.21", "10.1109/iv.2005.26", "10.2307/2980460", "10.1109/tvcg.2017.2743959", "10.1016/j.jvlc.2011.11.004", "10.1145/2501988.2502046", "10.1559/1523040042742402", "10.1007/s00779-011-0500-3", "10.1111/cgf.12932", "10.1109/tvcg.2010.89", "10.1111/cgf.13200", "10.1080/15230406.2016.1160797", "10.1179/000870410x12825500202896", "10.1109/tvcg.2007.70596", "10.5167/80972.19uzh-80972", "10.1007/978-3-319-11593-1\\_2", "10.1037/aca0000175", "10.1080/17538947.2014.923942", "10.1109/tvcg.2015.2467321", "10.1109/vissof.2005.1684299", "10.1559/152304098782383034", "10.1007/978-3-642-36763-2\\_38", "10.1109/tvcg.2013.130", "10.1109/tvcg.2014.2346274", "10.1111/cgf.12648", "10.1111/0004-5608.00242", "10.1177/1473871617724212", "10.1109/iv.2004.1320123", "10.1371/journal.pcbi.1006907", "10.1109/tvcg.2016.2599030", "10.1559/1523040042742411", "10.3390/informatics5030031", "10.1111/cgf.13079", "10.1109/tvcg.2015.2467811", "10.1016/j.tics.2003.12.004", "10.1007/s00799-016-0168-4", "10.1109/infvis.2004.57", "10.1007/s10021-007-9038-7", "10.1109/pacificvis.2015.7156366", "10.1007/978-3-319-27261-0\\_1", "10.1007/978-1-4471-2804-5\\_6", "10.1109/access.2019.2939977", "10.1109/tvcg.2017.2747545", "10.1109/icdm.2003.1250978", "10.1111/cgf.13167", "10.1016/0010-0285(78)90006-3", "10.3138/nj8v-8514-871t-221k", "10.1016/j.cag.2009.06.002", "10.1111/j.1467-8659.2011.01937.x", "10.1016/b978-044451020-4/50035-9", "10.1111/1467-8659.00566", "10.5220/0006618101080119", "10.1109/pacificvis.2012.6183571", "10.1145/2038558.2038579", "10.1109/tvcg.2010.191", "10.1111/j.0033-0124.1985.00075.x", "10.1109/tvcg.2004.1260761", "10.1007/978-3-642-34848-8\\_6", "10.1145/2968220.2968239", "10.1145/3002151.3002160", "10.1109/tst.2013.6509098", "10.1109/tvcg.2013.91", "10.1177/1473871615597077", "10.1016/j.jvlc.2011.02.001", "10.1080/17445647.2014.935502", "10.1177/1687814017740710", "10.1111/1744-7917.12601", "10.1073/pnas.0400280101", "10.1111/cgf.13672", "10.1109/mcg.2006.90", "10.1002/asi.21712", "10.1007/978-3-642-33024-7\\_3", "10.1145/2801040.2801056", "10.1109/mcg.2010.101", "10.1179/003962607x165041", "10.1057/palgrave.ivs.9500039", "10.1109/vast.2016.7883510", "10.1559/152304009788988288", "10.1080/23729333.2017.1301346", "10.1109/tvcg.2013.66", "10.1111/j.1467-8659.2012.03085.x", "10.1109/tvcg.2011.288", "10.3390/ijgi9040253", "10.1109/infvis.2005.1532150", "10.1145/2254556.2254636", "10.20382//jocg.v4i1a9", "10.1016/0010-0285(81)90016-5", "10.1145/2556288.2557224", "10.1109/iv.2001.942043", "10.1021/ed1000203", "10.1016/0169-7439(87)80084-9", "10.1109/tvcg.2010.154", "10.1016/j.jvlc.2015.10.003", "10.1109/tvcg.2019.2903945", "10.1109/tvcg.2013.120", "10.1109/tvcg.2019.2934263", "10.1146/annurev-ecolsys-102209-144718", "10.1109/tvcg.2008.165", "10.3138/a477-3202-7876-n514", "10.1080/23729333.2017.1288535", "10.1111/j.0020-2754.1998.00269.x", "10.1109/mcg.2004.41", "10.1109/vast.2009.5332593", "10.1002/smr.414", "10.1007/s12650-019-00584-3", "10.1145/22949.22950", "10.1179/1743277413y.0000000036", "10.1080/15230406.2016.1262280", "10.1016/s0341-8162(01)00164-3", "10.22224/gistbok/2017.3.8", "10.1109/tvcg.2008.155", "10.1057/ivs.2008.31", "10.1016/j.cag.2004.03.012", "10.1179/1743277412y.0000000007", "10.1016/j.soncn.2011.02.001", "10.1179/caj.1987.24.1.27", "10.3138/carto.48.3.1691", "10.5220/0004267205150524", "10.1109/38.974518", "10.1145/102377.115768", "10.1057/palgrave.ivs.9500186", "10.1109/5.58325", "10.5167/80972.uzh-80972", "10.1177/030913339602000204", "10.1007/978-3-642-22300-6\\_14", "10.1109/iv.2004.1320189", "10.1111/cgf.13447", "10.1007/s11192-017-2596-3", "10.1559/1523040053722150", "10.1007/978-3-662-45803-7\\_34"], "wos": 1, "children": [], "len": 1}], "len": 3}, {"doi": "10.1109/tvcg.2020.3030411", "title": "Co-Bridges: Pair-wise Visual Connection and Comparison for Multi-item Data Streams", "year": "2020", "conferenceName": "VAST", "authors": "Siming Chen;Natalia V. Andrienko;Gennady L. Andrienko;Jie Li 0006;Xiaoru Yuan", "citationCount": "0", "affiliation": "Yuan, XR (Corresponding Author), Peking Univ, Beijing, Peoples R China. Chen, Siming, Fudan Univ, Sch Data Sci, Shanghai, Peoples R China. Chen, Siming; Andrienko, Natalia; Andrienko, Gennady, Fraunhofer Inst IAIS, St Augustin, Germany. Andrienko, Natalia; Andrienko, Gennady, City Univ London, London, England. Li, Jie, Tianjin Univ, Tianjin, Peoples R China. Yuan, Xiaoru, Peking Univ, Beijing, Peoples R China.", "countries": "Germany;China;England", "abstract": "In various domains, there are abundant streams or sequences of multi-item data of various kinds, e.g. streams of news and social media texts, sequences of genes and sports events, etc. Comparison is an important and general task in data analysis. For comparing data streams involving multiple items (e.g., words in texts, actors or action types in action sequences, visited places in itineraries, etc.), we propose Co-Bridges, a visual design involving connection and comparison techniques that reveal similarities and differences between two streams. Co-Bridges use river and bridge metaphors, where two sides of a river represent data streams, and bridges connect temporally or sequentially aligned segments of streams. Commonalities and differences between these segments in terms of involvement of various items are shown on the bridges. Interactive query tools support the selection of particular stream subsets for focused exploration. The visualization supports both qualitative (common and distinct items) and quantitative (stream volume, amount of item involvement) comparisons. We further propose Comparison-of-Comparisons, in which two or more Co-Bridges corresponding to different selections are juxtaposed. We test the applicability of the Co-Bridges in different domains, including social media text streams and sports event sequences. We perform an evaluation of the users' capability to understand and use Co-Bridges. The results confirm that Co-Bridges is effective for supporting pair-wise visual comparisons in a wide range of applications.", "keywords": "Visual Comparison,Pair-wise Analysis,Multi-item Data Stream,Social Media", "link": "http://dx.doi.org/10.1109/TVCG.2020.3030411", "refList": ["10.1109/tvcg.2014.2346753", "10.1109/pacificvis.2010.5429590", "10.1109/vast.2009.5333443", "10.1101/gr.2289704", "10.1177/1473871611416549", "10.1057/palgrave.ivs.9500099", "10.1109/vast.2017.8585638", "10.1109/vast.2014.7042496", "10.1109/tvcg.2017.2764459", "10.1109/tvcg.2013.221", "10.1109/vast.2011.6102439", "10.1109/tvcg.2013.213", "10.1109/tmm.2016.2614220", "10.1109/tvcg.2016.2598797", "10.1145/2207676.2208556", "10.1145/1835804.1835827", "10.1109/tvcg.2013.124", "10.2312/conf/eg2013/stars/039-063", "10.1111/cgf.13211", "10.1109/tvcg.2014.2346920", "10.1109/tvcg.2011.239", "10.1016/j.jvlc.2018.08.008", "10.1109/mcg.2018.032421661", "10.1109/tvcg.2017.2744199", "10.1109/tvcg.2019.2934535", "10.1109/tvcg.2018.2864526", "10.1007/978-0-85729-436-4\\_9", "10.1109/vast.2016.7883511", "10.1109/tvcg.2014.2346682", "10.1109/tvcg.2015.2467618", "10.1145/2566486.2567977", "10.1109/tvcg.2017.2745320", "10.1080/136588199241247", "10.1111/cgf.13401", "10.1109/tvcg.2018.2864884", "10.1109/tvcg.2012.291", "10.1109/vast.2012.6400485", "10.1109/pacificvis.2016.7465266", "10.1109/tvcg.2011.232", "10.1109/tvcg.2017.2745083", "10.1109/tvcg.2012.253", "10.1007/s12650-014-0246-x", "10.1109/tvcg.2010.20", "10.1109/tvcg.2014.2346919", "10.1109/visual.2019.8933646", "10.1007/978-0-85729-079-3"], "wos": 1, "children": [], "len": 1}], "len": 7}, {"doi": "10.1109/tvcg.2019.2934263", "title": "R-Map: A Map Metaphor for Visualizing Information Reposting Process in Social Media", "year": "2019", "conferenceName": "VAST", "authors": "Shuai Chen;Sihang Li;Siming Chen;Xiaoru Yuan", "citationCount": "0", "affiliation": "Yuan, XR (Corresponding Author), Peking Univ, Natl Engn Lab Big Data Anal \\& Applicat, Beijing, Peoples R China. Chen, Shuai; Li, Sihang, Peking Univ, Sch EECS, Minist Educ, Key Lab Machine Petrept, Beijing, Peoples R China. Yuan, Xiaoru, Peking Univ, Natl Engn Lab Big Data Anal \\& Applicat, Beijing, Peoples R China. Chen, Siming, Fraunhofer Inst IAIS, St Augustin, Germany. Chen, Siming, Univ Bonn, Bonn, Germany.", "countries": "Germany;China", "abstract": "We propose R-Map (Reposting Map), a visual analytical approach with a map metaphor to support interactive exploration and analysis of the information reposting process in social media. A single original social media post can cause large cascades of repostings (i.e., retweets) on online networks, involving thousands, even millions of people with different opinions. Such reposting behaviors form the reposting tree, in which a node represents a message and a link represents the reposting relation. In R-Map, the reposting tree structure can be spatialized with highlighted key players and tiled nodes. The important reposting behaviors, the following relations and the semantics relations are represented as rivers, routes and bridges, respectively, in a virtual geographical space. R-Map supports a scalable overview of a large number of information repostings with semantics. Additional interactions on the map are provided to support the investigation of temporal patterns and user behaviors in the information diffusion process. We evaluate the usability and effectiveness of our system with two use cases and a formal user study.", "keywords": "Social Media,Information Diffusion,Map-like Visual Metaphor", "link": "http://dx.doi.org/10.1109/TVCG.2019.2934263", "refList": ["10.1109/infvis.2000.885091", "10.1109/pacificvis.2010.5429590", "10.1111/j.0020-2754.1998.00269.x", "10.1109/vast.2017.8585638", "10.1145/2700398", "10.1109/tmm.2016.2614229", "10.1109/visual.1991.175815", "10.1145/3183347", "10.1109/infvis.2001.963290", "10.1109/vast.2016.7883510", "10.1109/access.2016.2605009", "10.1109/mcg.2011.103", "10.1145/1124772.1124851", "10.1109/tmm.2016.2614220", "10.1109/tvcg.2010.79", "10.1109/infvis.2000.885095", "10.1111/cgf.13211", "10.1109/tvcg.2014.2346920", "10.1002/(sici)1097-0266(199606)17:6", "10.5670/oceanog.2016.66", "10.1559/152304003100011081", "10.1109/tit.1982.1056489", "10.1559/152304098782383034", "10.1109/tvcg.2014.2346922", "10.1007/978-3-540-85567-5\\_9", "10.1145/2488388.2488504", "10.1109/38.974518", "10.1109/bigdata.2013.6691714", "10.1109/pacificvis.2014.38", "10.1109/tvcg.2012.291", "10.1109/infvis.2005.1532128", "10.2307/2685881", "10.1007/1-4020-4179-9\\_91", "10.1109/infvis.1999.801860", "10.1109/asonam.2011.37"], "wos": 1, "children": [{"doi": "10.1111/cgf.14031", "year": "2020", "title": "The State of the Art in Map-Like Visualization", "conferenceName": "EuroVis", "authors": "Marius Hogr{\\\"{a}}fer;Magnus Heitzler;Hans{-}J{\\\"{o}}rg Schulz", "citationCount": "0", "affiliation": "Hografer, M (Corresponding Author), Aarhus Univ, Dept Comp Sci, Aarhus, Denmark.\nHografer, Marius; Schulz, Hans-Jorg, Aarhus Univ, Dept Comp Sci, Aarhus, Denmark.\nHeitzler, Magnus, Swiss Fed Inst Technol, Inst Cartog \\& Geoinformat, Zurich, Switzerland.", "countries": "Switzerland;Denmark", "abstract": "Cartographic maps have been shown to provide cognitive benefits when interpreting data in relation to a geographic location. In visualization, the term map-like describes techniques that incorporate characteristics of cartographic maps in their representation of abstract data. However, the field of map-like visualization is vast and currently lacks a clear classification of the existing techniques. Moreover, choosing the right technique to support a particular visualization task is further complicated, as techniques are scattered across different domains, with each considering different characteristics as map-like. In this paper, we give an overview of the literature on map-like visualization and provide a hierarchical classification of existing techniques along two general perspectives: imitation and schematization of cartographic maps. Each perspective is further divided into four principal categories that group common map-like techniques along the visual primitives they affect. We further discuss this classification from a task-centered view and highlight open research questions.", "keywords": "", "link": "https://doi.org/10.1111/cgf.14031", "refList": ["10.1111/j.0020-2754.1998.00269.x.21", "10.1109/iv.2005.26", "10.2307/2980460", "10.1109/tvcg.2017.2743959", "10.1016/j.jvlc.2011.11.004", "10.1145/2501988.2502046", "10.1559/1523040042742402", "10.1007/s00779-011-0500-3", "10.1111/cgf.12932", "10.1109/tvcg.2010.89", "10.1111/cgf.13200", "10.1080/15230406.2016.1160797", "10.1179/000870410x12825500202896", "10.1109/tvcg.2007.70596", "10.5167/80972.19uzh-80972", "10.1007/978-3-319-11593-1\\_2", "10.1037/aca0000175", "10.1080/17538947.2014.923942", "10.1109/tvcg.2015.2467321", "10.1109/vissof.2005.1684299", "10.1559/152304098782383034", "10.1007/978-3-642-36763-2\\_38", "10.1109/tvcg.2013.130", "10.1109/tvcg.2014.2346274", "10.1111/cgf.12648", "10.1111/0004-5608.00242", "10.1177/1473871617724212", "10.1109/iv.2004.1320123", "10.1371/journal.pcbi.1006907", "10.1109/tvcg.2016.2599030", "10.1559/1523040042742411", "10.3390/informatics5030031", "10.1111/cgf.13079", "10.1109/tvcg.2015.2467811", "10.1016/j.tics.2003.12.004", "10.1007/s00799-016-0168-4", "10.1109/infvis.2004.57", "10.1007/s10021-007-9038-7", "10.1109/pacificvis.2015.7156366", "10.1007/978-3-319-27261-0\\_1", "10.1007/978-1-4471-2804-5\\_6", "10.1109/access.2019.2939977", "10.1109/tvcg.2017.2747545", "10.1109/icdm.2003.1250978", "10.1111/cgf.13167", "10.1016/0010-0285(78)90006-3", "10.3138/nj8v-8514-871t-221k", "10.1016/j.cag.2009.06.002", "10.1111/j.1467-8659.2011.01937.x", "10.1016/b978-044451020-4/50035-9", "10.1111/1467-8659.00566", "10.5220/0006618101080119", "10.1109/pacificvis.2012.6183571", "10.1145/2038558.2038579", "10.1109/tvcg.2010.191", "10.1111/j.0033-0124.1985.00075.x", "10.1109/tvcg.2004.1260761", "10.1007/978-3-642-34848-8\\_6", "10.1145/2968220.2968239", "10.1145/3002151.3002160", "10.1109/tst.2013.6509098", "10.1109/tvcg.2013.91", "10.1177/1473871615597077", "10.1016/j.jvlc.2011.02.001", "10.1080/17445647.2014.935502", "10.1177/1687814017740710", "10.1111/1744-7917.12601", "10.1073/pnas.0400280101", "10.1111/cgf.13672", "10.1109/mcg.2006.90", "10.1002/asi.21712", "10.1007/978-3-642-33024-7\\_3", "10.1145/2801040.2801056", "10.1109/mcg.2010.101", "10.1179/003962607x165041", "10.1057/palgrave.ivs.9500039", "10.1109/vast.2016.7883510", "10.1559/152304009788988288", "10.1080/23729333.2017.1301346", "10.1109/tvcg.2013.66", "10.1111/j.1467-8659.2012.03085.x", "10.1109/tvcg.2011.288", "10.3390/ijgi9040253", "10.1109/infvis.2005.1532150", "10.1145/2254556.2254636", "10.20382//jocg.v4i1a9", "10.1016/0010-0285(81)90016-5", "10.1145/2556288.2557224", "10.1109/iv.2001.942043", "10.1021/ed1000203", "10.1016/0169-7439(87)80084-9", "10.1109/tvcg.2010.154", "10.1016/j.jvlc.2015.10.003", "10.1109/tvcg.2019.2903945", "10.1109/tvcg.2013.120", "10.1109/tvcg.2019.2934263", "10.1146/annurev-ecolsys-102209-144718", "10.1109/tvcg.2008.165", "10.3138/a477-3202-7876-n514", "10.1080/23729333.2017.1288535", "10.1111/j.0020-2754.1998.00269.x", "10.1109/mcg.2004.41", "10.1109/vast.2009.5332593", "10.1002/smr.414", "10.1007/s12650-019-00584-3", "10.1145/22949.22950", "10.1179/1743277413y.0000000036", "10.1080/15230406.2016.1262280", "10.1016/s0341-8162(01)00164-3", "10.22224/gistbok/2017.3.8", "10.1109/tvcg.2008.155", "10.1057/ivs.2008.31", "10.1016/j.cag.2004.03.012", "10.1179/1743277412y.0000000007", "10.1016/j.soncn.2011.02.001", "10.1179/caj.1987.24.1.27", "10.3138/carto.48.3.1691", "10.5220/0004267205150524", "10.1109/38.974518", "10.1145/102377.115768", "10.1057/palgrave.ivs.9500186", "10.1109/5.58325", "10.5167/80972.uzh-80972", "10.1177/030913339602000204", "10.1007/978-3-642-22300-6\\_14", "10.1109/iv.2004.1320189", "10.1111/cgf.13447", "10.1007/s11192-017-2596-3", "10.1559/1523040053722150", "10.1007/978-3-662-45803-7\\_34"], "wos": 1, "children": [], "len": 1}], "len": 3}, {"doi": "10.1109/tvcg.2019.2934266", "title": "VASSL: A Visual Analytics Toolkit for Social Spambot Labeling", "year": "2019", "conferenceName": "VAST", "authors": "Mosab Khayat;Morteza Karimzadeh;Jieqiong Zhao;David S. Ebert", "citationCount": "1", "affiliation": "Khayat, M (Corresponding Author), Purdue Univ, W Lafayette, IN 47907 USA. Khayat, Mosab; Zhao, Jieqiong; Ebert, David S., Purdue Univ, W Lafayette, IN 47907 USA. Karimzadeh, Morteza, Univ Colorado, Purdue Univ, Boulder, CO 80309 USA.", "countries": "USA", "abstract": "Social media platforms are filled with social spambots. Detecting these malicious accounts is essential, yet challenging, as they continually evolve to evade detection techniques. In this article, we present VASSL, a visual analytics system that assists in the process of detecting and labeling spambots. Our tool enhances the performance and scalability of manual labeling by providing multiple connected views and utilizing dimensionality reduction, sentiment analysis and topic modeling, enabling insights for the identification of spambots. The system allows users to select and analyze groups of accounts in an interactive manner, which enables the detection of spambots that may not be identified when examined individually. We present a user study to objectively evaluate the performance of VASSL users, as well as capturing subjective opinions about the usefulness and the ease of use of the tool.", "keywords": "Spambot,Labeling,Detection,Visual Analytics,Social Media Annotation", "link": "http://dx.doi.org/10.1109/TVCG.2019.2934266", "refList": ["10.7326/0003-4819-110-11-916", "10.1109/tifs.2013.2267732", "10.1111/cgf.12106", "10.1016/j.ins.2013.11.016", "10.1109/tvcg.2017.2752166", "10.1109/vast.2016.7883510", "10.1109/vl.1996.545307", "10.1145/2872518.2889302", "10.1109/tmm.2016.2614220", "10.1145/2818717", "10.1109/tdsc.2017.2681672", "10.1111/cgf.13211", "10.2307/2685478", "10.1109/tvcg.2014.2346920", "10.1109/tdsc.2016.2641441", "10.1109/tvcg.2017.2745080", "10.1109/vast.2012.6400557", "10.1109/asonam.2016.7752287", "10.1109/tvcg.2014.2346922", "10.1111/cgf.13217", "10.2307/249008", "10.1109/tvcg.2017.2711030", "10.1109/mcse.2013.70", "10.1109/tvcg.2015.2467196", "10.1016/j.comcom.2013.04.004", "10.1109/asonam.2014.6921650", "10.1109/mc.2016.183", "10.1126/science.290.5500.2323", "10.1145/3041021.3055135", "10.1162/jmlr.2003.3.4-5.993", "10.1109/tvcg.2017.2745083", "10.1109/tvcg.2013.153", "10.1109/iv.2008.89", "10.1109/mcom.2013.6588663", "10.1179/000870403235002042", "10.1145/3047010"], "wos": 1, "children": [{"doi": "10.1111/cgf.14034", "year": "2020", "title": "The State of the Art in Enhancing Trust in Machine Learning Models with the Use of Visualizations", "conferenceName": "EuroVis", "authors": "Angelos Chatzimparmpas;Rafael Messias Martins;Ilir Jusufi;Kostiantyn Kucher;Fabrice Rossi;Andreas Kerren", "citationCount": "2", "affiliation": "Chatzimparmpas, A (Corresponding Author), Linnaeus Univ, Dept Comp Sci \\& Media Technol, Vaxjo, Sweden.\nChatzimparmpas, A.; Martins, R. M.; Jusufi, I.; Kucher, K.; Kerren, A., Linnaeus Univ, Dept Comp Sci \\& Media Technol, Vaxjo, Sweden.\nRossi, F., PSL Univ, Univ Paris Dauphine, Ceremade, Paris, France.", "countries": "Sweden;France", "abstract": "Machine learning (ML) models are nowadays used in complex applications in various domains, such as medicine, bioinformatics, and other sciences. Due to their black box nature, however, it may sometimes be hard to understand and trust the results they provide. This has increased the demand for reliable visualization tools related to enhancing trust in ML models, which has become a prominent topic of research in the visualization community over the past decades. To provide an overview and present the frontiers of current research on the topic, we present a State-of-the-Art Report (STAR) on enhancing trust in ML models with the use of interactive visualization. We define and describe the background of the topic, introduce a categorization for visualization techniques that aim to accomplish this goal, and discuss insights and opportunities for future research directions. Among our contributions is a categorization of trust against different facets of interactive ML, expanded and improved from previous research. Our results are investigated from different analytical perspectives: (a) providing a statistical overview, (b) summarizing key findings, (c) performing topic analyses, and (d) exploring the data sets used in the individual papers, all with the support of an interactive web-based survey browser. We intend this survey to be beneficial for visualization researchers whose interests involve making ML models more trustworthy, as well as researchers and practitioners from other disciplines in their search for effective visualization techniques suitable for solving their tasks with confidence and conveying meaning to their data.", "keywords": "trustworthy machine learning; visualization; interpretable machine learning; explainable machine learning", "link": "https://doi.org/10.1111/cgf.14034", "refList": ["10.1109/mcg.2018.2878902", "10.1109/tvcg.2008.153", "10.2312/mlvis.20181130", "10.1109/tvcg.2016.2598828", "10.1145/3290605.3300911", "10.1145/2993901.2993909", "10.2312/mlvis.20191158", "10.1109/tvcg.2016.2598446", "10.1111/j.1467-8659.2009.01475.x", "10.1145/3290605.3300809", "10.1109/pacificvis.2018.00031", "10.1055/s-0029-1216348", "10.1007/978-3-319-90403-0\\_13", "10.1109/tvcg.2017.2745085", "10.1111/j.1467-8659.2011.01938.x", "10.1007/978-3-319-54024-5\\_6", "10.1016/s0167-9473(01)00065-2", "10.1111/cgf.12895", "10.2312/eurovisshort.20141152.17", "10.2312/eurova.20151098.22", "10.1111/cgf.13667", "10.3115/1072228.1072378", "10.1109/tbdata.2018.2877350.16", "10.1109/lars.2009.5418323.25", "10.1109/tvcg.2017.2744878", "10.1016/j.combustflame.2005.09.018", "10.1016/j.cag.2014.01.006", "10.1109/tvcg.2016.2570755", "10.2312/mlvis.20191158.1,19", "10.1518/hfes.46.1.50.30392", "10.1145/3301275.3302280", "10.1145/3351095.3372834.1", "10.1016/s0377-2217(01)00264-8", "10.1111/cgf.13424", "10.1007/978-3-319-23485-4\\_53", "10.1007/978-94-007-0753-5\\_3623", "10.1109/tvcg.2013.101", "10.1111/cgf.12884", "10.1111/j.1467-8659.2010.01835.x", "10.1021/ci9901338", "10.4230/lipics.itcs:2017", "10.1109/mis.2013.24", "10.1109/tvcg.2014.2346482", "10.1109/tvcg.2018.2865230", "10.1073/pnas.1807180116", "10.1109/dsaa.2018.00018", "10.1109/tvcg.2009.153", "10.3115/1219840.1219855", "10.1109/tvcg.2018.2864812", "10.1109/tvcg.2018.2872577", "10.2312/trvis.20191183", "10.1109/cvpr:2004.383", "10.1109/vast.2008.4677350", "10.1145/302979.303001", "10.1109/tvcg.2018.2864499", "10.1111/cgf.13672", "10.1109/tvcg.2014.2346626", "10.23915/distill.00010.18", "10.1109/tvcg.2017.2744805", "10.2312/mlvis:20191160.18", "10.23915/distill:00016", "10.1109/pacificvis.2016.7465260", "10.1111/cgf.13683", "10.23915/distill.00016.19", "10.1145/32906053.300803.22", "10.1109/tvcg.2014.2346574", "10.1177/1473871615600010", "10.1109/tvcg.2016.2598831", "10.1145/3230623", "10.1109/visual.2019.8933744", "10.1145/2993901.2993915", "10.1016/j.visinf.2017.01.006", "10.1145/2993901.2993914", "10.1109/tvcg.2014.2346984", "10.1109/5.726791", "10.23915/distill.00010", "10.1109/tvcg.2018.2864825", "10.2307/2394164", "10.1109/tvcg.2017.2744458", "10.1145/2993901.2993917.28", "10.1111/cgf.13711", "10.1109/tvcg.2016.2598664", "10.2307/2530428", "10.1109/icdar.1997.620583", "10.1109/tvcg.2017.2744718", "10.1111/cgf.13425", "10.1109/tvcg.2019.2903943", "10.1145/1518701.1518895", "10.1109/tvcg.2018.2864838", "10.1145/62038.62043", "10.1111/j.1467-8659.2011.01920.x", "10.1145/3025171.3025208", "10.1145/355112.355124", "10.1109/vast.2010.5652398", "10.1109/tvcg.2014.2346578", "10.1145/3173574.3174209", "10.4178/epih/e2014008", "10.1109/beliv.2018.8634201.25,28", "10.1016/j.eswa.2007.12.020", "10.1111/cgf:13406", "10.1109/mcg.2011.103", "10.1631/fitee.1700808", "10.1109/tvcg.2017.2745158", "10.1073/pnas.0307752101", "10.1109/tvcg.2018.2816223", "10.1109/tvcg.2017.2745141", "10.1145/32232.32234", "10.1109/tvcg.2019.2934267", "10.1109/tvcg.2018.2864477", "10.1145/3132169", "10.2312/eurova.20151100.19", "10.1145/3172944.3172964", "10.1145/2601248.2601268", "10.1109/isai-nlp.2018.8693002.1", "10.1111/cgf.13404", "10.1007/s100320200071", "10.2312/trvis.20191183.16", "10.1111/cgf.12755", "10.1145/2702123.2702509", "10.1145/1401890.1402008.25", "10.1109/tvcg.2012.65", "10.1177/1473871617733996", "10.2312/trvis.20191187.7", "10.21236/ada273556", "10.1109/vast.2010.5652450", "10.1111/j.1467-8659.2011.01940.x", "10.1177/875647939000600106", "10.1109/tvcg.2017.2711030", "10.1016/j.immuni.2016.04.014", "10.1109/tvcg.2019.2934209", "10.1016/0095-0696(78)90006-2", "10.1016/j.jclinepi.2015.04.014", "10.1016/j.ress.2013.02.013", "10.1111/cgf.12640", "10.1145/1015330.1015388.25", "10.1111/j.1467-8659.2009.01468.x", "10.1145/1541880.1541882", "10.1109/vast.2011.6102453", "10.1016/s0008-8846(98)00165-3", "10.2312/trvis.20191186.7", "10.1007/s13748-013-0040-3", "10.1109/tvcg.2015.2467757", "10.1109/tbdata.2018.2877350", "10.1109/vast.2017.8585613", "10.1080/10556789208805504", "10.1109/vast.2012.6400484", "10.1145/3025171.3025181", "10.1007/978-3-319-90403-0\\_12", "10.1109/mcg.2019.2922592", "10.1021/ci000392t", "10.1109/vast.2007.4389000", "10.1111/cgf.13406.16", "10.1111/cgf.13684", "10.2312/eurovisshort.20161166.17", "10.2312/evs:20191168", "10.1145/3041021.3055135", "10.1145/3301275.3302265", "10.1613/jair.4135", "10.1109/tvcg.2018.2864500", "10.1109/tvcg.2017.2744158", "10.1109/ssci.2015.33", "10.1111/cgf.13453", "10.2312/pe/eurovast/eurova11/049-052", "10.1145/3025171.3025181.13", "10.1145/371920.372094", "10.1109/tvcg.2017.2744938", "10.1111/j.1467-8659.2012.03108.x", "10.1109/tvcg.2019.2934251", "10.1145/3290605.3300809.18", "10.1109/ldav.2016.7874305", "10.1109/vast.2016.7883514", "10.1109/iccv.2015.425", "10.1145/3301275.3302324", "10.1109/tnnls.2013.2292894", "10.1109/tvcg.2018.2865044", "10.1109/tvcg.2013.157", "10.1371/journal.pcbi.0020161", "10.1186/s12916-019-1426-2", "10.1109/10.867928", "10.1111/cgf.13217", "10.1109/mcg.2019.2919033", "10.1145/2993901.2993910", "10.1109/tvcg.2017.2744738", "10.2307/258792", "10.1111/cgf.12655", "10.1016/j.dss.2014.03.001", "10.1109/tvcg.2019.2904069", "10.1111/cgf.13205", "10.1002/mds.22340", "10.1109/tvcg.2019.2934595", "10.1287/inte.2018.0957", "10.1109/cvpr.2007.382974", "10.1109/tvcg.2012.280", "10.1145/2678025.2701399.13", "10.2312/mlvis.20181130.13", "10.2312/eurova.20181106.16", "10.1109/tvcg.2018.2864475", "10.2312/mlvis.20191160.18,22", "10.1007/978-1-4612-4026-6.25", "10.1109/cvpr.2006.42", "10.1145/3172944.3172950", "10.1109/cvpr.2004.383.25", "10.1109/tvcg.2019.2934812", "10.1609/aimag.v35i4.2513", "10.2312/trvis.20191185.7", "10.1111/j.1467-8659.2009.01684.x", "10.1371/journal.pone.0129126", "10.1111/cgf.13092", "10.1162/coli\\_a\\_00237", "10.1109/tvcg.2017.2744818", "10.1109/vast.2011.6102448", "10.1109/tvcg.2009.111", "10.1109/tvcg.2019.2934619", "10.1016/s0377-2217(01)00264-8.25", "10.1111/cgf.12639", "10.1109/access.2019.2919343", "10.1186/s12874-019-0681-4", "10.1109/pacificvis.2015.7156366", "10.1109/pacificvis.2018.00029", "10.1109/tvcg.2019.2934261", "10.1080/13506280444000102.http://www.uvt.nl/ticc", "10.1109/vast.2018.8802509", "10.1111/cgf.13212", "10.1145/3200489", "10.1111/cgf.13176", "10.1177/1473871620904671", "10.1007/978-3-319-10590-1\\_53", "10.1111/j.1467-8659.2012.03126.x", "10.1111/cgf.13172", "10.1145/3025171.3025208.6,21", "10.1111/cgf.12366", "10.1109/tvcg.2019.2934659", "10.1109/cvprw.2009.5206848", "10.1016/j.media.2014.11.010", "10.1109/tvcg.2017.2744683", "10.1109/tvcg.2019.2934262", "10.1016/j.neucom.2006.11.018", "10.1177/1473871615571951", "10.1371/journal.pcbi.0020161.25", "10.1177/1473871611415994", "10.2312/trvis20191187", "10.2312/eurova", "10.1145/2858036.2858529", "10.1145/2207676.2207738", "10.1007/s11042-009-0417-2", "10.1145/3301275.3302317", "10.1038/s41746-019-0148-3", "10.1145/3351095.3372834", "10.1080/10691898.2011.11889627", "10.1109/tvcg.2018.2864504", "10.1109/vast.2017.8585720", "10.1109/mcg.2018.053491732", "10.1007/s10994-010-5207-6", "10.1109/tvcg.2019.2934433", "10.1016/j.cag.2017.05.005", "10.1109/tvcg.2012.279", "10.1145/3231622.3231641.19,20", "10.1145/1562849.1562851", "10.1007/11564126\\_", "10.1109/tvcg.2018.2846735", "10.3115/1225403.1225421", "10.1109/vast.2012.6400486", "10.2312/eurova.20191116.22", "10.1109/tvcg.2007.70443", "10.1080/027868291009242", "10.2312/eurova.20151100", "10.1145/2939502.2939503.19", "10.1016/j.cag.2014.02.004", "10.1145/2939672.2939778", "10.1109/vast.2010.5652484", "10.1111/cgf.12641", "10.1145/3301275.3302289", "10.1109/visual.2019.8933619", "10.1109/tvcg.2017.2672987", "10.1109/vast.2016.7883517.20", "10.1109/igarss.2017.8127684", "10.1016/j.jcae.2010.04.002", "10.1109/vast.2010.5652885", "10.1016/j.visinf.2019.03.002", "10.1007/s00371-018-1500-3", "10.1109/mcg.2018.042731661", "10.1109/34.598228", "10.1109/tvcg.2018.2865027", "10.1016/j.neucom.2017.01.105", "10.1111/cgf.12389", "10.1109/tvcg.2019.2934591", "10.1109/vast.2010.5652392.16", "10.1111/cgf.13416", "10.1080/02701367.1992.10608764", "10.1109/vast.2017.8585721", "10.1109/tvcg.2018.2843369", "10.1109/sbes.2010.27", "10.1109/vast.2015.7347637", "10.1145/1401890.1402008", "10.1016/j.bpj.2010.04.064", "10.1109/tvcg.2013.125", "10.1109/isai-nlp.2018.8693002", "10.1371/journal.pone.0160127", "10.1145/2856767.2856779", "10.1145/2678025.2701399", "10.1109/vast.2011.6102451", "10.1109/mcg.2010.18", "10.1021/ci4000213", "10.1109/vast.2012.6400492", "10.1007/11564126-49.25", "10.2312/eurova.20171114", "10.1109/vast.2010.5652443", "10.1145/3134599", "10.2312/pe/eurovast/eurovast10/013-018.19", "10.1109/tvcg.2019.2903946", "10.1109/tvcg.2015.2467717", "10.1177/1473871612460526", "10.1016/j.cag.2018.09.018", "10.1109/tvcg.2016.2598838", "10.1145/3172944.3172964.14", "10.1109/vast.2009.5333428", "10.1109/vast.2014.7042480", "10.2312/pe/eurovast/eurovast10/013-018", "10.1177/0962280215588241", "10.1145/2993901.2993917", "10.1109/cvpr.2008:4587581", "10.1109/tvcg.2015.2467551", "10.1016/j.visinf.2018.09.001", "10.1126/science.290.5500.2319", "10.2312/eurova.20151107", "10.1109/visual.2019.8933695", "10.13140/2.1.2393.1847", "10.1197/jamia.m1929", "10.1109/cvpr.2008.4587581.25", "10.1145/1518701.1518895.16", "10.1109/vds.2017.8573444", "10.2312/trvis:20191185", "10.1145/3359786", "10.13140/2.1.1341.1520", "10.2312/pe/eurovast/eurova11/049-052.17", "10.1109/tvcg.2014.2346660", "10.1145/3185517", "10.1109/adprl.2011.5967372", "10.1109/tvcg.2015.2467591", "10.1111/j.1751-9004.2009.00232.x", "10.1136/qshc.2004.010033", "10.1109/vast.2012.6400493", "10.1109/tvcg.2019.2934266", "10.1145/2971763.2971775", "10.1111/cgf.13730", "10.1109/vast.2012.6400488", "10.1111/cgf.13210", "10.1109/tvcg.2019.2934631", "10.1145/3172944.3172965", "10.1057/ivs.2010.2", "10.1109/tvcg.2017.2745258", "10.1016/j.jbusres.2019.07.039", "10.1162/jmlr.2003.3.4-5.993", "10.1109/pacificvis.2019.00044", "10.2312/pe/eurovast/eurova12/037-041", "10.1109/tvcg.2019.2934629", "10.1177/0018720814547570", "10.1145/3292500.3330908", "10.1111/j.1467-8659.2009.01467.x", "10.2312/eurova.20151098", "10.1177/1473871617713337", "10.1109/lars:2009.5418323", "10.1109/vast.2011.6102437", "10.1111/cgf.12878", "10.1561/1500000001", "10.1145/3025171.3025222", "10.1007/s11704-016-6028-y", "10.1016/j.procs.2017.05.216", "10.1109/cvpr.2007.382974.25", "10.1080/10447318.2020.1741118", "10.1109/vast.2012.6400489", "10.1145/3025171.3025172", "10.1109/tvcg.2017.2744098", "10.1109/tvcg.2005.66", "10.1016/j.dss.2009.05.016", "10.1007/978-1-4612-4026-6", "10.2312/evs.20191168.16,20,28", "10.2312/pe/eurovast/eurova12/037-041.17", "10.1145/3290605.3300803", "10.1145/1015330.1015388", "10.1111/cgf.13197", "10.1016/b978-1-55860-377-6.50048-7", "10.1111/cgf.13681", "10.1109/tvcg.2017.2744378", "10.1109/tvcg.2017.2744358", "10.1109/vast.2008.4677352"], "wos": 1, "children": [{"doi": "10.1109/tvcg.2020.3030368", "title": "Implicit Multidimensional Projection of Local Subspaces", "year": "2020", "conferenceName": "InfoVis", "authors": "Rongzheng Bian;Yumeng Xue;Liang Zhou;Jian Zhang 0070;Baoquan Chen;Daniel Weiskopf;Yunhai Wang", "citationCount": "1", "affiliation": "Wang, YH (Corresponding Author), Shandong Univ, Qingdao, Peoples R China. Zhou, L (Corresponding Author), Univ Utah, Salt Lake City, UT 84112 USA. Bian, Rongzheng; Xue, Yumeng; Wang, Yunhai, Shandong Univ, Qingdao, Peoples R China. Chen, Baoquan, Peking Univ, Beijing, Peoples R China. Zhang, Jian, Chinese Acad Sci, CNIC, Beijing, Peoples R China. Zhou, Liang, Univ Utah, Salt Lake City, UT 84112 USA. Weiskopf, Daniel, Univ Stuttgart, Stuttgart, Germany.", "countries": "USA;Germany;China", "abstract": "We propose a visualization method to understand the effect of multidimensional projection on local subspaces, using implicit function differentiation. Here, we understand the local subspace as the multidimensional local neighborhood of data points. Existing methods focus on the projection of multidimensional data points, and the neighborhood information is ignored. Our method is able to analyze the shape and directional information of the local subspace to gain more insights into the global structure of the data through the perception of local structures. Local subspaces are fitted by multidimensional ellipses that are spanned by basis vectors. An accurate and efficient vector transformation method is proposed based on analytical differentiation of multidimensional projections formulated as implicit functions. The results are visualized as glyphs and analyzed using a full set of specifically-designed interactions supported in our efficient web-based visualization tool. The usefulness of our method is demonstrated using various multi- and high-dimensional benchmark datasets. Our implicit differentiation vector transformation is evaluated through numerical comparisons; the overall method is evaluated through exploration examples and use cases.", "keywords": "High-dimensional data visualization,dimensionality reduction,local linear subspaces,user interaction", "link": "http://dx.doi.org/10.1109/TVCG.2020.3030368", "refList": ["10.3844/jcssp.2018.613.622", "10.1016/j.aci.2018.08.003", "10.3390/info9030065", "10.1016/j.visinf.2018.09.003", "10.1371/journal.pone.0118432", "10.1016/s0893-6080(05)80023-1", "10.1109/tvcg.2020.2986996", "10.1109/icst.2012.56", "10.1007/s10844-013-0250-y", "10.1109/tbdata.2018", "10.1145/1125451.1125659", "10.1109/tvcg.2013.125", "10.1177/1473871611412817", "10.1145/3290605.3300911", "10.1111/cgf.14034", "10.1007/s13721-013-0034-x", "10.1016/j.procs.2017.05.216", "10.1016/j.ins.2009.08.025", "10.1109/tvcg.2013.124", "10.1109/tvcg.2018.2864499", "10.1109/tvcg.2018.2864475", "10.1080/10447318.2020.1741118", "10.1016/j.imu.2019.100203", "10.1109/tvcg.2018.2865240", "10.1186/s12864-019-6413-7", "10.1109/tvcg.2015.2467551", "10.1002/widm.1249", "10.1007/978-3-319-66429-3\\_29", "10.1109/tvcg.2014.2346481", "10.1109/tvcg.2018.2864825", "10.1177/1473871620904671", "10.1109/tvcg.2019.2934267", "10.1136/bmjopen-2016-012799", "10.1109/smartgridcomm.2017.8340682", "10.1007/s10664-015-9401-9", "10.1145/1143844.1143874", "10.1111/cgf.12389", "10.1109/tvcg.2018.2872577", "10.1007/978-981-13-5802-9\\_20", "10.1016/j.ipm.2009.03.002", "10.5220/0006431602160222", "10.1109/mcg.2015.50", "10.1109/tvcg.2014.2346574", "10.1007/bf02289565", "10.1109/tvcg.2017.2744378", "10.1016/j.patrec.2008.08.010", "10.1023/a:1010933404324", "10.9735/2229-3981"], "wos": 1, "children": [], "len": 1}, {"doi": "10.1109/tvcg.2020.3030465", "title": "Visual Causality Analysis of Event Sequence Data", "year": "2020", "conferenceName": "VAST", "authors": "Zhuochen Jin;Shunan Guo;Nan Chen;Daniel Weiskopf;David Gotz;Nan Cao", "citationCount": "0", "affiliation": "Cao, N (Corresponding Author), Tongji Univ, IDVx Lab, Shanghai, Peoples R China. Jin, Zhuochen; Guo, Shunan; Chen, Nan; Cao, Nan, Tongji Univ, IDVx Lab, Shanghai, Peoples R China. Weiskopf, Daniel, Univ Stuttgart, Stuttgart, Germany. Gotz, David, Univ N Carolina, Chapel Hill, NC 27515 USA.", "countries": "USA;Germany;China", "abstract": "Causality is crucial to understanding the mechanisms behind complex systems and making decisions that lead to intended outcomes. Event sequence data is widely collected from many real-world processes, such as electronic health records, web clickstreams, and financial transactions, which transmit a great deal of information reflecting the causal relations among event types. Unfortunately, recovering causalities from observational event sequences is challenging, as the heterogeneous and high-dimensional event variables are often connected to rather complex underlying event excitation mechanisms that are hard to infer from limited observations. Many existing automated causal analysis techniques suffer from poor explainability and fail to include an adequate amount of human knowledge. In this paper, we introduce a visual analytics method for recovering causalities in event sequence data. We extend the Granger causality analysis algorithm on Hawkes processes to incorporate user feedback into causal model refinement. The visualization system includes an interactive causal analysis framework that supports bottom-up causal exploration, iterative causal verification and refinement, and causal comparison through a set of novel visualizations and interactions. We report two forms of evaluation: a quantitative evaluation of the model improvements resulting from the user-feedback mechanism, and a qualitative evaluation through case studies in different application domains to demonstrate the usefulness of the system.", "keywords": "Event sequence data,causality analysis,visual analytics", "link": "http://dx.doi.org/10.1109/TVCG.2020.3030465", "refList": ["10.5555/1642718", "10.1109/tvcg.2018.2865022", "10.5555/2074094.2074151", "10.1109/tvcg.2016.2618797", "10.1073/pnas.1320645111", "10.1109/tvcg.2017.2744843", "10.1109/iv.2017.69", "10.1109/tvcg.2019.2934399", "10.1145/3172944.3173007", "10.5555/1795555", "10.1109/mcg.2005.102", "10.1145/381641.381653", "10.1162/153244301753344614", "10.1111/cgf.14034", "10.1111/cgf.13198", "10.1017/cbo9780511519857", "10.1007/s10462-016-9475-9", "10.1075/ssol.2.2.07bor", "10.1007/978-1-4614-3223-4\\_3", "10.1109/infvis.2003.1249025", "10.1007/978-94-007-6094-313", "10.1145/2858036.2858387", "10.1109/tvcg.2007.70528", "10.1109/tvcg.2017.2674958", "10.1147/sj.454.0801", "10.1109/tvcg.2013.119", "10.1145/3173574.3173711", "10.1016/j.erss.2017.06.034", "10.1109/visual.2019.8933695", "10.1007/s11665-016-2173-6", "10.1016/0377-0427(87)90125-7", "10.2307/3601125", "10.1016/b978-0-444-88738-2.50018-x", "10.1109/mcg.2006.70", "10.1109/tvcg.2018.2865145", "10.1017/s1351324997001502", "10.1109/tvcg.2010.179", "10.1214/aos/1176344552", "10.1109/mcg.2009.22", "10.1007/978-3-319-26633-6\\_13", "10.1080/10447318.2014.905422", "10.1016/j.visinf.2019.03.004", "10.1057/palgrave.ivs.9500074", "10.1007/978-1-4614-3223-4"], "wos": 1, "children": [], "len": 1}], "len": 5}], "len": 7}, {"doi": "10.1109/tvcg.2020.3030411", "title": "Co-Bridges: Pair-wise Visual Connection and Comparison for Multi-item Data Streams", "year": "2020", "conferenceName": "VAST", "authors": "Siming Chen;Natalia V. Andrienko;Gennady L. Andrienko;Jie Li 0006;Xiaoru Yuan", "citationCount": "0", "affiliation": "Yuan, XR (Corresponding Author), Peking Univ, Beijing, Peoples R China. Chen, Siming, Fudan Univ, Sch Data Sci, Shanghai, Peoples R China. Chen, Siming; Andrienko, Natalia; Andrienko, Gennady, Fraunhofer Inst IAIS, St Augustin, Germany. Andrienko, Natalia; Andrienko, Gennady, City Univ London, London, England. Li, Jie, Tianjin Univ, Tianjin, Peoples R China. Yuan, Xiaoru, Peking Univ, Beijing, Peoples R China.", "countries": "Germany;China;England", "abstract": "In various domains, there are abundant streams or sequences of multi-item data of various kinds, e.g. streams of news and social media texts, sequences of genes and sports events, etc. Comparison is an important and general task in data analysis. For comparing data streams involving multiple items (e.g., words in texts, actors or action types in action sequences, visited places in itineraries, etc.), we propose Co-Bridges, a visual design involving connection and comparison techniques that reveal similarities and differences between two streams. Co-Bridges use river and bridge metaphors, where two sides of a river represent data streams, and bridges connect temporally or sequentially aligned segments of streams. Commonalities and differences between these segments in terms of involvement of various items are shown on the bridges. Interactive query tools support the selection of particular stream subsets for focused exploration. The visualization supports both qualitative (common and distinct items) and quantitative (stream volume, amount of item involvement) comparisons. We further propose Comparison-of-Comparisons, in which two or more Co-Bridges corresponding to different selections are juxtaposed. We test the applicability of the Co-Bridges in different domains, including social media text streams and sports event sequences. We perform an evaluation of the users' capability to understand and use Co-Bridges. The results confirm that Co-Bridges is effective for supporting pair-wise visual comparisons in a wide range of applications.", "keywords": "Visual Comparison,Pair-wise Analysis,Multi-item Data Stream,Social Media", "link": "http://dx.doi.org/10.1109/TVCG.2020.3030411", "refList": ["10.1109/tvcg.2014.2346753", "10.1109/pacificvis.2010.5429590", "10.1109/vast.2009.5333443", "10.1101/gr.2289704", "10.1177/1473871611416549", "10.1057/palgrave.ivs.9500099", "10.1109/vast.2017.8585638", "10.1109/vast.2014.7042496", "10.1109/tvcg.2017.2764459", "10.1109/tvcg.2013.221", "10.1109/vast.2011.6102439", "10.1109/tvcg.2013.213", "10.1109/tmm.2016.2614220", "10.1109/tvcg.2016.2598797", "10.1145/2207676.2208556", "10.1145/1835804.1835827", "10.1109/tvcg.2013.124", "10.2312/conf/eg2013/stars/039-063", "10.1111/cgf.13211", "10.1109/tvcg.2014.2346920", "10.1109/tvcg.2011.239", "10.1016/j.jvlc.2018.08.008", "10.1109/mcg.2018.032421661", "10.1109/tvcg.2017.2744199", "10.1109/tvcg.2019.2934535", "10.1109/tvcg.2018.2864526", "10.1007/978-0-85729-436-4\\_9", "10.1109/vast.2016.7883511", "10.1109/tvcg.2014.2346682", "10.1109/tvcg.2015.2467618", "10.1145/2566486.2567977", "10.1109/tvcg.2017.2745320", "10.1080/136588199241247", "10.1111/cgf.13401", "10.1109/tvcg.2018.2864884", "10.1109/tvcg.2012.291", "10.1109/vast.2012.6400485", "10.1109/pacificvis.2016.7465266", "10.1109/tvcg.2011.232", "10.1109/tvcg.2017.2745083", "10.1109/tvcg.2012.253", "10.1007/s12650-014-0246-x", "10.1109/tvcg.2010.20", "10.1109/tvcg.2014.2346919", "10.1109/visual.2019.8933646", "10.1007/978-0-85729-079-3"], "wos": 1, "children": [], "len": 1}, {"doi": "10.1111/cgf.13677", "year": "2019", "title": "An Ontological Framework for Supporting the Design and Evaluation of Visual Analytics Systems", "conferenceName": "EuroVis", "authors": "Min Chen;David S. Ebert", "citationCount": "5", "affiliation": "Chen, M (Corresponding Author), Univ Oxford, Oxford, England.\nChen, Min, Univ Oxford, Oxford, England.\nEbert, David S., Purdue Univ, W Lafayette, IN 47907 USA.", "countries": "USA;England", "abstract": "Designing, evaluating, and improving visual analytics (VA) systems is a primary area of activities in our discipline. In this paper, we present an ontological framework for recording and categorizing technical shortcomings to be addressed in a VA workflow, reasoning about the causes of such problems, identifying technical solutions, and anticipating secondary effects of the solutions. The methodology is built on the theoretical premise that designing a VA workflow is an optimization of the cost-benefit ratio of the processes in the workflow. It makes uses three fundamental measures to group and connect symptoms, causes, remedies, and side-effects, and guide the search for potential solutions to the problems. In terms of requirement analysis and system design, the proposed methodology can enable system designers to explore the decision space in a structured manner. In terms of evaluation, the proposed methodology is time-efficient and complementary to various forms of empirical studies, such as user surveys, controlled experiments, observational studies, focus group discussions, and so on. In general, it reduces the amount of trial-and-error in the lifecycle of VA system development.", "keywords": "", "link": "https://doi.org/10.1111/cgf.13677", "refList": ["10.1109/tvcg.2006.178", "10.1109/infvis.2000.885092", "10.1111/cgf.12920", "10.1057/ivs.2009.26", "10.1109/mcg.2017.3271463", "10.1007/978-3-319-10578-9\\_1", "10.1109/icdmw.2008.62", "10.1109/mcg.2017.51", "10.1145/3011141.3011207", "10.1109/tvcg.2013.134", "10.1080/10618600.1996.10474696", "10.1007/978-3-540-70956-5", "10.1109/visual.1990.146375", "10.1109/tvcg.2012.219", "10.1109/vl.1996.545307", "10.1057/ivs.2009.23", "10.1002/j.1538-7305.1948.tb00917.x", "10.1109/tvcg.2010.79", "10.1109/tvcg.2013.124", "10.1111/cgf.13211", "10.1007/978-3-642-40897-7\\_9", "10.1103/physrev.108.171", "10.1109/infvis.2004.59", "10.1109/iv.2008.36", "10.1111/cgf.13210", "10.1111/j.1467-8659.2008.01230.x", "10.1001/jama.293.10.1223", "10.1177/1473871611407399", "10.1109/visual.1995.480821", "10.1117/12.539227", "10.1109/tvcg.2015.2513410", "10.1109/vast.2011.6102463", "10.7749/citiescommunitiesterritories.dec2014.029.art01", "10.1109/mcg.2005.55", "10.1109/tvcg.2012.234", "10.1109/pacificvis.2012.6183556", "10.1103/physrev.106.620", "10.1109/infvis.1997.636792", "10.2307/2104491", "10.1145/2468356.2468677", "10.1145/3173574.3173611", "10.1109/tvcg.2018.2864838", "10.1111/cgf.13092", "10.1109/visual.2004.10", "10.1109/tvcg.2017.2744319", "10.1109/tvcg.2009.111", "10.1109/tvcg.2013.120", "10.1109/tvcg.2016.2603178"], "wos": 1, "children": [{"doi": "10.1109/tvcg.2019.2934264", "title": "The Validity, Generalizability and Feasibility of Summative Evaluation Methods in Visual Analytics", "year": "2019", "conferenceName": "VAST", "authors": "Mosab Khayat;Morteza Karimzadeh;David S. Ebert;Arif Ghafoor", "citationCount": "1", "affiliation": "Khayat, M (Corresponding Author), Purdue Univ, W Lafayette, IN 47907 USA. Khayat, Mosab; Karimzadeh, Morteza; Ebert, David S.; Ghafoor, Arif, Purdue Univ, W Lafayette, IN 47907 USA. Karimzadeh, Morteza, Univ Colorado, Boulder, CO 80309 USA.", "countries": "USA", "abstract": "Many evaluation methods have been used to assess the usefulness of Visual Analytics (VA) solutions. These methods stem from a variety of origins with different assumptions and goals, which cause confusion about their proofing capabilities. Moreover, the lack of discussion about the evaluation processes may limit our potential to develop new evaluation methods specialized for VA. In this paper, we present an analysis of evaluation methods that have been used to summatively evaluate VA solutions. We provide a survey and taxonomy of the evaluation methods that have appeared in the VAST literature in the past two years. We then analyze these methods in terms of validity and generalizability of their findings, as well as the feasibility of using them. We propose a new metric called summative quality to compare evaluation methods according to their ability to prove usefulness, and make recommendations for selecting evaluation methods based on their summative quality in the VA domain.", "keywords": "Summative evaluation,usefulness,evaluation process,taxonomy,visual analytics", "link": "http://dx.doi.org/10.1109/TVCG.2019.2934264", "refList": ["10.1109/tvcg.2017.2744478", "10.1109/tvcg.2018.2865025", "10.1109/tvcg.2006.85", "10.1109/tvcg.2014.2346331", "10.1109/beliv.2018.8634420", "10.1109/tvcg.2017.2745181", "10.1111/cgf.13677", "10.1109/tvcg.2018.2864844", "10.1109/tvcg.2013.126", "10.1109/tvcg.2018.2864811", "10.1109/infvis.2005.1532147", "10.1177/0956797613504966", "10.1145/2669557.2669579", "10.1109/mcg.2005.102", "10.1109/visual.2003.1250426", "10.1136/bmj.39489.470347.ad", "10.1109/tvcg.2017.2744080", "10.1109/mcg.2009.53", "10.1111/j.1467-8527.2005.00307.x", "10.1109/tvcg.2010.132", "10.1109/tvcg.2018.2864886", "10.1109/tvcg.2018.2864843", "10.1109/tvcg.2018.2865028", "10.1109/tvcg.2018.2865051", "10.1109/tvcg.2018.2865044", "10.1109/tvcg.2018.2865026", "10.1007/978-3-540-71080-6\\_6", "10.1109/tvcg.2018.2865020", "10.1177/1473871611407399", "10.1109/tvcg.2018.2864504", "10.1109/tvcg.2018.2864526", "10.1109/tvcg.2005.53", "10.1109/tvcg.2018.2864905", "10.1049/sej.1991.0040", "10.1109/tvcg.2015.2513410", "10.1109/tvcg.2017.2711030", "10.1109/tvcg.2011.279", "10.1109/vast.2017.8585505", "10.1147/jrd.2010.2042914", "10.1016/s0378-7206(98)00044-5", "10.1145/2993901.2993913", "10.1109/tvcg.2018.2865041", "10.1109/tvcg.2018.2864812", "10.1109/tvcg.2017.2744758", "10.1145/1168149.1168158", "10.1109/tvcg.2017.2745279", "10.1109/tvcg.2012.213", "10.1109/tvcg.2017.2744738", "10.1109/tvcg.2017.2745083", "10.1109/tvcg.2018.2864826", "10.1145/1377966.1377974", "10.1109/apec.2009.4802646", "10.1145/1168149.1168152", "10.1016/j.jss.2008.03.059", "10.1109/vast.2017.8585484", "10.1109/tvcg.2017.2744818", "10.1109/tvcg.2017.2744358", "10.1109/tvcg.2018.2864499", "10.1109/tvcg.2018.2865042", "10.1109/tvcg.2017.2744898"], "wos": 1, "children": [{"doi": "10.1109/tvcg.2020.3030388", "title": "Visualization of Human Spine Biomechanics for Spinal Surgery", "year": "2020", "conferenceName": "SciVis", "authors": "Pepe Eulzer;Sabine Bauer;Francis Kilian;Kai Lawonn", "citationCount": "0", "affiliation": "Eulzer, P (Corresponding Author), Univ Jena, Jena, Germany. Eulzer, Pepe; Lawonn, Kai, Univ Jena, Jena, Germany. Bauer, Sabine, Univ Koblenz Landau, Koblenz, Germany. Kilian, Francis, Cath Clin Koblenz Montabaur, Dept Spine Surg, Koblenz, Germany.", "countries": "Germany", "abstract": "We propose a visualization application, designed for the exploration of human spine simulation data. Our goal is to support research in biomechanical spine simulation and advance efforts to implement simulation-backed analysis in surgical applications. Biomechanical simulation is a state-of-the-art technique for analyzing load distributions of spinal structures. Through the inclusion of patient-specific data, such simulations may facilitate personalized treatment and customized surgical interventions. Difficulties in spine modelling and simulation can be partly attributed to poor result representation, which may also be a hindrance when introducing such techniques into a clinical environment. Comparisons of measurements across multiple similar anatomical structures and the integration of temporal data make commonly available diagrams and charts insufficient for an intuitive and systematic display of results. Therefore, we facilitate methods such as multiple coordinated views, abstraction and focus and context to display simulation outcomes in a dedicated tool. $\\mathrm{By}$ linking the result data with patient-specific anatomy, we make relevant parameters tangible for clinicians. Furthermore, we introduce new concepts to show the directions of impact force vectors, which were not accessible before. We integrated our toolset into a spine segmentation and simulation pipeline and evaluated our methods with both surgeons and biomechanical researchers. When comparing our methods against standard representations that are currently in use, we found increases in accuracy and speed in data exploration tasks. $\\mathrm{in}$ a qualitative review, domain experts deemed the tool highly useful when dealing with simulation result data, which typically combines time-dependent patient movement and the resulting force distributions on spinal structures.", "keywords": "Medical visualization,bioinformatics,coordinated views,focus and context,biomechanical simulation", "link": "http://dx.doi.org/10.1109/TVCG.2020.3030388", "refList": ["10.1109/tvcg.2018.2864903", "10.1177/1473871613510429", "10.1093/ehjqcco/qcz052", "10.1109/tvcg.2007.70594", "10.1109/tvcg.2018.2865076", "10.1055/s-0039-1687862", "10.1109/visual.1990.146375", "10.1109/tvcg.2017.2744198", "10.1016/j.ijmedinf.2014.10.001", "10.1109/tvcg.2013.124", "10.1016/j.jacc", "10.1111/cgf.13167", "10.17705/1thci.00055", "10.1136/bmjqs.2009.037895", "10.1109/tvcg.2013.238", "10.1109/tvcg.2018.2865240", "10.1186/1471-2261-6-34", "10.1109/tvcg.2019.2934264", "10.1109/tvcg.2013.200", "10.1109/tvcg.2011.209", "10.1109/tvcg.2014.2346682", "10.1109/tvcg.2015.2467091", "10.1136/bmjopen-2019-033208", "10.1109/beliv.2018.8634027", "10.1109/tvcg.2012.213", "10.1109/tvcg.2015.2467191", "10.1109/tvcg.2015.2467325", "10.1145/2133806.2133821", "10.1145/1806799.1806866", "10.1108/02635570610688869", "10.1002/hbm.20701", "10.1561/1100000039", "10.1145/3025453.3025645", "10.1109/tvcg.2009.111", "10.1109/tvcg.2013.120", "10.1109/tvcg.2016.2599030"], "wos": 1, "children": [], "len": 1}], "len": 3}], "len": 5}, {"doi": "10.1111/cgf.13987", "year": "2020", "title": "Augmenting Node-Link Diagrams with Topographic Attribute Maps", "conferenceName": "EuroVis", "authors": "Reinhold Preiner;Johanna Schmidt;Katharina Kr{\\\"{o}}sl;Tobias Schreck;Gabriel Mistelbauer", "citationCount": "0", "affiliation": "Preiner, R (Corresponding Author), Graz Univ Technol, Inst Comp Graph \\& Knowledge Visualizat, Graz, Austria.\nPreiner, R.; Schreck, T., Graz Univ Technol, Inst Comp Graph \\& Knowledge Visualizat, Graz, Austria.\nSchmidt, J.; Kroesl, K., Virtual Real \\& Visualisierung Forsch GmbH, VRVis Zentrum, Vienna, Austria.\nKroesl, K., TU Wien, Inst Visual Comp \\& Human Ctr Technol, Vienna, Austria.\nMistelbauer, G., Otto von Guericke Univ, Dept Simulat \\& Graph, Magdeburg, Germany.", "countries": "Germany;Austria", "abstract": "We propose a novel visualization technique for graphs that are attributed with scalar data. In many scenarios, these attributes (e.g., birth date in a family network) provide ambient context information for the graph structure, whose consideration is important for different visual graph analysis tasks. Graph attributes are usually conveyed using different visual representations (e.g., color, size, shape) or by reordering the graph structure according to the attribute domain (e.g., timelines). While visual encodings allow graphs to be arranged in a readable layout, assessing contextual information such as the relative similarities of attributes across the graph is often cumbersome. In contrast, attribute-based graph reordering serves the comparison task of attributes, but typically strongly impairs the readability of the structural information given by the graph's topology. In this work, we augment force-directed node-link diagrams with a continuous ambient representation of the attribute context. This way, we provide a consistent overview of the graph's topological structure as well as its attributes, supporting a wide range of graph-related analysis tasks. We resort to an intuitive height field metaphor, illustrated by a topographic map rendering using contour lines and suitable color maps. Contour lines visually connect nodes of similar attribute values, and depict their relative arrangement within the global context. Moreover, our contextual representation supports visualizing attribute value ranges associated with graph nodes (e.g., lifespans in a family network) as trajectories routed through this height field. We discuss how user interaction with both the structural and the contextual information fosters exploratory graph analysis tasks. The effectiveness and versatility of our technique is confirmed in a user study and case studies from various application domains.", "keywords": "", "link": "https://doi.org/10.1111/cgf.13987", "refList": ["10.1109/tvcg.2013.269", "10.1109/pacificvis.2010.5429590", "10.1073/pnas.0307654100", "10.1145/2505515.2505758", "10.1559/152304082783948286", "10.1109/pacificvis.2014.47", "10.1093/bioinformatics/btp432", "10.1111/j.1467-8659.2011.01898.x", "10.1111/cgf.12931", "10.1111/cgf.12880", "10.1109/tvcg.2014.2346422", "10.1111/j.1467-8659.2009.01706.x", "10.1109/tvcg.2016.2598795", "10.1111/cgf.12800", "10.1109/tvcg.2014.2315995", "10.1111/cgf.12656", "10.1111/cgf.13728", "10.1109/tvcg.2009.122", "10.1111/cgf.13211", "10.1109/tvcg.2007.70596", "10.1109/infvis.2002.1173152", "10.1109/tvcg.2015.2467691", "10.1109/tvcg.2003.1196007", "10.1109/infvis.2005.1532150", "10.1145/3243250.3243266", "10.1080/02693799008941549", "10.1371/journal.pone.0058779", "10.1109/infvis.1995.528686", "10.1111/cgf.12872", "10.1002/spe.4380211102", "10.1109/38.974518", "10.1145/3097983.3098130", "10.1002/aris.1440370106", "10.1145/1360612.1360691", "10.1109/mc.2016.145", "10.2307/3006914", "10.1111/j.1467-8659.2009.01683.x", "10.1145/1639714.1639784"], "wos": 1, "children": [], "len": 1}], "len": 31}], "len": 119}, {"doi": "10.1109/vast.2017.8585505", "title": "Interactive Visual Alignment of Medieval Text Versions", "year": "2017", "conferenceName": "VAST", "authors": "Stefan J\u00e4nicke;David Joseph Wrisley", "citationCount": "5", "affiliation": "Janicke, S (Corresponding Author), Univ Leipzig, Image \\& Signal Proc Grp, Inst Comp Sci, Leipzig, Germany. Jaenicke, Stefan, Univ Leipzig, Image \\& Signal Proc Grp, Inst Comp Sci, Leipzig, Germany. Wrisley, David Joseph, New York Univ Abu Dhabi, Digital Humanities, Abu Dhabi, U Arab Emirates.", "countries": "Emirates;Germany", "abstract": "Textual criticism consists of the identification and analysis of variant readings among different versions of a text. Being a relatively simple task for modern languages, the collation of medieval text traditions ranges from the complex to the virtually impossible depending on the degree of instability of textual transmission. We present a visual analytics environment that supports computationally aligning such complex textual differences typical of orally inflected medieval poetry. For the purpose of analyzing alignment, we provide interactive visualizations for different text hierarchy levels, specifically, a meso reading view to support investigating repetition and variance at the line level across text segments. In addition to outlining important aspects of our interdisciplinary collaboration, we emphasize the utility of the proposed system by various usage scenarios in medieval French literature.", "keywords": "", "link": "http://dx.doi.org/10.1109/VAST.2017.8585505", "refList": ["10.1109/vast.2014.7042493", "10.1109/tvcg.2014.2346435", "10.1109/vast.2009.5333443", "10.1075/ijcl.19.3.05sii", "10.1016/0022-2836(70)90057-4", "10.1016/0022-2836(81)90087-5", "10.1109/tvcg.2015.2467811", "10.1109/tvcg.2010.85", "10.1109/tvcg.2015.2467759", "10.1093/llc/fqu030", "10.1109/vast.2009.5333248", "10.1109/pacificvis.2015.7156366", "10.1109/vl.1996.545307", "10.1111/j.1467-8659.2011.01922.x", "10.1111/cgf.12125", "10.1111/j.1467-8659.2009.01439.x", "10.1109/tvcg.2012.96", "10.1007/978-3-540-71080-6\\_6", "10.1111/cgf.12618", "10.1109/tvcg.2014.2346431", "10.1109/tvcg.2012.277", "10.1111/cgf.12124", "10.1109/tvcg.2014.2346677", "10.1109/tvcg.2008.166", "10.3233/w0r-2010-1109", "10.1109/vast.2007.4389004", "10.1093/llc/fqv049", "10.1109/tvcg.2015.2467620", "10.1017/ccol9780521861755", "10.1109/tvcg.2009.111", "10.1109/tvcg.2008.172", "10.1179/000870403235002042"], "wos": 1, "children": [{"doi": "10.1109/tvcg.2019.2934264", "title": "The Validity, Generalizability and Feasibility of Summative Evaluation Methods in Visual Analytics", "year": "2019", "conferenceName": "VAST", "authors": "Mosab Khayat;Morteza Karimzadeh;David S. Ebert;Arif Ghafoor", "citationCount": "1", "affiliation": "Khayat, M (Corresponding Author), Purdue Univ, W Lafayette, IN 47907 USA. Khayat, Mosab; Karimzadeh, Morteza; Ebert, David S.; Ghafoor, Arif, Purdue Univ, W Lafayette, IN 47907 USA. Karimzadeh, Morteza, Univ Colorado, Boulder, CO 80309 USA.", "countries": "USA", "abstract": "Many evaluation methods have been used to assess the usefulness of Visual Analytics (VA) solutions. These methods stem from a variety of origins with different assumptions and goals, which cause confusion about their proofing capabilities. Moreover, the lack of discussion about the evaluation processes may limit our potential to develop new evaluation methods specialized for VA. In this paper, we present an analysis of evaluation methods that have been used to summatively evaluate VA solutions. We provide a survey and taxonomy of the evaluation methods that have appeared in the VAST literature in the past two years. We then analyze these methods in terms of validity and generalizability of their findings, as well as the feasibility of using them. We propose a new metric called summative quality to compare evaluation methods according to their ability to prove usefulness, and make recommendations for selecting evaluation methods based on their summative quality in the VA domain.", "keywords": "Summative evaluation,usefulness,evaluation process,taxonomy,visual analytics", "link": "http://dx.doi.org/10.1109/TVCG.2019.2934264", "refList": ["10.1109/tvcg.2017.2744478", "10.1109/tvcg.2018.2865025", "10.1109/tvcg.2006.85", "10.1109/tvcg.2014.2346331", "10.1109/beliv.2018.8634420", "10.1109/tvcg.2017.2745181", "10.1111/cgf.13677", "10.1109/tvcg.2018.2864844", "10.1109/tvcg.2013.126", "10.1109/tvcg.2018.2864811", "10.1109/infvis.2005.1532147", "10.1177/0956797613504966", "10.1145/2669557.2669579", "10.1109/mcg.2005.102", "10.1109/visual.2003.1250426", "10.1136/bmj.39489.470347.ad", "10.1109/tvcg.2017.2744080", "10.1109/mcg.2009.53", "10.1111/j.1467-8527.2005.00307.x", "10.1109/tvcg.2010.132", "10.1109/tvcg.2018.2864886", "10.1109/tvcg.2018.2864843", "10.1109/tvcg.2018.2865028", "10.1109/tvcg.2018.2865051", "10.1109/tvcg.2018.2865044", "10.1109/tvcg.2018.2865026", "10.1007/978-3-540-71080-6\\_6", "10.1109/tvcg.2018.2865020", "10.1177/1473871611407399", "10.1109/tvcg.2018.2864504", "10.1109/tvcg.2018.2864526", "10.1109/tvcg.2005.53", "10.1109/tvcg.2018.2864905", "10.1049/sej.1991.0040", "10.1109/tvcg.2015.2513410", "10.1109/tvcg.2017.2711030", "10.1109/tvcg.2011.279", "10.1109/vast.2017.8585505", "10.1147/jrd.2010.2042914", "10.1016/s0378-7206(98)00044-5", "10.1145/2993901.2993913", "10.1109/tvcg.2018.2865041", "10.1109/tvcg.2018.2864812", "10.1109/tvcg.2017.2744758", "10.1145/1168149.1168158", "10.1109/tvcg.2017.2745279", "10.1109/tvcg.2012.213", "10.1109/tvcg.2017.2744738", "10.1109/tvcg.2017.2745083", "10.1109/tvcg.2018.2864826", "10.1145/1377966.1377974", "10.1109/apec.2009.4802646", "10.1145/1168149.1168152", "10.1016/j.jss.2008.03.059", "10.1109/vast.2017.8585484", "10.1109/tvcg.2017.2744818", "10.1109/tvcg.2017.2744358", "10.1109/tvcg.2018.2864499", "10.1109/tvcg.2018.2865042", "10.1109/tvcg.2017.2744898"], "wos": 1, "children": [{"doi": "10.1109/tvcg.2020.3030388", "title": "Visualization of Human Spine Biomechanics for Spinal Surgery", "year": "2020", "conferenceName": "SciVis", "authors": "Pepe Eulzer;Sabine Bauer;Francis Kilian;Kai Lawonn", "citationCount": "0", "affiliation": "Eulzer, P (Corresponding Author), Univ Jena, Jena, Germany. Eulzer, Pepe; Lawonn, Kai, Univ Jena, Jena, Germany. Bauer, Sabine, Univ Koblenz Landau, Koblenz, Germany. Kilian, Francis, Cath Clin Koblenz Montabaur, Dept Spine Surg, Koblenz, Germany.", "countries": "Germany", "abstract": "We propose a visualization application, designed for the exploration of human spine simulation data. Our goal is to support research in biomechanical spine simulation and advance efforts to implement simulation-backed analysis in surgical applications. Biomechanical simulation is a state-of-the-art technique for analyzing load distributions of spinal structures. Through the inclusion of patient-specific data, such simulations may facilitate personalized treatment and customized surgical interventions. Difficulties in spine modelling and simulation can be partly attributed to poor result representation, which may also be a hindrance when introducing such techniques into a clinical environment. Comparisons of measurements across multiple similar anatomical structures and the integration of temporal data make commonly available diagrams and charts insufficient for an intuitive and systematic display of results. Therefore, we facilitate methods such as multiple coordinated views, abstraction and focus and context to display simulation outcomes in a dedicated tool. $\\mathrm{By}$ linking the result data with patient-specific anatomy, we make relevant parameters tangible for clinicians. Furthermore, we introduce new concepts to show the directions of impact force vectors, which were not accessible before. We integrated our toolset into a spine segmentation and simulation pipeline and evaluated our methods with both surgeons and biomechanical researchers. When comparing our methods against standard representations that are currently in use, we found increases in accuracy and speed in data exploration tasks. $\\mathrm{in}$ a qualitative review, domain experts deemed the tool highly useful when dealing with simulation result data, which typically combines time-dependent patient movement and the resulting force distributions on spinal structures.", "keywords": "Medical visualization,bioinformatics,coordinated views,focus and context,biomechanical simulation", "link": "http://dx.doi.org/10.1109/TVCG.2020.3030388", "refList": ["10.1109/tvcg.2018.2864903", "10.1177/1473871613510429", "10.1093/ehjqcco/qcz052", "10.1109/tvcg.2007.70594", "10.1109/tvcg.2018.2865076", "10.1055/s-0039-1687862", "10.1109/visual.1990.146375", "10.1109/tvcg.2017.2744198", "10.1016/j.ijmedinf.2014.10.001", "10.1109/tvcg.2013.124", "10.1016/j.jacc", "10.1111/cgf.13167", "10.17705/1thci.00055", "10.1136/bmjqs.2009.037895", "10.1109/tvcg.2013.238", "10.1109/tvcg.2018.2865240", "10.1186/1471-2261-6-34", "10.1109/tvcg.2019.2934264", "10.1109/tvcg.2013.200", "10.1109/tvcg.2011.209", "10.1109/tvcg.2014.2346682", "10.1109/tvcg.2015.2467091", "10.1136/bmjopen-2019-033208", "10.1109/beliv.2018.8634027", "10.1109/tvcg.2012.213", "10.1109/tvcg.2015.2467191", "10.1109/tvcg.2015.2467325", "10.1145/2133806.2133821", "10.1145/1806799.1806866", "10.1108/02635570610688869", "10.1002/hbm.20701", "10.1561/1100000039", "10.1145/3025453.3025645", "10.1109/tvcg.2009.111", "10.1109/tvcg.2013.120", "10.1109/tvcg.2016.2599030"], "wos": 1, "children": [], "len": 1}], "len": 3}, {"doi": "10.1109/tvcg.2020.3028975", "title": "A Survey of Text Alignment Visualization", "year": "2020", "conferenceName": "InfoVis", "authors": "Tariq Yousef;Stefan J\u00e4nicke", "citationCount": "0", "affiliation": "Yousef, T (Corresponding Author), Univ Leipzig, Leipzig, Germany. Yousef, Tariq, Univ Leipzig, Leipzig, Germany. Janicke, Stefan, Univ Southern Denmark, Odense, Denmark.", "countries": "Germany;Denmark", "abstract": "Text alignment is one of the fundamental techniques text-related domains like natural language processing, computational linguistics, and digital humanities. It compares two or more texts with each other aiming to find similar textual patterns, or to estimate in general how different or similar the texts are. Visualizing alignment results is an essential task, because it helps researchers getting a comprehensive overview of individual findings and the overall pattern structure. Different approaches have been developed to visualize and help making sense of these patterns depending on text size, alignment methods, and, most importantly, the underlying research tasks demanding for alignment. On the basis of those tasks, we reviewed existing text alignment visualization approaches, and discuss their advantages and drawbacks. We finally derive design implications and shed light on related future challenges.", "keywords": "Text Alignment,Text Visualization,Collation,Text Re-Use,Plagiarism Analysis,Translation Studies", "link": "http://dx.doi.org/10.1109/TVCG.2020.3028975", "refList": ["10.1093/bib/bbx108", "10.1109/tvcg.2014.2346435", "10.1093/bioinformatics/btp033", "10.1016/0022-2836(70)90057-4", "10.1093/llc/fqt032", "10.1109/icpr.2018.8545064", "10.1109/pacificvis.2015.7156366", "10.1109/vl.1996.545307", "10.1093/llc/18.1.101", "10.1093/llc/fqu007", "10.1093/llc/fqx024", "10.1109/jcdl.2014.6970166", "10.1109/tvcg.2013.124", "10.1016/j.ijhcs.2009.02.001", "10.1111/cgf.12618", "10.1109/tvcg.2015.2467618", "10.1109/vast.2017.8585505", "10.1109/laweb.2003.1250280", "10.1109/icdar.2013.39", "10.1145/1378889.1378892", "10.1111/cgf.12798", "10.1093/llc/fqt046", "10.1109/tvcg.2011.232", "10.1093/llc/fqv049", "10.1093/library/19.4.514", "10.1107/s0907444909007835", "10.1109/icdar.2011.157", "10.1109/tvcg.2008.172", "10.1179/000870403235002042"], "wos": 1, "children": [], "len": 1}, {"doi": "10.1109/tvcg.2020.3028976", "title": "Attention Flows: Analyzing and Comparing Attention Mechanisms in Language Models", "year": "2020", "conferenceName": "VAST", "authors": "Joseph F. DeRose;Jiayao Wang;Matthew Berger", "citationCount": "0", "affiliation": "DeRose, JF; Wang, JY; Berger, M (Corresponding Author), Vanderbilt Univ, 221 Kirkland Hall, Nashville, TN 37235 USA. DeRose, Joseph F.; Wang, Jiayao; Berger, Matthew, Vanderbilt Univ, 221 Kirkland Hall, Nashville, TN 37235 USA.", "countries": "USA", "abstract": "Advances in language modeling have led to the development of deep attention-based models that are performant across a wide variety of natural language processing (NLP) problems. These language models are typified by a pre-training process on large unlabeled text corpora and subsequently fine-tuned for specific tasks. Although considerable work has been devoted to understanding the attention mechanisms of pre-trained models, it is less understood how a model's attention mechanisms change when trained for a target NLP task. In this paper, we propose a visual analytics approach to understanding fine-tuning in attention-based language models. Our visualization, Attention Flows, is designed to support users in querying, tracing, and comparing attention within layers, across layers, and amongst attention heads in Transformer-based language models. To help users gain insight on how a classification decision is made, our design is centered on depicting classification-based attention at the deepest layer and how attention from prior layers flows throughout words in the input. Attention Flows supports the analysis of a single model, as well as the visual comparison between pre-trained and fine-tuned models via their similarities and differences. We use Attention Flows to study attention mechanisms in various sentence understanding tasks and highlight how attention evolves to address the nuances of solving these tasks.", "keywords": "NLP,Transformer,Visual Analytics", "link": "http://dx.doi.org/10.1109/TVCG.2020.3028976", "refList": ["10.1093/bib/bbx108", "10.1109/tvcg.2014.2346435", "10.1093/bioinformatics/btp033", "10.1016/0022-2836(70)90057-4", "10.1093/llc/fqt032", "10.1109/icpr.2018.8545064", "10.1109/pacificvis.2015.7156366", "10.1109/vl.1996.545307", "10.1093/llc/18.1.101", "10.1109/iccv.2015.507", "10.1093/llc/fqu007", "10.1093/llc/fqx024", "10.1109/jcdl.2014.6970166", "10.1109/tvcg.2013.124", "10.1109/tvcg.2012.96", "10.1016/j.ijhcs.2009.02.001", "10.1111/cgf.12618", "10.1109/tvcg.2015.2467618", "10.1109/vast.2017.8585505", "10.1109/icdar.2013.39", "10.1145/1378889.1378892", "10.1111/cgf.12798", "10.1093/llc/fqt046", "10.1109/tvcg.2011.232", "10.1093/library/19.4.514", "10.1107/s0907444909007835", "10.1109/tvcg.2008.172", "10.1179/000870403235002042"], "wos": 1, "children": [], "len": 1}], "len": 9}, {"doi": "10.1109/tvcg.2020.3028975", "title": "A Survey of Text Alignment Visualization", "year": "2020", "conferenceName": "InfoVis", "authors": "Tariq Yousef;Stefan J\u00e4nicke", "citationCount": "0", "affiliation": "Yousef, T (Corresponding Author), Univ Leipzig, Leipzig, Germany. Yousef, Tariq, Univ Leipzig, Leipzig, Germany. Janicke, Stefan, Univ Southern Denmark, Odense, Denmark.", "countries": "Germany;Denmark", "abstract": "Text alignment is one of the fundamental techniques text-related domains like natural language processing, computational linguistics, and digital humanities. It compares two or more texts with each other aiming to find similar textual patterns, or to estimate in general how different or similar the texts are. Visualizing alignment results is an essential task, because it helps researchers getting a comprehensive overview of individual findings and the overall pattern structure. Different approaches have been developed to visualize and help making sense of these patterns depending on text size, alignment methods, and, most importantly, the underlying research tasks demanding for alignment. On the basis of those tasks, we reviewed existing text alignment visualization approaches, and discuss their advantages and drawbacks. We finally derive design implications and shed light on related future challenges.", "keywords": "Text Alignment,Text Visualization,Collation,Text Re-Use,Plagiarism Analysis,Translation Studies", "link": "http://dx.doi.org/10.1109/TVCG.2020.3028975", "refList": ["10.1093/bib/bbx108", "10.1109/tvcg.2014.2346435", "10.1093/bioinformatics/btp033", "10.1016/0022-2836(70)90057-4", "10.1093/llc/fqt032", "10.1109/icpr.2018.8545064", "10.1109/pacificvis.2015.7156366", "10.1109/vl.1996.545307", "10.1093/llc/18.1.101", "10.1093/llc/fqu007", "10.1093/llc/fqx024", "10.1109/jcdl.2014.6970166", "10.1109/tvcg.2013.124", "10.1016/j.ijhcs.2009.02.001", "10.1111/cgf.12618", "10.1109/tvcg.2015.2467618", "10.1109/vast.2017.8585505", "10.1109/laweb.2003.1250280", "10.1109/icdar.2013.39", "10.1145/1378889.1378892", "10.1111/cgf.12798", "10.1093/llc/fqt046", "10.1109/tvcg.2011.232", "10.1093/llc/fqv049", "10.1093/library/19.4.514", "10.1107/s0907444909007835", "10.1109/icdar.2011.157", "10.1109/tvcg.2008.172", "10.1179/000870403235002042"], "wos": 1, "children": [], "len": 1}, {"doi": "10.1109/tvcg.2020.3028976", "title": "Attention Flows: Analyzing and Comparing Attention Mechanisms in Language Models", "year": "2020", "conferenceName": "VAST", "authors": "Joseph F. DeRose;Jiayao Wang;Matthew Berger", "citationCount": "0", "affiliation": "DeRose, JF; Wang, JY; Berger, M (Corresponding Author), Vanderbilt Univ, 221 Kirkland Hall, Nashville, TN 37235 USA. DeRose, Joseph F.; Wang, Jiayao; Berger, Matthew, Vanderbilt Univ, 221 Kirkland Hall, Nashville, TN 37235 USA.", "countries": "USA", "abstract": "Advances in language modeling have led to the development of deep attention-based models that are performant across a wide variety of natural language processing (NLP) problems. These language models are typified by a pre-training process on large unlabeled text corpora and subsequently fine-tuned for specific tasks. Although considerable work has been devoted to understanding the attention mechanisms of pre-trained models, it is less understood how a model's attention mechanisms change when trained for a target NLP task. In this paper, we propose a visual analytics approach to understanding fine-tuning in attention-based language models. Our visualization, Attention Flows, is designed to support users in querying, tracing, and comparing attention within layers, across layers, and amongst attention heads in Transformer-based language models. To help users gain insight on how a classification decision is made, our design is centered on depicting classification-based attention at the deepest layer and how attention from prior layers flows throughout words in the input. Attention Flows supports the analysis of a single model, as well as the visual comparison between pre-trained and fine-tuned models via their similarities and differences. We use Attention Flows to study attention mechanisms in various sentence understanding tasks and highlight how attention evolves to address the nuances of solving these tasks.", "keywords": "NLP,Transformer,Visual Analytics", "link": "http://dx.doi.org/10.1109/TVCG.2020.3028976", "refList": ["10.1093/bib/bbx108", "10.1109/tvcg.2014.2346435", "10.1093/bioinformatics/btp033", "10.1016/0022-2836(70)90057-4", "10.1093/llc/fqt032", "10.1109/icpr.2018.8545064", "10.1109/pacificvis.2015.7156366", "10.1109/vl.1996.545307", "10.1093/llc/18.1.101", "10.1109/iccv.2015.507", "10.1093/llc/fqu007", "10.1093/llc/fqx024", "10.1109/jcdl.2014.6970166", "10.1109/tvcg.2013.124", "10.1109/tvcg.2012.96", "10.1016/j.ijhcs.2009.02.001", "10.1111/cgf.12618", "10.1109/tvcg.2015.2467618", "10.1109/vast.2017.8585505", "10.1109/icdar.2013.39", "10.1145/1378889.1378892", "10.1111/cgf.12798", "10.1093/llc/fqt046", "10.1109/tvcg.2011.232", "10.1093/library/19.4.514", "10.1107/s0907444909007835", "10.1109/tvcg.2008.172", "10.1179/000870403235002042"], "wos": 1, "children": [], "len": 1}, {"doi": "10.1109/pacificvis.2019.00026", "year": "2019", "title": "Visual Quality Guidance for Document Exploration with Focus+Context Techniques", "conferenceName": "PacificVis", "authors": "Qi Han;Dennis Thom;Markus John;Steffen Koch;Thomas Ertl;Florian Heimerl", "citationCount": "1", "affiliation": "Han, Q (Corresponding Author), Univ Stuttgart, Inst Visualisat \\& Interact Syst, Stuttgart, Germany.\nHan, Qi; Thom, Dennis; John, Markus; Koch, Steffen; Ertl, Thomas, Univ Stuttgart, Inst Visualisat \\& Interact Syst, Stuttgart, Germany.\nHeimerl, Florian, Univ Wisconsin, Dept Comp Sci, Madison, WI USA.", "countries": "Germany;USA", "abstract": "Magic lens based focus+context techniques are powerful means for exploring document spatializations. Typically, they only offer additional summarized or abstracted views on focused documents. As a consequence, users might miss important information that is either not shown in aggregated form or that never happens to get focused. In this work, we present the design process and user study results for improving a magic lens based document exploration approach with exemplary visual quality cues to guide users in steering the exploration and support them in interpreting the summarization results. We contribute a thorough analysis of potential sources of information loss involved in these techniques, which include the visual spatialization of text documents, user-steered exploration, and the visual summarization. With lessons learned from previous research, we highlight the various ways those information losses could hamper the exploration. Furthermore, we formally define measures for the aforementioned different types of information losses and bias. Finally, we present the visual cues to depict these quality measures that are seamlessly integrated into the exploration approach. These visual cues guide users during the exploration and reduce the risk of misinterpretation and accelerate insight generation. We conclude with the results of a controlled user study and discuss the benefits and challenges of integrating quality guidance in exploration techniques.", "keywords": "Document Visualization; Focus plus Context; Visual Guidance; Uncertainty Visualization; Document Spatialization; Text Mining; Visual Analytics", "link": "https://doi.org/10.1109/PacificVis.2019.00026", "refList": ["10.1177/1473871612460526", "10.1016/j.cag.2014.01.006", "10.1109/tvcg.2007.70443", "10.1109/tvcg.2015.2467591", "10.1109/vast.2016.7883507", "10.1145/1456650.1456652", "10.1109/vast.2009.5333443", "10.1109/tvcg.2017.2744138", "10.1016/j.neucom.2006.11.018", "10.1111/cgf.13181", "10.1109/vast.2011.6102456", "10.1109/tvcg.2016.2598445", "10.1177/1536867x0300300204", "10.1109/bigdata.2015.7363807", "10.1109/vast.2011.6102449", "10.1109/pacificvis.2015.7156366", "10.1111/cgf.12871", "10.1109/tvcg.2013.186", "10.1111/j.1467-8659.2010.01835.x", "10.1145/1842993.1843002", "10.1145/2207676.2207741", "10.1007/978-1-4471-6497-5\\_1", "10.1109/tvcg.2013.162", "10.1109/t-c.1969.222678", "10.1145/2911451.2911546", "10.1109/tvcg.2012.285", "10.1109/tvcg.2014.2346743", "10.1109/tvcg.2015.2467691", "10.1109/tvcg.2016.2598466", "10.1109/2945.981848", "10.1109/vast.2007.4389006", "10.1145/302979.303148", "10.1109/vast.2014.7042494", "10.1109/infvis.1995.528686", "10.1109/tvcg.2012.277", "10.1109/tvcg.2017.2723397", "10.1177/0963721413481473", "10.1109/visual.2000.885678", "10.1109/tvcg.2018.2865233", "10.1109/tvcg.2013.153", "10.1016/0169-7439(87)80084-9", "10.1111/cgf.12655", "10.1109/tvcg.2018.2846735", "10.3115/1117729.1117730", "10.1109/tvcg.2015.2467717", "10.1145/22339.22342", "10.1109/vast.2011.6102488", "10.1109/tvcg.2016.2598468", "10.1109/tvcg.2016.2599058", "10.1109/tvcg.2014.2346433", "10.1109/tvcg.2006.138"], "wos": 1, "children": [], "len": 1}, {"doi": "10.1111/cgf.13446", "year": "2018", "title": "Quality Metrics for Information Visualization", "conferenceName": "EuroVis", "authors": "Michael Behrisch;Michael Blumenschein;Nam Wook Kim;Lin Shao;Mennatallah El{-}Assady;Johannes Fuchs;Daniel Seebacher;Alexandra Diehl;Ulrik Brandes;Hanspeter Pfister;Tobias Schreck;Daniel Weiskopf;Daniel A. Keim", "citationCount": "25", "affiliation": "Behrisch, M (Corresponding Author), Harvard Univ, Cambridge, MA 02138 USA.\nBehrisch, M.; Kim, N. W.; Pfister, H., Harvard Univ, Cambridge, MA 02138 USA.\nBlumenschein, M.; El-Assady, M.; Fuchs, J.; Seebacher, D.; Diehl, A.; Keim, D. A., Univ Konstanz, Constance, Germany.\nShao, L.; Schreck, T., Graz Univ Technol, Graz, Austria.\nBrandes, U., Swiss Fed Inst Technol, Zurich, Switzerland.\nWeiskopf, D., Univ Stuttgart, Stuttgart, Germany.", "countries": "Switzerland;Germany;USA;Austria", "abstract": "The visualization community has developed to date many intuitions and understandings of how to judge the quality of views in visualizing data. The computation of a visualization's quality and usefulness ranges from measuring clutter and overlap, up to the existence and perception of specific (visual) patterns. This survey attempts to report, categorize and unify the diverse understandings and aims to establish a common vocabulary that will enable a wide audience to understand their differences and subtleties. For this purpose, we present a commonly applicable quality metric formalization that should detail and relate all constituting parts of a quality metric. We organize our corpus of reviewed research papers along the data types established in the information visualization community: multi- and high-dimensional, relational, sequential, geospatial and text data. For each data type, we select the visualization subdomains in which quality metrics are an active research field and report their findings, reason on the underlying concepts, describe goals and outline the constraints and requirements. One central goal of this survey is to provide guidance on future research opportunities for the field and outline how different visualization communities could benefit from each other by applying or transferring knowledge to their respective subdomain. Additionally, we aim to motivate the visualization community to compare computed measures to the perception of humans.", "keywords": "", "link": "https://doi.org/10.1111/cgf.13446", "refList": ["10.2307/276978", "10.1057/ivs.2009.10", "10.1109/tvcg.2015.2467732", "10.1109/tvcg.2014.2346420", "10.1016/j.cag.2018.01.010", "10.1109/tvcg.2017.2743959", "10.1109/tvcg.2011.127", "10.1109/tvcg.2015.2467759", "10.1109/tvcg.2013.187", "10.1109/tvcg.2007.70594", "10.1186/1471-2105-9-155", "10.1145/2702123.2702545", "10.1145/1645953.1646023", "10.1093/bioinformatics/btm312", "10.1109/pacificvis.2016.7465245", "10.1145/3038462.3038463", "10.1007/978-3-540-70956-5", "10.1109/tvcg.2017.2743939", "10.1111/cgf.12932", "10.1111/j.1467-8659.2012.03106.x", "10.1145/1133265.1133318", "10.1109/tvcg.2010.186", "10.1109/iv.2013.101", "10.1109/tvcg.2016.2598590", "10.2312/conf/eg2013/stars/039-063", "10.3758/bf03201236", "10.1111/cgf.12935", "10.1145/1056808.1056914", "10.1007/bf01898350", "10.2307/1390686", "10.1109/2945.981848", "10.1109/hicss.2008.422", "10.1109/tvcg.2011.201", "10.1109/pacificvis.2011.5742390", "10.2307/2288400", "10.1111/cgf.12872", "10.1109/tvcg.2017.2674999", "10.1109/tvcg.2006.163", "10.1109/tvcg.2013.150", "10.1109/tvcg.2009.171", "10.1109/tvcg.2017.2723397", "10.1117/12.2079841", "10.1109/pacificvis.2009.4906838", "10.1109/infvis.2004.1", "10.1109/tvcg.2008.166", "10.1287/opre.20.5.993", "10.7155/jgaa.00370", "10.1111/j.1467-8659.2008.01240.x", "10.1109/inf0vis.2005.14", "10.1109/tvcg.2009.23", "10.1109/infvis.1998.729559", "10.1177/0165551506078083", "10.1109/t-c.1974.224051", "10.1109/tvcg.2017.2744339", "10.1109/tvcg.2014.2346433", "10.1145/989863.989940", "10.1109/tvcg.2015.2509990", "10.2307/2288843", "10.1016/j.neucom.2017.01.105", "10.1073/pnas.43.10.923", "10.1111/cgf.12647", "10.1016/j.rse.2017.06.031", "10.1109/infvis.2005.1532145", "10.1109/2945.841121", "10.1109/tvcg.2011.229", "10.2312/eurova.20141140", "10.1111/j.2044-8317.1974.tb00534.x", "10.1109/pacificvis.2015.7156366", "10.1109/vast.2009.5332628", "10.1109/vast.2014.7042480", "10.1145/2993901.2993907", "10.1177/0951692899011001004", "10.1007/978-3-642-03655-2\\_43", "10.1198/106186008x320465", "10.1109/visual.1997.663916", "10.1111/cgf.12125", "10.1109/infvis.2003.1249009", "10.1109/icdm.2003.1250978", "10.1109/tvcg.2017.2745919", "10.1109/tvcg.2012.128", "10.1109/vast.2010.5652450", "10.1109/tvcg.2006.161", "10.1145/571647.571649", "10.1109/tvcg.2011.193", "10.1111/cgf.12633", "10.1109/tvcg.2017.2674978", "10.1109/vast.2010.5652433", "10.1109/tvcg.2017.2745978", "10.1515/itit-2014-1070", "10.1145/1374489.1374501", "10.1109/tvcg.2009.153", "10.2312/eurovisshort.20171128", "10.2312/eurovisshort.20151130", "10.1016/0925-7721(94)00014-x", "10.1057/palgrave.ivs.95000/3", "10.1145/302979.303030", "10.1002/widm.1071", "10.1109/pacificvis.2014.42", "10.1109/tvcg.2016.2598467", "10.1111/j.1467-8659.2009.01667.x", "10.2307/2287708", "10.1177/1473871613477091", "10.1145/967900.968153", "10.1109/tvcg.2010.162", "10.1145/568522.568523", "10.1016/j.cag.2004.03.022", "10.1109/tvcg.2015.2466992", "10.1145/2993901.2993903", "10.1147/jrd.2015.2411412", "10.1177/154193120504900508", "10.1109/tvcg.2006.138", "10.1111/cgf.13168", "10.1111/cgf.12380", "10.2312/conf/eg2013/stars/095-116", "10.1109/tvcg.2017.2745859", "10.1109/tvcg.2017.2701829", "10.1109/tvcg.2007.70529", "10.1007/bf01199431", "10.1117/12.697548", "10.1109/tvcg.2017.2653106", "10.1207/s15327906mbr2701\\_4", "10.1109/vl.1996.545307", "10.1109/tvcg.2017.2745140", "10.1111/j.1467-8659.2012.03069.x", "10.1111/j.1467-8659.2011.01961.x", "10.1109/pacificvis.2016.7465244", "10.1109/tvcg.2013.124", "10.1057/ivs.2008.13", "10.2312/vissym/eurovis06/195-202", "10.2312/vissym/eurovis07/163-170", "10.1109/tvcg.2015.2467324", "10.1109/tvcg.2011.167", "10.1109/pacificvis.2014.40", "10.1109/pacificvis.2012.6183570", "10.1111/j.1467-8659.2012.03125.x", "10.1075/idj.20.1.02bei", "10.1111/1467-8306.00061", "10.1145/2858036.2858155", "10.1109/tvcg.2012.108", "10.2312/vmv.20171261", "10.1109/tvcg.2015.2467531", "10.1145/1379092.1379130", "10.1109/tpami.1979.4766909", "10.1080/13875860903039172", "10.1109/mcg.2006.70", "10.1109/tvcg.2010.242", "10.1109/vast.2007.4389004", "10.1109/tvcg.2015.2467191", "10.2312/cgvc.20171276", "10.1016/0169-7439(87)80084-9", "10.2312/pe/eurovisshort/eurovisshort2012/097-101", "10.1016/j.neucom.2014.07.073", "10.2307/2685263", "10.1145/996546.996554", "10.1111/j.1467-8659.2009.01666.x", "10.1117/12.2083444", "10.1109/tvcg.2014.2346572", "10.1007/978-0-387-39940-9\\_262", "10.1007/bf00988593", "10.1145/1054972.1055078", "10.1111/j.1467-8659.2009.01467.x", "10.1111/cgf.13181", "10.1145/502512.502530", "10.1109/pacificvis.2010.5429600", "10.1111/j.1467-8659.2011.01923.x", "10.1109/mcg.2004.41", "10.1109/tvcg.2015.2467971", "10.1111/j.1467-8659.2011.01919.x", "10.1002/sam.10071", "10.1109/tvcg.2010.184", "10.1007/978-3-642-27848-8\\_648-1", "10.1109/tvcg.2010.132", "10.1145/22949.22950", "10.1145/1842993.1843002", "10.1109/infvis.2000.885096", "10.1016/j.ins.2015.04.017", "10.1109/iv.2009.43", "10.1016/j.visinf.2017.11.001", "10.1109/tvcg.2011.239", "10.1109/infovis.2005.40", "10.1111/cgf.12641", "10.1109/pacificvis.2016.7465262", "10.1145/2470654.2466443", "10.1007/s10844-011-0157-4", "10.1111/cgf.12919", "10.1016/j.jvlc.2016.07.003", "10.1109/tvcg.2016.2549018", "10.1057/palgrave.ivs.9500166", "10.3406/colan.1981.1409.1", "10.1093/bioinformatics/bti141", "10.1111/j.1467-8306.2004.09401004.x", "10.1145/1168149.1168168", "10.1109/tvcg.2017.2744184", "10.1117/12.2079420", "10.1109/iv.2005.62", "10.1145/102377.115768", "10.1109/tvcg.2014.2346677", "10.1109/tvcg.2014.2346426", "10.1111/j.1467-8659.2012.03107.x", "10.5220/0006097400400051", "10.2991/978-94-6239-186-4", "10.2307/2284077", "10.1109/iv.2008.89", "10.1016/j.jvlc.2015.12.001", "10.1109/pacificvis.2013.6596147", "10.1145/1242572.1242826", "10.1016/j.cag.2007.01.030", "10.1111/cgf.12632", "10.2312/eurovisstar.20151113", "10.1559/152304009788188808"], "wos": 1, "children": [{"doi": "10.1109/vast.2018.8802486", "title": "SMARTexplore: Simplifying High-Dimensional Data Analysis through a Table-Based Visual Analytics Approach", "year": "2018", "conferenceName": "VAST", "authors": "Michael Blumenschein;Michael Behrisch;Stefanie Schmid;Simon Butscher;Deborah Wahl;Karoline Villinger;Britta Renner;Harald Reiterer;Daniel A. Keim", "citationCount": "0", "affiliation": "Blumenschein, M (Corresponding Author), Univ Konstanz, Constance, Germany. Blumenschein, Michael; Schmid, Stefanie; Butscher, Simon; Wahl, Deborah R.; Villinger, Karoline; Renner, Britta; Reiterer, Harald; Keim, Daniel A., Univ Konstanz, Constance, Germany. Behrisch, Michael, Harvard Univ, Cambridge, MA 02138 USA.", "countries": "Germany;USA", "abstract": "We present SMARTEXPLORE, a novel visual analytics technique that simplifies the identification and understanding of clusters, correlations, and complex patterns in high-dimensional data. The analysis is integrated into an interactive table-based visualization that maintains a consistent and familiar representation throughout the analysis. The visualization is tightly coupled with pattern matching, subspace analysis, reordering, and layout algorithms. To increase the analyst's trust in the revealed patterns, SMARTEXPLORE automatically selects and computes statistical measures based on dimension and data properties. While existing approaches to analyzing high-dimensional data (e.g., planar projections and Parallel coordinates) have proven effective, they typically have steep learning curves for non-visualization experts. Our evaluation, based on three expert case studies, confirms that non-visualization experts successfully reveal patterns in high-dimensional data when using SMARTEXPLORE.", "keywords": "High-dimensional data,visual exploration,pattern-driven analysis,tabular visualization,subspace,aggregation", "link": "http://dx.doi.org/10.1109/VAST.2018.8802486", "refList": ["10.1177/1473871612460526", "10.1109/tvcg.2015.2489649", "10.1111/j.1467-8659.2008.01241.x", "10.1007/978-3-319-25087-8\\_29", "10.1007/b98835", "10.13140/rg.2.2.16570.90567", "10.1109/tvcg.2014.2346260", "10.1109/vast.2009.5332628", "10.2307/2528823", "10.1109/tvcg.2010.184", "10.1145/1133265.1133318", "10.1057/palgrave.ivs.9500072", "10.1111/j.1467-8659.2012.03110.x", "10.1145/1007730.1007731", "10.1057/palgrave.ivs.9500086", "10.1111/cgf.12935", "10.1109/tvcg.2014.2346279", "10.1007/bf01898350", "10.1109/tvcg.2013.173", "10.1109/tvcg.2017.2672987", "10.1109/tvcg.2014.2346248", "10.1109/infvis.2004.46", "10.1109/vast.2010.5652433", "10.1109/vast.2009.5332611", "10.1109/tvcg.2015.2467553", "10.1109/tvcg.2015.2468078", "10.1109/tvcg.2017.2744098", "10.1109/tvcg.2013.150", "10.1109/tvcg.2016.2640960", "10.1111/cgf.12630", "10.1007/978-1-4757-1904-8", "10.1109/tvcg.2011.188", "10.1109/tvcg.2010.138", "10.1109/tvcg.2017.2745078", "10.1109/tvcg.2017.2743978", "10.1111/cgf.12879", "10.1109/iv.2008.33", "10.1111/cgf.13446", "10.1007/s00371-018-1483-0", "10.1109/infvis.1998.729559", "10.1145/2669557.2669572", "10.1111/j.1467-8659.2008.01239.x"], "wos": 1, "children": [], "len": 1}, {"doi": "10.1109/tvcg.2019.2934541", "title": "A Recursive Subdivision Technique for Sampling Multi-class Scatterplots", "year": "2019", "conferenceName": "InfoVis", "authors": "Xin Chen;Tong Ge;Jian Zhang 0070;Baoquan Chen;Chi-Wing Fu;Oliver Deussen;Yunhai Wang", "citationCount": "5", "affiliation": "Chen, X (Corresponding Author), Shandong Univ, Jinan, Shandong, Peoples R China. Chen, Xin; Ge, Tong; Wang, Yunhai, Shandong Univ, Jinan, Shandong, Peoples R China. Chen, Baoquan, Peking Univ, Beijing, Peoples R China. Fu, Chi-Wing, Chinese Univ Hong Kong, Hong Kong, Peoples R China. Fu, Chi-Wing, SIAT, Guangdong Prov Key Lab CV \\& VR Tech, Shenzhen, Guangdong, Peoples R China. Zhang, Jian, Chinese Acad Sci, CNIC, Beijing, Peoples R China. Deussen, Oliver, Konstanz Univ, Constance, Germany. Deussen, Oliver, SIAT, Shenzhen VIsuCA Key Lab, Shenzhen, Guangdong, Peoples R China.", "countries": "Germany;China", "abstract": "We present a non-uniform recursive sampling technique for multi-class scatterplots, with the specific goal of faithfully presenting relative data and class densities, while preserving major outliers in the plots. Our technique is based on a customized binary kd-tree, in which leaf nodes are created by recursively subdividing the underlying multi-class density map. By backtracking, we merge leaf nodes until they encompass points of all classes for our subsequently applied outlier-aware multi-class sampling strategy. A quantitative evaluation shows that our approach can better preserve outliers and at the same time relative densities in multi-class scatterplots compared to the previous approaches, several case studies demonstrate the effectiveness of our approach in exploring complex and real world data.", "keywords": "Scatterplot,multi-class sampling,kd-tree,outlier,relative density", "link": "http://dx.doi.org/10.1109/TVCG.2019.2934541", "refList": ["10.1057/palgrave.ivs.9500122", "10.1109/tvcg.2006.170", "10.1109/tvcg.2008.119", "10.1109/tvcg.2007.70580", "10.2307/2289444", "10.1145/1964921.1964943", "10.1109/tvcg.2013.65", "10.1109/tvcg.2011.229", "10.1109/iv.2004.1320207", "10.1109/itoec.2018.8740621", "10.1145/1778765.1778816", "10.1109/tvcg.2010.197", "10.1201/b17511", "10.1109/tvcg.2018.2864912", "10.1007/0-387-28695-0", "10.1109/5.726791", "10.1109/visual.1998.745301", "10.1016/j.physa.2011.12.004", "10.1145/1556262.1556289", "10.1109/tvcg.2007.70535", "10.1109/tvcg.2017.2674978", "10.1109/tvcg.2004.1272729", "10.1145/335191.335388", "10.1109/tvcg.2014.2346594", "10.1109/tvcg.2017.2744184", "10.1109/iv.2002.1028760", "10.1145/1842993.1842999", "10.1109/tvcg.2018.2869149", "10.1038/nmeth.2490", "10.1109/tvcg.2013.153", "10.1111/cgf.13446", "10.1109/tvcg.2010.176", "10.1145/2702123.2702585", "10.1057/ivs.2009.34"], "wos": 1, "children": [{"doi": "10.1109/tvcg.2020.3030443", "title": "CAVA: A Visual Analytics System for Exploratory Columnar Data Augmentation Using Knowledge Graphs", "year": "2020", "conferenceName": "VAST", "authors": "Dylan Cashman;Shenyu Xu;Subhajit Das;Florian Heimerl;Cong Liu;Shah Rukh Humayoun;Michael Gleicher;Alex Endert;Remco Chang", "citationCount": "0", "affiliation": "Cashman, D (Corresponding Author), Tufts Univ, Medford, MA 02155 USA. Cashman, Dylan; Liu, Cong; Chang, Remco, Tufts Univ, Medford, MA 02155 USA. Xu, Shenyu; Das, Subhajit; Endert, Alex, Georgia Tech, Atlanta, GA USA. Heimerl, Florian; Gleicher, Michael, Univ Wisconsin, Madison, WI 53706 USA. Humayoun, Shah Rukh, San Francisco State Univ, San Francisco, CA 94132 USA.", "countries": "USA", "abstract": "Most visual analytics systems assume that all foraging for data happens before the analytics process; once analysis begins, the set of data attributes considered is fixed. Such separation of data construction from analysis precludes iteration that can enable foraging informed by the needs that arise in-situ during the analysis. The separation of the foraging loop from the data analysis tasks can limit the pace and scope of analysis. In this paper, we present CAVA, a system that integrates data curation and data augmentation with the traditional data exploration and analysis tasks, enabling information foraging in-situ during analysis. Identifying attributes to add to the dataset is difficult because it requires human knowledge to determine which available attributes will be helpful for the ensuing analytical tasks. CAVA crawls knowledge graphs to provide users with a a broad set of attributes drawn from external data to choose from. Users can then specify complex operations on knowledge graphs to construct additional attributes. CAVA shows how visual analytics can help users forage for attributes by letting users visually explore the set of available data, and by serving as an interface for query construction. It also provides visualizations of the knowledge graph itself to help users understand complex joins such as multi-hop aggregations. We assess the ability of our system to enable users to perform complex data combinations without programming in a user study over two datasets. We then demonstrate the generalizability of CAVA through two additional usage scenarios. The results of the evaluation confirm that CAVA is effective in helping the user perform data foraging that leads to improved analysis outcomes, and offer evidence in support of integrating data augmentation as a part of the visual analytics pipeline.", "keywords": "Visual Analytics,Information Foraging,Data Augmentation", "link": "http://dx.doi.org/10.1109/TVCG.2020.3030443", "refList": ["10.1057/palgrave.ivs.9500122", "10.1109/tvcg.2016.2598867", "10.1111/cgf.13708", "10.1109/tvcg.2019.2934799", "10.1109/tvcg.2019.2934541", "10.1109/tvcg.2013.65", "10.1109/tvcg.2018.2875702", "10.1109/iv.2004.1320207", "10.1068/p260471", "10.1145/1778765.1778816", "10.1109/tvcg.2018.2808489", "10.1109/tvcg.2018.2864912", "10.1016/j.apgeog.2015.12.006", "10.1111/j.1467-8659.2011.01960.x", "10.1109/tvcg.2018.2864843", "10.1109/pacificvis.2010.5429604", "10.1109/tvcg.2014.2346898", "10.1109/5.726791", "10.1177/1475090214540874", "10.1109/icde.2016.7498287", "10.1145/1556262.1556289", "10.1109/tvcg.2007.70535", "10.1109/vast.2012.6400489", "10.1145/1056808.1056914", "10.1016/j.neucom.2014.09.063", "10.1145/7529.8927", "10.1109/tvcg.2016.2598495", "10.1109/tvcg.2016.2607204", "10.1109/vast47406.2019.8986943", "10.3758/bf03205986", "10.1109/infvis.2005.1532142", "10.1145/1150402.1150479", "10.1109/tvcg.2017.2674978", "10.1109/tvcg.2019.2945960", "10.1109/tvcg.2017.2744098", "10.1109/tvcg.2017.2674999", "10.1109/tvcg.2011.279", "10.1109/tvcg.2014.2346594", "10.1109/tvcg.2017.2744184", "10.1111/cgf.12876", "10.1007/s4095-020-0191-7", "10.1007/s11390-015-1535-0", "10.1111/cgf.12640", "10.1109/tvcg.2016.2598667", "10.1111/cgf.13683", "10.1109/tvcg.2013.153", "10.1109/tvcg.2019.2934208", "10.1109/tvcg.2019.2934655", "10.1111/cgf.12655", "10.1007/s11023-010-9221-z", "10.1109/vast.2012.6400487", "10.1145/2702123.2702585", "10.1007/bf00310175", "10.1109/tvcg.2017.2744378", "10.1103/physreve.64.061907", "10.1109/ldav.2017.8231848", "10.1109/tvcg.2016.2598831"], "wos": 1, "children": [], "len": 1}, {"doi": "10.1109/tvcg.2020.3030432", "title": "Evaluation of Sampling Methods for Scatterplots", "year": "2020", "conferenceName": "VAST", "authors": "Jun Yuan;Shouxing Xiang;Jiazhi Xia;Lingyun Yu;Shixia Liu", "citationCount": "0", "affiliation": "Liu, SX (Corresponding Author), Tsinghua Univ, BNRist, Beijing, Peoples R China. Yuan, Jun; Xiang, Shouxing; Liu, Shixia, Tsinghua Univ, BNRist, Beijing, Peoples R China. Xia, Jiazhi, Cent South Univ, Changsha, Peoples R China. Yu, Lingyun, Xian Jiaotong Liverpool Univ, Suzhou, Peoples R China.", "countries": "China", "abstract": "Given a scatterplot with tens of thousands of points or even more, a natural question is which sampling method should be used to create a small but \u201cgood\u201d scatterplot for a better abstraction. We present the results of a user study that investigates the influence of different sampling strategies on multi-class scatterplots. The main goal of this study is to understand the capability of sampling methods in preserving the density, outliers, and overall shape of a scatterplot. To this end, we comprehensively review the literature and select seven typical sampling strategies as well as eight representative datasets. We then design four experiments to understand the performance of different strategies in maintaining: 1) region density; 2) class density; 3) outliers; and 4) overall shape in the sampling results. The results show that: 1) random sampling is preferred for preserving region density; 2) blue noise sampling and random sampling have comparable performance with the three multi-class sampling strategies in preserving class density; 3) outlier biased density based sampling, recursive subdivision based sampling, and blue noise sampling perform the best in keeping outliers; and 4) blue noise sampling outperforms the others in maintaining the overall shape of a scatterplot.", "keywords": "Scatterplot,data sampling,empirical evaluation", "link": "http://dx.doi.org/10.1109/TVCG.2020.3030432", "refList": ["10.1057/palgrave.ivs.9500122", "10.1109/tvcg.2016.2598867", "10.1109/tvcg.2015.2467591", "10.1111/cgf.13708", "10.1109/tvcg.2019.2934799", "10.1109/tvcg.2019.2934541", "10.1109/tvcg.2013.65", "10.1109/iv.2004.1320207", "10.1068/p260471", "10.1145/1778765.1778816", "10.1109/tvcg.2018.2808489", "10.1109/tvcg.2018.2864912", "10.1016/j.apgeog.2015.12.006", "10.1111/j.1467-8659.2011.01960.x", "10.1109/tvcg.2018.2864843", "10.1109/pacificvis.2010.5429604", "10.1109/tvcg.2014.2346898", "10.1109/5.726791", "10.1177/1475090214540874", "10.1145/1556262.1556289", "10.1109/tvcg.2007.70535", "10.1109/vast.2012.6400489", "10.1145/1056808.1056914", "10.1016/j.neucom.2014.09.063", "10.1145/7529.8927", "10.1109/tvcg.2016.2607204", "10.1109/vast47406.2019.8986943", "10.3758/bf03205986", "10.1109/infvis.2005.1532142", "10.1145/1150402.1150479", "10.1109/tvcg.2017.2674978", "10.1109/tvcg.2017.2744098", "10.1109/tvcg.2017.2674999", "10.1109/tvcg.2011.279", "10.1109/tvcg.2014.2346594", "10.1109/tvcg.2017.2744184", "10.1111/cgf.12876", "10.1109/1011101.2019.2945960", "10.1007/s4095-020-0191-7", "10.1007/s11390-015-1535-0", "10.1111/cgf.12640", "10.1109/tvcg.2016.2598667", "10.1111/cgf.13683", "10.1109/tvcg.2013.153", "10.1109/tvcg.2019.2934208", "10.1109/tvcg.2019.2934655", "10.1111/cgf.12655", "10.1007/s11023-010-9221-z", "10.1109/vast.2012.6400487", "10.1145/2702123.2702585", "10.1007/bf00310175", "10.1109/tvcg.2017.2744378", "10.1103/physreve.64.061907", "10.1109/ldav.2017.8231848", "10.1109/tvcg.2016.2598831"], "wos": 1, "children": [], "len": 1}, {"doi": "10.1109/tvcg.2020.3030365", "title": "Modeling the Influence of Visual Density on Cluster Perception in Scatterplots Using Topology", "year": "2020", "conferenceName": "InfoVis", "authors": "Ghulam Jilani Quadri;Paul Rosen", "citationCount": "0", "affiliation": "Quadri, GJ (Corresponding Author), Univ S Florida, Tampa, FL 33620 USA. Quadri, Ghulam Jilani; Rosen, Paul, Univ S Florida, Tampa, FL 33620 USA.", "countries": "USA", "abstract": "Scatterplots are used for a variety of visual analytics tasks, including cluster identification, and the visual encodings used on a scatterplot play a deciding role on the level of visual separation of clusters. For visualization designers, optimizing the visual encodings is crucial to maximizing the clarity of data. This requires accurately modeling human perception of cluster separation, which remains challenging. We present a multi-stage user study focusing on four factors-distribution size of clusters, number of points, size of points, and opacity of points-that influence cluster identification in scatterplots. From these parameters, we have constructed two models, a distance-based model, and a density-based model, using the merge tree data structure from Topological Data Analysis. Our analysis demonstrates that these factors play an important role in the number of clusters perceived, and it verifies that the distance-based and density-based models can reasonably estimate the number of clusters a user observes. Finally, we demonstrate how these models can be used to optimize visual encodings on real-world data.", "keywords": "Scatterplot,clustering,perception,empirical evaluation,visual encoding,crowdsourcing,topological data analysis", "link": "http://dx.doi.org/10.1109/TVCG.2020.3030365", "refList": ["10.1109/tvcg.2017.2744359", "10.1145/1778765", "10.1109/tvcg.2019.2934799", "10.1111/cgf.12889", "10.1109/tvcg.2011.127", "10.1111/cgf.13444", "10.1145/1964897.1964910", "10.1167/8.7.6", "10.1145/3173574.3173991", "10.1145/1556262.1556289", "10.1145/1056808.1056914", "10.2307/2288400", "10.1109/tvcg.2014.2346594", "10.1109/iv.2002.1028760", "10.1177/001316447303300111", "10.1007/bf02289823", "10.1109/tvcg.2017.2744339", "10.1111/j.1467-8659.2009.01694.x", "10.1109/tvcg.2014.2346979", "10.1090/mbk/069", "10.1109/tvcg.2013.65", "10.1109/mcg.2012.37", "10.1109/pacificvis.2010.5429604", "10.1002/acp.2350050106", "10.1109/infvis.2005.1532136", "10.1177/1473871612465214", "10.1109/tvcg.2017.2674978", "10.1002/jhbs.20078", "10.1007/978-3-642-35142-6\\_14", "10.1007/978-3-319-71507-0", "10.1109/mcg.201.7.6", "10.3758/bf03193961", "10.1364/josa.49.000280", "10.1145/3025453.3025905", "10.1109/tvcg.201.9.2934541", "10.1109/tvcg.2018.2829750", "10.1177/1473871615606187", "10.1111/cgf.13408", "10.1109/pacificvis.2016.7465252", "10.1109/pacificvis.2016.7465244", "10.1109/inevis.2005.1532142", "10.1111/cgf.13414", "10.1111/j.1467-8659.2012.03125.x", "10.1167/16.5.11", "10.1109/infvis.2005.1532142", "10.1145/2858036.2858155", "10.1038/nmeth1210-941", "10.1177/1473871616638892", "10.1109/tcbb.2014.2306840", "10.1111/cgf.13684", "10.1177/0301006615602599", "10.1214/aoms/1177731915", "10.1145/2702123.2702585", "10.1109/tvcg.2013.183", "10.1109/tvcg.2014.2346572", "10.1109/tvcg.2018.2875702", "10.1109/tvcg.2017.2754480", "10.1109/vast.2014.7042493", "10.1057/palgrave.ivs.9500122", "10.1109/tvcg.2014.2330617", "10.1109/tvcg.2019.2934541", "10.1068/p030033", "10.1140/epjds/s13688-017-0109-5", "10.1201/b17511", "10.1016/s0925-7721(02)00093-7", "10.1109/pacificvis.2012.6183557", "10.1109/tvcg.2014.2346983", "10.1109/5.726791", "10.1080/01621459.1926.10502165", "10.1109/tvcg.2007.70535", "10.1109/tvcg.2018.2864907", "10.1111/cgf.12109", "10.1109/tvcg.2017.2744184", "10.1146/annurev-statistics-031017-100045", "10.1111/cgf.13409", "10.1145/3002151.3002162", "10.1016/s0378-4371(98)00494-4", "10.3138/y308-2422-8615-1233", "10.1111/cgf.12632", "10.1145/3290605.3300771"], "wos": 1, "children": [], "len": 1}, {"doi": "10.1111/cgf.14001", "year": "2020", "title": "Sunspot Plots: Model-based Structure Enhancement for Dense Scatter Plots", "conferenceName": "EuroVis", "authors": "Thomas Trautner;Fabian Bolte;Sergej Stoppel;Stefan Bruckner", "citationCount": "0", "affiliation": "Trautner, T (Corresponding Author), Univ Bergen, Bergen, Norway.\nTrautner, T.; Bolte, F.; Stoppel, S.; Bruckner, S., Univ Bergen, Bergen, Norway.", "countries": "Norway", "abstract": "Scatter plots are a powerful and well-established technique for visualizing the relationships between two variables as a collection of discrete points. However, especially when dealing with large and dense data, scatter plots often exhibit problems such as overplotting, making the data interpretation arduous. Density plots are able to overcome these limitations in highly populated regions, but fail to provide accurate information of individual data points. This is particularly problematic in sparse regions where the density estimate may not provide a good representation of the underlying data. In this paper, we present sunspot plots, a visualization technique that communicates dense data as a continuous data distribution, while preserving the discrete nature of data samples in sparsely populated areas. We furthermore demonstrate the advantages of our approach on typical failure cases of scatter plots within synthetic and real-world data sets and validate its effectiveness in a user study.", "keywords": "", "link": "https://doi.org/10.1111/cgf.14001", "refList": ["10.1057/palgrave.ivs.9500122", "10.2312/eggh/hpg12/097-103", "10.1109/tvcg.2008.119", "10.1109/pacificvis.2011.5742387", "10.1038/331163a0", "10.1109/visual.2019.8933620", "10.2307/2683294", "10.1201/9781351072304", "10.2307/2289444", "10.1109/tvcg.2019.2934541", "10.1080/00949657508810123", "10.1109/tvcg.2013.65", "10.1109/infvis.1997.636789", "10.1109/2945.841121", "10.1109/mcse.2007.55", "10.1109/tvcg.2010.197", "10.1111/cgf.12871", "10.1109/infvis.2003.1249018", "10.1145/3173574.3173991", "10.1109/tvcg.2012.238", "10.1007/0-387-28695-0", "10.1109/pacificvis.2010.5429604", "10.18637/jss.v008.i03", "10.1109/tvcg.2007.70596", "10.1109/visual.1998.745301", "10.1007/0-387-37977-0\\_3", "10.1145/1556262.1556289", "10.2312/wiced.20161094", "10.1109/tvcg.2007.70535", "10.1145/1056808.1056914", "10.1109/tvcg.2003.1196007", "10.1109/iv.2004.1320190", "10.1111/cgf.12877", "10.1162/leon.2007.40.2.202a", "10.1109/tvcg.2017.2674978", "10.1057/ivs.2010.4", "10.1016/j.cag.2018.02.008", "10.1201/9781315140919", "10.1109/visual.2000.885677", "10.1002/jhbs.20078", "10.1109/tvcg.2014.2346594", "10.1109/tvcg.2017.2744184", "10.1109/visual.2001.964495", "10.1109/iv.2002.1028760", "10.1111/cgf.13684", "10.1109/hicss.2013.197", "10.1109/tvcg.2019.2903956", "10.1093/mnras/stt961", "10.1109/tvcg.2017.2668409", "10.1111/j.1467-8659.2009.01478.x", "10.1145/2702123.2702585", "10.2307/1418003", "10.2307/1390742", "10.1145/360825.360839", "10.1109/pacificvis.2009.4906843", "10.1057/ivs.2009.34", "10.2307/2288711"], "wos": 1, "children": [], "len": 1}], "len": 9}, {"doi": "10.1109/tvcg.2019.2934284", "title": "Color Crafting: Automating the Construction of Designer Quality Color Ramps", "year": "2019", "conferenceName": "InfoVis", "authors": "Stephen Smart;Keke Wu;Danielle Albers Szafir", "citationCount": "3", "affiliation": "Smart, S (Corresponding Author), Univ Colorado, Boulder, CO 80309 USA. Smart, Stephen; Wu, Keke; Szafir, Danielle Albers, Univ Colorado, Boulder, CO 80309 USA.", "countries": "USA", "abstract": "Visualizations often encode numeric data using sequential and diverging color ramps. Effective ramps use colors that are sufficiently discriminable, align well with the data, and are aesthetically pleasing. Designers rely on years of experience to create high-quality color ramps. However, it is challenging for novice visualization developers that lack this experience to craft effective ramps as most guidelines for constructing ramps are loosely defined qualitative heuristics that are often difficult to apply. Our goal is to enable visualization developers to readily create effective color encodings using a single seed color. We do this using an algorithmic approach that models designer practices by analyzing patterns in the structure of designer-crafted color ramps. We construct these models from a corpus of 222 expert-designed color ramps, and use the results to automatically generate ramps that mimic designer practices. We evaluate our approach through an empirical study comparing the outputs of our approach with designer-crafted color ramps. Our models produce ramps that support accurate and aesthetically pleasing visualizations at least as well as designer ramps and that outperform conventional mathematical approaches.", "keywords": "Visualization,Aesthetics in Visualization,Color Perception,Visual Design,Design Mining", "link": "http://dx.doi.org/10.1109/TVCG.2019.2934284", "refList": ["10.1145/3009924", "10.1109/tvcg.2015.2489649", "10.1109/tvcg.2017.2744359", "10.1002/(sici)1098-1098(199622)7:2", "10.1016/s0734-189x(83)80046-2", "10.1109/tvcg.2016.2599106", "10.1364/josaa.29.000313", "10.1109/tvcg.2016.2598918", "10.2307/2683294", "10.1109/tvcg.2017.2653106", "10.1016/j.ijhcs.2010.05.006", "10.1016/0146-664x(81)90006-x", "10.1007/978-3-642-10520-3\\_9", "10.1109/38.135886", "10.1146/annurev-psych-120710-100504", "10.1016/j.csda.2008.11.033", "10.1145/2461912.2461988", "10.1016/j.cub.2007.06.022", "10.1016/s0146-664x(79)80040-4", "10.1109/mcg.2004.1297012", "10.1109/iv.2009.94", "10.1109/tpami.2010.184", "10.3758/s13414-010-0027-0", "10.1145/22949.22950", "10.1109/visual.1995.480803", "10.1109/tvcg.2014.2346277", "10.2307/2684111", "10.1109/tvcg.2018.2865240", "10.1111/cgf.12633", "10.1109/38.7760", "10.1016/j.jspi.2015.04.007", "10.1109/iv.2008.24", "10.1145/2939502.2939506", "10.1111/cgf.12127", "10.1016/j.cag.2010.11.015", "10.1145/3025453.3026041", "10.1109/tvcg.2012.315", "10.2307/2288400", "10.1511/2005.5.436", "10.1016/s0097-8493(96)00072-6", "10.1109/mcg.2018.011461525", "10.1145/2470654.2466420", "10.1109/tvcg.2012.279", "10.1109/tvcg.2014.2346978", "10.1109/tvcg.2017.2743978", "10.1145/3406601.3406602", "10.1117/12.2084548", "10.1109/tvcg.2018.2865147", "10.1109/tvcg.2015.2467191", "10.1111/cgf.13446", "10.1109/tvcg.2017.2744320", "10.1111/j.1467-8659.2008.01203.x", "10.1145/2702613.2702975", "10.1007/978-3-319-26633-6\\_13", "10.1145/2207676.2208547", "10.1109/tvcg.2008.174", "10.1179/000870403235002042"], "wos": 1, "children": [{"doi": "10.1109/tvcg.2020.3028891", "title": "A Structured Review of Data Management Technology for Interactive Visualization and Analysis", "year": "2020", "conferenceName": "InfoVis", "authors": "Leilani Battle;Carlos Scheidegger", "citationCount": "0", "affiliation": "Battle, L (Corresponding Author), Univ Maryland, Dept Comp Sci, College Pk, MD 20742 USA. Battle, Leilani, Univ Maryland, Dept Comp Sci, College Pk, MD 20742 USA. Scheidegger, Carlos, Univ Arizona, Dept Comp Sci, HDC Lab, Tucson, AZ 85721 USA.", "countries": "USA", "abstract": "In the last two decades, interactive visualization and analysis have become a central tool in data-driven decision making. Concurrently to the contributions in data visualization, research in data management has produced technology that directly benefits interactive analysis. Here, we contribute a systematic review of 30 years of work in this adjacent field, and highlight techniques and principles we believe to be underappreciated in visualization work. We structure our review along two axes. First, we use task taxonomies from the visualization literature to structure the space of interactions in usual systems. Second, we created a categorization of data management work that strikes a balance between specificity and generality. Concretely, we contribute a characterization of 131 research papers along these two axes. We find that five notions in data management venues fit interactive visualization systems well: materialized views, approximate query processing, user modeling and query prediction, muiti-query optimization, lineage techniques, and indexing techniques. In addition, we find a preponderance of work in materialized views and approximate query processing, most targeting a limited subset of the interaction tasks in the taxonomy we used. This suggests natural avenues of future research both in visualization and data management. Our categorization both changes how we visualization researchers design and build our systems, and highlights where future work is necessary.", "keywords": "", "link": "http://dx.doi.org/10.1109/TVCG.2020.3028891", "refList": ["10.1109/tvcg.2012.233", "10.1016/s0022-5371(74)80015-0", "10.1109/tvcg.2017.2744359", "10.1037/0096-3445.136.4.623", "10.1109/tvcg.2015.2467732", "10.1109/tvcg.2012.196", "10.1037/a0029856", "10.1109/tvcg.2014.2346979", "10.1037/h0030300", "10.1109/tvcg.2016.2598918", "10.1109/beliv.2018.8634420", "10.1109/tvcg.2018.2864909", "10.1111/cgf.13079", "10.3389/fpsyg.2012.00355", "10.1145/2858036.2858465", "10.1080/01621459.1989.10478821", "10.1037/0278-7393.24.3.732", "10.1109/tvcg.2011.127", "10.1145/2858036.2858063", "10.4249/scholarpedia.3325", "10.4324/9781410611949", "10.1111/cgf.13444", "10.1145/2993901.2993909", "10.1037/0033-295x.96.2.267", "10.1006/ijhc.1017", "10.1086/405615", "10.1109/tvcg.2019.2934801", "10.1038/17953", "10.1037/xhp0000314", "10.1109/tvcg.2019.2934400", "10.1145/2470654.2470723", "10.1037/0096-1523.16.2.332", "10.1167/16.5.11", "10.3758/s13423-016-1174-7", "10.3758/bf03207704", "10.1146/annurev.psych.55.090902.141415", "10.2307/2288400", "10.3758/bf03204258", "10.1109/tvcg.2011.279", "10.1109/vissoft.2014.36", "10.3758/s13423-011-0055-3", "10.1145/3025453.3025922", "10.1109/tvcg.2019.2934284", "10.3758/bf03210498", "10.3758/bf03200774", "10.2307/1419876", "10.1038/s41562-017-0058", "10.1109/tvcg.2010.237", "10.1109/pacificvis.2012.6183556", "10.1109/infvis.1997.636792", "10.1093/acprof:oso/9780198523192.003.0005", "10.1073/pnas.1117465109", "10.1109/tvcg.2013.234", "10.1038/nn.3655", "10.1111/cgf.12379", "10.1146/annurev-psych-010416-044232", "10.1111/cgf.13695", "10.1037/0033-295x.107.3.500", "10.1109/tvcg.2013.183", "10.1146/annurev.psych.53.100901.135125", "10.1037//0022-3514.79.6.995", "10.1559/152304003100010929", "10.1109/tvcg.2018.2865147", "10.1037/0096-1523.18.3.849", "10.1111/j.1467-8659.2009.01694.x", "10.1145/3290605.3300771"], "wos": 1, "children": [], "len": 1}], "len": 3}, {"doi": "10.1109/tvcg.2019.2934799", "title": "Data Sampling in Multi-view and Multi-class Scatterplots via Set Cover Optimization", "year": "2019", "conferenceName": "InfoVis", "authors": "Ruizhen Hu;Tingkai Sha;Oliver van Kaick;Oliver Deussen;Hui Huang 0004", "citationCount": "4", "affiliation": "Hu, RZ (Corresponding Author), Shenzhen Univ, Visual Comp Res Ctr, Shenzhen, Guangdong, Peoples R China. Hu, Ruizhen; Sha, Tingkai; Huang, Hui, Shenzhen Univ, Visual Comp Res Ctr, Shenzhen, Guangdong, Peoples R China. van Kaick, Oliver, Carleton Univ, Sch Comp Sci, Ottawa, ON, Canada. Deussen, Oliver, Konstanz Univ, Constance, Germany. Deussen, Oliver, SIAT, Shenzhen VisuCA Key Lab, Shenzhen, Guangdong, Peoples R China.", "countries": "Canada;Germany;China", "abstract": "We present a method for data sampling in scatterplots by jointly optimizing point selection for different views or classes. Our method uses space-filling curves (Z-order curves) that partition a point set into subsets that, when covered each by one sample, provide a sampling or coreset with good approximation guarantees in relation to the original point set. For scatterplot matrices with multiple views, different views provide different space-filling curves, leading to different partitions of the given point set. For multi-class scatterplots, the focus on either per-class distribution or global distribution provides two different partitions of the given point set that need to be considered in the selection of the coreset. For both cases, we convert the coreset selection problem into an Exact Cover Problem (ECP), and demonstrate with quantitative and qualitative evaluations that an approximate solution that solves the ECP efficiently is able to provide high-quality samplings.", "keywords": "Sampling,Scatterplot,SPLOM,Exact Cover Problem", "link": "http://dx.doi.org/10.1109/TVCG.2019.2934799", "refList": ["10.1057/palgrave.ivs.9500122", "10.1109/tvcg.2006.170", "10.1109/tvcg.2008.119", "10.1111/j.1467-8659.2009.01467.x", "10.2307/2289444", "10.1109/tvcg.2013.65", "10.1109/tvcg.2011.229", "10.1109/iv.2004.1320207", "10.1109/itoec.2018.8740621", "10.1145/1778765.1778816", "10.1109/tvcg.2018.2864912", "10.1007/0-387-28695-0", "10.1109/visual.1998.745301", "10.1287/moor.4.3.233", "10.1145/1556262.1556289", "10.1109/tvcg.2007.70535", "10.2307/2284239", "10.1109/tvcg.2017.2674978", "10.1016/j.dss.2009.05.016", "10.1109/tvcg.2014.2346594", "10.1109/vds.2017.8573446", "10.1007/978-1-4684-2001-2\\_9", "10.1109/iv.2002.1028760", "10.1145/1842993.1842999", "10.1038/nmeth.2490", "10.1109/tvcg.2013.153", "10.1111/cgf.13446", "10.1109/tvcg.2010.176", "10.1145/2702123.2702585", "10.1057/ivs.2009.34", "10.1179/000870403235002042"], "wos": 1, "children": [{"doi": "10.1109/tvcg.2020.3030443", "title": "CAVA: A Visual Analytics System for Exploratory Columnar Data Augmentation Using Knowledge Graphs", "year": "2020", "conferenceName": "VAST", "authors": "Dylan Cashman;Shenyu Xu;Subhajit Das;Florian Heimerl;Cong Liu;Shah Rukh Humayoun;Michael Gleicher;Alex Endert;Remco Chang", "citationCount": "0", "affiliation": "Cashman, D (Corresponding Author), Tufts Univ, Medford, MA 02155 USA. Cashman, Dylan; Liu, Cong; Chang, Remco, Tufts Univ, Medford, MA 02155 USA. Xu, Shenyu; Das, Subhajit; Endert, Alex, Georgia Tech, Atlanta, GA USA. Heimerl, Florian; Gleicher, Michael, Univ Wisconsin, Madison, WI 53706 USA. Humayoun, Shah Rukh, San Francisco State Univ, San Francisco, CA 94132 USA.", "countries": "USA", "abstract": "Most visual analytics systems assume that all foraging for data happens before the analytics process; once analysis begins, the set of data attributes considered is fixed. Such separation of data construction from analysis precludes iteration that can enable foraging informed by the needs that arise in-situ during the analysis. The separation of the foraging loop from the data analysis tasks can limit the pace and scope of analysis. In this paper, we present CAVA, a system that integrates data curation and data augmentation with the traditional data exploration and analysis tasks, enabling information foraging in-situ during analysis. Identifying attributes to add to the dataset is difficult because it requires human knowledge to determine which available attributes will be helpful for the ensuing analytical tasks. CAVA crawls knowledge graphs to provide users with a a broad set of attributes drawn from external data to choose from. Users can then specify complex operations on knowledge graphs to construct additional attributes. CAVA shows how visual analytics can help users forage for attributes by letting users visually explore the set of available data, and by serving as an interface for query construction. It also provides visualizations of the knowledge graph itself to help users understand complex joins such as multi-hop aggregations. We assess the ability of our system to enable users to perform complex data combinations without programming in a user study over two datasets. We then demonstrate the generalizability of CAVA through two additional usage scenarios. The results of the evaluation confirm that CAVA is effective in helping the user perform data foraging that leads to improved analysis outcomes, and offer evidence in support of integrating data augmentation as a part of the visual analytics pipeline.", "keywords": "Visual Analytics,Information Foraging,Data Augmentation", "link": "http://dx.doi.org/10.1109/TVCG.2020.3030443", "refList": ["10.1057/palgrave.ivs.9500122", "10.1109/tvcg.2016.2598867", "10.1111/cgf.13708", "10.1109/tvcg.2019.2934799", "10.1109/tvcg.2019.2934541", "10.1109/tvcg.2013.65", "10.1109/tvcg.2018.2875702", "10.1109/iv.2004.1320207", "10.1068/p260471", "10.1145/1778765.1778816", "10.1109/tvcg.2018.2808489", "10.1109/tvcg.2018.2864912", "10.1016/j.apgeog.2015.12.006", "10.1111/j.1467-8659.2011.01960.x", "10.1109/tvcg.2018.2864843", "10.1109/pacificvis.2010.5429604", "10.1109/tvcg.2014.2346898", "10.1109/5.726791", "10.1177/1475090214540874", "10.1109/icde.2016.7498287", "10.1145/1556262.1556289", "10.1109/tvcg.2007.70535", "10.1109/vast.2012.6400489", "10.1145/1056808.1056914", "10.1016/j.neucom.2014.09.063", "10.1145/7529.8927", "10.1109/tvcg.2016.2598495", "10.1109/tvcg.2016.2607204", "10.1109/vast47406.2019.8986943", "10.3758/bf03205986", "10.1109/infvis.2005.1532142", "10.1145/1150402.1150479", "10.1109/tvcg.2017.2674978", "10.1109/tvcg.2019.2945960", "10.1109/tvcg.2017.2744098", "10.1109/tvcg.2017.2674999", "10.1109/tvcg.2011.279", "10.1109/tvcg.2014.2346594", "10.1109/tvcg.2017.2744184", "10.1111/cgf.12876", "10.1007/s4095-020-0191-7", "10.1007/s11390-015-1535-0", "10.1111/cgf.12640", "10.1109/tvcg.2016.2598667", "10.1111/cgf.13683", "10.1109/tvcg.2013.153", "10.1109/tvcg.2019.2934208", "10.1109/tvcg.2019.2934655", "10.1111/cgf.12655", "10.1007/s11023-010-9221-z", "10.1109/vast.2012.6400487", "10.1145/2702123.2702585", "10.1007/bf00310175", "10.1109/tvcg.2017.2744378", "10.1103/physreve.64.061907", "10.1109/ldav.2017.8231848", "10.1109/tvcg.2016.2598831"], "wos": 1, "children": [], "len": 1}, {"doi": "10.1109/tvcg.2020.3030432", "title": "Evaluation of Sampling Methods for Scatterplots", "year": "2020", "conferenceName": "VAST", "authors": "Jun Yuan;Shouxing Xiang;Jiazhi Xia;Lingyun Yu;Shixia Liu", "citationCount": "0", "affiliation": "Liu, SX (Corresponding Author), Tsinghua Univ, BNRist, Beijing, Peoples R China. Yuan, Jun; Xiang, Shouxing; Liu, Shixia, Tsinghua Univ, BNRist, Beijing, Peoples R China. Xia, Jiazhi, Cent South Univ, Changsha, Peoples R China. Yu, Lingyun, Xian Jiaotong Liverpool Univ, Suzhou, Peoples R China.", "countries": "China", "abstract": "Given a scatterplot with tens of thousands of points or even more, a natural question is which sampling method should be used to create a small but \u201cgood\u201d scatterplot for a better abstraction. We present the results of a user study that investigates the influence of different sampling strategies on multi-class scatterplots. The main goal of this study is to understand the capability of sampling methods in preserving the density, outliers, and overall shape of a scatterplot. To this end, we comprehensively review the literature and select seven typical sampling strategies as well as eight representative datasets. We then design four experiments to understand the performance of different strategies in maintaining: 1) region density; 2) class density; 3) outliers; and 4) overall shape in the sampling results. The results show that: 1) random sampling is preferred for preserving region density; 2) blue noise sampling and random sampling have comparable performance with the three multi-class sampling strategies in preserving class density; 3) outlier biased density based sampling, recursive subdivision based sampling, and blue noise sampling perform the best in keeping outliers; and 4) blue noise sampling outperforms the others in maintaining the overall shape of a scatterplot.", "keywords": "Scatterplot,data sampling,empirical evaluation", "link": "http://dx.doi.org/10.1109/TVCG.2020.3030432", "refList": ["10.1057/palgrave.ivs.9500122", "10.1109/tvcg.2016.2598867", "10.1109/tvcg.2015.2467591", "10.1111/cgf.13708", "10.1109/tvcg.2019.2934799", "10.1109/tvcg.2019.2934541", "10.1109/tvcg.2013.65", "10.1109/iv.2004.1320207", "10.1068/p260471", "10.1145/1778765.1778816", "10.1109/tvcg.2018.2808489", "10.1109/tvcg.2018.2864912", "10.1016/j.apgeog.2015.12.006", "10.1111/j.1467-8659.2011.01960.x", "10.1109/tvcg.2018.2864843", "10.1109/pacificvis.2010.5429604", "10.1109/tvcg.2014.2346898", "10.1109/5.726791", "10.1177/1475090214540874", "10.1145/1556262.1556289", "10.1109/tvcg.2007.70535", "10.1109/vast.2012.6400489", "10.1145/1056808.1056914", "10.1016/j.neucom.2014.09.063", "10.1145/7529.8927", "10.1109/tvcg.2016.2607204", "10.1109/vast47406.2019.8986943", "10.3758/bf03205986", "10.1109/infvis.2005.1532142", "10.1145/1150402.1150479", "10.1109/tvcg.2017.2674978", "10.1109/tvcg.2017.2744098", "10.1109/tvcg.2017.2674999", "10.1109/tvcg.2011.279", "10.1109/tvcg.2014.2346594", "10.1109/tvcg.2017.2744184", "10.1111/cgf.12876", "10.1109/1011101.2019.2945960", "10.1007/s4095-020-0191-7", "10.1007/s11390-015-1535-0", "10.1111/cgf.12640", "10.1109/tvcg.2016.2598667", "10.1111/cgf.13683", "10.1109/tvcg.2013.153", "10.1109/tvcg.2019.2934208", "10.1109/tvcg.2019.2934655", "10.1111/cgf.12655", "10.1007/s11023-010-9221-z", "10.1109/vast.2012.6400487", "10.1145/2702123.2702585", "10.1007/bf00310175", "10.1109/tvcg.2017.2744378", "10.1103/physreve.64.061907", "10.1109/ldav.2017.8231848", "10.1109/tvcg.2016.2598831"], "wos": 1, "children": [], "len": 1}, {"doi": "10.1109/tvcg.2020.3030365", "title": "Modeling the Influence of Visual Density on Cluster Perception in Scatterplots Using Topology", "year": "2020", "conferenceName": "InfoVis", "authors": "Ghulam Jilani Quadri;Paul Rosen", "citationCount": "0", "affiliation": "Quadri, GJ (Corresponding Author), Univ S Florida, Tampa, FL 33620 USA. Quadri, Ghulam Jilani; Rosen, Paul, Univ S Florida, Tampa, FL 33620 USA.", "countries": "USA", "abstract": "Scatterplots are used for a variety of visual analytics tasks, including cluster identification, and the visual encodings used on a scatterplot play a deciding role on the level of visual separation of clusters. For visualization designers, optimizing the visual encodings is crucial to maximizing the clarity of data. This requires accurately modeling human perception of cluster separation, which remains challenging. We present a multi-stage user study focusing on four factors-distribution size of clusters, number of points, size of points, and opacity of points-that influence cluster identification in scatterplots. From these parameters, we have constructed two models, a distance-based model, and a density-based model, using the merge tree data structure from Topological Data Analysis. Our analysis demonstrates that these factors play an important role in the number of clusters perceived, and it verifies that the distance-based and density-based models can reasonably estimate the number of clusters a user observes. Finally, we demonstrate how these models can be used to optimize visual encodings on real-world data.", "keywords": "Scatterplot,clustering,perception,empirical evaluation,visual encoding,crowdsourcing,topological data analysis", "link": "http://dx.doi.org/10.1109/TVCG.2020.3030365", "refList": ["10.1109/tvcg.2017.2744359", "10.1145/1778765", "10.1109/tvcg.2019.2934799", "10.1111/cgf.12889", "10.1109/tvcg.2011.127", "10.1111/cgf.13444", "10.1145/1964897.1964910", "10.1167/8.7.6", "10.1145/3173574.3173991", "10.1145/1556262.1556289", "10.1145/1056808.1056914", "10.2307/2288400", "10.1109/tvcg.2014.2346594", "10.1109/iv.2002.1028760", "10.1177/001316447303300111", "10.1007/bf02289823", "10.1109/tvcg.2017.2744339", "10.1111/j.1467-8659.2009.01694.x", "10.1109/tvcg.2014.2346979", "10.1090/mbk/069", "10.1109/tvcg.2013.65", "10.1109/mcg.2012.37", "10.1109/pacificvis.2010.5429604", "10.1002/acp.2350050106", "10.1109/infvis.2005.1532136", "10.1177/1473871612465214", "10.1109/tvcg.2017.2674978", "10.1002/jhbs.20078", "10.1007/978-3-642-35142-6\\_14", "10.1007/978-3-319-71507-0", "10.1109/mcg.201.7.6", "10.3758/bf03193961", "10.1364/josa.49.000280", "10.1145/3025453.3025905", "10.1109/tvcg.201.9.2934541", "10.1109/tvcg.2018.2829750", "10.1177/1473871615606187", "10.1111/cgf.13408", "10.1109/pacificvis.2016.7465252", "10.1109/pacificvis.2016.7465244", "10.1109/inevis.2005.1532142", "10.1111/cgf.13414", "10.1111/j.1467-8659.2012.03125.x", "10.1167/16.5.11", "10.1109/infvis.2005.1532142", "10.1145/2858036.2858155", "10.1038/nmeth1210-941", "10.1177/1473871616638892", "10.1109/tcbb.2014.2306840", "10.1111/cgf.13684", "10.1177/0301006615602599", "10.1214/aoms/1177731915", "10.1145/2702123.2702585", "10.1109/tvcg.2013.183", "10.1109/tvcg.2014.2346572", "10.1109/tvcg.2018.2875702", "10.1109/tvcg.2017.2754480", "10.1109/vast.2014.7042493", "10.1057/palgrave.ivs.9500122", "10.1109/tvcg.2014.2330617", "10.1109/tvcg.2019.2934541", "10.1068/p030033", "10.1140/epjds/s13688-017-0109-5", "10.1201/b17511", "10.1016/s0925-7721(02)00093-7", "10.1109/pacificvis.2012.6183557", "10.1109/tvcg.2014.2346983", "10.1109/5.726791", "10.1080/01621459.1926.10502165", "10.1109/tvcg.2007.70535", "10.1109/tvcg.2018.2864907", "10.1111/cgf.12109", "10.1109/tvcg.2017.2744184", "10.1146/annurev-statistics-031017-100045", "10.1111/cgf.13409", "10.1145/3002151.3002162", "10.1016/s0378-4371(98)00494-4", "10.3138/y308-2422-8615-1233", "10.1111/cgf.12632", "10.1145/3290605.3300771"], "wos": 1, "children": [], "len": 1}], "len": 7}, {"doi": "10.1109/tvcg.2019.2934432", "title": "Discriminability Tests for Visualization Effectiveness and Scalability", "year": "2019", "conferenceName": "InfoVis", "authors": "Rafael Veras;Christopher Collins", "citationCount": "1", "affiliation": "Veras, R (Corresponding Author), Ontario Tech Univ, Oshawa, ON, Canada. Veras, Rafael; Collins, Christopher, Ontario Tech Univ, Oshawa, ON, Canada.", "countries": "Canada", "abstract": "The scalability of a particular visualization approach is limited by the ability for people to discern differences between plots made with different datasets. Ideally, when the data changes, the visualization changes in perceptible ways. This relation breaks down when there is a mismatch between the encoding and the character of the dataset being viewed. Unfortunately, visualizations are often designed and evaluated without fully exploring how they will respond to a wide variety of datasets. We explore the use of an image similarity measure, the Multi-Scale Structural Similarity Index (MS-SSIM), for testing the discriminability of a data visualization across a variety of datasets. MS-SSIM is able to capture the similarity of two visualizations across multiple scales, including low level granular changes and high level patterns. Significant data changes that are not captured by the MS-SSIM indicate visualizations of low discriminability and effectiveness. The measure's utility is demonstrated with two empirical studies. In the first, we compare human similarity judgments and MS-SSIM scores for a collection of scatterplots. In the second, we compute the discriminability values for a set of basic visualizations and compare them with empirical measurements of effectiveness. In both cases, the analyses show that the computational measure is able to approximate empirical results. Our approach can be used to rank competing encodings on their discriminability and to aid in selecting visualizations for a particular type of data distribution.", "keywords": "Scalability,Discriminability,Simulation,Perception", "link": "http://dx.doi.org/10.1109/TVCG.2019.2934432", "refList": ["10.1109/tvcg.2012.233", "10.1109/tvcg.2017.2744359", "10.1109/tvcg.2012.230", "10.1111/cgf.12647", "10.1109/tvcg.2016.2598918", "10.1109/tvcg.2007.70529", "10.1145/2858036.2858435", "10.1109/vast.2009.5332628", "10.1145/3025453.3025912", "10.1145/1133265.1133318", "10.1109/tip.2010.2092435", "10.1109/tvcg.2010.132", "10.1109/tvcg.2018.2865264", "10.1175/jtech-d-11-00103.1", "10.1145/1190036.1190039", "10.1111/cgf.12127", "10.1109/infvis.2005.1532142", "10.1145/2858036.2858155", "10.1109/mcg.2014.18", "10.1145/3173574.3174172", "10.1109/tvcg.2009.153", "10.1057/palgrave.ivs.9500070", "10.1109/tvcg.2018.2790961", "10.1109/tvcg.2014.2346978", "10.1109/tvcg.2018.2810918", "10.1111/cgf.13409", "10.1109/tip.2003.819861", "10.1145/2642918.2647411", "10.1080/15230406.2016.1140074", "10.1109/jstsp.2009.2015374", "10.1109/tvcg.2010.237", "10.1109/mcg.2009.6", "10.1111/j.1467-8659.2009.01667.x", "10.1109/tvcg.2010.161", "10.1111/cgf.13446", "10.1109/tvcg.2014.2346325", "10.1109/tvcg.2009.111", "10.1147/jrd.2015.2411412"], "wos": 1, "children": [{"doi": "10.1109/tvcg.2020.3030394", "title": "Direct Volume Rendering with Nonparametric Models of Uncertainty", "year": "2020", "conferenceName": "SciVis", "authors": "Tushar M. Athawale;Bo Ma 0002;Elham Sakhaee;Christopher R. Johnson;Alireza Entezari", "citationCount": "0", "affiliation": "Athawale, TM (Corresponding Author), Univ Utah, Sci Comp \\& Imaging SCI Inst, Salt Lake City, UT 84112 USA. Athawale, Tushar M.; Johnson, Chris R., Univ Utah, Sci Comp \\& Imaging SCI Inst, Salt Lake City, UT 84112 USA. Ma, Bo; Sakhaee, Elham; Entezari, Alireza, Univ Florida, Dept CISE, Gainesville, FL 32611 USA.", "countries": "USA", "abstract": "We present a nonparametric statistical framework for the quantification, analysis, and propagation of data uncertainty in direct volume rendering (DVR). The state-of-the-art statistical DVR framework allows for preserving the transfer function (TF) of the ground truth function when visualizing uncertain data; however, the existing framework is restricted to parametric models of uncertainty. In this paper, we address the limitations of the existing DVR framework by extending the DVR framework for nonparametric distributions. We exploit the quantile interpolation technique to derive probability distributions representing uncertainty in viewing-ray sample intensities in closed form, which allows for accurate and efficient computation. We evaluate our proposed nonparametric statistical models through qualitative and quantitative comparisons with the mean-field and parametric statistical models, such as uniform and Gaussian, as well as Gaussian mixtures. In addition, we present an extension of the state-of-the-art rendering parametric framework to 2D TFs for improved DVR classifications. We show the applicability of our uncertainty quantification framework to ensemble, downsampled, and bivariate versions of scalar field datasets.", "keywords": "Volumes,uncertainty,nonparametric,2D transfer function", "link": "http://dx.doi.org/10.1109/TVCG.2020.3030394", "refList": ["10.1109/icdm.2012.80", "10.1145/1401890.1401904", "10.1109/tvcg.2017.2745139", "10.18128/d030.v6.0", "10.1111/cgf.12142", "10.1109/tvcg.2009.114", "10.1111/j.1467-8659.2009.01677.x", "10.1109/mcse.2007.55", "10.1109/icde.2012.16", "10.1198/106186008x320465", "10.1145/1835804.1835868", "10.1559/1523040054738936", "10.1109/tvcg.2019.2934432", "10.1109/34.1000236", "10.1109/infvis.2005.1532136", "10.1109/tvcg.2012.128", "10.1109/pacificvis.2017.8031573", "10.1109/tvcg.2016.2598920", "10.1109/tvcg.2018.2865021", "10.1109/infvis.2005.1532142", "10.1145/2858036.2858155", "10.1109/sp.2009.22", "10.1109/tvcg.2017.2744184", "10.1145/773153.773173", "10.1145/2660267.2660348", "10.1109/icdmw.2009.93", "10.1016/j.jtrangeo.2015.09.001", "10.1109/icde.2010.5447831", "10.1007/11681878\\_14", "10.1111/cgf.13409", "10.1007/s13278-014-0205-5", "10.1109/tvcg.2011.163", "10.1145/3035918.3035940", "10.1109/sp.2008.33", "10.1145/2882903.2882931"], "wos": 1, "children": [], "len": 1}], "len": 3}, {"doi": "10.1109/tvcg.2019.2934208", "title": "Evaluating Perceptual Bias During Geometric Scaling of Scatterplots", "year": "2019", "conferenceName": "VAST", "authors": "Yating Wei;Honghui Mei;Ying Zhao;Shuyue Zhou;Bingru Lin;Haojing Jiang;Wei Chen", "citationCount": "5", "affiliation": "Chen, W (Corresponding Author), Zhejiang Univ, State Key Lab CAD \\& CG, Hangzhou 310058, Zhejiang, Peoples R China. Zhao, Y (Corresponding Author), Cent South Univ, Sch Comp Sci \\& Engn, Changsha 410083, Hunan, Peoples R China. Wei, Yating; Mei, Honghui; Zhou, Shuyue; Lin, Bingru; Chen, Wei, Zhejiang Univ, State Key Lab CAD \\& CG, Hangzhou 310058, Zhejiang, Peoples R China. Zhao, Ying; Jiang, Haojing, Cent South Univ, Sch Comp Sci \\& Engn, Changsha 410083, Hunan, Peoples R China.", "countries": "China", "abstract": "Scatterplots are frequently scaled to fit display areas in multi-view and multi-device data analysis environments. A common method used for scaling is to enlarge or shrink the entire scatterplot together with the inside points synchronously and proportionally. This process is called geometric scaling. However, geometric scaling of scatterplots may cause a perceptual bias, that is, the perceived and physical values of visual features may be dissociated with respect to geometric scaling. For example, if a scatterplot is projected from a laptop to a large projector screen, then observers may feel that the scatterplot shown on the projector has fewer points than that viewed on the laptop. This paper presents an evaluation study on the perceptual bias of visual features in scatterplots caused by geometric scaling. The study focuses on three fundamental visual features (i.e., numerosity, correlation, and cluster separation) and three hypotheses that are formulated on the basis of our experience. We carefully design three controlled experiments by using well-prepared synthetic data and recruit participants to complete the experiments on the basis of their subjective experience. With a detailed analysis of the experimental results, we obtain a set of instructive findings. First, geometric scaling causes a bias that has a linear relationship with the scale ratio. Second, no significant difference exists between the biases measured from normally and uniformly distributed scatterplots. Third, changing the point radius can correct the bias to a certain extent. These findings can be used to inspire the design decisions of scatterplots in various scenarios.", "keywords": "Evaluation,scatterplot,geometric scaling,bias,perceptual consistency", "link": "http://dx.doi.org/10.1109/TVCG.2019.2934208", "refList": ["10.2307/2288843", "10.1109/tvcg.2017.2744359", "10.1109/tvcg.2015.2467732", "10.1109/tvcg.2014.2346979", "10.1126/science.216.4550.1138", "10.1109/tvcg.2017.2744138", "10.1111/j.1467-8659.2009.01467.x", "10.1145/2491568.2491577", "10.1109/mwc.2018.1700325", "10.1145/2449396.2449439", "10.1109/tvcg.2011.127", "10.1109/tvcg.2011.229", "10.1167/15.5.4", "10.1073/pnas.1113195108", "10.1145/2702123.2702545", "10.1109/vast.2009.5332628", "10.1109/tvcg.2018.2800013", "10.1007/s12650-018-0530-2", "10.1016/s0042-6989(97)00340-4", "10.1109/vast.2010.5652460", "10.1109/mcg.2018.2879067", "10.1109/tvcg.2018.2864912", "10.1109/pacificvis.2010.5429604", "10.1109/tcst.2018.2819965", "10.1167/10.2.10", "10.1145/2470654.2481318", "10.1145/1842993.1843002", "10.1167/12.6.8", "10.1109/tvcg.2013.124", "10.1057/ivs.2008.13", "10.1109/tvcg.2007.70596", "10.1109/tvcg.2018.2865266", "10.1145/3173574.3173664", "10.1109/tvcg.2015.2467671", "10.1016/j.cag.2017.07.004", "10.1177/0956797613501520", "10.1109/tvcg.2018.2865020", "10.1111/j.1467-8659.2012.03125.x", "10.3758/bf03205986", "10.3758/s13423-016-1174-7", "10.1109/tvcg.2017.2680452", "10.1109/mc.2006.109", "10.1109/tvcg.2017.2744098", "10.1038/srep32810", "10.1016/j.visres.2013.06.006", "10.1002/jhbs.20078", "10.1109/tvcg.2006.163", "10.1109/tvcg.2014.2346594", "10.1109/tvcg.2017.2744184", "10.1016/j.cognition.2007.10.009", "10.1109/tvcg.2018.2865142", "10.3758/app.72.7.1839", "10.1109/tvcg.2018.2810918", "10.1016/j.jvlc.2017.10.001", "10.1145/2682623", "10.1109/tvcg.2018.2864884", "10.1145/3025453.3025984", "10.1109/tvcg.2006.184", "10.1109/tvcg.2013.153", "10.1016/j.jvlc.2018.08.003", "10.1109/tvcg.2016.2520921", "10.1111/cgf.13446", "10.1017/s0022381612000187", "10.1145/2702123.2702406", "10.1109/vast.2012.6400487", "10.1109/tvcg.2013.183", "10.1177/1473871611415997", "10.1145/2702123.2702585", "10.1145/2993901.2993903", "10.1109/tvcg.2013.120", "10.1111/cgf.12632", "10.1145/1385569.1385602", "10.1109/tvcg.2017.2754480", "10.1111/j.1467-8659.2009.01694.x"], "wos": 1, "children": [{"doi": "10.1109/tvcg.2020.3030456", "title": "Cartographic Relief Shading with Neural Networks", "year": "2020", "conferenceName": "InfoVis", "authors": "Bernhard Jenny;Magnus Heitzler;Dilpreet Singh;Marianna Farmakis-Serebryakova;Jeffery Chieh Liu;Lorenz Hurni", "citationCount": "4", "affiliation": "Jenny, B (Corresponding Author), Monash Univ, Melbourne, Vic, Australia. Jenny, Bernhard; Singh, Dilpreet; Liu, Jeffery Chieh, Monash Univ, Melbourne, Vic, Australia. Heitzler, Magnus; Farmakis-Serebryakova, Marianna; Hurni, Lorenz, Swiss Fed Inst Technol, Inst Cartog \\& Geoinformat, Zurich, Switzerland.", "countries": "Switzerland;Australia", "abstract": "Shaded relief is an effective method for visualising terrain on topographic maps, especially when the direction of illumination is adapted locally to emphasise individual terrain features. However, digital shading algorithms are unable to fully match the expressiveness of hand-crafted masterpieces, which are created through a laborious process by highly specialised cartographers. We replicate hand-drawn relief shading using U-Net neural networks. The deep neural networks are trained with manual shaded relief images of the Swiss topographic map series and terrain models of the same area. The networks generate shaded relief that closely resemble hand-drawn shaded relief art. The networks learn essential design principles from manual relief shading such as removing unnecessary terrain details, locally adjusting the illumination direction to accentuate individual terrain features, and varying brightness to emphasise larger landforms. Neural network shadings are generated from digital elevation models in a few seconds, and a study with 18 relief shading experts found that they are of high quality.", "keywords": "Relief shading,shaded relief,hillshade,neural rendering,illustrative visualisation,image-to-image translation", "link": "http://dx.doi.org/10.1109/TVCG.2020.3030456", "refList": ["10.1145/1456650.1456652", "10.1145/1145/1556262.1556270", "10.1145/345513.345271", "10.1109/tvcg.2019.2934803", "10.1145/3180658", "10.1109/tridui.2006.1618264", "10.3389/fict.2018.00015", "10.1109/vr.2018.8447558", "10.1518/hfes.45.1.160.27234", "10.1145/3290605.3300377", "10.1089/cpb.2006.9.157", "10.1007/s00779-011-0500-3", "10.1109/vl.1996.545307", "10.1109/tvcg.2019.2934415", "10.1109/5.726791", "10.1145/3290605.3300288", "10.1109/tvcg.2017.2745941", "10.1109/vr.2001.913779", "10.1145/586081.586086", "10.18637/jss.v067.i01", "10.1145/1502800.1502805", "10.1145/1165734.1165736", "10.1145/3126594.3126613", "10.1109/tvcg.2008.109", "10.1109/tvcg.2017.2744184", "10.1016/j.cola.2019.100937", "10.1109/visual.2019.8933545", "10.1145/3290605.3300555", "10.1111/cgf.13431", "10.1109/tvcg.2019.2934395", "10.1109/vr.2019.8798340", "10.1145/3025453.3026046", "10.1109/vr.2019.8797871", "10.1145/3290605.3300752", "10.1109/tvcg.2016.2520921", "10.1109/tvcg.2018.2865191", "10.1145/1970378.1970384", "10.1109/tvcg.2019.2934208", "10.18637/jss.v069.i01", "10.1162/105474698565659", "10.1145/1124772.1124775", "10.1109/vrais.1997.583043"], "wos": 1, "children": [], "len": 1}, {"doi": "10.1109/tvcg.2020.3030443", "title": "CAVA: A Visual Analytics System for Exploratory Columnar Data Augmentation Using Knowledge Graphs", "year": "2020", "conferenceName": "VAST", "authors": "Dylan Cashman;Shenyu Xu;Subhajit Das;Florian Heimerl;Cong Liu;Shah Rukh Humayoun;Michael Gleicher;Alex Endert;Remco Chang", "citationCount": "0", "affiliation": "Cashman, D (Corresponding Author), Tufts Univ, Medford, MA 02155 USA. Cashman, Dylan; Liu, Cong; Chang, Remco, Tufts Univ, Medford, MA 02155 USA. Xu, Shenyu; Das, Subhajit; Endert, Alex, Georgia Tech, Atlanta, GA USA. Heimerl, Florian; Gleicher, Michael, Univ Wisconsin, Madison, WI 53706 USA. Humayoun, Shah Rukh, San Francisco State Univ, San Francisco, CA 94132 USA.", "countries": "USA", "abstract": "Most visual analytics systems assume that all foraging for data happens before the analytics process; once analysis begins, the set of data attributes considered is fixed. Such separation of data construction from analysis precludes iteration that can enable foraging informed by the needs that arise in-situ during the analysis. The separation of the foraging loop from the data analysis tasks can limit the pace and scope of analysis. In this paper, we present CAVA, a system that integrates data curation and data augmentation with the traditional data exploration and analysis tasks, enabling information foraging in-situ during analysis. Identifying attributes to add to the dataset is difficult because it requires human knowledge to determine which available attributes will be helpful for the ensuing analytical tasks. CAVA crawls knowledge graphs to provide users with a a broad set of attributes drawn from external data to choose from. Users can then specify complex operations on knowledge graphs to construct additional attributes. CAVA shows how visual analytics can help users forage for attributes by letting users visually explore the set of available data, and by serving as an interface for query construction. It also provides visualizations of the knowledge graph itself to help users understand complex joins such as multi-hop aggregations. We assess the ability of our system to enable users to perform complex data combinations without programming in a user study over two datasets. We then demonstrate the generalizability of CAVA through two additional usage scenarios. The results of the evaluation confirm that CAVA is effective in helping the user perform data foraging that leads to improved analysis outcomes, and offer evidence in support of integrating data augmentation as a part of the visual analytics pipeline.", "keywords": "Visual Analytics,Information Foraging,Data Augmentation", "link": "http://dx.doi.org/10.1109/TVCG.2020.3030443", "refList": ["10.1057/palgrave.ivs.9500122", "10.1109/tvcg.2016.2598867", "10.1111/cgf.13708", "10.1109/tvcg.2019.2934799", "10.1109/tvcg.2019.2934541", "10.1109/tvcg.2013.65", "10.1109/tvcg.2018.2875702", "10.1109/iv.2004.1320207", "10.1068/p260471", "10.1145/1778765.1778816", "10.1109/tvcg.2018.2808489", "10.1109/tvcg.2018.2864912", "10.1016/j.apgeog.2015.12.006", "10.1111/j.1467-8659.2011.01960.x", "10.1109/tvcg.2018.2864843", "10.1109/pacificvis.2010.5429604", "10.1109/tvcg.2014.2346898", "10.1109/5.726791", "10.1177/1475090214540874", "10.1109/icde.2016.7498287", "10.1145/1556262.1556289", "10.1109/tvcg.2007.70535", "10.1109/vast.2012.6400489", "10.1145/1056808.1056914", "10.1016/j.neucom.2014.09.063", "10.1145/7529.8927", "10.1109/tvcg.2016.2598495", "10.1109/tvcg.2016.2607204", "10.1109/vast47406.2019.8986943", "10.3758/bf03205986", "10.1109/infvis.2005.1532142", "10.1145/1150402.1150479", "10.1109/tvcg.2017.2674978", "10.1109/tvcg.2019.2945960", "10.1109/tvcg.2017.2744098", "10.1109/tvcg.2017.2674999", "10.1109/tvcg.2011.279", "10.1109/tvcg.2014.2346594", "10.1109/tvcg.2017.2744184", "10.1111/cgf.12876", "10.1007/s4095-020-0191-7", "10.1007/s11390-015-1535-0", "10.1111/cgf.12640", "10.1109/tvcg.2016.2598667", "10.1111/cgf.13683", "10.1109/tvcg.2013.153", "10.1109/tvcg.2019.2934208", "10.1109/tvcg.2019.2934655", "10.1111/cgf.12655", "10.1007/s11023-010-9221-z", "10.1109/vast.2012.6400487", "10.1145/2702123.2702585", "10.1007/bf00310175", "10.1109/tvcg.2017.2744378", "10.1103/physreve.64.061907", "10.1109/ldav.2017.8231848", "10.1109/tvcg.2016.2598831"], "wos": 1, "children": [], "len": 1}, {"doi": "10.1109/tvcg.2020.3030432", "title": "Evaluation of Sampling Methods for Scatterplots", "year": "2020", "conferenceName": "VAST", "authors": "Jun Yuan;Shouxing Xiang;Jiazhi Xia;Lingyun Yu;Shixia Liu", "citationCount": "0", "affiliation": "Liu, SX (Corresponding Author), Tsinghua Univ, BNRist, Beijing, Peoples R China. Yuan, Jun; Xiang, Shouxing; Liu, Shixia, Tsinghua Univ, BNRist, Beijing, Peoples R China. Xia, Jiazhi, Cent South Univ, Changsha, Peoples R China. Yu, Lingyun, Xian Jiaotong Liverpool Univ, Suzhou, Peoples R China.", "countries": "China", "abstract": "Given a scatterplot with tens of thousands of points or even more, a natural question is which sampling method should be used to create a small but \u201cgood\u201d scatterplot for a better abstraction. We present the results of a user study that investigates the influence of different sampling strategies on multi-class scatterplots. The main goal of this study is to understand the capability of sampling methods in preserving the density, outliers, and overall shape of a scatterplot. To this end, we comprehensively review the literature and select seven typical sampling strategies as well as eight representative datasets. We then design four experiments to understand the performance of different strategies in maintaining: 1) region density; 2) class density; 3) outliers; and 4) overall shape in the sampling results. The results show that: 1) random sampling is preferred for preserving region density; 2) blue noise sampling and random sampling have comparable performance with the three multi-class sampling strategies in preserving class density; 3) outlier biased density based sampling, recursive subdivision based sampling, and blue noise sampling perform the best in keeping outliers; and 4) blue noise sampling outperforms the others in maintaining the overall shape of a scatterplot.", "keywords": "Scatterplot,data sampling,empirical evaluation", "link": "http://dx.doi.org/10.1109/TVCG.2020.3030432", "refList": ["10.1057/palgrave.ivs.9500122", "10.1109/tvcg.2016.2598867", "10.1109/tvcg.2015.2467591", "10.1111/cgf.13708", "10.1109/tvcg.2019.2934799", "10.1109/tvcg.2019.2934541", "10.1109/tvcg.2013.65", "10.1109/iv.2004.1320207", "10.1068/p260471", "10.1145/1778765.1778816", "10.1109/tvcg.2018.2808489", "10.1109/tvcg.2018.2864912", "10.1016/j.apgeog.2015.12.006", "10.1111/j.1467-8659.2011.01960.x", "10.1109/tvcg.2018.2864843", "10.1109/pacificvis.2010.5429604", "10.1109/tvcg.2014.2346898", "10.1109/5.726791", "10.1177/1475090214540874", "10.1145/1556262.1556289", "10.1109/tvcg.2007.70535", "10.1109/vast.2012.6400489", "10.1145/1056808.1056914", "10.1016/j.neucom.2014.09.063", "10.1145/7529.8927", "10.1109/tvcg.2016.2607204", "10.1109/vast47406.2019.8986943", "10.3758/bf03205986", "10.1109/infvis.2005.1532142", "10.1145/1150402.1150479", "10.1109/tvcg.2017.2674978", "10.1109/tvcg.2017.2744098", "10.1109/tvcg.2017.2674999", "10.1109/tvcg.2011.279", "10.1109/tvcg.2014.2346594", "10.1109/tvcg.2017.2744184", "10.1111/cgf.12876", "10.1109/1011101.2019.2945960", "10.1007/s4095-020-0191-7", "10.1007/s11390-015-1535-0", "10.1111/cgf.12640", "10.1109/tvcg.2016.2598667", "10.1111/cgf.13683", "10.1109/tvcg.2013.153", "10.1109/tvcg.2019.2934208", "10.1109/tvcg.2019.2934655", "10.1111/cgf.12655", "10.1007/s11023-010-9221-z", "10.1109/vast.2012.6400487", "10.1145/2702123.2702585", "10.1007/bf00310175", "10.1109/tvcg.2017.2744378", "10.1103/physreve.64.061907", "10.1109/ldav.2017.8231848", "10.1109/tvcg.2016.2598831"], "wos": 1, "children": [], "len": 1}], "len": 7}, {"doi": "10.1109/tvcg.2019.2934300", "title": "GUIRO: User-Guided Matrix Reordering", "year": "2019", "conferenceName": "VAST", "authors": "Michael Behrisch;Tobias Schreck;Hanspeter Pfister", "citationCount": "1", "affiliation": "Behrisch, M (Corresponding Author), Harvard Univ, Sch Engn \\& Appl Sci, Cambridge, MA 02138 USA. Behrisch, Michael; Pfister, Hanspeter, Harvard Univ, Sch Engn \\& Appl Sci, Cambridge, MA 02138 USA. Schreck, Tobias, Graz Univ Technol, Graz, Austria.", "countries": "USA;Austria", "abstract": "Matrix representations are one of the main established and empirically proven to be effective visualization techniques for relational (or network) data. However, matrices\u2014similar to node-link diagrams\u2014are most effective if their layout reveals the underlying data topology. Given the many developed algorithms, a practical problem arises: \u201cWhich matrix reordering algorithm should I choose for my dataset at hand?\u201d To make matters worse, different reordering algorithms applied to the same dataset may let significantly different visual matrix patterns emerge. This leads to the question of trustworthiness and explainability of these fully automated, often heuristic, black-box processes. We present GUIRO, a Visual Analytics system that helps novices, network analysts, and algorithm designers to open the black-box. Users can investigate the usefulness and expressiveness of 70 accessible matrix reordering algorithms. For network analysts, we introduce a novel model space representation and two interaction techniques for a user-guided reordering of rows or columns, and especially groups thereof (submatrix reordering). These novel techniques contribute to the understanding of the global and local dataset topology. We support algorithm designers by giving them access to 16 reordering quality metrics and visual exploration means for comparing reordering implementations on a row/column permutation level. We evaluated GUIRO in a guided explorative user study with 12 subjects, a case study demonstrating its usefulness in a real-world scenario, and through an expert study gathering feedback on our design decisions. We found that our proposed methods help even inexperienced users to understand matrix patterns and allow a user-guided steering of reordering algorithms. GUIRO helps to increase the transparency of matrix reordering algorithms, thus helping a broad range of users to get a better insight into the complex reordering process, in turn supporting data and reordering algorithm insights.", "keywords": "Visual Analytics,matrix,black-box algorithms,seriation,ordering,sorting,steerable algorithm,interaction,2D projection", "link": "http://dx.doi.org/10.1109/TVCG.2019.2934300", "refList": ["10.1109/tvcg.2007.70582", "10.2307/276978", "10.1109/tvcg.2008.61", "10.3390/su10040973", "10.1101/121889", "10.1145/1345448.1345453", "10.1186/s12879-014-0695-9", "10.1186/1471-2105-9-155", "10.1145/1124772.1124891", "10.1109/tvcg.2010.159", "10.1111/j.2044-8317.1974.tb00534.x", "10.1109/tpami.2015.2470671", "10.1198/000313005x22770", "10.1109/tvcg.2012.219", "10.1002/sam.10071", "10.1016/j.ejor.2016.08.066", "10.1007/s00265-003-0651-y", "10.1109/biovis.2013.6664342", "10.3115/v1/p14-1062", "10.3389/fpsyg.2017.01349", "10.1109/tpami.2004.1265866", "10.1057/palgrave.ivs.9500086", "10.1007/s004260000031", "10.1111/cgf.12935", "10.1145/800195.805928", "10.1109/tvcg.2014.2346279", "10.2312/eurovisstar.20141174", "10.1109/tvcg.2012.256", "10.1093/bioinformatics/17.suppl\\_1.s22", "10.1109/infvis.2004.46", "10.1007/978-3-319-06793-3\\_5", "10.1109/tvcg.2006.147", "10.1109/tvcg.2015.2468078", "10.1093/bioinformatics/bti141", "10.1145/1168149.1168168", "10.1109/tvcg.2017.2745978", "10.1177/1473871613513228", "10.1109/mcg.2014.62", "10.1109/tvcg.2006.166", "10.1145/2470654.2470724", "10.1177/154193120605000909", "10.1109/sibgrapi.2007.21", "10.1145/3065386", "10.1109/tvcg.2006.160", "10.1287/opre.20.5.993", "10.1111/cgf.13446", "10.1057/palgrave.ivs.9500092", "10.1145/568522.568523", "10.1109/mcg.2013.66", "10.1109/tvcg.2018.2865940", "10.1109/tvcg.2012.208"], "wos": 1, "children": [{"doi": "10.1109/tvcg.2020.3030471", "title": "Visual Analysis of Discrimination in Machine Learning", "year": "2020", "conferenceName": "InfoVis", "authors": "Qianwen Wang;Zhenhua Xu;Zhutian Chen;Yong Wang;Shixia Liu;Huamin Qu", "citationCount": "0", "affiliation": "Wang, QW (Corresponding Author), Hong Kong Univ Sci \\& Technol, Hong Kong, Peoples R China. Wang, Qianwen; Xu, Zhenhua; Chen, Zhutian; Wang, Yong; Qu, Huamin, Hong Kong Univ Sci \\& Technol, Hong Kong, Peoples R China. Liu, Shixia, Tsinghua Univ, Beijing, Peoples R China.", "countries": "China", "abstract": "The growing use of automated decision-making in critical applications, such as crime prediction and college admission, has raised questions about fairness in machine learning. How can we decide whether different treatments are reasonable or discriminatory? In this paper, we investigate discrimination in machine learning from a visual analytics perspective and propose an interactive visualization tool, DiscriLens, to support a more comprehensive analysis. To reveal detailed information on algorithmic discrimination, DiscriLens identifies a collection of potentially discriminatory itemsets based on causal modeling and classification rules mining. By combining an extended Euler diagram with a matrix-based visualization, we develop a novel set visualization to facilitate the exploration and interpretation of discriminatory itemsets. A user study shows that users can interpret the visually encoded information in DiscriLens quickly and accurately. Use cases demonstrate that DiscriLens provides informative guidance in understanding and reducing algorithmic discrimination.", "keywords": "Machine Learning,Discrimination,Data Visualization", "link": "http://dx.doi.org/10.1109/TVCG.2020.3030471", "refList": ["10.1109/tvcg.2019.2934396", "10.2312/eurovisstar.20141170", "10.1145/3357384.3357910", "10.1111/cgf.12791", "10.1109/tvcg.2018.2861397", "10.1111/j.1467-8659.2011.01898.x", "10.1145/2702123.2702237", "10.1109/tvcg.2019.2934798", "10.1109/mcg.2017.21", "10.1109/tvcg.2019.2934300", "10.1109/tvcg.2017.2745085", "10.1109/tvcg.2018.2859997", "10.1145/3173574.3174237", "10.1109/tvcg.2018.2865126", "10.1145/1718487.1718520", "10.1109/tvcg.2017.2743858", "10.1109/pacificvis.2015.7156392", "10.1109/tvcg.2018.2864477", "10.1145/324133.324140", "10.1137/140976649", "10.1145/3219819.3220088", "10.1109/tvcg.2019.2934805", "10.1145/1134271.1134277", "10.1137/090772745", "10.1016/j.jelectrocard.2010.09.003", "10.1109/tvcg.2012.253", "10.1145/2556612", "10.1109/tvcg.2013.173", "10.1109/tvcg.2019.2934619", "10.1109/tvcg.2017.2745078"], "wos": 1, "children": [], "len": 1}], "len": 3}, {"doi": "10.1109/tvcg.2019.2934796", "title": "Improving the Robustness of Scagnostics", "year": "2019", "conferenceName": "InfoVis", "authors": "Yunhai Wang;Zeyu Wang 0005;Tingting Liu;Michael Correll;Zhanglin Cheng;Oliver Deussen;Michael Sedlmair", "citationCount": "1", "affiliation": "Wang, YH (Corresponding Author), Shandong Univ, Jinan, Peoples R China. Wang, Yunhai; Wang, Zeyu; Liu, Tingting, Shandong Univ, Jinan, Peoples R China. Wang, Zeyu; Cheng, Zhanglin; Deussen, Oliver, SIAT, Shenzhen VisuCA Key Lab, Shenzhen, Peoples R China. Correll, Michael, Tableau Res, Seattle, WA USA. Deussen, Oliver, Konstanz Univ, Constance, Germany. Sedlmair, Michael, Univ Stuttgart, VISUS, Stuttgart, Germany.", "countries": "USA;Germany;China", "abstract": "In this paper, we examine the robustness of scagnostics through a series of theoretical and empirical studies. First, we investigate the sensitivity of scagnostics by employing perturbing operations on more than 60M synthetic and real-world scatterplots. We found that two scagnostic measures, Outlying and Clumpy, are overly sensitive to data binning. To understand how these measures align with human judgments of visual features, we conducted a study with 24 participants, which reveals that i) humans are not sensitive to small perturbations of the data that cause large changes in both measures, and ii) the perception of clumpiness heavily depends on per-cluster topologies and structures. Motivated by these results, we propose Robust Scagnostics (RScag) by combining adaptive binning with a hierarchy-based form of scagnostics. An analysis shows that RScag improves on the robustness of original scagnostics, aligns better with human judgments, and is equally fast as the traditional scagnostic measures.", "keywords": "Scagnostics,scatterplots,sensitivity analysis,Robust Scagnostics", "link": "http://dx.doi.org/10.1109/TVCG.2019.2934796", "refList": ["10.1057/palgrave.ivs.9500122", "10.1109/tvcg.2014.2346979", "10.1111/j.1467-8659.2009.01467.x", "10.1109/vast.2008.4677368", "10.2307/2289444", "10.1109/tvcg.2011.229", "10.1109/iv.2004.1320207", "10.1109/vast.2009.5332628", "10.1111/insr.12095\\_11", "10.1109/tvcg.2010.184", "10.1109/tvcg.2015.2467323", "10.1109/vast.2010.5652460", "10.1111/j.1467-8659.2012.03069.x", "10.1145/1842993.1843002", "10.1198/106186008x320465", "10.1109/pacificvis.2016.7465244", "10.1109/tvcg.2013.20", "10.1111/cgf.12641", "10.1109/tvcg.2012.128", "10.1109/tvcg.2015.2467671", "10.1057/palgrave.ivs.9500091", "10.1007/978-1-4612-4400-4", "10.1111/cgf.13176", "10.1002/0470870958", "10.1109/tvcg.2018.2864907", "10.1111/j.1467-8659.2012.03125.x", "10.1109/vast.2012.6400490", "10.1109/infvis.2005.1532142", "10.1109/vast.2010.5652433", "10.1109/vast.2009.5332611", "10.1201/9781315140919", "10.1145/2858036.2858155", "10.1109/ldav.2013.6675164", "10.1515/itit-2014-1070", "10.1111/cgf.13684", "10.1109/tpami.1979.4766909", "10.2307/2289936", "10.1109/pacificvis.2014.42", "10.1109/tvcg.2016.2598467", "10.1109/tvcg.2013.153", "10.1111/cgf.13446", "10.1109/tvcg.2006.94", "10.1109/tvcg.2014.2346572", "10.1111/cgf.12632", "10.1109/tvcg.2017.2744339"], "wos": 1, "children": [], "len": 1}, {"doi": "10.1109/vast47406.2019.8986917", "title": "VIANA: Visual Interactive Annotation of Argumentation", "year": "2019", "conferenceName": "VAST", "authors": "Fabian Sperrle;Rita Sevastjanova;Rebecca Kehlbeck;Mennatallah El-Assady", "citationCount": "0", "affiliation": "Sperrle, F (Corresponding Author), Univ Konstanz, Constance, Germany. Sperrle, Fabian; Sevastjanova, Rita; Kehlbeck, Rebecca; El-Assady, Mennatallah, Univ Konstanz, Constance, Germany.", "countries": "Germany", "abstract": "Argumentation Mining addresses the challenging tasks of identifying boundaries of argumentative text fragments and extracting their relationships. Fully automated solutions do not reach satisfactory accuracy due to their insufficient incorporation of semantics and domain knowledge. Therefore, experts currently rely on time-consuming manual annotations. In this paper, we present a visual analytics system that augments the manual annotation process by automatically suggesting which text fragments to annotate next. The accuracy of those suggestions is improved over time by incorporating linguistic knowledge and language modeling to learn a measure of argument similarity from user interactions. Based on a long-term collaboration with domain experts, we identify and model five high-level analysis tasks. We enable close reading and note-taking, annotation of arguments, argument reconstruction, extraction of argument relations, and exploration of argument graphs. To avoid context switches, we transition between all views through seamless morphing, visually anchoring all text- and graph-based layers. We evaluate our system with a two-stage expert user study based on a corpus of presidential debates. The results show that experts prefer our system over existing solutions due to the speedup provided by the automatic suggestions and the tight integration between text and graph views.", "keywords": "Argumentation annotation,machine learning,user interaction,layered interfaces,semantic transitions", "link": "http://dx.doi.org/10.1109/VAST47406.2019.8986917", "refList": ["10.1007/978-3-642-40624-9\\_1", "10.3233/978-1-61499-436-7-185", "10.1145/371920.372071", "10.3233/978-1-61499-906-5-4", "10.1109/tvcg.2015.2467759", "10.18653/v1/d15-1050", "10.2307/2529310", "10.1109/mic.2003.1167344", "10.1145/312624.312682", "10.1145/2850417", "10.18653/v1/p17-2039", "10.1016/j.eswa.2016.02.013", "10.1007/978-0-387-85820-3\\_3", "10.1007/s11412-009-9080-x", "10.1109/tvcg.2008.127", "10.1145/2207676.2207741", "10.1109/cit.2012.217", "10.3233/aac-170022", "10.1109/tvcg.2017.2745080", "10.1007/978-3-319-44039-2\\_6", "10.1145/3290605.3300233", "10.1007/978-94-017-0431-1", "10.3233/978-1-61499-906-5-313", "10.1142/s0218213004001922", "10.1109/tvcg.2012.262", "10.1177/001316446002000104", "10.1109/tvcg.2018.2834341", "10.3233/978-1-61499-436-7-463", "10.1145/1772690.1772773", "10.1109/tvcg.2014.2346677", "10.1145/2523813", "10.1162/153244303322533223", "10.1109/tvcg.2007.70539", "10.1109/tvcg.2015.2467531", "10.1109/tvcg.2018.2864769", "10.1007/978-3-319-90092-6\\_14", "10.1137/1.9781611972801.19", "10.1109/vast.2012.6400485", "10.1007/s10579-013-9215-6", "10.3115/v1/d14-1162", "10.1111/cgf.13446", "10.1109/tvcg.2006.156", "10.1111/cgf.13092", "10.1145/2645710.2645759", "10.1109/bigdata.2017.8258140", "10.1145/2669557.2669572", "10.2312/eurovisstar.20151113"], "wos": 1, "children": [], "len": 1}, {"doi": "10.1109/tvcg.2020.3030376", "title": "Insight Beyond Numbers: The Impact of Qualitative Factors on Visual Data Analysis", "year": "2020", "conferenceName": "VAST", "authors": "Benjamin Karer;Hans Hagen;Dirk J. Lehmann", "citationCount": "0", "affiliation": "Karer, B (Corresponding Author), Fed Criminal Police Off Germany, Wiesbaden, Germany. Karer, Benjamin, Fed Criminal Police Off Germany, Wiesbaden, Germany. Hagen, Hans, TU Kaiserslautern, Kaiserslautern, Germany. Lehmann, Dirk J., Ostfalia Univ Appl Sci, Wolfenbuttel, Germany. Lehmann, Dirk J., IAV GmbH, Berlin, Germany.", "countries": "Germany", "abstract": "As of today, data analysis focuses primarily on the findings to be made inside the data and concentrates less on how those findings relate to the domain of investigation. Contemporary visualization as a field of research shows a strong tendency to adopt this data-centrism. Despite their decisive influence on the analysis result, qualitative aspects of the analysis process such as the structure, soundness, and complexity of the applied reasoning strategy are rarely discussed explicitly. We argue that if the purpose of visualization is the provision of domain insight rather than the depiction of data analysis results, a holistic perspective requires a qualitative component to to be added to the discussion of quantitative and human factors. To support this point, we demonstrate how considerations of qualitative factors in visual analysis can be applied to obtain explanations and possible solutions for a number of practical limitations inherent to the data-centric perspective on analysis. Based on this discussion of what we call qualitative visual analysis, we develop an inside-outside principle of nested levels of context that can serve as a conceptual basis for the development of visualization systems that optimally support the emergence of insight during analysis.", "keywords": "Visualization,Reasoning,Qualitative Aspects", "link": "http://dx.doi.org/10.1109/TVCG.2020.3030376", "refList": ["10.1057/ivs.2009.22", "10.1109/tvcg.2015.2467732", "10.1109/infvis.2000.885092", "10.1109/vast.2014.7042482", "10.1145/1498700.1498704", "10.1109/tvcg.2009.108", "10.1109/tvcg.2018.2829750", "10.1037/0033-295x.111.4.1036", "10.1109/tvcg.2012.199", "10.1109/38.267476", "10.1007/978-3-540-70956-5\\_2", "10.1109/tvcg.2015.2467613", "10.1109/tvcg.2015.2467195", "10.1109/tvcg.2014.2346419", "10.1109/vast.2017.8585669", "10.1109/tvcg.2010.132", "10.1145/22949.22950", "10.1109/tvcg.2014.2346984", "10.1017/cbo9780511816772", "10.1109/mcg.2003.1231171", "10.1111/coin.12227", "10.1109/tvcg.2018.2865138", "10.1109/38.788803", "10.1109/tvcg.2018.2864849", "10.1109/mcg.2012.120", "10.1109/tvcg.2007.70535", "10.1162/neco.2008.12-06-420", "10.1109/tvcg.2018.2865240", "10.1089/tmj.2010.0114", "10.1109/beliv.2018.8634267", "10.1109/tvcg.2014.2346481", "10.1207/s15327809jls0402\\_2", "10.1109/tvcg.2006.80", "10.1145/2858036.2858280", "10.1109/tvcg.2017.2674978", "10.1109/tvcg.2011.52", "10.1016/j.cag.2014.03.002", "10.1109/tvcg.2015.2513410", "10.1111/j.1756-8765.2011.01150.x", "10.1109/infvis.2005.1532142", "10.1002/spe.4380211102", "10.1186/s41235-018-0120-9", "10.1073/pnas.1807180116", "10.1109/tvcg.2012.133", "10.1109/tvcg.2012.273", "10.1111/j.1467-8659.2011.01928.x", "10.1145/353485.353486", "10.1109/tvcg.2015.2462356", "10.1109/mcg.2019.2923483", "10.1111/cgf.13264", "10.1057/palgrave.ivs.9500070", "10.1145/1168149.1168158", "10.1109/mcg.2019.2961716", "10.1016/s0167-739x(96)00029-5", "10.1111/j.1467-8659.2009.01667.x", "10.1177/1473871611415989", "10.1109/tvcg.2013.234", "10.1109/iv.2012.33", "10.1111/cgf.13446", "10.1057/ivs.2008.28", "10.1111/cgf.12379", "10.1037/0033-295x.112.1.159", "10.1109/tvcg.2010.161", "10.1109/tvcg.2017.2744319", "10.1145/989863.989880", "10.1007/s11390-016-1663-1", "10.1177/1473871615609787", "10.1016/j.cola.2019.100911"], "wos": 1, "children": [], "len": 1}, {"doi": "10.1109/tvcg.2020.3030395", "title": "Towards Modeling Visualization Processes as Dynamic Bayesian Networks", "year": "2020", "conferenceName": "InfoVis", "authors": "Christian Heine 0002", "citationCount": "0", "affiliation": "Heine, C (Corresponding Author), Univ Leipzig, Leipzig, Germany. Heine, Christian, Univ Leipzig, Leipzig, Germany.", "countries": "Germany", "abstract": "Visualization designs typically need to be evaluated with user studies, because their suitability for a particular task is hard to predict. What the field of visualization is currently lacking are theories and models that can be used to explain why certain designs work and others do not. This paper outlines a general framework for modeling visualization processes that can serve as the first step towards such a theory. It surveys related research in mathematical and computational psychology and argues for the use of dynamic Bayesian networks to describe these time-dependent, probabilistic processes. It is discussed how these models could be used to aid in design evaluation. The development of concrete models will be a long process. Thus, the paper outlines a research program sketching how to develop prototypes and their extensions from existing models, controlled experiments, and observational studies.", "keywords": "Visualization,model building,perception,cognition,dynamic Bayesian networks", "link": "http://dx.doi.org/10.1109/TVCG.2020.3030395", "refList": ["10.1057/ivs.2009.22", "10.1109/tvcg.2015.2467732", "10.1109/infvis.2000.885092", "10.1109/vast.2014.7042482", "10.1145/1498700.1498704", "10.1109/tvcg.2009.108", "10.1109/tvcg.2018.2829750", "10.1037/0033-295x.111.4.1036", "10.1109/tvcg.2012.199", "10.1111/cgf.13899", "10.1109/38.267476", "10.1007/978-3-540-70956-5\\_2", "10.1109/tvcg.2015.2467613", "10.1109/tvcg.2015.2467195", "10.1109/tvcg.2014.2346419", "10.1145/3290605.3300562", "10.1109/vl.1996.545307", "10.1109/vast.2017.8585669", "10.1109/infvis.2003.1249004", "10.1109/tvcg.2010.132", "10.1145/22949.22950", "10.1109/tvcg.2014.2346984", "10.1145/3290605.3300418", "10.1017/cbo9780511816772", "10.1109/mcg.2003.1231171", "10.1111/coin.12227", "10.1109/tvcg.2018.2865138", "10.1109/38.788803", "10.1109/tvcg.2018.2864849", "10.1109/mcg.2012.120", "10.1109/tvcg.2007.70535", "10.1162/neco.2008.12-06-420", "10.1109/tvcg.2018.2865240", "10.1089/tmj.2010.0114", "10.1109/beliv.2018.8634267", "10.1109/tvcg.2014.2346481", "10.1207/s15327809jls0402\\_2", "10.1109/tvcg.2006.80", "10.1145/2858036.2858280", "10.1109/tvcg.2017.2674978", "10.1109/tvcg.2011.52", "10.1016/j.cag.2014.03.002", "10.1109/tvcg.2015.2513410", "10.1111/j.1756-8765.2011.01150.x", "10.1109/infvis.2005.1532142", "10.1002/spe.4380211102", "10.1186/s41235-018-0120-9", "10.1073/pnas.1807180116", "10.1109/tvcg.2012.133", "10.1109/tvcg.2012.273", "10.1111/j.1467-8659.2011.01928.x", "10.1145/353485.353486", "10.1109/tvcg.2015.2462356", "10.1109/mcg.2019.2923483", "10.1111/cgf.13264", "10.1057/palgrave.ivs.9500070", "10.1145/1168149.1168158", "10.1109/mcg.2019.2961716", "10.1016/s0167-739x(96)00029-5", "10.1111/j.1467-8659.2009.01667.x", "10.1177/1473871611415989", "10.1109/tvcg.2013.234", "10.1109/iv.2012.33", "10.1111/cgf.13446", "10.1057/ivs.2008.28", "10.1111/cgf.12379", "10.1037/0033-295x.112.1.159", "10.1017/cb09781139033916.005", "10.1109/tvcg.2010.161", "10.1109/tvcg.2017.2744319", "10.1145/989863.989880", "10.1007/s11390-016-1663-1", "10.1177/1473871615609787", "10.1016/j.cola.2019.100911", "10.1057/palgrave.ivs.9500025"], "wos": 1, "children": [], "len": 1}, {"doi": "10.1109/pacificvis48177.2020.8199", "year": "2020", "title": "Efficient Morphing of Shape-preserving Star Coordinates", "conferenceName": "PacificVis", "authors": "Vladimir Molchanov;Sagad Hamid;Lars Linsen", "citationCount": "0", "affiliation": "Molchanov, V (Corresponding Author), Westfalische Wilhelms Univ Munster, Munster, Germany.\nMolchanov, Vladimir; Hamid, Sagad; Linsen, Lars, Westfalische Wilhelms Univ Munster, Munster, Germany.", "countries": "Germany", "abstract": "Data tours follow an exploratory multi-dimensional data visualization concept that provides animations of projections of the multidimensional data to a 2D visual space. To create an animation, a sequence of key projections is provided and morphings between each pair of consecutive key projections are computed, which then can be stitched together to form the data tour. The morphings should be smooth so that a user can easily follow the transformations, and their computations shall be fast to allow for their integration into an interactive visual exploration process. Moreover, if the key projections are chosen to satisfy additional conditions, it is desirable that these conditions are maintained during morphing. Shape preservation is such a desirable condition, as it avoids shape distortions that may otherwise be caused by a projection. We develop a novel efficient morphing algorithms for computing shape-preserving data tours, i.e., data tours constructed for a sequence of shape-preserving linear projections. We propose a stepping strategy for the morphing to avoid discontinuities in the evolution of the projections, where we represent the linear projections using a star-coordinates system. Our algorithms are less computationally involved, produce smoother morphings, and require less user-defined parameter settings than existing state-of-the-art approaches.", "keywords": "Human-centered computing; Visualization; Visualization techniques", "link": "https://doi.org/10.1109/PacificVis48177.2020.8199", "refList": ["10.2312/eurovisshort.20141152", "10.1109/tvcg.2013.182", "10.1109/tvcg.2008.153", "10.1109/tvcg.2015.2467591", "10.4135/9781412985130", "10.1111/cgf.12878", "10.1016/j.cag.2016.08.007", "10.1080/10618600.1995.10474674", "10.1109/infvis.2003.1249004", "10.1002/9781118445112.stat06472", "10.1109/visual.1997.663916", "10.1111/cgf.12117", "10.1137/0906011", "10.1109/tvcg.2018.2865118", "10.1126/science.290.5500.2319", "10.1111/cgf.12845", "10.1111/j.1467-8659.2012.03125.x", "10.1109/tvcg.2017.2705189", "10.1002/0471725293", "10.1111/cgf.12876", "10.1111/cgf.13404", "10.2307/2289161", "10.1111/cgf.13446", "10.1198/106186008x318440", "10.2307/1390747", "10.1109/tvcg.2012.35", "10.1109/tvcg.2015.2467132", "10.1109/tvcg.2006.94", "10.1109/t-c.1974.224051", "10.1109/pacificvis.2019.00018", "10.1109/tvcg.2017.2744339", "10.1109/tsmcb.2005.850151"], "wos": 1, "children": [], "len": 1}, {"doi": "10.1109/pacificvis.2019.00018", "year": "2019", "title": "Scatterplot Summarization by Constructing Fast and Robust Principal Graphs from Skeletons", "conferenceName": "PacificVis", "authors": "Jos{\\'{e}} Matute;Marcel Fischer;Alexandru C. Telea;Lars Linsen", "citationCount": "1", "affiliation": "Matute, J (Corresponding Author), Univ Munster, Munster, Germany.\nMatute, Jose; Fischer, Marcel; Linsen, Lars, Univ Munster, Munster, Germany.\nTelea, Alexandru C., Univ Groningen, Groningen, Netherlands.", "countries": "Germany;Netherlands", "abstract": "Principal curves are a long-standing and well-known method for summarizing large scatterplots. They are defined as self-consistent curves (or curve sets in the more general case) that locally pass through the middle of the scatterplot data. However, computing principal curves that capture well complex scatterplot topologies and are robust to noise is hard and/or slow for large scatterplots. We present a fast and robust approach for computing principal graphs (a generalization of principal curves for more complex topologies) inspired by the similarity to medial descriptors (curves locally centered in a shape). Compared to state-of-the-art methods for computing principal graphs, we outperform these in terms of computational scalability and robustness to noise and resolution. We also demonstrate the advantages of our method over other scatterplot summarization approaches.", "keywords": "", "link": "https://doi.org/10.1109/PacificVis.2019.00018", "refList": ["10.1016/j.cag.2014.01.006", "10.1016/s0167-8655(02)00032-6", "10.1006/jmva.2000.1917", "10.1111/cgf.12386", "10.1109/vast.2008.4677367", "10.1109/tpami.2004.1261076", "10.1111/cgf.12865", "10.1109/tvcg.2010.213", "10.1109/tvcg.2014.2346455", "10.1109/tvcg.2011.233", "10.1111/j.1467-8659.2009.01680.x", "10.1109/tvcg.2016.2515611", "10.1109/tit.1982.1056489", "10.1109/34.899944", "10.1007/bf01889678", "10.1137/s0036144599352836", "10.1145/2858036.2858155", "10.1002/jhbs.20078", "10.1198/jcgs.2011.09224", "10.1109/tvcg.2017.2744184", "10.1057/ivs.2010.2", "10.1111/j.1467-8659.2012.03107.x", "10.2307/2289936", "10.1109/pacificvis.2014.42", "10.1109/tpami.2008.21", "10.1111/cgf.13446", "10.2307/2290446", "10.1109/34.982884", "10.1109/tvcg.2006.94", "10.2307/2288711", "10.1117/12.304651", "10.5201/ipol.2013.87", "10.1109/mlsp.2008.4685520"], "wos": 1, "children": [{"doi": "10.1109/pacificvis48177.2020.8199", "year": "2020", "title": "Efficient Morphing of Shape-preserving Star Coordinates", "conferenceName": "PacificVis", "authors": "Vladimir Molchanov;Sagad Hamid;Lars Linsen", "citationCount": "0", "affiliation": "Molchanov, V (Corresponding Author), Westfalische Wilhelms Univ Munster, Munster, Germany.\nMolchanov, Vladimir; Hamid, Sagad; Linsen, Lars, Westfalische Wilhelms Univ Munster, Munster, Germany.", "countries": "Germany", "abstract": "Data tours follow an exploratory multi-dimensional data visualization concept that provides animations of projections of the multidimensional data to a 2D visual space. To create an animation, a sequence of key projections is provided and morphings between each pair of consecutive key projections are computed, which then can be stitched together to form the data tour. The morphings should be smooth so that a user can easily follow the transformations, and their computations shall be fast to allow for their integration into an interactive visual exploration process. Moreover, if the key projections are chosen to satisfy additional conditions, it is desirable that these conditions are maintained during morphing. Shape preservation is such a desirable condition, as it avoids shape distortions that may otherwise be caused by a projection. We develop a novel efficient morphing algorithms for computing shape-preserving data tours, i.e., data tours constructed for a sequence of shape-preserving linear projections. We propose a stepping strategy for the morphing to avoid discontinuities in the evolution of the projections, where we represent the linear projections using a star-coordinates system. Our algorithms are less computationally involved, produce smoother morphings, and require less user-defined parameter settings than existing state-of-the-art approaches.", "keywords": "Human-centered computing; Visualization; Visualization techniques", "link": "https://doi.org/10.1109/PacificVis48177.2020.8199", "refList": ["10.2312/eurovisshort.20141152", "10.1109/tvcg.2013.182", "10.1109/tvcg.2008.153", "10.1109/tvcg.2015.2467591", "10.4135/9781412985130", "10.1111/cgf.12878", "10.1016/j.cag.2016.08.007", "10.1080/10618600.1995.10474674", "10.1109/infvis.2003.1249004", "10.1002/9781118445112.stat06472", "10.1109/visual.1997.663916", "10.1111/cgf.12117", "10.1137/0906011", "10.1109/tvcg.2018.2865118", "10.1126/science.290.5500.2319", "10.1111/cgf.12845", "10.1111/j.1467-8659.2012.03125.x", "10.1109/tvcg.2017.2705189", "10.1002/0471725293", "10.1111/cgf.12876", "10.1111/cgf.13404", "10.2307/2289161", "10.1111/cgf.13446", "10.1198/106186008x318440", "10.2307/1390747", "10.1109/tvcg.2012.35", "10.1109/tvcg.2015.2467132", "10.1109/tvcg.2006.94", "10.1109/t-c.1974.224051", "10.1109/pacificvis.2019.00018", "10.1109/tvcg.2017.2744339", "10.1109/tsmcb.2005.850151"], "wos": 1, "children": [], "len": 1}], "len": 3}, {"doi": "10.1111/cgf.13684", "year": "2019", "title": "ClustMe: A Visual Quality Measure for Ranking Monochrome Scatterplots based on Cluster Patterns", "conferenceName": "EuroVis", "authors": "Mostafa M. Abbas;Micha{\\\"{e}}l Aupetit;Michael Sedlmair;Halima Bensmail", "citationCount": "4", "affiliation": "Abbas, MM (Corresponding Author), HBKU, QCRI, Doha, Qatar.\nAbbas, Mostafa M.; Aupetit, Michael; Bensmail, Halima, HBKU, QCRI, Doha, Qatar.\nSedlmair, Michael, Univ Stuttgart, VISUS, Stuttgart, Germany.", "countries": "Qatar;Germany", "abstract": "We propose ClustMe, a new visual quality measure to rank monochrome scatterplots based on cluster patterns. ClustMe is based on data collected from a human-subjects study, in which 34 participants judged synthetically generated cluster patterns in 1000 scatterplots. We generated these patterns by carefully varying the free parameters of a simple Gaussian Mixture Model with two components, and asked the participants to count the number of clusters they could see (1 or more than 1). Based on the results, we form ClustMe by selecting the model that best predicts these human judgments among 7 different state-of-the-art merging techniques (Demp). To quantitatively evaluate ClustMe, we conducted a second study, in which 31 human subjects ranked 435 pairs of scatterplots of real and synthetic data in terms of cluster patterns complexity. We use this data to compare ClustMe's performance to 4 other state-of-the-art clustering measures, including the well-known Clumpiness scagnostics. We found that of all measures, ClustMe is in strongest agreement with the human rankings.", "keywords": "", "link": "https://doi.org/10.1111/cgf.13684", "refList": ["10.1109/tvcg.2014.2330617", "10.1109/tvcg.2014.2346979", "10.1109/tvcg.2017.2744138", "10.1109/tvcg.2017.2701829", "10.2307/2529310", "10.1109/tvcg.2011.229", "10.1109/vast.2011.6102437", "10.1068/p030033", "10.1016/j.jvcir.2011.01.005", "10.1109/tnn.2005.845141", "10.1145/2669557.2669559", "10.1167/8.7.6", "10.1145/2993901.2993907", "10.1145/2803140.2803143", "10.1145/1842993.1843002", "10.1109/pacificvis.2016.7465244", "10.1109/tvcg.2013.124", "10.1057/ivs.2008.13", "10.1109/vast.2012.6400488", "10.1111/j.1467-9574.2008.00412.x", "10.1214/aos/1176344136", "10.1109/tvcg.2015.2467671", "10.3138/y308-2422-8615-1233", "10.1111/j.1467-8659.2012.03125.x", "10.1177/001316446002000104", "10.1145/2858036.2858155", "10.1007/s11634-010-0058-3", "10.1214/009053605000000417", "10.1109/tvcg.2009.153", "10.1023/a:1018510926151", "10.1109/tvcg.2014.2346978", "10.1007/s10816-016-9307-x", "10.1177/0301006615602599", "10.1109/pacificvis.2014.42", "10.1162/neco.1991.3.2.246", "10.1007/3-540-44491-2\\_3", "10.1109/tvcg.2013.153", "10.1111/cgf.13446", "10.1109/tvcg.2018.2846735", "10.2307/2291604", "10.1109/inf0vis.2005.14", "10.1198/016214502760047131", "10.1007/s00180-008-0119-7", "10.1109/t-c.1974.224051", "10.1111/cgf.12632", "10.1109/tvcg.2017.2744339", "10.1111/j.1467-8659.2009.01694.x"], "wos": 1, "children": [{"doi": "10.1109/tvcg.2019.2934796", "title": "Improving the Robustness of Scagnostics", "year": "2019", "conferenceName": "InfoVis", "authors": "Yunhai Wang;Zeyu Wang 0005;Tingting Liu;Michael Correll;Zhanglin Cheng;Oliver Deussen;Michael Sedlmair", "citationCount": "1", "affiliation": "Wang, YH (Corresponding Author), Shandong Univ, Jinan, Peoples R China. Wang, Yunhai; Wang, Zeyu; Liu, Tingting, Shandong Univ, Jinan, Peoples R China. Wang, Zeyu; Cheng, Zhanglin; Deussen, Oliver, SIAT, Shenzhen VisuCA Key Lab, Shenzhen, Peoples R China. Correll, Michael, Tableau Res, Seattle, WA USA. Deussen, Oliver, Konstanz Univ, Constance, Germany. Sedlmair, Michael, Univ Stuttgart, VISUS, Stuttgart, Germany.", "countries": "USA;Germany;China", "abstract": "In this paper, we examine the robustness of scagnostics through a series of theoretical and empirical studies. First, we investigate the sensitivity of scagnostics by employing perturbing operations on more than 60M synthetic and real-world scatterplots. We found that two scagnostic measures, Outlying and Clumpy, are overly sensitive to data binning. To understand how these measures align with human judgments of visual features, we conducted a study with 24 participants, which reveals that i) humans are not sensitive to small perturbations of the data that cause large changes in both measures, and ii) the perception of clumpiness heavily depends on per-cluster topologies and structures. Motivated by these results, we propose Robust Scagnostics (RScag) by combining adaptive binning with a hierarchy-based form of scagnostics. An analysis shows that RScag improves on the robustness of original scagnostics, aligns better with human judgments, and is equally fast as the traditional scagnostic measures.", "keywords": "Scagnostics,scatterplots,sensitivity analysis,Robust Scagnostics", "link": "http://dx.doi.org/10.1109/TVCG.2019.2934796", "refList": ["10.1057/palgrave.ivs.9500122", "10.1109/tvcg.2014.2346979", "10.1111/j.1467-8659.2009.01467.x", "10.1109/vast.2008.4677368", "10.2307/2289444", "10.1109/tvcg.2011.229", "10.1109/iv.2004.1320207", "10.1109/vast.2009.5332628", "10.1111/insr.12095\\_11", "10.1109/tvcg.2010.184", "10.1109/tvcg.2015.2467323", "10.1109/vast.2010.5652460", "10.1111/j.1467-8659.2012.03069.x", "10.1145/1842993.1843002", "10.1198/106186008x320465", "10.1109/pacificvis.2016.7465244", "10.1109/tvcg.2013.20", "10.1111/cgf.12641", "10.1109/tvcg.2012.128", "10.1109/tvcg.2015.2467671", "10.1057/palgrave.ivs.9500091", "10.1007/978-1-4612-4400-4", "10.1111/cgf.13176", "10.1002/0470870958", "10.1109/tvcg.2018.2864907", "10.1111/j.1467-8659.2012.03125.x", "10.1109/vast.2012.6400490", "10.1109/infvis.2005.1532142", "10.1109/vast.2010.5652433", "10.1109/vast.2009.5332611", "10.1201/9781315140919", "10.1145/2858036.2858155", "10.1109/ldav.2013.6675164", "10.1515/itit-2014-1070", "10.1111/cgf.13684", "10.1109/tpami.1979.4766909", "10.2307/2289936", "10.1109/pacificvis.2014.42", "10.1109/tvcg.2016.2598467", "10.1109/tvcg.2013.153", "10.1111/cgf.13446", "10.1109/tvcg.2006.94", "10.1109/tvcg.2014.2346572", "10.1111/cgf.12632", "10.1109/tvcg.2017.2744339"], "wos": 1, "children": [], "len": 1}, {"doi": "10.1109/tvcg.2020.3030365", "title": "Modeling the Influence of Visual Density on Cluster Perception in Scatterplots Using Topology", "year": "2020", "conferenceName": "InfoVis", "authors": "Ghulam Jilani Quadri;Paul Rosen", "citationCount": "0", "affiliation": "Quadri, GJ (Corresponding Author), Univ S Florida, Tampa, FL 33620 USA. Quadri, Ghulam Jilani; Rosen, Paul, Univ S Florida, Tampa, FL 33620 USA.", "countries": "USA", "abstract": "Scatterplots are used for a variety of visual analytics tasks, including cluster identification, and the visual encodings used on a scatterplot play a deciding role on the level of visual separation of clusters. For visualization designers, optimizing the visual encodings is crucial to maximizing the clarity of data. This requires accurately modeling human perception of cluster separation, which remains challenging. We present a multi-stage user study focusing on four factors-distribution size of clusters, number of points, size of points, and opacity of points-that influence cluster identification in scatterplots. From these parameters, we have constructed two models, a distance-based model, and a density-based model, using the merge tree data structure from Topological Data Analysis. Our analysis demonstrates that these factors play an important role in the number of clusters perceived, and it verifies that the distance-based and density-based models can reasonably estimate the number of clusters a user observes. Finally, we demonstrate how these models can be used to optimize visual encodings on real-world data.", "keywords": "Scatterplot,clustering,perception,empirical evaluation,visual encoding,crowdsourcing,topological data analysis", "link": "http://dx.doi.org/10.1109/TVCG.2020.3030365", "refList": ["10.1109/tvcg.2017.2744359", "10.1145/1778765", "10.1109/tvcg.2019.2934799", "10.1111/cgf.12889", "10.1109/tvcg.2011.127", "10.1111/cgf.13444", "10.1145/1964897.1964910", "10.1167/8.7.6", "10.1145/3173574.3173991", "10.1145/1556262.1556289", "10.1145/1056808.1056914", "10.2307/2288400", "10.1109/tvcg.2014.2346594", "10.1109/iv.2002.1028760", "10.1177/001316447303300111", "10.1007/bf02289823", "10.1109/tvcg.2017.2744339", "10.1111/j.1467-8659.2009.01694.x", "10.1109/tvcg.2014.2346979", "10.1090/mbk/069", "10.1109/tvcg.2013.65", "10.1109/mcg.2012.37", "10.1109/pacificvis.2010.5429604", "10.1002/acp.2350050106", "10.1109/infvis.2005.1532136", "10.1177/1473871612465214", "10.1109/tvcg.2017.2674978", "10.1002/jhbs.20078", "10.1007/978-3-642-35142-6\\_14", "10.1007/978-3-319-71507-0", "10.1109/mcg.201.7.6", "10.3758/bf03193961", "10.1364/josa.49.000280", "10.1145/3025453.3025905", "10.1109/tvcg.201.9.2934541", "10.1109/tvcg.2018.2829750", "10.1177/1473871615606187", "10.1111/cgf.13408", "10.1109/pacificvis.2016.7465252", "10.1109/pacificvis.2016.7465244", "10.1109/inevis.2005.1532142", "10.1111/cgf.13414", "10.1111/j.1467-8659.2012.03125.x", "10.1167/16.5.11", "10.1109/infvis.2005.1532142", "10.1145/2858036.2858155", "10.1038/nmeth1210-941", "10.1177/1473871616638892", "10.1109/tcbb.2014.2306840", "10.1111/cgf.13684", "10.1177/0301006615602599", "10.1214/aoms/1177731915", "10.1145/2702123.2702585", "10.1109/tvcg.2013.183", "10.1109/tvcg.2014.2346572", "10.1109/tvcg.2018.2875702", "10.1109/tvcg.2017.2754480", "10.1109/vast.2014.7042493", "10.1057/palgrave.ivs.9500122", "10.1109/tvcg.2014.2330617", "10.1109/tvcg.2019.2934541", "10.1068/p030033", "10.1140/epjds/s13688-017-0109-5", "10.1201/b17511", "10.1016/s0925-7721(02)00093-7", "10.1109/pacificvis.2012.6183557", "10.1109/tvcg.2014.2346983", "10.1109/5.726791", "10.1080/01621459.1926.10502165", "10.1109/tvcg.2007.70535", "10.1109/tvcg.2018.2864907", "10.1111/cgf.12109", "10.1109/tvcg.2017.2744184", "10.1146/annurev-statistics-031017-100045", "10.1111/cgf.13409", "10.1145/3002151.3002162", "10.1016/s0378-4371(98)00494-4", "10.3138/y308-2422-8615-1233", "10.1111/cgf.12632", "10.1145/3290605.3300771"], "wos": 1, "children": [], "len": 1}, {"doi": "10.1111/cgf.14034", "year": "2020", "title": "The State of the Art in Enhancing Trust in Machine Learning Models with the Use of Visualizations", "conferenceName": "EuroVis", "authors": "Angelos Chatzimparmpas;Rafael Messias Martins;Ilir Jusufi;Kostiantyn Kucher;Fabrice Rossi;Andreas Kerren", "citationCount": "2", "affiliation": "Chatzimparmpas, A (Corresponding Author), Linnaeus Univ, Dept Comp Sci \\& Media Technol, Vaxjo, Sweden.\nChatzimparmpas, A.; Martins, R. M.; Jusufi, I.; Kucher, K.; Kerren, A., Linnaeus Univ, Dept Comp Sci \\& Media Technol, Vaxjo, Sweden.\nRossi, F., PSL Univ, Univ Paris Dauphine, Ceremade, Paris, France.", "countries": "Sweden;France", "abstract": "Machine learning (ML) models are nowadays used in complex applications in various domains, such as medicine, bioinformatics, and other sciences. Due to their black box nature, however, it may sometimes be hard to understand and trust the results they provide. This has increased the demand for reliable visualization tools related to enhancing trust in ML models, which has become a prominent topic of research in the visualization community over the past decades. To provide an overview and present the frontiers of current research on the topic, we present a State-of-the-Art Report (STAR) on enhancing trust in ML models with the use of interactive visualization. We define and describe the background of the topic, introduce a categorization for visualization techniques that aim to accomplish this goal, and discuss insights and opportunities for future research directions. Among our contributions is a categorization of trust against different facets of interactive ML, expanded and improved from previous research. Our results are investigated from different analytical perspectives: (a) providing a statistical overview, (b) summarizing key findings, (c) performing topic analyses, and (d) exploring the data sets used in the individual papers, all with the support of an interactive web-based survey browser. We intend this survey to be beneficial for visualization researchers whose interests involve making ML models more trustworthy, as well as researchers and practitioners from other disciplines in their search for effective visualization techniques suitable for solving their tasks with confidence and conveying meaning to their data.", "keywords": "trustworthy machine learning; visualization; interpretable machine learning; explainable machine learning", "link": "https://doi.org/10.1111/cgf.14034", "refList": ["10.1109/mcg.2018.2878902", "10.1109/tvcg.2008.153", "10.2312/mlvis.20181130", "10.1109/tvcg.2016.2598828", "10.1145/3290605.3300911", "10.1145/2993901.2993909", "10.2312/mlvis.20191158", "10.1109/tvcg.2016.2598446", "10.1111/j.1467-8659.2009.01475.x", "10.1145/3290605.3300809", "10.1109/pacificvis.2018.00031", "10.1055/s-0029-1216348", "10.1007/978-3-319-90403-0\\_13", "10.1109/tvcg.2017.2745085", "10.1111/j.1467-8659.2011.01938.x", "10.1007/978-3-319-54024-5\\_6", "10.1016/s0167-9473(01)00065-2", "10.1111/cgf.12895", "10.2312/eurovisshort.20141152.17", "10.2312/eurova.20151098.22", "10.1111/cgf.13667", "10.3115/1072228.1072378", "10.1109/tbdata.2018.2877350.16", "10.1109/lars.2009.5418323.25", "10.1109/tvcg.2017.2744878", "10.1016/j.combustflame.2005.09.018", "10.1016/j.cag.2014.01.006", "10.1109/tvcg.2016.2570755", "10.2312/mlvis.20191158.1,19", "10.1518/hfes.46.1.50.30392", "10.1145/3301275.3302280", "10.1145/3351095.3372834.1", "10.1016/s0377-2217(01)00264-8", "10.1111/cgf.13424", "10.1007/978-3-319-23485-4\\_53", "10.1007/978-94-007-0753-5\\_3623", "10.1109/tvcg.2013.101", "10.1111/cgf.12884", "10.1111/j.1467-8659.2010.01835.x", "10.1021/ci9901338", "10.4230/lipics.itcs:2017", "10.1109/mis.2013.24", "10.1109/tvcg.2014.2346482", "10.1109/tvcg.2018.2865230", "10.1073/pnas.1807180116", "10.1109/dsaa.2018.00018", "10.1109/tvcg.2009.153", "10.3115/1219840.1219855", "10.1109/tvcg.2018.2864812", "10.1109/tvcg.2018.2872577", "10.2312/trvis.20191183", "10.1109/cvpr:2004.383", "10.1109/vast.2008.4677350", "10.1145/302979.303001", "10.1109/tvcg.2018.2864499", "10.1111/cgf.13672", "10.1109/tvcg.2014.2346626", "10.23915/distill.00010.18", "10.1109/tvcg.2017.2744805", "10.2312/mlvis:20191160.18", "10.23915/distill:00016", "10.1109/pacificvis.2016.7465260", "10.1111/cgf.13683", "10.23915/distill.00016.19", "10.1145/32906053.300803.22", "10.1109/tvcg.2014.2346574", "10.1177/1473871615600010", "10.1109/tvcg.2016.2598831", "10.1145/3230623", "10.1109/visual.2019.8933744", "10.1145/2993901.2993915", "10.1016/j.visinf.2017.01.006", "10.1145/2993901.2993914", "10.1109/tvcg.2014.2346984", "10.1109/5.726791", "10.23915/distill.00010", "10.1109/tvcg.2018.2864825", "10.2307/2394164", "10.1109/tvcg.2017.2744458", "10.1145/2993901.2993917.28", "10.1111/cgf.13711", "10.1109/tvcg.2016.2598664", "10.2307/2530428", "10.1109/icdar.1997.620583", "10.1109/tvcg.2017.2744718", "10.1111/cgf.13425", "10.1109/tvcg.2019.2903943", "10.1145/1518701.1518895", "10.1109/tvcg.2018.2864838", "10.1145/62038.62043", "10.1111/j.1467-8659.2011.01920.x", "10.1145/3025171.3025208", "10.1145/355112.355124", "10.1109/vast.2010.5652398", "10.1109/tvcg.2014.2346578", "10.1145/3173574.3174209", "10.4178/epih/e2014008", "10.1109/beliv.2018.8634201.25,28", "10.1016/j.eswa.2007.12.020", "10.1111/cgf:13406", "10.1109/mcg.2011.103", "10.1631/fitee.1700808", "10.1109/tvcg.2017.2745158", "10.1073/pnas.0307752101", "10.1109/tvcg.2018.2816223", "10.1109/tvcg.2017.2745141", "10.1145/32232.32234", "10.1109/tvcg.2019.2934267", "10.1109/tvcg.2018.2864477", "10.1145/3132169", "10.2312/eurova.20151100.19", "10.1145/3172944.3172964", "10.1145/2601248.2601268", "10.1109/isai-nlp.2018.8693002.1", "10.1111/cgf.13404", "10.1007/s100320200071", "10.2312/trvis.20191183.16", "10.1111/cgf.12755", "10.1145/2702123.2702509", "10.1145/1401890.1402008.25", "10.1109/tvcg.2012.65", "10.1177/1473871617733996", "10.2312/trvis.20191187.7", "10.21236/ada273556", "10.1109/vast.2010.5652450", "10.1111/j.1467-8659.2011.01940.x", "10.1177/875647939000600106", "10.1109/tvcg.2017.2711030", "10.1016/j.immuni.2016.04.014", "10.1109/tvcg.2019.2934209", "10.1016/0095-0696(78)90006-2", "10.1016/j.jclinepi.2015.04.014", "10.1016/j.ress.2013.02.013", "10.1111/cgf.12640", "10.1145/1015330.1015388.25", "10.1111/j.1467-8659.2009.01468.x", "10.1145/1541880.1541882", "10.1109/vast.2011.6102453", "10.1016/s0008-8846(98)00165-3", "10.2312/trvis.20191186.7", "10.1007/s13748-013-0040-3", "10.1109/tvcg.2015.2467757", "10.1109/tbdata.2018.2877350", "10.1109/vast.2017.8585613", "10.1080/10556789208805504", "10.1109/vast.2012.6400484", "10.1145/3025171.3025181", "10.1007/978-3-319-90403-0\\_12", "10.1109/mcg.2019.2922592", "10.1021/ci000392t", "10.1109/vast.2007.4389000", "10.1111/cgf.13406.16", "10.1111/cgf.13684", "10.2312/eurovisshort.20161166.17", "10.2312/evs:20191168", "10.1145/3041021.3055135", "10.1145/3301275.3302265", "10.1613/jair.4135", "10.1109/tvcg.2018.2864500", "10.1109/tvcg.2017.2744158", "10.1109/ssci.2015.33", "10.1111/cgf.13453", "10.2312/pe/eurovast/eurova11/049-052", "10.1145/3025171.3025181.13", "10.1145/371920.372094", "10.1109/tvcg.2017.2744938", "10.1111/j.1467-8659.2012.03108.x", "10.1109/tvcg.2019.2934251", "10.1145/3290605.3300809.18", "10.1109/ldav.2016.7874305", "10.1109/vast.2016.7883514", "10.1109/iccv.2015.425", "10.1145/3301275.3302324", "10.1109/tnnls.2013.2292894", "10.1109/tvcg.2018.2865044", "10.1109/tvcg.2013.157", "10.1371/journal.pcbi.0020161", "10.1186/s12916-019-1426-2", "10.1109/10.867928", "10.1111/cgf.13217", "10.1109/mcg.2019.2919033", "10.1145/2993901.2993910", "10.1109/tvcg.2017.2744738", "10.2307/258792", "10.1111/cgf.12655", "10.1016/j.dss.2014.03.001", "10.1109/tvcg.2019.2904069", "10.1111/cgf.13205", "10.1002/mds.22340", "10.1109/tvcg.2019.2934595", "10.1287/inte.2018.0957", "10.1109/cvpr.2007.382974", "10.1109/tvcg.2012.280", "10.1145/2678025.2701399.13", "10.2312/mlvis.20181130.13", "10.2312/eurova.20181106.16", "10.1109/tvcg.2018.2864475", "10.2312/mlvis.20191160.18,22", "10.1007/978-1-4612-4026-6.25", "10.1109/cvpr.2006.42", "10.1145/3172944.3172950", "10.1109/cvpr.2004.383.25", "10.1109/tvcg.2019.2934812", "10.1609/aimag.v35i4.2513", "10.2312/trvis.20191185.7", "10.1111/j.1467-8659.2009.01684.x", "10.1371/journal.pone.0129126", "10.1111/cgf.13092", "10.1162/coli\\_a\\_00237", "10.1109/tvcg.2017.2744818", "10.1109/vast.2011.6102448", "10.1109/tvcg.2009.111", "10.1109/tvcg.2019.2934619", "10.1016/s0377-2217(01)00264-8.25", "10.1111/cgf.12639", "10.1109/access.2019.2919343", "10.1186/s12874-019-0681-4", "10.1109/pacificvis.2015.7156366", "10.1109/pacificvis.2018.00029", "10.1109/tvcg.2019.2934261", "10.1080/13506280444000102.http://www.uvt.nl/ticc", "10.1109/vast.2018.8802509", "10.1111/cgf.13212", "10.1145/3200489", "10.1111/cgf.13176", "10.1177/1473871620904671", "10.1007/978-3-319-10590-1\\_53", "10.1111/j.1467-8659.2012.03126.x", "10.1111/cgf.13172", "10.1145/3025171.3025208.6,21", "10.1111/cgf.12366", "10.1109/tvcg.2019.2934659", "10.1109/cvprw.2009.5206848", "10.1016/j.media.2014.11.010", "10.1109/tvcg.2017.2744683", "10.1109/tvcg.2019.2934262", "10.1016/j.neucom.2006.11.018", "10.1177/1473871615571951", "10.1371/journal.pcbi.0020161.25", "10.1177/1473871611415994", "10.2312/trvis20191187", "10.2312/eurova", "10.1145/2858036.2858529", "10.1145/2207676.2207738", "10.1007/s11042-009-0417-2", "10.1145/3301275.3302317", "10.1038/s41746-019-0148-3", "10.1145/3351095.3372834", "10.1080/10691898.2011.11889627", "10.1109/tvcg.2018.2864504", "10.1109/vast.2017.8585720", "10.1109/mcg.2018.053491732", "10.1007/s10994-010-5207-6", "10.1109/tvcg.2019.2934433", "10.1016/j.cag.2017.05.005", "10.1109/tvcg.2012.279", "10.1145/3231622.3231641.19,20", "10.1145/1562849.1562851", "10.1007/11564126\\_", "10.1109/tvcg.2018.2846735", "10.3115/1225403.1225421", "10.1109/vast.2012.6400486", "10.2312/eurova.20191116.22", "10.1109/tvcg.2007.70443", "10.1080/027868291009242", "10.2312/eurova.20151100", "10.1145/2939502.2939503.19", "10.1016/j.cag.2014.02.004", "10.1145/2939672.2939778", "10.1109/vast.2010.5652484", "10.1111/cgf.12641", "10.1145/3301275.3302289", "10.1109/visual.2019.8933619", "10.1109/tvcg.2017.2672987", "10.1109/vast.2016.7883517.20", "10.1109/igarss.2017.8127684", "10.1016/j.jcae.2010.04.002", "10.1109/vast.2010.5652885", "10.1016/j.visinf.2019.03.002", "10.1007/s00371-018-1500-3", "10.1109/mcg.2018.042731661", "10.1109/34.598228", "10.1109/tvcg.2018.2865027", "10.1016/j.neucom.2017.01.105", "10.1111/cgf.12389", "10.1109/tvcg.2019.2934591", "10.1109/vast.2010.5652392.16", "10.1111/cgf.13416", "10.1080/02701367.1992.10608764", "10.1109/vast.2017.8585721", "10.1109/tvcg.2018.2843369", "10.1109/sbes.2010.27", "10.1109/vast.2015.7347637", "10.1145/1401890.1402008", "10.1016/j.bpj.2010.04.064", "10.1109/tvcg.2013.125", "10.1109/isai-nlp.2018.8693002", "10.1371/journal.pone.0160127", "10.1145/2856767.2856779", "10.1145/2678025.2701399", "10.1109/vast.2011.6102451", "10.1109/mcg.2010.18", "10.1021/ci4000213", "10.1109/vast.2012.6400492", "10.1007/11564126-49.25", "10.2312/eurova.20171114", "10.1109/vast.2010.5652443", "10.1145/3134599", "10.2312/pe/eurovast/eurovast10/013-018.19", "10.1109/tvcg.2019.2903946", "10.1109/tvcg.2015.2467717", "10.1177/1473871612460526", "10.1016/j.cag.2018.09.018", "10.1109/tvcg.2016.2598838", "10.1145/3172944.3172964.14", "10.1109/vast.2009.5333428", "10.1109/vast.2014.7042480", "10.2312/pe/eurovast/eurovast10/013-018", "10.1177/0962280215588241", "10.1145/2993901.2993917", "10.1109/cvpr.2008:4587581", "10.1109/tvcg.2015.2467551", "10.1016/j.visinf.2018.09.001", "10.1126/science.290.5500.2319", "10.2312/eurova.20151107", "10.1109/visual.2019.8933695", "10.13140/2.1.2393.1847", "10.1197/jamia.m1929", "10.1109/cvpr.2008.4587581.25", "10.1145/1518701.1518895.16", "10.1109/vds.2017.8573444", "10.2312/trvis:20191185", "10.1145/3359786", "10.13140/2.1.1341.1520", "10.2312/pe/eurovast/eurova11/049-052.17", "10.1109/tvcg.2014.2346660", "10.1145/3185517", "10.1109/adprl.2011.5967372", "10.1109/tvcg.2015.2467591", "10.1111/j.1751-9004.2009.00232.x", "10.1136/qshc.2004.010033", "10.1109/vast.2012.6400493", "10.1109/tvcg.2019.2934266", "10.1145/2971763.2971775", "10.1111/cgf.13730", "10.1109/vast.2012.6400488", "10.1111/cgf.13210", "10.1109/tvcg.2019.2934631", "10.1145/3172944.3172965", "10.1057/ivs.2010.2", "10.1109/tvcg.2017.2745258", "10.1016/j.jbusres.2019.07.039", "10.1162/jmlr.2003.3.4-5.993", "10.1109/pacificvis.2019.00044", "10.2312/pe/eurovast/eurova12/037-041", "10.1109/tvcg.2019.2934629", "10.1177/0018720814547570", "10.1145/3292500.3330908", "10.1111/j.1467-8659.2009.01467.x", "10.2312/eurova.20151098", "10.1177/1473871617713337", "10.1109/lars:2009.5418323", "10.1109/vast.2011.6102437", "10.1111/cgf.12878", "10.1561/1500000001", "10.1145/3025171.3025222", "10.1007/s11704-016-6028-y", "10.1016/j.procs.2017.05.216", "10.1109/cvpr.2007.382974.25", "10.1080/10447318.2020.1741118", "10.1109/vast.2012.6400489", "10.1145/3025171.3025172", "10.1109/tvcg.2017.2744098", "10.1109/tvcg.2005.66", "10.1016/j.dss.2009.05.016", "10.1007/978-1-4612-4026-6", "10.2312/evs.20191168.16,20,28", "10.2312/pe/eurovast/eurova12/037-041.17", "10.1145/3290605.3300803", "10.1145/1015330.1015388", "10.1111/cgf.13197", "10.1016/b978-1-55860-377-6.50048-7", "10.1111/cgf.13681", "10.1109/tvcg.2017.2744378", "10.1109/tvcg.2017.2744358", "10.1109/vast.2008.4677352"], "wos": 1, "children": [{"doi": "10.1109/tvcg.2020.3030368", "title": "Implicit Multidimensional Projection of Local Subspaces", "year": "2020", "conferenceName": "InfoVis", "authors": "Rongzheng Bian;Yumeng Xue;Liang Zhou;Jian Zhang 0070;Baoquan Chen;Daniel Weiskopf;Yunhai Wang", "citationCount": "1", "affiliation": "Wang, YH (Corresponding Author), Shandong Univ, Qingdao, Peoples R China. Zhou, L (Corresponding Author), Univ Utah, Salt Lake City, UT 84112 USA. Bian, Rongzheng; Xue, Yumeng; Wang, Yunhai, Shandong Univ, Qingdao, Peoples R China. Chen, Baoquan, Peking Univ, Beijing, Peoples R China. Zhang, Jian, Chinese Acad Sci, CNIC, Beijing, Peoples R China. Zhou, Liang, Univ Utah, Salt Lake City, UT 84112 USA. Weiskopf, Daniel, Univ Stuttgart, Stuttgart, Germany.", "countries": "USA;Germany;China", "abstract": "We propose a visualization method to understand the effect of multidimensional projection on local subspaces, using implicit function differentiation. Here, we understand the local subspace as the multidimensional local neighborhood of data points. Existing methods focus on the projection of multidimensional data points, and the neighborhood information is ignored. Our method is able to analyze the shape and directional information of the local subspace to gain more insights into the global structure of the data through the perception of local structures. Local subspaces are fitted by multidimensional ellipses that are spanned by basis vectors. An accurate and efficient vector transformation method is proposed based on analytical differentiation of multidimensional projections formulated as implicit functions. The results are visualized as glyphs and analyzed using a full set of specifically-designed interactions supported in our efficient web-based visualization tool. The usefulness of our method is demonstrated using various multi- and high-dimensional benchmark datasets. Our implicit differentiation vector transformation is evaluated through numerical comparisons; the overall method is evaluated through exploration examples and use cases.", "keywords": "High-dimensional data visualization,dimensionality reduction,local linear subspaces,user interaction", "link": "http://dx.doi.org/10.1109/TVCG.2020.3030368", "refList": ["10.3844/jcssp.2018.613.622", "10.1016/j.aci.2018.08.003", "10.3390/info9030065", "10.1016/j.visinf.2018.09.003", "10.1371/journal.pone.0118432", "10.1016/s0893-6080(05)80023-1", "10.1109/tvcg.2020.2986996", "10.1109/icst.2012.56", "10.1007/s10844-013-0250-y", "10.1109/tbdata.2018", "10.1145/1125451.1125659", "10.1109/tvcg.2013.125", "10.1177/1473871611412817", "10.1145/3290605.3300911", "10.1111/cgf.14034", "10.1007/s13721-013-0034-x", "10.1016/j.procs.2017.05.216", "10.1016/j.ins.2009.08.025", "10.1109/tvcg.2013.124", "10.1109/tvcg.2018.2864499", "10.1109/tvcg.2018.2864475", "10.1080/10447318.2020.1741118", "10.1016/j.imu.2019.100203", "10.1109/tvcg.2018.2865240", "10.1186/s12864-019-6413-7", "10.1109/tvcg.2015.2467551", "10.1002/widm.1249", "10.1007/978-3-319-66429-3\\_29", "10.1109/tvcg.2014.2346481", "10.1109/tvcg.2018.2864825", "10.1177/1473871620904671", "10.1109/tvcg.2019.2934267", "10.1136/bmjopen-2016-012799", "10.1109/smartgridcomm.2017.8340682", "10.1007/s10664-015-9401-9", "10.1145/1143844.1143874", "10.1111/cgf.12389", "10.1109/tvcg.2018.2872577", "10.1007/978-981-13-5802-9\\_20", "10.1016/j.ipm.2009.03.002", "10.5220/0006431602160222", "10.1109/mcg.2015.50", "10.1109/tvcg.2014.2346574", "10.1007/bf02289565", "10.1109/tvcg.2017.2744378", "10.1016/j.patrec.2008.08.010", "10.1023/a:1010933404324", "10.9735/2229-3981"], "wos": 1, "children": [], "len": 1}, {"doi": "10.1109/tvcg.2020.3030465", "title": "Visual Causality Analysis of Event Sequence Data", "year": "2020", "conferenceName": "VAST", "authors": "Zhuochen Jin;Shunan Guo;Nan Chen;Daniel Weiskopf;David Gotz;Nan Cao", "citationCount": "0", "affiliation": "Cao, N (Corresponding Author), Tongji Univ, IDVx Lab, Shanghai, Peoples R China. Jin, Zhuochen; Guo, Shunan; Chen, Nan; Cao, Nan, Tongji Univ, IDVx Lab, Shanghai, Peoples R China. Weiskopf, Daniel, Univ Stuttgart, Stuttgart, Germany. Gotz, David, Univ N Carolina, Chapel Hill, NC 27515 USA.", "countries": "USA;Germany;China", "abstract": "Causality is crucial to understanding the mechanisms behind complex systems and making decisions that lead to intended outcomes. Event sequence data is widely collected from many real-world processes, such as electronic health records, web clickstreams, and financial transactions, which transmit a great deal of information reflecting the causal relations among event types. Unfortunately, recovering causalities from observational event sequences is challenging, as the heterogeneous and high-dimensional event variables are often connected to rather complex underlying event excitation mechanisms that are hard to infer from limited observations. Many existing automated causal analysis techniques suffer from poor explainability and fail to include an adequate amount of human knowledge. In this paper, we introduce a visual analytics method for recovering causalities in event sequence data. We extend the Granger causality analysis algorithm on Hawkes processes to incorporate user feedback into causal model refinement. The visualization system includes an interactive causal analysis framework that supports bottom-up causal exploration, iterative causal verification and refinement, and causal comparison through a set of novel visualizations and interactions. We report two forms of evaluation: a quantitative evaluation of the model improvements resulting from the user-feedback mechanism, and a qualitative evaluation through case studies in different application domains to demonstrate the usefulness of the system.", "keywords": "Event sequence data,causality analysis,visual analytics", "link": "http://dx.doi.org/10.1109/TVCG.2020.3030465", "refList": ["10.5555/1642718", "10.1109/tvcg.2018.2865022", "10.5555/2074094.2074151", "10.1109/tvcg.2016.2618797", "10.1073/pnas.1320645111", "10.1109/tvcg.2017.2744843", "10.1109/iv.2017.69", "10.1109/tvcg.2019.2934399", "10.1145/3172944.3173007", "10.5555/1795555", "10.1109/mcg.2005.102", "10.1145/381641.381653", "10.1162/153244301753344614", "10.1111/cgf.14034", "10.1111/cgf.13198", "10.1017/cbo9780511519857", "10.1007/s10462-016-9475-9", "10.1075/ssol.2.2.07bor", "10.1007/978-1-4614-3223-4\\_3", "10.1109/infvis.2003.1249025", "10.1007/978-94-007-6094-313", "10.1145/2858036.2858387", "10.1109/tvcg.2007.70528", "10.1109/tvcg.2017.2674958", "10.1147/sj.454.0801", "10.1109/tvcg.2013.119", "10.1145/3173574.3173711", "10.1016/j.erss.2017.06.034", "10.1109/visual.2019.8933695", "10.1007/s11665-016-2173-6", "10.1016/0377-0427(87)90125-7", "10.2307/3601125", "10.1016/b978-0-444-88738-2.50018-x", "10.1109/mcg.2006.70", "10.1109/tvcg.2018.2865145", "10.1017/s1351324997001502", "10.1109/tvcg.2010.179", "10.1214/aos/1176344552", "10.1109/mcg.2009.22", "10.1007/978-3-319-26633-6\\_13", "10.1080/10447318.2014.905422", "10.1016/j.visinf.2019.03.004", "10.1057/palgrave.ivs.9500074", "10.1007/978-1-4614-3223-4"], "wos": 1, "children": [], "len": 1}], "len": 5}, {"doi": "10.1111/cgf.14001", "year": "2020", "title": "Sunspot Plots: Model-based Structure Enhancement for Dense Scatter Plots", "conferenceName": "EuroVis", "authors": "Thomas Trautner;Fabian Bolte;Sergej Stoppel;Stefan Bruckner", "citationCount": "0", "affiliation": "Trautner, T (Corresponding Author), Univ Bergen, Bergen, Norway.\nTrautner, T.; Bolte, F.; Stoppel, S.; Bruckner, S., Univ Bergen, Bergen, Norway.", "countries": "Norway", "abstract": "Scatter plots are a powerful and well-established technique for visualizing the relationships between two variables as a collection of discrete points. However, especially when dealing with large and dense data, scatter plots often exhibit problems such as overplotting, making the data interpretation arduous. Density plots are able to overcome these limitations in highly populated regions, but fail to provide accurate information of individual data points. This is particularly problematic in sparse regions where the density estimate may not provide a good representation of the underlying data. In this paper, we present sunspot plots, a visualization technique that communicates dense data as a continuous data distribution, while preserving the discrete nature of data samples in sparsely populated areas. We furthermore demonstrate the advantages of our approach on typical failure cases of scatter plots within synthetic and real-world data sets and validate its effectiveness in a user study.", "keywords": "", "link": "https://doi.org/10.1111/cgf.14001", "refList": ["10.1057/palgrave.ivs.9500122", "10.2312/eggh/hpg12/097-103", "10.1109/tvcg.2008.119", "10.1109/pacificvis.2011.5742387", "10.1038/331163a0", "10.1109/visual.2019.8933620", "10.2307/2683294", "10.1201/9781351072304", "10.2307/2289444", "10.1109/tvcg.2019.2934541", "10.1080/00949657508810123", "10.1109/tvcg.2013.65", "10.1109/infvis.1997.636789", "10.1109/2945.841121", "10.1109/mcse.2007.55", "10.1109/tvcg.2010.197", "10.1111/cgf.12871", "10.1109/infvis.2003.1249018", "10.1145/3173574.3173991", "10.1109/tvcg.2012.238", "10.1007/0-387-28695-0", "10.1109/pacificvis.2010.5429604", "10.18637/jss.v008.i03", "10.1109/tvcg.2007.70596", "10.1109/visual.1998.745301", "10.1007/0-387-37977-0\\_3", "10.1145/1556262.1556289", "10.2312/wiced.20161094", "10.1109/tvcg.2007.70535", "10.1145/1056808.1056914", "10.1109/tvcg.2003.1196007", "10.1109/iv.2004.1320190", "10.1111/cgf.12877", "10.1162/leon.2007.40.2.202a", "10.1109/tvcg.2017.2674978", "10.1057/ivs.2010.4", "10.1016/j.cag.2018.02.008", "10.1201/9781315140919", "10.1109/visual.2000.885677", "10.1002/jhbs.20078", "10.1109/tvcg.2014.2346594", "10.1109/tvcg.2017.2744184", "10.1109/visual.2001.964495", "10.1109/iv.2002.1028760", "10.1111/cgf.13684", "10.1109/hicss.2013.197", "10.1109/tvcg.2019.2903956", "10.1093/mnras/stt961", "10.1109/tvcg.2017.2668409", "10.1111/j.1467-8659.2009.01478.x", "10.1145/2702123.2702585", "10.2307/1418003", "10.2307/1390742", "10.1145/360825.360839", "10.1109/pacificvis.2009.4906843", "10.1057/ivs.2009.34", "10.2307/2288711"], "wos": 1, "children": [], "len": 1}], "len": 13}, {"doi": "10.1111/cgf.14000", "year": "2020", "title": "Evaluating Reordering Strategies for Cluster Identification in Parallel Coordinates", "conferenceName": "EuroVis", "authors": "Michael Blumenschein;Xuan Zhang;David Pomerenke;Daniel A. Keim;Johannes Fuchs", "citationCount": "0", "affiliation": "Blumenschein, M (Corresponding Author), Univ Konstanz, Constance, Germany.\nBlumenschein, Michael; Pomerenke, David; Keim, Daniel A.; Fuchs, Johannes, Univ Konstanz, Constance, Germany.\nZhang, Xuan, Rhein Westfal TH Aachen, Aachen, Germany.", "countries": "Germany", "abstract": "The ability to perceive patterns in parallel coordinates plots (PCPs) is heavily influenced by the ordering of the dimensions. While the community has proposed over 30 automatic ordering strategies, we still lack empirical guidance for choosing an appropriate strategy for a given task. In this paper, we first propose a classification of tasks and patterns and analyze which PCP reordering strategies help in detecting them. Based on our classification, we then conduct an empirical user study with 31 participants to evaluate reordering strategies for cluster identification tasks. We particularly measure time, identification quality, and the users' confidence for two different strategies using both synthetic and real-world datasets. Our results show that, somewhat unexpectedly, participants tend to focus on dissimilar rather than similar dimension pairs when detecting clusters, and are more confident in their answers. This is especially true when increasing the amount of clutter in the data. As a result of these findings, we propose a new reordering strategy based on the dissimilarity of neighboring dimension pairs.", "keywords": "", "link": "https://doi.org/10.1111/cgf.14000", "refList": ["10.1111/j.1467-8659.2008.01241.x", "10.2312/conf/eg2013/stars/095-116", "10.1109/tvcg.2014.2346979", "10.1117/12.838819", "10.2307/2290001", "10.1111/cgf.12638", "10.1007/978-3-642-30217-6\\_42", "10.1109/sc.2005.47", "10.1002/wics.145", "10.1109/tvcg.2011.229", "10.1109/vast.2009.5332628", "10.1109/vast.2017.8585613", "10.1145/2993901.2993907", "10.1007/bf00410640", "10.1109/tvcg.2010.184", "10.11591/ijece.v5i6", "10.1111/j.1467-8659.2011.01961.x", "10.1109/visual.1997.663916", "10.1111/j.1467-8659.2012.03129.x", "10.1109/visual.1999.809866", "10.1057/ivs.2008.13", "10.1016/j.visinf.2017.11.001", "10.2307/2282967", "10.1007/978-0-387-68628-8\\_10", "10.5888/pcd9.120082", "10.1109/tvcg.2007.70535", "10.1109/vast.2010.5652450", "10.1007/bf01898350", "10.1016/0010-0285(91)90009-d", "10.1007/978-3-642-24958-7\\_12", "10.1109/infvis.2005.1532142", "10.1057/palgrave.ivs.9500166", "10.1111/j.1467-8659.2008.01239.x", "10.1109/mcse.2015.55", "10.2312/pe/eurovast/eurova12/007-011.7", "10.1109/tvcg.2009.153", "10.1198/jcgs.2010.09136", "10.1145/2463676.2463696", "10.1109/infvis.2005.1532138", "10.1109/tvcg.2010.242", "10.5220/0006097400400051", "10.1109/visual.2019.8933706", "10.1109/atc.2015.7388338", "10.2312/pe/eurovast/eurova12/007-011", "10.5120/5044-7370", "10.1111/cgf.13446", "10.1109/icmla.2012.148", "10.1016/j.jvlc.2015.12.001", "10.1109/tvcg.2015.2466992", "10.1111/j.1467-8659.2009.01666.x", "10.5169/seals-266450", "10.1109/infvis.1998.729559", "10.1016/j.jvlc.2017.10.003", "10.1109/visual.1995.485139", "10.1007/978-0-387-39940-9\\_262", "10.1109/tvcg.2006.138"], "wos": 1, "children": [], "len": 1}], "len": 71}, {"doi": "10.1111/cgf.13403", "year": "2018", "title": "Visualizing Expanded Query Results", "conferenceName": "EuroVis", "authors": "Michael Mazurek;Manuela Waldner", "citationCount": "1", "affiliation": "Mazurek, M (Corresponding Author), TU Wien, Vienna, Austria.\nMazurek, Michael; Waldner, Manuela, TU Wien, Vienna, Austria.", "countries": "Austria", "abstract": "When performing queries in web search engines, users often face difficulties choosing appropriate query terms. Search engines therefore usually suggest a list of expanded versions of the user query to disambiguate it or to resolve potential term mismatches. However, it has been shown that users find it difficult to choose an expanded query from such a list. In this paper, we describe the adoption of set-based text visualization techniques to visualize how query expansions enrich the result space of a given user query and how the result sets relate to each other. Our system uses a linguistic approach to expand queries and topic modeling to extract the most informative terms from the results of these queries. In a user study, we compare a common text list of query expansion suggestions to three set-based text visualization techniques adopted for visualizing expanded query results - namely, Compact Euler Diagrams, Parallel Tag Clouds, and a List View - to resolve ambiguous queries using interactive query expansion. Our results show that text visualization techniques do not increase retrieval efficiency, precision, or recall. Overall, users rate Parallel Tag Clouds visualizing key terms of the expanded query space lowest. Based on the results, we derive recommendations for visualizations of query expansion results, text visualization techniques in general, and discuss alternative use cases of set-based text visualization techniques in the context of web search.", "keywords": "", "link": "https://doi.org/10.1111/cgf.13403", "refList": ["10.1145/358923.358934", "10.1023/b:bttj.0000047600.45421.6d", "10.1111/cgf.12376", "10.1145/1277741.1277870", "10.1109/vast.2009.5333443", "10.2312/eurovisstar.20141170", "10.1109/iv.2008.78", "10.1109/wi.2005.158", "10.1007/s10791-008-9074-8", "10.1016/s0306-4573(99)00056-4", "10.1109/pacificvis.2015.7156366", "10.1145/2348283.2348298", "10.1108/eb026526", "10.1145/32206.32212", "10.1109/tvcg.2010.210", "10.1016/0306-4573(93)90024-8", "10.1109/infvis.2001.963287", "10.1109/vast.2015.7347686", "10.1109/tvcg.2013.212", "10.1109/tvcg.2013.242", "10.1109/52.582976", "10.1145/860435.860475", "10.1145/1631272.1631278", "10.1145/1277741.1277746", "10.1145/2071389.2071390", "10.1109/iv.2015.30", "10.1007/s00799-004-0111-y", "10.1057/palgrave.ivs.9500180", "10.1016/j.eswa.2010.08.066", "10.1145/2362364.2362367", "10.1097/brs.0b013e3181fdb4db", "10.1109/iv.2014.72", "10.1145/3025171.3025223", "10.1145/3038462.3038467"], "wos": 1, "children": [], "len": 1}, {"doi": "10.1111/cgf.13731", "year": "2019", "title": "The State of the Art in Visual Analysis Approaches for Ocean and Atmospheric Datasets", "conferenceName": "EuroVis", "authors": "Shehzad Afzal;Mohamad Mazen Hittawe;Sohaib Ghani;Tahira Jamil;Omar M. Knio;Markus Hadwiger;Kevin I.{-}J. Ho", "citationCount": "0", "affiliation": "Afzal, S (Corresponding Author), King Abdullah Univ Sci \\& Technol, Thuwal, Saudi Arabia.\nAfzal, S.; Hittawe, M. M.; Ghani, S.; Jamil, T.; Knio, O.; Hadwiger, M.; Hoteit, I, King Abdullah Univ Sci \\& Technol, Thuwal, Saudi Arabia.", "countries": "Arabia", "abstract": "The analysis of ocean and atmospheric datasets offers a unique set of challenges to scientists working in different application areas. These challenges include dealing with extremely large volumes of multidimensional data, supporting interactive visual analysis, ensembles exploration and visualization, exploring model sensitivities to inputs, mesoscale ocean features analysis, predictive analytics, heterogeneity and complexity of observational data, representing uncertainty, and many more. Researchers across disciplines collaborate to address such challenges, which led to significant research and development advances in ocean and atmospheric sciences, and also in several relevant areas such as visualization and visual analytics, big data analytics, machine learning and statistics. In this report, we perform an extensive survey of research advances in the visual analysis of ocean and atmospheric datasets. First, we survey the task requirements by conducting interviews with researchers, domain experts, and end users working with these datasets on a spectrum of analytics problems in the domain of ocean and atmospheric sciences. We then discuss existing models and frameworks related to data analysis, sense-making, and knowledge discovery for visual analytics applications. We categorize the techniques, systems, and tools presented in the literature based on the taxonomies of task requirements, interaction methods, visualization techniques, machine learning and statistical methods, evaluation methods, data types, data dimensions and size, spatial scale and application areas. We then evaluate the task requirements identified based on our interviews with domain experts in the context of categorized research based on our taxonomies, and existing models and frameworks of visual analytics to determine the extent to which they fulfill these task requirements, and identify the gaps in current research. In the last part of this report, we summarize the trends, challenges, and opportunities for future research in this area. (see http://www.acm.org/about/class/class/2012) )", "keywords": "", "link": "https://doi.org/10.1111/cgf.13731", "refList": ["10.1111/cgf.12898", "10.1109/icdmw.2009.55", "10.1109/tvcg.2013.144", "10.1109/tvcg.2015.2467754", "10.1109/tvcg.2015.2507569", "10.1109/tvcg.2014.2346455", "10.1111/cgf.12901", "10.1109/tvcg.2008.184", "10.1109/mc.2013.119", "10.1111/j.1467-8659.2009.01697.x", "10.1109/tvcg.2009.200", "10.1111/cgf.12649", "10.1109/2945.981847", "10.1109/tvcg.2014.2346481", "10.1109/tvcg.2012.190", "10.1109/mis.2006.75", "10.1109/iv.2015.13", "10.1111/cgf.12135", "10.1109/vast.2009.5332586", "10.1109/pacificvis.2011.5742369", "10.1109/tvcg.2008.131", "10.1109/tvcg.2013.131", "10.1109/tvcg.2010.82", "10.1109/pacificvis.2015.7156374", "10.1111/cgf.12886", "10.1109/tvcg.2016.2598869", "10.1109/vast.2012.6400553", "10.1109/pacificvis.2013.6596144", "10.1109/tvcg.2017.2745178", "10.1109/tvcg.2015.2410278", "10.1111/cgf.12931", "10.1109/tvcg.2009.155", "10.1109/pacificvis.2015.7156366", "10.1109/mcg.2015.121", "10.1007/978-1-4471-2804-5\\_6", "10.1109/ldav.2015.7348068", "10.1007/978-1-4471-6497-5\\_1", "10.1109/pacificvis.2009.4906852", "10.1111/cgf.12646", "10.1109/tvcg.2016.2607204", "10.1109/tvcg.2011.162", "10.1177/1473871612465214", "10.1109/mcg.2017.3621228", "10.1109/tvcg.2012.110", "10.1109/sc.2014.40", "10.5194/gmd-8-2329-2015", "10.1109/tvcg.2012.80", "10.1109/tvcg.2014.2346448", "10.1109/ldav.2012.6378978", "10.1007/s10915-011-9501-7", "10.1109/tvcg.2016.2598830", "10.1109/tvcg.2007.70515", "10.1109/vast.2011.6102460", "10.1109/pacificvis.2017.8031584", "10.1109/tvcg.2016.2637904", "10.1175/2009jtecha1374.1", "10.1109/tvcg.2015.2467591", "10.1109/tvcg.2015.2467204", "10.1109/tvcg.2008.59", "10.1109/tvcg.2013.143", "10.1109/tvcg.2008.119", "10.1109/tvcg.2015.2467411", "10.1109/icdmw.2009.91", "10.1109/tvcg.2016.2598868", "10.1109/tvcg.2017.2661309", "10.1109/vl.1996.545307", "10.1109/tvcg.2007.70523", "10.1109/tvcg.2008.140", "10.1109/icra.2012.6224689", "10.1109/tvcg.2010.80", "10.1167/tvst.7.1.16", "10.1109/pacificvis.2018.00037", "10.1111/cgf.13210", "10.1109/tvcg.2017.2698041", "10.1109/iv.2010.51", "10.1109/tvcg.2016.2640960", "10.1109/tvcg.2010.170", "10.1103/physrevd.71.077102", "10.5194/npg-22-545-2015", "10.1109/tvcg.2014.2307892", "10.1111/cgf.12650", "10.1109/iv.2009.38", "10.2312/pe.envirvis.envirvis13.053-057", "10.1145/3122948.3122952", "10.1109/ldav.2014.7013208", "10.1038/nature14956", "10.1109/vast.2015.7347671", "10.1109/vast.2015.7347634", "10.1109/tvcg.2014.2346755", "10.1177/1473871613481692", "10.1109/ldav.2017.8231849", "10.1109/tvcg.2017.2773071", "10.1109/iv.2011.79", "10.1109/tvcg.2013.10", "10.1109/tvcg.2008.157", "10.1111/j.1467-8659.2009.01664.x", "10.1109/pacificvis.2016.7465251", "10.1109/vast.2014.7042489", "10.1109/mis.2006.100", "10.1109/tvcg.2010.247", "10.1109/tvcg.2016.2534560", "10.1109/tvcg.2010.181", "10.1109/tvcg.2018.2864817", "10.1109/vast.2015.7347635", "10.1109/tvcg.2018.2864901", "10.1109/hicss.2016.183", "10.1109/iv.2010.32", "10.1111/j.1467-8659.2011.01948.x", "10.1109/tvcg.2017.2743989", "10.1109/pacificvis.2016.7465272", "10.1109/tvcg.2008.69", "10.1109/tvcg.2008.139", "10.1109/iv.2011.12", "10.1111/cgf.12520"], "wos": 1, "children": [{"doi": "10.1109/tvcg.2020.3030466", "title": "Uncertainty in Continuous Scatterplots, Continuous Parallel Coordinates, and Fibers", "year": "2020", "conferenceName": "SciVis", "authors": "Boyan Zheng;Filip Sadlo", "citationCount": "0", "affiliation": "Zheng, BY (Corresponding Author), Heidelberg Univ, Heidelberg, Germany. Zheng, Boyan; Sadlo, Filip, Heidelberg Univ, Heidelberg, Germany.", "countries": "Germany", "abstract": "In this paper, we introduce uncertainty to continuous scatterplots and continuous parallel coordinates. We derive respective models, validate them with sampling-based brute-force schemes, and present acceleration strategies for their computation. At the same time, we show that our approach lends itself as well for introducing uncertainty into the definition of fibers in bivariate data. Finally, we demonstrate the properties and the utility of our approach using specifically designed synthetic cases and simulated data.", "keywords": "Multivariate data,uncertainty visualization,uncertain continuous scatterplots,uncertain continuous parallel coordinates,uncertain fibers", "link": "http://dx.doi.org/10.1109/TVCG.2020.3030466", "refList": ["10.1109/tvcg.2018.2865193", "10.1109/tvcg.2013.143", "10.1109/tvcg.2015.2467204", "10.1109/pacificvis.2013.6596144", "10.1109/tvcg.2017.2745178", "10.1109/tmm.2016.2614227", "10.1109/scivis.2015.7429488", "10.1111/cgf.12100", "10.1109/pacificvis.2016.7465251", "10.1111/cgf.12898", "10.1109/tvcg.2015.2410278", "10.1109/icdmw.2009.55", "10.1109/tvcg.2015.2467754", "10.1109/tvcg.2010.247", "10.1109/tvcg.2019.2934312", "10.1111/cgf.13397", "10.1109/tvcg.2016.2598868", "10.1111/j.1467-8659.2011.01944.x", "10.1109/tvcg.2015.2507569", "10.1109/tvcg.2013.92", "10.1145/1268517.1268563", "10.1109/tvcg.2014.2346455", "10.1109/tvcg.2010.181", "10.1109/tvcg.2018.2853721", "10.1109/tvcg.2008.140", "10.1007/s12650-015-0341-7", "10.1109/mcg.2014.52", "10.1109/tvcg.2018.2864815", "10.1111/j.1467-8659.2012.03095.x", "10.1109/tvcg.2013.138", "10.1109/tvcg.2019.2934242", "10.3390/e20070540", "10.1016/j.jcp.2007.02.014", "10.1111/cgf.13999", "10.1109/tvcg.2017.2779501", "10.1111/cgf.12390", "10.1109/tvcg.2014.2307892", "10.1111/cgf.13531", "10.1109/tvcg.2013.152", "10.1038/nature14956", "10.1007/978-3-540-88606-8\\_4", "10.1109/mcg.2005.71", "10.1111/j.1467-8659.2011.01942.x", "10.1109/tvcg.2019.2934800", "10.1109/tvcg.2016.2598830", "10.1109/cvpr.2005.188", "10.1109/tvcg.2011.261", "10.1111/cgf.13731", "10.1109/tvcg.2017.2754480"], "wos": 1, "children": [], "len": 1}], "len": 3}, {"doi": "10.1111/cgf.14034", "year": "2020", "title": "The State of the Art in Enhancing Trust in Machine Learning Models with the Use of Visualizations", "conferenceName": "EuroVis", "authors": "Angelos Chatzimparmpas;Rafael Messias Martins;Ilir Jusufi;Kostiantyn Kucher;Fabrice Rossi;Andreas Kerren", "citationCount": "2", "affiliation": "Chatzimparmpas, A (Corresponding Author), Linnaeus Univ, Dept Comp Sci \\& Media Technol, Vaxjo, Sweden.\nChatzimparmpas, A.; Martins, R. M.; Jusufi, I.; Kucher, K.; Kerren, A., Linnaeus Univ, Dept Comp Sci \\& Media Technol, Vaxjo, Sweden.\nRossi, F., PSL Univ, Univ Paris Dauphine, Ceremade, Paris, France.", "countries": "Sweden;France", "abstract": "Machine learning (ML) models are nowadays used in complex applications in various domains, such as medicine, bioinformatics, and other sciences. Due to their black box nature, however, it may sometimes be hard to understand and trust the results they provide. This has increased the demand for reliable visualization tools related to enhancing trust in ML models, which has become a prominent topic of research in the visualization community over the past decades. To provide an overview and present the frontiers of current research on the topic, we present a State-of-the-Art Report (STAR) on enhancing trust in ML models with the use of interactive visualization. We define and describe the background of the topic, introduce a categorization for visualization techniques that aim to accomplish this goal, and discuss insights and opportunities for future research directions. Among our contributions is a categorization of trust against different facets of interactive ML, expanded and improved from previous research. Our results are investigated from different analytical perspectives: (a) providing a statistical overview, (b) summarizing key findings, (c) performing topic analyses, and (d) exploring the data sets used in the individual papers, all with the support of an interactive web-based survey browser. We intend this survey to be beneficial for visualization researchers whose interests involve making ML models more trustworthy, as well as researchers and practitioners from other disciplines in their search for effective visualization techniques suitable for solving their tasks with confidence and conveying meaning to their data.", "keywords": "trustworthy machine learning; visualization; interpretable machine learning; explainable machine learning", "link": "https://doi.org/10.1111/cgf.14034", "refList": ["10.1109/mcg.2018.2878902", "10.1109/tvcg.2008.153", "10.2312/mlvis.20181130", "10.1109/tvcg.2016.2598828", "10.1145/3290605.3300911", "10.1145/2993901.2993909", "10.2312/mlvis.20191158", "10.1109/tvcg.2016.2598446", "10.1111/j.1467-8659.2009.01475.x", "10.1145/3290605.3300809", "10.1109/pacificvis.2018.00031", "10.1055/s-0029-1216348", "10.1007/978-3-319-90403-0\\_13", "10.1109/tvcg.2017.2745085", "10.1111/j.1467-8659.2011.01938.x", "10.1007/978-3-319-54024-5\\_6", "10.1016/s0167-9473(01)00065-2", "10.1111/cgf.12895", "10.2312/eurovisshort.20141152.17", "10.2312/eurova.20151098.22", "10.1111/cgf.13667", "10.3115/1072228.1072378", "10.1109/tbdata.2018.2877350.16", "10.1109/lars.2009.5418323.25", "10.1109/tvcg.2017.2744878", "10.1016/j.combustflame.2005.09.018", "10.1016/j.cag.2014.01.006", "10.1109/tvcg.2016.2570755", "10.2312/mlvis.20191158.1,19", "10.1518/hfes.46.1.50.30392", "10.1145/3301275.3302280", "10.1145/3351095.3372834.1", "10.1016/s0377-2217(01)00264-8", "10.1111/cgf.13424", "10.1007/978-3-319-23485-4\\_53", "10.1007/978-94-007-0753-5\\_3623", "10.1109/tvcg.2013.101", "10.1111/cgf.12884", "10.1111/j.1467-8659.2010.01835.x", "10.1021/ci9901338", "10.4230/lipics.itcs:2017", "10.1109/mis.2013.24", "10.1109/tvcg.2014.2346482", "10.1109/tvcg.2018.2865230", "10.1073/pnas.1807180116", "10.1109/dsaa.2018.00018", "10.1109/tvcg.2009.153", "10.3115/1219840.1219855", "10.1109/tvcg.2018.2864812", "10.1109/tvcg.2018.2872577", "10.2312/trvis.20191183", "10.1109/cvpr:2004.383", "10.1109/vast.2008.4677350", "10.1145/302979.303001", "10.1109/tvcg.2018.2864499", "10.1111/cgf.13672", "10.1109/tvcg.2014.2346626", "10.23915/distill.00010.18", "10.1109/tvcg.2017.2744805", "10.2312/mlvis:20191160.18", "10.23915/distill:00016", "10.1109/pacificvis.2016.7465260", "10.1111/cgf.13683", "10.23915/distill.00016.19", "10.1145/32906053.300803.22", "10.1109/tvcg.2014.2346574", "10.1177/1473871615600010", "10.1109/tvcg.2016.2598831", "10.1145/3230623", "10.1109/visual.2019.8933744", "10.1145/2993901.2993915", "10.1016/j.visinf.2017.01.006", "10.1145/2993901.2993914", "10.1109/tvcg.2014.2346984", "10.1109/5.726791", "10.23915/distill.00010", "10.1109/tvcg.2018.2864825", "10.2307/2394164", "10.1109/tvcg.2017.2744458", "10.1145/2993901.2993917.28", "10.1111/cgf.13711", "10.1109/tvcg.2016.2598664", "10.2307/2530428", "10.1109/icdar.1997.620583", "10.1109/tvcg.2017.2744718", "10.1111/cgf.13425", "10.1109/tvcg.2019.2903943", "10.1145/1518701.1518895", "10.1109/tvcg.2018.2864838", "10.1145/62038.62043", "10.1111/j.1467-8659.2011.01920.x", "10.1145/3025171.3025208", "10.1145/355112.355124", "10.1109/vast.2010.5652398", "10.1109/tvcg.2014.2346578", "10.1145/3173574.3174209", "10.4178/epih/e2014008", "10.1109/beliv.2018.8634201.25,28", "10.1016/j.eswa.2007.12.020", "10.1111/cgf:13406", "10.1109/mcg.2011.103", "10.1631/fitee.1700808", "10.1109/tvcg.2017.2745158", "10.1073/pnas.0307752101", "10.1109/tvcg.2018.2816223", "10.1109/tvcg.2017.2745141", "10.1145/32232.32234", "10.1109/tvcg.2019.2934267", "10.1109/tvcg.2018.2864477", "10.1145/3132169", "10.2312/eurova.20151100.19", "10.1145/3172944.3172964", "10.1145/2601248.2601268", "10.1109/isai-nlp.2018.8693002.1", "10.1111/cgf.13404", "10.1007/s100320200071", "10.2312/trvis.20191183.16", "10.1111/cgf.12755", "10.1145/2702123.2702509", "10.1145/1401890.1402008.25", "10.1109/tvcg.2012.65", "10.1177/1473871617733996", "10.2312/trvis.20191187.7", "10.21236/ada273556", "10.1109/vast.2010.5652450", "10.1111/j.1467-8659.2011.01940.x", "10.1177/875647939000600106", "10.1109/tvcg.2017.2711030", "10.1016/j.immuni.2016.04.014", "10.1109/tvcg.2019.2934209", "10.1016/0095-0696(78)90006-2", "10.1016/j.jclinepi.2015.04.014", "10.1016/j.ress.2013.02.013", "10.1111/cgf.12640", "10.1145/1015330.1015388.25", "10.1111/j.1467-8659.2009.01468.x", "10.1145/1541880.1541882", "10.1109/vast.2011.6102453", "10.1016/s0008-8846(98)00165-3", "10.2312/trvis.20191186.7", "10.1007/s13748-013-0040-3", "10.1109/tvcg.2015.2467757", "10.1109/tbdata.2018.2877350", "10.1109/vast.2017.8585613", "10.1080/10556789208805504", "10.1109/vast.2012.6400484", "10.1145/3025171.3025181", "10.1007/978-3-319-90403-0\\_12", "10.1109/mcg.2019.2922592", "10.1021/ci000392t", "10.1109/vast.2007.4389000", "10.1111/cgf.13406.16", "10.1111/cgf.13684", "10.2312/eurovisshort.20161166.17", "10.2312/evs:20191168", "10.1145/3041021.3055135", "10.1145/3301275.3302265", "10.1613/jair.4135", "10.1109/tvcg.2018.2864500", "10.1109/tvcg.2017.2744158", "10.1109/ssci.2015.33", "10.1111/cgf.13453", "10.2312/pe/eurovast/eurova11/049-052", "10.1145/3025171.3025181.13", "10.1145/371920.372094", "10.1109/tvcg.2017.2744938", "10.1111/j.1467-8659.2012.03108.x", "10.1109/tvcg.2019.2934251", "10.1145/3290605.3300809.18", "10.1109/ldav.2016.7874305", "10.1109/vast.2016.7883514", "10.1109/iccv.2015.425", "10.1145/3301275.3302324", "10.1109/tnnls.2013.2292894", "10.1109/tvcg.2018.2865044", "10.1109/tvcg.2013.157", "10.1371/journal.pcbi.0020161", "10.1186/s12916-019-1426-2", "10.1109/10.867928", "10.1111/cgf.13217", "10.1109/mcg.2019.2919033", "10.1145/2993901.2993910", "10.1109/tvcg.2017.2744738", "10.2307/258792", "10.1111/cgf.12655", "10.1016/j.dss.2014.03.001", "10.1109/tvcg.2019.2904069", "10.1111/cgf.13205", "10.1002/mds.22340", "10.1109/tvcg.2019.2934595", "10.1287/inte.2018.0957", "10.1109/cvpr.2007.382974", "10.1109/tvcg.2012.280", "10.1145/2678025.2701399.13", "10.2312/mlvis.20181130.13", "10.2312/eurova.20181106.16", "10.1109/tvcg.2018.2864475", "10.2312/mlvis.20191160.18,22", "10.1007/978-1-4612-4026-6.25", "10.1109/cvpr.2006.42", "10.1145/3172944.3172950", "10.1109/cvpr.2004.383.25", "10.1109/tvcg.2019.2934812", "10.1609/aimag.v35i4.2513", "10.2312/trvis.20191185.7", "10.1111/j.1467-8659.2009.01684.x", "10.1371/journal.pone.0129126", "10.1111/cgf.13092", "10.1162/coli\\_a\\_00237", "10.1109/tvcg.2017.2744818", "10.1109/vast.2011.6102448", "10.1109/tvcg.2009.111", "10.1109/tvcg.2019.2934619", "10.1016/s0377-2217(01)00264-8.25", "10.1111/cgf.12639", "10.1109/access.2019.2919343", "10.1186/s12874-019-0681-4", "10.1109/pacificvis.2015.7156366", "10.1109/pacificvis.2018.00029", "10.1109/tvcg.2019.2934261", "10.1080/13506280444000102.http://www.uvt.nl/ticc", "10.1109/vast.2018.8802509", "10.1111/cgf.13212", "10.1145/3200489", "10.1111/cgf.13176", "10.1177/1473871620904671", "10.1007/978-3-319-10590-1\\_53", "10.1111/j.1467-8659.2012.03126.x", "10.1111/cgf.13172", "10.1145/3025171.3025208.6,21", "10.1111/cgf.12366", "10.1109/tvcg.2019.2934659", "10.1109/cvprw.2009.5206848", "10.1016/j.media.2014.11.010", "10.1109/tvcg.2017.2744683", "10.1109/tvcg.2019.2934262", "10.1016/j.neucom.2006.11.018", "10.1177/1473871615571951", "10.1371/journal.pcbi.0020161.25", "10.1177/1473871611415994", "10.2312/trvis20191187", "10.2312/eurova", "10.1145/2858036.2858529", "10.1145/2207676.2207738", "10.1007/s11042-009-0417-2", "10.1145/3301275.3302317", "10.1038/s41746-019-0148-3", "10.1145/3351095.3372834", "10.1080/10691898.2011.11889627", "10.1109/tvcg.2018.2864504", "10.1109/vast.2017.8585720", "10.1109/mcg.2018.053491732", "10.1007/s10994-010-5207-6", "10.1109/tvcg.2019.2934433", "10.1016/j.cag.2017.05.005", "10.1109/tvcg.2012.279", "10.1145/3231622.3231641.19,20", "10.1145/1562849.1562851", "10.1007/11564126\\_", "10.1109/tvcg.2018.2846735", "10.3115/1225403.1225421", "10.1109/vast.2012.6400486", "10.2312/eurova.20191116.22", "10.1109/tvcg.2007.70443", "10.1080/027868291009242", "10.2312/eurova.20151100", "10.1145/2939502.2939503.19", "10.1016/j.cag.2014.02.004", "10.1145/2939672.2939778", "10.1109/vast.2010.5652484", "10.1111/cgf.12641", "10.1145/3301275.3302289", "10.1109/visual.2019.8933619", "10.1109/tvcg.2017.2672987", "10.1109/vast.2016.7883517.20", "10.1109/igarss.2017.8127684", "10.1016/j.jcae.2010.04.002", "10.1109/vast.2010.5652885", "10.1016/j.visinf.2019.03.002", "10.1007/s00371-018-1500-3", "10.1109/mcg.2018.042731661", "10.1109/34.598228", "10.1109/tvcg.2018.2865027", "10.1016/j.neucom.2017.01.105", "10.1111/cgf.12389", "10.1109/tvcg.2019.2934591", "10.1109/vast.2010.5652392.16", "10.1111/cgf.13416", "10.1080/02701367.1992.10608764", "10.1109/vast.2017.8585721", "10.1109/tvcg.2018.2843369", "10.1109/sbes.2010.27", "10.1109/vast.2015.7347637", "10.1145/1401890.1402008", "10.1016/j.bpj.2010.04.064", "10.1109/tvcg.2013.125", "10.1109/isai-nlp.2018.8693002", "10.1371/journal.pone.0160127", "10.1145/2856767.2856779", "10.1145/2678025.2701399", "10.1109/vast.2011.6102451", "10.1109/mcg.2010.18", "10.1021/ci4000213", "10.1109/vast.2012.6400492", "10.1007/11564126-49.25", "10.2312/eurova.20171114", "10.1109/vast.2010.5652443", "10.1145/3134599", "10.2312/pe/eurovast/eurovast10/013-018.19", "10.1109/tvcg.2019.2903946", "10.1109/tvcg.2015.2467717", "10.1177/1473871612460526", "10.1016/j.cag.2018.09.018", "10.1109/tvcg.2016.2598838", "10.1145/3172944.3172964.14", "10.1109/vast.2009.5333428", "10.1109/vast.2014.7042480", "10.2312/pe/eurovast/eurovast10/013-018", "10.1177/0962280215588241", "10.1145/2993901.2993917", "10.1109/cvpr.2008:4587581", "10.1109/tvcg.2015.2467551", "10.1016/j.visinf.2018.09.001", "10.1126/science.290.5500.2319", "10.2312/eurova.20151107", "10.1109/visual.2019.8933695", "10.13140/2.1.2393.1847", "10.1197/jamia.m1929", "10.1109/cvpr.2008.4587581.25", "10.1145/1518701.1518895.16", "10.1109/vds.2017.8573444", "10.2312/trvis:20191185", "10.1145/3359786", "10.13140/2.1.1341.1520", "10.2312/pe/eurovast/eurova11/049-052.17", "10.1109/tvcg.2014.2346660", "10.1145/3185517", "10.1109/adprl.2011.5967372", "10.1109/tvcg.2015.2467591", "10.1111/j.1751-9004.2009.00232.x", "10.1136/qshc.2004.010033", "10.1109/vast.2012.6400493", "10.1109/tvcg.2019.2934266", "10.1145/2971763.2971775", "10.1111/cgf.13730", "10.1109/vast.2012.6400488", "10.1111/cgf.13210", "10.1109/tvcg.2019.2934631", "10.1145/3172944.3172965", "10.1057/ivs.2010.2", "10.1109/tvcg.2017.2745258", "10.1016/j.jbusres.2019.07.039", "10.1162/jmlr.2003.3.4-5.993", "10.1109/pacificvis.2019.00044", "10.2312/pe/eurovast/eurova12/037-041", "10.1109/tvcg.2019.2934629", "10.1177/0018720814547570", "10.1145/3292500.3330908", "10.1111/j.1467-8659.2009.01467.x", "10.2312/eurova.20151098", "10.1177/1473871617713337", "10.1109/lars:2009.5418323", "10.1109/vast.2011.6102437", "10.1111/cgf.12878", "10.1561/1500000001", "10.1145/3025171.3025222", "10.1007/s11704-016-6028-y", "10.1016/j.procs.2017.05.216", "10.1109/cvpr.2007.382974.25", "10.1080/10447318.2020.1741118", "10.1109/vast.2012.6400489", "10.1145/3025171.3025172", "10.1109/tvcg.2017.2744098", "10.1109/tvcg.2005.66", "10.1016/j.dss.2009.05.016", "10.1007/978-1-4612-4026-6", "10.2312/evs.20191168.16,20,28", "10.2312/pe/eurovast/eurova12/037-041.17", "10.1145/3290605.3300803", "10.1145/1015330.1015388", "10.1111/cgf.13197", "10.1016/b978-1-55860-377-6.50048-7", "10.1111/cgf.13681", "10.1109/tvcg.2017.2744378", "10.1109/tvcg.2017.2744358", "10.1109/vast.2008.4677352"], "wos": 1, "children": [{"doi": "10.1109/tvcg.2020.3030368", "title": "Implicit Multidimensional Projection of Local Subspaces", "year": "2020", "conferenceName": "InfoVis", "authors": "Rongzheng Bian;Yumeng Xue;Liang Zhou;Jian Zhang 0070;Baoquan Chen;Daniel Weiskopf;Yunhai Wang", "citationCount": "1", "affiliation": "Wang, YH (Corresponding Author), Shandong Univ, Qingdao, Peoples R China. Zhou, L (Corresponding Author), Univ Utah, Salt Lake City, UT 84112 USA. Bian, Rongzheng; Xue, Yumeng; Wang, Yunhai, Shandong Univ, Qingdao, Peoples R China. Chen, Baoquan, Peking Univ, Beijing, Peoples R China. Zhang, Jian, Chinese Acad Sci, CNIC, Beijing, Peoples R China. Zhou, Liang, Univ Utah, Salt Lake City, UT 84112 USA. Weiskopf, Daniel, Univ Stuttgart, Stuttgart, Germany.", "countries": "USA;Germany;China", "abstract": "We propose a visualization method to understand the effect of multidimensional projection on local subspaces, using implicit function differentiation. Here, we understand the local subspace as the multidimensional local neighborhood of data points. Existing methods focus on the projection of multidimensional data points, and the neighborhood information is ignored. Our method is able to analyze the shape and directional information of the local subspace to gain more insights into the global structure of the data through the perception of local structures. Local subspaces are fitted by multidimensional ellipses that are spanned by basis vectors. An accurate and efficient vector transformation method is proposed based on analytical differentiation of multidimensional projections formulated as implicit functions. The results are visualized as glyphs and analyzed using a full set of specifically-designed interactions supported in our efficient web-based visualization tool. The usefulness of our method is demonstrated using various multi- and high-dimensional benchmark datasets. Our implicit differentiation vector transformation is evaluated through numerical comparisons; the overall method is evaluated through exploration examples and use cases.", "keywords": "High-dimensional data visualization,dimensionality reduction,local linear subspaces,user interaction", "link": "http://dx.doi.org/10.1109/TVCG.2020.3030368", "refList": ["10.3844/jcssp.2018.613.622", "10.1016/j.aci.2018.08.003", "10.3390/info9030065", "10.1016/j.visinf.2018.09.003", "10.1371/journal.pone.0118432", "10.1016/s0893-6080(05)80023-1", "10.1109/tvcg.2020.2986996", "10.1109/icst.2012.56", "10.1007/s10844-013-0250-y", "10.1109/tbdata.2018", "10.1145/1125451.1125659", "10.1109/tvcg.2013.125", "10.1177/1473871611412817", "10.1145/3290605.3300911", "10.1111/cgf.14034", "10.1007/s13721-013-0034-x", "10.1016/j.procs.2017.05.216", "10.1016/j.ins.2009.08.025", "10.1109/tvcg.2013.124", "10.1109/tvcg.2018.2864499", "10.1109/tvcg.2018.2864475", "10.1080/10447318.2020.1741118", "10.1016/j.imu.2019.100203", "10.1109/tvcg.2018.2865240", "10.1186/s12864-019-6413-7", "10.1109/tvcg.2015.2467551", "10.1002/widm.1249", "10.1007/978-3-319-66429-3\\_29", "10.1109/tvcg.2014.2346481", "10.1109/tvcg.2018.2864825", "10.1177/1473871620904671", "10.1109/tvcg.2019.2934267", "10.1136/bmjopen-2016-012799", "10.1109/smartgridcomm.2017.8340682", "10.1007/s10664-015-9401-9", "10.1145/1143844.1143874", "10.1111/cgf.12389", "10.1109/tvcg.2018.2872577", "10.1007/978-981-13-5802-9\\_20", "10.1016/j.ipm.2009.03.002", "10.5220/0006431602160222", "10.1109/mcg.2015.50", "10.1109/tvcg.2014.2346574", "10.1007/bf02289565", "10.1109/tvcg.2017.2744378", "10.1016/j.patrec.2008.08.010", "10.1023/a:1010933404324", "10.9735/2229-3981"], "wos": 1, "children": [], "len": 1}, {"doi": "10.1109/tvcg.2020.3030465", "title": "Visual Causality Analysis of Event Sequence Data", "year": "2020", "conferenceName": "VAST", "authors": "Zhuochen Jin;Shunan Guo;Nan Chen;Daniel Weiskopf;David Gotz;Nan Cao", "citationCount": "0", "affiliation": "Cao, N (Corresponding Author), Tongji Univ, IDVx Lab, Shanghai, Peoples R China. Jin, Zhuochen; Guo, Shunan; Chen, Nan; Cao, Nan, Tongji Univ, IDVx Lab, Shanghai, Peoples R China. Weiskopf, Daniel, Univ Stuttgart, Stuttgart, Germany. Gotz, David, Univ N Carolina, Chapel Hill, NC 27515 USA.", "countries": "USA;Germany;China", "abstract": "Causality is crucial to understanding the mechanisms behind complex systems and making decisions that lead to intended outcomes. Event sequence data is widely collected from many real-world processes, such as electronic health records, web clickstreams, and financial transactions, which transmit a great deal of information reflecting the causal relations among event types. Unfortunately, recovering causalities from observational event sequences is challenging, as the heterogeneous and high-dimensional event variables are often connected to rather complex underlying event excitation mechanisms that are hard to infer from limited observations. Many existing automated causal analysis techniques suffer from poor explainability and fail to include an adequate amount of human knowledge. In this paper, we introduce a visual analytics method for recovering causalities in event sequence data. We extend the Granger causality analysis algorithm on Hawkes processes to incorporate user feedback into causal model refinement. The visualization system includes an interactive causal analysis framework that supports bottom-up causal exploration, iterative causal verification and refinement, and causal comparison through a set of novel visualizations and interactions. We report two forms of evaluation: a quantitative evaluation of the model improvements resulting from the user-feedback mechanism, and a qualitative evaluation through case studies in different application domains to demonstrate the usefulness of the system.", "keywords": "Event sequence data,causality analysis,visual analytics", "link": "http://dx.doi.org/10.1109/TVCG.2020.3030465", "refList": ["10.5555/1642718", "10.1109/tvcg.2018.2865022", "10.5555/2074094.2074151", "10.1109/tvcg.2016.2618797", "10.1073/pnas.1320645111", "10.1109/tvcg.2017.2744843", "10.1109/iv.2017.69", "10.1109/tvcg.2019.2934399", "10.1145/3172944.3173007", "10.5555/1795555", "10.1109/mcg.2005.102", "10.1145/381641.381653", "10.1162/153244301753344614", "10.1111/cgf.14034", "10.1111/cgf.13198", "10.1017/cbo9780511519857", "10.1007/s10462-016-9475-9", "10.1075/ssol.2.2.07bor", "10.1007/978-1-4614-3223-4\\_3", "10.1109/infvis.2003.1249025", "10.1007/978-94-007-6094-313", "10.1145/2858036.2858387", "10.1109/tvcg.2007.70528", "10.1109/tvcg.2017.2674958", "10.1147/sj.454.0801", "10.1109/tvcg.2013.119", "10.1145/3173574.3173711", "10.1016/j.erss.2017.06.034", "10.1109/visual.2019.8933695", "10.1007/s11665-016-2173-6", "10.1016/0377-0427(87)90125-7", "10.2307/3601125", "10.1016/b978-0-444-88738-2.50018-x", "10.1109/mcg.2006.70", "10.1109/tvcg.2018.2865145", "10.1017/s1351324997001502", "10.1109/tvcg.2010.179", "10.1214/aos/1176344552", "10.1109/mcg.2009.22", "10.1007/978-3-319-26633-6\\_13", "10.1080/10447318.2014.905422", "10.1016/j.visinf.2019.03.004", "10.1057/palgrave.ivs.9500074", "10.1007/978-1-4614-3223-4"], "wos": 1, "children": [], "len": 1}], "len": 5}, {"doi": "10.1111/cgf.14031", "year": "2020", "title": "The State of the Art in Map-Like Visualization", "conferenceName": "EuroVis", "authors": "Marius Hogr{\\\"{a}}fer;Magnus Heitzler;Hans{-}J{\\\"{o}}rg Schulz", "citationCount": "0", "affiliation": "Hografer, M (Corresponding Author), Aarhus Univ, Dept Comp Sci, Aarhus, Denmark.\nHografer, Marius; Schulz, Hans-Jorg, Aarhus Univ, Dept Comp Sci, Aarhus, Denmark.\nHeitzler, Magnus, Swiss Fed Inst Technol, Inst Cartog \\& Geoinformat, Zurich, Switzerland.", "countries": "Switzerland;Denmark", "abstract": "Cartographic maps have been shown to provide cognitive benefits when interpreting data in relation to a geographic location. In visualization, the term map-like describes techniques that incorporate characteristics of cartographic maps in their representation of abstract data. However, the field of map-like visualization is vast and currently lacks a clear classification of the existing techniques. Moreover, choosing the right technique to support a particular visualization task is further complicated, as techniques are scattered across different domains, with each considering different characteristics as map-like. In this paper, we give an overview of the literature on map-like visualization and provide a hierarchical classification of existing techniques along two general perspectives: imitation and schematization of cartographic maps. Each perspective is further divided into four principal categories that group common map-like techniques along the visual primitives they affect. We further discuss this classification from a task-centered view and highlight open research questions.", "keywords": "", "link": "https://doi.org/10.1111/cgf.14031", "refList": ["10.1111/j.0020-2754.1998.00269.x.21", "10.1109/iv.2005.26", "10.2307/2980460", "10.1109/tvcg.2017.2743959", "10.1016/j.jvlc.2011.11.004", "10.1145/2501988.2502046", "10.1559/1523040042742402", "10.1007/s00779-011-0500-3", "10.1111/cgf.12932", "10.1109/tvcg.2010.89", "10.1111/cgf.13200", "10.1080/15230406.2016.1160797", "10.1179/000870410x12825500202896", "10.1109/tvcg.2007.70596", "10.5167/80972.19uzh-80972", "10.1007/978-3-319-11593-1\\_2", "10.1037/aca0000175", "10.1080/17538947.2014.923942", "10.1109/tvcg.2015.2467321", "10.1109/vissof.2005.1684299", "10.1559/152304098782383034", "10.1007/978-3-642-36763-2\\_38", "10.1109/tvcg.2013.130", "10.1109/tvcg.2014.2346274", "10.1111/cgf.12648", "10.1111/0004-5608.00242", "10.1177/1473871617724212", "10.1109/iv.2004.1320123", "10.1371/journal.pcbi.1006907", "10.1109/tvcg.2016.2599030", "10.1559/1523040042742411", "10.3390/informatics5030031", "10.1111/cgf.13079", "10.1109/tvcg.2015.2467811", "10.1016/j.tics.2003.12.004", "10.1007/s00799-016-0168-4", "10.1109/infvis.2004.57", "10.1007/s10021-007-9038-7", "10.1109/pacificvis.2015.7156366", "10.1007/978-3-319-27261-0\\_1", "10.1007/978-1-4471-2804-5\\_6", "10.1109/access.2019.2939977", "10.1109/tvcg.2017.2747545", "10.1109/icdm.2003.1250978", "10.1111/cgf.13167", "10.1016/0010-0285(78)90006-3", "10.3138/nj8v-8514-871t-221k", "10.1016/j.cag.2009.06.002", "10.1111/j.1467-8659.2011.01937.x", "10.1016/b978-044451020-4/50035-9", "10.1111/1467-8659.00566", "10.5220/0006618101080119", "10.1109/pacificvis.2012.6183571", "10.1145/2038558.2038579", "10.1109/tvcg.2010.191", "10.1111/j.0033-0124.1985.00075.x", "10.1109/tvcg.2004.1260761", "10.1007/978-3-642-34848-8\\_6", "10.1145/2968220.2968239", "10.1145/3002151.3002160", "10.1109/tst.2013.6509098", "10.1109/tvcg.2013.91", "10.1177/1473871615597077", "10.1016/j.jvlc.2011.02.001", "10.1080/17445647.2014.935502", "10.1177/1687814017740710", "10.1111/1744-7917.12601", "10.1073/pnas.0400280101", "10.1111/cgf.13672", "10.1109/mcg.2006.90", "10.1002/asi.21712", "10.1007/978-3-642-33024-7\\_3", "10.1145/2801040.2801056", "10.1109/mcg.2010.101", "10.1179/003962607x165041", "10.1057/palgrave.ivs.9500039", "10.1109/vast.2016.7883510", "10.1559/152304009788988288", "10.1080/23729333.2017.1301346", "10.1109/tvcg.2013.66", "10.1111/j.1467-8659.2012.03085.x", "10.1109/tvcg.2011.288", "10.3390/ijgi9040253", "10.1109/infvis.2005.1532150", "10.1145/2254556.2254636", "10.20382//jocg.v4i1a9", "10.1016/0010-0285(81)90016-5", "10.1145/2556288.2557224", "10.1109/iv.2001.942043", "10.1021/ed1000203", "10.1016/0169-7439(87)80084-9", "10.1109/tvcg.2010.154", "10.1016/j.jvlc.2015.10.003", "10.1109/tvcg.2019.2903945", "10.1109/tvcg.2013.120", "10.1109/tvcg.2019.2934263", "10.1146/annurev-ecolsys-102209-144718", "10.1109/tvcg.2008.165", "10.3138/a477-3202-7876-n514", "10.1080/23729333.2017.1288535", "10.1111/j.0020-2754.1998.00269.x", "10.1109/mcg.2004.41", "10.1109/vast.2009.5332593", "10.1002/smr.414", "10.1007/s12650-019-00584-3", "10.1145/22949.22950", "10.1179/1743277413y.0000000036", "10.1080/15230406.2016.1262280", "10.1016/s0341-8162(01)00164-3", "10.22224/gistbok/2017.3.8", "10.1109/tvcg.2008.155", "10.1057/ivs.2008.31", "10.1016/j.cag.2004.03.012", "10.1179/1743277412y.0000000007", "10.1016/j.soncn.2011.02.001", "10.1179/caj.1987.24.1.27", "10.3138/carto.48.3.1691", "10.5220/0004267205150524", "10.1109/38.974518", "10.1145/102377.115768", "10.1057/palgrave.ivs.9500186", "10.1109/5.58325", "10.5167/80972.uzh-80972", "10.1177/030913339602000204", "10.1007/978-3-642-22300-6\\_14", "10.1109/iv.2004.1320189", "10.1111/cgf.13447", "10.1007/s11192-017-2596-3", "10.1559/1523040053722150", "10.1007/978-3-662-45803-7\\_34"], "wos": 1, "children": [], "len": 1}, {"doi": "10.1111/cgf.13211", "year": "2017", "title": "Social Media Visual Analytics", "conferenceName": "EuroVis", "authors": "Siming Chen;Lijing Lin;Xiaoru Yuan", "citationCount": "29", "affiliation": "Chen, SM (Corresponding Author), Peking Univ, Minist Educ, Key Lab Machine Percept, Beijing, Peoples R China.\nChen, SM (Corresponding Author), Peking Univ, Sch EECS, Beijing, Peoples R China.\nChen, Siming; Lin, Lijing; Yuan, Xiaoru, Peking Univ, Minist Educ, Key Lab Machine Percept, Beijing, Peoples R China.\nChen, Siming; Lin, Lijing; Yuan, Xiaoru, Peking Univ, Sch EECS, Beijing, Peoples R China.", "countries": "China", "abstract": "With the development of social media (e.g. Twitter, Flickr, Foursquare, Sina Weibo, etc.), a large number of people are now using them and post microblogs, messages and multi-media information. The everyday usage of social media results in big open social media data. The data offer fruitful information and reflect social behaviors of people. There is much visualization and visual analytics research on such data. We collect state-of-the-art research and put it into three main categories: social network, spatial temporal information and text analysis. We further summarize the visual analytics pipeline for the social media, combining the above categories and supporting complex tasks. With these techniques, social media analytics can apply to multiple disciplines. We summarize the applications and public tools to further investigate the challenges and trends.", "keywords": "", "link": "https://doi.org/10.1111/cgf.13211", "refList": ["10.1016/j.cag.2013.11.003", "10.1109/vast.2010.5652922", "10.1007/s12650-015-0277-y", "10.1007/978-3-540-70956-5", "10.1007/s00146-014-0549-4", "10.1109/tmm.2014.2340133", "10.1109/tmm.2015.2510329", "10.1057/palgrave.ivs.9500116", "10.1109/tvcg.2010.129", "10.1109/tvcg.2016.2598590", "10.1145/2065023.2065041", "10.1109/tvcg.2013.162", "10.1145/1963405.1963504", "10.1177/1473871613490678", "10.1007/978-0-85729-436-4\\_9", "10.1145/2488388.2488504", "10.1109/bigdata.2015.7363826", "10.1109/tvcg.2009.171", "10.1109/tvcg.2012.291", "10.1109/vast.2012.6400485", "10.1109/tvcg.2014.2371856", "10.1145/2089094.2089102", "10.1109/tvcg.2014.2346919", "10.1109/tvcg.2014.2346433", "10.1109/tvcg.2015.2509990", "10.1109/pacificvis.2015.7156366", "10.1016/j.jocs.2010.12.007", "10.1109/tvcg.2011.169", "10.1109/tvcg.2015.2467619", "10.1016/j.cag.2013.10.008", "10.1007/978-3-319-06793-3\\_3", "10.1109/tmm.2009.2012912", "10.1109/pacificvis.2015.7156367", "10.1109/tvcg.2014.2346922", "10.1371/journal.pone.0101837", "10.1109/tmm.2015.2425143", "10.1145/2493102.2493108", "10.1109/tvcg.2015.2467196", "10.1109/tvcg.2013.196", "10.1109/mcg.2014.61", "10.1109/pacificvis.2016.7465266", "10.1109/tvcg.2006.160", "10.1057/palgrave.ivs.9500092", "10.1016/j.giq.2012.06.002", "10.1016/b978-0-12-382229-1.00002-3", "10.1109/vast.2016.7883510", "10.1111/j.1467-8659.2012.03120.x", "10.1109/tmm.2016.2614220", "10.7155/jgaa.00302", "10.1109/tvcg.2014.2346920", "10.1109/vast.2015.7347631", "10.1371/journal.pone.0095043", "10.1109/vast.2014.7042495", "10.1511/2001.4.344", "10.1109/vast.2012.6400557", "10.1109/pacificvis.2012.6183572", "10.1145/2567948.2577020", "10.1016/j.joi.2014.07.006", "10.1111/j.1467-8659.2009.01687.x", "10.1145/2801040.2801054", "10.1016/j.bushor.2009.09.003", "10.1109/infvis.2000.885098", "10.1109/ldav.2013.6675163", "10.1007/s13218-012-0177-4", "10.1080/13658816.2013.825724", "10.1109/tvcg.2007.70582", "10.1109/mc.2013.152", "10.1109/vast.2014.7042496", "10.1109/vast.2011.6102456", "10.1145/2733373.2806236", "10.1109/tvcg.2013.221", "10.1177/1473871615576925", "10.1109/vast.2016.7883513", "10.1109/tvcg.2013.186", "10.1109/mc.2012.430", "10.1109/tvcg.2015.2467554", "10.1109/pacificvis.2014.48", "10.1145/2212776.2212796", "10.1109/tvcg.2006.107", "10.1109/pacificvis.2014.38", "10.1109/pacificvis.2015.7156376", "10.1109/vast.2014.7042535", "10.1109/tvcg.2014.2359887"], "wos": 1, "children": [{"doi": "10.1109/vast.2017.8585638", "title": "E-Map: A Visual Analytics Approach for Exploring Significant Event Evolutions in Social Media", "year": "2017", "conferenceName": "VAST", "authors": "Siming Chen;Shuai Chen;Lijing Lin;Xiaoru Yuan;Jie Liang 0004;Xiaolong Zhang", "citationCount": "10", "affiliation": "Yuan, XR (Corresponding Author), Peking Univ, Key Lab Machine Percept, Minist Educ, Beijing, Peoples R China. Yuan, XR (Corresponding Author), Peking Univ, Sch EECS, Beijing, Peoples R China. Chen, Siming; Chen, Shuai; Lin, Lijing; Yuan, Xiaoru, Peking Univ, Key Lab Machine Percept, Minist Educ, Beijing, Peoples R China. Chen, Siming; Chen, Shuai; Lin, Lijing; Yuan, Xiaoru, Peking Univ, Sch EECS, Beijing, Peoples R China. Liang, Jie, Univ Technol, Fac Engn \\& Informat Technol, Sydney, NSW, Australia. Zhang, Xiaolong, Penn State Univ, Coll Informat Sci \\& Technol, University Pk, PA 16802 USA.", "countries": "USA;China;Australia", "abstract": "Significant events are often discussed and spread through social media, involving many people. Reposting activities and opinions expressed in social media offer good opportunities to understand the evolution of events. However, the dynamics of reposting activities and the diversity of user comments pose challenges to understand event-related social media data. We propose E-Map, a visual analytics approach that uses map-like visualization tools to help multi-faceted analysis of social media data on a significant event and in-depth understanding of the development of the event. E-Map transforms extracted keywords, messages, and reposting behaviors into map features such as cities, towns, and rivers to build a structured and semantic space for users to explore. It also visualizes complex posting and reposting behaviors as simple trajectories and connections that can be easily followed. By supporting multi-level spatial temporal exploration, E-Map helps to reveal the patterns of event development and key players in an event, disclosing the ways they shape and affect the development of the event. Two cases analysing real-world events confirm the capacities of E-Map in facilitating the analysis of event evolution with social media data.", "keywords": "Social Media,Event Analysis,Map-like Visual Metaphor,Spatial Temporal Visual Analytics", "link": "http://dx.doi.org/10.1109/VAST.2017.8585638", "refList": ["10.1109/tvcg.2007.70582", "10.1109/tvcg.2016.2598919", "10.1109/pacificvis.2010.5429590", "10.1057/ivs.2008.23", "10.1109/vast.2014.7042496", "10.1016/j.cag.2013.11.003", "10.1109/vast.2011.6102456", "10.1109/tvcg.2013.221", "10.1109/tvcg.2011.185", "10.1109/vast.2016.7883510", "10.1111/j.1467-8659.2012.03120.x", "10.1109/tvcg.2013.186", "10.1109/tmm.2016.2614220", "10.7155/jgaa.00302", "10.1109/mc.2012.430", "10.1109/tvcg.2015.2467619", "10.1109/tvcg.2010.129", "10.1016/s0341-8162(01)00164-3", "10.1109/tvcg.2016.2598590", "10.1145/2065023.2065041", "10.1111/cgf.13211", "10.1109/tvcg.2013.162", "10.1109/tvcg.2011.288", "10.1145/1963405.1963504", "10.5670/oceanog.2016.66", "10.1109/tvcg.2015.2467554", "10.1109/tvcg.2015.2467691", "10.1016/j.cag.2013.10.008", "10.1109/mcg.2015.73", "10.1109/vast.2012.6400557", "10.1109/tvcg.2016.2539960", "10.1109/tit.1982.1056489", "10.1109/pacificvis.2012.6183572", "10.1109/tvcg.2014.2346922", "10.1109/tmm.2014.2384912", "10.1109/vast.2016.7883511", "10.1002/spe.4380211102", "10.1145/2488388.2488504", "10.2312/eurovisstar.20141176", "10.1109/bigdata.2013.6691714", "10.1109/tvcg.2009.171", "10.1109/tvcg.2013.196", "10.1109/vast.2008.4677356", "10.1145/2207676.2208672", "10.1111/j.1467-8659.2011.01955.x", "10.1109/pacificvis.2014.38", "10.1109/tvcg.2012.291", "10.1109/vast.2012.6400485", "10.1109/pacificvis.2015.7156376", "10.1145/1348549.1348556", "10.1109/vast.2015.7347632", "10.1109/tvcg.2014.2346919", "10.1109/tvcg.2014.2346433"], "wos": 1, "children": [{"doi": "10.1109/tvcg.2019.2934263", "title": "R-Map: A Map Metaphor for Visualizing Information Reposting Process in Social Media", "year": "2019", "conferenceName": "VAST", "authors": "Shuai Chen;Sihang Li;Siming Chen;Xiaoru Yuan", "citationCount": "0", "affiliation": "Yuan, XR (Corresponding Author), Peking Univ, Natl Engn Lab Big Data Anal \\& Applicat, Beijing, Peoples R China. Chen, Shuai; Li, Sihang, Peking Univ, Sch EECS, Minist Educ, Key Lab Machine Petrept, Beijing, Peoples R China. Yuan, Xiaoru, Peking Univ, Natl Engn Lab Big Data Anal \\& Applicat, Beijing, Peoples R China. Chen, Siming, Fraunhofer Inst IAIS, St Augustin, Germany. Chen, Siming, Univ Bonn, Bonn, Germany.", "countries": "Germany;China", "abstract": "We propose R-Map (Reposting Map), a visual analytical approach with a map metaphor to support interactive exploration and analysis of the information reposting process in social media. A single original social media post can cause large cascades of repostings (i.e., retweets) on online networks, involving thousands, even millions of people with different opinions. Such reposting behaviors form the reposting tree, in which a node represents a message and a link represents the reposting relation. In R-Map, the reposting tree structure can be spatialized with highlighted key players and tiled nodes. The important reposting behaviors, the following relations and the semantics relations are represented as rivers, routes and bridges, respectively, in a virtual geographical space. R-Map supports a scalable overview of a large number of information repostings with semantics. Additional interactions on the map are provided to support the investigation of temporal patterns and user behaviors in the information diffusion process. We evaluate the usability and effectiveness of our system with two use cases and a formal user study.", "keywords": "Social Media,Information Diffusion,Map-like Visual Metaphor", "link": "http://dx.doi.org/10.1109/TVCG.2019.2934263", "refList": ["10.1109/infvis.2000.885091", "10.1109/pacificvis.2010.5429590", "10.1111/j.0020-2754.1998.00269.x", "10.1109/vast.2017.8585638", "10.1145/2700398", "10.1109/tmm.2016.2614229", "10.1109/visual.1991.175815", "10.1145/3183347", "10.1109/infvis.2001.963290", "10.1109/vast.2016.7883510", "10.1109/access.2016.2605009", "10.1109/mcg.2011.103", "10.1145/1124772.1124851", "10.1109/tmm.2016.2614220", "10.1109/tvcg.2010.79", "10.1109/infvis.2000.885095", "10.1111/cgf.13211", "10.1109/tvcg.2014.2346920", "10.1002/(sici)1097-0266(199606)17:6", "10.5670/oceanog.2016.66", "10.1559/152304003100011081", "10.1109/tit.1982.1056489", "10.1559/152304098782383034", "10.1109/tvcg.2014.2346922", "10.1007/978-3-540-85567-5\\_9", "10.1145/2488388.2488504", "10.1109/38.974518", "10.1109/bigdata.2013.6691714", "10.1109/pacificvis.2014.38", "10.1109/tvcg.2012.291", "10.1109/infvis.2005.1532128", "10.2307/2685881", "10.1007/1-4020-4179-9\\_91", "10.1109/infvis.1999.801860", "10.1109/asonam.2011.37"], "wos": 1, "children": [{"doi": "10.1111/cgf.14031", "year": "2020", "title": "The State of the Art in Map-Like Visualization", "conferenceName": "EuroVis", "authors": "Marius Hogr{\\\"{a}}fer;Magnus Heitzler;Hans{-}J{\\\"{o}}rg Schulz", "citationCount": "0", "affiliation": "Hografer, M (Corresponding Author), Aarhus Univ, Dept Comp Sci, Aarhus, Denmark.\nHografer, Marius; Schulz, Hans-Jorg, Aarhus Univ, Dept Comp Sci, Aarhus, Denmark.\nHeitzler, Magnus, Swiss Fed Inst Technol, Inst Cartog \\& Geoinformat, Zurich, Switzerland.", "countries": "Switzerland;Denmark", "abstract": "Cartographic maps have been shown to provide cognitive benefits when interpreting data in relation to a geographic location. In visualization, the term map-like describes techniques that incorporate characteristics of cartographic maps in their representation of abstract data. However, the field of map-like visualization is vast and currently lacks a clear classification of the existing techniques. Moreover, choosing the right technique to support a particular visualization task is further complicated, as techniques are scattered across different domains, with each considering different characteristics as map-like. In this paper, we give an overview of the literature on map-like visualization and provide a hierarchical classification of existing techniques along two general perspectives: imitation and schematization of cartographic maps. Each perspective is further divided into four principal categories that group common map-like techniques along the visual primitives they affect. We further discuss this classification from a task-centered view and highlight open research questions.", "keywords": "", "link": "https://doi.org/10.1111/cgf.14031", "refList": ["10.1111/j.0020-2754.1998.00269.x.21", "10.1109/iv.2005.26", "10.2307/2980460", "10.1109/tvcg.2017.2743959", "10.1016/j.jvlc.2011.11.004", "10.1145/2501988.2502046", "10.1559/1523040042742402", "10.1007/s00779-011-0500-3", "10.1111/cgf.12932", "10.1109/tvcg.2010.89", "10.1111/cgf.13200", "10.1080/15230406.2016.1160797", "10.1179/000870410x12825500202896", "10.1109/tvcg.2007.70596", "10.5167/80972.19uzh-80972", "10.1007/978-3-319-11593-1\\_2", "10.1037/aca0000175", "10.1080/17538947.2014.923942", "10.1109/tvcg.2015.2467321", "10.1109/vissof.2005.1684299", "10.1559/152304098782383034", "10.1007/978-3-642-36763-2\\_38", "10.1109/tvcg.2013.130", "10.1109/tvcg.2014.2346274", "10.1111/cgf.12648", "10.1111/0004-5608.00242", "10.1177/1473871617724212", "10.1109/iv.2004.1320123", "10.1371/journal.pcbi.1006907", "10.1109/tvcg.2016.2599030", "10.1559/1523040042742411", "10.3390/informatics5030031", "10.1111/cgf.13079", "10.1109/tvcg.2015.2467811", "10.1016/j.tics.2003.12.004", "10.1007/s00799-016-0168-4", "10.1109/infvis.2004.57", "10.1007/s10021-007-9038-7", "10.1109/pacificvis.2015.7156366", "10.1007/978-3-319-27261-0\\_1", "10.1007/978-1-4471-2804-5\\_6", "10.1109/access.2019.2939977", "10.1109/tvcg.2017.2747545", "10.1109/icdm.2003.1250978", "10.1111/cgf.13167", "10.1016/0010-0285(78)90006-3", "10.3138/nj8v-8514-871t-221k", "10.1016/j.cag.2009.06.002", "10.1111/j.1467-8659.2011.01937.x", "10.1016/b978-044451020-4/50035-9", "10.1111/1467-8659.00566", "10.5220/0006618101080119", "10.1109/pacificvis.2012.6183571", "10.1145/2038558.2038579", "10.1109/tvcg.2010.191", "10.1111/j.0033-0124.1985.00075.x", "10.1109/tvcg.2004.1260761", "10.1007/978-3-642-34848-8\\_6", "10.1145/2968220.2968239", "10.1145/3002151.3002160", "10.1109/tst.2013.6509098", "10.1109/tvcg.2013.91", "10.1177/1473871615597077", "10.1016/j.jvlc.2011.02.001", "10.1080/17445647.2014.935502", "10.1177/1687814017740710", "10.1111/1744-7917.12601", "10.1073/pnas.0400280101", "10.1111/cgf.13672", "10.1109/mcg.2006.90", "10.1002/asi.21712", "10.1007/978-3-642-33024-7\\_3", "10.1145/2801040.2801056", "10.1109/mcg.2010.101", "10.1179/003962607x165041", "10.1057/palgrave.ivs.9500039", "10.1109/vast.2016.7883510", "10.1559/152304009788988288", "10.1080/23729333.2017.1301346", "10.1109/tvcg.2013.66", "10.1111/j.1467-8659.2012.03085.x", "10.1109/tvcg.2011.288", "10.3390/ijgi9040253", "10.1109/infvis.2005.1532150", "10.1145/2254556.2254636", "10.20382//jocg.v4i1a9", "10.1016/0010-0285(81)90016-5", "10.1145/2556288.2557224", "10.1109/iv.2001.942043", "10.1021/ed1000203", "10.1016/0169-7439(87)80084-9", "10.1109/tvcg.2010.154", "10.1016/j.jvlc.2015.10.003", "10.1109/tvcg.2019.2903945", "10.1109/tvcg.2013.120", "10.1109/tvcg.2019.2934263", "10.1146/annurev-ecolsys-102209-144718", "10.1109/tvcg.2008.165", "10.3138/a477-3202-7876-n514", "10.1080/23729333.2017.1288535", "10.1111/j.0020-2754.1998.00269.x", "10.1109/mcg.2004.41", "10.1109/vast.2009.5332593", "10.1002/smr.414", "10.1007/s12650-019-00584-3", "10.1145/22949.22950", "10.1179/1743277413y.0000000036", "10.1080/15230406.2016.1262280", "10.1016/s0341-8162(01)00164-3", "10.22224/gistbok/2017.3.8", "10.1109/tvcg.2008.155", "10.1057/ivs.2008.31", "10.1016/j.cag.2004.03.012", "10.1179/1743277412y.0000000007", "10.1016/j.soncn.2011.02.001", "10.1179/caj.1987.24.1.27", "10.3138/carto.48.3.1691", "10.5220/0004267205150524", "10.1109/38.974518", "10.1145/102377.115768", "10.1057/palgrave.ivs.9500186", "10.1109/5.58325", "10.5167/80972.uzh-80972", "10.1177/030913339602000204", "10.1007/978-3-642-22300-6\\_14", "10.1109/iv.2004.1320189", "10.1111/cgf.13447", "10.1007/s11192-017-2596-3", "10.1559/1523040053722150", "10.1007/978-3-662-45803-7\\_34"], "wos": 1, "children": [], "len": 1}], "len": 3}, {"doi": "10.1109/tvcg.2020.3030411", "title": "Co-Bridges: Pair-wise Visual Connection and Comparison for Multi-item Data Streams", "year": "2020", "conferenceName": "VAST", "authors": "Siming Chen;Natalia V. Andrienko;Gennady L. Andrienko;Jie Li 0006;Xiaoru Yuan", "citationCount": "0", "affiliation": "Yuan, XR (Corresponding Author), Peking Univ, Beijing, Peoples R China. Chen, Siming, Fudan Univ, Sch Data Sci, Shanghai, Peoples R China. Chen, Siming; Andrienko, Natalia; Andrienko, Gennady, Fraunhofer Inst IAIS, St Augustin, Germany. Andrienko, Natalia; Andrienko, Gennady, City Univ London, London, England. Li, Jie, Tianjin Univ, Tianjin, Peoples R China. Yuan, Xiaoru, Peking Univ, Beijing, Peoples R China.", "countries": "Germany;China;England", "abstract": "In various domains, there are abundant streams or sequences of multi-item data of various kinds, e.g. streams of news and social media texts, sequences of genes and sports events, etc. Comparison is an important and general task in data analysis. For comparing data streams involving multiple items (e.g., words in texts, actors or action types in action sequences, visited places in itineraries, etc.), we propose Co-Bridges, a visual design involving connection and comparison techniques that reveal similarities and differences between two streams. Co-Bridges use river and bridge metaphors, where two sides of a river represent data streams, and bridges connect temporally or sequentially aligned segments of streams. Commonalities and differences between these segments in terms of involvement of various items are shown on the bridges. Interactive query tools support the selection of particular stream subsets for focused exploration. The visualization supports both qualitative (common and distinct items) and quantitative (stream volume, amount of item involvement) comparisons. We further propose Comparison-of-Comparisons, in which two or more Co-Bridges corresponding to different selections are juxtaposed. We test the applicability of the Co-Bridges in different domains, including social media text streams and sports event sequences. We perform an evaluation of the users' capability to understand and use Co-Bridges. The results confirm that Co-Bridges is effective for supporting pair-wise visual comparisons in a wide range of applications.", "keywords": "Visual Comparison,Pair-wise Analysis,Multi-item Data Stream,Social Media", "link": "http://dx.doi.org/10.1109/TVCG.2020.3030411", "refList": ["10.1109/tvcg.2014.2346753", "10.1109/pacificvis.2010.5429590", "10.1109/vast.2009.5333443", "10.1101/gr.2289704", "10.1177/1473871611416549", "10.1057/palgrave.ivs.9500099", "10.1109/vast.2017.8585638", "10.1109/vast.2014.7042496", "10.1109/tvcg.2017.2764459", "10.1109/tvcg.2013.221", "10.1109/vast.2011.6102439", "10.1109/tvcg.2013.213", "10.1109/tmm.2016.2614220", "10.1109/tvcg.2016.2598797", "10.1145/2207676.2208556", "10.1145/1835804.1835827", "10.1109/tvcg.2013.124", "10.2312/conf/eg2013/stars/039-063", "10.1111/cgf.13211", "10.1109/tvcg.2014.2346920", "10.1109/tvcg.2011.239", "10.1016/j.jvlc.2018.08.008", "10.1109/mcg.2018.032421661", "10.1109/tvcg.2017.2744199", "10.1109/tvcg.2019.2934535", "10.1109/tvcg.2018.2864526", "10.1007/978-0-85729-436-4\\_9", "10.1109/vast.2016.7883511", "10.1109/tvcg.2014.2346682", "10.1109/tvcg.2015.2467618", "10.1145/2566486.2567977", "10.1109/tvcg.2017.2745320", "10.1080/136588199241247", "10.1111/cgf.13401", "10.1109/tvcg.2018.2864884", "10.1109/tvcg.2012.291", "10.1109/vast.2012.6400485", "10.1109/pacificvis.2016.7465266", "10.1109/tvcg.2011.232", "10.1109/tvcg.2017.2745083", "10.1109/tvcg.2012.253", "10.1007/s12650-014-0246-x", "10.1109/tvcg.2010.20", "10.1109/tvcg.2014.2346919", "10.1109/visual.2019.8933646", "10.1007/978-0-85729-079-3"], "wos": 1, "children": [], "len": 1}], "len": 7}, {"doi": "10.1109/tvcg.2019.2934263", "title": "R-Map: A Map Metaphor for Visualizing Information Reposting Process in Social Media", "year": "2019", "conferenceName": "VAST", "authors": "Shuai Chen;Sihang Li;Siming Chen;Xiaoru Yuan", "citationCount": "0", "affiliation": "Yuan, XR (Corresponding Author), Peking Univ, Natl Engn Lab Big Data Anal \\& Applicat, Beijing, Peoples R China. Chen, Shuai; Li, Sihang, Peking Univ, Sch EECS, Minist Educ, Key Lab Machine Petrept, Beijing, Peoples R China. Yuan, Xiaoru, Peking Univ, Natl Engn Lab Big Data Anal \\& Applicat, Beijing, Peoples R China. Chen, Siming, Fraunhofer Inst IAIS, St Augustin, Germany. Chen, Siming, Univ Bonn, Bonn, Germany.", "countries": "Germany;China", "abstract": "We propose R-Map (Reposting Map), a visual analytical approach with a map metaphor to support interactive exploration and analysis of the information reposting process in social media. A single original social media post can cause large cascades of repostings (i.e., retweets) on online networks, involving thousands, even millions of people with different opinions. Such reposting behaviors form the reposting tree, in which a node represents a message and a link represents the reposting relation. In R-Map, the reposting tree structure can be spatialized with highlighted key players and tiled nodes. The important reposting behaviors, the following relations and the semantics relations are represented as rivers, routes and bridges, respectively, in a virtual geographical space. R-Map supports a scalable overview of a large number of information repostings with semantics. Additional interactions on the map are provided to support the investigation of temporal patterns and user behaviors in the information diffusion process. We evaluate the usability and effectiveness of our system with two use cases and a formal user study.", "keywords": "Social Media,Information Diffusion,Map-like Visual Metaphor", "link": "http://dx.doi.org/10.1109/TVCG.2019.2934263", "refList": ["10.1109/infvis.2000.885091", "10.1109/pacificvis.2010.5429590", "10.1111/j.0020-2754.1998.00269.x", "10.1109/vast.2017.8585638", "10.1145/2700398", "10.1109/tmm.2016.2614229", "10.1109/visual.1991.175815", "10.1145/3183347", "10.1109/infvis.2001.963290", "10.1109/vast.2016.7883510", "10.1109/access.2016.2605009", "10.1109/mcg.2011.103", "10.1145/1124772.1124851", "10.1109/tmm.2016.2614220", "10.1109/tvcg.2010.79", "10.1109/infvis.2000.885095", "10.1111/cgf.13211", "10.1109/tvcg.2014.2346920", "10.1002/(sici)1097-0266(199606)17:6", "10.5670/oceanog.2016.66", "10.1559/152304003100011081", "10.1109/tit.1982.1056489", "10.1559/152304098782383034", "10.1109/tvcg.2014.2346922", "10.1007/978-3-540-85567-5\\_9", "10.1145/2488388.2488504", "10.1109/38.974518", "10.1109/bigdata.2013.6691714", "10.1109/pacificvis.2014.38", "10.1109/tvcg.2012.291", "10.1109/infvis.2005.1532128", "10.2307/2685881", "10.1007/1-4020-4179-9\\_91", "10.1109/infvis.1999.801860", "10.1109/asonam.2011.37"], "wos": 1, "children": [{"doi": "10.1111/cgf.14031", "year": "2020", "title": "The State of the Art in Map-Like Visualization", "conferenceName": "EuroVis", "authors": "Marius Hogr{\\\"{a}}fer;Magnus Heitzler;Hans{-}J{\\\"{o}}rg Schulz", "citationCount": "0", "affiliation": "Hografer, M (Corresponding Author), Aarhus Univ, Dept Comp Sci, Aarhus, Denmark.\nHografer, Marius; Schulz, Hans-Jorg, Aarhus Univ, Dept Comp Sci, Aarhus, Denmark.\nHeitzler, Magnus, Swiss Fed Inst Technol, Inst Cartog \\& Geoinformat, Zurich, Switzerland.", "countries": "Switzerland;Denmark", "abstract": "Cartographic maps have been shown to provide cognitive benefits when interpreting data in relation to a geographic location. In visualization, the term map-like describes techniques that incorporate characteristics of cartographic maps in their representation of abstract data. However, the field of map-like visualization is vast and currently lacks a clear classification of the existing techniques. Moreover, choosing the right technique to support a particular visualization task is further complicated, as techniques are scattered across different domains, with each considering different characteristics as map-like. In this paper, we give an overview of the literature on map-like visualization and provide a hierarchical classification of existing techniques along two general perspectives: imitation and schematization of cartographic maps. Each perspective is further divided into four principal categories that group common map-like techniques along the visual primitives they affect. We further discuss this classification from a task-centered view and highlight open research questions.", "keywords": "", "link": "https://doi.org/10.1111/cgf.14031", "refList": ["10.1111/j.0020-2754.1998.00269.x.21", "10.1109/iv.2005.26", "10.2307/2980460", "10.1109/tvcg.2017.2743959", "10.1016/j.jvlc.2011.11.004", "10.1145/2501988.2502046", "10.1559/1523040042742402", "10.1007/s00779-011-0500-3", "10.1111/cgf.12932", "10.1109/tvcg.2010.89", "10.1111/cgf.13200", "10.1080/15230406.2016.1160797", "10.1179/000870410x12825500202896", "10.1109/tvcg.2007.70596", "10.5167/80972.19uzh-80972", "10.1007/978-3-319-11593-1\\_2", "10.1037/aca0000175", "10.1080/17538947.2014.923942", "10.1109/tvcg.2015.2467321", "10.1109/vissof.2005.1684299", "10.1559/152304098782383034", "10.1007/978-3-642-36763-2\\_38", "10.1109/tvcg.2013.130", "10.1109/tvcg.2014.2346274", "10.1111/cgf.12648", "10.1111/0004-5608.00242", "10.1177/1473871617724212", "10.1109/iv.2004.1320123", "10.1371/journal.pcbi.1006907", "10.1109/tvcg.2016.2599030", "10.1559/1523040042742411", "10.3390/informatics5030031", "10.1111/cgf.13079", "10.1109/tvcg.2015.2467811", "10.1016/j.tics.2003.12.004", "10.1007/s00799-016-0168-4", "10.1109/infvis.2004.57", "10.1007/s10021-007-9038-7", "10.1109/pacificvis.2015.7156366", "10.1007/978-3-319-27261-0\\_1", "10.1007/978-1-4471-2804-5\\_6", "10.1109/access.2019.2939977", "10.1109/tvcg.2017.2747545", "10.1109/icdm.2003.1250978", "10.1111/cgf.13167", "10.1016/0010-0285(78)90006-3", "10.3138/nj8v-8514-871t-221k", "10.1016/j.cag.2009.06.002", "10.1111/j.1467-8659.2011.01937.x", "10.1016/b978-044451020-4/50035-9", "10.1111/1467-8659.00566", "10.5220/0006618101080119", "10.1109/pacificvis.2012.6183571", "10.1145/2038558.2038579", "10.1109/tvcg.2010.191", "10.1111/j.0033-0124.1985.00075.x", "10.1109/tvcg.2004.1260761", "10.1007/978-3-642-34848-8\\_6", "10.1145/2968220.2968239", "10.1145/3002151.3002160", "10.1109/tst.2013.6509098", "10.1109/tvcg.2013.91", "10.1177/1473871615597077", "10.1016/j.jvlc.2011.02.001", "10.1080/17445647.2014.935502", "10.1177/1687814017740710", "10.1111/1744-7917.12601", "10.1073/pnas.0400280101", "10.1111/cgf.13672", "10.1109/mcg.2006.90", "10.1002/asi.21712", "10.1007/978-3-642-33024-7\\_3", "10.1145/2801040.2801056", "10.1109/mcg.2010.101", "10.1179/003962607x165041", "10.1057/palgrave.ivs.9500039", "10.1109/vast.2016.7883510", "10.1559/152304009788988288", "10.1080/23729333.2017.1301346", "10.1109/tvcg.2013.66", "10.1111/j.1467-8659.2012.03085.x", "10.1109/tvcg.2011.288", "10.3390/ijgi9040253", "10.1109/infvis.2005.1532150", "10.1145/2254556.2254636", "10.20382//jocg.v4i1a9", "10.1016/0010-0285(81)90016-5", "10.1145/2556288.2557224", "10.1109/iv.2001.942043", "10.1021/ed1000203", "10.1016/0169-7439(87)80084-9", "10.1109/tvcg.2010.154", "10.1016/j.jvlc.2015.10.003", "10.1109/tvcg.2019.2903945", "10.1109/tvcg.2013.120", "10.1109/tvcg.2019.2934263", "10.1146/annurev-ecolsys-102209-144718", "10.1109/tvcg.2008.165", "10.3138/a477-3202-7876-n514", "10.1080/23729333.2017.1288535", "10.1111/j.0020-2754.1998.00269.x", "10.1109/mcg.2004.41", "10.1109/vast.2009.5332593", "10.1002/smr.414", "10.1007/s12650-019-00584-3", "10.1145/22949.22950", "10.1179/1743277413y.0000000036", "10.1080/15230406.2016.1262280", "10.1016/s0341-8162(01)00164-3", "10.22224/gistbok/2017.3.8", "10.1109/tvcg.2008.155", "10.1057/ivs.2008.31", "10.1016/j.cag.2004.03.012", "10.1179/1743277412y.0000000007", "10.1016/j.soncn.2011.02.001", "10.1179/caj.1987.24.1.27", "10.3138/carto.48.3.1691", "10.5220/0004267205150524", "10.1109/38.974518", "10.1145/102377.115768", "10.1057/palgrave.ivs.9500186", "10.1109/5.58325", "10.5167/80972.uzh-80972", "10.1177/030913339602000204", "10.1007/978-3-642-22300-6\\_14", "10.1109/iv.2004.1320189", "10.1111/cgf.13447", "10.1007/s11192-017-2596-3", "10.1559/1523040053722150", "10.1007/978-3-662-45803-7\\_34"], "wos": 1, "children": [], "len": 1}], "len": 3}, {"doi": "10.1109/tvcg.2019.2934266", "title": "VASSL: A Visual Analytics Toolkit for Social Spambot Labeling", "year": "2019", "conferenceName": "VAST", "authors": "Mosab Khayat;Morteza Karimzadeh;Jieqiong Zhao;David S. Ebert", "citationCount": "1", "affiliation": "Khayat, M (Corresponding Author), Purdue Univ, W Lafayette, IN 47907 USA. Khayat, Mosab; Zhao, Jieqiong; Ebert, David S., Purdue Univ, W Lafayette, IN 47907 USA. Karimzadeh, Morteza, Univ Colorado, Purdue Univ, Boulder, CO 80309 USA.", "countries": "USA", "abstract": "Social media platforms are filled with social spambots. Detecting these malicious accounts is essential, yet challenging, as they continually evolve to evade detection techniques. In this article, we present VASSL, a visual analytics system that assists in the process of detecting and labeling spambots. Our tool enhances the performance and scalability of manual labeling by providing multiple connected views and utilizing dimensionality reduction, sentiment analysis and topic modeling, enabling insights for the identification of spambots. The system allows users to select and analyze groups of accounts in an interactive manner, which enables the detection of spambots that may not be identified when examined individually. We present a user study to objectively evaluate the performance of VASSL users, as well as capturing subjective opinions about the usefulness and the ease of use of the tool.", "keywords": "Spambot,Labeling,Detection,Visual Analytics,Social Media Annotation", "link": "http://dx.doi.org/10.1109/TVCG.2019.2934266", "refList": ["10.7326/0003-4819-110-11-916", "10.1109/tifs.2013.2267732", "10.1111/cgf.12106", "10.1016/j.ins.2013.11.016", "10.1109/tvcg.2017.2752166", "10.1109/vast.2016.7883510", "10.1109/vl.1996.545307", "10.1145/2872518.2889302", "10.1109/tmm.2016.2614220", "10.1145/2818717", "10.1109/tdsc.2017.2681672", "10.1111/cgf.13211", "10.2307/2685478", "10.1109/tvcg.2014.2346920", "10.1109/tdsc.2016.2641441", "10.1109/tvcg.2017.2745080", "10.1109/vast.2012.6400557", "10.1109/asonam.2016.7752287", "10.1109/tvcg.2014.2346922", "10.1111/cgf.13217", "10.2307/249008", "10.1109/tvcg.2017.2711030", "10.1109/mcse.2013.70", "10.1109/tvcg.2015.2467196", "10.1016/j.comcom.2013.04.004", "10.1109/asonam.2014.6921650", "10.1109/mc.2016.183", "10.1126/science.290.5500.2323", "10.1145/3041021.3055135", "10.1162/jmlr.2003.3.4-5.993", "10.1109/tvcg.2017.2745083", "10.1109/tvcg.2013.153", "10.1109/iv.2008.89", "10.1109/mcom.2013.6588663", "10.1179/000870403235002042", "10.1145/3047010"], "wos": 1, "children": [{"doi": "10.1111/cgf.14034", "year": "2020", "title": "The State of the Art in Enhancing Trust in Machine Learning Models with the Use of Visualizations", "conferenceName": "EuroVis", "authors": "Angelos Chatzimparmpas;Rafael Messias Martins;Ilir Jusufi;Kostiantyn Kucher;Fabrice Rossi;Andreas Kerren", "citationCount": "2", "affiliation": "Chatzimparmpas, A (Corresponding Author), Linnaeus Univ, Dept Comp Sci \\& Media Technol, Vaxjo, Sweden.\nChatzimparmpas, A.; Martins, R. M.; Jusufi, I.; Kucher, K.; Kerren, A., Linnaeus Univ, Dept Comp Sci \\& Media Technol, Vaxjo, Sweden.\nRossi, F., PSL Univ, Univ Paris Dauphine, Ceremade, Paris, France.", "countries": "Sweden;France", "abstract": "Machine learning (ML) models are nowadays used in complex applications in various domains, such as medicine, bioinformatics, and other sciences. Due to their black box nature, however, it may sometimes be hard to understand and trust the results they provide. This has increased the demand for reliable visualization tools related to enhancing trust in ML models, which has become a prominent topic of research in the visualization community over the past decades. To provide an overview and present the frontiers of current research on the topic, we present a State-of-the-Art Report (STAR) on enhancing trust in ML models with the use of interactive visualization. We define and describe the background of the topic, introduce a categorization for visualization techniques that aim to accomplish this goal, and discuss insights and opportunities for future research directions. Among our contributions is a categorization of trust against different facets of interactive ML, expanded and improved from previous research. Our results are investigated from different analytical perspectives: (a) providing a statistical overview, (b) summarizing key findings, (c) performing topic analyses, and (d) exploring the data sets used in the individual papers, all with the support of an interactive web-based survey browser. We intend this survey to be beneficial for visualization researchers whose interests involve making ML models more trustworthy, as well as researchers and practitioners from other disciplines in their search for effective visualization techniques suitable for solving their tasks with confidence and conveying meaning to their data.", "keywords": "trustworthy machine learning; visualization; interpretable machine learning; explainable machine learning", "link": "https://doi.org/10.1111/cgf.14034", "refList": ["10.1109/mcg.2018.2878902", "10.1109/tvcg.2008.153", "10.2312/mlvis.20181130", "10.1109/tvcg.2016.2598828", "10.1145/3290605.3300911", "10.1145/2993901.2993909", "10.2312/mlvis.20191158", "10.1109/tvcg.2016.2598446", "10.1111/j.1467-8659.2009.01475.x", "10.1145/3290605.3300809", "10.1109/pacificvis.2018.00031", "10.1055/s-0029-1216348", "10.1007/978-3-319-90403-0\\_13", "10.1109/tvcg.2017.2745085", "10.1111/j.1467-8659.2011.01938.x", "10.1007/978-3-319-54024-5\\_6", "10.1016/s0167-9473(01)00065-2", "10.1111/cgf.12895", "10.2312/eurovisshort.20141152.17", "10.2312/eurova.20151098.22", "10.1111/cgf.13667", "10.3115/1072228.1072378", "10.1109/tbdata.2018.2877350.16", "10.1109/lars.2009.5418323.25", "10.1109/tvcg.2017.2744878", "10.1016/j.combustflame.2005.09.018", "10.1016/j.cag.2014.01.006", "10.1109/tvcg.2016.2570755", "10.2312/mlvis.20191158.1,19", "10.1518/hfes.46.1.50.30392", "10.1145/3301275.3302280", "10.1145/3351095.3372834.1", "10.1016/s0377-2217(01)00264-8", "10.1111/cgf.13424", "10.1007/978-3-319-23485-4\\_53", "10.1007/978-94-007-0753-5\\_3623", "10.1109/tvcg.2013.101", "10.1111/cgf.12884", "10.1111/j.1467-8659.2010.01835.x", "10.1021/ci9901338", "10.4230/lipics.itcs:2017", "10.1109/mis.2013.24", "10.1109/tvcg.2014.2346482", "10.1109/tvcg.2018.2865230", "10.1073/pnas.1807180116", "10.1109/dsaa.2018.00018", "10.1109/tvcg.2009.153", "10.3115/1219840.1219855", "10.1109/tvcg.2018.2864812", "10.1109/tvcg.2018.2872577", "10.2312/trvis.20191183", "10.1109/cvpr:2004.383", "10.1109/vast.2008.4677350", "10.1145/302979.303001", "10.1109/tvcg.2018.2864499", "10.1111/cgf.13672", "10.1109/tvcg.2014.2346626", "10.23915/distill.00010.18", "10.1109/tvcg.2017.2744805", "10.2312/mlvis:20191160.18", "10.23915/distill:00016", "10.1109/pacificvis.2016.7465260", "10.1111/cgf.13683", "10.23915/distill.00016.19", "10.1145/32906053.300803.22", "10.1109/tvcg.2014.2346574", "10.1177/1473871615600010", "10.1109/tvcg.2016.2598831", "10.1145/3230623", "10.1109/visual.2019.8933744", "10.1145/2993901.2993915", "10.1016/j.visinf.2017.01.006", "10.1145/2993901.2993914", "10.1109/tvcg.2014.2346984", "10.1109/5.726791", "10.23915/distill.00010", "10.1109/tvcg.2018.2864825", "10.2307/2394164", "10.1109/tvcg.2017.2744458", "10.1145/2993901.2993917.28", "10.1111/cgf.13711", "10.1109/tvcg.2016.2598664", "10.2307/2530428", "10.1109/icdar.1997.620583", "10.1109/tvcg.2017.2744718", "10.1111/cgf.13425", "10.1109/tvcg.2019.2903943", "10.1145/1518701.1518895", "10.1109/tvcg.2018.2864838", "10.1145/62038.62043", "10.1111/j.1467-8659.2011.01920.x", "10.1145/3025171.3025208", "10.1145/355112.355124", "10.1109/vast.2010.5652398", "10.1109/tvcg.2014.2346578", "10.1145/3173574.3174209", "10.4178/epih/e2014008", "10.1109/beliv.2018.8634201.25,28", "10.1016/j.eswa.2007.12.020", "10.1111/cgf:13406", "10.1109/mcg.2011.103", "10.1631/fitee.1700808", "10.1109/tvcg.2017.2745158", "10.1073/pnas.0307752101", "10.1109/tvcg.2018.2816223", "10.1109/tvcg.2017.2745141", "10.1145/32232.32234", "10.1109/tvcg.2019.2934267", "10.1109/tvcg.2018.2864477", "10.1145/3132169", "10.2312/eurova.20151100.19", "10.1145/3172944.3172964", "10.1145/2601248.2601268", "10.1109/isai-nlp.2018.8693002.1", "10.1111/cgf.13404", "10.1007/s100320200071", "10.2312/trvis.20191183.16", "10.1111/cgf.12755", "10.1145/2702123.2702509", "10.1145/1401890.1402008.25", "10.1109/tvcg.2012.65", "10.1177/1473871617733996", "10.2312/trvis.20191187.7", "10.21236/ada273556", "10.1109/vast.2010.5652450", "10.1111/j.1467-8659.2011.01940.x", "10.1177/875647939000600106", "10.1109/tvcg.2017.2711030", "10.1016/j.immuni.2016.04.014", "10.1109/tvcg.2019.2934209", "10.1016/0095-0696(78)90006-2", "10.1016/j.jclinepi.2015.04.014", "10.1016/j.ress.2013.02.013", "10.1111/cgf.12640", "10.1145/1015330.1015388.25", "10.1111/j.1467-8659.2009.01468.x", "10.1145/1541880.1541882", "10.1109/vast.2011.6102453", "10.1016/s0008-8846(98)00165-3", "10.2312/trvis.20191186.7", "10.1007/s13748-013-0040-3", "10.1109/tvcg.2015.2467757", "10.1109/tbdata.2018.2877350", "10.1109/vast.2017.8585613", "10.1080/10556789208805504", "10.1109/vast.2012.6400484", "10.1145/3025171.3025181", "10.1007/978-3-319-90403-0\\_12", "10.1109/mcg.2019.2922592", "10.1021/ci000392t", "10.1109/vast.2007.4389000", "10.1111/cgf.13406.16", "10.1111/cgf.13684", "10.2312/eurovisshort.20161166.17", "10.2312/evs:20191168", "10.1145/3041021.3055135", "10.1145/3301275.3302265", "10.1613/jair.4135", "10.1109/tvcg.2018.2864500", "10.1109/tvcg.2017.2744158", "10.1109/ssci.2015.33", "10.1111/cgf.13453", "10.2312/pe/eurovast/eurova11/049-052", "10.1145/3025171.3025181.13", "10.1145/371920.372094", "10.1109/tvcg.2017.2744938", "10.1111/j.1467-8659.2012.03108.x", "10.1109/tvcg.2019.2934251", "10.1145/3290605.3300809.18", "10.1109/ldav.2016.7874305", "10.1109/vast.2016.7883514", "10.1109/iccv.2015.425", "10.1145/3301275.3302324", "10.1109/tnnls.2013.2292894", "10.1109/tvcg.2018.2865044", "10.1109/tvcg.2013.157", "10.1371/journal.pcbi.0020161", "10.1186/s12916-019-1426-2", "10.1109/10.867928", "10.1111/cgf.13217", "10.1109/mcg.2019.2919033", "10.1145/2993901.2993910", "10.1109/tvcg.2017.2744738", "10.2307/258792", "10.1111/cgf.12655", "10.1016/j.dss.2014.03.001", "10.1109/tvcg.2019.2904069", "10.1111/cgf.13205", "10.1002/mds.22340", "10.1109/tvcg.2019.2934595", "10.1287/inte.2018.0957", "10.1109/cvpr.2007.382974", "10.1109/tvcg.2012.280", "10.1145/2678025.2701399.13", "10.2312/mlvis.20181130.13", "10.2312/eurova.20181106.16", "10.1109/tvcg.2018.2864475", "10.2312/mlvis.20191160.18,22", "10.1007/978-1-4612-4026-6.25", "10.1109/cvpr.2006.42", "10.1145/3172944.3172950", "10.1109/cvpr.2004.383.25", "10.1109/tvcg.2019.2934812", "10.1609/aimag.v35i4.2513", "10.2312/trvis.20191185.7", "10.1111/j.1467-8659.2009.01684.x", "10.1371/journal.pone.0129126", "10.1111/cgf.13092", "10.1162/coli\\_a\\_00237", "10.1109/tvcg.2017.2744818", "10.1109/vast.2011.6102448", "10.1109/tvcg.2009.111", "10.1109/tvcg.2019.2934619", "10.1016/s0377-2217(01)00264-8.25", "10.1111/cgf.12639", "10.1109/access.2019.2919343", "10.1186/s12874-019-0681-4", "10.1109/pacificvis.2015.7156366", "10.1109/pacificvis.2018.00029", "10.1109/tvcg.2019.2934261", "10.1080/13506280444000102.http://www.uvt.nl/ticc", "10.1109/vast.2018.8802509", "10.1111/cgf.13212", "10.1145/3200489", "10.1111/cgf.13176", "10.1177/1473871620904671", "10.1007/978-3-319-10590-1\\_53", "10.1111/j.1467-8659.2012.03126.x", "10.1111/cgf.13172", "10.1145/3025171.3025208.6,21", "10.1111/cgf.12366", "10.1109/tvcg.2019.2934659", "10.1109/cvprw.2009.5206848", "10.1016/j.media.2014.11.010", "10.1109/tvcg.2017.2744683", "10.1109/tvcg.2019.2934262", "10.1016/j.neucom.2006.11.018", "10.1177/1473871615571951", "10.1371/journal.pcbi.0020161.25", "10.1177/1473871611415994", "10.2312/trvis20191187", "10.2312/eurova", "10.1145/2858036.2858529", "10.1145/2207676.2207738", "10.1007/s11042-009-0417-2", "10.1145/3301275.3302317", "10.1038/s41746-019-0148-3", "10.1145/3351095.3372834", "10.1080/10691898.2011.11889627", "10.1109/tvcg.2018.2864504", "10.1109/vast.2017.8585720", "10.1109/mcg.2018.053491732", "10.1007/s10994-010-5207-6", "10.1109/tvcg.2019.2934433", "10.1016/j.cag.2017.05.005", "10.1109/tvcg.2012.279", "10.1145/3231622.3231641.19,20", "10.1145/1562849.1562851", "10.1007/11564126\\_", "10.1109/tvcg.2018.2846735", "10.3115/1225403.1225421", "10.1109/vast.2012.6400486", "10.2312/eurova.20191116.22", "10.1109/tvcg.2007.70443", "10.1080/027868291009242", "10.2312/eurova.20151100", "10.1145/2939502.2939503.19", "10.1016/j.cag.2014.02.004", "10.1145/2939672.2939778", "10.1109/vast.2010.5652484", "10.1111/cgf.12641", "10.1145/3301275.3302289", "10.1109/visual.2019.8933619", "10.1109/tvcg.2017.2672987", "10.1109/vast.2016.7883517.20", "10.1109/igarss.2017.8127684", "10.1016/j.jcae.2010.04.002", "10.1109/vast.2010.5652885", "10.1016/j.visinf.2019.03.002", "10.1007/s00371-018-1500-3", "10.1109/mcg.2018.042731661", "10.1109/34.598228", "10.1109/tvcg.2018.2865027", "10.1016/j.neucom.2017.01.105", "10.1111/cgf.12389", "10.1109/tvcg.2019.2934591", "10.1109/vast.2010.5652392.16", "10.1111/cgf.13416", "10.1080/02701367.1992.10608764", "10.1109/vast.2017.8585721", "10.1109/tvcg.2018.2843369", "10.1109/sbes.2010.27", "10.1109/vast.2015.7347637", "10.1145/1401890.1402008", "10.1016/j.bpj.2010.04.064", "10.1109/tvcg.2013.125", "10.1109/isai-nlp.2018.8693002", "10.1371/journal.pone.0160127", "10.1145/2856767.2856779", "10.1145/2678025.2701399", "10.1109/vast.2011.6102451", "10.1109/mcg.2010.18", "10.1021/ci4000213", "10.1109/vast.2012.6400492", "10.1007/11564126-49.25", "10.2312/eurova.20171114", "10.1109/vast.2010.5652443", "10.1145/3134599", "10.2312/pe/eurovast/eurovast10/013-018.19", "10.1109/tvcg.2019.2903946", "10.1109/tvcg.2015.2467717", "10.1177/1473871612460526", "10.1016/j.cag.2018.09.018", "10.1109/tvcg.2016.2598838", "10.1145/3172944.3172964.14", "10.1109/vast.2009.5333428", "10.1109/vast.2014.7042480", "10.2312/pe/eurovast/eurovast10/013-018", "10.1177/0962280215588241", "10.1145/2993901.2993917", "10.1109/cvpr.2008:4587581", "10.1109/tvcg.2015.2467551", "10.1016/j.visinf.2018.09.001", "10.1126/science.290.5500.2319", "10.2312/eurova.20151107", "10.1109/visual.2019.8933695", "10.13140/2.1.2393.1847", "10.1197/jamia.m1929", "10.1109/cvpr.2008.4587581.25", "10.1145/1518701.1518895.16", "10.1109/vds.2017.8573444", "10.2312/trvis:20191185", "10.1145/3359786", "10.13140/2.1.1341.1520", "10.2312/pe/eurovast/eurova11/049-052.17", "10.1109/tvcg.2014.2346660", "10.1145/3185517", "10.1109/adprl.2011.5967372", "10.1109/tvcg.2015.2467591", "10.1111/j.1751-9004.2009.00232.x", "10.1136/qshc.2004.010033", "10.1109/vast.2012.6400493", "10.1109/tvcg.2019.2934266", "10.1145/2971763.2971775", "10.1111/cgf.13730", "10.1109/vast.2012.6400488", "10.1111/cgf.13210", "10.1109/tvcg.2019.2934631", "10.1145/3172944.3172965", "10.1057/ivs.2010.2", "10.1109/tvcg.2017.2745258", "10.1016/j.jbusres.2019.07.039", "10.1162/jmlr.2003.3.4-5.993", "10.1109/pacificvis.2019.00044", "10.2312/pe/eurovast/eurova12/037-041", "10.1109/tvcg.2019.2934629", "10.1177/0018720814547570", "10.1145/3292500.3330908", "10.1111/j.1467-8659.2009.01467.x", "10.2312/eurova.20151098", "10.1177/1473871617713337", "10.1109/lars:2009.5418323", "10.1109/vast.2011.6102437", "10.1111/cgf.12878", "10.1561/1500000001", "10.1145/3025171.3025222", "10.1007/s11704-016-6028-y", "10.1016/j.procs.2017.05.216", "10.1109/cvpr.2007.382974.25", "10.1080/10447318.2020.1741118", "10.1109/vast.2012.6400489", "10.1145/3025171.3025172", "10.1109/tvcg.2017.2744098", "10.1109/tvcg.2005.66", "10.1016/j.dss.2009.05.016", "10.1007/978-1-4612-4026-6", "10.2312/evs.20191168.16,20,28", "10.2312/pe/eurovast/eurova12/037-041.17", "10.1145/3290605.3300803", "10.1145/1015330.1015388", "10.1111/cgf.13197", "10.1016/b978-1-55860-377-6.50048-7", "10.1111/cgf.13681", "10.1109/tvcg.2017.2744378", "10.1109/tvcg.2017.2744358", "10.1109/vast.2008.4677352"], "wos": 1, "children": [{"doi": "10.1109/tvcg.2020.3030368", "title": "Implicit Multidimensional Projection of Local Subspaces", "year": "2020", "conferenceName": "InfoVis", "authors": "Rongzheng Bian;Yumeng Xue;Liang Zhou;Jian Zhang 0070;Baoquan Chen;Daniel Weiskopf;Yunhai Wang", "citationCount": "1", "affiliation": "Wang, YH (Corresponding Author), Shandong Univ, Qingdao, Peoples R China. Zhou, L (Corresponding Author), Univ Utah, Salt Lake City, UT 84112 USA. Bian, Rongzheng; Xue, Yumeng; Wang, Yunhai, Shandong Univ, Qingdao, Peoples R China. Chen, Baoquan, Peking Univ, Beijing, Peoples R China. Zhang, Jian, Chinese Acad Sci, CNIC, Beijing, Peoples R China. Zhou, Liang, Univ Utah, Salt Lake City, UT 84112 USA. Weiskopf, Daniel, Univ Stuttgart, Stuttgart, Germany.", "countries": "USA;Germany;China", "abstract": "We propose a visualization method to understand the effect of multidimensional projection on local subspaces, using implicit function differentiation. Here, we understand the local subspace as the multidimensional local neighborhood of data points. Existing methods focus on the projection of multidimensional data points, and the neighborhood information is ignored. Our method is able to analyze the shape and directional information of the local subspace to gain more insights into the global structure of the data through the perception of local structures. Local subspaces are fitted by multidimensional ellipses that are spanned by basis vectors. An accurate and efficient vector transformation method is proposed based on analytical differentiation of multidimensional projections formulated as implicit functions. The results are visualized as glyphs and analyzed using a full set of specifically-designed interactions supported in our efficient web-based visualization tool. The usefulness of our method is demonstrated using various multi- and high-dimensional benchmark datasets. Our implicit differentiation vector transformation is evaluated through numerical comparisons; the overall method is evaluated through exploration examples and use cases.", "keywords": "High-dimensional data visualization,dimensionality reduction,local linear subspaces,user interaction", "link": "http://dx.doi.org/10.1109/TVCG.2020.3030368", "refList": ["10.3844/jcssp.2018.613.622", "10.1016/j.aci.2018.08.003", "10.3390/info9030065", "10.1016/j.visinf.2018.09.003", "10.1371/journal.pone.0118432", "10.1016/s0893-6080(05)80023-1", "10.1109/tvcg.2020.2986996", "10.1109/icst.2012.56", "10.1007/s10844-013-0250-y", "10.1109/tbdata.2018", "10.1145/1125451.1125659", "10.1109/tvcg.2013.125", "10.1177/1473871611412817", "10.1145/3290605.3300911", "10.1111/cgf.14034", "10.1007/s13721-013-0034-x", "10.1016/j.procs.2017.05.216", "10.1016/j.ins.2009.08.025", "10.1109/tvcg.2013.124", "10.1109/tvcg.2018.2864499", "10.1109/tvcg.2018.2864475", "10.1080/10447318.2020.1741118", "10.1016/j.imu.2019.100203", "10.1109/tvcg.2018.2865240", "10.1186/s12864-019-6413-7", "10.1109/tvcg.2015.2467551", "10.1002/widm.1249", "10.1007/978-3-319-66429-3\\_29", "10.1109/tvcg.2014.2346481", "10.1109/tvcg.2018.2864825", "10.1177/1473871620904671", "10.1109/tvcg.2019.2934267", "10.1136/bmjopen-2016-012799", "10.1109/smartgridcomm.2017.8340682", "10.1007/s10664-015-9401-9", "10.1145/1143844.1143874", "10.1111/cgf.12389", "10.1109/tvcg.2018.2872577", "10.1007/978-981-13-5802-9\\_20", "10.1016/j.ipm.2009.03.002", "10.5220/0006431602160222", "10.1109/mcg.2015.50", "10.1109/tvcg.2014.2346574", "10.1007/bf02289565", "10.1109/tvcg.2017.2744378", "10.1016/j.patrec.2008.08.010", "10.1023/a:1010933404324", "10.9735/2229-3981"], "wos": 1, "children": [], "len": 1}, {"doi": "10.1109/tvcg.2020.3030465", "title": "Visual Causality Analysis of Event Sequence Data", "year": "2020", "conferenceName": "VAST", "authors": "Zhuochen Jin;Shunan Guo;Nan Chen;Daniel Weiskopf;David Gotz;Nan Cao", "citationCount": "0", "affiliation": "Cao, N (Corresponding Author), Tongji Univ, IDVx Lab, Shanghai, Peoples R China. Jin, Zhuochen; Guo, Shunan; Chen, Nan; Cao, Nan, Tongji Univ, IDVx Lab, Shanghai, Peoples R China. Weiskopf, Daniel, Univ Stuttgart, Stuttgart, Germany. Gotz, David, Univ N Carolina, Chapel Hill, NC 27515 USA.", "countries": "USA;Germany;China", "abstract": "Causality is crucial to understanding the mechanisms behind complex systems and making decisions that lead to intended outcomes. Event sequence data is widely collected from many real-world processes, such as electronic health records, web clickstreams, and financial transactions, which transmit a great deal of information reflecting the causal relations among event types. Unfortunately, recovering causalities from observational event sequences is challenging, as the heterogeneous and high-dimensional event variables are often connected to rather complex underlying event excitation mechanisms that are hard to infer from limited observations. Many existing automated causal analysis techniques suffer from poor explainability and fail to include an adequate amount of human knowledge. In this paper, we introduce a visual analytics method for recovering causalities in event sequence data. We extend the Granger causality analysis algorithm on Hawkes processes to incorporate user feedback into causal model refinement. The visualization system includes an interactive causal analysis framework that supports bottom-up causal exploration, iterative causal verification and refinement, and causal comparison through a set of novel visualizations and interactions. We report two forms of evaluation: a quantitative evaluation of the model improvements resulting from the user-feedback mechanism, and a qualitative evaluation through case studies in different application domains to demonstrate the usefulness of the system.", "keywords": "Event sequence data,causality analysis,visual analytics", "link": "http://dx.doi.org/10.1109/TVCG.2020.3030465", "refList": ["10.5555/1642718", "10.1109/tvcg.2018.2865022", "10.5555/2074094.2074151", "10.1109/tvcg.2016.2618797", "10.1073/pnas.1320645111", "10.1109/tvcg.2017.2744843", "10.1109/iv.2017.69", "10.1109/tvcg.2019.2934399", "10.1145/3172944.3173007", "10.5555/1795555", "10.1109/mcg.2005.102", "10.1145/381641.381653", "10.1162/153244301753344614", "10.1111/cgf.14034", "10.1111/cgf.13198", "10.1017/cbo9780511519857", "10.1007/s10462-016-9475-9", "10.1075/ssol.2.2.07bor", "10.1007/978-1-4614-3223-4\\_3", "10.1109/infvis.2003.1249025", "10.1007/978-94-007-6094-313", "10.1145/2858036.2858387", "10.1109/tvcg.2007.70528", "10.1109/tvcg.2017.2674958", "10.1147/sj.454.0801", "10.1109/tvcg.2013.119", "10.1145/3173574.3173711", "10.1016/j.erss.2017.06.034", "10.1109/visual.2019.8933695", "10.1007/s11665-016-2173-6", "10.1016/0377-0427(87)90125-7", "10.2307/3601125", "10.1016/b978-0-444-88738-2.50018-x", "10.1109/mcg.2006.70", "10.1109/tvcg.2018.2865145", "10.1017/s1351324997001502", "10.1109/tvcg.2010.179", "10.1214/aos/1176344552", "10.1109/mcg.2009.22", "10.1007/978-3-319-26633-6\\_13", "10.1080/10447318.2014.905422", "10.1016/j.visinf.2019.03.004", "10.1057/palgrave.ivs.9500074", "10.1007/978-1-4614-3223-4"], "wos": 1, "children": [], "len": 1}], "len": 5}], "len": 7}, {"doi": "10.1109/tvcg.2020.3030411", "title": "Co-Bridges: Pair-wise Visual Connection and Comparison for Multi-item Data Streams", "year": "2020", "conferenceName": "VAST", "authors": "Siming Chen;Natalia V. Andrienko;Gennady L. Andrienko;Jie Li 0006;Xiaoru Yuan", "citationCount": "0", "affiliation": "Yuan, XR (Corresponding Author), Peking Univ, Beijing, Peoples R China. Chen, Siming, Fudan Univ, Sch Data Sci, Shanghai, Peoples R China. Chen, Siming; Andrienko, Natalia; Andrienko, Gennady, Fraunhofer Inst IAIS, St Augustin, Germany. Andrienko, Natalia; Andrienko, Gennady, City Univ London, London, England. Li, Jie, Tianjin Univ, Tianjin, Peoples R China. Yuan, Xiaoru, Peking Univ, Beijing, Peoples R China.", "countries": "Germany;China;England", "abstract": "In various domains, there are abundant streams or sequences of multi-item data of various kinds, e.g. streams of news and social media texts, sequences of genes and sports events, etc. Comparison is an important and general task in data analysis. For comparing data streams involving multiple items (e.g., words in texts, actors or action types in action sequences, visited places in itineraries, etc.), we propose Co-Bridges, a visual design involving connection and comparison techniques that reveal similarities and differences between two streams. Co-Bridges use river and bridge metaphors, where two sides of a river represent data streams, and bridges connect temporally or sequentially aligned segments of streams. Commonalities and differences between these segments in terms of involvement of various items are shown on the bridges. Interactive query tools support the selection of particular stream subsets for focused exploration. The visualization supports both qualitative (common and distinct items) and quantitative (stream volume, amount of item involvement) comparisons. We further propose Comparison-of-Comparisons, in which two or more Co-Bridges corresponding to different selections are juxtaposed. We test the applicability of the Co-Bridges in different domains, including social media text streams and sports event sequences. We perform an evaluation of the users' capability to understand and use Co-Bridges. The results confirm that Co-Bridges is effective for supporting pair-wise visual comparisons in a wide range of applications.", "keywords": "Visual Comparison,Pair-wise Analysis,Multi-item Data Stream,Social Media", "link": "http://dx.doi.org/10.1109/TVCG.2020.3030411", "refList": ["10.1109/tvcg.2014.2346753", "10.1109/pacificvis.2010.5429590", "10.1109/vast.2009.5333443", "10.1101/gr.2289704", "10.1177/1473871611416549", "10.1057/palgrave.ivs.9500099", "10.1109/vast.2017.8585638", "10.1109/vast.2014.7042496", "10.1109/tvcg.2017.2764459", "10.1109/tvcg.2013.221", "10.1109/vast.2011.6102439", "10.1109/tvcg.2013.213", "10.1109/tmm.2016.2614220", "10.1109/tvcg.2016.2598797", "10.1145/2207676.2208556", "10.1145/1835804.1835827", "10.1109/tvcg.2013.124", "10.2312/conf/eg2013/stars/039-063", "10.1111/cgf.13211", "10.1109/tvcg.2014.2346920", "10.1109/tvcg.2011.239", "10.1016/j.jvlc.2018.08.008", "10.1109/mcg.2018.032421661", "10.1109/tvcg.2017.2744199", "10.1109/tvcg.2019.2934535", "10.1109/tvcg.2018.2864526", "10.1007/978-0-85729-436-4\\_9", "10.1109/vast.2016.7883511", "10.1109/tvcg.2014.2346682", "10.1109/tvcg.2015.2467618", "10.1145/2566486.2567977", "10.1109/tvcg.2017.2745320", "10.1080/136588199241247", "10.1111/cgf.13401", "10.1109/tvcg.2018.2864884", "10.1109/tvcg.2012.291", "10.1109/vast.2012.6400485", "10.1109/pacificvis.2016.7465266", "10.1109/tvcg.2011.232", "10.1109/tvcg.2017.2745083", "10.1109/tvcg.2012.253", "10.1007/s12650-014-0246-x", "10.1109/tvcg.2010.20", "10.1109/tvcg.2014.2346919", "10.1109/visual.2019.8933646", "10.1007/978-0-85729-079-3"], "wos": 1, "children": [], "len": 1}, {"doi": "10.1111/cgf.13677", "year": "2019", "title": "An Ontological Framework for Supporting the Design and Evaluation of Visual Analytics Systems", "conferenceName": "EuroVis", "authors": "Min Chen;David S. Ebert", "citationCount": "5", "affiliation": "Chen, M (Corresponding Author), Univ Oxford, Oxford, England.\nChen, Min, Univ Oxford, Oxford, England.\nEbert, David S., Purdue Univ, W Lafayette, IN 47907 USA.", "countries": "USA;England", "abstract": "Designing, evaluating, and improving visual analytics (VA) systems is a primary area of activities in our discipline. In this paper, we present an ontological framework for recording and categorizing technical shortcomings to be addressed in a VA workflow, reasoning about the causes of such problems, identifying technical solutions, and anticipating secondary effects of the solutions. The methodology is built on the theoretical premise that designing a VA workflow is an optimization of the cost-benefit ratio of the processes in the workflow. It makes uses three fundamental measures to group and connect symptoms, causes, remedies, and side-effects, and guide the search for potential solutions to the problems. In terms of requirement analysis and system design, the proposed methodology can enable system designers to explore the decision space in a structured manner. In terms of evaluation, the proposed methodology is time-efficient and complementary to various forms of empirical studies, such as user surveys, controlled experiments, observational studies, focus group discussions, and so on. In general, it reduces the amount of trial-and-error in the lifecycle of VA system development.", "keywords": "", "link": "https://doi.org/10.1111/cgf.13677", "refList": ["10.1109/tvcg.2006.178", "10.1109/infvis.2000.885092", "10.1111/cgf.12920", "10.1057/ivs.2009.26", "10.1109/mcg.2017.3271463", "10.1007/978-3-319-10578-9\\_1", "10.1109/icdmw.2008.62", "10.1109/mcg.2017.51", "10.1145/3011141.3011207", "10.1109/tvcg.2013.134", "10.1080/10618600.1996.10474696", "10.1007/978-3-540-70956-5", "10.1109/visual.1990.146375", "10.1109/tvcg.2012.219", "10.1109/vl.1996.545307", "10.1057/ivs.2009.23", "10.1002/j.1538-7305.1948.tb00917.x", "10.1109/tvcg.2010.79", "10.1109/tvcg.2013.124", "10.1111/cgf.13211", "10.1007/978-3-642-40897-7\\_9", "10.1103/physrev.108.171", "10.1109/infvis.2004.59", "10.1109/iv.2008.36", "10.1111/cgf.13210", "10.1111/j.1467-8659.2008.01230.x", "10.1001/jama.293.10.1223", "10.1177/1473871611407399", "10.1109/visual.1995.480821", "10.1117/12.539227", "10.1109/tvcg.2015.2513410", "10.1109/vast.2011.6102463", "10.7749/citiescommunitiesterritories.dec2014.029.art01", "10.1109/mcg.2005.55", "10.1109/tvcg.2012.234", "10.1109/pacificvis.2012.6183556", "10.1103/physrev.106.620", "10.1109/infvis.1997.636792", "10.2307/2104491", "10.1145/2468356.2468677", "10.1145/3173574.3173611", "10.1109/tvcg.2018.2864838", "10.1111/cgf.13092", "10.1109/visual.2004.10", "10.1109/tvcg.2017.2744319", "10.1109/tvcg.2009.111", "10.1109/tvcg.2013.120", "10.1109/tvcg.2016.2603178"], "wos": 1, "children": [{"doi": "10.1109/tvcg.2019.2934264", "title": "The Validity, Generalizability and Feasibility of Summative Evaluation Methods in Visual Analytics", "year": "2019", "conferenceName": "VAST", "authors": "Mosab Khayat;Morteza Karimzadeh;David S. Ebert;Arif Ghafoor", "citationCount": "1", "affiliation": "Khayat, M (Corresponding Author), Purdue Univ, W Lafayette, IN 47907 USA. Khayat, Mosab; Karimzadeh, Morteza; Ebert, David S.; Ghafoor, Arif, Purdue Univ, W Lafayette, IN 47907 USA. Karimzadeh, Morteza, Univ Colorado, Boulder, CO 80309 USA.", "countries": "USA", "abstract": "Many evaluation methods have been used to assess the usefulness of Visual Analytics (VA) solutions. These methods stem from a variety of origins with different assumptions and goals, which cause confusion about their proofing capabilities. Moreover, the lack of discussion about the evaluation processes may limit our potential to develop new evaluation methods specialized for VA. In this paper, we present an analysis of evaluation methods that have been used to summatively evaluate VA solutions. We provide a survey and taxonomy of the evaluation methods that have appeared in the VAST literature in the past two years. We then analyze these methods in terms of validity and generalizability of their findings, as well as the feasibility of using them. We propose a new metric called summative quality to compare evaluation methods according to their ability to prove usefulness, and make recommendations for selecting evaluation methods based on their summative quality in the VA domain.", "keywords": "Summative evaluation,usefulness,evaluation process,taxonomy,visual analytics", "link": "http://dx.doi.org/10.1109/TVCG.2019.2934264", "refList": ["10.1109/tvcg.2017.2744478", "10.1109/tvcg.2018.2865025", "10.1109/tvcg.2006.85", "10.1109/tvcg.2014.2346331", "10.1109/beliv.2018.8634420", "10.1109/tvcg.2017.2745181", "10.1111/cgf.13677", "10.1109/tvcg.2018.2864844", "10.1109/tvcg.2013.126", "10.1109/tvcg.2018.2864811", "10.1109/infvis.2005.1532147", "10.1177/0956797613504966", "10.1145/2669557.2669579", "10.1109/mcg.2005.102", "10.1109/visual.2003.1250426", "10.1136/bmj.39489.470347.ad", "10.1109/tvcg.2017.2744080", "10.1109/mcg.2009.53", "10.1111/j.1467-8527.2005.00307.x", "10.1109/tvcg.2010.132", "10.1109/tvcg.2018.2864886", "10.1109/tvcg.2018.2864843", "10.1109/tvcg.2018.2865028", "10.1109/tvcg.2018.2865051", "10.1109/tvcg.2018.2865044", "10.1109/tvcg.2018.2865026", "10.1007/978-3-540-71080-6\\_6", "10.1109/tvcg.2018.2865020", "10.1177/1473871611407399", "10.1109/tvcg.2018.2864504", "10.1109/tvcg.2018.2864526", "10.1109/tvcg.2005.53", "10.1109/tvcg.2018.2864905", "10.1049/sej.1991.0040", "10.1109/tvcg.2015.2513410", "10.1109/tvcg.2017.2711030", "10.1109/tvcg.2011.279", "10.1109/vast.2017.8585505", "10.1147/jrd.2010.2042914", "10.1016/s0378-7206(98)00044-5", "10.1145/2993901.2993913", "10.1109/tvcg.2018.2865041", "10.1109/tvcg.2018.2864812", "10.1109/tvcg.2017.2744758", "10.1145/1168149.1168158", "10.1109/tvcg.2017.2745279", "10.1109/tvcg.2012.213", "10.1109/tvcg.2017.2744738", "10.1109/tvcg.2017.2745083", "10.1109/tvcg.2018.2864826", "10.1145/1377966.1377974", "10.1109/apec.2009.4802646", "10.1145/1168149.1168152", "10.1016/j.jss.2008.03.059", "10.1109/vast.2017.8585484", "10.1109/tvcg.2017.2744818", "10.1109/tvcg.2017.2744358", "10.1109/tvcg.2018.2864499", "10.1109/tvcg.2018.2865042", "10.1109/tvcg.2017.2744898"], "wos": 1, "children": [{"doi": "10.1109/tvcg.2020.3030388", "title": "Visualization of Human Spine Biomechanics for Spinal Surgery", "year": "2020", "conferenceName": "SciVis", "authors": "Pepe Eulzer;Sabine Bauer;Francis Kilian;Kai Lawonn", "citationCount": "0", "affiliation": "Eulzer, P (Corresponding Author), Univ Jena, Jena, Germany. Eulzer, Pepe; Lawonn, Kai, Univ Jena, Jena, Germany. Bauer, Sabine, Univ Koblenz Landau, Koblenz, Germany. Kilian, Francis, Cath Clin Koblenz Montabaur, Dept Spine Surg, Koblenz, Germany.", "countries": "Germany", "abstract": "We propose a visualization application, designed for the exploration of human spine simulation data. Our goal is to support research in biomechanical spine simulation and advance efforts to implement simulation-backed analysis in surgical applications. Biomechanical simulation is a state-of-the-art technique for analyzing load distributions of spinal structures. Through the inclusion of patient-specific data, such simulations may facilitate personalized treatment and customized surgical interventions. Difficulties in spine modelling and simulation can be partly attributed to poor result representation, which may also be a hindrance when introducing such techniques into a clinical environment. Comparisons of measurements across multiple similar anatomical structures and the integration of temporal data make commonly available diagrams and charts insufficient for an intuitive and systematic display of results. Therefore, we facilitate methods such as multiple coordinated views, abstraction and focus and context to display simulation outcomes in a dedicated tool. $\\mathrm{By}$ linking the result data with patient-specific anatomy, we make relevant parameters tangible for clinicians. Furthermore, we introduce new concepts to show the directions of impact force vectors, which were not accessible before. We integrated our toolset into a spine segmentation and simulation pipeline and evaluated our methods with both surgeons and biomechanical researchers. When comparing our methods against standard representations that are currently in use, we found increases in accuracy and speed in data exploration tasks. $\\mathrm{in}$ a qualitative review, domain experts deemed the tool highly useful when dealing with simulation result data, which typically combines time-dependent patient movement and the resulting force distributions on spinal structures.", "keywords": "Medical visualization,bioinformatics,coordinated views,focus and context,biomechanical simulation", "link": "http://dx.doi.org/10.1109/TVCG.2020.3030388", "refList": ["10.1109/tvcg.2018.2864903", "10.1177/1473871613510429", "10.1093/ehjqcco/qcz052", "10.1109/tvcg.2007.70594", "10.1109/tvcg.2018.2865076", "10.1055/s-0039-1687862", "10.1109/visual.1990.146375", "10.1109/tvcg.2017.2744198", "10.1016/j.ijmedinf.2014.10.001", "10.1109/tvcg.2013.124", "10.1016/j.jacc", "10.1111/cgf.13167", "10.17705/1thci.00055", "10.1136/bmjqs.2009.037895", "10.1109/tvcg.2013.238", "10.1109/tvcg.2018.2865240", "10.1186/1471-2261-6-34", "10.1109/tvcg.2019.2934264", "10.1109/tvcg.2013.200", "10.1109/tvcg.2011.209", "10.1109/tvcg.2014.2346682", "10.1109/tvcg.2015.2467091", "10.1136/bmjopen-2019-033208", "10.1109/beliv.2018.8634027", "10.1109/tvcg.2012.213", "10.1109/tvcg.2015.2467191", "10.1109/tvcg.2015.2467325", "10.1145/2133806.2133821", "10.1145/1806799.1806866", "10.1108/02635570610688869", "10.1002/hbm.20701", "10.1561/1100000039", "10.1145/3025453.3025645", "10.1109/tvcg.2009.111", "10.1109/tvcg.2013.120", "10.1109/tvcg.2016.2599030"], "wos": 1, "children": [], "len": 1}], "len": 3}], "len": 5}, {"doi": "10.1111/cgf.13987", "year": "2020", "title": "Augmenting Node-Link Diagrams with Topographic Attribute Maps", "conferenceName": "EuroVis", "authors": "Reinhold Preiner;Johanna Schmidt;Katharina Kr{\\\"{o}}sl;Tobias Schreck;Gabriel Mistelbauer", "citationCount": "0", "affiliation": "Preiner, R (Corresponding Author), Graz Univ Technol, Inst Comp Graph \\& Knowledge Visualizat, Graz, Austria.\nPreiner, R.; Schreck, T., Graz Univ Technol, Inst Comp Graph \\& Knowledge Visualizat, Graz, Austria.\nSchmidt, J.; Kroesl, K., Virtual Real \\& Visualisierung Forsch GmbH, VRVis Zentrum, Vienna, Austria.\nKroesl, K., TU Wien, Inst Visual Comp \\& Human Ctr Technol, Vienna, Austria.\nMistelbauer, G., Otto von Guericke Univ, Dept Simulat \\& Graph, Magdeburg, Germany.", "countries": "Germany;Austria", "abstract": "We propose a novel visualization technique for graphs that are attributed with scalar data. In many scenarios, these attributes (e.g., birth date in a family network) provide ambient context information for the graph structure, whose consideration is important for different visual graph analysis tasks. Graph attributes are usually conveyed using different visual representations (e.g., color, size, shape) or by reordering the graph structure according to the attribute domain (e.g., timelines). While visual encodings allow graphs to be arranged in a readable layout, assessing contextual information such as the relative similarities of attributes across the graph is often cumbersome. In contrast, attribute-based graph reordering serves the comparison task of attributes, but typically strongly impairs the readability of the structural information given by the graph's topology. In this work, we augment force-directed node-link diagrams with a continuous ambient representation of the attribute context. This way, we provide a consistent overview of the graph's topological structure as well as its attributes, supporting a wide range of graph-related analysis tasks. We resort to an intuitive height field metaphor, illustrated by a topographic map rendering using contour lines and suitable color maps. Contour lines visually connect nodes of similar attribute values, and depict their relative arrangement within the global context. Moreover, our contextual representation supports visualizing attribute value ranges associated with graph nodes (e.g., lifespans in a family network) as trajectories routed through this height field. We discuss how user interaction with both the structural and the contextual information fosters exploratory graph analysis tasks. The effectiveness and versatility of our technique is confirmed in a user study and case studies from various application domains.", "keywords": "", "link": "https://doi.org/10.1111/cgf.13987", "refList": ["10.1109/tvcg.2013.269", "10.1109/pacificvis.2010.5429590", "10.1073/pnas.0307654100", "10.1145/2505515.2505758", "10.1559/152304082783948286", "10.1109/pacificvis.2014.47", "10.1093/bioinformatics/btp432", "10.1111/j.1467-8659.2011.01898.x", "10.1111/cgf.12931", "10.1111/cgf.12880", "10.1109/tvcg.2014.2346422", "10.1111/j.1467-8659.2009.01706.x", "10.1109/tvcg.2016.2598795", "10.1111/cgf.12800", "10.1109/tvcg.2014.2315995", "10.1111/cgf.12656", "10.1111/cgf.13728", "10.1109/tvcg.2009.122", "10.1111/cgf.13211", "10.1109/tvcg.2007.70596", "10.1109/infvis.2002.1173152", "10.1109/tvcg.2015.2467691", "10.1109/tvcg.2003.1196007", "10.1109/infvis.2005.1532150", "10.1145/3243250.3243266", "10.1080/02693799008941549", "10.1371/journal.pone.0058779", "10.1109/infvis.1995.528686", "10.1111/cgf.12872", "10.1002/spe.4380211102", "10.1109/38.974518", "10.1145/3097983.3098130", "10.1002/aris.1440370106", "10.1145/1360612.1360691", "10.1109/mc.2016.145", "10.2307/3006914", "10.1111/j.1467-8659.2009.01683.x", "10.1145/1639714.1639784"], "wos": 1, "children": [], "len": 1}], "len": 31}, {"doi": "10.1111/cgf.13210", "year": "2017", "title": "The State-of-the-Art in Predictive Visual Analytics", "conferenceName": "EuroVis", "authors": "Yafeng Lu;Rolando Garcia;Brett Hansen;Michael Gleicher;Ross Maciejewski", "citationCount": "22", "affiliation": "Lu, YF (Corresponding Author), Arizona State Univ, Sch Comp Informat \\& Decis Syst Engn, Tempe, AZ 85287 USA.\nLu, Yafeng; Garcia, Rolando; Hansen, Brett; Maciejewski, Ross, Arizona State Univ, Sch Comp Informat \\& Decis Syst Engn, Tempe, AZ 85287 USA.\nGleicher, Michael, Univ Wisconsin, Dept Comp Sci, 1210 W Dayton St, Madison, WI 53706 USA.", "countries": "USA", "abstract": "Predictive analytics embraces an extensive range of techniques including statistical modeling, machine learning, and data mining and is applied in business intelligence, public health, disaster management and response, and many other fields. To date, visualization has been broadly used to support tasks in the predictive analytics pipeline. Primary uses have been in data cleaning, exploratory analysis, and diagnostics. For example, scatterplots and bar charts are used to illustrate class distributions and responses. More recently, extensive visual analytics systems for feature selection, incremental learning, and various prediction tasks have been proposed to support the growing use of complex models, agent-specific optimization, and comprehensive model comparison and result exploration. Such work is being driven by advances in interactive machine learning and the desire of end-users to understand and engage with the modeling process. In this state-of-the-art report, we catalogue recent advances in the visualization community for supporting predictive analytics. First, we define the scope of predictive analytics discussed in this article and describe how visual analytics can support predictive analytics tasks in a predictive visual analytics (PVA) pipeline. We then survey the literature and categorize the research with respect to the proposed PVA pipeline. Systems and techniques are evaluated in terms of their supported interactions, and interactions specific to predictive analytics are discussed. We end this report with a discussion of challenges and opportunities for future research in predictive visual analytics.", "keywords": "", "link": "https://doi.org/10.1111/cgf.13210", "refList": ["10.1109/tvcg.2015.2467622", "10.1109/tvcg.2014.2346578", "10.1109/pacificvis.2016.7465248", "10.1109/tvcg.2016.2598828", "10.1109/vast.2015.7347637", "10.1109/tvcg.2013.125", "10.1109/vast.2011.6102451", "10.1214/10-sts330", "10.1109/mcg.2014.52", "10.1111/j.1467-8659.2011.01938.x", "10.1109/tvcg.2011.188", "10.1109/vast.2012.6400492", "10.1109/visual.2000.885740", "10.1126/science.1248506", "10.1109/jstars.2015.2388496", "10.1109/tvcg.2011.212", "10.1111/j.1467-8659.2009.01684.x", "10.1109/vast.2010.5652443", "10.1109/tvcg.2010.82", "10.1109/vast.2011.6102448", "10.1145/312129.312298", "10.1111/cgf.12886", "10.1109/tvcg.2014.2346926", "10.1109/tvcg.2016.2598838", "10.1109/pacificvis.2013.6596144", "10.1109/pacificvis.2015.7156366", "10.1109/icdmw.2010.181", "10.1109/vast.2015.7347626", "10.1007/978-1-4471-6497-5\\_1", "10.1109/pacificvis.2011.5742377", "10.1109/tvcg.2013.138", "10.1111/j.1467-8659.2011.01940.x", "10.1109/tvcg.2015.2468078", "10.1109/tvcg.2014.2346482", "10.1109/pacificvis.2014.33", "10.1109/tvcg.2014.2331979", "10.1109/tvcg.2012.277", "10.1111/cgf.12630", "10.1109/tvcg.2010.138", "10.1109/tvcg.2011.197", "10.1109/tvcg.2016.2598829", "10.1109/mcg.2014.61", "10.1109/tvcg.2014.2346660", "10.1109/vast.2011.6102457", "10.1093/bioinformatics/bth351", "10.1109/pacificvis.2015.7156353", "10.1007/978-3-319-46493-0\\_1", "10.1109/tvcg.2007.70515", "10.1057/palgrave.ivs.9500091", "10.1109/vast.2011.6102453", "10.1111/cgf.12899", "10.1145/2858036.2858150", "10.1145/2858036.2858529", "10.1109/pacificvis.2013.6596145", "10.1109/vast.2012.6400484", "10.1109/vast.2012.6400488", "10.1038/494155a", "10.1109/vast.2014.7042495", "10.1007/978-3-540-71080-6\\_6", "10.1007/978-3-642-00304-2\\_1", "10.1109/pacificvis.2013.6596154", "10.1109/iv.2013.21", "10.1007/978-3-540-71080-6\\_10", "10.1109/pacificvis.2016.7465260", "10.1145/1562849.1562851", "10.1111/cgf.12650", "10.1145/347090.347124", "10.1111/j.1467-8659.2011.01939.x", "10.1109/vast.2009.5333431", "10.1109/vast.2010.5654445", "10.1109/pacificvis.2015.7156389", "10.1109/vast.2012.6400486", "10.1109/tvcg.2016.2598831", "10.5591/978-1-57735-516-8/ijcai11-289", "10.1111/j.1467-8659.2012.03108.x", "10.1109/vast.2011.6102439", "10.1007/s11704-016-6028-y", "10.1109/tvcg.2012.64", "10.1145/2207676.2207741", "10.1109/vast.2010.5652484", "10.1109/vast.2010.5652392", "10.1109/tvcg.2016.2598541", "10.1109/tvcg.2012.258", "10.1111/cgf.12907", "10.1109/tvcg.2012.278", "10.1111/j.1467-8659.2011.01918.x", "10.1109/tvcg.2012.207", "10.1111/j.1467-8659.2011.01920.x", "10.1111/cgf.12520", "10.1007/s11390-016-1663-1", "10.1109/vast.2010.5652398"], "wos": 1, "children": [{"doi": "10.1109/tvcg.2018.2865043", "title": "RegressionExplorer: Interactive Exploration of Logistic Regression Models with Subgroup Analysis", "year": "2018", "conferenceName": "VAST", "authors": "Dennis Dingen;Marcel van 't Veer;Patrick Houthuizen;Eveline H. J. Mestrom;Hendrikus H. M. Korsten;Arthur R. A. Bouwman;Jarke J. van Wijk", "citationCount": "5", "affiliation": "Dingen, D (Corresponding Author), Eindhoven Univ Technol, Eindhoven, Netherlands. Dingen, Dennis; van Wijk, Jarke, Eindhoven Univ Technol, Eindhoven, Netherlands. van't Veer, Marcel; Houthuizen, Patrick; Mestrom, Eveline H. J.; Korsten, Erik H. H. M.; Bouwman, Arthur R. A., Catharina Hosp, Eindhoven, Netherlands.", "countries": "Netherlands", "abstract": "We present RegressionExplorer, a Visual Analytics tool for the interactive exploration of logistic regression models. Our application domain is Clinical Biostatistics, where models are derived from patient data with the aim to obtain clinically meaningful insights and consequences. Development and interpretation of a proper model requires domain expertise and insight into model characteristics. Because of time constraints, often a limited number of candidate models is evaluated. RegressionExplorer enables experts to quickly generate, evaluate, and compare many different models, taking the workflow for model development as starting point. Global patterns in parameter values of candidate models can be explored effectively. In addition, experts are enabled to compare candidate models across multiple subpopulations. The insights obtained can be used to formulate new hypotheses or to steer model development. The effectiveness of the tool is demonstrated for two uses cases: prediction of a cardiac conduction disorder in patients after receiving a heart valve implant and prediction of hypernatremia in critically ill patients.", "keywords": "Visual analytics,Predictive visual analytics,Exploratory data analysis,Multivariate statistics,Regression analysis,Variable selection,Subgroup analysis", "link": "http://dx.doi.org/10.1109/TVCG.2018.2865043", "refList": ["10.1214/12-aos1058", "10.21037/jtd.2016.06.46", "10.1093/jamia/ocv006", "10.1109/tvcg.2013.125", "10.1007/s11704-016-6028-y", "10.1109/tvcg.2014.2350494", "10.1145/2590349", "10.1038/srep06085", "10.1002/pds.4328", "10.1111/cgf.13210", "10.1109/pacificvis.2016.7465261", "10.1007/978-3-642-21716-6\\_15", "10.1109/tvcg.2015.2467931", "10.1145/2678025.2701407", "10.1109/tvcg.2015.2467325", "10.1109/vast.2012.6400537", "10.1111/j.1467-8659.2009.01684.x", "10.1561/1100000039", "10.1109/mcg.2016.59", "10.1007/s11390-016-1663-1", "10.1198/000313002533", "10.1109/vast.2011.6102453"], "wos": 1, "children": [{"doi": "10.1109/pacificvis48177.2020.7090", "year": "2020", "title": "ExplainExplore: Visual Exploration of Machine Learning Explanations", "conferenceName": "PacificVis", "authors": "Dennis Collaris;Jarke J. van Wijk", "citationCount": "0", "affiliation": "Collaris, D (Corresponding Author), Eindhoven Univ Technol, Eindhoven, Netherlands.\nCollaris, Dennis; van Wijk, Jarke J., Eindhoven Univ Technol, Eindhoven, Netherlands.", "countries": "Netherlands", "abstract": "Machine learning models often exhibit complex behavior that is difficult to understand. Recent research in explainable AI has produced promising techniques to explain the inner workings of such models using feature contribution vectors. These vectors are helpful in a wide variety of applications. However, there are many parameters involved in this process and determining which settings are best is difficult due to the subjective nature of evaluating interpretability. To this end, we introduce EXPLAINEXPLORE: an interactive explanation system to explore explanations that fit the subjective preference of data scientists. We leverage the domain knowledge of the data scientist to find optimal parameter settings and instance perturbations, and enable the discussion of the model and its explanation with domain experts. We present a use case on a real-world dataset to demonstrate the effectiveness of our approach for the exploration and tuning of machine learning explanations.", "keywords": "Human-centered computing; Visualization; Computing methodologies; Machine learning", "link": "https://doi.org/10.1109/PacificVis48177.2020.7090", "refList": ["10.1145/3097983.3098047", "10.1109/tvcg.2016.2598838", "10.1145/2702123.2702509", "10.1109/tvcg.2016.2598828", "10.1609/aimag.v38i3.2741", "10.1137/1.9781611973440.78", "10.1109/tvcg.2013.125", "10.2307/2528823", "10.1111/j.1467-8659.2009.01475.x", "10.1145/2858036.2858529", "10.1080/13658810701349037", "10.1214/15-aoas848", "10.1145/2939672.2939778", "10.1109/tvcg.2015.2467554", "10.1038/494155a", "10.1145/2487575.2487579", "10.1145/2783258.2788613", "10.1109/icassp.1999.756335", "10.1111/cgf.12877", "10.1109/mlsp.2016.7738872", "10.1109/tvcg.2018.2865043", "10.1109/iv.2003.1217950", "10.1109/visual.1993.398859", "10.1109/tvcg.2014.2331979", "10.1016/j.ijhcs.2009.03.004", "10.1109/tvcg.2014.2346660", "10.1016/j.cor.2004.03.017", "10.1111/j.1467-8659.2009.01684.x", "10.1145/347090.347124", "10.1109/vast.2010.5652443", "10.1016/j.neucom.2017.01.105", "10.1007/978-3-319-04717-1\\_9", "10.1109/tvcg.2018.2864499", "10.1109/tvcg.2016.2598831", "10.1109/vast.2011.6102453"], "wos": 1, "children": [], "len": 1}], "len": 3}, {"doi": "10.1109/tvcg.2019.2934631", "title": "Explaining Vulnerabilities to Adversarial Machine Learning through Visual Analytics", "year": "2019", "conferenceName": "VAST", "authors": "Yuxin Ma;Tiankai Xie;Jundong Li;Ross Maciejewski", "citationCount": "5", "affiliation": "Ma, YX (Corresponding Author), Arizona State Univ, Sch Comp Informat \\& Decis Syst Engn, Tempe, AZ 85287 USA. Ma, Yuxin; Xie, Tiankai; Maciejewski, Ross, Arizona State Univ, Sch Comp Informat \\& Decis Syst Engn, Tempe, AZ 85287 USA. Li, Jundong, Univ Virginia, Dept Elect \\& Comp Engn, Charlottesville, VA 22903 USA.", "countries": "USA", "abstract": "Machine learning models are currently being deployed in a variety of real-world applications where model predictions are used to make decisions about healthcare, bank loans, and numerous other critical tasks. As the deployment of artificial intelligence technologies becomes ubiquitous, it is unsurprising that adversaries have begun developing methods to manipulate machine learning models to their advantage. While the visual analytics community has developed methods for opening the black box of machine learning models, little work has focused on helping the user understand their model vulnerabilities in the context of adversarial attacks. In this paper, we present a visual analytics framework for explaining and exploring model vulnerabilities to adversarial attacks. Our framework employs a multi-faceted visualization scheme designed to support the analysis of data poisoning attacks from the perspective of models, data instances, features, and local structures. We demonstrate our framework through two case studies on binary classifiers and illustrate model vulnerabilities with respect to varying attack strategies.", "keywords": "Adversarial machine learning,data poisoning,visual analytics", "link": "http://dx.doi.org/10.1109/TVCG.2019.2934631", "refList": ["10.1109/tvcg.2014.2346578", "10.1109/jbhi.2014.2344095", "10.1109/tvcg.2016.2598838", "10.3390/informatics5030031", "10.1145/1014052.1014066", "10.1109/tvcg.2017.2744938", "10.1145/2089125.2089129", "10.1145/2702123.2702509", "10.1109/vast.2017.8585721", "10.1109/tits.2017.2706978", "10.1109/tvcg.2016.2598828", "10.1109/tvcg.2013.65", "10.1109/vl.1996.545307", "10.1007/s11704-016-6028-y", "10.1007/s10994-010-5188-5", "10.1145/2858036.2858529", "10.1016/j.visinf.2017.01.006", "10.1109/5.726791", "10.1109/tvcg.2018.2864499", "10.1109/tvcg.2018.2864475", "10.1145/3190618", "10.1007/s10462-009-9109-6", "10.1109/tvcg.2018.2865044", "10.1111/cgf.13210", "10.1109/tvcg.2018.2816223", "10.3233/978-1-61499-098-7-870", "10.1109/tvcg.2018.2864504", "10.1109/vast.2017.8585720", "10.1109/tvcg.2014.2346482", "10.1109/tvcg.2014.2346594", "10.1109/tkde.2013.57", "10.1016/j.patcog.2018.07.023", "10.1109/tvcg.2018.2864812", "10.1007/978-3-030-10925-74", "10.1109/tvcg.2017.2744878", "10.1109/msp.2015.2426728", "10.1145/1562849.1562851", "10.1007/978-3-642-40994-325", "10.1109/tvcg.2014.2346660", "10.1038/nature21056", "10.1109/tvcg.2018.2864500", "10.1109/tvcg.2017.2744158", "10.1145/3041008.3041012", "10.1109/tvcg.2018.2865027", "10.1109/tvcg.2014.2346574", "10.1109/tvcg.2017.2744378", "10.1109/sp.2018.00057", "10.1145/2254556.2254651", "10.1109/tvcg.2017.2754480", "10.1109/vast.2011.6102453"], "wos": 1, "children": [{"doi": "10.1109/tvcg.2020.3028888", "title": "A Visual Analytics Framework for Explaining and Diagnosing Transfer Learning Processes", "year": "2020", "conferenceName": "VAST", "authors": "Yuxin Ma;Arlen Fan;Jingrui He;Arun Reddy Nelakurthi;Ross Maciejewski", "citationCount": "0", "affiliation": "Ma, YX (Corresponding Author), Arizona State Univ, Tempe, AZ 85287 USA. Ma, Yuxin; Fan, Arlen; Maciejewski, Ross, Arizona State Univ, Tempe, AZ 85287 USA. He, Jingrui, Univ Illinois, Champaign, IL USA. Nelakurthi, Arun Reddy, Samsung Res Amer, Mountain View, CA USA.", "countries": "USA", "abstract": "Many statistical learning models hold an assumption that the training data and the future unlabeled data are drawn from the same distribution. However, this assumption is difficult to fulfill in real-world scenarios and creates barriers in reusing existing labels from similar application domains. Transfer Learning is intended to relax this assumption by modeling relationships between domains, and is often applied in deep learning applications to reduce the demand for labeled data and training time. Despite recent advances in exploring deep learning models with visual analytics tools, little work has explored the issue of explaining and diagnosing the knowledge transfer process between deep learning models. In this paper, we present a visual analytics framework for the multi-level exploration of the transfer learning processes when training deep neural networks. Our framework establishes a multi-aspect design to explain how the learned knowledge from the existing model is transferred into the new learning task when training deep neural networks. Based on a comprehensive requirement and task analysis, we employ descriptive visualization with performance measures and detailed inspections of model behaviors from the statistical, instance, feature, and model structure levels. We demonstrate our framework through two case studies on image classification by fine-tuning AlexNets to illustrate how analysts can utilize our framework.", "keywords": "Transfer learning,deep learning,visual analytics", "link": "http://dx.doi.org/10.1109/TVCG.2020.3028888", "refList": ["10.1109/tvcg.2014.2346578", "10.1109/tvcg.2019.2934629", "10.1109/tvcg.2017.2744683", "10.1109/tvcg.2016.2598838", "10.1109/tvcg.2017.2744938", "10.1109/tvcg.2019.2934262", "10.1109/tpami.2018.2868685", "10.1145/2702123.2702509", "10.1109/vast.2017.8585721", "10.1109/tvcg.2018.2843369", "10.1109/tvcg.2016.2598828", "10.1111/j.1467-8659.2011.01898.x", "10.1109/tvcg.2013.65", "10.1145/2976749.2978318", "10.1007/978-3-030-01424-7\\_27", "10.1109/tvcg.2019.2934261", "10.1007/s11704-016-6028-y", "10.1016/j.visinf.2017.01.006", "10.1145/2858036.2858529", "10.1109/iccv.2015.279", "10.1109/mci.2018.2840738", "10.1109/tvcg.2019.2892483", "10.1109/vast.2018.8802509", "10.1109/tvcg.2013.124", "10.1186/s40537-016-0043-6", "10.1109/tvcg.2018.2864475", "10.1145/3200489", "10.1109/tvcg.2018.2865044", "10.1111/cgf.13210", "10.1109/tvcg.2018.2816223", "10.23915/distill.00007", "10.1109/tvcg.2017.2744199", "10.1109/tkde.2018.2876857", "10.1109/tvcg.2019.2934631", "10.1109/tvcg.2018.2864504", "10.1109/tvcg.2014.2346482", "10.1109/tvcg.2015.2467618", "10.1109/tvcg.2014.2346594", "10.1109/tvcg.2011.188", "10.1007/978-3-642-15561-1\\_16", "10.1109/tvcg.2018.2864812", "10.1109/mcg.2019.2919033", "10.1109/tvcg.2017.2744718", "10.1109/tvcg.2017.2744878", "10.1109/tvcg.2016.2598541", "10.1109/tkde.2009.191", "10.1145/3065386", "10.1016/j.ins.2016.03.021", "10.1109/tvcg.2019.2903943", "10.1007/s10994-009-5152-4", "10.1109/tvcg.2019.2934659", "10.1109/tvcg.2018.2864500", "10.1109/iccv.2017.74", "10.1109/tvcg.2017.2744158", "10.1109/tvcg.2012.207", "10.1111/cgf.13092", "10.1109/tvcg.2018.2865027", "10.1109/tvcg.2017.2744378", "10.1109/tvcg.2017.2744358", "10.1109/tvcg.2019.2934619", "10.1109/tvcg.2018.2864499", "10.1109/tvcg.2017.2754480", "10.1109/tvcg.2016.2598831"], "wos": 1, "children": [], "len": 1}, {"doi": "10.1111/cgf.14034", "year": "2020", "title": "The State of the Art in Enhancing Trust in Machine Learning Models with the Use of Visualizations", "conferenceName": "EuroVis", "authors": "Angelos Chatzimparmpas;Rafael Messias Martins;Ilir Jusufi;Kostiantyn Kucher;Fabrice Rossi;Andreas Kerren", "citationCount": "2", "affiliation": "Chatzimparmpas, A (Corresponding Author), Linnaeus Univ, Dept Comp Sci \\& Media Technol, Vaxjo, Sweden.\nChatzimparmpas, A.; Martins, R. M.; Jusufi, I.; Kucher, K.; Kerren, A., Linnaeus Univ, Dept Comp Sci \\& Media Technol, Vaxjo, Sweden.\nRossi, F., PSL Univ, Univ Paris Dauphine, Ceremade, Paris, France.", "countries": "Sweden;France", "abstract": "Machine learning (ML) models are nowadays used in complex applications in various domains, such as medicine, bioinformatics, and other sciences. Due to their black box nature, however, it may sometimes be hard to understand and trust the results they provide. This has increased the demand for reliable visualization tools related to enhancing trust in ML models, which has become a prominent topic of research in the visualization community over the past decades. To provide an overview and present the frontiers of current research on the topic, we present a State-of-the-Art Report (STAR) on enhancing trust in ML models with the use of interactive visualization. We define and describe the background of the topic, introduce a categorization for visualization techniques that aim to accomplish this goal, and discuss insights and opportunities for future research directions. Among our contributions is a categorization of trust against different facets of interactive ML, expanded and improved from previous research. Our results are investigated from different analytical perspectives: (a) providing a statistical overview, (b) summarizing key findings, (c) performing topic analyses, and (d) exploring the data sets used in the individual papers, all with the support of an interactive web-based survey browser. We intend this survey to be beneficial for visualization researchers whose interests involve making ML models more trustworthy, as well as researchers and practitioners from other disciplines in their search for effective visualization techniques suitable for solving their tasks with confidence and conveying meaning to their data.", "keywords": "trustworthy machine learning; visualization; interpretable machine learning; explainable machine learning", "link": "https://doi.org/10.1111/cgf.14034", "refList": ["10.1109/mcg.2018.2878902", "10.1109/tvcg.2008.153", "10.2312/mlvis.20181130", "10.1109/tvcg.2016.2598828", "10.1145/3290605.3300911", "10.1145/2993901.2993909", "10.2312/mlvis.20191158", "10.1109/tvcg.2016.2598446", "10.1111/j.1467-8659.2009.01475.x", "10.1145/3290605.3300809", "10.1109/pacificvis.2018.00031", "10.1055/s-0029-1216348", "10.1007/978-3-319-90403-0\\_13", "10.1109/tvcg.2017.2745085", "10.1111/j.1467-8659.2011.01938.x", "10.1007/978-3-319-54024-5\\_6", "10.1016/s0167-9473(01)00065-2", "10.1111/cgf.12895", "10.2312/eurovisshort.20141152.17", "10.2312/eurova.20151098.22", "10.1111/cgf.13667", "10.3115/1072228.1072378", "10.1109/tbdata.2018.2877350.16", "10.1109/lars.2009.5418323.25", "10.1109/tvcg.2017.2744878", "10.1016/j.combustflame.2005.09.018", "10.1016/j.cag.2014.01.006", "10.1109/tvcg.2016.2570755", "10.2312/mlvis.20191158.1,19", "10.1518/hfes.46.1.50.30392", "10.1145/3301275.3302280", "10.1145/3351095.3372834.1", "10.1016/s0377-2217(01)00264-8", "10.1111/cgf.13424", "10.1007/978-3-319-23485-4\\_53", "10.1007/978-94-007-0753-5\\_3623", "10.1109/tvcg.2013.101", "10.1111/cgf.12884", "10.1111/j.1467-8659.2010.01835.x", "10.1021/ci9901338", "10.4230/lipics.itcs:2017", "10.1109/mis.2013.24", "10.1109/tvcg.2014.2346482", "10.1109/tvcg.2018.2865230", "10.1073/pnas.1807180116", "10.1109/dsaa.2018.00018", "10.1109/tvcg.2009.153", "10.3115/1219840.1219855", "10.1109/tvcg.2018.2864812", "10.1109/tvcg.2018.2872577", "10.2312/trvis.20191183", "10.1109/cvpr:2004.383", "10.1109/vast.2008.4677350", "10.1145/302979.303001", "10.1109/tvcg.2018.2864499", "10.1111/cgf.13672", "10.1109/tvcg.2014.2346626", "10.23915/distill.00010.18", "10.1109/tvcg.2017.2744805", "10.2312/mlvis:20191160.18", "10.23915/distill:00016", "10.1109/pacificvis.2016.7465260", "10.1111/cgf.13683", "10.23915/distill.00016.19", "10.1145/32906053.300803.22", "10.1109/tvcg.2014.2346574", "10.1177/1473871615600010", "10.1109/tvcg.2016.2598831", "10.1145/3230623", "10.1109/visual.2019.8933744", "10.1145/2993901.2993915", "10.1016/j.visinf.2017.01.006", "10.1145/2993901.2993914", "10.1109/tvcg.2014.2346984", "10.1109/5.726791", "10.23915/distill.00010", "10.1109/tvcg.2018.2864825", "10.2307/2394164", "10.1109/tvcg.2017.2744458", "10.1145/2993901.2993917.28", "10.1111/cgf.13711", "10.1109/tvcg.2016.2598664", "10.2307/2530428", "10.1109/icdar.1997.620583", "10.1109/tvcg.2017.2744718", "10.1111/cgf.13425", "10.1109/tvcg.2019.2903943", "10.1145/1518701.1518895", "10.1109/tvcg.2018.2864838", "10.1145/62038.62043", "10.1111/j.1467-8659.2011.01920.x", "10.1145/3025171.3025208", "10.1145/355112.355124", "10.1109/vast.2010.5652398", "10.1109/tvcg.2014.2346578", "10.1145/3173574.3174209", "10.4178/epih/e2014008", "10.1109/beliv.2018.8634201.25,28", "10.1016/j.eswa.2007.12.020", "10.1111/cgf:13406", "10.1109/mcg.2011.103", "10.1631/fitee.1700808", "10.1109/tvcg.2017.2745158", "10.1073/pnas.0307752101", "10.1109/tvcg.2018.2816223", "10.1109/tvcg.2017.2745141", "10.1145/32232.32234", "10.1109/tvcg.2019.2934267", "10.1109/tvcg.2018.2864477", "10.1145/3132169", "10.2312/eurova.20151100.19", "10.1145/3172944.3172964", "10.1145/2601248.2601268", "10.1109/isai-nlp.2018.8693002.1", "10.1111/cgf.13404", "10.1007/s100320200071", "10.2312/trvis.20191183.16", "10.1111/cgf.12755", "10.1145/2702123.2702509", "10.1145/1401890.1402008.25", "10.1109/tvcg.2012.65", "10.1177/1473871617733996", "10.2312/trvis.20191187.7", "10.21236/ada273556", "10.1109/vast.2010.5652450", "10.1111/j.1467-8659.2011.01940.x", "10.1177/875647939000600106", "10.1109/tvcg.2017.2711030", "10.1016/j.immuni.2016.04.014", "10.1109/tvcg.2019.2934209", "10.1016/0095-0696(78)90006-2", "10.1016/j.jclinepi.2015.04.014", "10.1016/j.ress.2013.02.013", "10.1111/cgf.12640", "10.1145/1015330.1015388.25", "10.1111/j.1467-8659.2009.01468.x", "10.1145/1541880.1541882", "10.1109/vast.2011.6102453", "10.1016/s0008-8846(98)00165-3", "10.2312/trvis.20191186.7", "10.1007/s13748-013-0040-3", "10.1109/tvcg.2015.2467757", "10.1109/tbdata.2018.2877350", "10.1109/vast.2017.8585613", "10.1080/10556789208805504", "10.1109/vast.2012.6400484", "10.1145/3025171.3025181", "10.1007/978-3-319-90403-0\\_12", "10.1109/mcg.2019.2922592", "10.1021/ci000392t", "10.1109/vast.2007.4389000", "10.1111/cgf.13406.16", "10.1111/cgf.13684", "10.2312/eurovisshort.20161166.17", "10.2312/evs:20191168", "10.1145/3041021.3055135", "10.1145/3301275.3302265", "10.1613/jair.4135", "10.1109/tvcg.2018.2864500", "10.1109/tvcg.2017.2744158", "10.1109/ssci.2015.33", "10.1111/cgf.13453", "10.2312/pe/eurovast/eurova11/049-052", "10.1145/3025171.3025181.13", "10.1145/371920.372094", "10.1109/tvcg.2017.2744938", "10.1111/j.1467-8659.2012.03108.x", "10.1109/tvcg.2019.2934251", "10.1145/3290605.3300809.18", "10.1109/ldav.2016.7874305", "10.1109/vast.2016.7883514", "10.1109/iccv.2015.425", "10.1145/3301275.3302324", "10.1109/tnnls.2013.2292894", "10.1109/tvcg.2018.2865044", "10.1109/tvcg.2013.157", "10.1371/journal.pcbi.0020161", "10.1186/s12916-019-1426-2", "10.1109/10.867928", "10.1111/cgf.13217", "10.1109/mcg.2019.2919033", "10.1145/2993901.2993910", "10.1109/tvcg.2017.2744738", "10.2307/258792", "10.1111/cgf.12655", "10.1016/j.dss.2014.03.001", "10.1109/tvcg.2019.2904069", "10.1111/cgf.13205", "10.1002/mds.22340", "10.1109/tvcg.2019.2934595", "10.1287/inte.2018.0957", "10.1109/cvpr.2007.382974", "10.1109/tvcg.2012.280", "10.1145/2678025.2701399.13", "10.2312/mlvis.20181130.13", "10.2312/eurova.20181106.16", "10.1109/tvcg.2018.2864475", "10.2312/mlvis.20191160.18,22", "10.1007/978-1-4612-4026-6.25", "10.1109/cvpr.2006.42", "10.1145/3172944.3172950", "10.1109/cvpr.2004.383.25", "10.1109/tvcg.2019.2934812", "10.1609/aimag.v35i4.2513", "10.2312/trvis.20191185.7", "10.1111/j.1467-8659.2009.01684.x", "10.1371/journal.pone.0129126", "10.1111/cgf.13092", "10.1162/coli\\_a\\_00237", "10.1109/tvcg.2017.2744818", "10.1109/vast.2011.6102448", "10.1109/tvcg.2009.111", "10.1109/tvcg.2019.2934619", "10.1016/s0377-2217(01)00264-8.25", "10.1111/cgf.12639", "10.1109/access.2019.2919343", "10.1186/s12874-019-0681-4", "10.1109/pacificvis.2015.7156366", "10.1109/pacificvis.2018.00029", "10.1109/tvcg.2019.2934261", "10.1080/13506280444000102.http://www.uvt.nl/ticc", "10.1109/vast.2018.8802509", "10.1111/cgf.13212", "10.1145/3200489", "10.1111/cgf.13176", "10.1177/1473871620904671", "10.1007/978-3-319-10590-1\\_53", "10.1111/j.1467-8659.2012.03126.x", "10.1111/cgf.13172", "10.1145/3025171.3025208.6,21", "10.1111/cgf.12366", "10.1109/tvcg.2019.2934659", "10.1109/cvprw.2009.5206848", "10.1016/j.media.2014.11.010", "10.1109/tvcg.2017.2744683", "10.1109/tvcg.2019.2934262", "10.1016/j.neucom.2006.11.018", "10.1177/1473871615571951", "10.1371/journal.pcbi.0020161.25", "10.1177/1473871611415994", "10.2312/trvis20191187", "10.2312/eurova", "10.1145/2858036.2858529", "10.1145/2207676.2207738", "10.1007/s11042-009-0417-2", "10.1145/3301275.3302317", "10.1038/s41746-019-0148-3", "10.1145/3351095.3372834", "10.1080/10691898.2011.11889627", "10.1109/tvcg.2018.2864504", "10.1109/vast.2017.8585720", "10.1109/mcg.2018.053491732", "10.1007/s10994-010-5207-6", "10.1109/tvcg.2019.2934433", "10.1016/j.cag.2017.05.005", "10.1109/tvcg.2012.279", "10.1145/3231622.3231641.19,20", "10.1145/1562849.1562851", "10.1007/11564126\\_", "10.1109/tvcg.2018.2846735", "10.3115/1225403.1225421", "10.1109/vast.2012.6400486", "10.2312/eurova.20191116.22", "10.1109/tvcg.2007.70443", "10.1080/027868291009242", "10.2312/eurova.20151100", "10.1145/2939502.2939503.19", "10.1016/j.cag.2014.02.004", "10.1145/2939672.2939778", "10.1109/vast.2010.5652484", "10.1111/cgf.12641", "10.1145/3301275.3302289", "10.1109/visual.2019.8933619", "10.1109/tvcg.2017.2672987", "10.1109/vast.2016.7883517.20", "10.1109/igarss.2017.8127684", "10.1016/j.jcae.2010.04.002", "10.1109/vast.2010.5652885", "10.1016/j.visinf.2019.03.002", "10.1007/s00371-018-1500-3", "10.1109/mcg.2018.042731661", "10.1109/34.598228", "10.1109/tvcg.2018.2865027", "10.1016/j.neucom.2017.01.105", "10.1111/cgf.12389", "10.1109/tvcg.2019.2934591", "10.1109/vast.2010.5652392.16", "10.1111/cgf.13416", "10.1080/02701367.1992.10608764", "10.1109/vast.2017.8585721", "10.1109/tvcg.2018.2843369", "10.1109/sbes.2010.27", "10.1109/vast.2015.7347637", "10.1145/1401890.1402008", "10.1016/j.bpj.2010.04.064", "10.1109/tvcg.2013.125", "10.1109/isai-nlp.2018.8693002", "10.1371/journal.pone.0160127", "10.1145/2856767.2856779", "10.1145/2678025.2701399", "10.1109/vast.2011.6102451", "10.1109/mcg.2010.18", "10.1021/ci4000213", "10.1109/vast.2012.6400492", "10.1007/11564126-49.25", "10.2312/eurova.20171114", "10.1109/vast.2010.5652443", "10.1145/3134599", "10.2312/pe/eurovast/eurovast10/013-018.19", "10.1109/tvcg.2019.2903946", "10.1109/tvcg.2015.2467717", "10.1177/1473871612460526", "10.1016/j.cag.2018.09.018", "10.1109/tvcg.2016.2598838", "10.1145/3172944.3172964.14", "10.1109/vast.2009.5333428", "10.1109/vast.2014.7042480", "10.2312/pe/eurovast/eurovast10/013-018", "10.1177/0962280215588241", "10.1145/2993901.2993917", "10.1109/cvpr.2008:4587581", "10.1109/tvcg.2015.2467551", "10.1016/j.visinf.2018.09.001", "10.1126/science.290.5500.2319", "10.2312/eurova.20151107", "10.1109/visual.2019.8933695", "10.13140/2.1.2393.1847", "10.1197/jamia.m1929", "10.1109/cvpr.2008.4587581.25", "10.1145/1518701.1518895.16", "10.1109/vds.2017.8573444", "10.2312/trvis:20191185", "10.1145/3359786", "10.13140/2.1.1341.1520", "10.2312/pe/eurovast/eurova11/049-052.17", "10.1109/tvcg.2014.2346660", "10.1145/3185517", "10.1109/adprl.2011.5967372", "10.1109/tvcg.2015.2467591", "10.1111/j.1751-9004.2009.00232.x", "10.1136/qshc.2004.010033", "10.1109/vast.2012.6400493", "10.1109/tvcg.2019.2934266", "10.1145/2971763.2971775", "10.1111/cgf.13730", "10.1109/vast.2012.6400488", "10.1111/cgf.13210", "10.1109/tvcg.2019.2934631", "10.1145/3172944.3172965", "10.1057/ivs.2010.2", "10.1109/tvcg.2017.2745258", "10.1016/j.jbusres.2019.07.039", "10.1162/jmlr.2003.3.4-5.993", "10.1109/pacificvis.2019.00044", "10.2312/pe/eurovast/eurova12/037-041", "10.1109/tvcg.2019.2934629", "10.1177/0018720814547570", "10.1145/3292500.3330908", "10.1111/j.1467-8659.2009.01467.x", "10.2312/eurova.20151098", "10.1177/1473871617713337", "10.1109/lars:2009.5418323", "10.1109/vast.2011.6102437", "10.1111/cgf.12878", "10.1561/1500000001", "10.1145/3025171.3025222", "10.1007/s11704-016-6028-y", "10.1016/j.procs.2017.05.216", "10.1109/cvpr.2007.382974.25", "10.1080/10447318.2020.1741118", "10.1109/vast.2012.6400489", "10.1145/3025171.3025172", "10.1109/tvcg.2017.2744098", "10.1109/tvcg.2005.66", "10.1016/j.dss.2009.05.016", "10.1007/978-1-4612-4026-6", "10.2312/evs.20191168.16,20,28", "10.2312/pe/eurovast/eurova12/037-041.17", "10.1145/3290605.3300803", "10.1145/1015330.1015388", "10.1111/cgf.13197", "10.1016/b978-1-55860-377-6.50048-7", "10.1111/cgf.13681", "10.1109/tvcg.2017.2744378", "10.1109/tvcg.2017.2744358", "10.1109/vast.2008.4677352"], "wos": 1, "children": [{"doi": "10.1109/tvcg.2020.3030368", "title": "Implicit Multidimensional Projection of Local Subspaces", "year": "2020", "conferenceName": "InfoVis", "authors": "Rongzheng Bian;Yumeng Xue;Liang Zhou;Jian Zhang 0070;Baoquan Chen;Daniel Weiskopf;Yunhai Wang", "citationCount": "1", "affiliation": "Wang, YH (Corresponding Author), Shandong Univ, Qingdao, Peoples R China. Zhou, L (Corresponding Author), Univ Utah, Salt Lake City, UT 84112 USA. Bian, Rongzheng; Xue, Yumeng; Wang, Yunhai, Shandong Univ, Qingdao, Peoples R China. Chen, Baoquan, Peking Univ, Beijing, Peoples R China. Zhang, Jian, Chinese Acad Sci, CNIC, Beijing, Peoples R China. Zhou, Liang, Univ Utah, Salt Lake City, UT 84112 USA. Weiskopf, Daniel, Univ Stuttgart, Stuttgart, Germany.", "countries": "USA;Germany;China", "abstract": "We propose a visualization method to understand the effect of multidimensional projection on local subspaces, using implicit function differentiation. Here, we understand the local subspace as the multidimensional local neighborhood of data points. Existing methods focus on the projection of multidimensional data points, and the neighborhood information is ignored. Our method is able to analyze the shape and directional information of the local subspace to gain more insights into the global structure of the data through the perception of local structures. Local subspaces are fitted by multidimensional ellipses that are spanned by basis vectors. An accurate and efficient vector transformation method is proposed based on analytical differentiation of multidimensional projections formulated as implicit functions. The results are visualized as glyphs and analyzed using a full set of specifically-designed interactions supported in our efficient web-based visualization tool. The usefulness of our method is demonstrated using various multi- and high-dimensional benchmark datasets. Our implicit differentiation vector transformation is evaluated through numerical comparisons; the overall method is evaluated through exploration examples and use cases.", "keywords": "High-dimensional data visualization,dimensionality reduction,local linear subspaces,user interaction", "link": "http://dx.doi.org/10.1109/TVCG.2020.3030368", "refList": ["10.3844/jcssp.2018.613.622", "10.1016/j.aci.2018.08.003", "10.3390/info9030065", "10.1016/j.visinf.2018.09.003", "10.1371/journal.pone.0118432", "10.1016/s0893-6080(05)80023-1", "10.1109/tvcg.2020.2986996", "10.1109/icst.2012.56", "10.1007/s10844-013-0250-y", "10.1109/tbdata.2018", "10.1145/1125451.1125659", "10.1109/tvcg.2013.125", "10.1177/1473871611412817", "10.1145/3290605.3300911", "10.1111/cgf.14034", "10.1007/s13721-013-0034-x", "10.1016/j.procs.2017.05.216", "10.1016/j.ins.2009.08.025", "10.1109/tvcg.2013.124", "10.1109/tvcg.2018.2864499", "10.1109/tvcg.2018.2864475", "10.1080/10447318.2020.1741118", "10.1016/j.imu.2019.100203", "10.1109/tvcg.2018.2865240", "10.1186/s12864-019-6413-7", "10.1109/tvcg.2015.2467551", "10.1002/widm.1249", "10.1007/978-3-319-66429-3\\_29", "10.1109/tvcg.2014.2346481", "10.1109/tvcg.2018.2864825", "10.1177/1473871620904671", "10.1109/tvcg.2019.2934267", "10.1136/bmjopen-2016-012799", "10.1109/smartgridcomm.2017.8340682", "10.1007/s10664-015-9401-9", "10.1145/1143844.1143874", "10.1111/cgf.12389", "10.1109/tvcg.2018.2872577", "10.1007/978-981-13-5802-9\\_20", "10.1016/j.ipm.2009.03.002", "10.5220/0006431602160222", "10.1109/mcg.2015.50", "10.1109/tvcg.2014.2346574", "10.1007/bf02289565", "10.1109/tvcg.2017.2744378", "10.1016/j.patrec.2008.08.010", "10.1023/a:1010933404324", "10.9735/2229-3981"], "wos": 1, "children": [], "len": 1}, {"doi": "10.1109/tvcg.2020.3030465", "title": "Visual Causality Analysis of Event Sequence Data", "year": "2020", "conferenceName": "VAST", "authors": "Zhuochen Jin;Shunan Guo;Nan Chen;Daniel Weiskopf;David Gotz;Nan Cao", "citationCount": "0", "affiliation": "Cao, N (Corresponding Author), Tongji Univ, IDVx Lab, Shanghai, Peoples R China. Jin, Zhuochen; Guo, Shunan; Chen, Nan; Cao, Nan, Tongji Univ, IDVx Lab, Shanghai, Peoples R China. Weiskopf, Daniel, Univ Stuttgart, Stuttgart, Germany. Gotz, David, Univ N Carolina, Chapel Hill, NC 27515 USA.", "countries": "USA;Germany;China", "abstract": "Causality is crucial to understanding the mechanisms behind complex systems and making decisions that lead to intended outcomes. Event sequence data is widely collected from many real-world processes, such as electronic health records, web clickstreams, and financial transactions, which transmit a great deal of information reflecting the causal relations among event types. Unfortunately, recovering causalities from observational event sequences is challenging, as the heterogeneous and high-dimensional event variables are often connected to rather complex underlying event excitation mechanisms that are hard to infer from limited observations. Many existing automated causal analysis techniques suffer from poor explainability and fail to include an adequate amount of human knowledge. In this paper, we introduce a visual analytics method for recovering causalities in event sequence data. We extend the Granger causality analysis algorithm on Hawkes processes to incorporate user feedback into causal model refinement. The visualization system includes an interactive causal analysis framework that supports bottom-up causal exploration, iterative causal verification and refinement, and causal comparison through a set of novel visualizations and interactions. We report two forms of evaluation: a quantitative evaluation of the model improvements resulting from the user-feedback mechanism, and a qualitative evaluation through case studies in different application domains to demonstrate the usefulness of the system.", "keywords": "Event sequence data,causality analysis,visual analytics", "link": "http://dx.doi.org/10.1109/TVCG.2020.3030465", "refList": ["10.5555/1642718", "10.1109/tvcg.2018.2865022", "10.5555/2074094.2074151", "10.1109/tvcg.2016.2618797", "10.1073/pnas.1320645111", "10.1109/tvcg.2017.2744843", "10.1109/iv.2017.69", "10.1109/tvcg.2019.2934399", "10.1145/3172944.3173007", "10.5555/1795555", "10.1109/mcg.2005.102", "10.1145/381641.381653", "10.1162/153244301753344614", "10.1111/cgf.14034", "10.1111/cgf.13198", "10.1017/cbo9780511519857", "10.1007/s10462-016-9475-9", "10.1075/ssol.2.2.07bor", "10.1007/978-1-4614-3223-4\\_3", "10.1109/infvis.2003.1249025", "10.1007/978-94-007-6094-313", "10.1145/2858036.2858387", "10.1109/tvcg.2007.70528", "10.1109/tvcg.2017.2674958", "10.1147/sj.454.0801", "10.1109/tvcg.2013.119", "10.1145/3173574.3173711", "10.1016/j.erss.2017.06.034", "10.1109/visual.2019.8933695", "10.1007/s11665-016-2173-6", "10.1016/0377-0427(87)90125-7", "10.2307/3601125", "10.1016/b978-0-444-88738-2.50018-x", "10.1109/mcg.2006.70", "10.1109/tvcg.2018.2865145", "10.1017/s1351324997001502", "10.1109/tvcg.2010.179", "10.1214/aos/1176344552", "10.1109/mcg.2009.22", "10.1007/978-3-319-26633-6\\_13", "10.1080/10447318.2014.905422", "10.1016/j.visinf.2019.03.004", "10.1057/palgrave.ivs.9500074", "10.1007/978-1-4614-3223-4"], "wos": 1, "children": [], "len": 1}], "len": 5}, {"doi": "10.1111/cgf.13972", "year": "2020", "title": "Boxer: Interactive Comparison of Classifier Results", "conferenceName": "EuroVis", "authors": "Michael Gleicher;Aditya Barve;Xinyi Yu;Florian Heimerl", "citationCount": "0", "affiliation": "Gleicher, M (Corresponding Author), Univ Wisconsin, Madison, WI 53706 USA.\nGleicher, Michael; Barve, Aditya; Yu, Xinyi; Heimerl, Florian, Univ Wisconsin, Madison, WI 53706 USA.", "countries": "USA", "abstract": "Machine learning practitioners often compare the results of different classifiers to help select, diagnose and tune models. We present Boxer, a system to enable such comparison. Our system facilitates interactive exploration of the experimental results obtained by applying multiple classifiers to a common set of model inputs. The approach focuses on allowing the user to identify interesting subsets of training and testing instances and comparing performance of the classifiers on these subsets. The system couples standard visual designs with set algebra interactions and comparative elements. This allows the user to compose and coordinate views to specify subsets and assess classifier performance on them. The flexibility of these compositions allow the user to address a wide range of scenarios in developing and assessing classifiers. We demonstrate Boxer in use cases including model selection, tuning, fairness assessment, and data quality diagnosis.", "keywords": "", "link": "https://doi.org/10.1111/cgf.13972", "refList": ["10.1109/tvcg.2019.2934629", "10.1109/tvcg.2017.2744359", "10.1109/tvcg.2016.2598838", "10.1007/s10618-014-0368-8", "10.1109/tvcg.2017.2744938", "10.1109/tvcg.2019.2934262", "10.1145/3287560.3287589", "10.1109/vast.2017.8585721", "10.1109/tvcg.2016.2598828", "10.1109/tvcg.2009.128", "10.1109/tvcg.2017.2744018", "10.1080/00994480.2000.10748487", "10.5555/3305890.3306024", "10.1109/iccv.2015.329", "10.1109/tvcg.2013.125", "10.1089/big.2016.0007", "10.1109/memsys.2019.8870817", "10.1145/2939672.2939778", "10.1007/s11104-019-04156-0", "10.1371/journal.pone.0181142", "10.1145/3301275.3302324", "10.1109/tvcg.2017.2745158", "10.1109/tvcg.2018.2865044", "10.1023/a:1010933404324", "10.1145/2487575.2487579", "10.1109/tvcg.2013.157", "10.1145/2783258.2788613", "10.1109/tvcg.2017.2744199", "10.1109/tvcg.2019.2934631", "10.1016/s0304-3800(02)00064-9", "10.1007/s10115-013-0679-x", "10.1109/tvcg.2019.2934267", "10.1007/978-3-319-10590-1\\_53", "10.1109/vast.2017.8585720", "10.1016/0004-3702(80)90021-1", "10.1109/tvcg.2015.2467618", "10.1109/tvcg.2018.2864477", "10.1109/tvcg.2009.84", "10.1007/s11263-016-0911-8", "10.1111/cgf.12918", "10.1111/cgf.12373", "10.1109/tvcg.2017.2744878", "10.1109/tvcg.2018.2864812", "10.1109/mcg.2019.2919033", "10.1080/00207176808905715", "10.1002/er.3827", "10.1109/tvcg.2014.2346660", "10.1111/cgf.13417", "10.1109/tvcg.2019.2934659", "10.1109/tvcg.2017.2744158", "10.1016/b978-0-12-815849-4.00004-9", "10.1097/ede.0b013e3181c30fb2", "10.1111/cgf.13681", "10.1016/j.ejor.2006.04.051", "10.1109/tvcg.2019.2934619", "10.1109/tvcg.2016.2598468", "10.9735/2229-3981", "10.1109/tvcg.2016.2598831"], "wos": 1, "children": [], "len": 1}], "len": 11}, {"doi": "10.1109/tvcg.2019.2934659", "title": "Summit: Scaling Deep Learning Interpretability by Visualizing Activation and Attribution Summarizations", "year": "2019", "conferenceName": "VAST", "authors": "Fred Hohman;Haekyu Park;Caleb Robinson;Duen Horng Chau", "citationCount": "8", "affiliation": "Hohman, F (Corresponding Author), Georgia Tech, Atlanta, GA 30332 USA. Hohman, Fred; Park, Haekyu; Robinson, Caleb; Chau, Duen Horng (Polo), Georgia Tech, Atlanta, GA 30332 USA.", "countries": "USA", "abstract": "Deep learning is increasingly used in decision-making tasks. However, understanding how neural networks produce final predictions remains a fundamental challenge. Existing work on interpreting neural network predictions for images often focuses on explaining predictions for single images or neurons. As predictions are often computed from millions of weights that are optimized over millions of images, such explanations can easily miss a bigger picture. We present Summit, an interactive system that scalably and systematically summarizes and visualizes what features a deep learning model has learned and how those features interact to make predictions. Summit introduces two new scalable summarization techniques: (1) activation aggregation discovers important neurons, and (2) neuron-influence aggregation identifies relationships among such neurons. Summit combines these techniques to create the novel attribution graph that reveals and summarizes crucial neuron associations and substructures that contribute to a model's outcomes. Summit scales to large data, such as the ImageNet dataset with 1.2M images, and leverages neural network feature visualization and dataset examples to help users distill large, complex neural network models into compact, interactive visualizations. We present neural network exploration scenarios where Summit helps us discover multiple surprising insights into a prevalent, large-scale image classifier's learned representations and informs future neural network architecture design. The Summit visualization runs in modern web browsers and is open-sourced.", "keywords": "Deep learning interpretability,visual analytics,scalable summarization,attribution graph", "link": "http://dx.doi.org/10.1109/TVCG.2019.2934659", "refList": ["10.1097/pas.0000000000001151", "10.1109/tvcg.2017.2744683", "10.1109/tvcg.2009.108", "10.1109/cvpr.2016.265", "10.23915/distill.00015", "10.1126/science.aaf7894", "10.1145/2702123.2702509", "10.1109/tvcg.2018.2843369", "10.1109/tvcg.2016.2598828", "10.1111/j.1467-8659.2011.01957.x", "10.1109/iccv.2017.371", "10.5555/3305890.3306024", "10.1109/cvpr.2015.7298594", "10.1145/3219819.3219910", "10.1371/journal.pone.0130140", "10.1109/cvpr.2018.00391", "10.1145/2939672.2939778", "10.1007/s11263-015-0816-y", "10.1007/978-3-319-27857-5\\_77", "10.1137/s0036144503424786", "10.1111/cgf.13210", "10.23915/distill.00010", "10.23915/distill.00007", "10.1007/978-3-319-10590-1\\_53", "10.1007/978-3-030-01261-8\\_32", "10.1109/tvcg.2017.2744878", "10.1109/tvcg.2017.2744718", "10.23915/distill.00005", "10.1109/tkde.2009.191", "10.1109/cvpr.2018.00910", "10.5858/arpa.2018-0147-oa", "10.1109/tvcg.2018.2864500", "10.1109/iccv.2017.74", "10.1109/cvpr.2016.90", "10.1109/ijcnn.2017.7966422", "10.1111/cgf.12642", "10.1109/tvcg.2016.2598831"], "wos": 1, "children": [{"doi": "10.1109/tvcg.2020.3028957", "title": "A Visual Analytics Approach for Exploratory Causal Analysis: Exploration, Validation, and Applications", "year": "2020", "conferenceName": "VAST", "authors": "Xiao Xie;Fan Du;Yingcai Wu", "citationCount": "0", "affiliation": "Wu, YC (Corresponding Author), Zhejiang Univ, State Key Lab CAD\\&CG, Hangzhou, Zhejiang, Peoples R China. Du, F (Corresponding Author), Adobe Res, San Jose, CA 95110 USA. Xie, Xiao; Wu, Yingcai, Zhejiang Univ, State Key Lab CAD\\&CG, Hangzhou, Zhejiang, Peoples R China. Du, Fan, Adobe Res, San Jose, CA 95110 USA.", "countries": "USA;China", "abstract": "Using causal relations to guide decision making has become an essential analytical task across various domains, from marketing and medicine to education and social science. While powerful statistical models have been developed for inferring causal relations from data, domain practitioners still lack effective visual interface for interpreting the causal relations and applying them in their decision-making process. Through interview studies with domain experts, we characterize their current decision-making workflows, challenges, and needs. Through an iterative design process, we developed a visualization tool that allows analysts to explore, validate, and apply causal relations in real-world decision-making scenarios. The tool provides an uncertainty-aware causal graph visualization for presenting a large set of causal relations inferred from high-dimensional data. On top of the causal graph, it supports a set of intuitive user controls for performing what-if analyses and making action plans. We report on two case studies in marketing and student advising to demonstrate that users can effectively explore causal relations and design action plans for reaching their goals.", "keywords": "Exploratory causal analysis,correlation and causation,causal graph", "link": "http://dx.doi.org/10.1109/TVCG.2020.3028957", "refList": ["10.1109/tvcg.2019.2934629", "10.1109/tvcg.2017.2744683", "10.1109/tvcg.2017.2744938", "10.1109/tvcg.2019.2934262", "10.1109/vast.2017.8585721", "10.1109/tvcg.2018.2843369", "10.1145/3336191.3371824", "10.1016/j.visinf.2017.01.006", "10.1145/2858036.2858529", "10.1145/2939672.2939778", "10.1613/jair.346", "10.1038/s42256-019-0048-x", "10.1109/tvcg.2018.2865044", "10.1145/3287560.3287566", "10.1109/tvcg.2018.2816223", "10.1145/3287560.3287569", "10.1109/tvcg.2018.2864504", "10.1109/vast.2017.8585720", "10.1016/j.artint.2018.07.007", "10.1109/tvcg.2018.2864812", "10.1109/tvcg.2017.2744718", "10.1145/3359786", "10.1109/tvcg.2019.2934659", "10.1109/ic-cids.2019.8862140", "10.1109/tvcg.2017.2744158", "10.1038/ng.142", "10.1145/3351095.3372850", "10.1109/tvcg.2019.2934619", "10.1109/tvcg.2016.2598831"], "wos": 1, "children": [], "len": 1}, {"doi": "10.1109/tvcg.2020.3028888", "title": "A Visual Analytics Framework for Explaining and Diagnosing Transfer Learning Processes", "year": "2020", "conferenceName": "VAST", "authors": "Yuxin Ma;Arlen Fan;Jingrui He;Arun Reddy Nelakurthi;Ross Maciejewski", "citationCount": "0", "affiliation": "Ma, YX (Corresponding Author), Arizona State Univ, Tempe, AZ 85287 USA. Ma, Yuxin; Fan, Arlen; Maciejewski, Ross, Arizona State Univ, Tempe, AZ 85287 USA. He, Jingrui, Univ Illinois, Champaign, IL USA. Nelakurthi, Arun Reddy, Samsung Res Amer, Mountain View, CA USA.", "countries": "USA", "abstract": "Many statistical learning models hold an assumption that the training data and the future unlabeled data are drawn from the same distribution. However, this assumption is difficult to fulfill in real-world scenarios and creates barriers in reusing existing labels from similar application domains. Transfer Learning is intended to relax this assumption by modeling relationships between domains, and is often applied in deep learning applications to reduce the demand for labeled data and training time. Despite recent advances in exploring deep learning models with visual analytics tools, little work has explored the issue of explaining and diagnosing the knowledge transfer process between deep learning models. In this paper, we present a visual analytics framework for the multi-level exploration of the transfer learning processes when training deep neural networks. Our framework establishes a multi-aspect design to explain how the learned knowledge from the existing model is transferred into the new learning task when training deep neural networks. Based on a comprehensive requirement and task analysis, we employ descriptive visualization with performance measures and detailed inspections of model behaviors from the statistical, instance, feature, and model structure levels. We demonstrate our framework through two case studies on image classification by fine-tuning AlexNets to illustrate how analysts can utilize our framework.", "keywords": "Transfer learning,deep learning,visual analytics", "link": "http://dx.doi.org/10.1109/TVCG.2020.3028888", "refList": ["10.1109/tvcg.2014.2346578", "10.1109/tvcg.2019.2934629", "10.1109/tvcg.2017.2744683", "10.1109/tvcg.2016.2598838", "10.1109/tvcg.2017.2744938", "10.1109/tvcg.2019.2934262", "10.1109/tpami.2018.2868685", "10.1145/2702123.2702509", "10.1109/vast.2017.8585721", "10.1109/tvcg.2018.2843369", "10.1109/tvcg.2016.2598828", "10.1111/j.1467-8659.2011.01898.x", "10.1109/tvcg.2013.65", "10.1145/2976749.2978318", "10.1007/978-3-030-01424-7\\_27", "10.1109/tvcg.2019.2934261", "10.1007/s11704-016-6028-y", "10.1016/j.visinf.2017.01.006", "10.1145/2858036.2858529", "10.1109/iccv.2015.279", "10.1109/mci.2018.2840738", "10.1109/tvcg.2019.2892483", "10.1109/vast.2018.8802509", "10.1109/tvcg.2013.124", "10.1186/s40537-016-0043-6", "10.1109/tvcg.2018.2864475", "10.1145/3200489", "10.1109/tvcg.2018.2865044", "10.1111/cgf.13210", "10.1109/tvcg.2018.2816223", "10.23915/distill.00007", "10.1109/tvcg.2017.2744199", "10.1109/tkde.2018.2876857", "10.1109/tvcg.2019.2934631", "10.1109/tvcg.2018.2864504", "10.1109/tvcg.2014.2346482", "10.1109/tvcg.2015.2467618", "10.1109/tvcg.2014.2346594", "10.1109/tvcg.2011.188", "10.1007/978-3-642-15561-1\\_16", "10.1109/tvcg.2018.2864812", "10.1109/mcg.2019.2919033", "10.1109/tvcg.2017.2744718", "10.1109/tvcg.2017.2744878", "10.1109/tvcg.2016.2598541", "10.1109/tkde.2009.191", "10.1145/3065386", "10.1016/j.ins.2016.03.021", "10.1109/tvcg.2019.2903943", "10.1007/s10994-009-5152-4", "10.1109/tvcg.2019.2934659", "10.1109/tvcg.2018.2864500", "10.1109/iccv.2017.74", "10.1109/tvcg.2017.2744158", "10.1109/tvcg.2012.207", "10.1111/cgf.13092", "10.1109/tvcg.2018.2865027", "10.1109/tvcg.2017.2744378", "10.1109/tvcg.2017.2744358", "10.1109/tvcg.2019.2934619", "10.1109/tvcg.2018.2864499", "10.1109/tvcg.2017.2754480", "10.1109/tvcg.2016.2598831"], "wos": 1, "children": [], "len": 1}, {"doi": "10.1109/tvcg.2020.3030418", "title": "CNN Explainer: Learning Convolutional Neural Networks with Interactive Visualization", "year": "2020", "conferenceName": "VAST", "authors": "Zijie J. Wang;Robert Turko;Omar Shaikh;Haekyu Park;Nilaksh Das;Fred Hohman;Minsuk Kahng;Duen Horng Chau", "citationCount": "0", "affiliation": "Wang, ZJ (Corresponding Author), Georgia Tech, Atlanta, GA 30332 USA. Wang, Zijie J.; Turko, Robert; Shaikh, Omar; Park, Haekyu; Das, Nilaksh; Hohman, Fred; Chau, Duen Horng (Polo), Georgia Tech, Atlanta, GA 30332 USA. Kahng, Minsuk, Oregon State Univ, Corvallis, OR 97331 USA.", "countries": "USA", "abstract": "Deep learning's great success motivates many practitioners and students to learn about this exciting technology. However, it is often challenging for beginners to take their first step due to the complexity of understanding and applying deep learning. We present CNN Explainer, an interactive visualization tool designed for non-experts to learn and examine convolutional neural networks (CNNs), a foundational deep learning model architecture. Our tool addresses key challenges that novices face while learning about CNNs, which we identify from interviews with instructors and a survey with past students. CNN Explainer tightly integrates a model overview that summarizes a CNN's structure, and on-demand, dynamic visual explanation views that help users understand the underlying components of CNNs. Through smooth transitions across levels of abstraction, our tool enables users to inspect the interplay between low-level mathematical operations and high-level model structures. A qualitative user study shows that CNN Explainer helps users more easily understand the inner workings of CNNs, and is engaging and enjoyable to use. We also derive design lessons from our study. Developed using modern web technologies, CNN Explainer runs locally in users' web browsers without the need for installation or specialized hardware, broadening the public's education access to modern deep learning techniques.", "keywords": "Deep learning,machine learning,convolutional neural networks,visual analytics", "link": "http://dx.doi.org/10.1109/TVCG.2020.3030418", "refList": ["10.1016/j.cag.2018.09.018", "10.1109/tvcg.2017.2744683", "10.1109/tvcg.2017.2744938", "10.1037/0022-0663.83.4.484", "10.1016/j.patcog.2017.10.013", "10.1109/tvcg.2018.2843369", "10.1109/tvcg.2011.185", "10.1016/s0360-1315(99)00023-8", "10.1080/07380569.2012.651422", "10.1006/s1045-926x(02)00027-7", "10.1145/1821996.1821997", "10.1109/vast.2018.8802509", "10.1109/vl.2000.874346", "10.1007/978-3-319-27857-5\\_77", "10.1145/1227504.1227384", "10.1038/nature14539", "10.1109/tvcg.2018.2816223", "10.23915/distill.00016", "10.1162/neco.1997.9.8.1735", "10.1109/tvcg.2016.2640960", "10.1006/ijhc.2000.0409", "10.1109/tvcg.2017.2744718", "10.1006/s1045-926x(02)00028-9", "10.1111/cgf.13720", "10.1109/tvcg.2019.2934659", "10.1109/tvcg.2018.2864500", "10.1109/tvcg.2017.2744158", "10.1145/782941.782998", "10.1109/tvcg.2017.2744358", "10.1109/tvcg.2016.2598831"], "wos": 1, "children": [], "len": 1}, {"doi": "10.1109/tvcg.2020.3030342", "title": "DECE: Decision Explorer with Counterfactual Explanations for Machine Learning Models", "year": "2020", "conferenceName": "VAST", "authors": "Furui Cheng;Yao Ming;Huamin Qu", "citationCount": "0", "affiliation": "Cheng, FR (Corresponding Author), Hong Kong Univ Sci \\& Technol, Hong Kong, Peoples R China. Cheng, Furui; Ming, Yao; Qu, Huamin, Hong Kong Univ Sci \\& Technol, Hong Kong, Peoples R China. Ming, Yao, Bloomberg LP, New York, NY USA.", "countries": "USA;China", "abstract": "With machine learning models being increasingly applied to various decision-making scenarios, people have spent growing efforts to make machine learning models more transparent and explainable. Among various explanation techniques, counterfactual explanations have the advantages of being human-friendly and actionable-a counterfactual explanation tells the user how to gain the desired prediction with minimal changes to the input. Besides, counterfactual explanations can also serve as efficient probes to the models' decisions. In this work, we exploit the potential of counterfactual explanations to understand and explore the behavior of machine learning models. We design DECE, an interactive visualization system that helps understand and explore a model's decisions on individual instances and data subsets, supporting users ranging from decision-subjects to model developers. DECE supports exploratory analysis of model decisions by combining the strengths of counterfactual explanations at instance- and subgroup-levels. We also introduce a set of interactions that enable users to customize the generation of counterfactual explanations to find more actionable ones that can suit their needs. Through three use cases and an expert interview, we demonstrate the effectiveness of DECE in supporting decision exploration tasks and instance explanations.", "keywords": "Tabular Data,Explainable Machine Learning,Counterfactual Explanation,Decision Making", "link": "http://dx.doi.org/10.1109/TVCG.2020.3030342", "refList": ["10.1109/tvcg.2019.2934629", "10.1109/tvcg.2017.2744683", "10.1145/3173574.3173951", "10.1109/tvcg.2017.2744938", "10.1109/tvcg.2019.2934262", "10.1145/3336191.3371824", "10.1016/j.visinf.2017.01.006", "10.1145/2858036.2858529", "10.1145/2939672.2939778", "10.1613/jair.346", "10.1038/s42256-019-0048-x", "10.1109/tvcg.2018.2865044", "10.1145/3287560.3287566", "10.1109/tvcg.2018.2816223", "10.1145/3287560.3287569", "10.1109/tvcg.2018.2864504", "10.1016/j.artint.2018.07.007", "10.1109/tvcg.2018.2864812", "10.1109/tvcg.2017.2744718", "10.1145/3359786", "10.1109/tvcg.2019.2934659", "10.1109/ic-cids.2019.8862140", "10.1109/tvcg.2017.2744158", "10.1038/ng.142", "10.2139/ssrn.3063289", "10.1145/3351095.3372850", "10.1109/tvcg.2019.2934619", "10.1109/tvcg.2016.2598831"], "wos": 1, "children": [], "len": 1}, {"doi": "10.1111/cgf.14034", "year": "2020", "title": "The State of the Art in Enhancing Trust in Machine Learning Models with the Use of Visualizations", "conferenceName": "EuroVis", "authors": "Angelos Chatzimparmpas;Rafael Messias Martins;Ilir Jusufi;Kostiantyn Kucher;Fabrice Rossi;Andreas Kerren", "citationCount": "2", "affiliation": "Chatzimparmpas, A (Corresponding Author), Linnaeus Univ, Dept Comp Sci \\& Media Technol, Vaxjo, Sweden.\nChatzimparmpas, A.; Martins, R. M.; Jusufi, I.; Kucher, K.; Kerren, A., Linnaeus Univ, Dept Comp Sci \\& Media Technol, Vaxjo, Sweden.\nRossi, F., PSL Univ, Univ Paris Dauphine, Ceremade, Paris, France.", "countries": "Sweden;France", "abstract": "Machine learning (ML) models are nowadays used in complex applications in various domains, such as medicine, bioinformatics, and other sciences. Due to their black box nature, however, it may sometimes be hard to understand and trust the results they provide. This has increased the demand for reliable visualization tools related to enhancing trust in ML models, which has become a prominent topic of research in the visualization community over the past decades. To provide an overview and present the frontiers of current research on the topic, we present a State-of-the-Art Report (STAR) on enhancing trust in ML models with the use of interactive visualization. We define and describe the background of the topic, introduce a categorization for visualization techniques that aim to accomplish this goal, and discuss insights and opportunities for future research directions. Among our contributions is a categorization of trust against different facets of interactive ML, expanded and improved from previous research. Our results are investigated from different analytical perspectives: (a) providing a statistical overview, (b) summarizing key findings, (c) performing topic analyses, and (d) exploring the data sets used in the individual papers, all with the support of an interactive web-based survey browser. We intend this survey to be beneficial for visualization researchers whose interests involve making ML models more trustworthy, as well as researchers and practitioners from other disciplines in their search for effective visualization techniques suitable for solving their tasks with confidence and conveying meaning to their data.", "keywords": "trustworthy machine learning; visualization; interpretable machine learning; explainable machine learning", "link": "https://doi.org/10.1111/cgf.14034", "refList": ["10.1109/mcg.2018.2878902", "10.1109/tvcg.2008.153", "10.2312/mlvis.20181130", "10.1109/tvcg.2016.2598828", "10.1145/3290605.3300911", "10.1145/2993901.2993909", "10.2312/mlvis.20191158", "10.1109/tvcg.2016.2598446", "10.1111/j.1467-8659.2009.01475.x", "10.1145/3290605.3300809", "10.1109/pacificvis.2018.00031", "10.1055/s-0029-1216348", "10.1007/978-3-319-90403-0\\_13", "10.1109/tvcg.2017.2745085", "10.1111/j.1467-8659.2011.01938.x", "10.1007/978-3-319-54024-5\\_6", "10.1016/s0167-9473(01)00065-2", "10.1111/cgf.12895", "10.2312/eurovisshort.20141152.17", "10.2312/eurova.20151098.22", "10.1111/cgf.13667", "10.3115/1072228.1072378", "10.1109/tbdata.2018.2877350.16", "10.1109/lars.2009.5418323.25", "10.1109/tvcg.2017.2744878", "10.1016/j.combustflame.2005.09.018", "10.1016/j.cag.2014.01.006", "10.1109/tvcg.2016.2570755", "10.2312/mlvis.20191158.1,19", "10.1518/hfes.46.1.50.30392", "10.1145/3301275.3302280", "10.1145/3351095.3372834.1", "10.1016/s0377-2217(01)00264-8", "10.1111/cgf.13424", "10.1007/978-3-319-23485-4\\_53", "10.1007/978-94-007-0753-5\\_3623", "10.1109/tvcg.2013.101", "10.1111/cgf.12884", "10.1111/j.1467-8659.2010.01835.x", "10.1021/ci9901338", "10.4230/lipics.itcs:2017", "10.1109/mis.2013.24", "10.1109/tvcg.2014.2346482", "10.1109/tvcg.2018.2865230", "10.1073/pnas.1807180116", "10.1109/dsaa.2018.00018", "10.1109/tvcg.2009.153", "10.3115/1219840.1219855", "10.1109/tvcg.2018.2864812", "10.1109/tvcg.2018.2872577", "10.2312/trvis.20191183", "10.1109/cvpr:2004.383", "10.1109/vast.2008.4677350", "10.1145/302979.303001", "10.1109/tvcg.2018.2864499", "10.1111/cgf.13672", "10.1109/tvcg.2014.2346626", "10.23915/distill.00010.18", "10.1109/tvcg.2017.2744805", "10.2312/mlvis:20191160.18", "10.23915/distill:00016", "10.1109/pacificvis.2016.7465260", "10.1111/cgf.13683", "10.23915/distill.00016.19", "10.1145/32906053.300803.22", "10.1109/tvcg.2014.2346574", "10.1177/1473871615600010", "10.1109/tvcg.2016.2598831", "10.1145/3230623", "10.1109/visual.2019.8933744", "10.1145/2993901.2993915", "10.1016/j.visinf.2017.01.006", "10.1145/2993901.2993914", "10.1109/tvcg.2014.2346984", "10.1109/5.726791", "10.23915/distill.00010", "10.1109/tvcg.2018.2864825", "10.2307/2394164", "10.1109/tvcg.2017.2744458", "10.1145/2993901.2993917.28", "10.1111/cgf.13711", "10.1109/tvcg.2016.2598664", "10.2307/2530428", "10.1109/icdar.1997.620583", "10.1109/tvcg.2017.2744718", "10.1111/cgf.13425", "10.1109/tvcg.2019.2903943", "10.1145/1518701.1518895", "10.1109/tvcg.2018.2864838", "10.1145/62038.62043", "10.1111/j.1467-8659.2011.01920.x", "10.1145/3025171.3025208", "10.1145/355112.355124", "10.1109/vast.2010.5652398", "10.1109/tvcg.2014.2346578", "10.1145/3173574.3174209", "10.4178/epih/e2014008", "10.1109/beliv.2018.8634201.25,28", "10.1016/j.eswa.2007.12.020", "10.1111/cgf:13406", "10.1109/mcg.2011.103", "10.1631/fitee.1700808", "10.1109/tvcg.2017.2745158", "10.1073/pnas.0307752101", "10.1109/tvcg.2018.2816223", "10.1109/tvcg.2017.2745141", "10.1145/32232.32234", "10.1109/tvcg.2019.2934267", "10.1109/tvcg.2018.2864477", "10.1145/3132169", "10.2312/eurova.20151100.19", "10.1145/3172944.3172964", "10.1145/2601248.2601268", "10.1109/isai-nlp.2018.8693002.1", "10.1111/cgf.13404", "10.1007/s100320200071", "10.2312/trvis.20191183.16", "10.1111/cgf.12755", "10.1145/2702123.2702509", "10.1145/1401890.1402008.25", "10.1109/tvcg.2012.65", "10.1177/1473871617733996", "10.2312/trvis.20191187.7", "10.21236/ada273556", "10.1109/vast.2010.5652450", "10.1111/j.1467-8659.2011.01940.x", "10.1177/875647939000600106", "10.1109/tvcg.2017.2711030", "10.1016/j.immuni.2016.04.014", "10.1109/tvcg.2019.2934209", "10.1016/0095-0696(78)90006-2", "10.1016/j.jclinepi.2015.04.014", "10.1016/j.ress.2013.02.013", "10.1111/cgf.12640", "10.1145/1015330.1015388.25", "10.1111/j.1467-8659.2009.01468.x", "10.1145/1541880.1541882", "10.1109/vast.2011.6102453", "10.1016/s0008-8846(98)00165-3", "10.2312/trvis.20191186.7", "10.1007/s13748-013-0040-3", "10.1109/tvcg.2015.2467757", "10.1109/tbdata.2018.2877350", "10.1109/vast.2017.8585613", "10.1080/10556789208805504", "10.1109/vast.2012.6400484", "10.1145/3025171.3025181", "10.1007/978-3-319-90403-0\\_12", "10.1109/mcg.2019.2922592", "10.1021/ci000392t", "10.1109/vast.2007.4389000", "10.1111/cgf.13406.16", "10.1111/cgf.13684", "10.2312/eurovisshort.20161166.17", "10.2312/evs:20191168", "10.1145/3041021.3055135", "10.1145/3301275.3302265", "10.1613/jair.4135", "10.1109/tvcg.2018.2864500", "10.1109/tvcg.2017.2744158", "10.1109/ssci.2015.33", "10.1111/cgf.13453", "10.2312/pe/eurovast/eurova11/049-052", "10.1145/3025171.3025181.13", "10.1145/371920.372094", "10.1109/tvcg.2017.2744938", "10.1111/j.1467-8659.2012.03108.x", "10.1109/tvcg.2019.2934251", "10.1145/3290605.3300809.18", "10.1109/ldav.2016.7874305", "10.1109/vast.2016.7883514", "10.1109/iccv.2015.425", "10.1145/3301275.3302324", "10.1109/tnnls.2013.2292894", "10.1109/tvcg.2018.2865044", "10.1109/tvcg.2013.157", "10.1371/journal.pcbi.0020161", "10.1186/s12916-019-1426-2", "10.1109/10.867928", "10.1111/cgf.13217", "10.1109/mcg.2019.2919033", "10.1145/2993901.2993910", "10.1109/tvcg.2017.2744738", "10.2307/258792", "10.1111/cgf.12655", "10.1016/j.dss.2014.03.001", "10.1109/tvcg.2019.2904069", "10.1111/cgf.13205", "10.1002/mds.22340", "10.1109/tvcg.2019.2934595", "10.1287/inte.2018.0957", "10.1109/cvpr.2007.382974", "10.1109/tvcg.2012.280", "10.1145/2678025.2701399.13", "10.2312/mlvis.20181130.13", "10.2312/eurova.20181106.16", "10.1109/tvcg.2018.2864475", "10.2312/mlvis.20191160.18,22", "10.1007/978-1-4612-4026-6.25", "10.1109/cvpr.2006.42", "10.1145/3172944.3172950", "10.1109/cvpr.2004.383.25", "10.1109/tvcg.2019.2934812", "10.1609/aimag.v35i4.2513", "10.2312/trvis.20191185.7", "10.1111/j.1467-8659.2009.01684.x", "10.1371/journal.pone.0129126", "10.1111/cgf.13092", "10.1162/coli\\_a\\_00237", "10.1109/tvcg.2017.2744818", "10.1109/vast.2011.6102448", "10.1109/tvcg.2009.111", "10.1109/tvcg.2019.2934619", "10.1016/s0377-2217(01)00264-8.25", "10.1111/cgf.12639", "10.1109/access.2019.2919343", "10.1186/s12874-019-0681-4", "10.1109/pacificvis.2015.7156366", "10.1109/pacificvis.2018.00029", "10.1109/tvcg.2019.2934261", "10.1080/13506280444000102.http://www.uvt.nl/ticc", "10.1109/vast.2018.8802509", "10.1111/cgf.13212", "10.1145/3200489", "10.1111/cgf.13176", "10.1177/1473871620904671", "10.1007/978-3-319-10590-1\\_53", "10.1111/j.1467-8659.2012.03126.x", "10.1111/cgf.13172", "10.1145/3025171.3025208.6,21", "10.1111/cgf.12366", "10.1109/tvcg.2019.2934659", "10.1109/cvprw.2009.5206848", "10.1016/j.media.2014.11.010", "10.1109/tvcg.2017.2744683", "10.1109/tvcg.2019.2934262", "10.1016/j.neucom.2006.11.018", "10.1177/1473871615571951", "10.1371/journal.pcbi.0020161.25", "10.1177/1473871611415994", "10.2312/trvis20191187", "10.2312/eurova", "10.1145/2858036.2858529", "10.1145/2207676.2207738", "10.1007/s11042-009-0417-2", "10.1145/3301275.3302317", "10.1038/s41746-019-0148-3", "10.1145/3351095.3372834", "10.1080/10691898.2011.11889627", "10.1109/tvcg.2018.2864504", "10.1109/vast.2017.8585720", "10.1109/mcg.2018.053491732", "10.1007/s10994-010-5207-6", "10.1109/tvcg.2019.2934433", "10.1016/j.cag.2017.05.005", "10.1109/tvcg.2012.279", "10.1145/3231622.3231641.19,20", "10.1145/1562849.1562851", "10.1007/11564126\\_", "10.1109/tvcg.2018.2846735", "10.3115/1225403.1225421", "10.1109/vast.2012.6400486", "10.2312/eurova.20191116.22", "10.1109/tvcg.2007.70443", "10.1080/027868291009242", "10.2312/eurova.20151100", "10.1145/2939502.2939503.19", "10.1016/j.cag.2014.02.004", "10.1145/2939672.2939778", "10.1109/vast.2010.5652484", "10.1111/cgf.12641", "10.1145/3301275.3302289", "10.1109/visual.2019.8933619", "10.1109/tvcg.2017.2672987", "10.1109/vast.2016.7883517.20", "10.1109/igarss.2017.8127684", "10.1016/j.jcae.2010.04.002", "10.1109/vast.2010.5652885", "10.1016/j.visinf.2019.03.002", "10.1007/s00371-018-1500-3", "10.1109/mcg.2018.042731661", "10.1109/34.598228", "10.1109/tvcg.2018.2865027", "10.1016/j.neucom.2017.01.105", "10.1111/cgf.12389", "10.1109/tvcg.2019.2934591", "10.1109/vast.2010.5652392.16", "10.1111/cgf.13416", "10.1080/02701367.1992.10608764", "10.1109/vast.2017.8585721", "10.1109/tvcg.2018.2843369", "10.1109/sbes.2010.27", "10.1109/vast.2015.7347637", "10.1145/1401890.1402008", "10.1016/j.bpj.2010.04.064", "10.1109/tvcg.2013.125", "10.1109/isai-nlp.2018.8693002", "10.1371/journal.pone.0160127", "10.1145/2856767.2856779", "10.1145/2678025.2701399", "10.1109/vast.2011.6102451", "10.1109/mcg.2010.18", "10.1021/ci4000213", "10.1109/vast.2012.6400492", "10.1007/11564126-49.25", "10.2312/eurova.20171114", "10.1109/vast.2010.5652443", "10.1145/3134599", "10.2312/pe/eurovast/eurovast10/013-018.19", "10.1109/tvcg.2019.2903946", "10.1109/tvcg.2015.2467717", "10.1177/1473871612460526", "10.1016/j.cag.2018.09.018", "10.1109/tvcg.2016.2598838", "10.1145/3172944.3172964.14", "10.1109/vast.2009.5333428", "10.1109/vast.2014.7042480", "10.2312/pe/eurovast/eurovast10/013-018", "10.1177/0962280215588241", "10.1145/2993901.2993917", "10.1109/cvpr.2008:4587581", "10.1109/tvcg.2015.2467551", "10.1016/j.visinf.2018.09.001", "10.1126/science.290.5500.2319", "10.2312/eurova.20151107", "10.1109/visual.2019.8933695", "10.13140/2.1.2393.1847", "10.1197/jamia.m1929", "10.1109/cvpr.2008.4587581.25", "10.1145/1518701.1518895.16", "10.1109/vds.2017.8573444", "10.2312/trvis:20191185", "10.1145/3359786", "10.13140/2.1.1341.1520", "10.2312/pe/eurovast/eurova11/049-052.17", "10.1109/tvcg.2014.2346660", "10.1145/3185517", "10.1109/adprl.2011.5967372", "10.1109/tvcg.2015.2467591", "10.1111/j.1751-9004.2009.00232.x", "10.1136/qshc.2004.010033", "10.1109/vast.2012.6400493", "10.1109/tvcg.2019.2934266", "10.1145/2971763.2971775", "10.1111/cgf.13730", "10.1109/vast.2012.6400488", "10.1111/cgf.13210", "10.1109/tvcg.2019.2934631", "10.1145/3172944.3172965", "10.1057/ivs.2010.2", "10.1109/tvcg.2017.2745258", "10.1016/j.jbusres.2019.07.039", "10.1162/jmlr.2003.3.4-5.993", "10.1109/pacificvis.2019.00044", "10.2312/pe/eurovast/eurova12/037-041", "10.1109/tvcg.2019.2934629", "10.1177/0018720814547570", "10.1145/3292500.3330908", "10.1111/j.1467-8659.2009.01467.x", "10.2312/eurova.20151098", "10.1177/1473871617713337", "10.1109/lars:2009.5418323", "10.1109/vast.2011.6102437", "10.1111/cgf.12878", "10.1561/1500000001", "10.1145/3025171.3025222", "10.1007/s11704-016-6028-y", "10.1016/j.procs.2017.05.216", "10.1109/cvpr.2007.382974.25", "10.1080/10447318.2020.1741118", "10.1109/vast.2012.6400489", "10.1145/3025171.3025172", "10.1109/tvcg.2017.2744098", "10.1109/tvcg.2005.66", "10.1016/j.dss.2009.05.016", "10.1007/978-1-4612-4026-6", "10.2312/evs.20191168.16,20,28", "10.2312/pe/eurovast/eurova12/037-041.17", "10.1145/3290605.3300803", "10.1145/1015330.1015388", "10.1111/cgf.13197", "10.1016/b978-1-55860-377-6.50048-7", "10.1111/cgf.13681", "10.1109/tvcg.2017.2744378", "10.1109/tvcg.2017.2744358", "10.1109/vast.2008.4677352"], "wos": 1, "children": [{"doi": "10.1109/tvcg.2020.3030368", "title": "Implicit Multidimensional Projection of Local Subspaces", "year": "2020", "conferenceName": "InfoVis", "authors": "Rongzheng Bian;Yumeng Xue;Liang Zhou;Jian Zhang 0070;Baoquan Chen;Daniel Weiskopf;Yunhai Wang", "citationCount": "1", "affiliation": "Wang, YH (Corresponding Author), Shandong Univ, Qingdao, Peoples R China. Zhou, L (Corresponding Author), Univ Utah, Salt Lake City, UT 84112 USA. Bian, Rongzheng; Xue, Yumeng; Wang, Yunhai, Shandong Univ, Qingdao, Peoples R China. Chen, Baoquan, Peking Univ, Beijing, Peoples R China. Zhang, Jian, Chinese Acad Sci, CNIC, Beijing, Peoples R China. Zhou, Liang, Univ Utah, Salt Lake City, UT 84112 USA. Weiskopf, Daniel, Univ Stuttgart, Stuttgart, Germany.", "countries": "USA;Germany;China", "abstract": "We propose a visualization method to understand the effect of multidimensional projection on local subspaces, using implicit function differentiation. Here, we understand the local subspace as the multidimensional local neighborhood of data points. Existing methods focus on the projection of multidimensional data points, and the neighborhood information is ignored. Our method is able to analyze the shape and directional information of the local subspace to gain more insights into the global structure of the data through the perception of local structures. Local subspaces are fitted by multidimensional ellipses that are spanned by basis vectors. An accurate and efficient vector transformation method is proposed based on analytical differentiation of multidimensional projections formulated as implicit functions. The results are visualized as glyphs and analyzed using a full set of specifically-designed interactions supported in our efficient web-based visualization tool. The usefulness of our method is demonstrated using various multi- and high-dimensional benchmark datasets. Our implicit differentiation vector transformation is evaluated through numerical comparisons; the overall method is evaluated through exploration examples and use cases.", "keywords": "High-dimensional data visualization,dimensionality reduction,local linear subspaces,user interaction", "link": "http://dx.doi.org/10.1109/TVCG.2020.3030368", "refList": ["10.3844/jcssp.2018.613.622", "10.1016/j.aci.2018.08.003", "10.3390/info9030065", "10.1016/j.visinf.2018.09.003", "10.1371/journal.pone.0118432", "10.1016/s0893-6080(05)80023-1", "10.1109/tvcg.2020.2986996", "10.1109/icst.2012.56", "10.1007/s10844-013-0250-y", "10.1109/tbdata.2018", "10.1145/1125451.1125659", "10.1109/tvcg.2013.125", "10.1177/1473871611412817", "10.1145/3290605.3300911", "10.1111/cgf.14034", "10.1007/s13721-013-0034-x", "10.1016/j.procs.2017.05.216", "10.1016/j.ins.2009.08.025", "10.1109/tvcg.2013.124", "10.1109/tvcg.2018.2864499", "10.1109/tvcg.2018.2864475", "10.1080/10447318.2020.1741118", "10.1016/j.imu.2019.100203", "10.1109/tvcg.2018.2865240", "10.1186/s12864-019-6413-7", "10.1109/tvcg.2015.2467551", "10.1002/widm.1249", "10.1007/978-3-319-66429-3\\_29", "10.1109/tvcg.2014.2346481", "10.1109/tvcg.2018.2864825", "10.1177/1473871620904671", "10.1109/tvcg.2019.2934267", "10.1136/bmjopen-2016-012799", "10.1109/smartgridcomm.2017.8340682", "10.1007/s10664-015-9401-9", "10.1145/1143844.1143874", "10.1111/cgf.12389", "10.1109/tvcg.2018.2872577", "10.1007/978-981-13-5802-9\\_20", "10.1016/j.ipm.2009.03.002", "10.5220/0006431602160222", "10.1109/mcg.2015.50", "10.1109/tvcg.2014.2346574", "10.1007/bf02289565", "10.1109/tvcg.2017.2744378", "10.1016/j.patrec.2008.08.010", "10.1023/a:1010933404324", "10.9735/2229-3981"], "wos": 1, "children": [], "len": 1}, {"doi": "10.1109/tvcg.2020.3030465", "title": "Visual Causality Analysis of Event Sequence Data", "year": "2020", "conferenceName": "VAST", "authors": "Zhuochen Jin;Shunan Guo;Nan Chen;Daniel Weiskopf;David Gotz;Nan Cao", "citationCount": "0", "affiliation": "Cao, N (Corresponding Author), Tongji Univ, IDVx Lab, Shanghai, Peoples R China. Jin, Zhuochen; Guo, Shunan; Chen, Nan; Cao, Nan, Tongji Univ, IDVx Lab, Shanghai, Peoples R China. Weiskopf, Daniel, Univ Stuttgart, Stuttgart, Germany. Gotz, David, Univ N Carolina, Chapel Hill, NC 27515 USA.", "countries": "USA;Germany;China", "abstract": "Causality is crucial to understanding the mechanisms behind complex systems and making decisions that lead to intended outcomes. Event sequence data is widely collected from many real-world processes, such as electronic health records, web clickstreams, and financial transactions, which transmit a great deal of information reflecting the causal relations among event types. Unfortunately, recovering causalities from observational event sequences is challenging, as the heterogeneous and high-dimensional event variables are often connected to rather complex underlying event excitation mechanisms that are hard to infer from limited observations. Many existing automated causal analysis techniques suffer from poor explainability and fail to include an adequate amount of human knowledge. In this paper, we introduce a visual analytics method for recovering causalities in event sequence data. We extend the Granger causality analysis algorithm on Hawkes processes to incorporate user feedback into causal model refinement. The visualization system includes an interactive causal analysis framework that supports bottom-up causal exploration, iterative causal verification and refinement, and causal comparison through a set of novel visualizations and interactions. We report two forms of evaluation: a quantitative evaluation of the model improvements resulting from the user-feedback mechanism, and a qualitative evaluation through case studies in different application domains to demonstrate the usefulness of the system.", "keywords": "Event sequence data,causality analysis,visual analytics", "link": "http://dx.doi.org/10.1109/TVCG.2020.3030465", "refList": ["10.5555/1642718", "10.1109/tvcg.2018.2865022", "10.5555/2074094.2074151", "10.1109/tvcg.2016.2618797", "10.1073/pnas.1320645111", "10.1109/tvcg.2017.2744843", "10.1109/iv.2017.69", "10.1109/tvcg.2019.2934399", "10.1145/3172944.3173007", "10.5555/1795555", "10.1109/mcg.2005.102", "10.1145/381641.381653", "10.1162/153244301753344614", "10.1111/cgf.14034", "10.1111/cgf.13198", "10.1017/cbo9780511519857", "10.1007/s10462-016-9475-9", "10.1075/ssol.2.2.07bor", "10.1007/978-1-4614-3223-4\\_3", "10.1109/infvis.2003.1249025", "10.1007/978-94-007-6094-313", "10.1145/2858036.2858387", "10.1109/tvcg.2007.70528", "10.1109/tvcg.2017.2674958", "10.1147/sj.454.0801", "10.1109/tvcg.2013.119", "10.1145/3173574.3173711", "10.1016/j.erss.2017.06.034", "10.1109/visual.2019.8933695", "10.1007/s11665-016-2173-6", "10.1016/0377-0427(87)90125-7", "10.2307/3601125", "10.1016/b978-0-444-88738-2.50018-x", "10.1109/mcg.2006.70", "10.1109/tvcg.2018.2865145", "10.1017/s1351324997001502", "10.1109/tvcg.2010.179", "10.1214/aos/1176344552", "10.1109/mcg.2009.22", "10.1007/978-3-319-26633-6\\_13", "10.1080/10447318.2014.905422", "10.1016/j.visinf.2019.03.004", "10.1057/palgrave.ivs.9500074", "10.1007/978-1-4614-3223-4"], "wos": 1, "children": [], "len": 1}], "len": 5}, {"doi": "10.1111/cgf.13972", "year": "2020", "title": "Boxer: Interactive Comparison of Classifier Results", "conferenceName": "EuroVis", "authors": "Michael Gleicher;Aditya Barve;Xinyi Yu;Florian Heimerl", "citationCount": "0", "affiliation": "Gleicher, M (Corresponding Author), Univ Wisconsin, Madison, WI 53706 USA.\nGleicher, Michael; Barve, Aditya; Yu, Xinyi; Heimerl, Florian, Univ Wisconsin, Madison, WI 53706 USA.", "countries": "USA", "abstract": "Machine learning practitioners often compare the results of different classifiers to help select, diagnose and tune models. We present Boxer, a system to enable such comparison. Our system facilitates interactive exploration of the experimental results obtained by applying multiple classifiers to a common set of model inputs. The approach focuses on allowing the user to identify interesting subsets of training and testing instances and comparing performance of the classifiers on these subsets. The system couples standard visual designs with set algebra interactions and comparative elements. This allows the user to compose and coordinate views to specify subsets and assess classifier performance on them. The flexibility of these compositions allow the user to address a wide range of scenarios in developing and assessing classifiers. We demonstrate Boxer in use cases including model selection, tuning, fairness assessment, and data quality diagnosis.", "keywords": "", "link": "https://doi.org/10.1111/cgf.13972", "refList": ["10.1109/tvcg.2019.2934629", "10.1109/tvcg.2017.2744359", "10.1109/tvcg.2016.2598838", "10.1007/s10618-014-0368-8", "10.1109/tvcg.2017.2744938", "10.1109/tvcg.2019.2934262", "10.1145/3287560.3287589", "10.1109/vast.2017.8585721", "10.1109/tvcg.2016.2598828", "10.1109/tvcg.2009.128", "10.1109/tvcg.2017.2744018", "10.1080/00994480.2000.10748487", "10.5555/3305890.3306024", "10.1109/iccv.2015.329", "10.1109/tvcg.2013.125", "10.1089/big.2016.0007", "10.1109/memsys.2019.8870817", "10.1145/2939672.2939778", "10.1007/s11104-019-04156-0", "10.1371/journal.pone.0181142", "10.1145/3301275.3302324", "10.1109/tvcg.2017.2745158", "10.1109/tvcg.2018.2865044", "10.1023/a:1010933404324", "10.1145/2487575.2487579", "10.1109/tvcg.2013.157", "10.1145/2783258.2788613", "10.1109/tvcg.2017.2744199", "10.1109/tvcg.2019.2934631", "10.1016/s0304-3800(02)00064-9", "10.1007/s10115-013-0679-x", "10.1109/tvcg.2019.2934267", "10.1007/978-3-319-10590-1\\_53", "10.1109/vast.2017.8585720", "10.1016/0004-3702(80)90021-1", "10.1109/tvcg.2015.2467618", "10.1109/tvcg.2018.2864477", "10.1109/tvcg.2009.84", "10.1007/s11263-016-0911-8", "10.1111/cgf.12918", "10.1111/cgf.12373", "10.1109/tvcg.2017.2744878", "10.1109/tvcg.2018.2864812", "10.1109/mcg.2019.2919033", "10.1080/00207176808905715", "10.1002/er.3827", "10.1109/tvcg.2014.2346660", "10.1111/cgf.13417", "10.1109/tvcg.2019.2934659", "10.1109/tvcg.2017.2744158", "10.1016/b978-0-12-815849-4.00004-9", "10.1097/ede.0b013e3181c30fb2", "10.1111/cgf.13681", "10.1016/j.ejor.2006.04.051", "10.1109/tvcg.2019.2934619", "10.1109/tvcg.2016.2598468", "10.9735/2229-3981", "10.1109/tvcg.2016.2598831"], "wos": 1, "children": [], "len": 1}], "len": 17}, {"doi": "10.1109/tvcg.2019.2934630", "title": "Tac-Simur: Tactic-based Simulative Visual Analytics of Table Tennis", "year": "2019", "conferenceName": "VAST", "authors": "Jiachen Wang;Kejian Zhao;Dazhen Deng;Anqi Cao;Xiao Xie;Zheng Zhou;Hui Zhang;Yingcai Wu", "citationCount": "3", "affiliation": "Wang, JC (Corresponding Author), Zhejiang Univ, State Key Lab CAD\\&CG, Hangzhou, Zhejiang, Peoples R China. Wang, Jiachen; Zhao, Kejian; Deng, Dazhen; Cao, Anqi; Xie, Xiao; Wu, Yingcai, Zhejiang Univ, State Key Lab CAD\\&CG, Hangzhou, Zhejiang, Peoples R China. Zhou, Zheng; Zhang, Hui, Zhejiang Univ, Dept Sport Sci, Hangzhou, Zhejiang, Peoples R China.", "countries": "China", "abstract": "Simulative analysis in competitive sports can provide prospective insights, which can help improve the performance of players in future matches. However, adequately simulating the complex competition process and effectively explaining the simulation result to domain experts are typically challenging. This work presents a design study to address these challenges in table tennis. We propose a well-established hybrid second-order Markov chain model to characterize and simulate the competition process in table tennis. Compared with existing methods, our approach is the first to support the effective simulation of tactics, which represent high-level competition strategies in table tennis. Furthermore, we introduce a visual analytics system called Tac-Simur based on the proposed model for simulative visual analytics. Tac-Simur enables users to easily navigate different players and their tactics based on their respective performance in matches to identify the player and the tactics of interest for further analysis. Then, users can utilize the system to interactively explore diverse simulation tasks and visually explain the simulation results. The effectiveness and usefulness of this work are demonstrated by two case studies, in which domain experts utilize Tac-Simur to find interesting and valuable insights. The domain experts also provide positive feedback on the usability of Tac-Simur. Our work can be extended to other similar sports such as tennis and badminton.", "keywords": "Simulative Visual Analytics,Table Tennis,Design Study", "link": "http://dx.doi.org/10.1109/TVCG.2019.2934630", "refList": ["10.1140/epjds29", "10.1002/nav.20017", "10.1016/j.eswa.2015.09.004", "10.1145/3200491", "10.1111/j.1467-8659.2012.03118.x", "10.1145/2939672.2939764", "10.1109/tvcg.2013.192", "10.1109/tvcg.2017.2744218", "10.1515/ijcss-2016-0002", "10.1109/icdm.2015.26", "10.1145/2362383.2362387", "10.1007/s12650-018-0521-3", "10.1109/mcg.2016.124", "10.1109/tmm.2016.2614221", "10.1007/s12650-015-0337-3", "10.1080/02640414.2013.805885", "10.1109/mcg.2016.101", "10.1111/cgf.13210", "10.16829/j.slxb.201702001", "10.1155/2013/409539", "10.1080/02640414.2013.792948", "10.1109/tvcg.2012.263", "10.1109/tvcg.2018.2865041", "10.1109/vast.2014.7042478", "10.1515/hukin-2017-0002", "10.1145/2783258.2788598", "10.2312/eurovisshort.20151137", "10.1111/cgf.13447", "10.1145/3097983.3098045", "10.1111/j.2517-6161.1985.tb01383.x", "10.1109/mmul.2012.54", "10.1515/1559-0410.1416", "10.1111/cgf.13436", "10.1260/1747-9541.5.2.205", "10.1080/02640414.2018.1450073", "10.1109/tvcg.2014.2346445", "10.1109/tvcg.2016.2598432"], "wos": 1, "children": [{"doi": "10.1109/tvcg.2020.3028958", "title": "Auditing the Sensitivity of Graph-based Ranking with Visual Analytics", "year": "2020", "conferenceName": "VAST", "authors": "Tiankai Xie;Yuxin Ma;Hanghang Tong;My T. Thai;Ross Maciejewski", "citationCount": "0", "affiliation": "Xie, TK (Corresponding Author), Arizona State Univ, Tempe, AZ 85287 USA. Xie, Tiankai; Ma, Yuxin; Maciejewski, Ross, Arizona State Univ, Tempe, AZ 85287 USA. Tong, Hanghang, Univ Illinois, Urbana, IL USA. Thai, My T., Univ Florida, Gainesville, FL 32611 USA.", "countries": "USA", "abstract": "Graph mining plays a pivotal role across a number of disciplines, and a variety of algorithms have been developed to answer who/what type questions. For example, what items shall we recommend to a given user on an e-commerce platform? The answers to such questions are typically returned in the form of a ranked list, and graph-based ranking methods are widely used in industrial information retrieval settings. However, these ranking algorithms have a variety of sensitivities, and even small changes in rank can lead to vast reductions in product sales and page hits. As such, there is a need for tools and methods that can help model developers and analysts explore the sensitivities of graph ranking algorithms with respect to perturbations within the graph structure. In this paper, we present a visual analytics framework for explaining and exploring the sensitivity of any graph-based ranking algorithm by performing perturbation-based what-if analysis. We demonstrate our framework through three case studies inspecting the sensitivity of two classic graph-based ranking algorithms (PageRank and HITS) as applied to rankings in political news media and social networks.", "keywords": "Graph-based ranking,sensitivity analysis,visual analytics", "link": "http://dx.doi.org/10.1109/TVCG.2020.3028958", "refList": ["10.1109/wsc.2017.8247800", "10.1023/a:1022649401552", "10.1515/1559-0410.11416", "10.1109/tvcg.2016.2598919", "10.1177/1473871611416549", "10.1109/tvcg.2019.2934630", "10.1140/epjds29", "10.1109/tvcg.2019.2934670", "10.1016/j.eswa.2015.09.004", "10.1145/2702123.2702509", "10.1016/j.visinf.2018.12.001", "10.2307/3002000", "10.1109/tvcg.2019.2934399", "10.1007/s41060-016-0032-z", "10.1111/cgf.13198", "10.14778/2350229.2350254", "10.1145/2939672.2939764", "10.1016/j.visinf.2017.01.006", "10.1145/2858036.2858529", "10.1109/vast.2017.8585647", "10.1007/bf01187020", "10.1109/icdm.2015.26", "10.1145/2362383.2362387", "10.1177/0049124104268644", "10.1109/vast.2011.6102442", "10.1109/infvis.2003.1249025", "10.1109/tvcg.2018.2864475", "10.1109/tvcg.2007.70528", "10.1109/tvcg.2015.2467691", "10.1111/cgf.13210", "10.1214/aos/1176344136", "10.1109/tvcg.2015.2424872", "10.1016/j.visinf.2018.09.001", "10.1177/089443939100900106", "10.1109/tvcg.2015.2467931", "10.1162/neco.1997.9.8.1735", "10.1007/s11162-011-9241-4", "10.1111/cgf.13680", "10.1145/3065386", "10.1109/tvcg.2018.2864889", "10.1177/003804070808100402", "10.1109/icdm.2010.62", "10.1038/s41598-020-59669-x", "10.1162/153244303321897717", "10.1109/tvcg.2019.2934619", "10.1007/bf00356088", "10.1109/tvcg.2016.2598432", "10.1109/tvcg.2016.2598831"], "wos": 1, "children": [], "len": 1}, {"doi": "10.1109/tvcg.2020.3030358", "title": "Once Upon A Time In Visualization: Understanding the Use of Textual Narratives for Causality", "year": "2020", "conferenceName": "VAST", "authors": "Arjun Choudhry;Mandar Sharma;Pramod Chundury;Thomas Kapler;Derek W. S. Gray;Naren Ramakrishnan;Niklas Elmqvist", "citationCount": "0", "affiliation": "Choudhry, A (Corresponding Author), Virginia Tech, Arlington, VA 24061 USA. Choudhry, Arjun; Sharma, Mandar; Ramakrishnan, Naren, Virginia Tech, Arlington, VA 24061 USA. Chundury, Pramod; Elmqvist, Niklas, Univ Maryland, College Pk, MD 20742 USA. Kapler, Thomas; Gray, Derek W. S., Uncharted Software, Toronto, ON, Canada.", "countries": "Canada;USA", "abstract": "Causality visualization can help people understand temporal chains of events, such as messages sent in a distributed system, cause and effect in a historical conflict, or the interplay between political actors over time. However, as the scale and complexity of these event sequences grows, even these visualizations can become overwhelming to use. In this paper, we propose the use of textual narratives as a data-driven storytelling method to augment causality visualization. We first propose a design space for how textual narratives can be used to describe causal data. We then present results from a crowdsourced user study where participants were asked to recover causality information from two causality visualizations-causal graphs and Hasse diagrams-with and without an associated textual narrative. Finally, we describe Causeworks, a causality visualization system for understanding how specific interventions influence a causal model. The system incorporates an automatic textual narrative mechanism based on our design space. We validate Causeworks through interviews with experts who used the system for understanding complex events.", "keywords": "Causality visualization,natural language generation,data-driven storytelling,temporal data,quantitative studies", "link": "http://dx.doi.org/10.1109/TVCG.2020.3030358", "refList": ["10.1371/journal.pone.0171156", "10.1007/s11424-013-2290-3", "10.1109/tvcg.2019.2934630", "10.1515/hukin-2015-0013", "10.1109/tvcg.2017.2745181", "10.1111/j.1467-8659.2012.03118.x", "10.1007/s10618-017-0513-2", "10.1371/journal.pone.0029638", "10.1016/j.visinf.2019.10.002", "10.1109/tvcg.2013.192", "10.1109/tvcg.2017.2744218", "10.1590/s1980-65742014000300004", "10.1186/1471-2105-16-s13-s8", "10.1109/mcg.2016.124", "10.1109/tmm.2016.2614221", "10.1145/3219819.3219832", "10.1007/s11424-013-2291-2", "10.1198/016214506000000302", "10.1109/tvcg.2019.2934243", "10.1109/iv.2011.57", "10.1111/cgf.13189", "10.1109/tvcg.2018.2865041", "10.1109/vast.2014.7042477", "10.1177/1473871613511959", "10.1109/iv.2010.39", "10.3390/ijgi4042159", "10.1111/cgf.13436", "10.1016/j.visinf.2017.01.005", "10.1109/tvcg.2014.2346445"], "wos": 1, "children": [], "len": 1}, {"doi": "10.1111/cgf.13965", "year": "2020", "title": "Bombalytics: Visualization of Competition and Collaboration Strategies of Players in a Bomb Laying Game", "conferenceName": "EuroVis", "authors": "Shivam Agarwal;G{\\\"{u}}nter Wallner;Fabian Beck", "citationCount": "0", "affiliation": "Agarwal, S (Corresponding Author), Univ Duisburg Essen, Duisburg, Germany.\nAgarwal, Shivam; Beck, Fabian, Univ Duisburg Essen, Duisburg, Germany.\nWallner, Gunter, Eindhoven Univ Technol, Eindhoven, Netherlands.\nWallner, Gunter, Univ Appl Arts Vienna, Vienna, Austria.", "countries": "Germany;Austria;Netherlands", "abstract": "Competition and collaboration form complex interaction patterns between the agents and objects involved. Only by understanding these interaction patterns, we can reveal the strategies the participating parties applied. In this paper, we study such competition and collaboration behavior for a computer game. Serving as a testbed for artificial intelligence, the multiplayer bomb laying game Pommerman provides a rich source of advanced behavior of computer agents. We propose a visualization approach that shows an overview of multiple games, with a detailed timeline-based visualization for exploring the specifics of each game. Since an analyst can only fully understand the data when considering the direct and indirect interactions between agents, we suggest various visual encodings of these interactions. Based on feedback from expert users and an application example, we demonstrate that the approach helps identify central competition strategies and provides insights on collaboration.", "keywords": "", "link": "https://doi.org/10.1111/cgf.13965", "refList": ["10.1145/1822348.1822349", "10.1016/j.cag.2013.11.010", "10.1145/2793107.2793112", "10.1109/tvcg.2019.2934630", "10.1145/3343055.3360747", "10.1016/j.intcom.2010.04.004", "10.1109/cig.2019.8848091", "10.1007/s11554-013-0347-0", "10.1007/s12650-019-00566-5", "10.1109/bigdata.2018.8622571", "10.1007/978-3-319-63519-4", "10.1109/tciaig.2014.2365470", "10.1016/j.entcom.2013.02.002", "10.1609/aimag.v34i3.2492", "10.1145/3311350.3357716", "10.1109/tvcg.2018.2864885", "10.1177/1473871617718377", "10.1109/tvcg.2018.2864504", "10.1111/cgf.12919", "10.1109/tvcg.2019.2934243", "10.1109/tvcg.2018.2859969", "10.1145/3235765.3235812", "10.1109/tvcg.2017.2745320", "10.1109/tvcg.2016.2598415", "10.1109/tciaig.2012.2188528", "10.1109/iscas.2019.8702471", "10.2307/350902", "10.1109/mc.2018.2890217", "10.1145/3027063.3053146", "10.1111/cgf.13436", "10.1145/3130859.3131439", "10.1016/j.compedu.2011.11.015"], "wos": 1, "children": [], "len": 1}], "len": 7}, {"doi": "10.1109/tvcg.2019.2934595", "title": "Visual Interaction with Deep Learning Models through Collaborative Semantic Inference", "year": "2019", "conferenceName": "VAST", "authors": "Sebastian Gehrmann;Hendrik Strobelt;Robert Kr\u00fcger;Hanspeter Pfister;Alexander M. Rush", "citationCount": "3", "affiliation": "Gehrmann, S (Corresponding Author), Harvard NLP Grp, Cambridge, MA 02138 USA. Gehrmann, Sebastian; Rush, Alexander M., Harvard NLP Grp, Cambridge, MA 02138 USA. Strobelt, Hendrik, IBM Res Cambridge, Cambridge, MA USA. Kruger, Robert, MIT IBM Watson AI Lab, Cambridge, MA USA. Pfister, Hanspeter, Harvard Visual Comp Grp, Cambridge, MA USA.", "countries": "USA", "abstract": "Automation of tasks can have critical consequences when humans lose agency over decision processes. Deep learning models are particularly susceptible since current black-box approaches lack explainable reasoning. We argue that both the visual interface and model structure of deep learning systems need to take into account interaction design. We propose a framework of collaborative semantic inference (CSI) for the co-design of interactions and models to enable visual collaboration between humans and algorithms. The approach exposes the intermediate reasoning process of models which allows semantic interactions with the visual metaphors of a problem, which means that a user can both understand and control parts of the model reasoning process. We demonstrate the feasibility of CSI with a co-designed case study of a document summarization system.", "keywords": "Human-Computer Collaboration,Deep Learning,Neural Networks,Interaction Design,Human-Centered Design", "link": "http://dx.doi.org/10.1109/TVCG.2019.2934595", "refList": ["10.1109/vast.2017.8585721", "10.1109/tvcg.2012.195", "10.1613/jair.295", "10.1162/tacl\\textbackslash{}a\\textbackslash{}00254", "10.1007/978-3-540-70956-5", "10.1145/2678025.2701399", "10.1016/j.visinf.2017.01.006", "10.1145/2858036.2858529", "10.5555/645526.657137", "10.1146/annurev.neur0.26.041002.131047.issn", "10.1145/2207676.2207741", "10.1145/2939672.2939778", "10.1109/vlhcc.2010.15", "10.3115/v1/d14-1130", "10.18653/v1/p17-1099", "10.1109/tvcg.2018.2865044", "10.18653/v1/p17-1080", "10.1111/cgf.13210", "10.1162/tacl\\_a\\_00254", "10.1109/tvcg.2018.2816223", "10.1109/72.279181", "10.1145/2783258.2788613", "10.2112/si85-057.1", "10.1145/1866029.1866078", "10.1007/978-3-319-10590-1\\_53", "10.1109/tvcg.2018.2865230", "10.1007/s12650-018-0531-1", "10.1145/2365952.2365964", "10.1017/s026988890200019x", "10.1109/iccv.2015.337", "10.1109/tvcg.2017.2744878", "10.1145/3027063.3053103", "10.1109/tvcg.2017.2744718", "10.1145/302979.303030", "10.1109/cvpr.2018.00917", "10.1007/s40708-016-0042-6", "10.1073/pnas.1807184115", "10.1609/aimag.v35i4.2513", "10.1016/j.ijhcs.2009.03.004", "10.1109/tvcg.2017.2744158", "10.1109/tvcg.2018.2864838", "10.1111/cgf.13092", "10.1109/tvcg.2018.2865027", "10.1109/tvcg.2014.2346574", "10.1109/tvcg.2017.2744358", "10.1109/tvcg.2018.2864499", "10.1016/s0167-739x(97)00022-8", "10.1093/bi0inf0rmatics/bth267"], "wos": 1, "children": [{"doi": "10.1111/cgf.14034", "year": "2020", "title": "The State of the Art in Enhancing Trust in Machine Learning Models with the Use of Visualizations", "conferenceName": "EuroVis", "authors": "Angelos Chatzimparmpas;Rafael Messias Martins;Ilir Jusufi;Kostiantyn Kucher;Fabrice Rossi;Andreas Kerren", "citationCount": "2", "affiliation": "Chatzimparmpas, A (Corresponding Author), Linnaeus Univ, Dept Comp Sci \\& Media Technol, Vaxjo, Sweden.\nChatzimparmpas, A.; Martins, R. M.; Jusufi, I.; Kucher, K.; Kerren, A., Linnaeus Univ, Dept Comp Sci \\& Media Technol, Vaxjo, Sweden.\nRossi, F., PSL Univ, Univ Paris Dauphine, Ceremade, Paris, France.", "countries": "Sweden;France", "abstract": "Machine learning (ML) models are nowadays used in complex applications in various domains, such as medicine, bioinformatics, and other sciences. Due to their black box nature, however, it may sometimes be hard to understand and trust the results they provide. This has increased the demand for reliable visualization tools related to enhancing trust in ML models, which has become a prominent topic of research in the visualization community over the past decades. To provide an overview and present the frontiers of current research on the topic, we present a State-of-the-Art Report (STAR) on enhancing trust in ML models with the use of interactive visualization. We define and describe the background of the topic, introduce a categorization for visualization techniques that aim to accomplish this goal, and discuss insights and opportunities for future research directions. Among our contributions is a categorization of trust against different facets of interactive ML, expanded and improved from previous research. Our results are investigated from different analytical perspectives: (a) providing a statistical overview, (b) summarizing key findings, (c) performing topic analyses, and (d) exploring the data sets used in the individual papers, all with the support of an interactive web-based survey browser. We intend this survey to be beneficial for visualization researchers whose interests involve making ML models more trustworthy, as well as researchers and practitioners from other disciplines in their search for effective visualization techniques suitable for solving their tasks with confidence and conveying meaning to their data.", "keywords": "trustworthy machine learning; visualization; interpretable machine learning; explainable machine learning", "link": "https://doi.org/10.1111/cgf.14034", "refList": ["10.1109/mcg.2018.2878902", "10.1109/tvcg.2008.153", "10.2312/mlvis.20181130", "10.1109/tvcg.2016.2598828", "10.1145/3290605.3300911", "10.1145/2993901.2993909", "10.2312/mlvis.20191158", "10.1109/tvcg.2016.2598446", "10.1111/j.1467-8659.2009.01475.x", "10.1145/3290605.3300809", "10.1109/pacificvis.2018.00031", "10.1055/s-0029-1216348", "10.1007/978-3-319-90403-0\\_13", "10.1109/tvcg.2017.2745085", "10.1111/j.1467-8659.2011.01938.x", "10.1007/978-3-319-54024-5\\_6", "10.1016/s0167-9473(01)00065-2", "10.1111/cgf.12895", "10.2312/eurovisshort.20141152.17", "10.2312/eurova.20151098.22", "10.1111/cgf.13667", "10.3115/1072228.1072378", "10.1109/tbdata.2018.2877350.16", "10.1109/lars.2009.5418323.25", "10.1109/tvcg.2017.2744878", "10.1016/j.combustflame.2005.09.018", "10.1016/j.cag.2014.01.006", "10.1109/tvcg.2016.2570755", "10.2312/mlvis.20191158.1,19", "10.1518/hfes.46.1.50.30392", "10.1145/3301275.3302280", "10.1145/3351095.3372834.1", "10.1016/s0377-2217(01)00264-8", "10.1111/cgf.13424", "10.1007/978-3-319-23485-4\\_53", "10.1007/978-94-007-0753-5\\_3623", "10.1109/tvcg.2013.101", "10.1111/cgf.12884", "10.1111/j.1467-8659.2010.01835.x", "10.1021/ci9901338", "10.4230/lipics.itcs:2017", "10.1109/mis.2013.24", "10.1109/tvcg.2014.2346482", "10.1109/tvcg.2018.2865230", "10.1073/pnas.1807180116", "10.1109/dsaa.2018.00018", "10.1109/tvcg.2009.153", "10.3115/1219840.1219855", "10.1109/tvcg.2018.2864812", "10.1109/tvcg.2018.2872577", "10.2312/trvis.20191183", "10.1109/cvpr:2004.383", "10.1109/vast.2008.4677350", "10.1145/302979.303001", "10.1109/tvcg.2018.2864499", "10.1111/cgf.13672", "10.1109/tvcg.2014.2346626", "10.23915/distill.00010.18", "10.1109/tvcg.2017.2744805", "10.2312/mlvis:20191160.18", "10.23915/distill:00016", "10.1109/pacificvis.2016.7465260", "10.1111/cgf.13683", "10.23915/distill.00016.19", "10.1145/32906053.300803.22", "10.1109/tvcg.2014.2346574", "10.1177/1473871615600010", "10.1109/tvcg.2016.2598831", "10.1145/3230623", "10.1109/visual.2019.8933744", "10.1145/2993901.2993915", "10.1016/j.visinf.2017.01.006", "10.1145/2993901.2993914", "10.1109/tvcg.2014.2346984", "10.1109/5.726791", "10.23915/distill.00010", "10.1109/tvcg.2018.2864825", "10.2307/2394164", "10.1109/tvcg.2017.2744458", "10.1145/2993901.2993917.28", "10.1111/cgf.13711", "10.1109/tvcg.2016.2598664", "10.2307/2530428", "10.1109/icdar.1997.620583", "10.1109/tvcg.2017.2744718", "10.1111/cgf.13425", "10.1109/tvcg.2019.2903943", "10.1145/1518701.1518895", "10.1109/tvcg.2018.2864838", "10.1145/62038.62043", "10.1111/j.1467-8659.2011.01920.x", "10.1145/3025171.3025208", "10.1145/355112.355124", "10.1109/vast.2010.5652398", "10.1109/tvcg.2014.2346578", "10.1145/3173574.3174209", "10.4178/epih/e2014008", "10.1109/beliv.2018.8634201.25,28", "10.1016/j.eswa.2007.12.020", "10.1111/cgf:13406", "10.1109/mcg.2011.103", "10.1631/fitee.1700808", "10.1109/tvcg.2017.2745158", "10.1073/pnas.0307752101", "10.1109/tvcg.2018.2816223", "10.1109/tvcg.2017.2745141", "10.1145/32232.32234", "10.1109/tvcg.2019.2934267", "10.1109/tvcg.2018.2864477", "10.1145/3132169", "10.2312/eurova.20151100.19", "10.1145/3172944.3172964", "10.1145/2601248.2601268", "10.1109/isai-nlp.2018.8693002.1", "10.1111/cgf.13404", "10.1007/s100320200071", "10.2312/trvis.20191183.16", "10.1111/cgf.12755", "10.1145/2702123.2702509", "10.1145/1401890.1402008.25", "10.1109/tvcg.2012.65", "10.1177/1473871617733996", "10.2312/trvis.20191187.7", "10.21236/ada273556", "10.1109/vast.2010.5652450", "10.1111/j.1467-8659.2011.01940.x", "10.1177/875647939000600106", "10.1109/tvcg.2017.2711030", "10.1016/j.immuni.2016.04.014", "10.1109/tvcg.2019.2934209", "10.1016/0095-0696(78)90006-2", "10.1016/j.jclinepi.2015.04.014", "10.1016/j.ress.2013.02.013", "10.1111/cgf.12640", "10.1145/1015330.1015388.25", "10.1111/j.1467-8659.2009.01468.x", "10.1145/1541880.1541882", "10.1109/vast.2011.6102453", "10.1016/s0008-8846(98)00165-3", "10.2312/trvis.20191186.7", "10.1007/s13748-013-0040-3", "10.1109/tvcg.2015.2467757", "10.1109/tbdata.2018.2877350", "10.1109/vast.2017.8585613", "10.1080/10556789208805504", "10.1109/vast.2012.6400484", "10.1145/3025171.3025181", "10.1007/978-3-319-90403-0\\_12", "10.1109/mcg.2019.2922592", "10.1021/ci000392t", "10.1109/vast.2007.4389000", "10.1111/cgf.13406.16", "10.1111/cgf.13684", "10.2312/eurovisshort.20161166.17", "10.2312/evs:20191168", "10.1145/3041021.3055135", "10.1145/3301275.3302265", "10.1613/jair.4135", "10.1109/tvcg.2018.2864500", "10.1109/tvcg.2017.2744158", "10.1109/ssci.2015.33", "10.1111/cgf.13453", "10.2312/pe/eurovast/eurova11/049-052", "10.1145/3025171.3025181.13", "10.1145/371920.372094", "10.1109/tvcg.2017.2744938", "10.1111/j.1467-8659.2012.03108.x", "10.1109/tvcg.2019.2934251", "10.1145/3290605.3300809.18", "10.1109/ldav.2016.7874305", "10.1109/vast.2016.7883514", "10.1109/iccv.2015.425", "10.1145/3301275.3302324", "10.1109/tnnls.2013.2292894", "10.1109/tvcg.2018.2865044", "10.1109/tvcg.2013.157", "10.1371/journal.pcbi.0020161", "10.1186/s12916-019-1426-2", "10.1109/10.867928", "10.1111/cgf.13217", "10.1109/mcg.2019.2919033", "10.1145/2993901.2993910", "10.1109/tvcg.2017.2744738", "10.2307/258792", "10.1111/cgf.12655", "10.1016/j.dss.2014.03.001", "10.1109/tvcg.2019.2904069", "10.1111/cgf.13205", "10.1002/mds.22340", "10.1109/tvcg.2019.2934595", "10.1287/inte.2018.0957", "10.1109/cvpr.2007.382974", "10.1109/tvcg.2012.280", "10.1145/2678025.2701399.13", "10.2312/mlvis.20181130.13", "10.2312/eurova.20181106.16", "10.1109/tvcg.2018.2864475", "10.2312/mlvis.20191160.18,22", "10.1007/978-1-4612-4026-6.25", "10.1109/cvpr.2006.42", "10.1145/3172944.3172950", "10.1109/cvpr.2004.383.25", "10.1109/tvcg.2019.2934812", "10.1609/aimag.v35i4.2513", "10.2312/trvis.20191185.7", "10.1111/j.1467-8659.2009.01684.x", "10.1371/journal.pone.0129126", "10.1111/cgf.13092", "10.1162/coli\\_a\\_00237", "10.1109/tvcg.2017.2744818", "10.1109/vast.2011.6102448", "10.1109/tvcg.2009.111", "10.1109/tvcg.2019.2934619", "10.1016/s0377-2217(01)00264-8.25", "10.1111/cgf.12639", "10.1109/access.2019.2919343", "10.1186/s12874-019-0681-4", "10.1109/pacificvis.2015.7156366", "10.1109/pacificvis.2018.00029", "10.1109/tvcg.2019.2934261", "10.1080/13506280444000102.http://www.uvt.nl/ticc", "10.1109/vast.2018.8802509", "10.1111/cgf.13212", "10.1145/3200489", "10.1111/cgf.13176", "10.1177/1473871620904671", "10.1007/978-3-319-10590-1\\_53", "10.1111/j.1467-8659.2012.03126.x", "10.1111/cgf.13172", "10.1145/3025171.3025208.6,21", "10.1111/cgf.12366", "10.1109/tvcg.2019.2934659", "10.1109/cvprw.2009.5206848", "10.1016/j.media.2014.11.010", "10.1109/tvcg.2017.2744683", "10.1109/tvcg.2019.2934262", "10.1016/j.neucom.2006.11.018", "10.1177/1473871615571951", "10.1371/journal.pcbi.0020161.25", "10.1177/1473871611415994", "10.2312/trvis20191187", "10.2312/eurova", "10.1145/2858036.2858529", "10.1145/2207676.2207738", "10.1007/s11042-009-0417-2", "10.1145/3301275.3302317", "10.1038/s41746-019-0148-3", "10.1145/3351095.3372834", "10.1080/10691898.2011.11889627", "10.1109/tvcg.2018.2864504", "10.1109/vast.2017.8585720", "10.1109/mcg.2018.053491732", "10.1007/s10994-010-5207-6", "10.1109/tvcg.2019.2934433", "10.1016/j.cag.2017.05.005", "10.1109/tvcg.2012.279", "10.1145/3231622.3231641.19,20", "10.1145/1562849.1562851", "10.1007/11564126\\_", "10.1109/tvcg.2018.2846735", "10.3115/1225403.1225421", "10.1109/vast.2012.6400486", "10.2312/eurova.20191116.22", "10.1109/tvcg.2007.70443", "10.1080/027868291009242", "10.2312/eurova.20151100", "10.1145/2939502.2939503.19", "10.1016/j.cag.2014.02.004", "10.1145/2939672.2939778", "10.1109/vast.2010.5652484", "10.1111/cgf.12641", "10.1145/3301275.3302289", "10.1109/visual.2019.8933619", "10.1109/tvcg.2017.2672987", "10.1109/vast.2016.7883517.20", "10.1109/igarss.2017.8127684", "10.1016/j.jcae.2010.04.002", "10.1109/vast.2010.5652885", "10.1016/j.visinf.2019.03.002", "10.1007/s00371-018-1500-3", "10.1109/mcg.2018.042731661", "10.1109/34.598228", "10.1109/tvcg.2018.2865027", "10.1016/j.neucom.2017.01.105", "10.1111/cgf.12389", "10.1109/tvcg.2019.2934591", "10.1109/vast.2010.5652392.16", "10.1111/cgf.13416", "10.1080/02701367.1992.10608764", "10.1109/vast.2017.8585721", "10.1109/tvcg.2018.2843369", "10.1109/sbes.2010.27", "10.1109/vast.2015.7347637", "10.1145/1401890.1402008", "10.1016/j.bpj.2010.04.064", "10.1109/tvcg.2013.125", "10.1109/isai-nlp.2018.8693002", "10.1371/journal.pone.0160127", "10.1145/2856767.2856779", "10.1145/2678025.2701399", "10.1109/vast.2011.6102451", "10.1109/mcg.2010.18", "10.1021/ci4000213", "10.1109/vast.2012.6400492", "10.1007/11564126-49.25", "10.2312/eurova.20171114", "10.1109/vast.2010.5652443", "10.1145/3134599", "10.2312/pe/eurovast/eurovast10/013-018.19", "10.1109/tvcg.2019.2903946", "10.1109/tvcg.2015.2467717", "10.1177/1473871612460526", "10.1016/j.cag.2018.09.018", "10.1109/tvcg.2016.2598838", "10.1145/3172944.3172964.14", "10.1109/vast.2009.5333428", "10.1109/vast.2014.7042480", "10.2312/pe/eurovast/eurovast10/013-018", "10.1177/0962280215588241", "10.1145/2993901.2993917", "10.1109/cvpr.2008:4587581", "10.1109/tvcg.2015.2467551", "10.1016/j.visinf.2018.09.001", "10.1126/science.290.5500.2319", "10.2312/eurova.20151107", "10.1109/visual.2019.8933695", "10.13140/2.1.2393.1847", "10.1197/jamia.m1929", "10.1109/cvpr.2008.4587581.25", "10.1145/1518701.1518895.16", "10.1109/vds.2017.8573444", "10.2312/trvis:20191185", "10.1145/3359786", "10.13140/2.1.1341.1520", "10.2312/pe/eurovast/eurova11/049-052.17", "10.1109/tvcg.2014.2346660", "10.1145/3185517", "10.1109/adprl.2011.5967372", "10.1109/tvcg.2015.2467591", "10.1111/j.1751-9004.2009.00232.x", "10.1136/qshc.2004.010033", "10.1109/vast.2012.6400493", "10.1109/tvcg.2019.2934266", "10.1145/2971763.2971775", "10.1111/cgf.13730", "10.1109/vast.2012.6400488", "10.1111/cgf.13210", "10.1109/tvcg.2019.2934631", "10.1145/3172944.3172965", "10.1057/ivs.2010.2", "10.1109/tvcg.2017.2745258", "10.1016/j.jbusres.2019.07.039", "10.1162/jmlr.2003.3.4-5.993", "10.1109/pacificvis.2019.00044", "10.2312/pe/eurovast/eurova12/037-041", "10.1109/tvcg.2019.2934629", "10.1177/0018720814547570", "10.1145/3292500.3330908", "10.1111/j.1467-8659.2009.01467.x", "10.2312/eurova.20151098", "10.1177/1473871617713337", "10.1109/lars:2009.5418323", "10.1109/vast.2011.6102437", "10.1111/cgf.12878", "10.1561/1500000001", "10.1145/3025171.3025222", "10.1007/s11704-016-6028-y", "10.1016/j.procs.2017.05.216", "10.1109/cvpr.2007.382974.25", "10.1080/10447318.2020.1741118", "10.1109/vast.2012.6400489", "10.1145/3025171.3025172", "10.1109/tvcg.2017.2744098", "10.1109/tvcg.2005.66", "10.1016/j.dss.2009.05.016", "10.1007/978-1-4612-4026-6", "10.2312/evs.20191168.16,20,28", "10.2312/pe/eurovast/eurova12/037-041.17", "10.1145/3290605.3300803", "10.1145/1015330.1015388", "10.1111/cgf.13197", "10.1016/b978-1-55860-377-6.50048-7", "10.1111/cgf.13681", "10.1109/tvcg.2017.2744378", "10.1109/tvcg.2017.2744358", "10.1109/vast.2008.4677352"], "wos": 1, "children": [{"doi": "10.1109/tvcg.2020.3030368", "title": "Implicit Multidimensional Projection of Local Subspaces", "year": "2020", "conferenceName": "InfoVis", "authors": "Rongzheng Bian;Yumeng Xue;Liang Zhou;Jian Zhang 0070;Baoquan Chen;Daniel Weiskopf;Yunhai Wang", "citationCount": "1", "affiliation": "Wang, YH (Corresponding Author), Shandong Univ, Qingdao, Peoples R China. Zhou, L (Corresponding Author), Univ Utah, Salt Lake City, UT 84112 USA. Bian, Rongzheng; Xue, Yumeng; Wang, Yunhai, Shandong Univ, Qingdao, Peoples R China. Chen, Baoquan, Peking Univ, Beijing, Peoples R China. Zhang, Jian, Chinese Acad Sci, CNIC, Beijing, Peoples R China. Zhou, Liang, Univ Utah, Salt Lake City, UT 84112 USA. Weiskopf, Daniel, Univ Stuttgart, Stuttgart, Germany.", "countries": "USA;Germany;China", "abstract": "We propose a visualization method to understand the effect of multidimensional projection on local subspaces, using implicit function differentiation. Here, we understand the local subspace as the multidimensional local neighborhood of data points. Existing methods focus on the projection of multidimensional data points, and the neighborhood information is ignored. Our method is able to analyze the shape and directional information of the local subspace to gain more insights into the global structure of the data through the perception of local structures. Local subspaces are fitted by multidimensional ellipses that are spanned by basis vectors. An accurate and efficient vector transformation method is proposed based on analytical differentiation of multidimensional projections formulated as implicit functions. The results are visualized as glyphs and analyzed using a full set of specifically-designed interactions supported in our efficient web-based visualization tool. The usefulness of our method is demonstrated using various multi- and high-dimensional benchmark datasets. Our implicit differentiation vector transformation is evaluated through numerical comparisons; the overall method is evaluated through exploration examples and use cases.", "keywords": "High-dimensional data visualization,dimensionality reduction,local linear subspaces,user interaction", "link": "http://dx.doi.org/10.1109/TVCG.2020.3030368", "refList": ["10.3844/jcssp.2018.613.622", "10.1016/j.aci.2018.08.003", "10.3390/info9030065", "10.1016/j.visinf.2018.09.003", "10.1371/journal.pone.0118432", "10.1016/s0893-6080(05)80023-1", "10.1109/tvcg.2020.2986996", "10.1109/icst.2012.56", "10.1007/s10844-013-0250-y", "10.1109/tbdata.2018", "10.1145/1125451.1125659", "10.1109/tvcg.2013.125", "10.1177/1473871611412817", "10.1145/3290605.3300911", "10.1111/cgf.14034", "10.1007/s13721-013-0034-x", "10.1016/j.procs.2017.05.216", "10.1016/j.ins.2009.08.025", "10.1109/tvcg.2013.124", "10.1109/tvcg.2018.2864499", "10.1109/tvcg.2018.2864475", "10.1080/10447318.2020.1741118", "10.1016/j.imu.2019.100203", "10.1109/tvcg.2018.2865240", "10.1186/s12864-019-6413-7", "10.1109/tvcg.2015.2467551", "10.1002/widm.1249", "10.1007/978-3-319-66429-3\\_29", "10.1109/tvcg.2014.2346481", "10.1109/tvcg.2018.2864825", "10.1177/1473871620904671", "10.1109/tvcg.2019.2934267", "10.1136/bmjopen-2016-012799", "10.1109/smartgridcomm.2017.8340682", "10.1007/s10664-015-9401-9", "10.1145/1143844.1143874", "10.1111/cgf.12389", "10.1109/tvcg.2018.2872577", "10.1007/978-981-13-5802-9\\_20", "10.1016/j.ipm.2009.03.002", "10.5220/0006431602160222", "10.1109/mcg.2015.50", "10.1109/tvcg.2014.2346574", "10.1007/bf02289565", "10.1109/tvcg.2017.2744378", "10.1016/j.patrec.2008.08.010", "10.1023/a:1010933404324", "10.9735/2229-3981"], "wos": 1, "children": [], "len": 1}, {"doi": "10.1109/tvcg.2020.3030465", "title": "Visual Causality Analysis of Event Sequence Data", "year": "2020", "conferenceName": "VAST", "authors": "Zhuochen Jin;Shunan Guo;Nan Chen;Daniel Weiskopf;David Gotz;Nan Cao", "citationCount": "0", "affiliation": "Cao, N (Corresponding Author), Tongji Univ, IDVx Lab, Shanghai, Peoples R China. Jin, Zhuochen; Guo, Shunan; Chen, Nan; Cao, Nan, Tongji Univ, IDVx Lab, Shanghai, Peoples R China. Weiskopf, Daniel, Univ Stuttgart, Stuttgart, Germany. Gotz, David, Univ N Carolina, Chapel Hill, NC 27515 USA.", "countries": "USA;Germany;China", "abstract": "Causality is crucial to understanding the mechanisms behind complex systems and making decisions that lead to intended outcomes. Event sequence data is widely collected from many real-world processes, such as electronic health records, web clickstreams, and financial transactions, which transmit a great deal of information reflecting the causal relations among event types. Unfortunately, recovering causalities from observational event sequences is challenging, as the heterogeneous and high-dimensional event variables are often connected to rather complex underlying event excitation mechanisms that are hard to infer from limited observations. Many existing automated causal analysis techniques suffer from poor explainability and fail to include an adequate amount of human knowledge. In this paper, we introduce a visual analytics method for recovering causalities in event sequence data. We extend the Granger causality analysis algorithm on Hawkes processes to incorporate user feedback into causal model refinement. The visualization system includes an interactive causal analysis framework that supports bottom-up causal exploration, iterative causal verification and refinement, and causal comparison through a set of novel visualizations and interactions. We report two forms of evaluation: a quantitative evaluation of the model improvements resulting from the user-feedback mechanism, and a qualitative evaluation through case studies in different application domains to demonstrate the usefulness of the system.", "keywords": "Event sequence data,causality analysis,visual analytics", "link": "http://dx.doi.org/10.1109/TVCG.2020.3030465", "refList": ["10.5555/1642718", "10.1109/tvcg.2018.2865022", "10.5555/2074094.2074151", "10.1109/tvcg.2016.2618797", "10.1073/pnas.1320645111", "10.1109/tvcg.2017.2744843", "10.1109/iv.2017.69", "10.1109/tvcg.2019.2934399", "10.1145/3172944.3173007", "10.5555/1795555", "10.1109/mcg.2005.102", "10.1145/381641.381653", "10.1162/153244301753344614", "10.1111/cgf.14034", "10.1111/cgf.13198", "10.1017/cbo9780511519857", "10.1007/s10462-016-9475-9", "10.1075/ssol.2.2.07bor", "10.1007/978-1-4614-3223-4\\_3", "10.1109/infvis.2003.1249025", "10.1007/978-94-007-6094-313", "10.1145/2858036.2858387", "10.1109/tvcg.2007.70528", "10.1109/tvcg.2017.2674958", "10.1147/sj.454.0801", "10.1109/tvcg.2013.119", "10.1145/3173574.3173711", "10.1016/j.erss.2017.06.034", "10.1109/visual.2019.8933695", "10.1007/s11665-016-2173-6", "10.1016/0377-0427(87)90125-7", "10.2307/3601125", "10.1016/b978-0-444-88738-2.50018-x", "10.1109/mcg.2006.70", "10.1109/tvcg.2018.2865145", "10.1017/s1351324997001502", "10.1109/tvcg.2010.179", "10.1214/aos/1176344552", "10.1109/mcg.2009.22", "10.1007/978-3-319-26633-6\\_13", "10.1080/10447318.2014.905422", "10.1016/j.visinf.2019.03.004", "10.1057/palgrave.ivs.9500074", "10.1007/978-1-4614-3223-4"], "wos": 1, "children": [], "len": 1}], "len": 5}], "len": 7}, {"doi": "10.1109/tvcg.2020.3028888", "title": "A Visual Analytics Framework for Explaining and Diagnosing Transfer Learning Processes", "year": "2020", "conferenceName": "VAST", "authors": "Yuxin Ma;Arlen Fan;Jingrui He;Arun Reddy Nelakurthi;Ross Maciejewski", "citationCount": "0", "affiliation": "Ma, YX (Corresponding Author), Arizona State Univ, Tempe, AZ 85287 USA. Ma, Yuxin; Fan, Arlen; Maciejewski, Ross, Arizona State Univ, Tempe, AZ 85287 USA. He, Jingrui, Univ Illinois, Champaign, IL USA. Nelakurthi, Arun Reddy, Samsung Res Amer, Mountain View, CA USA.", "countries": "USA", "abstract": "Many statistical learning models hold an assumption that the training data and the future unlabeled data are drawn from the same distribution. However, this assumption is difficult to fulfill in real-world scenarios and creates barriers in reusing existing labels from similar application domains. Transfer Learning is intended to relax this assumption by modeling relationships between domains, and is often applied in deep learning applications to reduce the demand for labeled data and training time. Despite recent advances in exploring deep learning models with visual analytics tools, little work has explored the issue of explaining and diagnosing the knowledge transfer process between deep learning models. In this paper, we present a visual analytics framework for the multi-level exploration of the transfer learning processes when training deep neural networks. Our framework establishes a multi-aspect design to explain how the learned knowledge from the existing model is transferred into the new learning task when training deep neural networks. Based on a comprehensive requirement and task analysis, we employ descriptive visualization with performance measures and detailed inspections of model behaviors from the statistical, instance, feature, and model structure levels. We demonstrate our framework through two case studies on image classification by fine-tuning AlexNets to illustrate how analysts can utilize our framework.", "keywords": "Transfer learning,deep learning,visual analytics", "link": "http://dx.doi.org/10.1109/TVCG.2020.3028888", "refList": ["10.1109/tvcg.2014.2346578", "10.1109/tvcg.2019.2934629", "10.1109/tvcg.2017.2744683", "10.1109/tvcg.2016.2598838", "10.1109/tvcg.2017.2744938", "10.1109/tvcg.2019.2934262", "10.1109/tpami.2018.2868685", "10.1145/2702123.2702509", "10.1109/vast.2017.8585721", "10.1109/tvcg.2018.2843369", "10.1109/tvcg.2016.2598828", "10.1111/j.1467-8659.2011.01898.x", "10.1109/tvcg.2013.65", "10.1145/2976749.2978318", "10.1007/978-3-030-01424-7\\_27", "10.1109/tvcg.2019.2934261", "10.1007/s11704-016-6028-y", "10.1016/j.visinf.2017.01.006", "10.1145/2858036.2858529", "10.1109/iccv.2015.279", "10.1109/mci.2018.2840738", "10.1109/tvcg.2019.2892483", "10.1109/vast.2018.8802509", "10.1109/tvcg.2013.124", "10.1186/s40537-016-0043-6", "10.1109/tvcg.2018.2864475", "10.1145/3200489", "10.1109/tvcg.2018.2865044", "10.1111/cgf.13210", "10.1109/tvcg.2018.2816223", "10.23915/distill.00007", "10.1109/tvcg.2017.2744199", "10.1109/tkde.2018.2876857", "10.1109/tvcg.2019.2934631", "10.1109/tvcg.2018.2864504", "10.1109/tvcg.2014.2346482", "10.1109/tvcg.2015.2467618", "10.1109/tvcg.2014.2346594", "10.1109/tvcg.2011.188", "10.1007/978-3-642-15561-1\\_16", "10.1109/tvcg.2018.2864812", "10.1109/mcg.2019.2919033", "10.1109/tvcg.2017.2744718", "10.1109/tvcg.2017.2744878", "10.1109/tvcg.2016.2598541", "10.1109/tkde.2009.191", "10.1145/3065386", "10.1016/j.ins.2016.03.021", "10.1109/tvcg.2019.2903943", "10.1007/s10994-009-5152-4", "10.1109/tvcg.2019.2934659", "10.1109/tvcg.2018.2864500", "10.1109/iccv.2017.74", "10.1109/tvcg.2017.2744158", "10.1109/tvcg.2012.207", "10.1111/cgf.13092", "10.1109/tvcg.2018.2865027", "10.1109/tvcg.2017.2744378", "10.1109/tvcg.2017.2744358", "10.1109/tvcg.2019.2934619", "10.1109/tvcg.2018.2864499", "10.1109/tvcg.2017.2754480", "10.1109/tvcg.2016.2598831"], "wos": 1, "children": [], "len": 1}, {"doi": "10.1109/tvcg.2020.3028958", "title": "Auditing the Sensitivity of Graph-based Ranking with Visual Analytics", "year": "2020", "conferenceName": "VAST", "authors": "Tiankai Xie;Yuxin Ma;Hanghang Tong;My T. Thai;Ross Maciejewski", "citationCount": "0", "affiliation": "Xie, TK (Corresponding Author), Arizona State Univ, Tempe, AZ 85287 USA. Xie, Tiankai; Ma, Yuxin; Maciejewski, Ross, Arizona State Univ, Tempe, AZ 85287 USA. Tong, Hanghang, Univ Illinois, Urbana, IL USA. Thai, My T., Univ Florida, Gainesville, FL 32611 USA.", "countries": "USA", "abstract": "Graph mining plays a pivotal role across a number of disciplines, and a variety of algorithms have been developed to answer who/what type questions. For example, what items shall we recommend to a given user on an e-commerce platform? The answers to such questions are typically returned in the form of a ranked list, and graph-based ranking methods are widely used in industrial information retrieval settings. However, these ranking algorithms have a variety of sensitivities, and even small changes in rank can lead to vast reductions in product sales and page hits. As such, there is a need for tools and methods that can help model developers and analysts explore the sensitivities of graph ranking algorithms with respect to perturbations within the graph structure. In this paper, we present a visual analytics framework for explaining and exploring the sensitivity of any graph-based ranking algorithm by performing perturbation-based what-if analysis. We demonstrate our framework through three case studies inspecting the sensitivity of two classic graph-based ranking algorithms (PageRank and HITS) as applied to rankings in political news media and social networks.", "keywords": "Graph-based ranking,sensitivity analysis,visual analytics", "link": "http://dx.doi.org/10.1109/TVCG.2020.3028958", "refList": ["10.1109/wsc.2017.8247800", "10.1023/a:1022649401552", "10.1515/1559-0410.11416", "10.1109/tvcg.2016.2598919", "10.1177/1473871611416549", "10.1109/tvcg.2019.2934630", "10.1140/epjds29", "10.1109/tvcg.2019.2934670", "10.1016/j.eswa.2015.09.004", "10.1145/2702123.2702509", "10.1016/j.visinf.2018.12.001", "10.2307/3002000", "10.1109/tvcg.2019.2934399", "10.1007/s41060-016-0032-z", "10.1111/cgf.13198", "10.14778/2350229.2350254", "10.1145/2939672.2939764", "10.1016/j.visinf.2017.01.006", "10.1145/2858036.2858529", "10.1109/vast.2017.8585647", "10.1007/bf01187020", "10.1109/icdm.2015.26", "10.1145/2362383.2362387", "10.1177/0049124104268644", "10.1109/vast.2011.6102442", "10.1109/infvis.2003.1249025", "10.1109/tvcg.2018.2864475", "10.1109/tvcg.2007.70528", "10.1109/tvcg.2015.2467691", "10.1111/cgf.13210", "10.1214/aos/1176344136", "10.1109/tvcg.2015.2424872", "10.1016/j.visinf.2018.09.001", "10.1177/089443939100900106", "10.1109/tvcg.2015.2467931", "10.1162/neco.1997.9.8.1735", "10.1007/s11162-011-9241-4", "10.1111/cgf.13680", "10.1145/3065386", "10.1109/tvcg.2018.2864889", "10.1177/003804070808100402", "10.1109/icdm.2010.62", "10.1038/s41598-020-59669-x", "10.1162/153244303321897717", "10.1109/tvcg.2019.2934619", "10.1007/bf00356088", "10.1109/tvcg.2016.2598432", "10.1109/tvcg.2016.2598831"], "wos": 1, "children": [], "len": 1}, {"doi": "10.1111/cgf.13731", "year": "2019", "title": "The State of the Art in Visual Analysis Approaches for Ocean and Atmospheric Datasets", "conferenceName": "EuroVis", "authors": "Shehzad Afzal;Mohamad Mazen Hittawe;Sohaib Ghani;Tahira Jamil;Omar M. Knio;Markus Hadwiger;Kevin I.{-}J. Ho", "citationCount": "0", "affiliation": "Afzal, S (Corresponding Author), King Abdullah Univ Sci \\& Technol, Thuwal, Saudi Arabia.\nAfzal, S.; Hittawe, M. M.; Ghani, S.; Jamil, T.; Knio, O.; Hadwiger, M.; Hoteit, I, King Abdullah Univ Sci \\& Technol, Thuwal, Saudi Arabia.", "countries": "Arabia", "abstract": "The analysis of ocean and atmospheric datasets offers a unique set of challenges to scientists working in different application areas. These challenges include dealing with extremely large volumes of multidimensional data, supporting interactive visual analysis, ensembles exploration and visualization, exploring model sensitivities to inputs, mesoscale ocean features analysis, predictive analytics, heterogeneity and complexity of observational data, representing uncertainty, and many more. Researchers across disciplines collaborate to address such challenges, which led to significant research and development advances in ocean and atmospheric sciences, and also in several relevant areas such as visualization and visual analytics, big data analytics, machine learning and statistics. In this report, we perform an extensive survey of research advances in the visual analysis of ocean and atmospheric datasets. First, we survey the task requirements by conducting interviews with researchers, domain experts, and end users working with these datasets on a spectrum of analytics problems in the domain of ocean and atmospheric sciences. We then discuss existing models and frameworks related to data analysis, sense-making, and knowledge discovery for visual analytics applications. We categorize the techniques, systems, and tools presented in the literature based on the taxonomies of task requirements, interaction methods, visualization techniques, machine learning and statistical methods, evaluation methods, data types, data dimensions and size, spatial scale and application areas. We then evaluate the task requirements identified based on our interviews with domain experts in the context of categorized research based on our taxonomies, and existing models and frameworks of visual analytics to determine the extent to which they fulfill these task requirements, and identify the gaps in current research. In the last part of this report, we summarize the trends, challenges, and opportunities for future research in this area. (see http://www.acm.org/about/class/class/2012) )", "keywords": "", "link": "https://doi.org/10.1111/cgf.13731", "refList": ["10.1111/cgf.12898", "10.1109/icdmw.2009.55", "10.1109/tvcg.2013.144", "10.1109/tvcg.2015.2467754", "10.1109/tvcg.2015.2507569", "10.1109/tvcg.2014.2346455", "10.1111/cgf.12901", "10.1109/tvcg.2008.184", "10.1109/mc.2013.119", "10.1111/j.1467-8659.2009.01697.x", "10.1109/tvcg.2009.200", "10.1111/cgf.12649", "10.1109/2945.981847", "10.1109/tvcg.2014.2346481", "10.1109/tvcg.2012.190", "10.1109/mis.2006.75", "10.1109/iv.2015.13", "10.1111/cgf.12135", "10.1109/vast.2009.5332586", "10.1109/pacificvis.2011.5742369", "10.1109/tvcg.2008.131", "10.1109/tvcg.2013.131", "10.1109/tvcg.2010.82", "10.1109/pacificvis.2015.7156374", "10.1111/cgf.12886", "10.1109/tvcg.2016.2598869", "10.1109/vast.2012.6400553", "10.1109/pacificvis.2013.6596144", "10.1109/tvcg.2017.2745178", "10.1109/tvcg.2015.2410278", "10.1111/cgf.12931", "10.1109/tvcg.2009.155", "10.1109/pacificvis.2015.7156366", "10.1109/mcg.2015.121", "10.1007/978-1-4471-2804-5\\_6", "10.1109/ldav.2015.7348068", "10.1007/978-1-4471-6497-5\\_1", "10.1109/pacificvis.2009.4906852", "10.1111/cgf.12646", "10.1109/tvcg.2016.2607204", "10.1109/tvcg.2011.162", "10.1177/1473871612465214", "10.1109/mcg.2017.3621228", "10.1109/tvcg.2012.110", "10.1109/sc.2014.40", "10.5194/gmd-8-2329-2015", "10.1109/tvcg.2012.80", "10.1109/tvcg.2014.2346448", "10.1109/ldav.2012.6378978", "10.1007/s10915-011-9501-7", "10.1109/tvcg.2016.2598830", "10.1109/tvcg.2007.70515", "10.1109/vast.2011.6102460", "10.1109/pacificvis.2017.8031584", "10.1109/tvcg.2016.2637904", "10.1175/2009jtecha1374.1", "10.1109/tvcg.2015.2467591", "10.1109/tvcg.2015.2467204", "10.1109/tvcg.2008.59", "10.1109/tvcg.2013.143", "10.1109/tvcg.2008.119", "10.1109/tvcg.2015.2467411", "10.1109/icdmw.2009.91", "10.1109/tvcg.2016.2598868", "10.1109/tvcg.2017.2661309", "10.1109/vl.1996.545307", "10.1109/tvcg.2007.70523", "10.1109/tvcg.2008.140", "10.1109/icra.2012.6224689", "10.1109/tvcg.2010.80", "10.1167/tvst.7.1.16", "10.1109/pacificvis.2018.00037", "10.1111/cgf.13210", "10.1109/tvcg.2017.2698041", "10.1109/iv.2010.51", "10.1109/tvcg.2016.2640960", "10.1109/tvcg.2010.170", "10.1103/physrevd.71.077102", "10.5194/npg-22-545-2015", "10.1109/tvcg.2014.2307892", "10.1111/cgf.12650", "10.1109/iv.2009.38", "10.2312/pe.envirvis.envirvis13.053-057", "10.1145/3122948.3122952", "10.1109/ldav.2014.7013208", "10.1038/nature14956", "10.1109/vast.2015.7347671", "10.1109/vast.2015.7347634", "10.1109/tvcg.2014.2346755", "10.1177/1473871613481692", "10.1109/ldav.2017.8231849", "10.1109/tvcg.2017.2773071", "10.1109/iv.2011.79", "10.1109/tvcg.2013.10", "10.1109/tvcg.2008.157", "10.1111/j.1467-8659.2009.01664.x", "10.1109/pacificvis.2016.7465251", "10.1109/vast.2014.7042489", "10.1109/mis.2006.100", "10.1109/tvcg.2010.247", "10.1109/tvcg.2016.2534560", "10.1109/tvcg.2010.181", "10.1109/tvcg.2018.2864817", "10.1109/vast.2015.7347635", "10.1109/tvcg.2018.2864901", "10.1109/hicss.2016.183", "10.1109/iv.2010.32", "10.1111/j.1467-8659.2011.01948.x", "10.1109/tvcg.2017.2743989", "10.1109/pacificvis.2016.7465272", "10.1109/tvcg.2008.69", "10.1109/tvcg.2008.139", "10.1109/iv.2011.12", "10.1111/cgf.12520"], "wos": 1, "children": [{"doi": "10.1109/tvcg.2020.3030466", "title": "Uncertainty in Continuous Scatterplots, Continuous Parallel Coordinates, and Fibers", "year": "2020", "conferenceName": "SciVis", "authors": "Boyan Zheng;Filip Sadlo", "citationCount": "0", "affiliation": "Zheng, BY (Corresponding Author), Heidelberg Univ, Heidelberg, Germany. Zheng, Boyan; Sadlo, Filip, Heidelberg Univ, Heidelberg, Germany.", "countries": "Germany", "abstract": "In this paper, we introduce uncertainty to continuous scatterplots and continuous parallel coordinates. We derive respective models, validate them with sampling-based brute-force schemes, and present acceleration strategies for their computation. At the same time, we show that our approach lends itself as well for introducing uncertainty into the definition of fibers in bivariate data. Finally, we demonstrate the properties and the utility of our approach using specifically designed synthetic cases and simulated data.", "keywords": "Multivariate data,uncertainty visualization,uncertain continuous scatterplots,uncertain continuous parallel coordinates,uncertain fibers", "link": "http://dx.doi.org/10.1109/TVCG.2020.3030466", "refList": ["10.1109/tvcg.2018.2865193", "10.1109/tvcg.2013.143", "10.1109/tvcg.2015.2467204", "10.1109/pacificvis.2013.6596144", "10.1109/tvcg.2017.2745178", "10.1109/tmm.2016.2614227", "10.1109/scivis.2015.7429488", "10.1111/cgf.12100", "10.1109/pacificvis.2016.7465251", "10.1111/cgf.12898", "10.1109/tvcg.2015.2410278", "10.1109/icdmw.2009.55", "10.1109/tvcg.2015.2467754", "10.1109/tvcg.2010.247", "10.1109/tvcg.2019.2934312", "10.1111/cgf.13397", "10.1109/tvcg.2016.2598868", "10.1111/j.1467-8659.2011.01944.x", "10.1109/tvcg.2015.2507569", "10.1109/tvcg.2013.92", "10.1145/1268517.1268563", "10.1109/tvcg.2014.2346455", "10.1109/tvcg.2010.181", "10.1109/tvcg.2018.2853721", "10.1109/tvcg.2008.140", "10.1007/s12650-015-0341-7", "10.1109/mcg.2014.52", "10.1109/tvcg.2018.2864815", "10.1111/j.1467-8659.2012.03095.x", "10.1109/tvcg.2013.138", "10.1109/tvcg.2019.2934242", "10.3390/e20070540", "10.1016/j.jcp.2007.02.014", "10.1111/cgf.13999", "10.1109/tvcg.2017.2779501", "10.1111/cgf.12390", "10.1109/tvcg.2014.2307892", "10.1111/cgf.13531", "10.1109/tvcg.2013.152", "10.1038/nature14956", "10.1007/978-3-540-88606-8\\_4", "10.1109/mcg.2005.71", "10.1111/j.1467-8659.2011.01942.x", "10.1109/tvcg.2019.2934800", "10.1109/tvcg.2016.2598830", "10.1109/cvpr.2005.188", "10.1109/tvcg.2011.261", "10.1111/cgf.13731", "10.1109/tvcg.2017.2754480"], "wos": 1, "children": [], "len": 1}], "len": 3}, {"doi": "10.1111/cgf.13677", "year": "2019", "title": "An Ontological Framework for Supporting the Design and Evaluation of Visual Analytics Systems", "conferenceName": "EuroVis", "authors": "Min Chen;David S. Ebert", "citationCount": "5", "affiliation": "Chen, M (Corresponding Author), Univ Oxford, Oxford, England.\nChen, Min, Univ Oxford, Oxford, England.\nEbert, David S., Purdue Univ, W Lafayette, IN 47907 USA.", "countries": "USA;England", "abstract": "Designing, evaluating, and improving visual analytics (VA) systems is a primary area of activities in our discipline. In this paper, we present an ontological framework for recording and categorizing technical shortcomings to be addressed in a VA workflow, reasoning about the causes of such problems, identifying technical solutions, and anticipating secondary effects of the solutions. The methodology is built on the theoretical premise that designing a VA workflow is an optimization of the cost-benefit ratio of the processes in the workflow. It makes uses three fundamental measures to group and connect symptoms, causes, remedies, and side-effects, and guide the search for potential solutions to the problems. In terms of requirement analysis and system design, the proposed methodology can enable system designers to explore the decision space in a structured manner. In terms of evaluation, the proposed methodology is time-efficient and complementary to various forms of empirical studies, such as user surveys, controlled experiments, observational studies, focus group discussions, and so on. In general, it reduces the amount of trial-and-error in the lifecycle of VA system development.", "keywords": "", "link": "https://doi.org/10.1111/cgf.13677", "refList": ["10.1109/tvcg.2006.178", "10.1109/infvis.2000.885092", "10.1111/cgf.12920", "10.1057/ivs.2009.26", "10.1109/mcg.2017.3271463", "10.1007/978-3-319-10578-9\\_1", "10.1109/icdmw.2008.62", "10.1109/mcg.2017.51", "10.1145/3011141.3011207", "10.1109/tvcg.2013.134", "10.1080/10618600.1996.10474696", "10.1007/978-3-540-70956-5", "10.1109/visual.1990.146375", "10.1109/tvcg.2012.219", "10.1109/vl.1996.545307", "10.1057/ivs.2009.23", "10.1002/j.1538-7305.1948.tb00917.x", "10.1109/tvcg.2010.79", "10.1109/tvcg.2013.124", "10.1111/cgf.13211", "10.1007/978-3-642-40897-7\\_9", "10.1103/physrev.108.171", "10.1109/infvis.2004.59", "10.1109/iv.2008.36", "10.1111/cgf.13210", "10.1111/j.1467-8659.2008.01230.x", "10.1001/jama.293.10.1223", "10.1177/1473871611407399", "10.1109/visual.1995.480821", "10.1117/12.539227", "10.1109/tvcg.2015.2513410", "10.1109/vast.2011.6102463", "10.7749/citiescommunitiesterritories.dec2014.029.art01", "10.1109/mcg.2005.55", "10.1109/tvcg.2012.234", "10.1109/pacificvis.2012.6183556", "10.1103/physrev.106.620", "10.1109/infvis.1997.636792", "10.2307/2104491", "10.1145/2468356.2468677", "10.1145/3173574.3173611", "10.1109/tvcg.2018.2864838", "10.1111/cgf.13092", "10.1109/visual.2004.10", "10.1109/tvcg.2017.2744319", "10.1109/tvcg.2009.111", "10.1109/tvcg.2013.120", "10.1109/tvcg.2016.2603178"], "wos": 1, "children": [{"doi": "10.1109/tvcg.2019.2934264", "title": "The Validity, Generalizability and Feasibility of Summative Evaluation Methods in Visual Analytics", "year": "2019", "conferenceName": "VAST", "authors": "Mosab Khayat;Morteza Karimzadeh;David S. Ebert;Arif Ghafoor", "citationCount": "1", "affiliation": "Khayat, M (Corresponding Author), Purdue Univ, W Lafayette, IN 47907 USA. Khayat, Mosab; Karimzadeh, Morteza; Ebert, David S.; Ghafoor, Arif, Purdue Univ, W Lafayette, IN 47907 USA. Karimzadeh, Morteza, Univ Colorado, Boulder, CO 80309 USA.", "countries": "USA", "abstract": "Many evaluation methods have been used to assess the usefulness of Visual Analytics (VA) solutions. These methods stem from a variety of origins with different assumptions and goals, which cause confusion about their proofing capabilities. Moreover, the lack of discussion about the evaluation processes may limit our potential to develop new evaluation methods specialized for VA. In this paper, we present an analysis of evaluation methods that have been used to summatively evaluate VA solutions. We provide a survey and taxonomy of the evaluation methods that have appeared in the VAST literature in the past two years. We then analyze these methods in terms of validity and generalizability of their findings, as well as the feasibility of using them. We propose a new metric called summative quality to compare evaluation methods according to their ability to prove usefulness, and make recommendations for selecting evaluation methods based on their summative quality in the VA domain.", "keywords": "Summative evaluation,usefulness,evaluation process,taxonomy,visual analytics", "link": "http://dx.doi.org/10.1109/TVCG.2019.2934264", "refList": ["10.1109/tvcg.2017.2744478", "10.1109/tvcg.2018.2865025", "10.1109/tvcg.2006.85", "10.1109/tvcg.2014.2346331", "10.1109/beliv.2018.8634420", "10.1109/tvcg.2017.2745181", "10.1111/cgf.13677", "10.1109/tvcg.2018.2864844", "10.1109/tvcg.2013.126", "10.1109/tvcg.2018.2864811", "10.1109/infvis.2005.1532147", "10.1177/0956797613504966", "10.1145/2669557.2669579", "10.1109/mcg.2005.102", "10.1109/visual.2003.1250426", "10.1136/bmj.39489.470347.ad", "10.1109/tvcg.2017.2744080", "10.1109/mcg.2009.53", "10.1111/j.1467-8527.2005.00307.x", "10.1109/tvcg.2010.132", "10.1109/tvcg.2018.2864886", "10.1109/tvcg.2018.2864843", "10.1109/tvcg.2018.2865028", "10.1109/tvcg.2018.2865051", "10.1109/tvcg.2018.2865044", "10.1109/tvcg.2018.2865026", "10.1007/978-3-540-71080-6\\_6", "10.1109/tvcg.2018.2865020", "10.1177/1473871611407399", "10.1109/tvcg.2018.2864504", "10.1109/tvcg.2018.2864526", "10.1109/tvcg.2005.53", "10.1109/tvcg.2018.2864905", "10.1049/sej.1991.0040", "10.1109/tvcg.2015.2513410", "10.1109/tvcg.2017.2711030", "10.1109/tvcg.2011.279", "10.1109/vast.2017.8585505", "10.1147/jrd.2010.2042914", "10.1016/s0378-7206(98)00044-5", "10.1145/2993901.2993913", "10.1109/tvcg.2018.2865041", "10.1109/tvcg.2018.2864812", "10.1109/tvcg.2017.2744758", "10.1145/1168149.1168158", "10.1109/tvcg.2017.2745279", "10.1109/tvcg.2012.213", "10.1109/tvcg.2017.2744738", "10.1109/tvcg.2017.2745083", "10.1109/tvcg.2018.2864826", "10.1145/1377966.1377974", "10.1109/apec.2009.4802646", "10.1145/1168149.1168152", "10.1016/j.jss.2008.03.059", "10.1109/vast.2017.8585484", "10.1109/tvcg.2017.2744818", "10.1109/tvcg.2017.2744358", "10.1109/tvcg.2018.2864499", "10.1109/tvcg.2018.2865042", "10.1109/tvcg.2017.2744898"], "wos": 1, "children": [{"doi": "10.1109/tvcg.2020.3030388", "title": "Visualization of Human Spine Biomechanics for Spinal Surgery", "year": "2020", "conferenceName": "SciVis", "authors": "Pepe Eulzer;Sabine Bauer;Francis Kilian;Kai Lawonn", "citationCount": "0", "affiliation": "Eulzer, P (Corresponding Author), Univ Jena, Jena, Germany. Eulzer, Pepe; Lawonn, Kai, Univ Jena, Jena, Germany. Bauer, Sabine, Univ Koblenz Landau, Koblenz, Germany. Kilian, Francis, Cath Clin Koblenz Montabaur, Dept Spine Surg, Koblenz, Germany.", "countries": "Germany", "abstract": "We propose a visualization application, designed for the exploration of human spine simulation data. Our goal is to support research in biomechanical spine simulation and advance efforts to implement simulation-backed analysis in surgical applications. Biomechanical simulation is a state-of-the-art technique for analyzing load distributions of spinal structures. Through the inclusion of patient-specific data, such simulations may facilitate personalized treatment and customized surgical interventions. Difficulties in spine modelling and simulation can be partly attributed to poor result representation, which may also be a hindrance when introducing such techniques into a clinical environment. Comparisons of measurements across multiple similar anatomical structures and the integration of temporal data make commonly available diagrams and charts insufficient for an intuitive and systematic display of results. Therefore, we facilitate methods such as multiple coordinated views, abstraction and focus and context to display simulation outcomes in a dedicated tool. $\\mathrm{By}$ linking the result data with patient-specific anatomy, we make relevant parameters tangible for clinicians. Furthermore, we introduce new concepts to show the directions of impact force vectors, which were not accessible before. We integrated our toolset into a spine segmentation and simulation pipeline and evaluated our methods with both surgeons and biomechanical researchers. When comparing our methods against standard representations that are currently in use, we found increases in accuracy and speed in data exploration tasks. $\\mathrm{in}$ a qualitative review, domain experts deemed the tool highly useful when dealing with simulation result data, which typically combines time-dependent patient movement and the resulting force distributions on spinal structures.", "keywords": "Medical visualization,bioinformatics,coordinated views,focus and context,biomechanical simulation", "link": "http://dx.doi.org/10.1109/TVCG.2020.3030388", "refList": ["10.1109/tvcg.2018.2864903", "10.1177/1473871613510429", "10.1093/ehjqcco/qcz052", "10.1109/tvcg.2007.70594", "10.1109/tvcg.2018.2865076", "10.1055/s-0039-1687862", "10.1109/visual.1990.146375", "10.1109/tvcg.2017.2744198", "10.1016/j.ijmedinf.2014.10.001", "10.1109/tvcg.2013.124", "10.1016/j.jacc", "10.1111/cgf.13167", "10.17705/1thci.00055", "10.1136/bmjqs.2009.037895", "10.1109/tvcg.2013.238", "10.1109/tvcg.2018.2865240", "10.1186/1471-2261-6-34", "10.1109/tvcg.2019.2934264", "10.1109/tvcg.2013.200", "10.1109/tvcg.2011.209", "10.1109/tvcg.2014.2346682", "10.1109/tvcg.2015.2467091", "10.1136/bmjopen-2019-033208", "10.1109/beliv.2018.8634027", "10.1109/tvcg.2012.213", "10.1109/tvcg.2015.2467191", "10.1109/tvcg.2015.2467325", "10.1145/2133806.2133821", "10.1145/1806799.1806866", "10.1108/02635570610688869", "10.1002/hbm.20701", "10.1561/1100000039", "10.1145/3025453.3025645", "10.1109/tvcg.2009.111", "10.1109/tvcg.2013.120", "10.1109/tvcg.2016.2599030"], "wos": 1, "children": [], "len": 1}], "len": 3}], "len": 5}, {"doi": "10.1111/cgf.14034", "year": "2020", "title": "The State of the Art in Enhancing Trust in Machine Learning Models with the Use of Visualizations", "conferenceName": "EuroVis", "authors": "Angelos Chatzimparmpas;Rafael Messias Martins;Ilir Jusufi;Kostiantyn Kucher;Fabrice Rossi;Andreas Kerren", "citationCount": "2", "affiliation": "Chatzimparmpas, A (Corresponding Author), Linnaeus Univ, Dept Comp Sci \\& Media Technol, Vaxjo, Sweden.\nChatzimparmpas, A.; Martins, R. M.; Jusufi, I.; Kucher, K.; Kerren, A., Linnaeus Univ, Dept Comp Sci \\& Media Technol, Vaxjo, Sweden.\nRossi, F., PSL Univ, Univ Paris Dauphine, Ceremade, Paris, France.", "countries": "Sweden;France", "abstract": "Machine learning (ML) models are nowadays used in complex applications in various domains, such as medicine, bioinformatics, and other sciences. Due to their black box nature, however, it may sometimes be hard to understand and trust the results they provide. This has increased the demand for reliable visualization tools related to enhancing trust in ML models, which has become a prominent topic of research in the visualization community over the past decades. To provide an overview and present the frontiers of current research on the topic, we present a State-of-the-Art Report (STAR) on enhancing trust in ML models with the use of interactive visualization. We define and describe the background of the topic, introduce a categorization for visualization techniques that aim to accomplish this goal, and discuss insights and opportunities for future research directions. Among our contributions is a categorization of trust against different facets of interactive ML, expanded and improved from previous research. Our results are investigated from different analytical perspectives: (a) providing a statistical overview, (b) summarizing key findings, (c) performing topic analyses, and (d) exploring the data sets used in the individual papers, all with the support of an interactive web-based survey browser. We intend this survey to be beneficial for visualization researchers whose interests involve making ML models more trustworthy, as well as researchers and practitioners from other disciplines in their search for effective visualization techniques suitable for solving their tasks with confidence and conveying meaning to their data.", "keywords": "trustworthy machine learning; visualization; interpretable machine learning; explainable machine learning", "link": "https://doi.org/10.1111/cgf.14034", "refList": ["10.1109/mcg.2018.2878902", "10.1109/tvcg.2008.153", "10.2312/mlvis.20181130", "10.1109/tvcg.2016.2598828", "10.1145/3290605.3300911", "10.1145/2993901.2993909", "10.2312/mlvis.20191158", "10.1109/tvcg.2016.2598446", "10.1111/j.1467-8659.2009.01475.x", "10.1145/3290605.3300809", "10.1109/pacificvis.2018.00031", "10.1055/s-0029-1216348", "10.1007/978-3-319-90403-0\\_13", "10.1109/tvcg.2017.2745085", "10.1111/j.1467-8659.2011.01938.x", "10.1007/978-3-319-54024-5\\_6", "10.1016/s0167-9473(01)00065-2", "10.1111/cgf.12895", "10.2312/eurovisshort.20141152.17", "10.2312/eurova.20151098.22", "10.1111/cgf.13667", "10.3115/1072228.1072378", "10.1109/tbdata.2018.2877350.16", "10.1109/lars.2009.5418323.25", "10.1109/tvcg.2017.2744878", "10.1016/j.combustflame.2005.09.018", "10.1016/j.cag.2014.01.006", "10.1109/tvcg.2016.2570755", "10.2312/mlvis.20191158.1,19", "10.1518/hfes.46.1.50.30392", "10.1145/3301275.3302280", "10.1145/3351095.3372834.1", "10.1016/s0377-2217(01)00264-8", "10.1111/cgf.13424", "10.1007/978-3-319-23485-4\\_53", "10.1007/978-94-007-0753-5\\_3623", "10.1109/tvcg.2013.101", "10.1111/cgf.12884", "10.1111/j.1467-8659.2010.01835.x", "10.1021/ci9901338", "10.4230/lipics.itcs:2017", "10.1109/mis.2013.24", "10.1109/tvcg.2014.2346482", "10.1109/tvcg.2018.2865230", "10.1073/pnas.1807180116", "10.1109/dsaa.2018.00018", "10.1109/tvcg.2009.153", "10.3115/1219840.1219855", "10.1109/tvcg.2018.2864812", "10.1109/tvcg.2018.2872577", "10.2312/trvis.20191183", "10.1109/cvpr:2004.383", "10.1109/vast.2008.4677350", "10.1145/302979.303001", "10.1109/tvcg.2018.2864499", "10.1111/cgf.13672", "10.1109/tvcg.2014.2346626", "10.23915/distill.00010.18", "10.1109/tvcg.2017.2744805", "10.2312/mlvis:20191160.18", "10.23915/distill:00016", "10.1109/pacificvis.2016.7465260", "10.1111/cgf.13683", "10.23915/distill.00016.19", "10.1145/32906053.300803.22", "10.1109/tvcg.2014.2346574", "10.1177/1473871615600010", "10.1109/tvcg.2016.2598831", "10.1145/3230623", "10.1109/visual.2019.8933744", "10.1145/2993901.2993915", "10.1016/j.visinf.2017.01.006", "10.1145/2993901.2993914", "10.1109/tvcg.2014.2346984", "10.1109/5.726791", "10.23915/distill.00010", "10.1109/tvcg.2018.2864825", "10.2307/2394164", "10.1109/tvcg.2017.2744458", "10.1145/2993901.2993917.28", "10.1111/cgf.13711", "10.1109/tvcg.2016.2598664", "10.2307/2530428", "10.1109/icdar.1997.620583", "10.1109/tvcg.2017.2744718", "10.1111/cgf.13425", "10.1109/tvcg.2019.2903943", "10.1145/1518701.1518895", "10.1109/tvcg.2018.2864838", "10.1145/62038.62043", "10.1111/j.1467-8659.2011.01920.x", "10.1145/3025171.3025208", "10.1145/355112.355124", "10.1109/vast.2010.5652398", "10.1109/tvcg.2014.2346578", "10.1145/3173574.3174209", "10.4178/epih/e2014008", "10.1109/beliv.2018.8634201.25,28", "10.1016/j.eswa.2007.12.020", "10.1111/cgf:13406", "10.1109/mcg.2011.103", "10.1631/fitee.1700808", "10.1109/tvcg.2017.2745158", "10.1073/pnas.0307752101", "10.1109/tvcg.2018.2816223", "10.1109/tvcg.2017.2745141", "10.1145/32232.32234", "10.1109/tvcg.2019.2934267", "10.1109/tvcg.2018.2864477", "10.1145/3132169", "10.2312/eurova.20151100.19", "10.1145/3172944.3172964", "10.1145/2601248.2601268", "10.1109/isai-nlp.2018.8693002.1", "10.1111/cgf.13404", "10.1007/s100320200071", "10.2312/trvis.20191183.16", "10.1111/cgf.12755", "10.1145/2702123.2702509", "10.1145/1401890.1402008.25", "10.1109/tvcg.2012.65", "10.1177/1473871617733996", "10.2312/trvis.20191187.7", "10.21236/ada273556", "10.1109/vast.2010.5652450", "10.1111/j.1467-8659.2011.01940.x", "10.1177/875647939000600106", "10.1109/tvcg.2017.2711030", "10.1016/j.immuni.2016.04.014", "10.1109/tvcg.2019.2934209", "10.1016/0095-0696(78)90006-2", "10.1016/j.jclinepi.2015.04.014", "10.1016/j.ress.2013.02.013", "10.1111/cgf.12640", "10.1145/1015330.1015388.25", "10.1111/j.1467-8659.2009.01468.x", "10.1145/1541880.1541882", "10.1109/vast.2011.6102453", "10.1016/s0008-8846(98)00165-3", "10.2312/trvis.20191186.7", "10.1007/s13748-013-0040-3", "10.1109/tvcg.2015.2467757", "10.1109/tbdata.2018.2877350", "10.1109/vast.2017.8585613", "10.1080/10556789208805504", "10.1109/vast.2012.6400484", "10.1145/3025171.3025181", "10.1007/978-3-319-90403-0\\_12", "10.1109/mcg.2019.2922592", "10.1021/ci000392t", "10.1109/vast.2007.4389000", "10.1111/cgf.13406.16", "10.1111/cgf.13684", "10.2312/eurovisshort.20161166.17", "10.2312/evs:20191168", "10.1145/3041021.3055135", "10.1145/3301275.3302265", "10.1613/jair.4135", "10.1109/tvcg.2018.2864500", "10.1109/tvcg.2017.2744158", "10.1109/ssci.2015.33", "10.1111/cgf.13453", "10.2312/pe/eurovast/eurova11/049-052", "10.1145/3025171.3025181.13", "10.1145/371920.372094", "10.1109/tvcg.2017.2744938", "10.1111/j.1467-8659.2012.03108.x", "10.1109/tvcg.2019.2934251", "10.1145/3290605.3300809.18", "10.1109/ldav.2016.7874305", "10.1109/vast.2016.7883514", "10.1109/iccv.2015.425", "10.1145/3301275.3302324", "10.1109/tnnls.2013.2292894", "10.1109/tvcg.2018.2865044", "10.1109/tvcg.2013.157", "10.1371/journal.pcbi.0020161", "10.1186/s12916-019-1426-2", "10.1109/10.867928", "10.1111/cgf.13217", "10.1109/mcg.2019.2919033", "10.1145/2993901.2993910", "10.1109/tvcg.2017.2744738", "10.2307/258792", "10.1111/cgf.12655", "10.1016/j.dss.2014.03.001", "10.1109/tvcg.2019.2904069", "10.1111/cgf.13205", "10.1002/mds.22340", "10.1109/tvcg.2019.2934595", "10.1287/inte.2018.0957", "10.1109/cvpr.2007.382974", "10.1109/tvcg.2012.280", "10.1145/2678025.2701399.13", "10.2312/mlvis.20181130.13", "10.2312/eurova.20181106.16", "10.1109/tvcg.2018.2864475", "10.2312/mlvis.20191160.18,22", "10.1007/978-1-4612-4026-6.25", "10.1109/cvpr.2006.42", "10.1145/3172944.3172950", "10.1109/cvpr.2004.383.25", "10.1109/tvcg.2019.2934812", "10.1609/aimag.v35i4.2513", "10.2312/trvis.20191185.7", "10.1111/j.1467-8659.2009.01684.x", "10.1371/journal.pone.0129126", "10.1111/cgf.13092", "10.1162/coli\\_a\\_00237", "10.1109/tvcg.2017.2744818", "10.1109/vast.2011.6102448", "10.1109/tvcg.2009.111", "10.1109/tvcg.2019.2934619", "10.1016/s0377-2217(01)00264-8.25", "10.1111/cgf.12639", "10.1109/access.2019.2919343", "10.1186/s12874-019-0681-4", "10.1109/pacificvis.2015.7156366", "10.1109/pacificvis.2018.00029", "10.1109/tvcg.2019.2934261", "10.1080/13506280444000102.http://www.uvt.nl/ticc", "10.1109/vast.2018.8802509", "10.1111/cgf.13212", "10.1145/3200489", "10.1111/cgf.13176", "10.1177/1473871620904671", "10.1007/978-3-319-10590-1\\_53", "10.1111/j.1467-8659.2012.03126.x", "10.1111/cgf.13172", "10.1145/3025171.3025208.6,21", "10.1111/cgf.12366", "10.1109/tvcg.2019.2934659", "10.1109/cvprw.2009.5206848", "10.1016/j.media.2014.11.010", "10.1109/tvcg.2017.2744683", "10.1109/tvcg.2019.2934262", "10.1016/j.neucom.2006.11.018", "10.1177/1473871615571951", "10.1371/journal.pcbi.0020161.25", "10.1177/1473871611415994", "10.2312/trvis20191187", "10.2312/eurova", "10.1145/2858036.2858529", "10.1145/2207676.2207738", "10.1007/s11042-009-0417-2", "10.1145/3301275.3302317", "10.1038/s41746-019-0148-3", "10.1145/3351095.3372834", "10.1080/10691898.2011.11889627", "10.1109/tvcg.2018.2864504", "10.1109/vast.2017.8585720", "10.1109/mcg.2018.053491732", "10.1007/s10994-010-5207-6", "10.1109/tvcg.2019.2934433", "10.1016/j.cag.2017.05.005", "10.1109/tvcg.2012.279", "10.1145/3231622.3231641.19,20", "10.1145/1562849.1562851", "10.1007/11564126\\_", "10.1109/tvcg.2018.2846735", "10.3115/1225403.1225421", "10.1109/vast.2012.6400486", "10.2312/eurova.20191116.22", "10.1109/tvcg.2007.70443", "10.1080/027868291009242", "10.2312/eurova.20151100", "10.1145/2939502.2939503.19", "10.1016/j.cag.2014.02.004", "10.1145/2939672.2939778", "10.1109/vast.2010.5652484", "10.1111/cgf.12641", "10.1145/3301275.3302289", "10.1109/visual.2019.8933619", "10.1109/tvcg.2017.2672987", "10.1109/vast.2016.7883517.20", "10.1109/igarss.2017.8127684", "10.1016/j.jcae.2010.04.002", "10.1109/vast.2010.5652885", "10.1016/j.visinf.2019.03.002", "10.1007/s00371-018-1500-3", "10.1109/mcg.2018.042731661", "10.1109/34.598228", "10.1109/tvcg.2018.2865027", "10.1016/j.neucom.2017.01.105", "10.1111/cgf.12389", "10.1109/tvcg.2019.2934591", "10.1109/vast.2010.5652392.16", "10.1111/cgf.13416", "10.1080/02701367.1992.10608764", "10.1109/vast.2017.8585721", "10.1109/tvcg.2018.2843369", "10.1109/sbes.2010.27", "10.1109/vast.2015.7347637", "10.1145/1401890.1402008", "10.1016/j.bpj.2010.04.064", "10.1109/tvcg.2013.125", "10.1109/isai-nlp.2018.8693002", "10.1371/journal.pone.0160127", "10.1145/2856767.2856779", "10.1145/2678025.2701399", "10.1109/vast.2011.6102451", "10.1109/mcg.2010.18", "10.1021/ci4000213", "10.1109/vast.2012.6400492", "10.1007/11564126-49.25", "10.2312/eurova.20171114", "10.1109/vast.2010.5652443", "10.1145/3134599", "10.2312/pe/eurovast/eurovast10/013-018.19", "10.1109/tvcg.2019.2903946", "10.1109/tvcg.2015.2467717", "10.1177/1473871612460526", "10.1016/j.cag.2018.09.018", "10.1109/tvcg.2016.2598838", "10.1145/3172944.3172964.14", "10.1109/vast.2009.5333428", "10.1109/vast.2014.7042480", "10.2312/pe/eurovast/eurovast10/013-018", "10.1177/0962280215588241", "10.1145/2993901.2993917", "10.1109/cvpr.2008:4587581", "10.1109/tvcg.2015.2467551", "10.1016/j.visinf.2018.09.001", "10.1126/science.290.5500.2319", "10.2312/eurova.20151107", "10.1109/visual.2019.8933695", "10.13140/2.1.2393.1847", "10.1197/jamia.m1929", "10.1109/cvpr.2008.4587581.25", "10.1145/1518701.1518895.16", "10.1109/vds.2017.8573444", "10.2312/trvis:20191185", "10.1145/3359786", "10.13140/2.1.1341.1520", "10.2312/pe/eurovast/eurova11/049-052.17", "10.1109/tvcg.2014.2346660", "10.1145/3185517", "10.1109/adprl.2011.5967372", "10.1109/tvcg.2015.2467591", "10.1111/j.1751-9004.2009.00232.x", "10.1136/qshc.2004.010033", "10.1109/vast.2012.6400493", "10.1109/tvcg.2019.2934266", "10.1145/2971763.2971775", "10.1111/cgf.13730", "10.1109/vast.2012.6400488", "10.1111/cgf.13210", "10.1109/tvcg.2019.2934631", "10.1145/3172944.3172965", "10.1057/ivs.2010.2", "10.1109/tvcg.2017.2745258", "10.1016/j.jbusres.2019.07.039", "10.1162/jmlr.2003.3.4-5.993", "10.1109/pacificvis.2019.00044", "10.2312/pe/eurovast/eurova12/037-041", "10.1109/tvcg.2019.2934629", "10.1177/0018720814547570", "10.1145/3292500.3330908", "10.1111/j.1467-8659.2009.01467.x", "10.2312/eurova.20151098", "10.1177/1473871617713337", "10.1109/lars:2009.5418323", "10.1109/vast.2011.6102437", "10.1111/cgf.12878", "10.1561/1500000001", "10.1145/3025171.3025222", "10.1007/s11704-016-6028-y", "10.1016/j.procs.2017.05.216", "10.1109/cvpr.2007.382974.25", "10.1080/10447318.2020.1741118", "10.1109/vast.2012.6400489", "10.1145/3025171.3025172", "10.1109/tvcg.2017.2744098", "10.1109/tvcg.2005.66", "10.1016/j.dss.2009.05.016", "10.1007/978-1-4612-4026-6", "10.2312/evs.20191168.16,20,28", "10.2312/pe/eurovast/eurova12/037-041.17", "10.1145/3290605.3300803", "10.1145/1015330.1015388", "10.1111/cgf.13197", "10.1016/b978-1-55860-377-6.50048-7", "10.1111/cgf.13681", "10.1109/tvcg.2017.2744378", "10.1109/tvcg.2017.2744358", "10.1109/vast.2008.4677352"], "wos": 1, "children": [{"doi": "10.1109/tvcg.2020.3030368", "title": "Implicit Multidimensional Projection of Local Subspaces", "year": "2020", "conferenceName": "InfoVis", "authors": "Rongzheng Bian;Yumeng Xue;Liang Zhou;Jian Zhang 0070;Baoquan Chen;Daniel Weiskopf;Yunhai Wang", "citationCount": "1", "affiliation": "Wang, YH (Corresponding Author), Shandong Univ, Qingdao, Peoples R China. Zhou, L (Corresponding Author), Univ Utah, Salt Lake City, UT 84112 USA. Bian, Rongzheng; Xue, Yumeng; Wang, Yunhai, Shandong Univ, Qingdao, Peoples R China. Chen, Baoquan, Peking Univ, Beijing, Peoples R China. Zhang, Jian, Chinese Acad Sci, CNIC, Beijing, Peoples R China. Zhou, Liang, Univ Utah, Salt Lake City, UT 84112 USA. Weiskopf, Daniel, Univ Stuttgart, Stuttgart, Germany.", "countries": "USA;Germany;China", "abstract": "We propose a visualization method to understand the effect of multidimensional projection on local subspaces, using implicit function differentiation. Here, we understand the local subspace as the multidimensional local neighborhood of data points. Existing methods focus on the projection of multidimensional data points, and the neighborhood information is ignored. Our method is able to analyze the shape and directional information of the local subspace to gain more insights into the global structure of the data through the perception of local structures. Local subspaces are fitted by multidimensional ellipses that are spanned by basis vectors. An accurate and efficient vector transformation method is proposed based on analytical differentiation of multidimensional projections formulated as implicit functions. The results are visualized as glyphs and analyzed using a full set of specifically-designed interactions supported in our efficient web-based visualization tool. The usefulness of our method is demonstrated using various multi- and high-dimensional benchmark datasets. Our implicit differentiation vector transformation is evaluated through numerical comparisons; the overall method is evaluated through exploration examples and use cases.", "keywords": "High-dimensional data visualization,dimensionality reduction,local linear subspaces,user interaction", "link": "http://dx.doi.org/10.1109/TVCG.2020.3030368", "refList": ["10.3844/jcssp.2018.613.622", "10.1016/j.aci.2018.08.003", "10.3390/info9030065", "10.1016/j.visinf.2018.09.003", "10.1371/journal.pone.0118432", "10.1016/s0893-6080(05)80023-1", "10.1109/tvcg.2020.2986996", "10.1109/icst.2012.56", "10.1007/s10844-013-0250-y", "10.1109/tbdata.2018", "10.1145/1125451.1125659", "10.1109/tvcg.2013.125", "10.1177/1473871611412817", "10.1145/3290605.3300911", "10.1111/cgf.14034", "10.1007/s13721-013-0034-x", "10.1016/j.procs.2017.05.216", "10.1016/j.ins.2009.08.025", "10.1109/tvcg.2013.124", "10.1109/tvcg.2018.2864499", "10.1109/tvcg.2018.2864475", "10.1080/10447318.2020.1741118", "10.1016/j.imu.2019.100203", "10.1109/tvcg.2018.2865240", "10.1186/s12864-019-6413-7", "10.1109/tvcg.2015.2467551", "10.1002/widm.1249", "10.1007/978-3-319-66429-3\\_29", "10.1109/tvcg.2014.2346481", "10.1109/tvcg.2018.2864825", "10.1177/1473871620904671", "10.1109/tvcg.2019.2934267", "10.1136/bmjopen-2016-012799", "10.1109/smartgridcomm.2017.8340682", "10.1007/s10664-015-9401-9", "10.1145/1143844.1143874", "10.1111/cgf.12389", "10.1109/tvcg.2018.2872577", "10.1007/978-981-13-5802-9\\_20", "10.1016/j.ipm.2009.03.002", "10.5220/0006431602160222", "10.1109/mcg.2015.50", "10.1109/tvcg.2014.2346574", "10.1007/bf02289565", "10.1109/tvcg.2017.2744378", "10.1016/j.patrec.2008.08.010", "10.1023/a:1010933404324", "10.9735/2229-3981"], "wos": 1, "children": [], "len": 1}, {"doi": "10.1109/tvcg.2020.3030465", "title": "Visual Causality Analysis of Event Sequence Data", "year": "2020", "conferenceName": "VAST", "authors": "Zhuochen Jin;Shunan Guo;Nan Chen;Daniel Weiskopf;David Gotz;Nan Cao", "citationCount": "0", "affiliation": "Cao, N (Corresponding Author), Tongji Univ, IDVx Lab, Shanghai, Peoples R China. Jin, Zhuochen; Guo, Shunan; Chen, Nan; Cao, Nan, Tongji Univ, IDVx Lab, Shanghai, Peoples R China. Weiskopf, Daniel, Univ Stuttgart, Stuttgart, Germany. Gotz, David, Univ N Carolina, Chapel Hill, NC 27515 USA.", "countries": "USA;Germany;China", "abstract": "Causality is crucial to understanding the mechanisms behind complex systems and making decisions that lead to intended outcomes. Event sequence data is widely collected from many real-world processes, such as electronic health records, web clickstreams, and financial transactions, which transmit a great deal of information reflecting the causal relations among event types. Unfortunately, recovering causalities from observational event sequences is challenging, as the heterogeneous and high-dimensional event variables are often connected to rather complex underlying event excitation mechanisms that are hard to infer from limited observations. Many existing automated causal analysis techniques suffer from poor explainability and fail to include an adequate amount of human knowledge. In this paper, we introduce a visual analytics method for recovering causalities in event sequence data. We extend the Granger causality analysis algorithm on Hawkes processes to incorporate user feedback into causal model refinement. The visualization system includes an interactive causal analysis framework that supports bottom-up causal exploration, iterative causal verification and refinement, and causal comparison through a set of novel visualizations and interactions. We report two forms of evaluation: a quantitative evaluation of the model improvements resulting from the user-feedback mechanism, and a qualitative evaluation through case studies in different application domains to demonstrate the usefulness of the system.", "keywords": "Event sequence data,causality analysis,visual analytics", "link": "http://dx.doi.org/10.1109/TVCG.2020.3030465", "refList": ["10.5555/1642718", "10.1109/tvcg.2018.2865022", "10.5555/2074094.2074151", "10.1109/tvcg.2016.2618797", "10.1073/pnas.1320645111", "10.1109/tvcg.2017.2744843", "10.1109/iv.2017.69", "10.1109/tvcg.2019.2934399", "10.1145/3172944.3173007", "10.5555/1795555", "10.1109/mcg.2005.102", "10.1145/381641.381653", "10.1162/153244301753344614", "10.1111/cgf.14034", "10.1111/cgf.13198", "10.1017/cbo9780511519857", "10.1007/s10462-016-9475-9", "10.1075/ssol.2.2.07bor", "10.1007/978-1-4614-3223-4\\_3", "10.1109/infvis.2003.1249025", "10.1007/978-94-007-6094-313", "10.1145/2858036.2858387", "10.1109/tvcg.2007.70528", "10.1109/tvcg.2017.2674958", "10.1147/sj.454.0801", "10.1109/tvcg.2013.119", "10.1145/3173574.3173711", "10.1016/j.erss.2017.06.034", "10.1109/visual.2019.8933695", "10.1007/s11665-016-2173-6", "10.1016/0377-0427(87)90125-7", "10.2307/3601125", "10.1016/b978-0-444-88738-2.50018-x", "10.1109/mcg.2006.70", "10.1109/tvcg.2018.2865145", "10.1017/s1351324997001502", "10.1109/tvcg.2010.179", "10.1214/aos/1176344552", "10.1109/mcg.2009.22", "10.1007/978-3-319-26633-6\\_13", "10.1080/10447318.2014.905422", "10.1016/j.visinf.2019.03.004", "10.1057/palgrave.ivs.9500074", "10.1007/978-1-4614-3223-4"], "wos": 1, "children": [], "len": 1}], "len": 5}], "len": 71}, {"doi": "10.1111/cgf.13212", "year": "2017", "title": "Survey of Surveys (SoS) - Mapping The Landscape of Survey Papers in Information Visualization", "conferenceName": "EuroVis", "authors": "Liam McNabb;Robert S. Laramee", "citationCount": "18", "affiliation": "McNabb, L (Corresponding Author), Swansea Univ, Dept Comp Sci, Swansea, W Glam, Wales.\nMcNabb, Liam; Laramee, Robert S., Swansea Univ, Dept Comp Sci, Swansea, W Glam, Wales.", "countries": "Wales", "abstract": "Information visualization as a field is growing rapidly in popularity since the first information visualization conference in 1995. However, as a consequence of its growth, it is increasingly difficult to follow the growing body of literature within the field. Survey papers and literature reviews are valuable tools for managing the great volume of previously published research papers, and the quantity of survey papers in visualization has reached a critical mass. To this end, this survey paper takes a quantum step forward by surveying and classifying literature survey papers in order to help researchers understand the current landscape of Information Visualization. It is, to our knowledge, the first survey of survey papers (SoS) in Information Visualization. This paper classifies survey papers into natural topic clusters which enables readers to find relevant literature and develops the first classification of classifications. The paper also enables researchers to identify both mature and less developed research directions as well as identify future directions. It is a valuable resource for both newcomers and experienced researchers in and outside the field of Information Visualization and Visual Analytics.", "keywords": "", "link": "https://doi.org/10.1111/cgf.13212", "refList": ["10.2312/eurovisstar.20151110", "10.1109/tvcg.2013.126", "10.1111/cgf.12932", "10.1006/jvlc.1993.1015", "10.1109/iv.2010.21", "10.2312/conf/eg2013/stars/039-063", "10.1111/cgf.12935", "10.1109/2945.981847", "10.1109/tits.2015.2436897", "10.1109/tits.2016.2530146", "10.1109/tvcg.2003.1207445", "10.1109/vissof.2007.4290693", "10.1016/s1386-5056(02)00072-2", "10.1109/tvcg.2009.23", "10.3145/epi.2014.may.02", "10.1007/s003710050111", "10.1111/cgf.12931", "10.1109/tvcg.2011.229", "10.1109/pacificvis.2015.7156366", "10.1007/978-1-4471-2804-5\\_6", "10.1016/j.cag.2012.07.006", "10.1109/tvcg.2010.79", "10.1109/tvcg.2011.144", "10.1109/tvcg.2013.238", "10.1109/38.708564", "10.1145/2994310.2994327", "10.1145/2543581.2543589", "10.1109/vast.2012.6400554", "10.1080/10447310701702402", "10.1109/tvcg.2014.2346665", "10.1002/widm.1071", "10.2312/eurovisstar.20151114", "10.1109/tvcg.2015.2466992", "10.1111/cgf.12936", "10.1109/tst.2013.6509098", "10.1016/j.ijhcs.2013.08.004", "10.1109/infvis.2000.885092", "10.1177/1473871611416549", "10.2312/conf/eg2013/stars/095-116", "10.2312/eurovisstar.20141170", "10.1111/j.1467-8659.2012.03094.x", "10.1109/tvcg.2015.2424889", "10.1016/j.jfs.2016.01.006", "10.1109/tvcg.2013.124", "10.1111/j.1467-8659.2012.03125.x", "10.2312/eurovisstar.20151109", "10.1109/tvcg.2011.279", "10.1109/tvcg.2009.84", "10.1111/j.1467-8659.2012.03184.x", "10.1057/palgrave.ivs.9500182", "10.2200/s00685ed1v01y201512vis005", "10.1145/22627.22349", "10.2312/eurovisshort.20141149", "10.1109/tvcg.2013.120", "10.1109/tvcg.2016.2615308", "10.1007/s11390-016-1663-1", "10.1007/s00371-013-0892-3", "10.1109/vast.2012.6400552", "10.1111/j.1467-8659.2011.01898.x", "10.2312/pe.eurovisshort.eurovisshort2013.019-023", "10.1080/10618600.1996.10474696", "10.1007/s11704-016-6028-y", "10.1109/cmv.2007.20", "10.1007/s11390-013-1383-8", "10.1109/2945.841119", "10.1002/wics.1285", "10.1057/ivs.2008.31", "10.1145/2993901.2993906", "10.1109/tvcg.2007.70535", "10.1177/1473871611424815", "10.1016/j.soncn.2011.02.001", "10.1111/j.1467-8306.2004.09401004.x", "10.1145/180171.180173", "10.1006/s1045-926x(02)00028-9", "10.1109/pacificvis.2012.6183556", "10.1136/amiajnl-2014-002955", "10.1109/tvcg.2013.153", "10.1016/s1045-926x(05)80036-9", "10.1109/tvcg.2010.110", "10.1561/1100000039", "10.1145/22339.22349", "10.2312/eurovisstar.20151113"], "wos": 1, "children": [{"doi": "10.1111/cgf.14034", "year": "2020", "title": "The State of the Art in Enhancing Trust in Machine Learning Models with the Use of Visualizations", "conferenceName": "EuroVis", "authors": "Angelos Chatzimparmpas;Rafael Messias Martins;Ilir Jusufi;Kostiantyn Kucher;Fabrice Rossi;Andreas Kerren", "citationCount": "2", "affiliation": "Chatzimparmpas, A (Corresponding Author), Linnaeus Univ, Dept Comp Sci \\& Media Technol, Vaxjo, Sweden.\nChatzimparmpas, A.; Martins, R. M.; Jusufi, I.; Kucher, K.; Kerren, A., Linnaeus Univ, Dept Comp Sci \\& Media Technol, Vaxjo, Sweden.\nRossi, F., PSL Univ, Univ Paris Dauphine, Ceremade, Paris, France.", "countries": "Sweden;France", "abstract": "Machine learning (ML) models are nowadays used in complex applications in various domains, such as medicine, bioinformatics, and other sciences. Due to their black box nature, however, it may sometimes be hard to understand and trust the results they provide. This has increased the demand for reliable visualization tools related to enhancing trust in ML models, which has become a prominent topic of research in the visualization community over the past decades. To provide an overview and present the frontiers of current research on the topic, we present a State-of-the-Art Report (STAR) on enhancing trust in ML models with the use of interactive visualization. We define and describe the background of the topic, introduce a categorization for visualization techniques that aim to accomplish this goal, and discuss insights and opportunities for future research directions. Among our contributions is a categorization of trust against different facets of interactive ML, expanded and improved from previous research. Our results are investigated from different analytical perspectives: (a) providing a statistical overview, (b) summarizing key findings, (c) performing topic analyses, and (d) exploring the data sets used in the individual papers, all with the support of an interactive web-based survey browser. We intend this survey to be beneficial for visualization researchers whose interests involve making ML models more trustworthy, as well as researchers and practitioners from other disciplines in their search for effective visualization techniques suitable for solving their tasks with confidence and conveying meaning to their data.", "keywords": "trustworthy machine learning; visualization; interpretable machine learning; explainable machine learning", "link": "https://doi.org/10.1111/cgf.14034", "refList": ["10.1109/mcg.2018.2878902", "10.1109/tvcg.2008.153", "10.2312/mlvis.20181130", "10.1109/tvcg.2016.2598828", "10.1145/3290605.3300911", "10.1145/2993901.2993909", "10.2312/mlvis.20191158", "10.1109/tvcg.2016.2598446", "10.1111/j.1467-8659.2009.01475.x", "10.1145/3290605.3300809", "10.1109/pacificvis.2018.00031", "10.1055/s-0029-1216348", "10.1007/978-3-319-90403-0\\_13", "10.1109/tvcg.2017.2745085", "10.1111/j.1467-8659.2011.01938.x", "10.1007/978-3-319-54024-5\\_6", "10.1016/s0167-9473(01)00065-2", "10.1111/cgf.12895", "10.2312/eurovisshort.20141152.17", "10.2312/eurova.20151098.22", "10.1111/cgf.13667", "10.3115/1072228.1072378", "10.1109/tbdata.2018.2877350.16", "10.1109/lars.2009.5418323.25", "10.1109/tvcg.2017.2744878", "10.1016/j.combustflame.2005.09.018", "10.1016/j.cag.2014.01.006", "10.1109/tvcg.2016.2570755", "10.2312/mlvis.20191158.1,19", "10.1518/hfes.46.1.50.30392", "10.1145/3301275.3302280", "10.1145/3351095.3372834.1", "10.1016/s0377-2217(01)00264-8", "10.1111/cgf.13424", "10.1007/978-3-319-23485-4\\_53", "10.1007/978-94-007-0753-5\\_3623", "10.1109/tvcg.2013.101", "10.1111/cgf.12884", "10.1111/j.1467-8659.2010.01835.x", "10.1021/ci9901338", "10.4230/lipics.itcs:2017", "10.1109/mis.2013.24", "10.1109/tvcg.2014.2346482", "10.1109/tvcg.2018.2865230", "10.1073/pnas.1807180116", "10.1109/dsaa.2018.00018", "10.1109/tvcg.2009.153", "10.3115/1219840.1219855", "10.1109/tvcg.2018.2864812", "10.1109/tvcg.2018.2872577", "10.2312/trvis.20191183", "10.1109/cvpr:2004.383", "10.1109/vast.2008.4677350", "10.1145/302979.303001", "10.1109/tvcg.2018.2864499", "10.1111/cgf.13672", "10.1109/tvcg.2014.2346626", "10.23915/distill.00010.18", "10.1109/tvcg.2017.2744805", "10.2312/mlvis:20191160.18", "10.23915/distill:00016", "10.1109/pacificvis.2016.7465260", "10.1111/cgf.13683", "10.23915/distill.00016.19", "10.1145/32906053.300803.22", "10.1109/tvcg.2014.2346574", "10.1177/1473871615600010", "10.1109/tvcg.2016.2598831", "10.1145/3230623", "10.1109/visual.2019.8933744", "10.1145/2993901.2993915", "10.1016/j.visinf.2017.01.006", "10.1145/2993901.2993914", "10.1109/tvcg.2014.2346984", "10.1109/5.726791", "10.23915/distill.00010", "10.1109/tvcg.2018.2864825", "10.2307/2394164", "10.1109/tvcg.2017.2744458", "10.1145/2993901.2993917.28", "10.1111/cgf.13711", "10.1109/tvcg.2016.2598664", "10.2307/2530428", "10.1109/icdar.1997.620583", "10.1109/tvcg.2017.2744718", "10.1111/cgf.13425", "10.1109/tvcg.2019.2903943", "10.1145/1518701.1518895", "10.1109/tvcg.2018.2864838", "10.1145/62038.62043", "10.1111/j.1467-8659.2011.01920.x", "10.1145/3025171.3025208", "10.1145/355112.355124", "10.1109/vast.2010.5652398", "10.1109/tvcg.2014.2346578", "10.1145/3173574.3174209", "10.4178/epih/e2014008", "10.1109/beliv.2018.8634201.25,28", "10.1016/j.eswa.2007.12.020", "10.1111/cgf:13406", "10.1109/mcg.2011.103", "10.1631/fitee.1700808", "10.1109/tvcg.2017.2745158", "10.1073/pnas.0307752101", "10.1109/tvcg.2018.2816223", "10.1109/tvcg.2017.2745141", "10.1145/32232.32234", "10.1109/tvcg.2019.2934267", "10.1109/tvcg.2018.2864477", "10.1145/3132169", "10.2312/eurova.20151100.19", "10.1145/3172944.3172964", "10.1145/2601248.2601268", "10.1109/isai-nlp.2018.8693002.1", "10.1111/cgf.13404", "10.1007/s100320200071", "10.2312/trvis.20191183.16", "10.1111/cgf.12755", "10.1145/2702123.2702509", "10.1145/1401890.1402008.25", "10.1109/tvcg.2012.65", "10.1177/1473871617733996", "10.2312/trvis.20191187.7", "10.21236/ada273556", "10.1109/vast.2010.5652450", "10.1111/j.1467-8659.2011.01940.x", "10.1177/875647939000600106", "10.1109/tvcg.2017.2711030", "10.1016/j.immuni.2016.04.014", "10.1109/tvcg.2019.2934209", "10.1016/0095-0696(78)90006-2", "10.1016/j.jclinepi.2015.04.014", "10.1016/j.ress.2013.02.013", "10.1111/cgf.12640", "10.1145/1015330.1015388.25", "10.1111/j.1467-8659.2009.01468.x", "10.1145/1541880.1541882", "10.1109/vast.2011.6102453", "10.1016/s0008-8846(98)00165-3", "10.2312/trvis.20191186.7", "10.1007/s13748-013-0040-3", "10.1109/tvcg.2015.2467757", "10.1109/tbdata.2018.2877350", "10.1109/vast.2017.8585613", "10.1080/10556789208805504", "10.1109/vast.2012.6400484", "10.1145/3025171.3025181", "10.1007/978-3-319-90403-0\\_12", "10.1109/mcg.2019.2922592", "10.1021/ci000392t", "10.1109/vast.2007.4389000", "10.1111/cgf.13406.16", "10.1111/cgf.13684", "10.2312/eurovisshort.20161166.17", "10.2312/evs:20191168", "10.1145/3041021.3055135", "10.1145/3301275.3302265", "10.1613/jair.4135", "10.1109/tvcg.2018.2864500", "10.1109/tvcg.2017.2744158", "10.1109/ssci.2015.33", "10.1111/cgf.13453", "10.2312/pe/eurovast/eurova11/049-052", "10.1145/3025171.3025181.13", "10.1145/371920.372094", "10.1109/tvcg.2017.2744938", "10.1111/j.1467-8659.2012.03108.x", "10.1109/tvcg.2019.2934251", "10.1145/3290605.3300809.18", "10.1109/ldav.2016.7874305", "10.1109/vast.2016.7883514", "10.1109/iccv.2015.425", "10.1145/3301275.3302324", "10.1109/tnnls.2013.2292894", "10.1109/tvcg.2018.2865044", "10.1109/tvcg.2013.157", "10.1371/journal.pcbi.0020161", "10.1186/s12916-019-1426-2", "10.1109/10.867928", "10.1111/cgf.13217", "10.1109/mcg.2019.2919033", "10.1145/2993901.2993910", "10.1109/tvcg.2017.2744738", "10.2307/258792", "10.1111/cgf.12655", "10.1016/j.dss.2014.03.001", "10.1109/tvcg.2019.2904069", "10.1111/cgf.13205", "10.1002/mds.22340", "10.1109/tvcg.2019.2934595", "10.1287/inte.2018.0957", "10.1109/cvpr.2007.382974", "10.1109/tvcg.2012.280", "10.1145/2678025.2701399.13", "10.2312/mlvis.20181130.13", "10.2312/eurova.20181106.16", "10.1109/tvcg.2018.2864475", "10.2312/mlvis.20191160.18,22", "10.1007/978-1-4612-4026-6.25", "10.1109/cvpr.2006.42", "10.1145/3172944.3172950", "10.1109/cvpr.2004.383.25", "10.1109/tvcg.2019.2934812", "10.1609/aimag.v35i4.2513", "10.2312/trvis.20191185.7", "10.1111/j.1467-8659.2009.01684.x", "10.1371/journal.pone.0129126", "10.1111/cgf.13092", "10.1162/coli\\_a\\_00237", "10.1109/tvcg.2017.2744818", "10.1109/vast.2011.6102448", "10.1109/tvcg.2009.111", "10.1109/tvcg.2019.2934619", "10.1016/s0377-2217(01)00264-8.25", "10.1111/cgf.12639", "10.1109/access.2019.2919343", "10.1186/s12874-019-0681-4", "10.1109/pacificvis.2015.7156366", "10.1109/pacificvis.2018.00029", "10.1109/tvcg.2019.2934261", "10.1080/13506280444000102.http://www.uvt.nl/ticc", "10.1109/vast.2018.8802509", "10.1111/cgf.13212", "10.1145/3200489", "10.1111/cgf.13176", "10.1177/1473871620904671", "10.1007/978-3-319-10590-1\\_53", "10.1111/j.1467-8659.2012.03126.x", "10.1111/cgf.13172", "10.1145/3025171.3025208.6,21", "10.1111/cgf.12366", "10.1109/tvcg.2019.2934659", "10.1109/cvprw.2009.5206848", "10.1016/j.media.2014.11.010", "10.1109/tvcg.2017.2744683", "10.1109/tvcg.2019.2934262", "10.1016/j.neucom.2006.11.018", "10.1177/1473871615571951", "10.1371/journal.pcbi.0020161.25", "10.1177/1473871611415994", "10.2312/trvis20191187", "10.2312/eurova", "10.1145/2858036.2858529", "10.1145/2207676.2207738", "10.1007/s11042-009-0417-2", "10.1145/3301275.3302317", "10.1038/s41746-019-0148-3", "10.1145/3351095.3372834", "10.1080/10691898.2011.11889627", "10.1109/tvcg.2018.2864504", "10.1109/vast.2017.8585720", "10.1109/mcg.2018.053491732", "10.1007/s10994-010-5207-6", "10.1109/tvcg.2019.2934433", "10.1016/j.cag.2017.05.005", "10.1109/tvcg.2012.279", "10.1145/3231622.3231641.19,20", "10.1145/1562849.1562851", "10.1007/11564126\\_", "10.1109/tvcg.2018.2846735", "10.3115/1225403.1225421", "10.1109/vast.2012.6400486", "10.2312/eurova.20191116.22", "10.1109/tvcg.2007.70443", "10.1080/027868291009242", "10.2312/eurova.20151100", "10.1145/2939502.2939503.19", "10.1016/j.cag.2014.02.004", "10.1145/2939672.2939778", "10.1109/vast.2010.5652484", "10.1111/cgf.12641", "10.1145/3301275.3302289", "10.1109/visual.2019.8933619", "10.1109/tvcg.2017.2672987", "10.1109/vast.2016.7883517.20", "10.1109/igarss.2017.8127684", "10.1016/j.jcae.2010.04.002", "10.1109/vast.2010.5652885", "10.1016/j.visinf.2019.03.002", "10.1007/s00371-018-1500-3", "10.1109/mcg.2018.042731661", "10.1109/34.598228", "10.1109/tvcg.2018.2865027", "10.1016/j.neucom.2017.01.105", "10.1111/cgf.12389", "10.1109/tvcg.2019.2934591", "10.1109/vast.2010.5652392.16", "10.1111/cgf.13416", "10.1080/02701367.1992.10608764", "10.1109/vast.2017.8585721", "10.1109/tvcg.2018.2843369", "10.1109/sbes.2010.27", "10.1109/vast.2015.7347637", "10.1145/1401890.1402008", "10.1016/j.bpj.2010.04.064", "10.1109/tvcg.2013.125", "10.1109/isai-nlp.2018.8693002", "10.1371/journal.pone.0160127", "10.1145/2856767.2856779", "10.1145/2678025.2701399", "10.1109/vast.2011.6102451", "10.1109/mcg.2010.18", "10.1021/ci4000213", "10.1109/vast.2012.6400492", "10.1007/11564126-49.25", "10.2312/eurova.20171114", "10.1109/vast.2010.5652443", "10.1145/3134599", "10.2312/pe/eurovast/eurovast10/013-018.19", "10.1109/tvcg.2019.2903946", "10.1109/tvcg.2015.2467717", "10.1177/1473871612460526", "10.1016/j.cag.2018.09.018", "10.1109/tvcg.2016.2598838", "10.1145/3172944.3172964.14", "10.1109/vast.2009.5333428", "10.1109/vast.2014.7042480", "10.2312/pe/eurovast/eurovast10/013-018", "10.1177/0962280215588241", "10.1145/2993901.2993917", "10.1109/cvpr.2008:4587581", "10.1109/tvcg.2015.2467551", "10.1016/j.visinf.2018.09.001", "10.1126/science.290.5500.2319", "10.2312/eurova.20151107", "10.1109/visual.2019.8933695", "10.13140/2.1.2393.1847", "10.1197/jamia.m1929", "10.1109/cvpr.2008.4587581.25", "10.1145/1518701.1518895.16", "10.1109/vds.2017.8573444", "10.2312/trvis:20191185", "10.1145/3359786", "10.13140/2.1.1341.1520", "10.2312/pe/eurovast/eurova11/049-052.17", "10.1109/tvcg.2014.2346660", "10.1145/3185517", "10.1109/adprl.2011.5967372", "10.1109/tvcg.2015.2467591", "10.1111/j.1751-9004.2009.00232.x", "10.1136/qshc.2004.010033", "10.1109/vast.2012.6400493", "10.1109/tvcg.2019.2934266", "10.1145/2971763.2971775", "10.1111/cgf.13730", "10.1109/vast.2012.6400488", "10.1111/cgf.13210", "10.1109/tvcg.2019.2934631", "10.1145/3172944.3172965", "10.1057/ivs.2010.2", "10.1109/tvcg.2017.2745258", "10.1016/j.jbusres.2019.07.039", "10.1162/jmlr.2003.3.4-5.993", "10.1109/pacificvis.2019.00044", "10.2312/pe/eurovast/eurova12/037-041", "10.1109/tvcg.2019.2934629", "10.1177/0018720814547570", "10.1145/3292500.3330908", "10.1111/j.1467-8659.2009.01467.x", "10.2312/eurova.20151098", "10.1177/1473871617713337", "10.1109/lars:2009.5418323", "10.1109/vast.2011.6102437", "10.1111/cgf.12878", "10.1561/1500000001", "10.1145/3025171.3025222", "10.1007/s11704-016-6028-y", "10.1016/j.procs.2017.05.216", "10.1109/cvpr.2007.382974.25", "10.1080/10447318.2020.1741118", "10.1109/vast.2012.6400489", "10.1145/3025171.3025172", "10.1109/tvcg.2017.2744098", "10.1109/tvcg.2005.66", "10.1016/j.dss.2009.05.016", "10.1007/978-1-4612-4026-6", "10.2312/evs.20191168.16,20,28", "10.2312/pe/eurovast/eurova12/037-041.17", "10.1145/3290605.3300803", "10.1145/1015330.1015388", "10.1111/cgf.13197", "10.1016/b978-1-55860-377-6.50048-7", "10.1111/cgf.13681", "10.1109/tvcg.2017.2744378", "10.1109/tvcg.2017.2744358", "10.1109/vast.2008.4677352"], "wos": 1, "children": [{"doi": "10.1109/tvcg.2020.3030368", "title": "Implicit Multidimensional Projection of Local Subspaces", "year": "2020", "conferenceName": "InfoVis", "authors": "Rongzheng Bian;Yumeng Xue;Liang Zhou;Jian Zhang 0070;Baoquan Chen;Daniel Weiskopf;Yunhai Wang", "citationCount": "1", "affiliation": "Wang, YH (Corresponding Author), Shandong Univ, Qingdao, Peoples R China. Zhou, L (Corresponding Author), Univ Utah, Salt Lake City, UT 84112 USA. Bian, Rongzheng; Xue, Yumeng; Wang, Yunhai, Shandong Univ, Qingdao, Peoples R China. Chen, Baoquan, Peking Univ, Beijing, Peoples R China. Zhang, Jian, Chinese Acad Sci, CNIC, Beijing, Peoples R China. Zhou, Liang, Univ Utah, Salt Lake City, UT 84112 USA. Weiskopf, Daniel, Univ Stuttgart, Stuttgart, Germany.", "countries": "USA;Germany;China", "abstract": "We propose a visualization method to understand the effect of multidimensional projection on local subspaces, using implicit function differentiation. Here, we understand the local subspace as the multidimensional local neighborhood of data points. Existing methods focus on the projection of multidimensional data points, and the neighborhood information is ignored. Our method is able to analyze the shape and directional information of the local subspace to gain more insights into the global structure of the data through the perception of local structures. Local subspaces are fitted by multidimensional ellipses that are spanned by basis vectors. An accurate and efficient vector transformation method is proposed based on analytical differentiation of multidimensional projections formulated as implicit functions. The results are visualized as glyphs and analyzed using a full set of specifically-designed interactions supported in our efficient web-based visualization tool. The usefulness of our method is demonstrated using various multi- and high-dimensional benchmark datasets. Our implicit differentiation vector transformation is evaluated through numerical comparisons; the overall method is evaluated through exploration examples and use cases.", "keywords": "High-dimensional data visualization,dimensionality reduction,local linear subspaces,user interaction", "link": "http://dx.doi.org/10.1109/TVCG.2020.3030368", "refList": ["10.3844/jcssp.2018.613.622", "10.1016/j.aci.2018.08.003", "10.3390/info9030065", "10.1016/j.visinf.2018.09.003", "10.1371/journal.pone.0118432", "10.1016/s0893-6080(05)80023-1", "10.1109/tvcg.2020.2986996", "10.1109/icst.2012.56", "10.1007/s10844-013-0250-y", "10.1109/tbdata.2018", "10.1145/1125451.1125659", "10.1109/tvcg.2013.125", "10.1177/1473871611412817", "10.1145/3290605.3300911", "10.1111/cgf.14034", "10.1007/s13721-013-0034-x", "10.1016/j.procs.2017.05.216", "10.1016/j.ins.2009.08.025", "10.1109/tvcg.2013.124", "10.1109/tvcg.2018.2864499", "10.1109/tvcg.2018.2864475", "10.1080/10447318.2020.1741118", "10.1016/j.imu.2019.100203", "10.1109/tvcg.2018.2865240", "10.1186/s12864-019-6413-7", "10.1109/tvcg.2015.2467551", "10.1002/widm.1249", "10.1007/978-3-319-66429-3\\_29", "10.1109/tvcg.2014.2346481", "10.1109/tvcg.2018.2864825", "10.1177/1473871620904671", "10.1109/tvcg.2019.2934267", "10.1136/bmjopen-2016-012799", "10.1109/smartgridcomm.2017.8340682", "10.1007/s10664-015-9401-9", "10.1145/1143844.1143874", "10.1111/cgf.12389", "10.1109/tvcg.2018.2872577", "10.1007/978-981-13-5802-9\\_20", "10.1016/j.ipm.2009.03.002", "10.5220/0006431602160222", "10.1109/mcg.2015.50", "10.1109/tvcg.2014.2346574", "10.1007/bf02289565", "10.1109/tvcg.2017.2744378", "10.1016/j.patrec.2008.08.010", "10.1023/a:1010933404324", "10.9735/2229-3981"], "wos": 1, "children": [], "len": 1}, {"doi": "10.1109/tvcg.2020.3030465", "title": "Visual Causality Analysis of Event Sequence Data", "year": "2020", "conferenceName": "VAST", "authors": "Zhuochen Jin;Shunan Guo;Nan Chen;Daniel Weiskopf;David Gotz;Nan Cao", "citationCount": "0", "affiliation": "Cao, N (Corresponding Author), Tongji Univ, IDVx Lab, Shanghai, Peoples R China. Jin, Zhuochen; Guo, Shunan; Chen, Nan; Cao, Nan, Tongji Univ, IDVx Lab, Shanghai, Peoples R China. Weiskopf, Daniel, Univ Stuttgart, Stuttgart, Germany. Gotz, David, Univ N Carolina, Chapel Hill, NC 27515 USA.", "countries": "USA;Germany;China", "abstract": "Causality is crucial to understanding the mechanisms behind complex systems and making decisions that lead to intended outcomes. Event sequence data is widely collected from many real-world processes, such as electronic health records, web clickstreams, and financial transactions, which transmit a great deal of information reflecting the causal relations among event types. Unfortunately, recovering causalities from observational event sequences is challenging, as the heterogeneous and high-dimensional event variables are often connected to rather complex underlying event excitation mechanisms that are hard to infer from limited observations. Many existing automated causal analysis techniques suffer from poor explainability and fail to include an adequate amount of human knowledge. In this paper, we introduce a visual analytics method for recovering causalities in event sequence data. We extend the Granger causality analysis algorithm on Hawkes processes to incorporate user feedback into causal model refinement. The visualization system includes an interactive causal analysis framework that supports bottom-up causal exploration, iterative causal verification and refinement, and causal comparison through a set of novel visualizations and interactions. We report two forms of evaluation: a quantitative evaluation of the model improvements resulting from the user-feedback mechanism, and a qualitative evaluation through case studies in different application domains to demonstrate the usefulness of the system.", "keywords": "Event sequence data,causality analysis,visual analytics", "link": "http://dx.doi.org/10.1109/TVCG.2020.3030465", "refList": ["10.5555/1642718", "10.1109/tvcg.2018.2865022", "10.5555/2074094.2074151", "10.1109/tvcg.2016.2618797", "10.1073/pnas.1320645111", "10.1109/tvcg.2017.2744843", "10.1109/iv.2017.69", "10.1109/tvcg.2019.2934399", "10.1145/3172944.3173007", "10.5555/1795555", "10.1109/mcg.2005.102", "10.1145/381641.381653", "10.1162/153244301753344614", "10.1111/cgf.14034", "10.1111/cgf.13198", "10.1017/cbo9780511519857", "10.1007/s10462-016-9475-9", "10.1075/ssol.2.2.07bor", "10.1007/978-1-4614-3223-4\\_3", "10.1109/infvis.2003.1249025", "10.1007/978-94-007-6094-313", "10.1145/2858036.2858387", "10.1109/tvcg.2007.70528", "10.1109/tvcg.2017.2674958", "10.1147/sj.454.0801", "10.1109/tvcg.2013.119", "10.1145/3173574.3173711", "10.1016/j.erss.2017.06.034", "10.1109/visual.2019.8933695", "10.1007/s11665-016-2173-6", "10.1016/0377-0427(87)90125-7", "10.2307/3601125", "10.1016/b978-0-444-88738-2.50018-x", "10.1109/mcg.2006.70", "10.1109/tvcg.2018.2865145", "10.1017/s1351324997001502", "10.1109/tvcg.2010.179", "10.1214/aos/1176344552", "10.1109/mcg.2009.22", "10.1007/978-3-319-26633-6\\_13", "10.1080/10447318.2014.905422", "10.1016/j.visinf.2019.03.004", "10.1057/palgrave.ivs.9500074", "10.1007/978-1-4614-3223-4"], "wos": 1, "children": [], "len": 1}], "len": 5}], "len": 7}], "len": 679}, "index": 84, "embedding": [-1.4562033414840698, 4.761749267578125, -1.030107021331787, -2.273205041885376, 1.829912543296814, 0.16650904715061188, -0.7323254346847534, 4.006412506103516, 11.978285789489746, 6.566682815551758, 4.600355625152588, 7.332823276519775, 12.545782089233398, -1.592404842376709, 6.115561008453369, -0.5232402086257935, 8.06509017944336, 0.07072390615940094, 5.590092658996582, 3.8539366722106934, -0.06630208343267441, -0.5897487998008728, 1.4503097534179688, 8.631973266601562, -2.405334949493408, 12.966142654418945, -0.24968700110912323, 3.120314359664917, 3.530061960220337, 3.3627400398254395, 5.003738880157471, 3.9514458179473877], "projection": [2.4757866859436035, 11.990944862365723], "size": 340, "height": 8, "width": 91}