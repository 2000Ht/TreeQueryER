{"data": {"doi": "10.1109/tvcg.2016.2599041", "title": "OSPRay - A CPU Ray Tracing Framework for Scientific Visualization", "year": "2016", "conferenceName": "SciVis", "authors": "Ingo Wald;Gregory P. Johnson;Jefferson Amstutz;Carson Brownlee;Aaron Knoll;Jim Jeffers;Johannes G\u00fcnther;Paul A. Navr\u00e1til", "citationCount": "55", "affiliation": "Wald, I (Corresponding Author), Intel Corp, Santa Clara, CA 95051 USA. Wald, I.; Johnson, G. P.; Amstutz, J.; Brownlee, C.; Jeffers, J.; Guenther, J., Intel Corp, Santa Clara, CA 95051 USA. Brownlee, C.; Navratil, P., Texas Adv Comp Ctr, Austin, TX USA. Knoll, A., Univ Utah, SCI Inst, Salt Lake City, UT 84112 USA. Knoll, A., Argonne Natl Lab, 9700 S Cass Ave, Argonne, IL 60439 USA.", "countries": "USA", "abstract": "Scientific data is continually increasing in complexity, variety and size, making efficient visualization and specifically rendering an ongoing challenge. Traditional rasterization-based visualization approaches encounter performance and quality limitations, particularly in HPC environments without dedicated rendering hardware. In this paper, we present OSPRay, a turn-key CPU ray tracing framework oriented towards production-use scientific visualization which can utilize varying SIMD widths and multiple device backends found across diverse HPC resources. This framework provides a high-quality, efficient CPU-based solution for typical visualization workloads, which has already been integrated into several prevalent visualization packages. We show that this system delivers the performance, high-level API simplicity, and modular device support needed to provide a compelling new rendering framework for implementing efficient scientific visualization workflows.", "keywords": "", "link": "http://dx.doi.org/10.1109/TVCG.2016.2599041", "refList": ["10.1111/j.1467-8659.2005.00855.x", "10.1109/tvcg.2015.2467963", "10.1016/0263-7855(96)00018-5", "10.1145/1778765.1778803", "10.1145/2019627.2019634", "10.1109/rt.2007.4342603", "10.1109/mcg.2009.130", "10.1109/pacificvis.2011.5742355", "10.1145/300523.300537", "10.1371/journal.pone.0038586", "10.1109/2945.795215", "10.1145/2601097.2601199", "10.1109/pvgs.2003.1249046", "10.1109/tvcg.2010.173"], "wos": 1, "children": [{"doi": "10.1109/tvcg.2017.2743979", "title": "Screen-Space Normal Distribution Function Caching for Consistent Multi-Resolution Rendering of Large Particle Data", "year": "2017", "conferenceName": "SciVis", "authors": "Mohamed Ibrahim;Patrick Wickenhauser;Peter Rautek;Guido Reina;Markus Hadwiger", "citationCount": "1", "affiliation": "Ibrahim, M (Corresponding Author), KAUST, Thuwal 239556900, Saudi Arabia. Ibrahim, Mohamed; Rautek, Peter; Hadwiger, Markus, KAUST, Thuwal 239556900, Saudi Arabia. Wickenhaeuser, Patrick; Reina, Guido, Univ Stuttgart, Visualizat Res Ctr VISUS, Stuttgart, Germany.", "countries": "Germany;Arabia", "abstract": "Molecular dynamics (MD) simulations are crucial to investigating important processes in physics and thermodynamics. The simulated atoms are usually visualized as hard spheres with Phong shading, where individual particles and their local density can be perceived well in close-up views. However, for large-scale simulations with 10 million particles or more, the visualization of large fields-of-view usually suffers from strong aliasing artifacts, because the mismatch between data size and output resolution leads to severe under-sampling of the geometry. Excessive super-sampling can alleviate this problem, but is prohibitively expensive. This paper presents a novel visualization method for large-scale particle data that addresses aliasing while enabling interactive high-quality rendering. We introduce the novel concept of screen-space normal distribution functions (S-NDFs) for particle data. S-NDFs represent the distribution of surface normals that map to a given pixel in screen space, which enables high-quality re-lighting without re-rendering particles. In order to facilitate interactive zooming, we cache S-NDFs in a screen-space mipmap (S-MIP). Together, these two concepts enable interactive, scale-consistent re-lighting and shading changes, as well as zooming, without having to re-sample the particle data. We show how our method facilitates the interactive exploration of real-world large-scale MD simulation data in different scenarios.", "keywords": "Multiresolution Techniques,Point-Based Data,Glyph-based Techniques,Scalability Issues,Molecular Visualization", "link": "http://dx.doi.org/10.1109/TVCG.2017.2743979", "refList": ["10.1109/tvcg.2011.81", "10.1109/tvcg.2010.215", "10.2312/spbg/spbg06/059-065", "10.1111/j.1467-8659.2009.01698.x", "10.1109/tvcg.2014.2350479", "10.1145/2508363.2508422", "10.1145/965141.563893", "10.1111/j.1467-8659.2012.03128.x", "10.1111/j.1467-8659.2011.01964.x", "10.1111/cgf.12363", "10.2312/vcbm.20151209", "10.1145/2366145.2366152", "10.1109/visual.2003.1250404", "10.1007/978-3-642-38750-0\\_1", "10.1109/tvcg.2007.70439", "10.1109/scivis.2015.7429492", "10.1145/1239451.1239479", "10.2312/egwr/egsr07/195-206", "10.1109/tvcg.2014.2346324", "10.1111/cgf.12197", "10.2312/egpgv/egpgv13/009-016", "10.1109/tvcg.2009.142", "10.1109/tvcg.2016.2599041", "10.1109/sc.2014.40", "10.1109/visual.2004.103", "10.1021/ct500169q", "10.1145/1730804.1730834"], "wos": 1, "children": [], "len": 1}, {"doi": "10.1109/tvcg.2017.2745105", "title": "CasCADe: A Novel 4D Visualization System for Virtual Construction Planning", "year": "2017", "conferenceName": "InfoVis", "authors": "Paulo Ivson;Daniel Nascimento;Waldemar Celes Filho;Simone D. J. Barbosa", "citationCount": "3", "affiliation": "Ivson, P (Corresponding Author), Pontificia Univ Catolica Rio de Janeiro, Tecgraf Inst, Rio de Janeiro, Brazil. Ivson, Paulo; Nascimento, Daniel; Celes, Waldemar, Pontificia Univ Catolica Rio de Janeiro, Tecgraf Inst, Rio de Janeiro, Brazil. Barbosa, Simone D. J., Pontificia Univ Catolica Rio de Janeiro, Informat Dept, Rio de Janeiro, Brazil.", "countries": "Brazil", "abstract": "Building Information Modeling (BIM) provides an integrated 3D environment to manage large-scale engineering projects. The Architecture, Engineering and Construction (AEC) industry explores 4D visualizations over these datasets for virtual construction planning. However, existing solutions lack adequate visual mechanisms to inspect the underlying schedule and make inconsistencies readily apparent. The goal of this paper is to apply best practices of information visualization to improve 4D analysis of construction plans. We first present a review of previous work that identifies common use cases and limitations. We then consulted with AEC professionals to specify the main design requirements for such applications. These guided the development of CasCADe, a novel 4D visualization system where task sequencing and spatio-temporal simultaneity are immediately apparent. This unique framework enables the combination of diverse analytical features to create an information-rich analysis environment. We also describe how engineering collaborators used CasCADe to review the real-world construction plans of an Oil &amp;amp; Gas process plant. The system made evident schedule uncertainties, identified work-space conflicts and helped analyze other constructability issues. The results and contributions of this paper suggest new avenues for future research in information visualization for the AEC industry.", "keywords": "Visualization in physical sciences and engineering,design studies,integrating spatial and non-spatial data visualization,task and requirements analysis", "link": "http://dx.doi.org/10.1109/TVCG.2017.2745105", "refList": ["10.1061/(asce)0733-9364(2000)126:4(251", "10.1109/tvcg.2013.126", "10.1109/tvcg.2011.127", "10.1111/j.1467-8659.2010.01725.x", "10.1145/1053427.1053439", "10.1061/(asce)0733-9364(2002)128:4(287", "10.1016/s0926-5805(98)00053-3", "10.1109/2945.981847", "10.1109/tvcg.2009.102", "10.1016/j.autcon.2009.11.004", "10.1109/iv.1999.781617", "10.1016/j.autcon.2014.03.009", "10.1109/tvcg.2007.70539", "10.1111/1467-8659.00689", "10.1109/mcg.2003.1210862", "10.1016/s0097-8493(00)00130-8", "10.1016/j.autcon.2012.08.004", "10.1061/(asce)0887-3801(2009)23:6(391", "10.1109/tii.2012.2188901", "10.1109/mcg.2003.1242376", "10.1109/tvcg.2007.70570", "10.1145/345513.345271", "10.1016/j.autcon.2010.09.016", "10.1006/ijhc.2000.0418", "10.1111/j.1467-8659.2012.03081.x", "10.1109/tvcg.2009.152", "10.1061/(asce)0733-9364(2004)130:4(598", "10.1145/199404.199409", "10.1109/tvcg.2011.144", "10.1109/iv.2004.1320137", "10.1016/j.autcon.2011.07.005", "10.1109/tvcg.2008.194", "10.1109/tvcg.2012.110", "10.1109/iv.2008.18", "10.1109/tvcg.2012.213", "10.1109/tvcg.2016.2599041", "10.1109/tvcg.2007.70515", "10.1145/2699276.2699280", "10.1179/000870403235002042", "10.1111/j.1467-9671.2010.01194.x", "10.1109/tvcg.2008.59", "10.1109/visual.1997.663876", "10.1109/tvcg.2007.70574", "10.1109/2945.466717", "10.1016/j.autcon.2006.04.001", "10.1016/j.cad.2014.02.001", "10.1109/tvcg.2004.1260759", "10.1145/1279640.1279642", "10.1016/j.autcon.2011.10.003", "10.1109/visual.1996.568118", "10.1016/j.autcon.2014.04.009", "10.1061/(asce)0733-9364(1996)122:4(337", "10.1109/vl.1996.545307", "10.1108/09699980910970860", "10.1109/visual.1995.480803", "10.1109/tvcg.2006.115", "10.1016/j.autcon.2004.06.002", "10.1016/j.autcon.2013.09.003", "10.1061/(asce)co.1943-7862.0000102", "10.1016/j.autcon.2009.11.015", "10.1109/tvcg.2009.84", "10.1145/1090122.1090154", "10.1061/9780784413616.040", "10.1145/1360612.1360700", "10.3758/bf03206757", "10.1016/j.aei.2015.01.011", "10.1016/j.autcon.2015.02.007", "10.1111/j.1538-4632.2005.00575.x", "10.1061/(asce)0887-3801(2002)16:2(124", "10.1145/882262.882299", "10.1016/j.autcon.2004.08.012", "10.1016/j.autcon.2011.12.011", "10.1016/j.compenvurbsys.2009.07.003", "10.1061/(asce)lm.1943-5630.0000127", "10.1080/0144619042000201376", "10.1109/tvcg.2005.62", "10.1109/cmv.2007.20", "10.1109/70.56661", "10.1109/2945.841119", "10.1109/tvcg.2007.70535", "10.1109/iv.2011.15", "10.1016/j.cag.2010.11.015", "10.1016/j.aei.2009.05.002", "10.1109/iv.2003.1218054", "10.1109/sibgrapi.2007.36", "10.1109/tvcg.2012.265", "10.1145/2601097.2601199", "10.1109/2945.675649", "10.1109/iv.1997.626539", "10.1016/j.autcon.2008.10.003", "10.1109/2945.468391"], "wos": 1, "children": [], "len": 1}, {"doi": "10.1109/tvcg.2018.2864841", "title": "A Declarative Grammar of Flexible Volume Visualization Pipelines", "year": "2018", "conferenceName": "SciVis", "authors": "Min Shih;Charles Rozhon;Kwan-Liu Ma", "citationCount": "1", "affiliation": "Shih, M (Corresponding Author), Univ Calif Davis, Davis, CA 95616 USA. Shih, Min; Rozhon, Charles; Ma, Kwan-Liu, Univ Calif Davis, Davis, CA 95616 USA.", "countries": "USA", "abstract": "This paper presents a declarative grammar for conveniently and effectively specifying advanced volume visualizations. Existing methods for creating volume visualizations either lack the flexibility to specify sophisticated visualizations or are difficult to use for those unfamiliar with volume rendering implementation and parameterization. Our design provides the ability to quickly create expressive visualizations without knowledge of the volume rendering implementation. It attempts to capture aspects of those difficult but powerful methods while remaining flexible and easy to use. As a proof of concept, our current implementation of the grammar allows users to combine multiple data variables in various ways and define transfer functions for diverse input data. The grammar also has the ability to describe advanced shading effects and create animations. We demonstrate the power and flexibility of our approach using multiple practical volume visualizations.", "keywords": "Volume visualization,direct volume rendering,declarative specification,multivariate/multimodal volume data,animation", "link": "http://dx.doi.org/10.1109/TVCG.2018.2864841", "refList": ["10.1109/38.31462", "10.1007/978-0-387-98141-3\\_1", "10.1109/visual.1992.235219", "10.1109/visual.2004.95", "10.1080/14685240802376389", "10.1109/tvcg.2015.2467449", "10.1109/visual.2005.1532788", "10.1109/tvcg.2011.185", "10.1145/2345156.2254079", "10.1109/scivis.2015.7429514", "10.1109/tvcg.2014.2346318", "10.1111/j.1467-8659.2011.01952.x", "10.2312/vissym/eurovis07/115-122", "10.1109/tvcg.2002.1021579", "10.1109/mcg.2009.130", "10.1109/tvcg.2015.2467091", "10.1109/tvcg.2007.70555", "10.1111/j.1467-8659.2007.01095.x", "10.1016/j.parco.2007.09.001", "10.1109/tvcg.2009.174", "10.1109/tvcg.2007.70534", "10.1109/tvcg.2016.2599041", "10.1109/tvcg.2014.2346322", "10.1109/mcg.2008.96", "10.1109/tvcg.2009.189", "10.1109/ipdps.2011.385", "10.1109/tvcg.2016.2599030"], "wos": 1, "children": [], "len": 1}, {"doi": "10.1111/cgf.13958", "year": "2020", "title": "CPU Ray Tracing of Tree-Based Adaptive Mesh Refinement Data", "conferenceName": "EuroVis", "authors": "Feng Wang;Nathan Marshak;William Usher;Carsten Burstedde;Aaron Knoll;Timo Heister;Chris R. Johnson", "citationCount": "0", "affiliation": "Wang, F (Corresponding Author), Univ Utah, SCI Inst, Salt Lake City, UT 84112 USA.\nWang, Feng; Marshak, Nathan; Usher, Will; Johnson, Chris R., Univ Utah, SCI Inst, Salt Lake City, UT 84112 USA.\nUsher, Will; Knoll, Aaron, Intel Corp, Santa Clara, CA 95051 USA.\nBurstedde, Carsten, Univ Bonn, Inst Numer Simulat, Bonn, Germany.\nHeister, Timo, Clemson Univ, Sch Math \\& Stat Sci, Clemson, SC 29631 USA.", "countries": "Germany;USA", "abstract": "Adaptive mesh refinement (AMR) techniques allow for representing a simulation's computation domain in an adaptive fashion. Although these techniques have found widespread adoption in high-performance computing simulations, visualizing their data output interactively and without cracks or artifacts remains challenging. In this paper, we present an efficient solution for direct volume rendering and hybrid implicit isosurface ray tracing of tree-based AMR (TB-AMR) data. We propose a novel reconstruction strategy, Generalized Trilinear Interpolation (GTI), to interpolate across AMR level boundaries without cracks or discontinuities in the surface normal. We employ a general sparse octree structure supporting a wide range of AMR data, and use it to accelerate volume rendering, hybrid implicit isosurface rendering and value queries. We demonstrate that our approach achieves artifact-free isosurface and volume rendering and provides higher quality output images compared to existing methods at interactive rendering rates.", "keywords": "", "link": "https://doi.org/10.1111/cgf.13958", "refList": ["10.1109/tvcg.2010.240", "10.1016/s0010-4655(99)00501-9", "10.1109/5992.774839", "10.1145/3139295.3139305", "10.2312/vissym/eurovis06/259-266", "10.1145/195826.195828", "10.1109/ldav48142.2019.8944267", "10.2312/evs.20191167", "10.1109/tvcg.2018.2864850", "10.1109/tvcg.2005.79", "10.21105/joss.01370", "10.1016/0021-9991(84)90073-1", "10.1109/visual.1998.745713", "10.1145/2601097.2601199", "10.1109/ldav.2013.6675156", "10.1109/tvcg.2009.149", "10.1007/s00371-008-0215-2", "10.1109/tvcg.2016.2599041", "10.1137/100791634", "10.1109/inpar.2012.6339601", "10.2312/vg/vg-pbg08/163-170", "10.1109/ldav.2012.6378973", "10.2312/pgv.20181091"], "wos": 1, "children": [], "len": 1}], "len": 9}, "index": 620, "embedding": [2.5432186126708984, 0.9459424614906311, -1.030107021331787, 2.0624101161956787, -0.4703770875930786, 0.16650904715061188, -0.39244166016578674, 0.9263279438018799, -0.4351607859134674, 0.6386509537696838, 1.2324711084365845, 0.46760788559913635, -0.14601923525333405, 1.7470577955245972, -0.804432213306427, 2.5998494625091553, 0.0804746001958847, 2.2755250930786133, -0.7047576308250427, 3.7734875679016113, -0.06630208343267441, 1.2249079942703247, 1.3202943801879883, 1.3797266483306885, -0.37562060356140137, 1.4100342988967896, -0.5452967882156372, -0.19688554108142853, 2.3079144954681396, -0.2010241001844406, -0.3296189606189728, 0.927079975605011], "projection": [-1.8100926876068115, 7.578824520111084], "size": 5, "height": 2, "width": 4}