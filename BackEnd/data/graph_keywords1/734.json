{"data": {"doi": "10.1109/tvcg.2018.2864491", "title": "Labels on Levels: Labeling of Multi-Scale Multi-Instance and Crowded 3D Biological Environments", "year": "2018", "conferenceName": "SciVis", "authors": "David Kouril;Ladislav Cmol\u00edk;Barbora Kozl\u00edkov\u00e1;Hsiang-Yun Wu;Graham Johnson;David S. Goodsell;Arthur J. Olson;M. Eduard Gr\u00f6ller;Ivan Viola", "citationCount": "1", "affiliation": "Kouril, D (Corresponding Author), TU Wien, Vienna, Austria. Kouril, David; Wu, Hsiang-Yun; Groller, M. Eduard; Viola, Ivan, TU Wien, Vienna, Austria. Groller, M. Eduard, VRVis Res Ctr, Vienna, Austria. Cmolik, Ladislav, Czech Tech Univ, Fac Elect Engn, Prague, Czech Republic. Kozlikova, Barbora, Masaryk Univ, Brno, Czech Republic. Johnson, Graham, Allen Inst Cell Sci, Seattle, WA USA. Goodsell, David S.; Olson, Arthur, Scripps Res Inst, San Diego, CA USA.", "countries": "Republic;USA;Austria", "abstract": "Labeling is intrinsically important for exploring and understanding complex environments and models in a variety of domains. We present a method for interactive labeling of crowded 3D scenes containing very many instances of objects spanning multiple scales in size. In contrast to previous labeling methods, we target cases where many instances of dozens of types are present and where the hierarchical structure of the objects in the scene presents an opportunity to choose the most suitable level for each placed label. Our solution builds on and goes beyond labeling techniques in medical 3D visualization, cartography, and biological illustrations from books and prints. In contrast to these techniques, the main characteristics of our new technique are: 1) a novel way of labeling objects as part of a bigger structure when appropriate, 2) visual clutter reduction by labeling only representative instances for each type of an object, and a strategy of selecting those. The appropriate level of label is chosen by analyzing the scene's depth buffer and the scene objects' hierarchy tree. We address the topic of communicating the parent-children relationship between labels by employing visual hierarchy concepts adapted from graphic design. Selecting representative instances considers several criteria tailored to the character of the data and is combined with a greedy optimization approach. We demonstrate the usage of our method with models from mesoscale biology where these two characteristics-multi-scale and multi-instance-are abundant, along with the fact that these scenes are extraordinarily dense.", "keywords": "labeling,multi-scale data,multi-instance data", "link": "http://dx.doi.org/10.1109/TVCG.2018.2864491", "refList": ["10.1145/1111411.1111431", "10.1002/jcc.20084", "10.1109/tvcg.2017.2744518", "10.1145/2557423", "10.1007/978-3-319-03611-3\\_17", "10.2312/vcbm.20141192", "10.1016/j.comgeo.2009.03.006", "10.1145/2024156.2024165", "10.1559/152304075784313304", "10.1057/palgrave.ivs.9500163", "10.1016/b978-155860915-0/50040-8", "10.2312/vcbm.20151209", "10.1016/j.cag.2010.05.002", "10.1145/1377980.1377986", "10.1109/tvcg.2008.168", "10.1039/c4fd00017j", "10.2312/vcbm.20131266", "10.1109/vr.2014.6802046", "10.1111/j.1467-8659.2005.00880.x", "10.1109/tvcg.2006.136", "10.1109/cadgraphics.2013.51", "10.1109/pacificvis.2010.5429592", "10.1007/978-3-319-57336-6\\_9", "10.1002/bmb.2006.494034042644", "10.1038/nmeth.3204", "10.1007/978-3-319-04657-0\\_7"], "wos": 1, "children": [], "len": 1}, "index": 734, "embedding": [-0.50124591588974, -0.12391387671232224, 0.9111193418502808, -2.359832525253296, 0.4078415334224701, 0.16650904715061188, -0.713410496711731, -0.9959407448768616, -0.3436215817928314, -0.8709165453910828, 0.581229567527771, -0.02199849858880043, 0.682111382484436, -1.0204217433929443, -0.12451648712158203, -0.5360970497131348, -0.0857093557715416, 0.05552856996655464, 0.9910241365432739, -1.063811182975769, -0.06630208343267441, -0.6208713054656982, 0.07903006672859192, -0.1577943116426468, -2.390096426010132, 0.061810001730918884, 0.4020661413669586, 0.7089816331863403, -0.29490089416503906, -1.3593682050704956, 0.3354058265686035, -0.36160412430763245], "projection": [-0.1503404676914215, 3.7915971279144287], "size": 1, "height": 1, "width": 1}