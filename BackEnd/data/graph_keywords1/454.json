{"data": {"doi": "10.1109/tvcg.2015.2467324", "title": "A comparative study between RadViz and Star Coordinates", "year": "2015", "conferenceName": "InfoVis", "authors": "Manuel Rubio-S\u00e1nchez;Laura Raya;Francisco Diaz;Alberto S\u00e1nchez", "citationCount": "34", "affiliation": "Rubio-Sanchez, M (Corresponding Author), URJC, Madrid, Spain. Rubio-Sanchez, Manuel; Sanchez, Alberto, URJC, Madrid, Spain. Diaz, Francisco, UPM, Madrid, Spain.", "countries": "Spain", "abstract": "RadViz and star coordinates are two of the most popular projection-based multivariate visualization techniques that arrange variables in radial layouts. Formally, the main difference between them consists of a nonlinear normalization step inherent in RadViz. In this paper we show that, although RadViz can be useful when analyzing sparse data, in general this design choice limits its applicability and introduces several drawbacks for exploratory data analysis. In particular, we observe that the normalization step introduces nonlinear distortions, can encumber outlier detection, prevents associating the plots with useful linear mappings, and impedes estimating original data attributes accurately. In addition, users have greater flexibility when choosing different layouts and views of the data in star coordinates. Therefore, we suggest that analysts and researchers should carefully consider whether RadViz's normalization step is beneficial regarding the data sets' characteristics and analysis tasks.", "keywords": "RadViz, Star coordinates, Exploratory data analysis, Cluster analysis, Classification, Outlier detection", "link": "http://dx.doi.org/10.1109/TVCG.2015.2467324", "refList": ["10.1109/tvcg.2013.182", "10.1057/palgrave.ivs.9500099", "10.1016/0003-2670(94)00085-9", "10.2307/2334381", "10.1109/tvcg.2014.2346258", "10.1126/science.286.5439.531", "10.1109/visual.1997.663916", "10.1109/iv.2012.46", "10.1109/tvcg.2008.173", "10.1145/1111360.1111363", "10.1126/science.290.5500.2319", "10.1196/annals.1310.020", "10.1126/science.290.5500.2323", "10.1007/978-3-540-68125-0\\_72", "10.1109/tcsvt.2013.2242640", "10.2307/2981662", "10.1145/1148020.1148024", "10.1109/infvis.1998.729559", "10.1177/1473871612439357", "10.1007/s10618-005-0031-5"], "wos": 1, "children": [{"doi": "10.1109/tvcg.2017.2744098", "title": "LDSScanner: Exploratory Analysis of Low-Dimensional Structures in High-Dimensional Datasets", "year": "2017", "conferenceName": "VAST", "authors": "Jiazhi Xia;Fenjin Ye;Wei Chen;Yusi Wang;Weifeng Chen 0002;Yuxin Ma;Anthony K. H. Tung", "citationCount": "15", "affiliation": "Chen, W (Corresponding Author), Zhejiang Univ, Hangzhou, Zhejiang, Peoples R China. Xia, Jiazhi; Ye, Fenjin; Wang, Yusi, Cent S Univ, Changsha, Hunan, Peoples R China. Chen, Wei; Ma, Yuxin, Zhejiang Univ, Hangzhou, Zhejiang, Peoples R China. Chen, Weifeng, Zhejiang Univ Finance \\& Econ, Hangzhou, Zhejiang, Peoples R China. Tung, Anthony K. H., Natl Univ Singapore, Singapore, Singapore.", "countries": "Singapore;China", "abstract": "Many approaches for analyzing a high-dimensional dataset assume that the dataset contains specific structures, e.g., clusters in linear subspaces or non-linear manifolds. This yields a trial-and-error process to verify the appropriate model and parameters. This paper contributes an exploratory interface that supports visual identification of low-dimensional structures in a high-dimensional dataset, and facilitates the optimized selection of data models and configurations. Our key idea is to abstract a set of global and local feature descriptors from the neighborhood graph-based representation of the latent low-dimensional structure, such as pairwise geodesic distance (GD) among points and pairwise local tangent space divergence (LTSD) among pointwise local tangent spaces (LTS). We propose a new LTSD-GD view, which is constructed by mapping LTSD and GD to the<inline-formula><tex-math notation=\"LaTeX\">$x$</tex-math><alternatives><inline-graphic xlink:href=\"24tvcg01-xia-2744098-ieq-1-source.tif\" xmlns:xlink=\"http://www.w3.org/1999/xlink\"/></alternatives></inline-formula>axis and<inline-formula><tex-math notation=\"LaTeX\">$y$</tex-math><alternatives><inline-graphic xlink:href=\"24tvcg01-xia-2744098-ieq-2-source.tif\" xmlns:xlink=\"http://www.w3.org/1999/xlink\"/></alternatives></inline-formula>axis using 1D multidimensional scaling, respectively. Unlike traditional dimensionality reduction methods that preserve various kinds of distances among points, the LTSD-GD view presents the distribution of pointwise LTS (<inline-formula><tex-math notation=\"LaTeX\">$x$</tex-math><alternatives><inline-graphic xlink:href=\"24tvcg01-xia-2744098-ieq-3-source.tif\" xmlns:xlink=\"http://www.w3.org/1999/xlink\"/></alternatives></inline-formula>axis) and the variation of LTS in structures (the combination of<inline-formula><tex-math notation=\"LaTeX\">$x$</tex-math><alternatives><inline-graphic xlink:href=\"24tvcg01-xia-2744098-ieq-4-source.tif\" xmlns:xlink=\"http://www.w3.org/1999/xlink\"/></alternatives></inline-formula>axis and<inline-formula><tex-math notation=\"LaTeX\">$y$</tex-math><alternatives><inline-graphic xlink:href=\"24tvcg01-xia-2744098-ieq-5-source.tif\" xmlns:xlink=\"http://www.w3.org/1999/xlink\"/></alternatives></inline-formula>axis). We design and implement a suite of visual tools for navigating and reasoning about intrinsic structures of a high-dimensional dataset. Three case studies verify the effectiveness of our approach.", "keywords": "High-dimensional data,low-dimensional structure,subspace,manifold,visual exploration", "link": "http://dx.doi.org/10.1109/TVCG.2017.2744098", "refList": ["10.1109/tvcg.2015.2467591", "10.1111/cgf.12639", "10.1109/tvcg.2016.2570755", "10.1162/089976698300017467", "10.1023/a:1004678431677", "10.1109/cvpr.2007.382974", "10.1109/tvcg.2011.229", "10.1111/cgf.12878", "10.1109/vast.2009.5332628", "10.1109/msp.2010.939739", "10.1109/visual.1997.663916", "10.1109/5.726791", "10.1109/vast.2012.6400488", "10.1109/tvcg.2015.2467324", "10.1109/tvcg.2016.2598466", "10.1109/vast.2010.5652450", "10.1126/science.290.5500.2319", "10.1109/tvcg.2013.150", "10.1109/vast.2010.5652392", "10.1137/s1064827502419154", "10.1126/science.290.5500.2323", "10.1109/icdm.2004.10112", "10.1109/tvcg.2015.2467191", "10.1109/visual.1990.146402", "10.1214/13-aos1199", "10.1109/tvcg.2015.2467717", "10.1109/tvcg.2013.160", "10.1109/infvis.2003.1249013"], "wos": 1, "children": [{"doi": "10.1109/tvcg.2018.2865020", "title": "Evaluating Multi-Dimensional Visualizations for Understanding Fuzzy Clusters", "year": "2018", "conferenceName": "VAST", "authors": "Ying Zhao;Feng Luo;Minghui Chen;Yingchao Wang;Jiazhi Xia;Fangfang Zhou;Yunhai Wang;Yi Chen 0007;Wei Chen", "citationCount": "10", "affiliation": "Xia, JZ (Corresponding Author), Cent S Univ, Changsha, Hunan, Peoples R China. Chen, W (Corresponding Author), Zhejiang Univ, State Key Lab CAD \\& CG, Hangzhou, Zhejiang, Peoples R China. Zhao, Ying; Luo, Feng; Chen, Minghui; Wang, Yingchao; Xia, Jiazhi; Zhou, Fangfang, Cent S Univ, Changsha, Hunan, Peoples R China. Wang, Yunhai, Shandong Univ, Jinan, Shandong, Peoples R China. Chen, Yi, Beijing Technol \\& Business Univ, Beijing, Peoples R China. Chen, Wei, Zhejiang Univ, State Key Lab CAD \\& CG, Hangzhou, Zhejiang, Peoples R China.", "countries": "China", "abstract": "Fuzzy clustering assigns a probability of membership for a datum to a cluster, which veritably reflects real-world clustering scenarios but significantly increases the complexity of understanding fuzzy clusters. Many studies have demonstrated that visualization techniques for multi-dimensional data are beneficial to understand fuzzy clusters. However, no empirical evidence exists on the effectiveness and efficiency of these visualization techniques in solving analytical tasks featured by fuzzy clusters. In this paper, we conduct a controlled experiment to evaluate the ability of fuzzy clusters analysis to use four multi-dimensional visualization techniques, namely, parallel coordinate plot, scatterplot matrix, principal component analysis, and Radviz. First, we define the analytical tasks and their representative questions specific to fuzzy clusters analysis. Then, we design objective questionnaires to compare the accuracy, time, and satisfaction in using the four techniques to solve the questions. We also design subjective questionnaires to collect the experience of the volunteers with the four techniques in terms of ease of use, informativeness, and helpfulness. With a complete experiment process and a detailed result analysis, we test against four hypotheses that are formulated on the basis of our experience, and provide instructive guidance for analysts in selecting appropriate and efficient visualization techniques to analyze fuzzy clusters.", "keywords": "Evaluation,multi-dimensional visualization,fuzzy clustering,parallel coordinate plot,scatterplot matrix,principal component analysis,radviz", "link": "http://dx.doi.org/10.1109/TVCG.2018.2865020", "refList": ["10.1007/s00500-006-0111-5", "10.1109/tvcg.2015.2424878", "10.1109/tvcg.2014.2330617", "10.1016/s0019-9958(69)90591-9", "10.1109/fuzzy.2004.1375750", "10.5244/c.8.19", "10.1007/s00371-013-0892-3", "10.1007/b98835", "10.1109/72.363467", "10.1057/palgrave.ivs.9500099", "10.1016/j.ins.2010.08.026", "10.2307/2290001", "10.1109/iv.2009.74", "10.1016/s0377-2217(99)00118-6", "10.1016/0098-3004(84)90020-7", "10.1109/visual.1990.146375", "10.1109/tvcg.2016.2598479", "10.1109/tvcg.2017.2745138", "10.1109/tvcg.2017.2744198", "10.1109/tvcg.2018.2816203", "10.1016/s0019-9958(65)90241-x", "10.1016/s0167-9473(02)00290-6", "10.1145/2702123.2702293", "10.1111/j.1467-8659.2011.01961.x", "10.1109/visual.1997.663916", "10.1111/j.1467-8659.2012.03129.x", "10.1016/s0305-0483(00)00042-6", "10.1057/ivs.2008.13", "10.1109/mcg.2015.97", "10.1109/tvcg.2015.2467324", "10.1109/infvis.2005.1532136", "10.1109/icdm.2014.24", "10.1109/tvcg.2008.173", "10.1109/vast.2010.5652450", "10.1109/isefs.2006.251180", "10.1109/tvcg.2016.2598831", "10.1016/s0925-2312(01)00653-1", "10.1016/j.patcog.2006.02.006", "10.1109/tvcg.2017.2744098", "10.5604/15084183.1197450", "10.1109/tvcg.2009.153", "10.1007/978-1-4757-1904-8", "10.1016/s0148-9062(98)00011-4", "10.1145/3025453.3025882", "10.1016/s0933-3657(98)00069-4", "10.1145/1168149.1168169", "10.1109/tvcg.2013.153", "10.1007/978-3-540-33037-0\\_25", "10.1111/j.1467-8659.2009.01666.x", "10.1109/infvis.1998.729559", "10.1109/tfuzz.2003.812696", "10.1016/s0165-0114(98)00224-3", "10.1109/69.553159"], "wos": 1, "children": [{"doi": "10.1109/tvcg.2019.2934208", "title": "Evaluating Perceptual Bias During Geometric Scaling of Scatterplots", "year": "2019", "conferenceName": "VAST", "authors": "Yating Wei;Honghui Mei;Ying Zhao;Shuyue Zhou;Bingru Lin;Haojing Jiang;Wei Chen", "citationCount": "5", "affiliation": "Chen, W (Corresponding Author), Zhejiang Univ, State Key Lab CAD \\& CG, Hangzhou 310058, Zhejiang, Peoples R China. Zhao, Y (Corresponding Author), Cent South Univ, Sch Comp Sci \\& Engn, Changsha 410083, Hunan, Peoples R China. Wei, Yating; Mei, Honghui; Zhou, Shuyue; Lin, Bingru; Chen, Wei, Zhejiang Univ, State Key Lab CAD \\& CG, Hangzhou 310058, Zhejiang, Peoples R China. Zhao, Ying; Jiang, Haojing, Cent South Univ, Sch Comp Sci \\& Engn, Changsha 410083, Hunan, Peoples R China.", "countries": "China", "abstract": "Scatterplots are frequently scaled to fit display areas in multi-view and multi-device data analysis environments. A common method used for scaling is to enlarge or shrink the entire scatterplot together with the inside points synchronously and proportionally. This process is called geometric scaling. However, geometric scaling of scatterplots may cause a perceptual bias, that is, the perceived and physical values of visual features may be dissociated with respect to geometric scaling. For example, if a scatterplot is projected from a laptop to a large projector screen, then observers may feel that the scatterplot shown on the projector has fewer points than that viewed on the laptop. This paper presents an evaluation study on the perceptual bias of visual features in scatterplots caused by geometric scaling. The study focuses on three fundamental visual features (i.e., numerosity, correlation, and cluster separation) and three hypotheses that are formulated on the basis of our experience. We carefully design three controlled experiments by using well-prepared synthetic data and recruit participants to complete the experiments on the basis of their subjective experience. With a detailed analysis of the experimental results, we obtain a set of instructive findings. First, geometric scaling causes a bias that has a linear relationship with the scale ratio. Second, no significant difference exists between the biases measured from normally and uniformly distributed scatterplots. Third, changing the point radius can correct the bias to a certain extent. These findings can be used to inspire the design decisions of scatterplots in various scenarios.", "keywords": "Evaluation,scatterplot,geometric scaling,bias,perceptual consistency", "link": "http://dx.doi.org/10.1109/TVCG.2019.2934208", "refList": ["10.2307/2288843", "10.1109/tvcg.2017.2744359", "10.1109/tvcg.2015.2467732", "10.1109/tvcg.2014.2346979", "10.1126/science.216.4550.1138", "10.1109/tvcg.2017.2744138", "10.1111/j.1467-8659.2009.01467.x", "10.1145/2491568.2491577", "10.1109/mwc.2018.1700325", "10.1145/2449396.2449439", "10.1109/tvcg.2011.127", "10.1109/tvcg.2011.229", "10.1167/15.5.4", "10.1073/pnas.1113195108", "10.1145/2702123.2702545", "10.1109/vast.2009.5332628", "10.1109/tvcg.2018.2800013", "10.1007/s12650-018-0530-2", "10.1016/s0042-6989(97)00340-4", "10.1109/vast.2010.5652460", "10.1109/mcg.2018.2879067", "10.1109/tvcg.2018.2864912", "10.1109/pacificvis.2010.5429604", "10.1109/tcst.2018.2819965", "10.1167/10.2.10", "10.1145/2470654.2481318", "10.1145/1842993.1843002", "10.1167/12.6.8", "10.1109/tvcg.2013.124", "10.1057/ivs.2008.13", "10.1109/tvcg.2007.70596", "10.1109/tvcg.2018.2865266", "10.1145/3173574.3173664", "10.1109/tvcg.2015.2467671", "10.1016/j.cag.2017.07.004", "10.1177/0956797613501520", "10.1109/tvcg.2018.2865020", "10.1111/j.1467-8659.2012.03125.x", "10.3758/bf03205986", "10.3758/s13423-016-1174-7", "10.1109/tvcg.2017.2680452", "10.1109/mc.2006.109", "10.1109/tvcg.2017.2744098", "10.1038/srep32810", "10.1016/j.visres.2013.06.006", "10.1002/jhbs.20078", "10.1109/tvcg.2006.163", "10.1109/tvcg.2014.2346594", "10.1109/tvcg.2017.2744184", "10.1016/j.cognition.2007.10.009", "10.1109/tvcg.2018.2865142", "10.3758/app.72.7.1839", "10.1109/tvcg.2018.2810918", "10.1016/j.jvlc.2017.10.001", "10.1145/2682623", "10.1109/tvcg.2018.2864884", "10.1145/3025453.3025984", "10.1109/tvcg.2006.184", "10.1109/tvcg.2013.153", "10.1016/j.jvlc.2018.08.003", "10.1109/tvcg.2016.2520921", "10.1111/cgf.13446", "10.1017/s0022381612000187", "10.1145/2702123.2702406", "10.1109/vast.2012.6400487", "10.1109/tvcg.2013.183", "10.1177/1473871611415997", "10.1145/2702123.2702585", "10.1145/2993901.2993903", "10.1109/tvcg.2013.120", "10.1111/cgf.12632", "10.1145/1385569.1385602", "10.1109/tvcg.2017.2754480", "10.1111/j.1467-8659.2009.01694.x"], "wos": 1, "children": [{"doi": "10.1109/tvcg.2020.3030456", "title": "Cartographic Relief Shading with Neural Networks", "year": "2020", "conferenceName": "InfoVis", "authors": "Bernhard Jenny;Magnus Heitzler;Dilpreet Singh;Marianna Farmakis-Serebryakova;Jeffery Chieh Liu;Lorenz Hurni", "citationCount": "4", "affiliation": "Jenny, B (Corresponding Author), Monash Univ, Melbourne, Vic, Australia. Jenny, Bernhard; Singh, Dilpreet; Liu, Jeffery Chieh, Monash Univ, Melbourne, Vic, Australia. Heitzler, Magnus; Farmakis-Serebryakova, Marianna; Hurni, Lorenz, Swiss Fed Inst Technol, Inst Cartog \\& Geoinformat, Zurich, Switzerland.", "countries": "Switzerland;Australia", "abstract": "Shaded relief is an effective method for visualising terrain on topographic maps, especially when the direction of illumination is adapted locally to emphasise individual terrain features. However, digital shading algorithms are unable to fully match the expressiveness of hand-crafted masterpieces, which are created through a laborious process by highly specialised cartographers. We replicate hand-drawn relief shading using U-Net neural networks. The deep neural networks are trained with manual shaded relief images of the Swiss topographic map series and terrain models of the same area. The networks generate shaded relief that closely resemble hand-drawn shaded relief art. The networks learn essential design principles from manual relief shading such as removing unnecessary terrain details, locally adjusting the illumination direction to accentuate individual terrain features, and varying brightness to emphasise larger landforms. Neural network shadings are generated from digital elevation models in a few seconds, and a study with 18 relief shading experts found that they are of high quality.", "keywords": "Relief shading,shaded relief,hillshade,neural rendering,illustrative visualisation,image-to-image translation", "link": "http://dx.doi.org/10.1109/TVCG.2020.3030456", "refList": ["10.1145/1456650.1456652", "10.1145/1145/1556262.1556270", "10.1145/345513.345271", "10.1109/tvcg.2019.2934803", "10.1145/3180658", "10.1109/tridui.2006.1618264", "10.3389/fict.2018.00015", "10.1109/vr.2018.8447558", "10.1518/hfes.45.1.160.27234", "10.1145/3290605.3300377", "10.1089/cpb.2006.9.157", "10.1007/s00779-011-0500-3", "10.1109/vl.1996.545307", "10.1109/tvcg.2019.2934415", "10.1109/5.726791", "10.1145/3290605.3300288", "10.1109/tvcg.2017.2745941", "10.1109/vr.2001.913779", "10.1145/586081.586086", "10.18637/jss.v067.i01", "10.1145/1502800.1502805", "10.1145/1165734.1165736", "10.1145/3126594.3126613", "10.1109/tvcg.2008.109", "10.1109/tvcg.2017.2744184", "10.1016/j.cola.2019.100937", "10.1109/visual.2019.8933545", "10.1145/3290605.3300555", "10.1111/cgf.13431", "10.1109/tvcg.2019.2934395", "10.1109/vr.2019.8798340", "10.1145/3025453.3026046", "10.1109/vr.2019.8797871", "10.1145/3290605.3300752", "10.1109/tvcg.2016.2520921", "10.1109/tvcg.2018.2865191", "10.1145/1970378.1970384", "10.1109/tvcg.2019.2934208", "10.18637/jss.v069.i01", "10.1162/105474698565659", "10.1145/1124772.1124775", "10.1109/vrais.1997.583043"], "wos": 1, "children": [], "len": 1}, {"doi": "10.1109/tvcg.2020.3030443", "title": "CAVA: A Visual Analytics System for Exploratory Columnar Data Augmentation Using Knowledge Graphs", "year": "2020", "conferenceName": "VAST", "authors": "Dylan Cashman;Shenyu Xu;Subhajit Das;Florian Heimerl;Cong Liu;Shah Rukh Humayoun;Michael Gleicher;Alex Endert;Remco Chang", "citationCount": "0", "affiliation": "Cashman, D (Corresponding Author), Tufts Univ, Medford, MA 02155 USA. Cashman, Dylan; Liu, Cong; Chang, Remco, Tufts Univ, Medford, MA 02155 USA. Xu, Shenyu; Das, Subhajit; Endert, Alex, Georgia Tech, Atlanta, GA USA. Heimerl, Florian; Gleicher, Michael, Univ Wisconsin, Madison, WI 53706 USA. Humayoun, Shah Rukh, San Francisco State Univ, San Francisco, CA 94132 USA.", "countries": "USA", "abstract": "Most visual analytics systems assume that all foraging for data happens before the analytics process; once analysis begins, the set of data attributes considered is fixed. Such separation of data construction from analysis precludes iteration that can enable foraging informed by the needs that arise in-situ during the analysis. The separation of the foraging loop from the data analysis tasks can limit the pace and scope of analysis. In this paper, we present CAVA, a system that integrates data curation and data augmentation with the traditional data exploration and analysis tasks, enabling information foraging in-situ during analysis. Identifying attributes to add to the dataset is difficult because it requires human knowledge to determine which available attributes will be helpful for the ensuing analytical tasks. CAVA crawls knowledge graphs to provide users with a a broad set of attributes drawn from external data to choose from. Users can then specify complex operations on knowledge graphs to construct additional attributes. CAVA shows how visual analytics can help users forage for attributes by letting users visually explore the set of available data, and by serving as an interface for query construction. It also provides visualizations of the knowledge graph itself to help users understand complex joins such as multi-hop aggregations. We assess the ability of our system to enable users to perform complex data combinations without programming in a user study over two datasets. We then demonstrate the generalizability of CAVA through two additional usage scenarios. The results of the evaluation confirm that CAVA is effective in helping the user perform data foraging that leads to improved analysis outcomes, and offer evidence in support of integrating data augmentation as a part of the visual analytics pipeline.", "keywords": "Visual Analytics,Information Foraging,Data Augmentation", "link": "http://dx.doi.org/10.1109/TVCG.2020.3030443", "refList": ["10.1057/palgrave.ivs.9500122", "10.1109/tvcg.2016.2598867", "10.1111/cgf.13708", "10.1109/tvcg.2019.2934799", "10.1109/tvcg.2019.2934541", "10.1109/tvcg.2013.65", "10.1109/tvcg.2018.2875702", "10.1109/iv.2004.1320207", "10.1068/p260471", "10.1145/1778765.1778816", "10.1109/tvcg.2018.2808489", "10.1109/tvcg.2018.2864912", "10.1016/j.apgeog.2015.12.006", "10.1111/j.1467-8659.2011.01960.x", "10.1109/tvcg.2018.2864843", "10.1109/pacificvis.2010.5429604", "10.1109/tvcg.2014.2346898", "10.1109/5.726791", "10.1177/1475090214540874", "10.1109/icde.2016.7498287", "10.1145/1556262.1556289", "10.1109/tvcg.2007.70535", "10.1109/vast.2012.6400489", "10.1145/1056808.1056914", "10.1016/j.neucom.2014.09.063", "10.1145/7529.8927", "10.1109/tvcg.2016.2598495", "10.1109/tvcg.2016.2607204", "10.1109/vast47406.2019.8986943", "10.3758/bf03205986", "10.1109/infvis.2005.1532142", "10.1145/1150402.1150479", "10.1109/tvcg.2017.2674978", "10.1109/tvcg.2019.2945960", "10.1109/tvcg.2017.2744098", "10.1109/tvcg.2017.2674999", "10.1109/tvcg.2011.279", "10.1109/tvcg.2014.2346594", "10.1109/tvcg.2017.2744184", "10.1111/cgf.12876", "10.1007/s4095-020-0191-7", "10.1007/s11390-015-1535-0", "10.1111/cgf.12640", "10.1109/tvcg.2016.2598667", "10.1111/cgf.13683", "10.1109/tvcg.2013.153", "10.1109/tvcg.2019.2934208", "10.1109/tvcg.2019.2934655", "10.1111/cgf.12655", "10.1007/s11023-010-9221-z", "10.1109/vast.2012.6400487", "10.1145/2702123.2702585", "10.1007/bf00310175", "10.1109/tvcg.2017.2744378", "10.1103/physreve.64.061907", "10.1109/ldav.2017.8231848", "10.1109/tvcg.2016.2598831"], "wos": 1, "children": [], "len": 1}, {"doi": "10.1109/tvcg.2020.3030432", "title": "Evaluation of Sampling Methods for Scatterplots", "year": "2020", "conferenceName": "VAST", "authors": "Jun Yuan;Shouxing Xiang;Jiazhi Xia;Lingyun Yu;Shixia Liu", "citationCount": "0", "affiliation": "Liu, SX (Corresponding Author), Tsinghua Univ, BNRist, Beijing, Peoples R China. Yuan, Jun; Xiang, Shouxing; Liu, Shixia, Tsinghua Univ, BNRist, Beijing, Peoples R China. Xia, Jiazhi, Cent South Univ, Changsha, Peoples R China. Yu, Lingyun, Xian Jiaotong Liverpool Univ, Suzhou, Peoples R China.", "countries": "China", "abstract": "Given a scatterplot with tens of thousands of points or even more, a natural question is which sampling method should be used to create a small but \u201cgood\u201d scatterplot for a better abstraction. We present the results of a user study that investigates the influence of different sampling strategies on multi-class scatterplots. The main goal of this study is to understand the capability of sampling methods in preserving the density, outliers, and overall shape of a scatterplot. To this end, we comprehensively review the literature and select seven typical sampling strategies as well as eight representative datasets. We then design four experiments to understand the performance of different strategies in maintaining: 1) region density; 2) class density; 3) outliers; and 4) overall shape in the sampling results. The results show that: 1) random sampling is preferred for preserving region density; 2) blue noise sampling and random sampling have comparable performance with the three multi-class sampling strategies in preserving class density; 3) outlier biased density based sampling, recursive subdivision based sampling, and blue noise sampling perform the best in keeping outliers; and 4) blue noise sampling outperforms the others in maintaining the overall shape of a scatterplot.", "keywords": "Scatterplot,data sampling,empirical evaluation", "link": "http://dx.doi.org/10.1109/TVCG.2020.3030432", "refList": ["10.1057/palgrave.ivs.9500122", "10.1109/tvcg.2016.2598867", "10.1109/tvcg.2015.2467591", "10.1111/cgf.13708", "10.1109/tvcg.2019.2934799", "10.1109/tvcg.2019.2934541", "10.1109/tvcg.2013.65", "10.1109/iv.2004.1320207", "10.1068/p260471", "10.1145/1778765.1778816", "10.1109/tvcg.2018.2808489", "10.1109/tvcg.2018.2864912", "10.1016/j.apgeog.2015.12.006", "10.1111/j.1467-8659.2011.01960.x", "10.1109/tvcg.2018.2864843", "10.1109/pacificvis.2010.5429604", "10.1109/tvcg.2014.2346898", "10.1109/5.726791", "10.1177/1475090214540874", "10.1145/1556262.1556289", "10.1109/tvcg.2007.70535", "10.1109/vast.2012.6400489", "10.1145/1056808.1056914", "10.1016/j.neucom.2014.09.063", "10.1145/7529.8927", "10.1109/tvcg.2016.2607204", "10.1109/vast47406.2019.8986943", "10.3758/bf03205986", "10.1109/infvis.2005.1532142", "10.1145/1150402.1150479", "10.1109/tvcg.2017.2674978", "10.1109/tvcg.2017.2744098", "10.1109/tvcg.2017.2674999", "10.1109/tvcg.2011.279", "10.1109/tvcg.2014.2346594", "10.1109/tvcg.2017.2744184", "10.1111/cgf.12876", "10.1109/1011101.2019.2945960", "10.1007/s4095-020-0191-7", "10.1007/s11390-015-1535-0", "10.1111/cgf.12640", "10.1109/tvcg.2016.2598667", "10.1111/cgf.13683", "10.1109/tvcg.2013.153", "10.1109/tvcg.2019.2934208", "10.1109/tvcg.2019.2934655", "10.1111/cgf.12655", "10.1007/s11023-010-9221-z", "10.1109/vast.2012.6400487", "10.1145/2702123.2702585", "10.1007/bf00310175", "10.1109/tvcg.2017.2744378", "10.1103/physreve.64.061907", "10.1109/ldav.2017.8231848", "10.1109/tvcg.2016.2598831"], "wos": 1, "children": [], "len": 1}], "len": 7}, {"doi": "10.1109/tvcg.2019.2934264", "title": "The Validity, Generalizability and Feasibility of Summative Evaluation Methods in Visual Analytics", "year": "2019", "conferenceName": "VAST", "authors": "Mosab Khayat;Morteza Karimzadeh;David S. Ebert;Arif Ghafoor", "citationCount": "1", "affiliation": "Khayat, M (Corresponding Author), Purdue Univ, W Lafayette, IN 47907 USA. Khayat, Mosab; Karimzadeh, Morteza; Ebert, David S.; Ghafoor, Arif, Purdue Univ, W Lafayette, IN 47907 USA. Karimzadeh, Morteza, Univ Colorado, Boulder, CO 80309 USA.", "countries": "USA", "abstract": "Many evaluation methods have been used to assess the usefulness of Visual Analytics (VA) solutions. These methods stem from a variety of origins with different assumptions and goals, which cause confusion about their proofing capabilities. Moreover, the lack of discussion about the evaluation processes may limit our potential to develop new evaluation methods specialized for VA. In this paper, we present an analysis of evaluation methods that have been used to summatively evaluate VA solutions. We provide a survey and taxonomy of the evaluation methods that have appeared in the VAST literature in the past two years. We then analyze these methods in terms of validity and generalizability of their findings, as well as the feasibility of using them. We propose a new metric called summative quality to compare evaluation methods according to their ability to prove usefulness, and make recommendations for selecting evaluation methods based on their summative quality in the VA domain.", "keywords": "Summative evaluation,usefulness,evaluation process,taxonomy,visual analytics", "link": "http://dx.doi.org/10.1109/TVCG.2019.2934264", "refList": ["10.1109/tvcg.2017.2744478", "10.1109/tvcg.2018.2865025", "10.1109/tvcg.2006.85", "10.1109/tvcg.2014.2346331", "10.1109/beliv.2018.8634420", "10.1109/tvcg.2017.2745181", "10.1111/cgf.13677", "10.1109/tvcg.2018.2864844", "10.1109/tvcg.2013.126", "10.1109/tvcg.2018.2864811", "10.1109/infvis.2005.1532147", "10.1177/0956797613504966", "10.1145/2669557.2669579", "10.1109/mcg.2005.102", "10.1109/visual.2003.1250426", "10.1136/bmj.39489.470347.ad", "10.1109/tvcg.2017.2744080", "10.1109/mcg.2009.53", "10.1111/j.1467-8527.2005.00307.x", "10.1109/tvcg.2010.132", "10.1109/tvcg.2018.2864886", "10.1109/tvcg.2018.2864843", "10.1109/tvcg.2018.2865028", "10.1109/tvcg.2018.2865051", "10.1109/tvcg.2018.2865044", "10.1109/tvcg.2018.2865026", "10.1007/978-3-540-71080-6\\_6", "10.1109/tvcg.2018.2865020", "10.1177/1473871611407399", "10.1109/tvcg.2018.2864504", "10.1109/tvcg.2018.2864526", "10.1109/tvcg.2005.53", "10.1109/tvcg.2018.2864905", "10.1049/sej.1991.0040", "10.1109/tvcg.2015.2513410", "10.1109/tvcg.2017.2711030", "10.1109/tvcg.2011.279", "10.1109/vast.2017.8585505", "10.1147/jrd.2010.2042914", "10.1016/s0378-7206(98)00044-5", "10.1145/2993901.2993913", "10.1109/tvcg.2018.2865041", "10.1109/tvcg.2018.2864812", "10.1109/tvcg.2017.2744758", "10.1145/1168149.1168158", "10.1109/tvcg.2017.2745279", "10.1109/tvcg.2012.213", "10.1109/tvcg.2017.2744738", "10.1109/tvcg.2017.2745083", "10.1109/tvcg.2018.2864826", "10.1145/1377966.1377974", "10.1109/apec.2009.4802646", "10.1145/1168149.1168152", "10.1016/j.jss.2008.03.059", "10.1109/vast.2017.8585484", "10.1109/tvcg.2017.2744818", "10.1109/tvcg.2017.2744358", "10.1109/tvcg.2018.2864499", "10.1109/tvcg.2018.2865042", "10.1109/tvcg.2017.2744898"], "wos": 1, "children": [{"doi": "10.1109/tvcg.2020.3030388", "title": "Visualization of Human Spine Biomechanics for Spinal Surgery", "year": "2020", "conferenceName": "SciVis", "authors": "Pepe Eulzer;Sabine Bauer;Francis Kilian;Kai Lawonn", "citationCount": "0", "affiliation": "Eulzer, P (Corresponding Author), Univ Jena, Jena, Germany. Eulzer, Pepe; Lawonn, Kai, Univ Jena, Jena, Germany. Bauer, Sabine, Univ Koblenz Landau, Koblenz, Germany. Kilian, Francis, Cath Clin Koblenz Montabaur, Dept Spine Surg, Koblenz, Germany.", "countries": "Germany", "abstract": "We propose a visualization application, designed for the exploration of human spine simulation data. Our goal is to support research in biomechanical spine simulation and advance efforts to implement simulation-backed analysis in surgical applications. Biomechanical simulation is a state-of-the-art technique for analyzing load distributions of spinal structures. Through the inclusion of patient-specific data, such simulations may facilitate personalized treatment and customized surgical interventions. Difficulties in spine modelling and simulation can be partly attributed to poor result representation, which may also be a hindrance when introducing such techniques into a clinical environment. Comparisons of measurements across multiple similar anatomical structures and the integration of temporal data make commonly available diagrams and charts insufficient for an intuitive and systematic display of results. Therefore, we facilitate methods such as multiple coordinated views, abstraction and focus and context to display simulation outcomes in a dedicated tool. $\\mathrm{By}$ linking the result data with patient-specific anatomy, we make relevant parameters tangible for clinicians. Furthermore, we introduce new concepts to show the directions of impact force vectors, which were not accessible before. We integrated our toolset into a spine segmentation and simulation pipeline and evaluated our methods with both surgeons and biomechanical researchers. When comparing our methods against standard representations that are currently in use, we found increases in accuracy and speed in data exploration tasks. $\\mathrm{in}$ a qualitative review, domain experts deemed the tool highly useful when dealing with simulation result data, which typically combines time-dependent patient movement and the resulting force distributions on spinal structures.", "keywords": "Medical visualization,bioinformatics,coordinated views,focus and context,biomechanical simulation", "link": "http://dx.doi.org/10.1109/TVCG.2020.3030388", "refList": ["10.1109/tvcg.2018.2864903", "10.1177/1473871613510429", "10.1093/ehjqcco/qcz052", "10.1109/tvcg.2007.70594", "10.1109/tvcg.2018.2865076", "10.1055/s-0039-1687862", "10.1109/visual.1990.146375", "10.1109/tvcg.2017.2744198", "10.1016/j.ijmedinf.2014.10.001", "10.1109/tvcg.2013.124", "10.1016/j.jacc", "10.1111/cgf.13167", "10.17705/1thci.00055", "10.1136/bmjqs.2009.037895", "10.1109/tvcg.2013.238", "10.1109/tvcg.2018.2865240", "10.1186/1471-2261-6-34", "10.1109/tvcg.2019.2934264", "10.1109/tvcg.2013.200", "10.1109/tvcg.2011.209", "10.1109/tvcg.2014.2346682", "10.1109/tvcg.2015.2467091", "10.1136/bmjopen-2019-033208", "10.1109/beliv.2018.8634027", "10.1109/tvcg.2012.213", "10.1109/tvcg.2015.2467191", "10.1109/tvcg.2015.2467325", "10.1145/2133806.2133821", "10.1145/1806799.1806866", "10.1108/02635570610688869", "10.1002/hbm.20701", "10.1561/1100000039", "10.1145/3025453.3025645", "10.1109/tvcg.2009.111", "10.1109/tvcg.2013.120", "10.1109/tvcg.2016.2599030"], "wos": 1, "children": [], "len": 1}], "len": 3}, {"doi": "10.1109/tvcg.2019.2934655", "title": "Visual Analytics for Electromagnetic Situation Awareness in Radio Monitoring and Management", "year": "2019", "conferenceName": "VAST", "authors": "Ying Zhao;Xiaobo Luo;Xiaoru Lin;Hairong Wang;Xiaoyan Kui;Fangfang Zhou;Jinsong Wang;Yi Chen 0007;Wei Chen", "citationCount": "3", "affiliation": "Kui, XY; Zhou, FF (Corresponding Author), Cent S Univ, Sch Comp Sci \\& Engn, Changsha, Hunan, Peoples R China. Zhao, Ying; Luo, Xiaobo; Lin, Xiaoru; Kui, Xiaoyan; Zhou, Fangfang, Cent S Univ, Sch Comp Sci \\& Engn, Changsha, Hunan, Peoples R China. Wang, Hairong, Cent S Univ, Sch Automat, Changsha, Hunan, Peoples R China. Wang, Jinsong, Southwest Elect \\& Telecom Engn Inst, Shanghai, Peoples R China. Chen, Yi, Beijing Technol \\& Business Univ, Beijing Key Lab Big Data Technol Food Safety, Beijing, Peoples R China. Chen, Wei, Zhejiang Univ, Key Lab CAD \\& CG, Hangzhou, Zhejiang, Peoples R China.", "countries": "China", "abstract": "Traditional radio monitoring and management largely depend on radio spectrum data analysis, which requires considerable domain experience and heavy cognition effort and frequently results in incorrect signal judgment and incomprehensive situation awareness. Faced with increasingly complicated electromagnetic environments, radio supervisors urgently need additional data sources and advanced analytical technologies to enhance their situation awareness ability. This paper introduces a visual analytics approach for electromagnetic situation awareness. Guided by a detailed scenario and requirement analysis, we first propose a signal clustering method to process radio signal data and a situation assessment model to obtain qualitative and quantitative descriptions of the electromagnetic situations. We then design a two-module interface with a set of visualization views and interactions to help radio supervisors perceive and understand the electromagnetic situations by a joint analysis of radio signal data and radio spectrum data. Evaluations on real-world data sets and an interview with actual users demonstrate the effectiveness of our prototype system. Finally, we discuss the limitations of the proposed approach and provide future work directions.", "keywords": "Radio monitoring and management,radio signal data,radio spectrum data,situation awareness,visual analytics", "link": "http://dx.doi.org/10.1109/TVCG.2019.2934655", "refList": ["10.1016/j.newast.2010.07.009", "10.1109/tvcg.2017.2744459", "10.1109/tvcg.2018.2864503", "10.1145/1029208.1029219", "10.1109/pacificvis.2014.54", "10.1109/tvcg.2018.2829750", "10.1016/j.jvlc.2017.11.004", "10.1109/tcyb.2015.2448236", "10.1016/j.patrec.2017.11.011", "10.1109/tvcg.2015.2505305", "10.1109/vast.2014.7042528", "10.1007/s12650-018-0530-2", "10.1109/tvcg.2018.2816203", "10.1109/tmm.2016.2614220", "10.1109/tvcg.2017.2745180", "10.1109/mcg.2018.2879067", "10.1109/tvcg.2018.2859973", "10.1109/tvcg.2016.2598460", "10.1109/infvis.2005.1532134", "10.1109/tvcg.2018.2851227", "10.1155/2012/920671", "10.1109/vast.2014.7042479", "10.1109/tvcg.2013.228", "10.1109/tvcg.2018.2865077", "10.1016/j.csda.2005.10.001", "10.1109/tvcg.2018.2865028", "10.1109/tvcg.2011.239", "10.1145/3173574.3174237", "10.1007/s13042-016-0603-2", "10.1109/tvcg.2018.2865020", "10.1017/s1041610219000024", "10.1109/2945.981848", "10.1109/tvcg.2010.193", "10.1109/tvcg.2018.2802520", "10.1145/3200766", "10.1109/wcncw.2015.7122557", "10.1145/3006299.3006312", "10.1109/icsssm.2007.4280175", "10.1126/science.1242072", "10.1109/tvcg.2017.2744098", "10.1109/tvcg.2015.2467196", "10.1109/tvcg.2016.2598619", "10.1109/tvcg.2016.2598664", "10.1109/tvcg.2013.196", "10.1109/comst.2016.2631080", "10.1109/tvcg.2018.2865029", "10.1007/s10816-016-9307-x", "10.1109/tvcg.2008.166", "10.1109/tvcg.2017.2758362", "10.1109/vizsec.2005.1532072", "10.1518/001872095779049543", "10.1109/tvcg.2007.70415", "10.1016/j.ins.2018.01.013", "10.1109/tvcg.2014.2346911", "10.1109/mim.2013.6616284", "10.1109/jsyst.2014.2358997", "10.1111/cgf.12910", "10.1109/isi.2009.5137305", "10.1109/tvcg.2011.179", "10.1007/s11277-015-2631-8", "10.1111/cgf.12396", "10.1109/tvcg.2013.2297933", "10.1109/tvcg.2014.2346926", "10.1109/tvcg.2014.2346913", "10.1109/pacificvis.2018.00030", "10.1109/tvcg.2014.2346433", "10.1109/tvcg.2016.2614803"], "wos": 1, "children": [{"doi": "10.1109/tvcg.2020.3030443", "title": "CAVA: A Visual Analytics System for Exploratory Columnar Data Augmentation Using Knowledge Graphs", "year": "2020", "conferenceName": "VAST", "authors": "Dylan Cashman;Shenyu Xu;Subhajit Das;Florian Heimerl;Cong Liu;Shah Rukh Humayoun;Michael Gleicher;Alex Endert;Remco Chang", "citationCount": "0", "affiliation": "Cashman, D (Corresponding Author), Tufts Univ, Medford, MA 02155 USA. Cashman, Dylan; Liu, Cong; Chang, Remco, Tufts Univ, Medford, MA 02155 USA. Xu, Shenyu; Das, Subhajit; Endert, Alex, Georgia Tech, Atlanta, GA USA. Heimerl, Florian; Gleicher, Michael, Univ Wisconsin, Madison, WI 53706 USA. Humayoun, Shah Rukh, San Francisco State Univ, San Francisco, CA 94132 USA.", "countries": "USA", "abstract": "Most visual analytics systems assume that all foraging for data happens before the analytics process; once analysis begins, the set of data attributes considered is fixed. Such separation of data construction from analysis precludes iteration that can enable foraging informed by the needs that arise in-situ during the analysis. The separation of the foraging loop from the data analysis tasks can limit the pace and scope of analysis. In this paper, we present CAVA, a system that integrates data curation and data augmentation with the traditional data exploration and analysis tasks, enabling information foraging in-situ during analysis. Identifying attributes to add to the dataset is difficult because it requires human knowledge to determine which available attributes will be helpful for the ensuing analytical tasks. CAVA crawls knowledge graphs to provide users with a a broad set of attributes drawn from external data to choose from. Users can then specify complex operations on knowledge graphs to construct additional attributes. CAVA shows how visual analytics can help users forage for attributes by letting users visually explore the set of available data, and by serving as an interface for query construction. It also provides visualizations of the knowledge graph itself to help users understand complex joins such as multi-hop aggregations. We assess the ability of our system to enable users to perform complex data combinations without programming in a user study over two datasets. We then demonstrate the generalizability of CAVA through two additional usage scenarios. The results of the evaluation confirm that CAVA is effective in helping the user perform data foraging that leads to improved analysis outcomes, and offer evidence in support of integrating data augmentation as a part of the visual analytics pipeline.", "keywords": "Visual Analytics,Information Foraging,Data Augmentation", "link": "http://dx.doi.org/10.1109/TVCG.2020.3030443", "refList": ["10.1057/palgrave.ivs.9500122", "10.1109/tvcg.2016.2598867", "10.1111/cgf.13708", "10.1109/tvcg.2019.2934799", "10.1109/tvcg.2019.2934541", "10.1109/tvcg.2013.65", "10.1109/tvcg.2018.2875702", "10.1109/iv.2004.1320207", "10.1068/p260471", "10.1145/1778765.1778816", "10.1109/tvcg.2018.2808489", "10.1109/tvcg.2018.2864912", "10.1016/j.apgeog.2015.12.006", "10.1111/j.1467-8659.2011.01960.x", "10.1109/tvcg.2018.2864843", "10.1109/pacificvis.2010.5429604", "10.1109/tvcg.2014.2346898", "10.1109/5.726791", "10.1177/1475090214540874", "10.1109/icde.2016.7498287", "10.1145/1556262.1556289", "10.1109/tvcg.2007.70535", "10.1109/vast.2012.6400489", "10.1145/1056808.1056914", "10.1016/j.neucom.2014.09.063", "10.1145/7529.8927", "10.1109/tvcg.2016.2598495", "10.1109/tvcg.2016.2607204", "10.1109/vast47406.2019.8986943", "10.3758/bf03205986", "10.1109/infvis.2005.1532142", "10.1145/1150402.1150479", "10.1109/tvcg.2017.2674978", "10.1109/tvcg.2019.2945960", "10.1109/tvcg.2017.2744098", "10.1109/tvcg.2017.2674999", "10.1109/tvcg.2011.279", "10.1109/tvcg.2014.2346594", "10.1109/tvcg.2017.2744184", "10.1111/cgf.12876", "10.1007/s4095-020-0191-7", "10.1007/s11390-015-1535-0", "10.1111/cgf.12640", "10.1109/tvcg.2016.2598667", "10.1111/cgf.13683", "10.1109/tvcg.2013.153", "10.1109/tvcg.2019.2934208", "10.1109/tvcg.2019.2934655", "10.1111/cgf.12655", "10.1007/s11023-010-9221-z", "10.1109/vast.2012.6400487", "10.1145/2702123.2702585", "10.1007/bf00310175", "10.1109/tvcg.2017.2744378", "10.1103/physreve.64.061907", "10.1109/ldav.2017.8231848", "10.1109/tvcg.2016.2598831"], "wos": 1, "children": [], "len": 1}, {"doi": "10.1109/tvcg.2020.3030432", "title": "Evaluation of Sampling Methods for Scatterplots", "year": "2020", "conferenceName": "VAST", "authors": "Jun Yuan;Shouxing Xiang;Jiazhi Xia;Lingyun Yu;Shixia Liu", "citationCount": "0", "affiliation": "Liu, SX (Corresponding Author), Tsinghua Univ, BNRist, Beijing, Peoples R China. Yuan, Jun; Xiang, Shouxing; Liu, Shixia, Tsinghua Univ, BNRist, Beijing, Peoples R China. Xia, Jiazhi, Cent South Univ, Changsha, Peoples R China. Yu, Lingyun, Xian Jiaotong Liverpool Univ, Suzhou, Peoples R China.", "countries": "China", "abstract": "Given a scatterplot with tens of thousands of points or even more, a natural question is which sampling method should be used to create a small but \u201cgood\u201d scatterplot for a better abstraction. We present the results of a user study that investigates the influence of different sampling strategies on multi-class scatterplots. The main goal of this study is to understand the capability of sampling methods in preserving the density, outliers, and overall shape of a scatterplot. To this end, we comprehensively review the literature and select seven typical sampling strategies as well as eight representative datasets. We then design four experiments to understand the performance of different strategies in maintaining: 1) region density; 2) class density; 3) outliers; and 4) overall shape in the sampling results. The results show that: 1) random sampling is preferred for preserving region density; 2) blue noise sampling and random sampling have comparable performance with the three multi-class sampling strategies in preserving class density; 3) outlier biased density based sampling, recursive subdivision based sampling, and blue noise sampling perform the best in keeping outliers; and 4) blue noise sampling outperforms the others in maintaining the overall shape of a scatterplot.", "keywords": "Scatterplot,data sampling,empirical evaluation", "link": "http://dx.doi.org/10.1109/TVCG.2020.3030432", "refList": ["10.1057/palgrave.ivs.9500122", "10.1109/tvcg.2016.2598867", "10.1109/tvcg.2015.2467591", "10.1111/cgf.13708", "10.1109/tvcg.2019.2934799", "10.1109/tvcg.2019.2934541", "10.1109/tvcg.2013.65", "10.1109/iv.2004.1320207", "10.1068/p260471", "10.1145/1778765.1778816", "10.1109/tvcg.2018.2808489", "10.1109/tvcg.2018.2864912", "10.1016/j.apgeog.2015.12.006", "10.1111/j.1467-8659.2011.01960.x", "10.1109/tvcg.2018.2864843", "10.1109/pacificvis.2010.5429604", "10.1109/tvcg.2014.2346898", "10.1109/5.726791", "10.1177/1475090214540874", "10.1145/1556262.1556289", "10.1109/tvcg.2007.70535", "10.1109/vast.2012.6400489", "10.1145/1056808.1056914", "10.1016/j.neucom.2014.09.063", "10.1145/7529.8927", "10.1109/tvcg.2016.2607204", "10.1109/vast47406.2019.8986943", "10.3758/bf03205986", "10.1109/infvis.2005.1532142", "10.1145/1150402.1150479", "10.1109/tvcg.2017.2674978", "10.1109/tvcg.2017.2744098", "10.1109/tvcg.2017.2674999", "10.1109/tvcg.2011.279", "10.1109/tvcg.2014.2346594", "10.1109/tvcg.2017.2744184", "10.1111/cgf.12876", "10.1109/1011101.2019.2945960", "10.1007/s4095-020-0191-7", "10.1007/s11390-015-1535-0", "10.1111/cgf.12640", "10.1109/tvcg.2016.2598667", "10.1111/cgf.13683", "10.1109/tvcg.2013.153", "10.1109/tvcg.2019.2934208", "10.1109/tvcg.2019.2934655", "10.1111/cgf.12655", "10.1007/s11023-010-9221-z", "10.1109/vast.2012.6400487", "10.1145/2702123.2702585", "10.1007/bf00310175", "10.1109/tvcg.2017.2744378", "10.1103/physreve.64.061907", "10.1109/ldav.2017.8231848", "10.1109/tvcg.2016.2598831"], "wos": 1, "children": [], "len": 1}], "len": 5}, {"doi": "10.1109/tvcg.2020.3030440", "title": "Context-aware Sampling of Large Networks via Graph Representation Learning", "year": "2020", "conferenceName": "InfoVis", "authors": "Zhiguang Zhou;Chen Shi;Xilong Shen;Lihong Cai;Haoxuan Wang;Yuhua Liu;Ying Zhao;Wei Chen", "citationCount": "0", "affiliation": "Zhao, Y (Corresponding Author), Cent South Univ, Changsha, Peoples R China. Chen, W (Corresponding Author), Zhejiang Univ, State Key Lab CAD \\& CG, Hangzhou, Peoples R China. Zhou, Zhiguang; Shi, Chen; Shen, Xilong; Cai, Lihong; Wang, Haoxuan; Liu, Yuhua, Zhejiang Univ Finance \\& Econ, Sch Informat, Hangzhou, Peoples R China. Zhao, Ying, Cent South Univ, Changsha, Peoples R China. Chen, Wei, Zhejiang Univ, State Key Lab CAD \\& CG, Hangzhou, Peoples R China.", "countries": "China", "abstract": "Numerous sampling strategies have been proposed to simplify large-scale networks for highly readable visualizations. It is of great challenge to preserve contextual structures formed by nodes and edges with tight relationships in a sampled graph, because they are easily overlooked during the process of sampling due to their irregular distribution and immunity to scale. In this paper, a new graph sampling method is proposed oriented to the preservation of contextual structures. We first utilize a graph representation learning (GRL) model to transform nodes into vectors so that the contextual structures in a network can be effectively extracted and organized. Then, we propose a multi-objective blue noise sampling model to select a subset of nodes in the vectorized space to preserve contextual structures with the retention of relative data and cluster densities in addition to those features of significance, such as bridging nodes and graph connections. We also design a set of visual interfaces enabling users to interactively conduct context-aware sampling, visually compare results with various sampling strategies, and deeply explore large networks. Case studies and quantitative comparisons based on real-world datasets have demonstrated the effectiveness of our method in the abstraction and exploration of large networks.", "keywords": "Graph sampling,Graph representation learning,Blue noise sampling,Graph evaluation", "link": "http://dx.doi.org/10.1109/TVCG.2020.3030440", "refList": ["10.1145/2491159.2491168", "10.1016/j.physa.2015.04.035", "10.1145/1830252.1830274", "10.1109/icdmw.2007.91", "10.1002/net.21834", "10.1109/tvcg.2018.2864503", "10.1016/j.cag.2018.01.010", "10.1109/icc.2016.7511156", "10.1111/cgf.13444", "10.1145/956750.956831", "10.1145/364099.364331", "10.1007/s00180-016-0663-5", "10.1109/tvcg.2013.223", "10.1007/s12650-018-0530-2", "10.1103/physreve.73.016102", "10.1109/access.2018.2870684", "10.1007/978-3-319-06793-3\\_1", "10.2312/vissym/eurovis05/239-246", "10.1016/j.ins.2015.02.014", "10.1145/2339530.2339723", "10.1109/icde.2015.7113345", "10.1109/tvcg.2011.233", "10.14778/2809974.2809980", "10.1109/glocom.2015.7417471", "10.1145/2578153.2578175", "10.1214/aoms/1177705148", "10.1109/tvcg.2008.130", "10.14232/actacyb.20.1.2011.6", "10.1504/ijitm.2019.099809", "10.1109/tvcg.2018.2865020", "10.1145/956750", "10.1002/cpe.4330060203", "10.1145/1150402.1150479", "10.1103/physreve.72.036118", "10.1109/tvcg.2017.2744098", "10.1145/2020408.2020512", "10.1142/s0129183114400075", "10.1109/jsac.2011.111005", "10.1016/j.camwa.2011.11.057", "10.1145/2470654.2466444", "10.1109/tvcg.2017.2674999", "10.1214/aos/1013203451", "10.1109/icdcsw.2011.34", "10.1016/j.physa.2013.11.015", "10.1145/1081870.1081893", "10.1109/tnet.2008.2001730", "10.1109/access.2016.2633485", "10.1145/1879141.1879192", "10.1371/journal.pone.0098679", "10.1126/science.220.4598.671", "10.1109/pacificvis.2015.7156355", "10.1088/1475-7516/2011/08/011", "10.1007/978-3-319-27261-0\\_41", "10.1111/cgf.13410", "10.1109/tvcg.2018.2865139", "10.1109/tvcg.2016.2598831", "10.1016/j.physa.2014.06.065"], "wos": 1, "children": [], "len": 1}], "len": 21}, {"doi": "10.1109/vast.2018.8802486", "title": "SMARTexplore: Simplifying High-Dimensional Data Analysis through a Table-Based Visual Analytics Approach", "year": "2018", "conferenceName": "VAST", "authors": "Michael Blumenschein;Michael Behrisch;Stefanie Schmid;Simon Butscher;Deborah Wahl;Karoline Villinger;Britta Renner;Harald Reiterer;Daniel A. Keim", "citationCount": "0", "affiliation": "Blumenschein, M (Corresponding Author), Univ Konstanz, Constance, Germany. Blumenschein, Michael; Schmid, Stefanie; Butscher, Simon; Wahl, Deborah R.; Villinger, Karoline; Renner, Britta; Reiterer, Harald; Keim, Daniel A., Univ Konstanz, Constance, Germany. Behrisch, Michael, Harvard Univ, Cambridge, MA 02138 USA.", "countries": "Germany;USA", "abstract": "We present SMARTEXPLORE, a novel visual analytics technique that simplifies the identification and understanding of clusters, correlations, and complex patterns in high-dimensional data. The analysis is integrated into an interactive table-based visualization that maintains a consistent and familiar representation throughout the analysis. The visualization is tightly coupled with pattern matching, subspace analysis, reordering, and layout algorithms. To increase the analyst's trust in the revealed patterns, SMARTEXPLORE automatically selects and computes statistical measures based on dimension and data properties. While existing approaches to analyzing high-dimensional data (e.g., planar projections and Parallel coordinates) have proven effective, they typically have steep learning curves for non-visualization experts. Our evaluation, based on three expert case studies, confirms that non-visualization experts successfully reveal patterns in high-dimensional data when using SMARTEXPLORE.", "keywords": "High-dimensional data,visual exploration,pattern-driven analysis,tabular visualization,subspace,aggregation", "link": "http://dx.doi.org/10.1109/VAST.2018.8802486", "refList": ["10.1177/1473871612460526", "10.1109/tvcg.2015.2489649", "10.1111/j.1467-8659.2008.01241.x", "10.1007/978-3-319-25087-8\\_29", "10.1007/b98835", "10.13140/rg.2.2.16570.90567", "10.1109/tvcg.2014.2346260", "10.1109/vast.2009.5332628", "10.2307/2528823", "10.1109/tvcg.2010.184", "10.1145/1133265.1133318", "10.1057/palgrave.ivs.9500072", "10.1111/j.1467-8659.2012.03110.x", "10.1145/1007730.1007731", "10.1057/palgrave.ivs.9500086", "10.1111/cgf.12935", "10.1109/tvcg.2014.2346279", "10.1007/bf01898350", "10.1109/tvcg.2013.173", "10.1109/tvcg.2017.2672987", "10.1109/tvcg.2014.2346248", "10.1109/infvis.2004.46", "10.1109/vast.2010.5652433", "10.1109/vast.2009.5332611", "10.1109/tvcg.2015.2467553", "10.1109/tvcg.2015.2468078", "10.1109/tvcg.2017.2744098", "10.1109/tvcg.2013.150", "10.1109/tvcg.2016.2640960", "10.1111/cgf.12630", "10.1007/978-1-4757-1904-8", "10.1109/tvcg.2011.188", "10.1109/tvcg.2010.138", "10.1109/tvcg.2017.2745078", "10.1109/tvcg.2017.2743978", "10.1111/cgf.12879", "10.1109/iv.2008.33", "10.1111/cgf.13446", "10.1007/s00371-018-1483-0", "10.1109/infvis.1998.729559", "10.1145/2669557.2669572", "10.1111/j.1467-8659.2008.01239.x"], "wos": 1, "children": [], "len": 1}, {"doi": "10.1109/tvcg.2019.2934208", "title": "Evaluating Perceptual Bias During Geometric Scaling of Scatterplots", "year": "2019", "conferenceName": "VAST", "authors": "Yating Wei;Honghui Mei;Ying Zhao;Shuyue Zhou;Bingru Lin;Haojing Jiang;Wei Chen", "citationCount": "5", "affiliation": "Chen, W (Corresponding Author), Zhejiang Univ, State Key Lab CAD \\& CG, Hangzhou 310058, Zhejiang, Peoples R China. Zhao, Y (Corresponding Author), Cent South Univ, Sch Comp Sci \\& Engn, Changsha 410083, Hunan, Peoples R China. Wei, Yating; Mei, Honghui; Zhou, Shuyue; Lin, Bingru; Chen, Wei, Zhejiang Univ, State Key Lab CAD \\& CG, Hangzhou 310058, Zhejiang, Peoples R China. Zhao, Ying; Jiang, Haojing, Cent South Univ, Sch Comp Sci \\& Engn, Changsha 410083, Hunan, Peoples R China.", "countries": "China", "abstract": "Scatterplots are frequently scaled to fit display areas in multi-view and multi-device data analysis environments. A common method used for scaling is to enlarge or shrink the entire scatterplot together with the inside points synchronously and proportionally. This process is called geometric scaling. However, geometric scaling of scatterplots may cause a perceptual bias, that is, the perceived and physical values of visual features may be dissociated with respect to geometric scaling. For example, if a scatterplot is projected from a laptop to a large projector screen, then observers may feel that the scatterplot shown on the projector has fewer points than that viewed on the laptop. This paper presents an evaluation study on the perceptual bias of visual features in scatterplots caused by geometric scaling. The study focuses on three fundamental visual features (i.e., numerosity, correlation, and cluster separation) and three hypotheses that are formulated on the basis of our experience. We carefully design three controlled experiments by using well-prepared synthetic data and recruit participants to complete the experiments on the basis of their subjective experience. With a detailed analysis of the experimental results, we obtain a set of instructive findings. First, geometric scaling causes a bias that has a linear relationship with the scale ratio. Second, no significant difference exists between the biases measured from normally and uniformly distributed scatterplots. Third, changing the point radius can correct the bias to a certain extent. These findings can be used to inspire the design decisions of scatterplots in various scenarios.", "keywords": "Evaluation,scatterplot,geometric scaling,bias,perceptual consistency", "link": "http://dx.doi.org/10.1109/TVCG.2019.2934208", "refList": ["10.2307/2288843", "10.1109/tvcg.2017.2744359", "10.1109/tvcg.2015.2467732", "10.1109/tvcg.2014.2346979", "10.1126/science.216.4550.1138", "10.1109/tvcg.2017.2744138", "10.1111/j.1467-8659.2009.01467.x", "10.1145/2491568.2491577", "10.1109/mwc.2018.1700325", "10.1145/2449396.2449439", "10.1109/tvcg.2011.127", "10.1109/tvcg.2011.229", "10.1167/15.5.4", "10.1073/pnas.1113195108", "10.1145/2702123.2702545", "10.1109/vast.2009.5332628", "10.1109/tvcg.2018.2800013", "10.1007/s12650-018-0530-2", "10.1016/s0042-6989(97)00340-4", "10.1109/vast.2010.5652460", "10.1109/mcg.2018.2879067", "10.1109/tvcg.2018.2864912", "10.1109/pacificvis.2010.5429604", "10.1109/tcst.2018.2819965", "10.1167/10.2.10", "10.1145/2470654.2481318", "10.1145/1842993.1843002", "10.1167/12.6.8", "10.1109/tvcg.2013.124", "10.1057/ivs.2008.13", "10.1109/tvcg.2007.70596", "10.1109/tvcg.2018.2865266", "10.1145/3173574.3173664", "10.1109/tvcg.2015.2467671", "10.1016/j.cag.2017.07.004", "10.1177/0956797613501520", "10.1109/tvcg.2018.2865020", "10.1111/j.1467-8659.2012.03125.x", "10.3758/bf03205986", "10.3758/s13423-016-1174-7", "10.1109/tvcg.2017.2680452", "10.1109/mc.2006.109", "10.1109/tvcg.2017.2744098", "10.1038/srep32810", "10.1016/j.visres.2013.06.006", "10.1002/jhbs.20078", "10.1109/tvcg.2006.163", "10.1109/tvcg.2014.2346594", "10.1109/tvcg.2017.2744184", "10.1016/j.cognition.2007.10.009", "10.1109/tvcg.2018.2865142", "10.3758/app.72.7.1839", "10.1109/tvcg.2018.2810918", "10.1016/j.jvlc.2017.10.001", "10.1145/2682623", "10.1109/tvcg.2018.2864884", "10.1145/3025453.3025984", "10.1109/tvcg.2006.184", "10.1109/tvcg.2013.153", "10.1016/j.jvlc.2018.08.003", "10.1109/tvcg.2016.2520921", "10.1111/cgf.13446", "10.1017/s0022381612000187", "10.1145/2702123.2702406", "10.1109/vast.2012.6400487", "10.1109/tvcg.2013.183", "10.1177/1473871611415997", "10.1145/2702123.2702585", "10.1145/2993901.2993903", "10.1109/tvcg.2013.120", "10.1111/cgf.12632", "10.1145/1385569.1385602", "10.1109/tvcg.2017.2754480", "10.1111/j.1467-8659.2009.01694.x"], "wos": 1, "children": [{"doi": "10.1109/tvcg.2020.3030456", "title": "Cartographic Relief Shading with Neural Networks", "year": "2020", "conferenceName": "InfoVis", "authors": "Bernhard Jenny;Magnus Heitzler;Dilpreet Singh;Marianna Farmakis-Serebryakova;Jeffery Chieh Liu;Lorenz Hurni", "citationCount": "4", "affiliation": "Jenny, B (Corresponding Author), Monash Univ, Melbourne, Vic, Australia. Jenny, Bernhard; Singh, Dilpreet; Liu, Jeffery Chieh, Monash Univ, Melbourne, Vic, Australia. Heitzler, Magnus; Farmakis-Serebryakova, Marianna; Hurni, Lorenz, Swiss Fed Inst Technol, Inst Cartog \\& Geoinformat, Zurich, Switzerland.", "countries": "Switzerland;Australia", "abstract": "Shaded relief is an effective method for visualising terrain on topographic maps, especially when the direction of illumination is adapted locally to emphasise individual terrain features. However, digital shading algorithms are unable to fully match the expressiveness of hand-crafted masterpieces, which are created through a laborious process by highly specialised cartographers. We replicate hand-drawn relief shading using U-Net neural networks. The deep neural networks are trained with manual shaded relief images of the Swiss topographic map series and terrain models of the same area. The networks generate shaded relief that closely resemble hand-drawn shaded relief art. The networks learn essential design principles from manual relief shading such as removing unnecessary terrain details, locally adjusting the illumination direction to accentuate individual terrain features, and varying brightness to emphasise larger landforms. Neural network shadings are generated from digital elevation models in a few seconds, and a study with 18 relief shading experts found that they are of high quality.", "keywords": "Relief shading,shaded relief,hillshade,neural rendering,illustrative visualisation,image-to-image translation", "link": "http://dx.doi.org/10.1109/TVCG.2020.3030456", "refList": ["10.1145/1456650.1456652", "10.1145/1145/1556262.1556270", "10.1145/345513.345271", "10.1109/tvcg.2019.2934803", "10.1145/3180658", "10.1109/tridui.2006.1618264", "10.3389/fict.2018.00015", "10.1109/vr.2018.8447558", "10.1518/hfes.45.1.160.27234", "10.1145/3290605.3300377", "10.1089/cpb.2006.9.157", "10.1007/s00779-011-0500-3", "10.1109/vl.1996.545307", "10.1109/tvcg.2019.2934415", "10.1109/5.726791", "10.1145/3290605.3300288", "10.1109/tvcg.2017.2745941", "10.1109/vr.2001.913779", "10.1145/586081.586086", "10.18637/jss.v067.i01", "10.1145/1502800.1502805", "10.1145/1165734.1165736", "10.1145/3126594.3126613", "10.1109/tvcg.2008.109", "10.1109/tvcg.2017.2744184", "10.1016/j.cola.2019.100937", "10.1109/visual.2019.8933545", "10.1145/3290605.3300555", "10.1111/cgf.13431", "10.1109/tvcg.2019.2934395", "10.1109/vr.2019.8798340", "10.1145/3025453.3026046", "10.1109/vr.2019.8797871", "10.1145/3290605.3300752", "10.1109/tvcg.2016.2520921", "10.1109/tvcg.2018.2865191", "10.1145/1970378.1970384", "10.1109/tvcg.2019.2934208", "10.18637/jss.v069.i01", "10.1162/105474698565659", "10.1145/1124772.1124775", "10.1109/vrais.1997.583043"], "wos": 1, "children": [], "len": 1}, {"doi": "10.1109/tvcg.2020.3030443", "title": "CAVA: A Visual Analytics System for Exploratory Columnar Data Augmentation Using Knowledge Graphs", "year": "2020", "conferenceName": "VAST", "authors": "Dylan Cashman;Shenyu Xu;Subhajit Das;Florian Heimerl;Cong Liu;Shah Rukh Humayoun;Michael Gleicher;Alex Endert;Remco Chang", "citationCount": "0", "affiliation": "Cashman, D (Corresponding Author), Tufts Univ, Medford, MA 02155 USA. Cashman, Dylan; Liu, Cong; Chang, Remco, Tufts Univ, Medford, MA 02155 USA. Xu, Shenyu; Das, Subhajit; Endert, Alex, Georgia Tech, Atlanta, GA USA. Heimerl, Florian; Gleicher, Michael, Univ Wisconsin, Madison, WI 53706 USA. Humayoun, Shah Rukh, San Francisco State Univ, San Francisco, CA 94132 USA.", "countries": "USA", "abstract": "Most visual analytics systems assume that all foraging for data happens before the analytics process; once analysis begins, the set of data attributes considered is fixed. Such separation of data construction from analysis precludes iteration that can enable foraging informed by the needs that arise in-situ during the analysis. The separation of the foraging loop from the data analysis tasks can limit the pace and scope of analysis. In this paper, we present CAVA, a system that integrates data curation and data augmentation with the traditional data exploration and analysis tasks, enabling information foraging in-situ during analysis. Identifying attributes to add to the dataset is difficult because it requires human knowledge to determine which available attributes will be helpful for the ensuing analytical tasks. CAVA crawls knowledge graphs to provide users with a a broad set of attributes drawn from external data to choose from. Users can then specify complex operations on knowledge graphs to construct additional attributes. CAVA shows how visual analytics can help users forage for attributes by letting users visually explore the set of available data, and by serving as an interface for query construction. It also provides visualizations of the knowledge graph itself to help users understand complex joins such as multi-hop aggregations. We assess the ability of our system to enable users to perform complex data combinations without programming in a user study over two datasets. We then demonstrate the generalizability of CAVA through two additional usage scenarios. The results of the evaluation confirm that CAVA is effective in helping the user perform data foraging that leads to improved analysis outcomes, and offer evidence in support of integrating data augmentation as a part of the visual analytics pipeline.", "keywords": "Visual Analytics,Information Foraging,Data Augmentation", "link": "http://dx.doi.org/10.1109/TVCG.2020.3030443", "refList": ["10.1057/palgrave.ivs.9500122", "10.1109/tvcg.2016.2598867", "10.1111/cgf.13708", "10.1109/tvcg.2019.2934799", "10.1109/tvcg.2019.2934541", "10.1109/tvcg.2013.65", "10.1109/tvcg.2018.2875702", "10.1109/iv.2004.1320207", "10.1068/p260471", "10.1145/1778765.1778816", "10.1109/tvcg.2018.2808489", "10.1109/tvcg.2018.2864912", "10.1016/j.apgeog.2015.12.006", "10.1111/j.1467-8659.2011.01960.x", "10.1109/tvcg.2018.2864843", "10.1109/pacificvis.2010.5429604", "10.1109/tvcg.2014.2346898", "10.1109/5.726791", "10.1177/1475090214540874", "10.1109/icde.2016.7498287", "10.1145/1556262.1556289", "10.1109/tvcg.2007.70535", "10.1109/vast.2012.6400489", "10.1145/1056808.1056914", "10.1016/j.neucom.2014.09.063", "10.1145/7529.8927", "10.1109/tvcg.2016.2598495", "10.1109/tvcg.2016.2607204", "10.1109/vast47406.2019.8986943", "10.3758/bf03205986", "10.1109/infvis.2005.1532142", "10.1145/1150402.1150479", "10.1109/tvcg.2017.2674978", "10.1109/tvcg.2019.2945960", "10.1109/tvcg.2017.2744098", "10.1109/tvcg.2017.2674999", "10.1109/tvcg.2011.279", "10.1109/tvcg.2014.2346594", "10.1109/tvcg.2017.2744184", "10.1111/cgf.12876", "10.1007/s4095-020-0191-7", "10.1007/s11390-015-1535-0", "10.1111/cgf.12640", "10.1109/tvcg.2016.2598667", "10.1111/cgf.13683", "10.1109/tvcg.2013.153", "10.1109/tvcg.2019.2934208", "10.1109/tvcg.2019.2934655", "10.1111/cgf.12655", "10.1007/s11023-010-9221-z", "10.1109/vast.2012.6400487", "10.1145/2702123.2702585", "10.1007/bf00310175", "10.1109/tvcg.2017.2744378", "10.1103/physreve.64.061907", "10.1109/ldav.2017.8231848", "10.1109/tvcg.2016.2598831"], "wos": 1, "children": [], "len": 1}, {"doi": "10.1109/tvcg.2020.3030432", "title": "Evaluation of Sampling Methods for Scatterplots", "year": "2020", "conferenceName": "VAST", "authors": "Jun Yuan;Shouxing Xiang;Jiazhi Xia;Lingyun Yu;Shixia Liu", "citationCount": "0", "affiliation": "Liu, SX (Corresponding Author), Tsinghua Univ, BNRist, Beijing, Peoples R China. Yuan, Jun; Xiang, Shouxing; Liu, Shixia, Tsinghua Univ, BNRist, Beijing, Peoples R China. Xia, Jiazhi, Cent South Univ, Changsha, Peoples R China. Yu, Lingyun, Xian Jiaotong Liverpool Univ, Suzhou, Peoples R China.", "countries": "China", "abstract": "Given a scatterplot with tens of thousands of points or even more, a natural question is which sampling method should be used to create a small but \u201cgood\u201d scatterplot for a better abstraction. We present the results of a user study that investigates the influence of different sampling strategies on multi-class scatterplots. The main goal of this study is to understand the capability of sampling methods in preserving the density, outliers, and overall shape of a scatterplot. To this end, we comprehensively review the literature and select seven typical sampling strategies as well as eight representative datasets. We then design four experiments to understand the performance of different strategies in maintaining: 1) region density; 2) class density; 3) outliers; and 4) overall shape in the sampling results. The results show that: 1) random sampling is preferred for preserving region density; 2) blue noise sampling and random sampling have comparable performance with the three multi-class sampling strategies in preserving class density; 3) outlier biased density based sampling, recursive subdivision based sampling, and blue noise sampling perform the best in keeping outliers; and 4) blue noise sampling outperforms the others in maintaining the overall shape of a scatterplot.", "keywords": "Scatterplot,data sampling,empirical evaluation", "link": "http://dx.doi.org/10.1109/TVCG.2020.3030432", "refList": ["10.1057/palgrave.ivs.9500122", "10.1109/tvcg.2016.2598867", "10.1109/tvcg.2015.2467591", "10.1111/cgf.13708", "10.1109/tvcg.2019.2934799", "10.1109/tvcg.2019.2934541", "10.1109/tvcg.2013.65", "10.1109/iv.2004.1320207", "10.1068/p260471", "10.1145/1778765.1778816", "10.1109/tvcg.2018.2808489", "10.1109/tvcg.2018.2864912", "10.1016/j.apgeog.2015.12.006", "10.1111/j.1467-8659.2011.01960.x", "10.1109/tvcg.2018.2864843", "10.1109/pacificvis.2010.5429604", "10.1109/tvcg.2014.2346898", "10.1109/5.726791", "10.1177/1475090214540874", "10.1145/1556262.1556289", "10.1109/tvcg.2007.70535", "10.1109/vast.2012.6400489", "10.1145/1056808.1056914", "10.1016/j.neucom.2014.09.063", "10.1145/7529.8927", "10.1109/tvcg.2016.2607204", "10.1109/vast47406.2019.8986943", "10.3758/bf03205986", "10.1109/infvis.2005.1532142", "10.1145/1150402.1150479", "10.1109/tvcg.2017.2674978", "10.1109/tvcg.2017.2744098", "10.1109/tvcg.2017.2674999", "10.1109/tvcg.2011.279", "10.1109/tvcg.2014.2346594", "10.1109/tvcg.2017.2744184", "10.1111/cgf.12876", "10.1109/1011101.2019.2945960", "10.1007/s4095-020-0191-7", "10.1007/s11390-015-1535-0", "10.1111/cgf.12640", "10.1109/tvcg.2016.2598667", "10.1111/cgf.13683", "10.1109/tvcg.2013.153", "10.1109/tvcg.2019.2934208", "10.1109/tvcg.2019.2934655", "10.1111/cgf.12655", "10.1007/s11023-010-9221-z", "10.1109/vast.2012.6400487", "10.1145/2702123.2702585", "10.1007/bf00310175", "10.1109/tvcg.2017.2744378", "10.1103/physreve.64.061907", "10.1109/ldav.2017.8231848", "10.1109/tvcg.2016.2598831"], "wos": 1, "children": [], "len": 1}], "len": 7}, {"doi": "10.1109/tvcg.2019.2934800", "title": "RSATree: Distribution-Aware Data Representation of Large-Scale Tabular Datasets for Flexible Visual Query", "year": "2019", "conferenceName": "InfoVis", "authors": "Honghui Mei;Wei Chen;Yating Wei;Yuanzhe Hu;Shuyue Zhou;Bingru Lin;Ying Zhao;Jiazhi Xia", "citationCount": "2", "affiliation": "Chen, W (Corresponding Author), Zhejiang Univ, State Key Lab CAD\\&CG, Hangzhou, Peoples R China. Mei, Honghui; Chen, Wei; Yating, Wei; Hu, Yuanzhe; Zhou, Shuyue; Lin, Bingru, Zhejiang Univ, State Key Lab CAD\\&CG, Hangzhou, Peoples R China. Ying, Zhao; Xia, Jiazhi, Cent S Univ, Sch Comp Sci \\& Engn, Changsha, Peoples R China.", "countries": "China", "abstract": "Analysts commonly investigate the data distributions derived from statistical aggregations of data that are represented by charts, such as histograms and binned scatterplots, to visualize and analyze a large-scale dataset. Aggregate queries are implicitly executed through such a process. Datasets are constantly extremely large; thus, the response time should be accelerated by calculating predefined data cubes. However, the queries are limited to the predefined binning schema of preprocessed data cubes. Such limitation hinders analysts' flexible adjustment of visual specifications to investigate the implicit patterns in the data effectively. Particularly, RSATree enables arbitrary queries and flexible binning strategies by leveraging three schemes, namely, an R-tree-based space partitioning scheme to catch the data distribution, a locality-sensitive hashing technique to achieve locality-preserving random access to data items, and a summed area table scheme to support interactive query of aggregated values with a linear computational complexity. This study presents and implements a web-based visual query system that supports visual specification, query, and exploration of large-scale tabular data with user-adjustable granularities. We demonstrate the efficiency and utility of our approach by performing various experiments on real-world datasets and analyzing time and space complexity.", "keywords": "Aggregate query,visual query,large-scale data visualization,R-tree,summed area table,hashing", "link": "http://dx.doi.org/10.1109/TVCG.2019.2934800", "refList": ["10.1057/palgrave.ivs.9500122", "10.1145/3183713.3196909", "10.1145/2882903.2882919", "10.1145/2207676.2208294", "10.1007/s007780100049", "10.14778/2735479.2735485", "10.1109/mwc.2018.1700325", "10.1111/cgf.12129", "10.1109/tvcg.2014.2346452", "10.1016/b978-0-12-814837-2.00002-0", "10.1145/2254556.2254659", "10.1109/tvcg.2011.185", "10.1006/jvlc.1997.0037", "10.1145/1189769.1189775", "10.1109/tkde.2007.190664", "10.14778/2831360.2831371", "10.1023/a:1009726021843", "10.1016/j.neucom.2015.08.117", "10.1109/vast.2014.7042480", "10.1109/tvcg.2016.2598694", "10.1145/2465351.2465355", "10.1109/52.329404", "10.1016/j.jvlc.2017.05.003", "10.1109/tvcg.2016.2598624", "10.1109/infvis.1996.559210", "10.1109/icde.2016.7498287", "10.1109/icde.2014.6816674", "10.1145/997817.997857", "10.1109/pacificvis.2014.60", "10.1109/tvcg.2017.2744098", "10.1111/j.1467-8659.2005.00880.x", "10.1109/tvcg.2014.2346594", "10.1109/icde.1999.754932", "10.1109/tits.2015.2436897", "10.1109/tvcg.2013.179", "10.1016/j.jvlc.2017.10.001", "10.1109/2945.981851", "10.1109/tvcg.2012.23", "10.1109/tvcg.2017.2758362", "10.1145/2133416.2146416", "10.1109/pacificvis.2013.6596132", "10.1109/tits.2017.2711644", "10.1145/248603.248616", "10.1109/tvcg.2016.2607714", "10.1109/tvcg.2013.152", "10.1145/3219819.3219867", "10.1145/356924.356930", "10.1109/tvcg.2015.2467191", "10.1111/cgf.12459", "10.1109/cvpr.2005.188", "10.1145/93597.98741", "10.1016/j.visinf.2018.04.011", "10.1109/icde.2001.914867"], "wos": 1, "children": [{"doi": "10.1109/tvcg.2020.3030466", "title": "Uncertainty in Continuous Scatterplots, Continuous Parallel Coordinates, and Fibers", "year": "2020", "conferenceName": "SciVis", "authors": "Boyan Zheng;Filip Sadlo", "citationCount": "0", "affiliation": "Zheng, BY (Corresponding Author), Heidelberg Univ, Heidelberg, Germany. Zheng, Boyan; Sadlo, Filip, Heidelberg Univ, Heidelberg, Germany.", "countries": "Germany", "abstract": "In this paper, we introduce uncertainty to continuous scatterplots and continuous parallel coordinates. We derive respective models, validate them with sampling-based brute-force schemes, and present acceleration strategies for their computation. At the same time, we show that our approach lends itself as well for introducing uncertainty into the definition of fibers in bivariate data. Finally, we demonstrate the properties and the utility of our approach using specifically designed synthetic cases and simulated data.", "keywords": "Multivariate data,uncertainty visualization,uncertain continuous scatterplots,uncertain continuous parallel coordinates,uncertain fibers", "link": "http://dx.doi.org/10.1109/TVCG.2020.3030466", "refList": ["10.1109/tvcg.2018.2865193", "10.1109/tvcg.2013.143", "10.1109/tvcg.2015.2467204", "10.1109/pacificvis.2013.6596144", "10.1109/tvcg.2017.2745178", "10.1109/tmm.2016.2614227", "10.1109/scivis.2015.7429488", "10.1111/cgf.12100", "10.1109/pacificvis.2016.7465251", "10.1111/cgf.12898", "10.1109/tvcg.2015.2410278", "10.1109/icdmw.2009.55", "10.1109/tvcg.2015.2467754", "10.1109/tvcg.2010.247", "10.1109/tvcg.2019.2934312", "10.1111/cgf.13397", "10.1109/tvcg.2016.2598868", "10.1111/j.1467-8659.2011.01944.x", "10.1109/tvcg.2015.2507569", "10.1109/tvcg.2013.92", "10.1145/1268517.1268563", "10.1109/tvcg.2014.2346455", "10.1109/tvcg.2010.181", "10.1109/tvcg.2018.2853721", "10.1109/tvcg.2008.140", "10.1007/s12650-015-0341-7", "10.1109/mcg.2014.52", "10.1109/tvcg.2018.2864815", "10.1111/j.1467-8659.2012.03095.x", "10.1109/tvcg.2013.138", "10.1109/tvcg.2019.2934242", "10.3390/e20070540", "10.1016/j.jcp.2007.02.014", "10.1111/cgf.13999", "10.1109/tvcg.2017.2779501", "10.1111/cgf.12390", "10.1109/tvcg.2014.2307892", "10.1111/cgf.13531", "10.1109/tvcg.2013.152", "10.1038/nature14956", "10.1007/978-3-540-88606-8\\_4", "10.1109/mcg.2005.71", "10.1111/j.1467-8659.2011.01942.x", "10.1109/tvcg.2019.2934800", "10.1109/tvcg.2016.2598830", "10.1109/cvpr.2005.188", "10.1109/tvcg.2011.261", "10.1111/cgf.13731", "10.1109/tvcg.2017.2754480"], "wos": 1, "children": [], "len": 1}], "len": 3}, {"doi": "10.1109/tvcg.2019.2934655", "title": "Visual Analytics for Electromagnetic Situation Awareness in Radio Monitoring and Management", "year": "2019", "conferenceName": "VAST", "authors": "Ying Zhao;Xiaobo Luo;Xiaoru Lin;Hairong Wang;Xiaoyan Kui;Fangfang Zhou;Jinsong Wang;Yi Chen 0007;Wei Chen", "citationCount": "3", "affiliation": "Kui, XY; Zhou, FF (Corresponding Author), Cent S Univ, Sch Comp Sci \\& Engn, Changsha, Hunan, Peoples R China. Zhao, Ying; Luo, Xiaobo; Lin, Xiaoru; Kui, Xiaoyan; Zhou, Fangfang, Cent S Univ, Sch Comp Sci \\& Engn, Changsha, Hunan, Peoples R China. Wang, Hairong, Cent S Univ, Sch Automat, Changsha, Hunan, Peoples R China. Wang, Jinsong, Southwest Elect \\& Telecom Engn Inst, Shanghai, Peoples R China. Chen, Yi, Beijing Technol \\& Business Univ, Beijing Key Lab Big Data Technol Food Safety, Beijing, Peoples R China. Chen, Wei, Zhejiang Univ, Key Lab CAD \\& CG, Hangzhou, Zhejiang, Peoples R China.", "countries": "China", "abstract": "Traditional radio monitoring and management largely depend on radio spectrum data analysis, which requires considerable domain experience and heavy cognition effort and frequently results in incorrect signal judgment and incomprehensive situation awareness. Faced with increasingly complicated electromagnetic environments, radio supervisors urgently need additional data sources and advanced analytical technologies to enhance their situation awareness ability. This paper introduces a visual analytics approach for electromagnetic situation awareness. Guided by a detailed scenario and requirement analysis, we first propose a signal clustering method to process radio signal data and a situation assessment model to obtain qualitative and quantitative descriptions of the electromagnetic situations. We then design a two-module interface with a set of visualization views and interactions to help radio supervisors perceive and understand the electromagnetic situations by a joint analysis of radio signal data and radio spectrum data. Evaluations on real-world data sets and an interview with actual users demonstrate the effectiveness of our prototype system. Finally, we discuss the limitations of the proposed approach and provide future work directions.", "keywords": "Radio monitoring and management,radio signal data,radio spectrum data,situation awareness,visual analytics", "link": "http://dx.doi.org/10.1109/TVCG.2019.2934655", "refList": ["10.1016/j.newast.2010.07.009", "10.1109/tvcg.2017.2744459", "10.1109/tvcg.2018.2864503", "10.1145/1029208.1029219", "10.1109/pacificvis.2014.54", "10.1109/tvcg.2018.2829750", "10.1016/j.jvlc.2017.11.004", "10.1109/tcyb.2015.2448236", "10.1016/j.patrec.2017.11.011", "10.1109/tvcg.2015.2505305", "10.1109/vast.2014.7042528", "10.1007/s12650-018-0530-2", "10.1109/tvcg.2018.2816203", "10.1109/tmm.2016.2614220", "10.1109/tvcg.2017.2745180", "10.1109/mcg.2018.2879067", "10.1109/tvcg.2018.2859973", "10.1109/tvcg.2016.2598460", "10.1109/infvis.2005.1532134", "10.1109/tvcg.2018.2851227", "10.1155/2012/920671", "10.1109/vast.2014.7042479", "10.1109/tvcg.2013.228", "10.1109/tvcg.2018.2865077", "10.1016/j.csda.2005.10.001", "10.1109/tvcg.2018.2865028", "10.1109/tvcg.2011.239", "10.1145/3173574.3174237", "10.1007/s13042-016-0603-2", "10.1109/tvcg.2018.2865020", "10.1017/s1041610219000024", "10.1109/2945.981848", "10.1109/tvcg.2010.193", "10.1109/tvcg.2018.2802520", "10.1145/3200766", "10.1109/wcncw.2015.7122557", "10.1145/3006299.3006312", "10.1109/icsssm.2007.4280175", "10.1126/science.1242072", "10.1109/tvcg.2017.2744098", "10.1109/tvcg.2015.2467196", "10.1109/tvcg.2016.2598619", "10.1109/tvcg.2016.2598664", "10.1109/tvcg.2013.196", "10.1109/comst.2016.2631080", "10.1109/tvcg.2018.2865029", "10.1007/s10816-016-9307-x", "10.1109/tvcg.2008.166", "10.1109/tvcg.2017.2758362", "10.1109/vizsec.2005.1532072", "10.1518/001872095779049543", "10.1109/tvcg.2007.70415", "10.1016/j.ins.2018.01.013", "10.1109/tvcg.2014.2346911", "10.1109/mim.2013.6616284", "10.1109/jsyst.2014.2358997", "10.1111/cgf.12910", "10.1109/isi.2009.5137305", "10.1109/tvcg.2011.179", "10.1007/s11277-015-2631-8", "10.1111/cgf.12396", "10.1109/tvcg.2013.2297933", "10.1109/tvcg.2014.2346926", "10.1109/tvcg.2014.2346913", "10.1109/pacificvis.2018.00030", "10.1109/tvcg.2014.2346433", "10.1109/tvcg.2016.2614803"], "wos": 1, "children": [{"doi": "10.1109/tvcg.2020.3030443", "title": "CAVA: A Visual Analytics System for Exploratory Columnar Data Augmentation Using Knowledge Graphs", "year": "2020", "conferenceName": "VAST", "authors": "Dylan Cashman;Shenyu Xu;Subhajit Das;Florian Heimerl;Cong Liu;Shah Rukh Humayoun;Michael Gleicher;Alex Endert;Remco Chang", "citationCount": "0", "affiliation": "Cashman, D (Corresponding Author), Tufts Univ, Medford, MA 02155 USA. Cashman, Dylan; Liu, Cong; Chang, Remco, Tufts Univ, Medford, MA 02155 USA. Xu, Shenyu; Das, Subhajit; Endert, Alex, Georgia Tech, Atlanta, GA USA. Heimerl, Florian; Gleicher, Michael, Univ Wisconsin, Madison, WI 53706 USA. Humayoun, Shah Rukh, San Francisco State Univ, San Francisco, CA 94132 USA.", "countries": "USA", "abstract": "Most visual analytics systems assume that all foraging for data happens before the analytics process; once analysis begins, the set of data attributes considered is fixed. Such separation of data construction from analysis precludes iteration that can enable foraging informed by the needs that arise in-situ during the analysis. The separation of the foraging loop from the data analysis tasks can limit the pace and scope of analysis. In this paper, we present CAVA, a system that integrates data curation and data augmentation with the traditional data exploration and analysis tasks, enabling information foraging in-situ during analysis. Identifying attributes to add to the dataset is difficult because it requires human knowledge to determine which available attributes will be helpful for the ensuing analytical tasks. CAVA crawls knowledge graphs to provide users with a a broad set of attributes drawn from external data to choose from. Users can then specify complex operations on knowledge graphs to construct additional attributes. CAVA shows how visual analytics can help users forage for attributes by letting users visually explore the set of available data, and by serving as an interface for query construction. It also provides visualizations of the knowledge graph itself to help users understand complex joins such as multi-hop aggregations. We assess the ability of our system to enable users to perform complex data combinations without programming in a user study over two datasets. We then demonstrate the generalizability of CAVA through two additional usage scenarios. The results of the evaluation confirm that CAVA is effective in helping the user perform data foraging that leads to improved analysis outcomes, and offer evidence in support of integrating data augmentation as a part of the visual analytics pipeline.", "keywords": "Visual Analytics,Information Foraging,Data Augmentation", "link": "http://dx.doi.org/10.1109/TVCG.2020.3030443", "refList": ["10.1057/palgrave.ivs.9500122", "10.1109/tvcg.2016.2598867", "10.1111/cgf.13708", "10.1109/tvcg.2019.2934799", "10.1109/tvcg.2019.2934541", "10.1109/tvcg.2013.65", "10.1109/tvcg.2018.2875702", "10.1109/iv.2004.1320207", "10.1068/p260471", "10.1145/1778765.1778816", "10.1109/tvcg.2018.2808489", "10.1109/tvcg.2018.2864912", "10.1016/j.apgeog.2015.12.006", "10.1111/j.1467-8659.2011.01960.x", "10.1109/tvcg.2018.2864843", "10.1109/pacificvis.2010.5429604", "10.1109/tvcg.2014.2346898", "10.1109/5.726791", "10.1177/1475090214540874", "10.1109/icde.2016.7498287", "10.1145/1556262.1556289", "10.1109/tvcg.2007.70535", "10.1109/vast.2012.6400489", "10.1145/1056808.1056914", "10.1016/j.neucom.2014.09.063", "10.1145/7529.8927", "10.1109/tvcg.2016.2598495", "10.1109/tvcg.2016.2607204", "10.1109/vast47406.2019.8986943", "10.3758/bf03205986", "10.1109/infvis.2005.1532142", "10.1145/1150402.1150479", "10.1109/tvcg.2017.2674978", "10.1109/tvcg.2019.2945960", "10.1109/tvcg.2017.2744098", "10.1109/tvcg.2017.2674999", "10.1109/tvcg.2011.279", "10.1109/tvcg.2014.2346594", "10.1109/tvcg.2017.2744184", "10.1111/cgf.12876", "10.1007/s4095-020-0191-7", "10.1007/s11390-015-1535-0", "10.1111/cgf.12640", "10.1109/tvcg.2016.2598667", "10.1111/cgf.13683", "10.1109/tvcg.2013.153", "10.1109/tvcg.2019.2934208", "10.1109/tvcg.2019.2934655", "10.1111/cgf.12655", "10.1007/s11023-010-9221-z", "10.1109/vast.2012.6400487", "10.1145/2702123.2702585", "10.1007/bf00310175", "10.1109/tvcg.2017.2744378", "10.1103/physreve.64.061907", "10.1109/ldav.2017.8231848", "10.1109/tvcg.2016.2598831"], "wos": 1, "children": [], "len": 1}, {"doi": "10.1109/tvcg.2020.3030432", "title": "Evaluation of Sampling Methods for Scatterplots", "year": "2020", "conferenceName": "VAST", "authors": "Jun Yuan;Shouxing Xiang;Jiazhi Xia;Lingyun Yu;Shixia Liu", "citationCount": "0", "affiliation": "Liu, SX (Corresponding Author), Tsinghua Univ, BNRist, Beijing, Peoples R China. Yuan, Jun; Xiang, Shouxing; Liu, Shixia, Tsinghua Univ, BNRist, Beijing, Peoples R China. Xia, Jiazhi, Cent South Univ, Changsha, Peoples R China. Yu, Lingyun, Xian Jiaotong Liverpool Univ, Suzhou, Peoples R China.", "countries": "China", "abstract": "Given a scatterplot with tens of thousands of points or even more, a natural question is which sampling method should be used to create a small but \u201cgood\u201d scatterplot for a better abstraction. We present the results of a user study that investigates the influence of different sampling strategies on multi-class scatterplots. The main goal of this study is to understand the capability of sampling methods in preserving the density, outliers, and overall shape of a scatterplot. To this end, we comprehensively review the literature and select seven typical sampling strategies as well as eight representative datasets. We then design four experiments to understand the performance of different strategies in maintaining: 1) region density; 2) class density; 3) outliers; and 4) overall shape in the sampling results. The results show that: 1) random sampling is preferred for preserving region density; 2) blue noise sampling and random sampling have comparable performance with the three multi-class sampling strategies in preserving class density; 3) outlier biased density based sampling, recursive subdivision based sampling, and blue noise sampling perform the best in keeping outliers; and 4) blue noise sampling outperforms the others in maintaining the overall shape of a scatterplot.", "keywords": "Scatterplot,data sampling,empirical evaluation", "link": "http://dx.doi.org/10.1109/TVCG.2020.3030432", "refList": ["10.1057/palgrave.ivs.9500122", "10.1109/tvcg.2016.2598867", "10.1109/tvcg.2015.2467591", "10.1111/cgf.13708", "10.1109/tvcg.2019.2934799", "10.1109/tvcg.2019.2934541", "10.1109/tvcg.2013.65", "10.1109/iv.2004.1320207", "10.1068/p260471", "10.1145/1778765.1778816", "10.1109/tvcg.2018.2808489", "10.1109/tvcg.2018.2864912", "10.1016/j.apgeog.2015.12.006", "10.1111/j.1467-8659.2011.01960.x", "10.1109/tvcg.2018.2864843", "10.1109/pacificvis.2010.5429604", "10.1109/tvcg.2014.2346898", "10.1109/5.726791", "10.1177/1475090214540874", "10.1145/1556262.1556289", "10.1109/tvcg.2007.70535", "10.1109/vast.2012.6400489", "10.1145/1056808.1056914", "10.1016/j.neucom.2014.09.063", "10.1145/7529.8927", "10.1109/tvcg.2016.2607204", "10.1109/vast47406.2019.8986943", "10.3758/bf03205986", "10.1109/infvis.2005.1532142", "10.1145/1150402.1150479", "10.1109/tvcg.2017.2674978", "10.1109/tvcg.2017.2744098", "10.1109/tvcg.2017.2674999", "10.1109/tvcg.2011.279", "10.1109/tvcg.2014.2346594", "10.1109/tvcg.2017.2744184", "10.1111/cgf.12876", "10.1109/1011101.2019.2945960", "10.1007/s4095-020-0191-7", "10.1007/s11390-015-1535-0", "10.1111/cgf.12640", "10.1109/tvcg.2016.2598667", "10.1111/cgf.13683", "10.1109/tvcg.2013.153", "10.1109/tvcg.2019.2934208", "10.1109/tvcg.2019.2934655", "10.1111/cgf.12655", "10.1007/s11023-010-9221-z", "10.1109/vast.2012.6400487", "10.1145/2702123.2702585", "10.1007/bf00310175", "10.1109/tvcg.2017.2744378", "10.1103/physreve.64.061907", "10.1109/ldav.2017.8231848", "10.1109/tvcg.2016.2598831"], "wos": 1, "children": [], "len": 1}], "len": 5}, {"doi": "10.1109/tvcg.2020.3030443", "title": "CAVA: A Visual Analytics System for Exploratory Columnar Data Augmentation Using Knowledge Graphs", "year": "2020", "conferenceName": "VAST", "authors": "Dylan Cashman;Shenyu Xu;Subhajit Das;Florian Heimerl;Cong Liu;Shah Rukh Humayoun;Michael Gleicher;Alex Endert;Remco Chang", "citationCount": "0", "affiliation": "Cashman, D (Corresponding Author), Tufts Univ, Medford, MA 02155 USA. Cashman, Dylan; Liu, Cong; Chang, Remco, Tufts Univ, Medford, MA 02155 USA. Xu, Shenyu; Das, Subhajit; Endert, Alex, Georgia Tech, Atlanta, GA USA. Heimerl, Florian; Gleicher, Michael, Univ Wisconsin, Madison, WI 53706 USA. Humayoun, Shah Rukh, San Francisco State Univ, San Francisco, CA 94132 USA.", "countries": "USA", "abstract": "Most visual analytics systems assume that all foraging for data happens before the analytics process; once analysis begins, the set of data attributes considered is fixed. Such separation of data construction from analysis precludes iteration that can enable foraging informed by the needs that arise in-situ during the analysis. The separation of the foraging loop from the data analysis tasks can limit the pace and scope of analysis. In this paper, we present CAVA, a system that integrates data curation and data augmentation with the traditional data exploration and analysis tasks, enabling information foraging in-situ during analysis. Identifying attributes to add to the dataset is difficult because it requires human knowledge to determine which available attributes will be helpful for the ensuing analytical tasks. CAVA crawls knowledge graphs to provide users with a a broad set of attributes drawn from external data to choose from. Users can then specify complex operations on knowledge graphs to construct additional attributes. CAVA shows how visual analytics can help users forage for attributes by letting users visually explore the set of available data, and by serving as an interface for query construction. It also provides visualizations of the knowledge graph itself to help users understand complex joins such as multi-hop aggregations. We assess the ability of our system to enable users to perform complex data combinations without programming in a user study over two datasets. We then demonstrate the generalizability of CAVA through two additional usage scenarios. The results of the evaluation confirm that CAVA is effective in helping the user perform data foraging that leads to improved analysis outcomes, and offer evidence in support of integrating data augmentation as a part of the visual analytics pipeline.", "keywords": "Visual Analytics,Information Foraging,Data Augmentation", "link": "http://dx.doi.org/10.1109/TVCG.2020.3030443", "refList": ["10.1057/palgrave.ivs.9500122", "10.1109/tvcg.2016.2598867", "10.1111/cgf.13708", "10.1109/tvcg.2019.2934799", "10.1109/tvcg.2019.2934541", "10.1109/tvcg.2013.65", "10.1109/tvcg.2018.2875702", "10.1109/iv.2004.1320207", "10.1068/p260471", "10.1145/1778765.1778816", "10.1109/tvcg.2018.2808489", "10.1109/tvcg.2018.2864912", "10.1016/j.apgeog.2015.12.006", "10.1111/j.1467-8659.2011.01960.x", "10.1109/tvcg.2018.2864843", "10.1109/pacificvis.2010.5429604", "10.1109/tvcg.2014.2346898", "10.1109/5.726791", "10.1177/1475090214540874", "10.1109/icde.2016.7498287", "10.1145/1556262.1556289", "10.1109/tvcg.2007.70535", "10.1109/vast.2012.6400489", "10.1145/1056808.1056914", "10.1016/j.neucom.2014.09.063", "10.1145/7529.8927", "10.1109/tvcg.2016.2598495", "10.1109/tvcg.2016.2607204", "10.1109/vast47406.2019.8986943", "10.3758/bf03205986", "10.1109/infvis.2005.1532142", "10.1145/1150402.1150479", "10.1109/tvcg.2017.2674978", "10.1109/tvcg.2019.2945960", "10.1109/tvcg.2017.2744098", "10.1109/tvcg.2017.2674999", "10.1109/tvcg.2011.279", "10.1109/tvcg.2014.2346594", "10.1109/tvcg.2017.2744184", "10.1111/cgf.12876", "10.1007/s4095-020-0191-7", "10.1007/s11390-015-1535-0", "10.1111/cgf.12640", "10.1109/tvcg.2016.2598667", "10.1111/cgf.13683", "10.1109/tvcg.2013.153", "10.1109/tvcg.2019.2934208", "10.1109/tvcg.2019.2934655", "10.1111/cgf.12655", "10.1007/s11023-010-9221-z", "10.1109/vast.2012.6400487", "10.1145/2702123.2702585", "10.1007/bf00310175", "10.1109/tvcg.2017.2744378", "10.1103/physreve.64.061907", "10.1109/ldav.2017.8231848", "10.1109/tvcg.2016.2598831"], "wos": 1, "children": [], "len": 1}, {"doi": "10.1109/tvcg.2020.3030440", "title": "Context-aware Sampling of Large Networks via Graph Representation Learning", "year": "2020", "conferenceName": "InfoVis", "authors": "Zhiguang Zhou;Chen Shi;Xilong Shen;Lihong Cai;Haoxuan Wang;Yuhua Liu;Ying Zhao;Wei Chen", "citationCount": "0", "affiliation": "Zhao, Y (Corresponding Author), Cent South Univ, Changsha, Peoples R China. Chen, W (Corresponding Author), Zhejiang Univ, State Key Lab CAD \\& CG, Hangzhou, Peoples R China. Zhou, Zhiguang; Shi, Chen; Shen, Xilong; Cai, Lihong; Wang, Haoxuan; Liu, Yuhua, Zhejiang Univ Finance \\& Econ, Sch Informat, Hangzhou, Peoples R China. Zhao, Ying, Cent South Univ, Changsha, Peoples R China. Chen, Wei, Zhejiang Univ, State Key Lab CAD \\& CG, Hangzhou, Peoples R China.", "countries": "China", "abstract": "Numerous sampling strategies have been proposed to simplify large-scale networks for highly readable visualizations. It is of great challenge to preserve contextual structures formed by nodes and edges with tight relationships in a sampled graph, because they are easily overlooked during the process of sampling due to their irregular distribution and immunity to scale. In this paper, a new graph sampling method is proposed oriented to the preservation of contextual structures. We first utilize a graph representation learning (GRL) model to transform nodes into vectors so that the contextual structures in a network can be effectively extracted and organized. Then, we propose a multi-objective blue noise sampling model to select a subset of nodes in the vectorized space to preserve contextual structures with the retention of relative data and cluster densities in addition to those features of significance, such as bridging nodes and graph connections. We also design a set of visual interfaces enabling users to interactively conduct context-aware sampling, visually compare results with various sampling strategies, and deeply explore large networks. Case studies and quantitative comparisons based on real-world datasets have demonstrated the effectiveness of our method in the abstraction and exploration of large networks.", "keywords": "Graph sampling,Graph representation learning,Blue noise sampling,Graph evaluation", "link": "http://dx.doi.org/10.1109/TVCG.2020.3030440", "refList": ["10.1145/2491159.2491168", "10.1016/j.physa.2015.04.035", "10.1145/1830252.1830274", "10.1109/icdmw.2007.91", "10.1002/net.21834", "10.1109/tvcg.2018.2864503", "10.1016/j.cag.2018.01.010", "10.1109/icc.2016.7511156", "10.1111/cgf.13444", "10.1145/956750.956831", "10.1145/364099.364331", "10.1007/s00180-016-0663-5", "10.1109/tvcg.2013.223", "10.1007/s12650-018-0530-2", "10.1103/physreve.73.016102", "10.1109/access.2018.2870684", "10.1007/978-3-319-06793-3\\_1", "10.2312/vissym/eurovis05/239-246", "10.1016/j.ins.2015.02.014", "10.1145/2339530.2339723", "10.1109/icde.2015.7113345", "10.1109/tvcg.2011.233", "10.14778/2809974.2809980", "10.1109/glocom.2015.7417471", "10.1145/2578153.2578175", "10.1214/aoms/1177705148", "10.1109/tvcg.2008.130", "10.14232/actacyb.20.1.2011.6", "10.1504/ijitm.2019.099809", "10.1109/tvcg.2018.2865020", "10.1145/956750", "10.1002/cpe.4330060203", "10.1145/1150402.1150479", "10.1103/physreve.72.036118", "10.1109/tvcg.2017.2744098", "10.1145/2020408.2020512", "10.1142/s0129183114400075", "10.1109/jsac.2011.111005", "10.1016/j.camwa.2011.11.057", "10.1145/2470654.2466444", "10.1109/tvcg.2017.2674999", "10.1214/aos/1013203451", "10.1109/icdcsw.2011.34", "10.1016/j.physa.2013.11.015", "10.1145/1081870.1081893", "10.1109/tnet.2008.2001730", "10.1109/access.2016.2633485", "10.1145/1879141.1879192", "10.1371/journal.pone.0098679", "10.1126/science.220.4598.671", "10.1109/pacificvis.2015.7156355", "10.1088/1475-7516/2011/08/011", "10.1007/978-3-319-27261-0\\_41", "10.1111/cgf.13410", "10.1109/tvcg.2018.2865139", "10.1109/tvcg.2016.2598831", "10.1016/j.physa.2014.06.065"], "wos": 1, "children": [], "len": 1}, {"doi": "10.1109/tvcg.2020.3030432", "title": "Evaluation of Sampling Methods for Scatterplots", "year": "2020", "conferenceName": "VAST", "authors": "Jun Yuan;Shouxing Xiang;Jiazhi Xia;Lingyun Yu;Shixia Liu", "citationCount": "0", "affiliation": "Liu, SX (Corresponding Author), Tsinghua Univ, BNRist, Beijing, Peoples R China. Yuan, Jun; Xiang, Shouxing; Liu, Shixia, Tsinghua Univ, BNRist, Beijing, Peoples R China. Xia, Jiazhi, Cent South Univ, Changsha, Peoples R China. Yu, Lingyun, Xian Jiaotong Liverpool Univ, Suzhou, Peoples R China.", "countries": "China", "abstract": "Given a scatterplot with tens of thousands of points or even more, a natural question is which sampling method should be used to create a small but \u201cgood\u201d scatterplot for a better abstraction. We present the results of a user study that investigates the influence of different sampling strategies on multi-class scatterplots. The main goal of this study is to understand the capability of sampling methods in preserving the density, outliers, and overall shape of a scatterplot. To this end, we comprehensively review the literature and select seven typical sampling strategies as well as eight representative datasets. We then design four experiments to understand the performance of different strategies in maintaining: 1) region density; 2) class density; 3) outliers; and 4) overall shape in the sampling results. The results show that: 1) random sampling is preferred for preserving region density; 2) blue noise sampling and random sampling have comparable performance with the three multi-class sampling strategies in preserving class density; 3) outlier biased density based sampling, recursive subdivision based sampling, and blue noise sampling perform the best in keeping outliers; and 4) blue noise sampling outperforms the others in maintaining the overall shape of a scatterplot.", "keywords": "Scatterplot,data sampling,empirical evaluation", "link": "http://dx.doi.org/10.1109/TVCG.2020.3030432", "refList": ["10.1057/palgrave.ivs.9500122", "10.1109/tvcg.2016.2598867", "10.1109/tvcg.2015.2467591", "10.1111/cgf.13708", "10.1109/tvcg.2019.2934799", "10.1109/tvcg.2019.2934541", "10.1109/tvcg.2013.65", "10.1109/iv.2004.1320207", "10.1068/p260471", "10.1145/1778765.1778816", "10.1109/tvcg.2018.2808489", "10.1109/tvcg.2018.2864912", "10.1016/j.apgeog.2015.12.006", "10.1111/j.1467-8659.2011.01960.x", "10.1109/tvcg.2018.2864843", "10.1109/pacificvis.2010.5429604", "10.1109/tvcg.2014.2346898", "10.1109/5.726791", "10.1177/1475090214540874", "10.1145/1556262.1556289", "10.1109/tvcg.2007.70535", "10.1109/vast.2012.6400489", "10.1145/1056808.1056914", "10.1016/j.neucom.2014.09.063", "10.1145/7529.8927", "10.1109/tvcg.2016.2607204", "10.1109/vast47406.2019.8986943", "10.3758/bf03205986", "10.1109/infvis.2005.1532142", "10.1145/1150402.1150479", "10.1109/tvcg.2017.2674978", "10.1109/tvcg.2017.2744098", "10.1109/tvcg.2017.2674999", "10.1109/tvcg.2011.279", "10.1109/tvcg.2014.2346594", "10.1109/tvcg.2017.2744184", "10.1111/cgf.12876", "10.1109/1011101.2019.2945960", "10.1007/s4095-020-0191-7", "10.1007/s11390-015-1535-0", "10.1111/cgf.12640", "10.1109/tvcg.2016.2598667", "10.1111/cgf.13683", "10.1109/tvcg.2013.153", "10.1109/tvcg.2019.2934208", "10.1109/tvcg.2019.2934655", "10.1111/cgf.12655", "10.1007/s11023-010-9221-z", "10.1109/vast.2012.6400487", "10.1145/2702123.2702585", "10.1007/bf00310175", "10.1109/tvcg.2017.2744378", "10.1103/physreve.64.061907", "10.1109/ldav.2017.8231848", "10.1109/tvcg.2016.2598831"], "wos": 1, "children": [], "len": 1}, {"doi": "10.1111/cgf.14034", "year": "2020", "title": "The State of the Art in Enhancing Trust in Machine Learning Models with the Use of Visualizations", "conferenceName": "EuroVis", "authors": "Angelos Chatzimparmpas;Rafael Messias Martins;Ilir Jusufi;Kostiantyn Kucher;Fabrice Rossi;Andreas Kerren", "citationCount": "2", "affiliation": "Chatzimparmpas, A (Corresponding Author), Linnaeus Univ, Dept Comp Sci \\& Media Technol, Vaxjo, Sweden.\nChatzimparmpas, A.; Martins, R. M.; Jusufi, I.; Kucher, K.; Kerren, A., Linnaeus Univ, Dept Comp Sci \\& Media Technol, Vaxjo, Sweden.\nRossi, F., PSL Univ, Univ Paris Dauphine, Ceremade, Paris, France.", "countries": "Sweden;France", "abstract": "Machine learning (ML) models are nowadays used in complex applications in various domains, such as medicine, bioinformatics, and other sciences. Due to their black box nature, however, it may sometimes be hard to understand and trust the results they provide. This has increased the demand for reliable visualization tools related to enhancing trust in ML models, which has become a prominent topic of research in the visualization community over the past decades. To provide an overview and present the frontiers of current research on the topic, we present a State-of-the-Art Report (STAR) on enhancing trust in ML models with the use of interactive visualization. We define and describe the background of the topic, introduce a categorization for visualization techniques that aim to accomplish this goal, and discuss insights and opportunities for future research directions. Among our contributions is a categorization of trust against different facets of interactive ML, expanded and improved from previous research. Our results are investigated from different analytical perspectives: (a) providing a statistical overview, (b) summarizing key findings, (c) performing topic analyses, and (d) exploring the data sets used in the individual papers, all with the support of an interactive web-based survey browser. We intend this survey to be beneficial for visualization researchers whose interests involve making ML models more trustworthy, as well as researchers and practitioners from other disciplines in their search for effective visualization techniques suitable for solving their tasks with confidence and conveying meaning to their data.", "keywords": "trustworthy machine learning; visualization; interpretable machine learning; explainable machine learning", "link": "https://doi.org/10.1111/cgf.14034", "refList": ["10.1109/mcg.2018.2878902", "10.1109/tvcg.2008.153", "10.2312/mlvis.20181130", "10.1109/tvcg.2016.2598828", "10.1145/3290605.3300911", "10.1145/2993901.2993909", "10.2312/mlvis.20191158", "10.1109/tvcg.2016.2598446", "10.1111/j.1467-8659.2009.01475.x", "10.1145/3290605.3300809", "10.1109/pacificvis.2018.00031", "10.1055/s-0029-1216348", "10.1007/978-3-319-90403-0\\_13", "10.1109/tvcg.2017.2745085", "10.1111/j.1467-8659.2011.01938.x", "10.1007/978-3-319-54024-5\\_6", "10.1016/s0167-9473(01)00065-2", "10.1111/cgf.12895", "10.2312/eurovisshort.20141152.17", "10.2312/eurova.20151098.22", "10.1111/cgf.13667", "10.3115/1072228.1072378", "10.1109/tbdata.2018.2877350.16", "10.1109/lars.2009.5418323.25", "10.1109/tvcg.2017.2744878", "10.1016/j.combustflame.2005.09.018", "10.1016/j.cag.2014.01.006", "10.1109/tvcg.2016.2570755", "10.2312/mlvis.20191158.1,19", "10.1518/hfes.46.1.50.30392", "10.1145/3301275.3302280", "10.1145/3351095.3372834.1", "10.1016/s0377-2217(01)00264-8", "10.1111/cgf.13424", "10.1007/978-3-319-23485-4\\_53", "10.1007/978-94-007-0753-5\\_3623", "10.1109/tvcg.2013.101", "10.1111/cgf.12884", "10.1111/j.1467-8659.2010.01835.x", "10.1021/ci9901338", "10.4230/lipics.itcs:2017", "10.1109/mis.2013.24", "10.1109/tvcg.2014.2346482", "10.1109/tvcg.2018.2865230", "10.1073/pnas.1807180116", "10.1109/dsaa.2018.00018", "10.1109/tvcg.2009.153", "10.3115/1219840.1219855", "10.1109/tvcg.2018.2864812", "10.1109/tvcg.2018.2872577", "10.2312/trvis.20191183", "10.1109/cvpr:2004.383", "10.1109/vast.2008.4677350", "10.1145/302979.303001", "10.1109/tvcg.2018.2864499", "10.1111/cgf.13672", "10.1109/tvcg.2014.2346626", "10.23915/distill.00010.18", "10.1109/tvcg.2017.2744805", "10.2312/mlvis:20191160.18", "10.23915/distill:00016", "10.1109/pacificvis.2016.7465260", "10.1111/cgf.13683", "10.23915/distill.00016.19", "10.1145/32906053.300803.22", "10.1109/tvcg.2014.2346574", "10.1177/1473871615600010", "10.1109/tvcg.2016.2598831", "10.1145/3230623", "10.1109/visual.2019.8933744", "10.1145/2993901.2993915", "10.1016/j.visinf.2017.01.006", "10.1145/2993901.2993914", "10.1109/tvcg.2014.2346984", "10.1109/5.726791", "10.23915/distill.00010", "10.1109/tvcg.2018.2864825", "10.2307/2394164", "10.1109/tvcg.2017.2744458", "10.1145/2993901.2993917.28", "10.1111/cgf.13711", "10.1109/tvcg.2016.2598664", "10.2307/2530428", "10.1109/icdar.1997.620583", "10.1109/tvcg.2017.2744718", "10.1111/cgf.13425", "10.1109/tvcg.2019.2903943", "10.1145/1518701.1518895", "10.1109/tvcg.2018.2864838", "10.1145/62038.62043", "10.1111/j.1467-8659.2011.01920.x", "10.1145/3025171.3025208", "10.1145/355112.355124", "10.1109/vast.2010.5652398", "10.1109/tvcg.2014.2346578", "10.1145/3173574.3174209", "10.4178/epih/e2014008", "10.1109/beliv.2018.8634201.25,28", "10.1016/j.eswa.2007.12.020", "10.1111/cgf:13406", "10.1109/mcg.2011.103", "10.1631/fitee.1700808", "10.1109/tvcg.2017.2745158", "10.1073/pnas.0307752101", "10.1109/tvcg.2018.2816223", "10.1109/tvcg.2017.2745141", "10.1145/32232.32234", "10.1109/tvcg.2019.2934267", "10.1109/tvcg.2018.2864477", "10.1145/3132169", "10.2312/eurova.20151100.19", "10.1145/3172944.3172964", "10.1145/2601248.2601268", "10.1109/isai-nlp.2018.8693002.1", "10.1111/cgf.13404", "10.1007/s100320200071", "10.2312/trvis.20191183.16", "10.1111/cgf.12755", "10.1145/2702123.2702509", "10.1145/1401890.1402008.25", "10.1109/tvcg.2012.65", "10.1177/1473871617733996", "10.2312/trvis.20191187.7", "10.21236/ada273556", "10.1109/vast.2010.5652450", "10.1111/j.1467-8659.2011.01940.x", "10.1177/875647939000600106", "10.1109/tvcg.2017.2711030", "10.1016/j.immuni.2016.04.014", "10.1109/tvcg.2019.2934209", "10.1016/0095-0696(78)90006-2", "10.1016/j.jclinepi.2015.04.014", "10.1016/j.ress.2013.02.013", "10.1111/cgf.12640", "10.1145/1015330.1015388.25", "10.1111/j.1467-8659.2009.01468.x", "10.1145/1541880.1541882", "10.1109/vast.2011.6102453", "10.1016/s0008-8846(98)00165-3", "10.2312/trvis.20191186.7", "10.1007/s13748-013-0040-3", "10.1109/tvcg.2015.2467757", "10.1109/tbdata.2018.2877350", "10.1109/vast.2017.8585613", "10.1080/10556789208805504", "10.1109/vast.2012.6400484", "10.1145/3025171.3025181", "10.1007/978-3-319-90403-0\\_12", "10.1109/mcg.2019.2922592", "10.1021/ci000392t", "10.1109/vast.2007.4389000", "10.1111/cgf.13406.16", "10.1111/cgf.13684", "10.2312/eurovisshort.20161166.17", "10.2312/evs:20191168", "10.1145/3041021.3055135", "10.1145/3301275.3302265", "10.1613/jair.4135", "10.1109/tvcg.2018.2864500", "10.1109/tvcg.2017.2744158", "10.1109/ssci.2015.33", "10.1111/cgf.13453", "10.2312/pe/eurovast/eurova11/049-052", "10.1145/3025171.3025181.13", "10.1145/371920.372094", "10.1109/tvcg.2017.2744938", "10.1111/j.1467-8659.2012.03108.x", "10.1109/tvcg.2019.2934251", "10.1145/3290605.3300809.18", "10.1109/ldav.2016.7874305", "10.1109/vast.2016.7883514", "10.1109/iccv.2015.425", "10.1145/3301275.3302324", "10.1109/tnnls.2013.2292894", "10.1109/tvcg.2018.2865044", "10.1109/tvcg.2013.157", "10.1371/journal.pcbi.0020161", "10.1186/s12916-019-1426-2", "10.1109/10.867928", "10.1111/cgf.13217", "10.1109/mcg.2019.2919033", "10.1145/2993901.2993910", "10.1109/tvcg.2017.2744738", "10.2307/258792", "10.1111/cgf.12655", "10.1016/j.dss.2014.03.001", "10.1109/tvcg.2019.2904069", "10.1111/cgf.13205", "10.1002/mds.22340", "10.1109/tvcg.2019.2934595", "10.1287/inte.2018.0957", "10.1109/cvpr.2007.382974", "10.1109/tvcg.2012.280", "10.1145/2678025.2701399.13", "10.2312/mlvis.20181130.13", "10.2312/eurova.20181106.16", "10.1109/tvcg.2018.2864475", "10.2312/mlvis.20191160.18,22", "10.1007/978-1-4612-4026-6.25", "10.1109/cvpr.2006.42", "10.1145/3172944.3172950", "10.1109/cvpr.2004.383.25", "10.1109/tvcg.2019.2934812", "10.1609/aimag.v35i4.2513", "10.2312/trvis.20191185.7", "10.1111/j.1467-8659.2009.01684.x", "10.1371/journal.pone.0129126", "10.1111/cgf.13092", "10.1162/coli\\_a\\_00237", "10.1109/tvcg.2017.2744818", "10.1109/vast.2011.6102448", "10.1109/tvcg.2009.111", "10.1109/tvcg.2019.2934619", "10.1016/s0377-2217(01)00264-8.25", "10.1111/cgf.12639", "10.1109/access.2019.2919343", "10.1186/s12874-019-0681-4", "10.1109/pacificvis.2015.7156366", "10.1109/pacificvis.2018.00029", "10.1109/tvcg.2019.2934261", "10.1080/13506280444000102.http://www.uvt.nl/ticc", "10.1109/vast.2018.8802509", "10.1111/cgf.13212", "10.1145/3200489", "10.1111/cgf.13176", "10.1177/1473871620904671", "10.1007/978-3-319-10590-1\\_53", "10.1111/j.1467-8659.2012.03126.x", "10.1111/cgf.13172", "10.1145/3025171.3025208.6,21", "10.1111/cgf.12366", "10.1109/tvcg.2019.2934659", "10.1109/cvprw.2009.5206848", "10.1016/j.media.2014.11.010", "10.1109/tvcg.2017.2744683", "10.1109/tvcg.2019.2934262", "10.1016/j.neucom.2006.11.018", "10.1177/1473871615571951", "10.1371/journal.pcbi.0020161.25", "10.1177/1473871611415994", "10.2312/trvis20191187", "10.2312/eurova", "10.1145/2858036.2858529", "10.1145/2207676.2207738", "10.1007/s11042-009-0417-2", "10.1145/3301275.3302317", "10.1038/s41746-019-0148-3", "10.1145/3351095.3372834", "10.1080/10691898.2011.11889627", "10.1109/tvcg.2018.2864504", "10.1109/vast.2017.8585720", "10.1109/mcg.2018.053491732", "10.1007/s10994-010-5207-6", "10.1109/tvcg.2019.2934433", "10.1016/j.cag.2017.05.005", "10.1109/tvcg.2012.279", "10.1145/3231622.3231641.19,20", "10.1145/1562849.1562851", "10.1007/11564126\\_", "10.1109/tvcg.2018.2846735", "10.3115/1225403.1225421", "10.1109/vast.2012.6400486", "10.2312/eurova.20191116.22", "10.1109/tvcg.2007.70443", "10.1080/027868291009242", "10.2312/eurova.20151100", "10.1145/2939502.2939503.19", "10.1016/j.cag.2014.02.004", "10.1145/2939672.2939778", "10.1109/vast.2010.5652484", "10.1111/cgf.12641", "10.1145/3301275.3302289", "10.1109/visual.2019.8933619", "10.1109/tvcg.2017.2672987", "10.1109/vast.2016.7883517.20", "10.1109/igarss.2017.8127684", "10.1016/j.jcae.2010.04.002", "10.1109/vast.2010.5652885", "10.1016/j.visinf.2019.03.002", "10.1007/s00371-018-1500-3", "10.1109/mcg.2018.042731661", "10.1109/34.598228", "10.1109/tvcg.2018.2865027", "10.1016/j.neucom.2017.01.105", "10.1111/cgf.12389", "10.1109/tvcg.2019.2934591", "10.1109/vast.2010.5652392.16", "10.1111/cgf.13416", "10.1080/02701367.1992.10608764", "10.1109/vast.2017.8585721", "10.1109/tvcg.2018.2843369", "10.1109/sbes.2010.27", "10.1109/vast.2015.7347637", "10.1145/1401890.1402008", "10.1016/j.bpj.2010.04.064", "10.1109/tvcg.2013.125", "10.1109/isai-nlp.2018.8693002", "10.1371/journal.pone.0160127", "10.1145/2856767.2856779", "10.1145/2678025.2701399", "10.1109/vast.2011.6102451", "10.1109/mcg.2010.18", "10.1021/ci4000213", "10.1109/vast.2012.6400492", "10.1007/11564126-49.25", "10.2312/eurova.20171114", "10.1109/vast.2010.5652443", "10.1145/3134599", "10.2312/pe/eurovast/eurovast10/013-018.19", "10.1109/tvcg.2019.2903946", "10.1109/tvcg.2015.2467717", "10.1177/1473871612460526", "10.1016/j.cag.2018.09.018", "10.1109/tvcg.2016.2598838", "10.1145/3172944.3172964.14", "10.1109/vast.2009.5333428", "10.1109/vast.2014.7042480", "10.2312/pe/eurovast/eurovast10/013-018", "10.1177/0962280215588241", "10.1145/2993901.2993917", "10.1109/cvpr.2008:4587581", "10.1109/tvcg.2015.2467551", "10.1016/j.visinf.2018.09.001", "10.1126/science.290.5500.2319", "10.2312/eurova.20151107", "10.1109/visual.2019.8933695", "10.13140/2.1.2393.1847", "10.1197/jamia.m1929", "10.1109/cvpr.2008.4587581.25", "10.1145/1518701.1518895.16", "10.1109/vds.2017.8573444", "10.2312/trvis:20191185", "10.1145/3359786", "10.13140/2.1.1341.1520", "10.2312/pe/eurovast/eurova11/049-052.17", "10.1109/tvcg.2014.2346660", "10.1145/3185517", "10.1109/adprl.2011.5967372", "10.1109/tvcg.2015.2467591", "10.1111/j.1751-9004.2009.00232.x", "10.1136/qshc.2004.010033", "10.1109/vast.2012.6400493", "10.1109/tvcg.2019.2934266", "10.1145/2971763.2971775", "10.1111/cgf.13730", "10.1109/vast.2012.6400488", "10.1111/cgf.13210", "10.1109/tvcg.2019.2934631", "10.1145/3172944.3172965", "10.1057/ivs.2010.2", "10.1109/tvcg.2017.2745258", "10.1016/j.jbusres.2019.07.039", "10.1162/jmlr.2003.3.4-5.993", "10.1109/pacificvis.2019.00044", "10.2312/pe/eurovast/eurova12/037-041", "10.1109/tvcg.2019.2934629", "10.1177/0018720814547570", "10.1145/3292500.3330908", "10.1111/j.1467-8659.2009.01467.x", "10.2312/eurova.20151098", "10.1177/1473871617713337", "10.1109/lars:2009.5418323", "10.1109/vast.2011.6102437", "10.1111/cgf.12878", "10.1561/1500000001", "10.1145/3025171.3025222", "10.1007/s11704-016-6028-y", "10.1016/j.procs.2017.05.216", "10.1109/cvpr.2007.382974.25", "10.1080/10447318.2020.1741118", "10.1109/vast.2012.6400489", "10.1145/3025171.3025172", "10.1109/tvcg.2017.2744098", "10.1109/tvcg.2005.66", "10.1016/j.dss.2009.05.016", "10.1007/978-1-4612-4026-6", "10.2312/evs.20191168.16,20,28", "10.2312/pe/eurovast/eurova12/037-041.17", "10.1145/3290605.3300803", "10.1145/1015330.1015388", "10.1111/cgf.13197", "10.1016/b978-1-55860-377-6.50048-7", "10.1111/cgf.13681", "10.1109/tvcg.2017.2744378", "10.1109/tvcg.2017.2744358", "10.1109/vast.2008.4677352"], "wos": 1, "children": [{"doi": "10.1109/tvcg.2020.3030368", "title": "Implicit Multidimensional Projection of Local Subspaces", "year": "2020", "conferenceName": "InfoVis", "authors": "Rongzheng Bian;Yumeng Xue;Liang Zhou;Jian Zhang 0070;Baoquan Chen;Daniel Weiskopf;Yunhai Wang", "citationCount": "1", "affiliation": "Wang, YH (Corresponding Author), Shandong Univ, Qingdao, Peoples R China. Zhou, L (Corresponding Author), Univ Utah, Salt Lake City, UT 84112 USA. Bian, Rongzheng; Xue, Yumeng; Wang, Yunhai, Shandong Univ, Qingdao, Peoples R China. Chen, Baoquan, Peking Univ, Beijing, Peoples R China. Zhang, Jian, Chinese Acad Sci, CNIC, Beijing, Peoples R China. Zhou, Liang, Univ Utah, Salt Lake City, UT 84112 USA. Weiskopf, Daniel, Univ Stuttgart, Stuttgart, Germany.", "countries": "USA;Germany;China", "abstract": "We propose a visualization method to understand the effect of multidimensional projection on local subspaces, using implicit function differentiation. Here, we understand the local subspace as the multidimensional local neighborhood of data points. Existing methods focus on the projection of multidimensional data points, and the neighborhood information is ignored. Our method is able to analyze the shape and directional information of the local subspace to gain more insights into the global structure of the data through the perception of local structures. Local subspaces are fitted by multidimensional ellipses that are spanned by basis vectors. An accurate and efficient vector transformation method is proposed based on analytical differentiation of multidimensional projections formulated as implicit functions. The results are visualized as glyphs and analyzed using a full set of specifically-designed interactions supported in our efficient web-based visualization tool. The usefulness of our method is demonstrated using various multi- and high-dimensional benchmark datasets. Our implicit differentiation vector transformation is evaluated through numerical comparisons; the overall method is evaluated through exploration examples and use cases.", "keywords": "High-dimensional data visualization,dimensionality reduction,local linear subspaces,user interaction", "link": "http://dx.doi.org/10.1109/TVCG.2020.3030368", "refList": ["10.3844/jcssp.2018.613.622", "10.1016/j.aci.2018.08.003", "10.3390/info9030065", "10.1016/j.visinf.2018.09.003", "10.1371/journal.pone.0118432", "10.1016/s0893-6080(05)80023-1", "10.1109/tvcg.2020.2986996", "10.1109/icst.2012.56", "10.1007/s10844-013-0250-y", "10.1109/tbdata.2018", "10.1145/1125451.1125659", "10.1109/tvcg.2013.125", "10.1177/1473871611412817", "10.1145/3290605.3300911", "10.1111/cgf.14034", "10.1007/s13721-013-0034-x", "10.1016/j.procs.2017.05.216", "10.1016/j.ins.2009.08.025", "10.1109/tvcg.2013.124", "10.1109/tvcg.2018.2864499", "10.1109/tvcg.2018.2864475", "10.1080/10447318.2020.1741118", "10.1016/j.imu.2019.100203", "10.1109/tvcg.2018.2865240", "10.1186/s12864-019-6413-7", "10.1109/tvcg.2015.2467551", "10.1002/widm.1249", "10.1007/978-3-319-66429-3\\_29", "10.1109/tvcg.2014.2346481", "10.1109/tvcg.2018.2864825", "10.1177/1473871620904671", "10.1109/tvcg.2019.2934267", "10.1136/bmjopen-2016-012799", "10.1109/smartgridcomm.2017.8340682", "10.1007/s10664-015-9401-9", "10.1145/1143844.1143874", "10.1111/cgf.12389", "10.1109/tvcg.2018.2872577", "10.1007/978-981-13-5802-9\\_20", "10.1016/j.ipm.2009.03.002", "10.5220/0006431602160222", "10.1109/mcg.2015.50", "10.1109/tvcg.2014.2346574", "10.1007/bf02289565", "10.1109/tvcg.2017.2744378", "10.1016/j.patrec.2008.08.010", "10.1023/a:1010933404324", "10.9735/2229-3981"], "wos": 1, "children": [], "len": 1}, {"doi": "10.1109/tvcg.2020.3030465", "title": "Visual Causality Analysis of Event Sequence Data", "year": "2020", "conferenceName": "VAST", "authors": "Zhuochen Jin;Shunan Guo;Nan Chen;Daniel Weiskopf;David Gotz;Nan Cao", "citationCount": "0", "affiliation": "Cao, N (Corresponding Author), Tongji Univ, IDVx Lab, Shanghai, Peoples R China. Jin, Zhuochen; Guo, Shunan; Chen, Nan; Cao, Nan, Tongji Univ, IDVx Lab, Shanghai, Peoples R China. Weiskopf, Daniel, Univ Stuttgart, Stuttgart, Germany. Gotz, David, Univ N Carolina, Chapel Hill, NC 27515 USA.", "countries": "USA;Germany;China", "abstract": "Causality is crucial to understanding the mechanisms behind complex systems and making decisions that lead to intended outcomes. Event sequence data is widely collected from many real-world processes, such as electronic health records, web clickstreams, and financial transactions, which transmit a great deal of information reflecting the causal relations among event types. Unfortunately, recovering causalities from observational event sequences is challenging, as the heterogeneous and high-dimensional event variables are often connected to rather complex underlying event excitation mechanisms that are hard to infer from limited observations. Many existing automated causal analysis techniques suffer from poor explainability and fail to include an adequate amount of human knowledge. In this paper, we introduce a visual analytics method for recovering causalities in event sequence data. We extend the Granger causality analysis algorithm on Hawkes processes to incorporate user feedback into causal model refinement. The visualization system includes an interactive causal analysis framework that supports bottom-up causal exploration, iterative causal verification and refinement, and causal comparison through a set of novel visualizations and interactions. We report two forms of evaluation: a quantitative evaluation of the model improvements resulting from the user-feedback mechanism, and a qualitative evaluation through case studies in different application domains to demonstrate the usefulness of the system.", "keywords": "Event sequence data,causality analysis,visual analytics", "link": "http://dx.doi.org/10.1109/TVCG.2020.3030465", "refList": ["10.5555/1642718", "10.1109/tvcg.2018.2865022", "10.5555/2074094.2074151", "10.1109/tvcg.2016.2618797", "10.1073/pnas.1320645111", "10.1109/tvcg.2017.2744843", "10.1109/iv.2017.69", "10.1109/tvcg.2019.2934399", "10.1145/3172944.3173007", "10.5555/1795555", "10.1109/mcg.2005.102", "10.1145/381641.381653", "10.1162/153244301753344614", "10.1111/cgf.14034", "10.1111/cgf.13198", "10.1017/cbo9780511519857", "10.1007/s10462-016-9475-9", "10.1075/ssol.2.2.07bor", "10.1007/978-1-4614-3223-4\\_3", "10.1109/infvis.2003.1249025", "10.1007/978-94-007-6094-313", "10.1145/2858036.2858387", "10.1109/tvcg.2007.70528", "10.1109/tvcg.2017.2674958", "10.1147/sj.454.0801", "10.1109/tvcg.2013.119", "10.1145/3173574.3173711", "10.1016/j.erss.2017.06.034", "10.1109/visual.2019.8933695", "10.1007/s11665-016-2173-6", "10.1016/0377-0427(87)90125-7", "10.2307/3601125", "10.1016/b978-0-444-88738-2.50018-x", "10.1109/mcg.2006.70", "10.1109/tvcg.2018.2865145", "10.1017/s1351324997001502", "10.1109/tvcg.2010.179", "10.1214/aos/1176344552", "10.1109/mcg.2009.22", "10.1007/978-3-319-26633-6\\_13", "10.1080/10447318.2014.905422", "10.1016/j.visinf.2019.03.004", "10.1057/palgrave.ivs.9500074", "10.1007/978-1-4614-3223-4"], "wos": 1, "children": [], "len": 1}], "len": 5}], "len": 55}, {"doi": "10.1109/tvcg.2018.2865020", "title": "Evaluating Multi-Dimensional Visualizations for Understanding Fuzzy Clusters", "year": "2018", "conferenceName": "VAST", "authors": "Ying Zhao;Feng Luo;Minghui Chen;Yingchao Wang;Jiazhi Xia;Fangfang Zhou;Yunhai Wang;Yi Chen 0007;Wei Chen", "citationCount": "10", "affiliation": "Xia, JZ (Corresponding Author), Cent S Univ, Changsha, Hunan, Peoples R China. Chen, W (Corresponding Author), Zhejiang Univ, State Key Lab CAD \\& CG, Hangzhou, Zhejiang, Peoples R China. Zhao, Ying; Luo, Feng; Chen, Minghui; Wang, Yingchao; Xia, Jiazhi; Zhou, Fangfang, Cent S Univ, Changsha, Hunan, Peoples R China. Wang, Yunhai, Shandong Univ, Jinan, Shandong, Peoples R China. Chen, Yi, Beijing Technol \\& Business Univ, Beijing, Peoples R China. Chen, Wei, Zhejiang Univ, State Key Lab CAD \\& CG, Hangzhou, Zhejiang, Peoples R China.", "countries": "China", "abstract": "Fuzzy clustering assigns a probability of membership for a datum to a cluster, which veritably reflects real-world clustering scenarios but significantly increases the complexity of understanding fuzzy clusters. Many studies have demonstrated that visualization techniques for multi-dimensional data are beneficial to understand fuzzy clusters. However, no empirical evidence exists on the effectiveness and efficiency of these visualization techniques in solving analytical tasks featured by fuzzy clusters. In this paper, we conduct a controlled experiment to evaluate the ability of fuzzy clusters analysis to use four multi-dimensional visualization techniques, namely, parallel coordinate plot, scatterplot matrix, principal component analysis, and Radviz. First, we define the analytical tasks and their representative questions specific to fuzzy clusters analysis. Then, we design objective questionnaires to compare the accuracy, time, and satisfaction in using the four techniques to solve the questions. We also design subjective questionnaires to collect the experience of the volunteers with the four techniques in terms of ease of use, informativeness, and helpfulness. With a complete experiment process and a detailed result analysis, we test against four hypotheses that are formulated on the basis of our experience, and provide instructive guidance for analysts in selecting appropriate and efficient visualization techniques to analyze fuzzy clusters.", "keywords": "Evaluation,multi-dimensional visualization,fuzzy clustering,parallel coordinate plot,scatterplot matrix,principal component analysis,radviz", "link": "http://dx.doi.org/10.1109/TVCG.2018.2865020", "refList": ["10.1007/s00500-006-0111-5", "10.1109/tvcg.2015.2424878", "10.1109/tvcg.2014.2330617", "10.1016/s0019-9958(69)90591-9", "10.1109/fuzzy.2004.1375750", "10.5244/c.8.19", "10.1007/s00371-013-0892-3", "10.1007/b98835", "10.1109/72.363467", "10.1057/palgrave.ivs.9500099", "10.1016/j.ins.2010.08.026", "10.2307/2290001", "10.1109/iv.2009.74", "10.1016/s0377-2217(99)00118-6", "10.1016/0098-3004(84)90020-7", "10.1109/visual.1990.146375", "10.1109/tvcg.2016.2598479", "10.1109/tvcg.2017.2745138", "10.1109/tvcg.2017.2744198", "10.1109/tvcg.2018.2816203", "10.1016/s0019-9958(65)90241-x", "10.1016/s0167-9473(02)00290-6", "10.1145/2702123.2702293", "10.1111/j.1467-8659.2011.01961.x", "10.1109/visual.1997.663916", "10.1111/j.1467-8659.2012.03129.x", "10.1016/s0305-0483(00)00042-6", "10.1057/ivs.2008.13", "10.1109/mcg.2015.97", "10.1109/tvcg.2015.2467324", "10.1109/infvis.2005.1532136", "10.1109/icdm.2014.24", "10.1109/tvcg.2008.173", "10.1109/vast.2010.5652450", "10.1109/isefs.2006.251180", "10.1109/tvcg.2016.2598831", "10.1016/s0925-2312(01)00653-1", "10.1016/j.patcog.2006.02.006", "10.1109/tvcg.2017.2744098", "10.5604/15084183.1197450", "10.1109/tvcg.2009.153", "10.1007/978-1-4757-1904-8", "10.1016/s0148-9062(98)00011-4", "10.1145/3025453.3025882", "10.1016/s0933-3657(98)00069-4", "10.1145/1168149.1168169", "10.1109/tvcg.2013.153", "10.1007/978-3-540-33037-0\\_25", "10.1111/j.1467-8659.2009.01666.x", "10.1109/infvis.1998.729559", "10.1109/tfuzz.2003.812696", "10.1016/s0165-0114(98)00224-3", "10.1109/69.553159"], "wos": 1, "children": [{"doi": "10.1109/tvcg.2019.2934208", "title": "Evaluating Perceptual Bias During Geometric Scaling of Scatterplots", "year": "2019", "conferenceName": "VAST", "authors": "Yating Wei;Honghui Mei;Ying Zhao;Shuyue Zhou;Bingru Lin;Haojing Jiang;Wei Chen", "citationCount": "5", "affiliation": "Chen, W (Corresponding Author), Zhejiang Univ, State Key Lab CAD \\& CG, Hangzhou 310058, Zhejiang, Peoples R China. Zhao, Y (Corresponding Author), Cent South Univ, Sch Comp Sci \\& Engn, Changsha 410083, Hunan, Peoples R China. Wei, Yating; Mei, Honghui; Zhou, Shuyue; Lin, Bingru; Chen, Wei, Zhejiang Univ, State Key Lab CAD \\& CG, Hangzhou 310058, Zhejiang, Peoples R China. Zhao, Ying; Jiang, Haojing, Cent South Univ, Sch Comp Sci \\& Engn, Changsha 410083, Hunan, Peoples R China.", "countries": "China", "abstract": "Scatterplots are frequently scaled to fit display areas in multi-view and multi-device data analysis environments. A common method used for scaling is to enlarge or shrink the entire scatterplot together with the inside points synchronously and proportionally. This process is called geometric scaling. However, geometric scaling of scatterplots may cause a perceptual bias, that is, the perceived and physical values of visual features may be dissociated with respect to geometric scaling. For example, if a scatterplot is projected from a laptop to a large projector screen, then observers may feel that the scatterplot shown on the projector has fewer points than that viewed on the laptop. This paper presents an evaluation study on the perceptual bias of visual features in scatterplots caused by geometric scaling. The study focuses on three fundamental visual features (i.e., numerosity, correlation, and cluster separation) and three hypotheses that are formulated on the basis of our experience. We carefully design three controlled experiments by using well-prepared synthetic data and recruit participants to complete the experiments on the basis of their subjective experience. With a detailed analysis of the experimental results, we obtain a set of instructive findings. First, geometric scaling causes a bias that has a linear relationship with the scale ratio. Second, no significant difference exists between the biases measured from normally and uniformly distributed scatterplots. Third, changing the point radius can correct the bias to a certain extent. These findings can be used to inspire the design decisions of scatterplots in various scenarios.", "keywords": "Evaluation,scatterplot,geometric scaling,bias,perceptual consistency", "link": "http://dx.doi.org/10.1109/TVCG.2019.2934208", "refList": ["10.2307/2288843", "10.1109/tvcg.2017.2744359", "10.1109/tvcg.2015.2467732", "10.1109/tvcg.2014.2346979", "10.1126/science.216.4550.1138", "10.1109/tvcg.2017.2744138", "10.1111/j.1467-8659.2009.01467.x", "10.1145/2491568.2491577", "10.1109/mwc.2018.1700325", "10.1145/2449396.2449439", "10.1109/tvcg.2011.127", "10.1109/tvcg.2011.229", "10.1167/15.5.4", "10.1073/pnas.1113195108", "10.1145/2702123.2702545", "10.1109/vast.2009.5332628", "10.1109/tvcg.2018.2800013", "10.1007/s12650-018-0530-2", "10.1016/s0042-6989(97)00340-4", "10.1109/vast.2010.5652460", "10.1109/mcg.2018.2879067", "10.1109/tvcg.2018.2864912", "10.1109/pacificvis.2010.5429604", "10.1109/tcst.2018.2819965", "10.1167/10.2.10", "10.1145/2470654.2481318", "10.1145/1842993.1843002", "10.1167/12.6.8", "10.1109/tvcg.2013.124", "10.1057/ivs.2008.13", "10.1109/tvcg.2007.70596", "10.1109/tvcg.2018.2865266", "10.1145/3173574.3173664", "10.1109/tvcg.2015.2467671", "10.1016/j.cag.2017.07.004", "10.1177/0956797613501520", "10.1109/tvcg.2018.2865020", "10.1111/j.1467-8659.2012.03125.x", "10.3758/bf03205986", "10.3758/s13423-016-1174-7", "10.1109/tvcg.2017.2680452", "10.1109/mc.2006.109", "10.1109/tvcg.2017.2744098", "10.1038/srep32810", "10.1016/j.visres.2013.06.006", "10.1002/jhbs.20078", "10.1109/tvcg.2006.163", "10.1109/tvcg.2014.2346594", "10.1109/tvcg.2017.2744184", "10.1016/j.cognition.2007.10.009", "10.1109/tvcg.2018.2865142", "10.3758/app.72.7.1839", "10.1109/tvcg.2018.2810918", "10.1016/j.jvlc.2017.10.001", "10.1145/2682623", "10.1109/tvcg.2018.2864884", "10.1145/3025453.3025984", "10.1109/tvcg.2006.184", "10.1109/tvcg.2013.153", "10.1016/j.jvlc.2018.08.003", "10.1109/tvcg.2016.2520921", "10.1111/cgf.13446", "10.1017/s0022381612000187", "10.1145/2702123.2702406", "10.1109/vast.2012.6400487", "10.1109/tvcg.2013.183", "10.1177/1473871611415997", "10.1145/2702123.2702585", "10.1145/2993901.2993903", "10.1109/tvcg.2013.120", "10.1111/cgf.12632", "10.1145/1385569.1385602", "10.1109/tvcg.2017.2754480", "10.1111/j.1467-8659.2009.01694.x"], "wos": 1, "children": [{"doi": "10.1109/tvcg.2020.3030456", "title": "Cartographic Relief Shading with Neural Networks", "year": "2020", "conferenceName": "InfoVis", "authors": "Bernhard Jenny;Magnus Heitzler;Dilpreet Singh;Marianna Farmakis-Serebryakova;Jeffery Chieh Liu;Lorenz Hurni", "citationCount": "4", "affiliation": "Jenny, B (Corresponding Author), Monash Univ, Melbourne, Vic, Australia. Jenny, Bernhard; Singh, Dilpreet; Liu, Jeffery Chieh, Monash Univ, Melbourne, Vic, Australia. Heitzler, Magnus; Farmakis-Serebryakova, Marianna; Hurni, Lorenz, Swiss Fed Inst Technol, Inst Cartog \\& Geoinformat, Zurich, Switzerland.", "countries": "Switzerland;Australia", "abstract": "Shaded relief is an effective method for visualising terrain on topographic maps, especially when the direction of illumination is adapted locally to emphasise individual terrain features. However, digital shading algorithms are unable to fully match the expressiveness of hand-crafted masterpieces, which are created through a laborious process by highly specialised cartographers. We replicate hand-drawn relief shading using U-Net neural networks. The deep neural networks are trained with manual shaded relief images of the Swiss topographic map series and terrain models of the same area. The networks generate shaded relief that closely resemble hand-drawn shaded relief art. The networks learn essential design principles from manual relief shading such as removing unnecessary terrain details, locally adjusting the illumination direction to accentuate individual terrain features, and varying brightness to emphasise larger landforms. Neural network shadings are generated from digital elevation models in a few seconds, and a study with 18 relief shading experts found that they are of high quality.", "keywords": "Relief shading,shaded relief,hillshade,neural rendering,illustrative visualisation,image-to-image translation", "link": "http://dx.doi.org/10.1109/TVCG.2020.3030456", "refList": ["10.1145/1456650.1456652", "10.1145/1145/1556262.1556270", "10.1145/345513.345271", "10.1109/tvcg.2019.2934803", "10.1145/3180658", "10.1109/tridui.2006.1618264", "10.3389/fict.2018.00015", "10.1109/vr.2018.8447558", "10.1518/hfes.45.1.160.27234", "10.1145/3290605.3300377", "10.1089/cpb.2006.9.157", "10.1007/s00779-011-0500-3", "10.1109/vl.1996.545307", "10.1109/tvcg.2019.2934415", "10.1109/5.726791", "10.1145/3290605.3300288", "10.1109/tvcg.2017.2745941", "10.1109/vr.2001.913779", "10.1145/586081.586086", "10.18637/jss.v067.i01", "10.1145/1502800.1502805", "10.1145/1165734.1165736", "10.1145/3126594.3126613", "10.1109/tvcg.2008.109", "10.1109/tvcg.2017.2744184", "10.1016/j.cola.2019.100937", "10.1109/visual.2019.8933545", "10.1145/3290605.3300555", "10.1111/cgf.13431", "10.1109/tvcg.2019.2934395", "10.1109/vr.2019.8798340", "10.1145/3025453.3026046", "10.1109/vr.2019.8797871", "10.1145/3290605.3300752", "10.1109/tvcg.2016.2520921", "10.1109/tvcg.2018.2865191", "10.1145/1970378.1970384", "10.1109/tvcg.2019.2934208", "10.18637/jss.v069.i01", "10.1162/105474698565659", "10.1145/1124772.1124775", "10.1109/vrais.1997.583043"], "wos": 1, "children": [], "len": 1}, {"doi": "10.1109/tvcg.2020.3030443", "title": "CAVA: A Visual Analytics System for Exploratory Columnar Data Augmentation Using Knowledge Graphs", "year": "2020", "conferenceName": "VAST", "authors": "Dylan Cashman;Shenyu Xu;Subhajit Das;Florian Heimerl;Cong Liu;Shah Rukh Humayoun;Michael Gleicher;Alex Endert;Remco Chang", "citationCount": "0", "affiliation": "Cashman, D (Corresponding Author), Tufts Univ, Medford, MA 02155 USA. Cashman, Dylan; Liu, Cong; Chang, Remco, Tufts Univ, Medford, MA 02155 USA. Xu, Shenyu; Das, Subhajit; Endert, Alex, Georgia Tech, Atlanta, GA USA. Heimerl, Florian; Gleicher, Michael, Univ Wisconsin, Madison, WI 53706 USA. Humayoun, Shah Rukh, San Francisco State Univ, San Francisco, CA 94132 USA.", "countries": "USA", "abstract": "Most visual analytics systems assume that all foraging for data happens before the analytics process; once analysis begins, the set of data attributes considered is fixed. Such separation of data construction from analysis precludes iteration that can enable foraging informed by the needs that arise in-situ during the analysis. The separation of the foraging loop from the data analysis tasks can limit the pace and scope of analysis. In this paper, we present CAVA, a system that integrates data curation and data augmentation with the traditional data exploration and analysis tasks, enabling information foraging in-situ during analysis. Identifying attributes to add to the dataset is difficult because it requires human knowledge to determine which available attributes will be helpful for the ensuing analytical tasks. CAVA crawls knowledge graphs to provide users with a a broad set of attributes drawn from external data to choose from. Users can then specify complex operations on knowledge graphs to construct additional attributes. CAVA shows how visual analytics can help users forage for attributes by letting users visually explore the set of available data, and by serving as an interface for query construction. It also provides visualizations of the knowledge graph itself to help users understand complex joins such as multi-hop aggregations. We assess the ability of our system to enable users to perform complex data combinations without programming in a user study over two datasets. We then demonstrate the generalizability of CAVA through two additional usage scenarios. The results of the evaluation confirm that CAVA is effective in helping the user perform data foraging that leads to improved analysis outcomes, and offer evidence in support of integrating data augmentation as a part of the visual analytics pipeline.", "keywords": "Visual Analytics,Information Foraging,Data Augmentation", "link": "http://dx.doi.org/10.1109/TVCG.2020.3030443", "refList": ["10.1057/palgrave.ivs.9500122", "10.1109/tvcg.2016.2598867", "10.1111/cgf.13708", "10.1109/tvcg.2019.2934799", "10.1109/tvcg.2019.2934541", "10.1109/tvcg.2013.65", "10.1109/tvcg.2018.2875702", "10.1109/iv.2004.1320207", "10.1068/p260471", "10.1145/1778765.1778816", "10.1109/tvcg.2018.2808489", "10.1109/tvcg.2018.2864912", "10.1016/j.apgeog.2015.12.006", "10.1111/j.1467-8659.2011.01960.x", "10.1109/tvcg.2018.2864843", "10.1109/pacificvis.2010.5429604", "10.1109/tvcg.2014.2346898", "10.1109/5.726791", "10.1177/1475090214540874", "10.1109/icde.2016.7498287", "10.1145/1556262.1556289", "10.1109/tvcg.2007.70535", "10.1109/vast.2012.6400489", "10.1145/1056808.1056914", "10.1016/j.neucom.2014.09.063", "10.1145/7529.8927", "10.1109/tvcg.2016.2598495", "10.1109/tvcg.2016.2607204", "10.1109/vast47406.2019.8986943", "10.3758/bf03205986", "10.1109/infvis.2005.1532142", "10.1145/1150402.1150479", "10.1109/tvcg.2017.2674978", "10.1109/tvcg.2019.2945960", "10.1109/tvcg.2017.2744098", "10.1109/tvcg.2017.2674999", "10.1109/tvcg.2011.279", "10.1109/tvcg.2014.2346594", "10.1109/tvcg.2017.2744184", "10.1111/cgf.12876", "10.1007/s4095-020-0191-7", "10.1007/s11390-015-1535-0", "10.1111/cgf.12640", "10.1109/tvcg.2016.2598667", "10.1111/cgf.13683", "10.1109/tvcg.2013.153", "10.1109/tvcg.2019.2934208", "10.1109/tvcg.2019.2934655", "10.1111/cgf.12655", "10.1007/s11023-010-9221-z", "10.1109/vast.2012.6400487", "10.1145/2702123.2702585", "10.1007/bf00310175", "10.1109/tvcg.2017.2744378", "10.1103/physreve.64.061907", "10.1109/ldav.2017.8231848", "10.1109/tvcg.2016.2598831"], "wos": 1, "children": [], "len": 1}, {"doi": "10.1109/tvcg.2020.3030432", "title": "Evaluation of Sampling Methods for Scatterplots", "year": "2020", "conferenceName": "VAST", "authors": "Jun Yuan;Shouxing Xiang;Jiazhi Xia;Lingyun Yu;Shixia Liu", "citationCount": "0", "affiliation": "Liu, SX (Corresponding Author), Tsinghua Univ, BNRist, Beijing, Peoples R China. Yuan, Jun; Xiang, Shouxing; Liu, Shixia, Tsinghua Univ, BNRist, Beijing, Peoples R China. Xia, Jiazhi, Cent South Univ, Changsha, Peoples R China. Yu, Lingyun, Xian Jiaotong Liverpool Univ, Suzhou, Peoples R China.", "countries": "China", "abstract": "Given a scatterplot with tens of thousands of points or even more, a natural question is which sampling method should be used to create a small but \u201cgood\u201d scatterplot for a better abstraction. We present the results of a user study that investigates the influence of different sampling strategies on multi-class scatterplots. The main goal of this study is to understand the capability of sampling methods in preserving the density, outliers, and overall shape of a scatterplot. To this end, we comprehensively review the literature and select seven typical sampling strategies as well as eight representative datasets. We then design four experiments to understand the performance of different strategies in maintaining: 1) region density; 2) class density; 3) outliers; and 4) overall shape in the sampling results. The results show that: 1) random sampling is preferred for preserving region density; 2) blue noise sampling and random sampling have comparable performance with the three multi-class sampling strategies in preserving class density; 3) outlier biased density based sampling, recursive subdivision based sampling, and blue noise sampling perform the best in keeping outliers; and 4) blue noise sampling outperforms the others in maintaining the overall shape of a scatterplot.", "keywords": "Scatterplot,data sampling,empirical evaluation", "link": "http://dx.doi.org/10.1109/TVCG.2020.3030432", "refList": ["10.1057/palgrave.ivs.9500122", "10.1109/tvcg.2016.2598867", "10.1109/tvcg.2015.2467591", "10.1111/cgf.13708", "10.1109/tvcg.2019.2934799", "10.1109/tvcg.2019.2934541", "10.1109/tvcg.2013.65", "10.1109/iv.2004.1320207", "10.1068/p260471", "10.1145/1778765.1778816", "10.1109/tvcg.2018.2808489", "10.1109/tvcg.2018.2864912", "10.1016/j.apgeog.2015.12.006", "10.1111/j.1467-8659.2011.01960.x", "10.1109/tvcg.2018.2864843", "10.1109/pacificvis.2010.5429604", "10.1109/tvcg.2014.2346898", "10.1109/5.726791", "10.1177/1475090214540874", "10.1145/1556262.1556289", "10.1109/tvcg.2007.70535", "10.1109/vast.2012.6400489", "10.1145/1056808.1056914", "10.1016/j.neucom.2014.09.063", "10.1145/7529.8927", "10.1109/tvcg.2016.2607204", "10.1109/vast47406.2019.8986943", "10.3758/bf03205986", "10.1109/infvis.2005.1532142", "10.1145/1150402.1150479", "10.1109/tvcg.2017.2674978", "10.1109/tvcg.2017.2744098", "10.1109/tvcg.2017.2674999", "10.1109/tvcg.2011.279", "10.1109/tvcg.2014.2346594", "10.1109/tvcg.2017.2744184", "10.1111/cgf.12876", "10.1109/1011101.2019.2945960", "10.1007/s4095-020-0191-7", "10.1007/s11390-015-1535-0", "10.1111/cgf.12640", "10.1109/tvcg.2016.2598667", "10.1111/cgf.13683", "10.1109/tvcg.2013.153", "10.1109/tvcg.2019.2934208", "10.1109/tvcg.2019.2934655", "10.1111/cgf.12655", "10.1007/s11023-010-9221-z", "10.1109/vast.2012.6400487", "10.1145/2702123.2702585", "10.1007/bf00310175", "10.1109/tvcg.2017.2744378", "10.1103/physreve.64.061907", "10.1109/ldav.2017.8231848", "10.1109/tvcg.2016.2598831"], "wos": 1, "children": [], "len": 1}], "len": 7}, {"doi": "10.1109/tvcg.2019.2934264", "title": "The Validity, Generalizability and Feasibility of Summative Evaluation Methods in Visual Analytics", "year": "2019", "conferenceName": "VAST", "authors": "Mosab Khayat;Morteza Karimzadeh;David S. Ebert;Arif Ghafoor", "citationCount": "1", "affiliation": "Khayat, M (Corresponding Author), Purdue Univ, W Lafayette, IN 47907 USA. Khayat, Mosab; Karimzadeh, Morteza; Ebert, David S.; Ghafoor, Arif, Purdue Univ, W Lafayette, IN 47907 USA. Karimzadeh, Morteza, Univ Colorado, Boulder, CO 80309 USA.", "countries": "USA", "abstract": "Many evaluation methods have been used to assess the usefulness of Visual Analytics (VA) solutions. These methods stem from a variety of origins with different assumptions and goals, which cause confusion about their proofing capabilities. Moreover, the lack of discussion about the evaluation processes may limit our potential to develop new evaluation methods specialized for VA. In this paper, we present an analysis of evaluation methods that have been used to summatively evaluate VA solutions. We provide a survey and taxonomy of the evaluation methods that have appeared in the VAST literature in the past two years. We then analyze these methods in terms of validity and generalizability of their findings, as well as the feasibility of using them. We propose a new metric called summative quality to compare evaluation methods according to their ability to prove usefulness, and make recommendations for selecting evaluation methods based on their summative quality in the VA domain.", "keywords": "Summative evaluation,usefulness,evaluation process,taxonomy,visual analytics", "link": "http://dx.doi.org/10.1109/TVCG.2019.2934264", "refList": ["10.1109/tvcg.2017.2744478", "10.1109/tvcg.2018.2865025", "10.1109/tvcg.2006.85", "10.1109/tvcg.2014.2346331", "10.1109/beliv.2018.8634420", "10.1109/tvcg.2017.2745181", "10.1111/cgf.13677", "10.1109/tvcg.2018.2864844", "10.1109/tvcg.2013.126", "10.1109/tvcg.2018.2864811", "10.1109/infvis.2005.1532147", "10.1177/0956797613504966", "10.1145/2669557.2669579", "10.1109/mcg.2005.102", "10.1109/visual.2003.1250426", "10.1136/bmj.39489.470347.ad", "10.1109/tvcg.2017.2744080", "10.1109/mcg.2009.53", "10.1111/j.1467-8527.2005.00307.x", "10.1109/tvcg.2010.132", "10.1109/tvcg.2018.2864886", "10.1109/tvcg.2018.2864843", "10.1109/tvcg.2018.2865028", "10.1109/tvcg.2018.2865051", "10.1109/tvcg.2018.2865044", "10.1109/tvcg.2018.2865026", "10.1007/978-3-540-71080-6\\_6", "10.1109/tvcg.2018.2865020", "10.1177/1473871611407399", "10.1109/tvcg.2018.2864504", "10.1109/tvcg.2018.2864526", "10.1109/tvcg.2005.53", "10.1109/tvcg.2018.2864905", "10.1049/sej.1991.0040", "10.1109/tvcg.2015.2513410", "10.1109/tvcg.2017.2711030", "10.1109/tvcg.2011.279", "10.1109/vast.2017.8585505", "10.1147/jrd.2010.2042914", "10.1016/s0378-7206(98)00044-5", "10.1145/2993901.2993913", "10.1109/tvcg.2018.2865041", "10.1109/tvcg.2018.2864812", "10.1109/tvcg.2017.2744758", "10.1145/1168149.1168158", "10.1109/tvcg.2017.2745279", "10.1109/tvcg.2012.213", "10.1109/tvcg.2017.2744738", "10.1109/tvcg.2017.2745083", "10.1109/tvcg.2018.2864826", "10.1145/1377966.1377974", "10.1109/apec.2009.4802646", "10.1145/1168149.1168152", "10.1016/j.jss.2008.03.059", "10.1109/vast.2017.8585484", "10.1109/tvcg.2017.2744818", "10.1109/tvcg.2017.2744358", "10.1109/tvcg.2018.2864499", "10.1109/tvcg.2018.2865042", "10.1109/tvcg.2017.2744898"], "wos": 1, "children": [{"doi": "10.1109/tvcg.2020.3030388", "title": "Visualization of Human Spine Biomechanics for Spinal Surgery", "year": "2020", "conferenceName": "SciVis", "authors": "Pepe Eulzer;Sabine Bauer;Francis Kilian;Kai Lawonn", "citationCount": "0", "affiliation": "Eulzer, P (Corresponding Author), Univ Jena, Jena, Germany. Eulzer, Pepe; Lawonn, Kai, Univ Jena, Jena, Germany. Bauer, Sabine, Univ Koblenz Landau, Koblenz, Germany. Kilian, Francis, Cath Clin Koblenz Montabaur, Dept Spine Surg, Koblenz, Germany.", "countries": "Germany", "abstract": "We propose a visualization application, designed for the exploration of human spine simulation data. Our goal is to support research in biomechanical spine simulation and advance efforts to implement simulation-backed analysis in surgical applications. Biomechanical simulation is a state-of-the-art technique for analyzing load distributions of spinal structures. Through the inclusion of patient-specific data, such simulations may facilitate personalized treatment and customized surgical interventions. Difficulties in spine modelling and simulation can be partly attributed to poor result representation, which may also be a hindrance when introducing such techniques into a clinical environment. Comparisons of measurements across multiple similar anatomical structures and the integration of temporal data make commonly available diagrams and charts insufficient for an intuitive and systematic display of results. Therefore, we facilitate methods such as multiple coordinated views, abstraction and focus and context to display simulation outcomes in a dedicated tool. $\\mathrm{By}$ linking the result data with patient-specific anatomy, we make relevant parameters tangible for clinicians. Furthermore, we introduce new concepts to show the directions of impact force vectors, which were not accessible before. We integrated our toolset into a spine segmentation and simulation pipeline and evaluated our methods with both surgeons and biomechanical researchers. When comparing our methods against standard representations that are currently in use, we found increases in accuracy and speed in data exploration tasks. $\\mathrm{in}$ a qualitative review, domain experts deemed the tool highly useful when dealing with simulation result data, which typically combines time-dependent patient movement and the resulting force distributions on spinal structures.", "keywords": "Medical visualization,bioinformatics,coordinated views,focus and context,biomechanical simulation", "link": "http://dx.doi.org/10.1109/TVCG.2020.3030388", "refList": ["10.1109/tvcg.2018.2864903", "10.1177/1473871613510429", "10.1093/ehjqcco/qcz052", "10.1109/tvcg.2007.70594", "10.1109/tvcg.2018.2865076", "10.1055/s-0039-1687862", "10.1109/visual.1990.146375", "10.1109/tvcg.2017.2744198", "10.1016/j.ijmedinf.2014.10.001", "10.1109/tvcg.2013.124", "10.1016/j.jacc", "10.1111/cgf.13167", "10.17705/1thci.00055", "10.1136/bmjqs.2009.037895", "10.1109/tvcg.2013.238", "10.1109/tvcg.2018.2865240", "10.1186/1471-2261-6-34", "10.1109/tvcg.2019.2934264", "10.1109/tvcg.2013.200", "10.1109/tvcg.2011.209", "10.1109/tvcg.2014.2346682", "10.1109/tvcg.2015.2467091", "10.1136/bmjopen-2019-033208", "10.1109/beliv.2018.8634027", "10.1109/tvcg.2012.213", "10.1109/tvcg.2015.2467191", "10.1109/tvcg.2015.2467325", "10.1145/2133806.2133821", "10.1145/1806799.1806866", "10.1108/02635570610688869", "10.1002/hbm.20701", "10.1561/1100000039", "10.1145/3025453.3025645", "10.1109/tvcg.2009.111", "10.1109/tvcg.2013.120", "10.1109/tvcg.2016.2599030"], "wos": 1, "children": [], "len": 1}], "len": 3}, {"doi": "10.1109/tvcg.2019.2934655", "title": "Visual Analytics for Electromagnetic Situation Awareness in Radio Monitoring and Management", "year": "2019", "conferenceName": "VAST", "authors": "Ying Zhao;Xiaobo Luo;Xiaoru Lin;Hairong Wang;Xiaoyan Kui;Fangfang Zhou;Jinsong Wang;Yi Chen 0007;Wei Chen", "citationCount": "3", "affiliation": "Kui, XY; Zhou, FF (Corresponding Author), Cent S Univ, Sch Comp Sci \\& Engn, Changsha, Hunan, Peoples R China. Zhao, Ying; Luo, Xiaobo; Lin, Xiaoru; Kui, Xiaoyan; Zhou, Fangfang, Cent S Univ, Sch Comp Sci \\& Engn, Changsha, Hunan, Peoples R China. Wang, Hairong, Cent S Univ, Sch Automat, Changsha, Hunan, Peoples R China. Wang, Jinsong, Southwest Elect \\& Telecom Engn Inst, Shanghai, Peoples R China. Chen, Yi, Beijing Technol \\& Business Univ, Beijing Key Lab Big Data Technol Food Safety, Beijing, Peoples R China. Chen, Wei, Zhejiang Univ, Key Lab CAD \\& CG, Hangzhou, Zhejiang, Peoples R China.", "countries": "China", "abstract": "Traditional radio monitoring and management largely depend on radio spectrum data analysis, which requires considerable domain experience and heavy cognition effort and frequently results in incorrect signal judgment and incomprehensive situation awareness. Faced with increasingly complicated electromagnetic environments, radio supervisors urgently need additional data sources and advanced analytical technologies to enhance their situation awareness ability. This paper introduces a visual analytics approach for electromagnetic situation awareness. Guided by a detailed scenario and requirement analysis, we first propose a signal clustering method to process radio signal data and a situation assessment model to obtain qualitative and quantitative descriptions of the electromagnetic situations. We then design a two-module interface with a set of visualization views and interactions to help radio supervisors perceive and understand the electromagnetic situations by a joint analysis of radio signal data and radio spectrum data. Evaluations on real-world data sets and an interview with actual users demonstrate the effectiveness of our prototype system. Finally, we discuss the limitations of the proposed approach and provide future work directions.", "keywords": "Radio monitoring and management,radio signal data,radio spectrum data,situation awareness,visual analytics", "link": "http://dx.doi.org/10.1109/TVCG.2019.2934655", "refList": ["10.1016/j.newast.2010.07.009", "10.1109/tvcg.2017.2744459", "10.1109/tvcg.2018.2864503", "10.1145/1029208.1029219", "10.1109/pacificvis.2014.54", "10.1109/tvcg.2018.2829750", "10.1016/j.jvlc.2017.11.004", "10.1109/tcyb.2015.2448236", "10.1016/j.patrec.2017.11.011", "10.1109/tvcg.2015.2505305", "10.1109/vast.2014.7042528", "10.1007/s12650-018-0530-2", "10.1109/tvcg.2018.2816203", "10.1109/tmm.2016.2614220", "10.1109/tvcg.2017.2745180", "10.1109/mcg.2018.2879067", "10.1109/tvcg.2018.2859973", "10.1109/tvcg.2016.2598460", "10.1109/infvis.2005.1532134", "10.1109/tvcg.2018.2851227", "10.1155/2012/920671", "10.1109/vast.2014.7042479", "10.1109/tvcg.2013.228", "10.1109/tvcg.2018.2865077", "10.1016/j.csda.2005.10.001", "10.1109/tvcg.2018.2865028", "10.1109/tvcg.2011.239", "10.1145/3173574.3174237", "10.1007/s13042-016-0603-2", "10.1109/tvcg.2018.2865020", "10.1017/s1041610219000024", "10.1109/2945.981848", "10.1109/tvcg.2010.193", "10.1109/tvcg.2018.2802520", "10.1145/3200766", "10.1109/wcncw.2015.7122557", "10.1145/3006299.3006312", "10.1109/icsssm.2007.4280175", "10.1126/science.1242072", "10.1109/tvcg.2017.2744098", "10.1109/tvcg.2015.2467196", "10.1109/tvcg.2016.2598619", "10.1109/tvcg.2016.2598664", "10.1109/tvcg.2013.196", "10.1109/comst.2016.2631080", "10.1109/tvcg.2018.2865029", "10.1007/s10816-016-9307-x", "10.1109/tvcg.2008.166", "10.1109/tvcg.2017.2758362", "10.1109/vizsec.2005.1532072", "10.1518/001872095779049543", "10.1109/tvcg.2007.70415", "10.1016/j.ins.2018.01.013", "10.1109/tvcg.2014.2346911", "10.1109/mim.2013.6616284", "10.1109/jsyst.2014.2358997", "10.1111/cgf.12910", "10.1109/isi.2009.5137305", "10.1109/tvcg.2011.179", "10.1007/s11277-015-2631-8", "10.1111/cgf.12396", "10.1109/tvcg.2013.2297933", "10.1109/tvcg.2014.2346926", "10.1109/tvcg.2014.2346913", "10.1109/pacificvis.2018.00030", "10.1109/tvcg.2014.2346433", "10.1109/tvcg.2016.2614803"], "wos": 1, "children": [{"doi": "10.1109/tvcg.2020.3030443", "title": "CAVA: A Visual Analytics System for Exploratory Columnar Data Augmentation Using Knowledge Graphs", "year": "2020", "conferenceName": "VAST", "authors": "Dylan Cashman;Shenyu Xu;Subhajit Das;Florian Heimerl;Cong Liu;Shah Rukh Humayoun;Michael Gleicher;Alex Endert;Remco Chang", "citationCount": "0", "affiliation": "Cashman, D (Corresponding Author), Tufts Univ, Medford, MA 02155 USA. Cashman, Dylan; Liu, Cong; Chang, Remco, Tufts Univ, Medford, MA 02155 USA. Xu, Shenyu; Das, Subhajit; Endert, Alex, Georgia Tech, Atlanta, GA USA. Heimerl, Florian; Gleicher, Michael, Univ Wisconsin, Madison, WI 53706 USA. Humayoun, Shah Rukh, San Francisco State Univ, San Francisco, CA 94132 USA.", "countries": "USA", "abstract": "Most visual analytics systems assume that all foraging for data happens before the analytics process; once analysis begins, the set of data attributes considered is fixed. Such separation of data construction from analysis precludes iteration that can enable foraging informed by the needs that arise in-situ during the analysis. The separation of the foraging loop from the data analysis tasks can limit the pace and scope of analysis. In this paper, we present CAVA, a system that integrates data curation and data augmentation with the traditional data exploration and analysis tasks, enabling information foraging in-situ during analysis. Identifying attributes to add to the dataset is difficult because it requires human knowledge to determine which available attributes will be helpful for the ensuing analytical tasks. CAVA crawls knowledge graphs to provide users with a a broad set of attributes drawn from external data to choose from. Users can then specify complex operations on knowledge graphs to construct additional attributes. CAVA shows how visual analytics can help users forage for attributes by letting users visually explore the set of available data, and by serving as an interface for query construction. It also provides visualizations of the knowledge graph itself to help users understand complex joins such as multi-hop aggregations. We assess the ability of our system to enable users to perform complex data combinations without programming in a user study over two datasets. We then demonstrate the generalizability of CAVA through two additional usage scenarios. The results of the evaluation confirm that CAVA is effective in helping the user perform data foraging that leads to improved analysis outcomes, and offer evidence in support of integrating data augmentation as a part of the visual analytics pipeline.", "keywords": "Visual Analytics,Information Foraging,Data Augmentation", "link": "http://dx.doi.org/10.1109/TVCG.2020.3030443", "refList": ["10.1057/palgrave.ivs.9500122", "10.1109/tvcg.2016.2598867", "10.1111/cgf.13708", "10.1109/tvcg.2019.2934799", "10.1109/tvcg.2019.2934541", "10.1109/tvcg.2013.65", "10.1109/tvcg.2018.2875702", "10.1109/iv.2004.1320207", "10.1068/p260471", "10.1145/1778765.1778816", "10.1109/tvcg.2018.2808489", "10.1109/tvcg.2018.2864912", "10.1016/j.apgeog.2015.12.006", "10.1111/j.1467-8659.2011.01960.x", "10.1109/tvcg.2018.2864843", "10.1109/pacificvis.2010.5429604", "10.1109/tvcg.2014.2346898", "10.1109/5.726791", "10.1177/1475090214540874", "10.1109/icde.2016.7498287", "10.1145/1556262.1556289", "10.1109/tvcg.2007.70535", "10.1109/vast.2012.6400489", "10.1145/1056808.1056914", "10.1016/j.neucom.2014.09.063", "10.1145/7529.8927", "10.1109/tvcg.2016.2598495", "10.1109/tvcg.2016.2607204", "10.1109/vast47406.2019.8986943", "10.3758/bf03205986", "10.1109/infvis.2005.1532142", "10.1145/1150402.1150479", "10.1109/tvcg.2017.2674978", "10.1109/tvcg.2019.2945960", "10.1109/tvcg.2017.2744098", "10.1109/tvcg.2017.2674999", "10.1109/tvcg.2011.279", "10.1109/tvcg.2014.2346594", "10.1109/tvcg.2017.2744184", "10.1111/cgf.12876", "10.1007/s4095-020-0191-7", "10.1007/s11390-015-1535-0", "10.1111/cgf.12640", "10.1109/tvcg.2016.2598667", "10.1111/cgf.13683", "10.1109/tvcg.2013.153", "10.1109/tvcg.2019.2934208", "10.1109/tvcg.2019.2934655", "10.1111/cgf.12655", "10.1007/s11023-010-9221-z", "10.1109/vast.2012.6400487", "10.1145/2702123.2702585", "10.1007/bf00310175", "10.1109/tvcg.2017.2744378", "10.1103/physreve.64.061907", "10.1109/ldav.2017.8231848", "10.1109/tvcg.2016.2598831"], "wos": 1, "children": [], "len": 1}, {"doi": "10.1109/tvcg.2020.3030432", "title": "Evaluation of Sampling Methods for Scatterplots", "year": "2020", "conferenceName": "VAST", "authors": "Jun Yuan;Shouxing Xiang;Jiazhi Xia;Lingyun Yu;Shixia Liu", "citationCount": "0", "affiliation": "Liu, SX (Corresponding Author), Tsinghua Univ, BNRist, Beijing, Peoples R China. Yuan, Jun; Xiang, Shouxing; Liu, Shixia, Tsinghua Univ, BNRist, Beijing, Peoples R China. Xia, Jiazhi, Cent South Univ, Changsha, Peoples R China. Yu, Lingyun, Xian Jiaotong Liverpool Univ, Suzhou, Peoples R China.", "countries": "China", "abstract": "Given a scatterplot with tens of thousands of points or even more, a natural question is which sampling method should be used to create a small but \u201cgood\u201d scatterplot for a better abstraction. We present the results of a user study that investigates the influence of different sampling strategies on multi-class scatterplots. The main goal of this study is to understand the capability of sampling methods in preserving the density, outliers, and overall shape of a scatterplot. To this end, we comprehensively review the literature and select seven typical sampling strategies as well as eight representative datasets. We then design four experiments to understand the performance of different strategies in maintaining: 1) region density; 2) class density; 3) outliers; and 4) overall shape in the sampling results. The results show that: 1) random sampling is preferred for preserving region density; 2) blue noise sampling and random sampling have comparable performance with the three multi-class sampling strategies in preserving class density; 3) outlier biased density based sampling, recursive subdivision based sampling, and blue noise sampling perform the best in keeping outliers; and 4) blue noise sampling outperforms the others in maintaining the overall shape of a scatterplot.", "keywords": "Scatterplot,data sampling,empirical evaluation", "link": "http://dx.doi.org/10.1109/TVCG.2020.3030432", "refList": ["10.1057/palgrave.ivs.9500122", "10.1109/tvcg.2016.2598867", "10.1109/tvcg.2015.2467591", "10.1111/cgf.13708", "10.1109/tvcg.2019.2934799", "10.1109/tvcg.2019.2934541", "10.1109/tvcg.2013.65", "10.1109/iv.2004.1320207", "10.1068/p260471", "10.1145/1778765.1778816", "10.1109/tvcg.2018.2808489", "10.1109/tvcg.2018.2864912", "10.1016/j.apgeog.2015.12.006", "10.1111/j.1467-8659.2011.01960.x", "10.1109/tvcg.2018.2864843", "10.1109/pacificvis.2010.5429604", "10.1109/tvcg.2014.2346898", "10.1109/5.726791", "10.1177/1475090214540874", "10.1145/1556262.1556289", "10.1109/tvcg.2007.70535", "10.1109/vast.2012.6400489", "10.1145/1056808.1056914", "10.1016/j.neucom.2014.09.063", "10.1145/7529.8927", "10.1109/tvcg.2016.2607204", "10.1109/vast47406.2019.8986943", "10.3758/bf03205986", "10.1109/infvis.2005.1532142", "10.1145/1150402.1150479", "10.1109/tvcg.2017.2674978", "10.1109/tvcg.2017.2744098", "10.1109/tvcg.2017.2674999", "10.1109/tvcg.2011.279", "10.1109/tvcg.2014.2346594", "10.1109/tvcg.2017.2744184", "10.1111/cgf.12876", "10.1109/1011101.2019.2945960", "10.1007/s4095-020-0191-7", "10.1007/s11390-015-1535-0", "10.1111/cgf.12640", "10.1109/tvcg.2016.2598667", "10.1111/cgf.13683", "10.1109/tvcg.2013.153", "10.1109/tvcg.2019.2934208", "10.1109/tvcg.2019.2934655", "10.1111/cgf.12655", "10.1007/s11023-010-9221-z", "10.1109/vast.2012.6400487", "10.1145/2702123.2702585", "10.1007/bf00310175", "10.1109/tvcg.2017.2744378", "10.1103/physreve.64.061907", "10.1109/ldav.2017.8231848", "10.1109/tvcg.2016.2598831"], "wos": 1, "children": [], "len": 1}], "len": 5}, {"doi": "10.1109/tvcg.2020.3030440", "title": "Context-aware Sampling of Large Networks via Graph Representation Learning", "year": "2020", "conferenceName": "InfoVis", "authors": "Zhiguang Zhou;Chen Shi;Xilong Shen;Lihong Cai;Haoxuan Wang;Yuhua Liu;Ying Zhao;Wei Chen", "citationCount": "0", "affiliation": "Zhao, Y (Corresponding Author), Cent South Univ, Changsha, Peoples R China. Chen, W (Corresponding Author), Zhejiang Univ, State Key Lab CAD \\& CG, Hangzhou, Peoples R China. Zhou, Zhiguang; Shi, Chen; Shen, Xilong; Cai, Lihong; Wang, Haoxuan; Liu, Yuhua, Zhejiang Univ Finance \\& Econ, Sch Informat, Hangzhou, Peoples R China. Zhao, Ying, Cent South Univ, Changsha, Peoples R China. Chen, Wei, Zhejiang Univ, State Key Lab CAD \\& CG, Hangzhou, Peoples R China.", "countries": "China", "abstract": "Numerous sampling strategies have been proposed to simplify large-scale networks for highly readable visualizations. It is of great challenge to preserve contextual structures formed by nodes and edges with tight relationships in a sampled graph, because they are easily overlooked during the process of sampling due to their irregular distribution and immunity to scale. In this paper, a new graph sampling method is proposed oriented to the preservation of contextual structures. We first utilize a graph representation learning (GRL) model to transform nodes into vectors so that the contextual structures in a network can be effectively extracted and organized. Then, we propose a multi-objective blue noise sampling model to select a subset of nodes in the vectorized space to preserve contextual structures with the retention of relative data and cluster densities in addition to those features of significance, such as bridging nodes and graph connections. We also design a set of visual interfaces enabling users to interactively conduct context-aware sampling, visually compare results with various sampling strategies, and deeply explore large networks. Case studies and quantitative comparisons based on real-world datasets have demonstrated the effectiveness of our method in the abstraction and exploration of large networks.", "keywords": "Graph sampling,Graph representation learning,Blue noise sampling,Graph evaluation", "link": "http://dx.doi.org/10.1109/TVCG.2020.3030440", "refList": ["10.1145/2491159.2491168", "10.1016/j.physa.2015.04.035", "10.1145/1830252.1830274", "10.1109/icdmw.2007.91", "10.1002/net.21834", "10.1109/tvcg.2018.2864503", "10.1016/j.cag.2018.01.010", "10.1109/icc.2016.7511156", "10.1111/cgf.13444", "10.1145/956750.956831", "10.1145/364099.364331", "10.1007/s00180-016-0663-5", "10.1109/tvcg.2013.223", "10.1007/s12650-018-0530-2", "10.1103/physreve.73.016102", "10.1109/access.2018.2870684", "10.1007/978-3-319-06793-3\\_1", "10.2312/vissym/eurovis05/239-246", "10.1016/j.ins.2015.02.014", "10.1145/2339530.2339723", "10.1109/icde.2015.7113345", "10.1109/tvcg.2011.233", "10.14778/2809974.2809980", "10.1109/glocom.2015.7417471", "10.1145/2578153.2578175", "10.1214/aoms/1177705148", "10.1109/tvcg.2008.130", "10.14232/actacyb.20.1.2011.6", "10.1504/ijitm.2019.099809", "10.1109/tvcg.2018.2865020", "10.1145/956750", "10.1002/cpe.4330060203", "10.1145/1150402.1150479", "10.1103/physreve.72.036118", "10.1109/tvcg.2017.2744098", "10.1145/2020408.2020512", "10.1142/s0129183114400075", "10.1109/jsac.2011.111005", "10.1016/j.camwa.2011.11.057", "10.1145/2470654.2466444", "10.1109/tvcg.2017.2674999", "10.1214/aos/1013203451", "10.1109/icdcsw.2011.34", "10.1016/j.physa.2013.11.015", "10.1145/1081870.1081893", "10.1109/tnet.2008.2001730", "10.1109/access.2016.2633485", "10.1145/1879141.1879192", "10.1371/journal.pone.0098679", "10.1126/science.220.4598.671", "10.1109/pacificvis.2015.7156355", "10.1088/1475-7516/2011/08/011", "10.1007/978-3-319-27261-0\\_41", "10.1111/cgf.13410", "10.1109/tvcg.2018.2865139", "10.1109/tvcg.2016.2598831", "10.1016/j.physa.2014.06.065"], "wos": 1, "children": [], "len": 1}], "len": 21}, {"doi": "10.1109/tvcg.2018.2865118", "title": "Shape-preserving Star Coordinates", "year": "2018", "conferenceName": "InfoVis", "authors": "Vladimir Molchanov;Lars Linsen", "citationCount": "1", "affiliation": "Molchanov, V (Corresponding Author), Westfalische Wilhelms Univ Munster, Munster, Germany. Molchanov, Vladimir; Linsen, Lars, Westfalische Wilhelms Univ Munster, Munster, Germany.", "countries": "Germany", "abstract": "Dimensionality reduction is commonly applied to multidimensional data to reduce the complexity of their analysis. In visual analysis systems, projections embed multidimensional data into 2D or 3D spaces for graphical representation. To facilitate a robust and accurate analysis, essential characteristics of the multidimensional data shall be preserved when projecting. Orthographic star coordinates is a state-of-the-art linear projection method that avoids distortion of multidimensional clusters by restricting interactive exploration to orthographic projections. However, existing numerical methods for computing orthographic star coordinates have a number of limitations when putting them into practice. We overcome these limitations by proposing the novel concept of shape-preserving star coordinates where shape preservation is assured using a superset of orthographic projections. Our scheme is explicit, exact, simple, fast, parameter-free, and stable. To maintain a valid shape-preserving star-coordinates configuration during user interaction with one of the star-coordinates axes, we derive an algorithm that only requires us to modify the configuration of one additional compensatory axis. Different design goals can be targeted by using different strategies for selecting the compensatory axis. We propose and discuss four strategies including a strategy that approximates orthographic star coordinates very well and a data-driven strategy. We further present shape-preserving morphing strategies between two shape-preserving configurations, which can be adapted for the generation of data tours. We apply our concept to multiple data analysis scenarios to document its applicability and validate its desired properties.", "keywords": "Star coordinates,multidimensional data projection,multivariate data visualization", "link": "http://dx.doi.org/10.1109/TVCG.2018.2865118", "refList": ["10.1007/978-1-4612-4214", "10.2312/eurovisshort.20141152", "10.1109/tvcg.2013.182", "10.1057/palgrave.ivs.9500099", "10.2307/2334381", "10.1109/tvcg.2014.2346258", "10.1016/j.cag.2016.08.007", "10.1111/cgf.13196", "10.1080/10618600.1995.10474674", "10.1111/cgf.12117", "10.1137/0906011", "10.1109/tvcg.2015.2467324", "10.3390/pr5040075", "10.2307/2289161", "10.1109/tvcg.2015.2467132", "10.1109/t-c.1974.224051", "10.1177/1473871612439357", "10.2312/vcbm.20151204", "10.1109/tvcg.2010.209"], "wos": 1, "children": [{"doi": "10.1109/pacificvis48177.2020.8199", "year": "2020", "title": "Efficient Morphing of Shape-preserving Star Coordinates", "conferenceName": "PacificVis", "authors": "Vladimir Molchanov;Sagad Hamid;Lars Linsen", "citationCount": "0", "affiliation": "Molchanov, V (Corresponding Author), Westfalische Wilhelms Univ Munster, Munster, Germany.\nMolchanov, Vladimir; Hamid, Sagad; Linsen, Lars, Westfalische Wilhelms Univ Munster, Munster, Germany.", "countries": "Germany", "abstract": "Data tours follow an exploratory multi-dimensional data visualization concept that provides animations of projections of the multidimensional data to a 2D visual space. To create an animation, a sequence of key projections is provided and morphings between each pair of consecutive key projections are computed, which then can be stitched together to form the data tour. The morphings should be smooth so that a user can easily follow the transformations, and their computations shall be fast to allow for their integration into an interactive visual exploration process. Moreover, if the key projections are chosen to satisfy additional conditions, it is desirable that these conditions are maintained during morphing. Shape preservation is such a desirable condition, as it avoids shape distortions that may otherwise be caused by a projection. We develop a novel efficient morphing algorithms for computing shape-preserving data tours, i.e., data tours constructed for a sequence of shape-preserving linear projections. We propose a stepping strategy for the morphing to avoid discontinuities in the evolution of the projections, where we represent the linear projections using a star-coordinates system. Our algorithms are less computationally involved, produce smoother morphings, and require less user-defined parameter settings than existing state-of-the-art approaches.", "keywords": "Human-centered computing; Visualization; Visualization techniques", "link": "https://doi.org/10.1109/PacificVis48177.2020.8199", "refList": ["10.2312/eurovisshort.20141152", "10.1109/tvcg.2013.182", "10.1109/tvcg.2008.153", "10.1109/tvcg.2015.2467591", "10.4135/9781412985130", "10.1111/cgf.12878", "10.1016/j.cag.2016.08.007", "10.1080/10618600.1995.10474674", "10.1109/infvis.2003.1249004", "10.1002/9781118445112.stat06472", "10.1109/visual.1997.663916", "10.1111/cgf.12117", "10.1137/0906011", "10.1109/tvcg.2018.2865118", "10.1126/science.290.5500.2319", "10.1111/cgf.12845", "10.1111/j.1467-8659.2012.03125.x", "10.1109/tvcg.2017.2705189", "10.1002/0471725293", "10.1111/cgf.12876", "10.1111/cgf.13404", "10.2307/2289161", "10.1111/cgf.13446", "10.1198/106186008x318440", "10.2307/1390747", "10.1109/tvcg.2012.35", "10.1109/tvcg.2015.2467132", "10.1109/tvcg.2006.94", "10.1109/t-c.1974.224051", "10.1109/pacificvis.2019.00018", "10.1109/tvcg.2017.2744339", "10.1109/tsmcb.2005.850151"], "wos": 1, "children": [], "len": 1}], "len": 3}, {"doi": "10.1109/vast47406.2019.8986923", "title": "ICE: An Interactive Configuration Explorer for High Dimensional Categorical Parameter Spaces", "year": "2019", "conferenceName": "VAST", "authors": "Anjul Tyagi;Zhen Cao;Tyler Estro;Erez Zadok;Klaus Mueller", "citationCount": "0", "affiliation": "Tyagi, A (Corresponding Author), SUNY Stony Brook, Dept Comp Sci, Stony Brook, NY 11794 USA. Tyagi, Anjul; Cao, Zhen; Estro, Tyler; Zadok, Erez; Mueller, Klaus, SUNY Stony Brook, Dept Comp Sci, Stony Brook, NY 11794 USA.", "countries": "USA", "abstract": "There are many applications where users seek to explore the impact of the settings of several categorical variables with respect to one dependent numerical variable. For example, a computer systems analyst might want to study how the type of file system or storage device affects system performance. A usual choice is the method of Parallel Sets designed to visualize multivariate categorical variables, However, we found that the magnitude of the parameter impacts on the numerical variable cannot be easily observed here. We also attempted a dimension reduction approach based on Multiple Correspondence Analysis but found that the SVD-generated 2D layout resulted in a loss of information. We hence propose a novel approach, the Interactive Configuration Explorer (ICE), which directly addresses the need of analysts to learn how the dependent numerical variable is affected by the parameter settings given multiple optimization objectives. No information is lost as ICE shows the complete distribution and statistics of the dependent variable in context with each categorical variable. Analysts can interactively filter the variables to optimize for certain goals such as achieving a system with maximum performance, low variance, etc. Our system was developed in tight collaboration with a group of systems performance researchers and its final effectiveness was evaluated with expert interviews, a comparative user study, and two case studies.", "keywords": "Data Clustering,Illustrative Visualization,User Interfaces,High Dimensional Data", "link": "http://dx.doi.org/10.1109/VAST47406.2019.8986923", "refList": ["10.1109/sibgrapi.2015.38", "10.1023/a:1022602019183", "10.1109/tvcg.2013.182", "10.1021/acsami.9b02947", "10.1007/978-3-540-88411-8\\_2", "10.1023/a:1009769707641", "10.1016/j.patcog.2017.04.019", "10.1007/s10606-008-9080-9", "10.1109/tvcg.2017.2701829", "10.1109/tvcg.2010.223", "10.7551/mitpress/1090.001.0001", "10.1080/00949657508810123", "10.1145/502512.502530", "10.1109/tvcg.2011.185", "10.1109/tvcg.2014.2350494", "10.1007/bf02948829", "10.1109/visual.1997.663916", "10.2307/2685478", "10.1109/tvcg.2015.2467324", "10.1109/tvcg.2010.183", "10.1145/1496909.1496922", "10.1111/cgf.13176", "10.1145/3035918.3064029", "10.1111/j.1467-8659.2011.01940.x", "10.1109/jproc.2015.2494218", "10.1109/tvcg.2014.2346321", "10.1109/tits.2015.2436897", "10.1111/cgf.13214", "10.1137/s1052623497329683", "10.1126/science.290.5500.2323", "10.1109/tvcg.2015.2467132.3", "10.18637/jss.v048.i04", "10.1145/3116213", "10.1109/tvcg.2014.2346448", "10.1126/science.220.4598.671", "10.1109/iv.2009.103", "10.1111/j.1467-8659.2009.01684.x", "10.1109/tvcg.2018.2864510", "10.1109/tvcg.2015.2467132", "10.1109/nnsp.1999.788121", "10.1109/tvcg.2009.111", "10.1088/1748-9326/6/4/045404", "10.1177/1473871612439357", "10.1007/bf02239469", "10.1179/000870403235002042", "10.1109/tvcg.2006.76"], "wos": 1, "children": [], "len": 1}, {"doi": "10.1111/cgf.13446", "year": "2018", "title": "Quality Metrics for Information Visualization", "conferenceName": "EuroVis", "authors": "Michael Behrisch;Michael Blumenschein;Nam Wook Kim;Lin Shao;Mennatallah El{-}Assady;Johannes Fuchs;Daniel Seebacher;Alexandra Diehl;Ulrik Brandes;Hanspeter Pfister;Tobias Schreck;Daniel Weiskopf;Daniel A. Keim", "citationCount": "25", "affiliation": "Behrisch, M (Corresponding Author), Harvard Univ, Cambridge, MA 02138 USA.\nBehrisch, M.; Kim, N. W.; Pfister, H., Harvard Univ, Cambridge, MA 02138 USA.\nBlumenschein, M.; El-Assady, M.; Fuchs, J.; Seebacher, D.; Diehl, A.; Keim, D. A., Univ Konstanz, Constance, Germany.\nShao, L.; Schreck, T., Graz Univ Technol, Graz, Austria.\nBrandes, U., Swiss Fed Inst Technol, Zurich, Switzerland.\nWeiskopf, D., Univ Stuttgart, Stuttgart, Germany.", "countries": "Switzerland;Germany;USA;Austria", "abstract": "The visualization community has developed to date many intuitions and understandings of how to judge the quality of views in visualizing data. The computation of a visualization's quality and usefulness ranges from measuring clutter and overlap, up to the existence and perception of specific (visual) patterns. This survey attempts to report, categorize and unify the diverse understandings and aims to establish a common vocabulary that will enable a wide audience to understand their differences and subtleties. For this purpose, we present a commonly applicable quality metric formalization that should detail and relate all constituting parts of a quality metric. We organize our corpus of reviewed research papers along the data types established in the information visualization community: multi- and high-dimensional, relational, sequential, geospatial and text data. For each data type, we select the visualization subdomains in which quality metrics are an active research field and report their findings, reason on the underlying concepts, describe goals and outline the constraints and requirements. One central goal of this survey is to provide guidance on future research opportunities for the field and outline how different visualization communities could benefit from each other by applying or transferring knowledge to their respective subdomain. Additionally, we aim to motivate the visualization community to compare computed measures to the perception of humans.", "keywords": "", "link": "https://doi.org/10.1111/cgf.13446", "refList": ["10.2307/276978", "10.1057/ivs.2009.10", "10.1109/tvcg.2015.2467732", "10.1109/tvcg.2014.2346420", "10.1016/j.cag.2018.01.010", "10.1109/tvcg.2017.2743959", "10.1109/tvcg.2011.127", "10.1109/tvcg.2015.2467759", "10.1109/tvcg.2013.187", "10.1109/tvcg.2007.70594", "10.1186/1471-2105-9-155", "10.1145/2702123.2702545", "10.1145/1645953.1646023", "10.1093/bioinformatics/btm312", "10.1109/pacificvis.2016.7465245", "10.1145/3038462.3038463", "10.1007/978-3-540-70956-5", "10.1109/tvcg.2017.2743939", "10.1111/cgf.12932", "10.1111/j.1467-8659.2012.03106.x", "10.1145/1133265.1133318", "10.1109/tvcg.2010.186", "10.1109/iv.2013.101", "10.1109/tvcg.2016.2598590", "10.2312/conf/eg2013/stars/039-063", "10.3758/bf03201236", "10.1111/cgf.12935", "10.1145/1056808.1056914", "10.1007/bf01898350", "10.2307/1390686", "10.1109/2945.981848", "10.1109/hicss.2008.422", "10.1109/tvcg.2011.201", "10.1109/pacificvis.2011.5742390", "10.2307/2288400", "10.1111/cgf.12872", "10.1109/tvcg.2017.2674999", "10.1109/tvcg.2006.163", "10.1109/tvcg.2013.150", "10.1109/tvcg.2009.171", "10.1109/tvcg.2017.2723397", "10.1117/12.2079841", "10.1109/pacificvis.2009.4906838", "10.1109/infvis.2004.1", "10.1109/tvcg.2008.166", "10.1287/opre.20.5.993", "10.7155/jgaa.00370", "10.1111/j.1467-8659.2008.01240.x", "10.1109/inf0vis.2005.14", "10.1109/tvcg.2009.23", "10.1109/infvis.1998.729559", "10.1177/0165551506078083", "10.1109/t-c.1974.224051", "10.1109/tvcg.2017.2744339", "10.1109/tvcg.2014.2346433", "10.1145/989863.989940", "10.1109/tvcg.2015.2509990", "10.2307/2288843", "10.1016/j.neucom.2017.01.105", "10.1073/pnas.43.10.923", "10.1111/cgf.12647", "10.1016/j.rse.2017.06.031", "10.1109/infvis.2005.1532145", "10.1109/2945.841121", "10.1109/tvcg.2011.229", "10.2312/eurova.20141140", "10.1111/j.2044-8317.1974.tb00534.x", "10.1109/pacificvis.2015.7156366", "10.1109/vast.2009.5332628", "10.1109/vast.2014.7042480", "10.1145/2993901.2993907", "10.1177/0951692899011001004", "10.1007/978-3-642-03655-2\\_43", "10.1198/106186008x320465", "10.1109/visual.1997.663916", "10.1111/cgf.12125", "10.1109/infvis.2003.1249009", "10.1109/icdm.2003.1250978", "10.1109/tvcg.2017.2745919", "10.1109/tvcg.2012.128", "10.1109/vast.2010.5652450", "10.1109/tvcg.2006.161", "10.1145/571647.571649", "10.1109/tvcg.2011.193", "10.1111/cgf.12633", "10.1109/tvcg.2017.2674978", "10.1109/vast.2010.5652433", "10.1109/tvcg.2017.2745978", "10.1515/itit-2014-1070", "10.1145/1374489.1374501", "10.1109/tvcg.2009.153", "10.2312/eurovisshort.20171128", "10.2312/eurovisshort.20151130", "10.1016/0925-7721(94)00014-x", "10.1057/palgrave.ivs.95000/3", "10.1145/302979.303030", "10.1002/widm.1071", "10.1109/pacificvis.2014.42", "10.1109/tvcg.2016.2598467", "10.1111/j.1467-8659.2009.01667.x", "10.2307/2287708", "10.1177/1473871613477091", "10.1145/967900.968153", "10.1109/tvcg.2010.162", "10.1145/568522.568523", "10.1016/j.cag.2004.03.022", "10.1109/tvcg.2015.2466992", "10.1145/2993901.2993903", "10.1147/jrd.2015.2411412", "10.1177/154193120504900508", "10.1109/tvcg.2006.138", "10.1111/cgf.13168", "10.1111/cgf.12380", "10.2312/conf/eg2013/stars/095-116", "10.1109/tvcg.2017.2745859", "10.1109/tvcg.2017.2701829", "10.1109/tvcg.2007.70529", "10.1007/bf01199431", "10.1117/12.697548", "10.1109/tvcg.2017.2653106", "10.1207/s15327906mbr2701\\_4", "10.1109/vl.1996.545307", "10.1109/tvcg.2017.2745140", "10.1111/j.1467-8659.2012.03069.x", "10.1111/j.1467-8659.2011.01961.x", "10.1109/pacificvis.2016.7465244", "10.1109/tvcg.2013.124", "10.1057/ivs.2008.13", "10.2312/vissym/eurovis06/195-202", "10.2312/vissym/eurovis07/163-170", "10.1109/tvcg.2015.2467324", "10.1109/tvcg.2011.167", "10.1109/pacificvis.2014.40", "10.1109/pacificvis.2012.6183570", "10.1111/j.1467-8659.2012.03125.x", "10.1075/idj.20.1.02bei", "10.1111/1467-8306.00061", "10.1145/2858036.2858155", "10.1109/tvcg.2012.108", "10.2312/vmv.20171261", "10.1109/tvcg.2015.2467531", "10.1145/1379092.1379130", "10.1109/tpami.1979.4766909", "10.1080/13875860903039172", "10.1109/mcg.2006.70", "10.1109/tvcg.2010.242", "10.1109/vast.2007.4389004", "10.1109/tvcg.2015.2467191", "10.2312/cgvc.20171276", "10.1016/0169-7439(87)80084-9", "10.2312/pe/eurovisshort/eurovisshort2012/097-101", "10.1016/j.neucom.2014.07.073", "10.2307/2685263", "10.1145/996546.996554", "10.1111/j.1467-8659.2009.01666.x", "10.1117/12.2083444", "10.1109/tvcg.2014.2346572", "10.1007/978-0-387-39940-9\\_262", "10.1007/bf00988593", "10.1145/1054972.1055078", "10.1111/j.1467-8659.2009.01467.x", "10.1111/cgf.13181", "10.1145/502512.502530", "10.1109/pacificvis.2010.5429600", "10.1111/j.1467-8659.2011.01923.x", "10.1109/mcg.2004.41", "10.1109/tvcg.2015.2467971", "10.1111/j.1467-8659.2011.01919.x", "10.1002/sam.10071", "10.1109/tvcg.2010.184", "10.1007/978-3-642-27848-8\\_648-1", "10.1109/tvcg.2010.132", "10.1145/22949.22950", "10.1145/1842993.1843002", "10.1109/infvis.2000.885096", "10.1016/j.ins.2015.04.017", "10.1109/iv.2009.43", "10.1016/j.visinf.2017.11.001", "10.1109/tvcg.2011.239", "10.1109/infovis.2005.40", "10.1111/cgf.12641", "10.1109/pacificvis.2016.7465262", "10.1145/2470654.2466443", "10.1007/s10844-011-0157-4", "10.1111/cgf.12919", "10.1016/j.jvlc.2016.07.003", "10.1109/tvcg.2016.2549018", "10.1057/palgrave.ivs.9500166", "10.3406/colan.1981.1409.1", "10.1093/bioinformatics/bti141", "10.1111/j.1467-8306.2004.09401004.x", "10.1145/1168149.1168168", "10.1109/tvcg.2017.2744184", "10.1117/12.2079420", "10.1109/iv.2005.62", "10.1145/102377.115768", "10.1109/tvcg.2014.2346677", "10.1109/tvcg.2014.2346426", "10.1111/j.1467-8659.2012.03107.x", "10.5220/0006097400400051", "10.2991/978-94-6239-186-4", "10.2307/2284077", "10.1109/iv.2008.89", "10.1016/j.jvlc.2015.12.001", "10.1109/pacificvis.2013.6596147", "10.1145/1242572.1242826", "10.1016/j.cag.2007.01.030", "10.1111/cgf.12632", "10.2312/eurovisstar.20151113", "10.1559/152304009788188808"], "wos": 1, "children": [{"doi": "10.1109/vast.2018.8802486", "title": "SMARTexplore: Simplifying High-Dimensional Data Analysis through a Table-Based Visual Analytics Approach", "year": "2018", "conferenceName": "VAST", "authors": "Michael Blumenschein;Michael Behrisch;Stefanie Schmid;Simon Butscher;Deborah Wahl;Karoline Villinger;Britta Renner;Harald Reiterer;Daniel A. Keim", "citationCount": "0", "affiliation": "Blumenschein, M (Corresponding Author), Univ Konstanz, Constance, Germany. Blumenschein, Michael; Schmid, Stefanie; Butscher, Simon; Wahl, Deborah R.; Villinger, Karoline; Renner, Britta; Reiterer, Harald; Keim, Daniel A., Univ Konstanz, Constance, Germany. Behrisch, Michael, Harvard Univ, Cambridge, MA 02138 USA.", "countries": "Germany;USA", "abstract": "We present SMARTEXPLORE, a novel visual analytics technique that simplifies the identification and understanding of clusters, correlations, and complex patterns in high-dimensional data. The analysis is integrated into an interactive table-based visualization that maintains a consistent and familiar representation throughout the analysis. The visualization is tightly coupled with pattern matching, subspace analysis, reordering, and layout algorithms. To increase the analyst's trust in the revealed patterns, SMARTEXPLORE automatically selects and computes statistical measures based on dimension and data properties. While existing approaches to analyzing high-dimensional data (e.g., planar projections and Parallel coordinates) have proven effective, they typically have steep learning curves for non-visualization experts. Our evaluation, based on three expert case studies, confirms that non-visualization experts successfully reveal patterns in high-dimensional data when using SMARTEXPLORE.", "keywords": "High-dimensional data,visual exploration,pattern-driven analysis,tabular visualization,subspace,aggregation", "link": "http://dx.doi.org/10.1109/VAST.2018.8802486", "refList": ["10.1177/1473871612460526", "10.1109/tvcg.2015.2489649", "10.1111/j.1467-8659.2008.01241.x", "10.1007/978-3-319-25087-8\\_29", "10.1007/b98835", "10.13140/rg.2.2.16570.90567", "10.1109/tvcg.2014.2346260", "10.1109/vast.2009.5332628", "10.2307/2528823", "10.1109/tvcg.2010.184", "10.1145/1133265.1133318", "10.1057/palgrave.ivs.9500072", "10.1111/j.1467-8659.2012.03110.x", "10.1145/1007730.1007731", "10.1057/palgrave.ivs.9500086", "10.1111/cgf.12935", "10.1109/tvcg.2014.2346279", "10.1007/bf01898350", "10.1109/tvcg.2013.173", "10.1109/tvcg.2017.2672987", "10.1109/tvcg.2014.2346248", "10.1109/infvis.2004.46", "10.1109/vast.2010.5652433", "10.1109/vast.2009.5332611", "10.1109/tvcg.2015.2467553", "10.1109/tvcg.2015.2468078", "10.1109/tvcg.2017.2744098", "10.1109/tvcg.2013.150", "10.1109/tvcg.2016.2640960", "10.1111/cgf.12630", "10.1007/978-1-4757-1904-8", "10.1109/tvcg.2011.188", "10.1109/tvcg.2010.138", "10.1109/tvcg.2017.2745078", "10.1109/tvcg.2017.2743978", "10.1111/cgf.12879", "10.1109/iv.2008.33", "10.1111/cgf.13446", "10.1007/s00371-018-1483-0", "10.1109/infvis.1998.729559", "10.1145/2669557.2669572", "10.1111/j.1467-8659.2008.01239.x"], "wos": 1, "children": [], "len": 1}, {"doi": "10.1109/tvcg.2019.2934541", "title": "A Recursive Subdivision Technique for Sampling Multi-class Scatterplots", "year": "2019", "conferenceName": "InfoVis", "authors": "Xin Chen;Tong Ge;Jian Zhang 0070;Baoquan Chen;Chi-Wing Fu;Oliver Deussen;Yunhai Wang", "citationCount": "5", "affiliation": "Chen, X (Corresponding Author), Shandong Univ, Jinan, Shandong, Peoples R China. Chen, Xin; Ge, Tong; Wang, Yunhai, Shandong Univ, Jinan, Shandong, Peoples R China. Chen, Baoquan, Peking Univ, Beijing, Peoples R China. Fu, Chi-Wing, Chinese Univ Hong Kong, Hong Kong, Peoples R China. Fu, Chi-Wing, SIAT, Guangdong Prov Key Lab CV \\& VR Tech, Shenzhen, Guangdong, Peoples R China. Zhang, Jian, Chinese Acad Sci, CNIC, Beijing, Peoples R China. Deussen, Oliver, Konstanz Univ, Constance, Germany. Deussen, Oliver, SIAT, Shenzhen VIsuCA Key Lab, Shenzhen, Guangdong, Peoples R China.", "countries": "Germany;China", "abstract": "We present a non-uniform recursive sampling technique for multi-class scatterplots, with the specific goal of faithfully presenting relative data and class densities, while preserving major outliers in the plots. Our technique is based on a customized binary kd-tree, in which leaf nodes are created by recursively subdividing the underlying multi-class density map. By backtracking, we merge leaf nodes until they encompass points of all classes for our subsequently applied outlier-aware multi-class sampling strategy. A quantitative evaluation shows that our approach can better preserve outliers and at the same time relative densities in multi-class scatterplots compared to the previous approaches, several case studies demonstrate the effectiveness of our approach in exploring complex and real world data.", "keywords": "Scatterplot,multi-class sampling,kd-tree,outlier,relative density", "link": "http://dx.doi.org/10.1109/TVCG.2019.2934541", "refList": ["10.1057/palgrave.ivs.9500122", "10.1109/tvcg.2006.170", "10.1109/tvcg.2008.119", "10.1109/tvcg.2007.70580", "10.2307/2289444", "10.1145/1964921.1964943", "10.1109/tvcg.2013.65", "10.1109/tvcg.2011.229", "10.1109/iv.2004.1320207", "10.1109/itoec.2018.8740621", "10.1145/1778765.1778816", "10.1109/tvcg.2010.197", "10.1201/b17511", "10.1109/tvcg.2018.2864912", "10.1007/0-387-28695-0", "10.1109/5.726791", "10.1109/visual.1998.745301", "10.1016/j.physa.2011.12.004", "10.1145/1556262.1556289", "10.1109/tvcg.2007.70535", "10.1109/tvcg.2017.2674978", "10.1109/tvcg.2004.1272729", "10.1145/335191.335388", "10.1109/tvcg.2014.2346594", "10.1109/tvcg.2017.2744184", "10.1109/iv.2002.1028760", "10.1145/1842993.1842999", "10.1109/tvcg.2018.2869149", "10.1038/nmeth.2490", "10.1109/tvcg.2013.153", "10.1111/cgf.13446", "10.1109/tvcg.2010.176", "10.1145/2702123.2702585", "10.1057/ivs.2009.34"], "wos": 1, "children": [{"doi": "10.1109/tvcg.2020.3030443", "title": "CAVA: A Visual Analytics System for Exploratory Columnar Data Augmentation Using Knowledge Graphs", "year": "2020", "conferenceName": "VAST", "authors": "Dylan Cashman;Shenyu Xu;Subhajit Das;Florian Heimerl;Cong Liu;Shah Rukh Humayoun;Michael Gleicher;Alex Endert;Remco Chang", "citationCount": "0", "affiliation": "Cashman, D (Corresponding Author), Tufts Univ, Medford, MA 02155 USA. Cashman, Dylan; Liu, Cong; Chang, Remco, Tufts Univ, Medford, MA 02155 USA. Xu, Shenyu; Das, Subhajit; Endert, Alex, Georgia Tech, Atlanta, GA USA. Heimerl, Florian; Gleicher, Michael, Univ Wisconsin, Madison, WI 53706 USA. Humayoun, Shah Rukh, San Francisco State Univ, San Francisco, CA 94132 USA.", "countries": "USA", "abstract": "Most visual analytics systems assume that all foraging for data happens before the analytics process; once analysis begins, the set of data attributes considered is fixed. Such separation of data construction from analysis precludes iteration that can enable foraging informed by the needs that arise in-situ during the analysis. The separation of the foraging loop from the data analysis tasks can limit the pace and scope of analysis. In this paper, we present CAVA, a system that integrates data curation and data augmentation with the traditional data exploration and analysis tasks, enabling information foraging in-situ during analysis. Identifying attributes to add to the dataset is difficult because it requires human knowledge to determine which available attributes will be helpful for the ensuing analytical tasks. CAVA crawls knowledge graphs to provide users with a a broad set of attributes drawn from external data to choose from. Users can then specify complex operations on knowledge graphs to construct additional attributes. CAVA shows how visual analytics can help users forage for attributes by letting users visually explore the set of available data, and by serving as an interface for query construction. It also provides visualizations of the knowledge graph itself to help users understand complex joins such as multi-hop aggregations. We assess the ability of our system to enable users to perform complex data combinations without programming in a user study over two datasets. We then demonstrate the generalizability of CAVA through two additional usage scenarios. The results of the evaluation confirm that CAVA is effective in helping the user perform data foraging that leads to improved analysis outcomes, and offer evidence in support of integrating data augmentation as a part of the visual analytics pipeline.", "keywords": "Visual Analytics,Information Foraging,Data Augmentation", "link": "http://dx.doi.org/10.1109/TVCG.2020.3030443", "refList": ["10.1057/palgrave.ivs.9500122", "10.1109/tvcg.2016.2598867", "10.1111/cgf.13708", "10.1109/tvcg.2019.2934799", "10.1109/tvcg.2019.2934541", "10.1109/tvcg.2013.65", "10.1109/tvcg.2018.2875702", "10.1109/iv.2004.1320207", "10.1068/p260471", "10.1145/1778765.1778816", "10.1109/tvcg.2018.2808489", "10.1109/tvcg.2018.2864912", "10.1016/j.apgeog.2015.12.006", "10.1111/j.1467-8659.2011.01960.x", "10.1109/tvcg.2018.2864843", "10.1109/pacificvis.2010.5429604", "10.1109/tvcg.2014.2346898", "10.1109/5.726791", "10.1177/1475090214540874", "10.1109/icde.2016.7498287", "10.1145/1556262.1556289", "10.1109/tvcg.2007.70535", "10.1109/vast.2012.6400489", "10.1145/1056808.1056914", "10.1016/j.neucom.2014.09.063", "10.1145/7529.8927", "10.1109/tvcg.2016.2598495", "10.1109/tvcg.2016.2607204", "10.1109/vast47406.2019.8986943", "10.3758/bf03205986", "10.1109/infvis.2005.1532142", "10.1145/1150402.1150479", "10.1109/tvcg.2017.2674978", "10.1109/tvcg.2019.2945960", "10.1109/tvcg.2017.2744098", "10.1109/tvcg.2017.2674999", "10.1109/tvcg.2011.279", "10.1109/tvcg.2014.2346594", "10.1109/tvcg.2017.2744184", "10.1111/cgf.12876", "10.1007/s4095-020-0191-7", "10.1007/s11390-015-1535-0", "10.1111/cgf.12640", "10.1109/tvcg.2016.2598667", "10.1111/cgf.13683", "10.1109/tvcg.2013.153", "10.1109/tvcg.2019.2934208", "10.1109/tvcg.2019.2934655", "10.1111/cgf.12655", "10.1007/s11023-010-9221-z", "10.1109/vast.2012.6400487", "10.1145/2702123.2702585", "10.1007/bf00310175", "10.1109/tvcg.2017.2744378", "10.1103/physreve.64.061907", "10.1109/ldav.2017.8231848", "10.1109/tvcg.2016.2598831"], "wos": 1, "children": [], "len": 1}, {"doi": "10.1109/tvcg.2020.3030432", "title": "Evaluation of Sampling Methods for Scatterplots", "year": "2020", "conferenceName": "VAST", "authors": "Jun Yuan;Shouxing Xiang;Jiazhi Xia;Lingyun Yu;Shixia Liu", "citationCount": "0", "affiliation": "Liu, SX (Corresponding Author), Tsinghua Univ, BNRist, Beijing, Peoples R China. Yuan, Jun; Xiang, Shouxing; Liu, Shixia, Tsinghua Univ, BNRist, Beijing, Peoples R China. Xia, Jiazhi, Cent South Univ, Changsha, Peoples R China. Yu, Lingyun, Xian Jiaotong Liverpool Univ, Suzhou, Peoples R China.", "countries": "China", "abstract": "Given a scatterplot with tens of thousands of points or even more, a natural question is which sampling method should be used to create a small but \u201cgood\u201d scatterplot for a better abstraction. We present the results of a user study that investigates the influence of different sampling strategies on multi-class scatterplots. The main goal of this study is to understand the capability of sampling methods in preserving the density, outliers, and overall shape of a scatterplot. To this end, we comprehensively review the literature and select seven typical sampling strategies as well as eight representative datasets. We then design four experiments to understand the performance of different strategies in maintaining: 1) region density; 2) class density; 3) outliers; and 4) overall shape in the sampling results. The results show that: 1) random sampling is preferred for preserving region density; 2) blue noise sampling and random sampling have comparable performance with the three multi-class sampling strategies in preserving class density; 3) outlier biased density based sampling, recursive subdivision based sampling, and blue noise sampling perform the best in keeping outliers; and 4) blue noise sampling outperforms the others in maintaining the overall shape of a scatterplot.", "keywords": "Scatterplot,data sampling,empirical evaluation", "link": "http://dx.doi.org/10.1109/TVCG.2020.3030432", "refList": ["10.1057/palgrave.ivs.9500122", "10.1109/tvcg.2016.2598867", "10.1109/tvcg.2015.2467591", "10.1111/cgf.13708", "10.1109/tvcg.2019.2934799", "10.1109/tvcg.2019.2934541", "10.1109/tvcg.2013.65", "10.1109/iv.2004.1320207", "10.1068/p260471", "10.1145/1778765.1778816", "10.1109/tvcg.2018.2808489", "10.1109/tvcg.2018.2864912", "10.1016/j.apgeog.2015.12.006", "10.1111/j.1467-8659.2011.01960.x", "10.1109/tvcg.2018.2864843", "10.1109/pacificvis.2010.5429604", "10.1109/tvcg.2014.2346898", "10.1109/5.726791", "10.1177/1475090214540874", "10.1145/1556262.1556289", "10.1109/tvcg.2007.70535", "10.1109/vast.2012.6400489", "10.1145/1056808.1056914", "10.1016/j.neucom.2014.09.063", "10.1145/7529.8927", "10.1109/tvcg.2016.2607204", "10.1109/vast47406.2019.8986943", "10.3758/bf03205986", "10.1109/infvis.2005.1532142", "10.1145/1150402.1150479", "10.1109/tvcg.2017.2674978", "10.1109/tvcg.2017.2744098", "10.1109/tvcg.2017.2674999", "10.1109/tvcg.2011.279", "10.1109/tvcg.2014.2346594", "10.1109/tvcg.2017.2744184", "10.1111/cgf.12876", "10.1109/1011101.2019.2945960", "10.1007/s4095-020-0191-7", "10.1007/s11390-015-1535-0", "10.1111/cgf.12640", "10.1109/tvcg.2016.2598667", "10.1111/cgf.13683", "10.1109/tvcg.2013.153", "10.1109/tvcg.2019.2934208", "10.1109/tvcg.2019.2934655", "10.1111/cgf.12655", "10.1007/s11023-010-9221-z", "10.1109/vast.2012.6400487", "10.1145/2702123.2702585", "10.1007/bf00310175", "10.1109/tvcg.2017.2744378", "10.1103/physreve.64.061907", "10.1109/ldav.2017.8231848", "10.1109/tvcg.2016.2598831"], "wos": 1, "children": [], "len": 1}, {"doi": "10.1109/tvcg.2020.3030365", "title": "Modeling the Influence of Visual Density on Cluster Perception in Scatterplots Using Topology", "year": "2020", "conferenceName": "InfoVis", "authors": "Ghulam Jilani Quadri;Paul Rosen", "citationCount": "0", "affiliation": "Quadri, GJ (Corresponding Author), Univ S Florida, Tampa, FL 33620 USA. Quadri, Ghulam Jilani; Rosen, Paul, Univ S Florida, Tampa, FL 33620 USA.", "countries": "USA", "abstract": "Scatterplots are used for a variety of visual analytics tasks, including cluster identification, and the visual encodings used on a scatterplot play a deciding role on the level of visual separation of clusters. For visualization designers, optimizing the visual encodings is crucial to maximizing the clarity of data. This requires accurately modeling human perception of cluster separation, which remains challenging. We present a multi-stage user study focusing on four factors-distribution size of clusters, number of points, size of points, and opacity of points-that influence cluster identification in scatterplots. From these parameters, we have constructed two models, a distance-based model, and a density-based model, using the merge tree data structure from Topological Data Analysis. Our analysis demonstrates that these factors play an important role in the number of clusters perceived, and it verifies that the distance-based and density-based models can reasonably estimate the number of clusters a user observes. Finally, we demonstrate how these models can be used to optimize visual encodings on real-world data.", "keywords": "Scatterplot,clustering,perception,empirical evaluation,visual encoding,crowdsourcing,topological data analysis", "link": "http://dx.doi.org/10.1109/TVCG.2020.3030365", "refList": ["10.1109/tvcg.2017.2744359", "10.1145/1778765", "10.1109/tvcg.2019.2934799", "10.1111/cgf.12889", "10.1109/tvcg.2011.127", "10.1111/cgf.13444", "10.1145/1964897.1964910", "10.1167/8.7.6", "10.1145/3173574.3173991", "10.1145/1556262.1556289", "10.1145/1056808.1056914", "10.2307/2288400", "10.1109/tvcg.2014.2346594", "10.1109/iv.2002.1028760", "10.1177/001316447303300111", "10.1007/bf02289823", "10.1109/tvcg.2017.2744339", "10.1111/j.1467-8659.2009.01694.x", "10.1109/tvcg.2014.2346979", "10.1090/mbk/069", "10.1109/tvcg.2013.65", "10.1109/mcg.2012.37", "10.1109/pacificvis.2010.5429604", "10.1002/acp.2350050106", "10.1109/infvis.2005.1532136", "10.1177/1473871612465214", "10.1109/tvcg.2017.2674978", "10.1002/jhbs.20078", "10.1007/978-3-642-35142-6\\_14", "10.1007/978-3-319-71507-0", "10.1109/mcg.201.7.6", "10.3758/bf03193961", "10.1364/josa.49.000280", "10.1145/3025453.3025905", "10.1109/tvcg.201.9.2934541", "10.1109/tvcg.2018.2829750", "10.1177/1473871615606187", "10.1111/cgf.13408", "10.1109/pacificvis.2016.7465252", "10.1109/pacificvis.2016.7465244", "10.1109/inevis.2005.1532142", "10.1111/cgf.13414", "10.1111/j.1467-8659.2012.03125.x", "10.1167/16.5.11", "10.1109/infvis.2005.1532142", "10.1145/2858036.2858155", "10.1038/nmeth1210-941", "10.1177/1473871616638892", "10.1109/tcbb.2014.2306840", "10.1111/cgf.13684", "10.1177/0301006615602599", "10.1214/aoms/1177731915", "10.1145/2702123.2702585", "10.1109/tvcg.2013.183", "10.1109/tvcg.2014.2346572", "10.1109/tvcg.2018.2875702", "10.1109/tvcg.2017.2754480", "10.1109/vast.2014.7042493", "10.1057/palgrave.ivs.9500122", "10.1109/tvcg.2014.2330617", "10.1109/tvcg.2019.2934541", "10.1068/p030033", "10.1140/epjds/s13688-017-0109-5", "10.1201/b17511", "10.1016/s0925-7721(02)00093-7", "10.1109/pacificvis.2012.6183557", "10.1109/tvcg.2014.2346983", "10.1109/5.726791", "10.1080/01621459.1926.10502165", "10.1109/tvcg.2007.70535", "10.1109/tvcg.2018.2864907", "10.1111/cgf.12109", "10.1109/tvcg.2017.2744184", "10.1146/annurev-statistics-031017-100045", "10.1111/cgf.13409", "10.1145/3002151.3002162", "10.1016/s0378-4371(98)00494-4", "10.3138/y308-2422-8615-1233", "10.1111/cgf.12632", "10.1145/3290605.3300771"], "wos": 1, "children": [], "len": 1}, {"doi": "10.1111/cgf.14001", "year": "2020", "title": "Sunspot Plots: Model-based Structure Enhancement for Dense Scatter Plots", "conferenceName": "EuroVis", "authors": "Thomas Trautner;Fabian Bolte;Sergej Stoppel;Stefan Bruckner", "citationCount": "0", "affiliation": "Trautner, T (Corresponding Author), Univ Bergen, Bergen, Norway.\nTrautner, T.; Bolte, F.; Stoppel, S.; Bruckner, S., Univ Bergen, Bergen, Norway.", "countries": "Norway", "abstract": "Scatter plots are a powerful and well-established technique for visualizing the relationships between two variables as a collection of discrete points. However, especially when dealing with large and dense data, scatter plots often exhibit problems such as overplotting, making the data interpretation arduous. Density plots are able to overcome these limitations in highly populated regions, but fail to provide accurate information of individual data points. This is particularly problematic in sparse regions where the density estimate may not provide a good representation of the underlying data. In this paper, we present sunspot plots, a visualization technique that communicates dense data as a continuous data distribution, while preserving the discrete nature of data samples in sparsely populated areas. We furthermore demonstrate the advantages of our approach on typical failure cases of scatter plots within synthetic and real-world data sets and validate its effectiveness in a user study.", "keywords": "", "link": "https://doi.org/10.1111/cgf.14001", "refList": ["10.1057/palgrave.ivs.9500122", "10.2312/eggh/hpg12/097-103", "10.1109/tvcg.2008.119", "10.1109/pacificvis.2011.5742387", "10.1038/331163a0", "10.1109/visual.2019.8933620", "10.2307/2683294", "10.1201/9781351072304", "10.2307/2289444", "10.1109/tvcg.2019.2934541", "10.1080/00949657508810123", "10.1109/tvcg.2013.65", "10.1109/infvis.1997.636789", "10.1109/2945.841121", "10.1109/mcse.2007.55", "10.1109/tvcg.2010.197", "10.1111/cgf.12871", "10.1109/infvis.2003.1249018", "10.1145/3173574.3173991", "10.1109/tvcg.2012.238", "10.1007/0-387-28695-0", "10.1109/pacificvis.2010.5429604", "10.18637/jss.v008.i03", "10.1109/tvcg.2007.70596", "10.1109/visual.1998.745301", "10.1007/0-387-37977-0\\_3", "10.1145/1556262.1556289", "10.2312/wiced.20161094", "10.1109/tvcg.2007.70535", "10.1145/1056808.1056914", "10.1109/tvcg.2003.1196007", "10.1109/iv.2004.1320190", "10.1111/cgf.12877", "10.1162/leon.2007.40.2.202a", "10.1109/tvcg.2017.2674978", "10.1057/ivs.2010.4", "10.1016/j.cag.2018.02.008", "10.1201/9781315140919", "10.1109/visual.2000.885677", "10.1002/jhbs.20078", "10.1109/tvcg.2014.2346594", "10.1109/tvcg.2017.2744184", "10.1109/visual.2001.964495", "10.1109/iv.2002.1028760", "10.1111/cgf.13684", "10.1109/hicss.2013.197", "10.1109/tvcg.2019.2903956", "10.1093/mnras/stt961", "10.1109/tvcg.2017.2668409", "10.1111/j.1467-8659.2009.01478.x", "10.1145/2702123.2702585", "10.2307/1418003", "10.2307/1390742", "10.1145/360825.360839", "10.1109/pacificvis.2009.4906843", "10.1057/ivs.2009.34", "10.2307/2288711"], "wos": 1, "children": [], "len": 1}], "len": 9}, {"doi": "10.1109/tvcg.2019.2934284", "title": "Color Crafting: Automating the Construction of Designer Quality Color Ramps", "year": "2019", "conferenceName": "InfoVis", "authors": "Stephen Smart;Keke Wu;Danielle Albers Szafir", "citationCount": "3", "affiliation": "Smart, S (Corresponding Author), Univ Colorado, Boulder, CO 80309 USA. Smart, Stephen; Wu, Keke; Szafir, Danielle Albers, Univ Colorado, Boulder, CO 80309 USA.", "countries": "USA", "abstract": "Visualizations often encode numeric data using sequential and diverging color ramps. Effective ramps use colors that are sufficiently discriminable, align well with the data, and are aesthetically pleasing. Designers rely on years of experience to create high-quality color ramps. However, it is challenging for novice visualization developers that lack this experience to craft effective ramps as most guidelines for constructing ramps are loosely defined qualitative heuristics that are often difficult to apply. Our goal is to enable visualization developers to readily create effective color encodings using a single seed color. We do this using an algorithmic approach that models designer practices by analyzing patterns in the structure of designer-crafted color ramps. We construct these models from a corpus of 222 expert-designed color ramps, and use the results to automatically generate ramps that mimic designer practices. We evaluate our approach through an empirical study comparing the outputs of our approach with designer-crafted color ramps. Our models produce ramps that support accurate and aesthetically pleasing visualizations at least as well as designer ramps and that outperform conventional mathematical approaches.", "keywords": "Visualization,Aesthetics in Visualization,Color Perception,Visual Design,Design Mining", "link": "http://dx.doi.org/10.1109/TVCG.2019.2934284", "refList": ["10.1145/3009924", "10.1109/tvcg.2015.2489649", "10.1109/tvcg.2017.2744359", "10.1002/(sici)1098-1098(199622)7:2", "10.1016/s0734-189x(83)80046-2", "10.1109/tvcg.2016.2599106", "10.1364/josaa.29.000313", "10.1109/tvcg.2016.2598918", "10.2307/2683294", "10.1109/tvcg.2017.2653106", "10.1016/j.ijhcs.2010.05.006", "10.1016/0146-664x(81)90006-x", "10.1007/978-3-642-10520-3\\_9", "10.1109/38.135886", "10.1146/annurev-psych-120710-100504", "10.1016/j.csda.2008.11.033", "10.1145/2461912.2461988", "10.1016/j.cub.2007.06.022", "10.1016/s0146-664x(79)80040-4", "10.1109/mcg.2004.1297012", "10.1109/iv.2009.94", "10.1109/tpami.2010.184", "10.3758/s13414-010-0027-0", "10.1145/22949.22950", "10.1109/visual.1995.480803", "10.1109/tvcg.2014.2346277", "10.2307/2684111", "10.1109/tvcg.2018.2865240", "10.1111/cgf.12633", "10.1109/38.7760", "10.1016/j.jspi.2015.04.007", "10.1109/iv.2008.24", "10.1145/2939502.2939506", "10.1111/cgf.12127", "10.1016/j.cag.2010.11.015", "10.1145/3025453.3026041", "10.1109/tvcg.2012.315", "10.2307/2288400", "10.1511/2005.5.436", "10.1016/s0097-8493(96)00072-6", "10.1109/mcg.2018.011461525", "10.1145/2470654.2466420", "10.1109/tvcg.2012.279", "10.1109/tvcg.2014.2346978", "10.1109/tvcg.2017.2743978", "10.1145/3406601.3406602", "10.1117/12.2084548", "10.1109/tvcg.2018.2865147", "10.1109/tvcg.2015.2467191", "10.1111/cgf.13446", "10.1109/tvcg.2017.2744320", "10.1111/j.1467-8659.2008.01203.x", "10.1145/2702613.2702975", "10.1007/978-3-319-26633-6\\_13", "10.1145/2207676.2208547", "10.1109/tvcg.2008.174", "10.1179/000870403235002042"], "wos": 1, "children": [{"doi": "10.1109/tvcg.2020.3028891", "title": "A Structured Review of Data Management Technology for Interactive Visualization and Analysis", "year": "2020", "conferenceName": "InfoVis", "authors": "Leilani Battle;Carlos Scheidegger", "citationCount": "0", "affiliation": "Battle, L (Corresponding Author), Univ Maryland, Dept Comp Sci, College Pk, MD 20742 USA. Battle, Leilani, Univ Maryland, Dept Comp Sci, College Pk, MD 20742 USA. Scheidegger, Carlos, Univ Arizona, Dept Comp Sci, HDC Lab, Tucson, AZ 85721 USA.", "countries": "USA", "abstract": "In the last two decades, interactive visualization and analysis have become a central tool in data-driven decision making. Concurrently to the contributions in data visualization, research in data management has produced technology that directly benefits interactive analysis. Here, we contribute a systematic review of 30 years of work in this adjacent field, and highlight techniques and principles we believe to be underappreciated in visualization work. We structure our review along two axes. First, we use task taxonomies from the visualization literature to structure the space of interactions in usual systems. Second, we created a categorization of data management work that strikes a balance between specificity and generality. Concretely, we contribute a characterization of 131 research papers along these two axes. We find that five notions in data management venues fit interactive visualization systems well: materialized views, approximate query processing, user modeling and query prediction, muiti-query optimization, lineage techniques, and indexing techniques. In addition, we find a preponderance of work in materialized views and approximate query processing, most targeting a limited subset of the interaction tasks in the taxonomy we used. This suggests natural avenues of future research both in visualization and data management. Our categorization both changes how we visualization researchers design and build our systems, and highlights where future work is necessary.", "keywords": "", "link": "http://dx.doi.org/10.1109/TVCG.2020.3028891", "refList": ["10.1109/tvcg.2012.233", "10.1016/s0022-5371(74)80015-0", "10.1109/tvcg.2017.2744359", "10.1037/0096-3445.136.4.623", "10.1109/tvcg.2015.2467732", "10.1109/tvcg.2012.196", "10.1037/a0029856", "10.1109/tvcg.2014.2346979", "10.1037/h0030300", "10.1109/tvcg.2016.2598918", "10.1109/beliv.2018.8634420", "10.1109/tvcg.2018.2864909", "10.1111/cgf.13079", "10.3389/fpsyg.2012.00355", "10.1145/2858036.2858465", "10.1080/01621459.1989.10478821", "10.1037/0278-7393.24.3.732", "10.1109/tvcg.2011.127", "10.1145/2858036.2858063", "10.4249/scholarpedia.3325", "10.4324/9781410611949", "10.1111/cgf.13444", "10.1145/2993901.2993909", "10.1037/0033-295x.96.2.267", "10.1006/ijhc.1017", "10.1086/405615", "10.1109/tvcg.2019.2934801", "10.1038/17953", "10.1037/xhp0000314", "10.1109/tvcg.2019.2934400", "10.1145/2470654.2470723", "10.1037/0096-1523.16.2.332", "10.1167/16.5.11", "10.3758/s13423-016-1174-7", "10.3758/bf03207704", "10.1146/annurev.psych.55.090902.141415", "10.2307/2288400", "10.3758/bf03204258", "10.1109/tvcg.2011.279", "10.1109/vissoft.2014.36", "10.3758/s13423-011-0055-3", "10.1145/3025453.3025922", "10.1109/tvcg.2019.2934284", "10.3758/bf03210498", "10.3758/bf03200774", "10.2307/1419876", "10.1038/s41562-017-0058", "10.1109/tvcg.2010.237", "10.1109/pacificvis.2012.6183556", "10.1109/infvis.1997.636792", "10.1093/acprof:oso/9780198523192.003.0005", "10.1073/pnas.1117465109", "10.1109/tvcg.2013.234", "10.1038/nn.3655", "10.1111/cgf.12379", "10.1146/annurev-psych-010416-044232", "10.1111/cgf.13695", "10.1037/0033-295x.107.3.500", "10.1109/tvcg.2013.183", "10.1146/annurev.psych.53.100901.135125", "10.1037//0022-3514.79.6.995", "10.1559/152304003100010929", "10.1109/tvcg.2018.2865147", "10.1037/0096-1523.18.3.849", "10.1111/j.1467-8659.2009.01694.x", "10.1145/3290605.3300771"], "wos": 1, "children": [], "len": 1}], "len": 3}, {"doi": "10.1109/tvcg.2019.2934799", "title": "Data Sampling in Multi-view and Multi-class Scatterplots via Set Cover Optimization", "year": "2019", "conferenceName": "InfoVis", "authors": "Ruizhen Hu;Tingkai Sha;Oliver van Kaick;Oliver Deussen;Hui Huang 0004", "citationCount": "4", "affiliation": "Hu, RZ (Corresponding Author), Shenzhen Univ, Visual Comp Res Ctr, Shenzhen, Guangdong, Peoples R China. Hu, Ruizhen; Sha, Tingkai; Huang, Hui, Shenzhen Univ, Visual Comp Res Ctr, Shenzhen, Guangdong, Peoples R China. van Kaick, Oliver, Carleton Univ, Sch Comp Sci, Ottawa, ON, Canada. Deussen, Oliver, Konstanz Univ, Constance, Germany. Deussen, Oliver, SIAT, Shenzhen VisuCA Key Lab, Shenzhen, Guangdong, Peoples R China.", "countries": "Canada;Germany;China", "abstract": "We present a method for data sampling in scatterplots by jointly optimizing point selection for different views or classes. Our method uses space-filling curves (Z-order curves) that partition a point set into subsets that, when covered each by one sample, provide a sampling or coreset with good approximation guarantees in relation to the original point set. For scatterplot matrices with multiple views, different views provide different space-filling curves, leading to different partitions of the given point set. For multi-class scatterplots, the focus on either per-class distribution or global distribution provides two different partitions of the given point set that need to be considered in the selection of the coreset. For both cases, we convert the coreset selection problem into an Exact Cover Problem (ECP), and demonstrate with quantitative and qualitative evaluations that an approximate solution that solves the ECP efficiently is able to provide high-quality samplings.", "keywords": "Sampling,Scatterplot,SPLOM,Exact Cover Problem", "link": "http://dx.doi.org/10.1109/TVCG.2019.2934799", "refList": ["10.1057/palgrave.ivs.9500122", "10.1109/tvcg.2006.170", "10.1109/tvcg.2008.119", "10.1111/j.1467-8659.2009.01467.x", "10.2307/2289444", "10.1109/tvcg.2013.65", "10.1109/tvcg.2011.229", "10.1109/iv.2004.1320207", "10.1109/itoec.2018.8740621", "10.1145/1778765.1778816", "10.1109/tvcg.2018.2864912", "10.1007/0-387-28695-0", "10.1109/visual.1998.745301", "10.1287/moor.4.3.233", "10.1145/1556262.1556289", "10.1109/tvcg.2007.70535", "10.2307/2284239", "10.1109/tvcg.2017.2674978", "10.1016/j.dss.2009.05.016", "10.1109/tvcg.2014.2346594", "10.1109/vds.2017.8573446", "10.1007/978-1-4684-2001-2\\_9", "10.1109/iv.2002.1028760", "10.1145/1842993.1842999", "10.1038/nmeth.2490", "10.1109/tvcg.2013.153", "10.1111/cgf.13446", "10.1109/tvcg.2010.176", "10.1145/2702123.2702585", "10.1057/ivs.2009.34", "10.1179/000870403235002042"], "wos": 1, "children": [{"doi": "10.1109/tvcg.2020.3030443", "title": "CAVA: A Visual Analytics System for Exploratory Columnar Data Augmentation Using Knowledge Graphs", "year": "2020", "conferenceName": "VAST", "authors": "Dylan Cashman;Shenyu Xu;Subhajit Das;Florian Heimerl;Cong Liu;Shah Rukh Humayoun;Michael Gleicher;Alex Endert;Remco Chang", "citationCount": "0", "affiliation": "Cashman, D (Corresponding Author), Tufts Univ, Medford, MA 02155 USA. Cashman, Dylan; Liu, Cong; Chang, Remco, Tufts Univ, Medford, MA 02155 USA. Xu, Shenyu; Das, Subhajit; Endert, Alex, Georgia Tech, Atlanta, GA USA. Heimerl, Florian; Gleicher, Michael, Univ Wisconsin, Madison, WI 53706 USA. Humayoun, Shah Rukh, San Francisco State Univ, San Francisco, CA 94132 USA.", "countries": "USA", "abstract": "Most visual analytics systems assume that all foraging for data happens before the analytics process; once analysis begins, the set of data attributes considered is fixed. Such separation of data construction from analysis precludes iteration that can enable foraging informed by the needs that arise in-situ during the analysis. The separation of the foraging loop from the data analysis tasks can limit the pace and scope of analysis. In this paper, we present CAVA, a system that integrates data curation and data augmentation with the traditional data exploration and analysis tasks, enabling information foraging in-situ during analysis. Identifying attributes to add to the dataset is difficult because it requires human knowledge to determine which available attributes will be helpful for the ensuing analytical tasks. CAVA crawls knowledge graphs to provide users with a a broad set of attributes drawn from external data to choose from. Users can then specify complex operations on knowledge graphs to construct additional attributes. CAVA shows how visual analytics can help users forage for attributes by letting users visually explore the set of available data, and by serving as an interface for query construction. It also provides visualizations of the knowledge graph itself to help users understand complex joins such as multi-hop aggregations. We assess the ability of our system to enable users to perform complex data combinations without programming in a user study over two datasets. We then demonstrate the generalizability of CAVA through two additional usage scenarios. The results of the evaluation confirm that CAVA is effective in helping the user perform data foraging that leads to improved analysis outcomes, and offer evidence in support of integrating data augmentation as a part of the visual analytics pipeline.", "keywords": "Visual Analytics,Information Foraging,Data Augmentation", "link": "http://dx.doi.org/10.1109/TVCG.2020.3030443", "refList": ["10.1057/palgrave.ivs.9500122", "10.1109/tvcg.2016.2598867", "10.1111/cgf.13708", "10.1109/tvcg.2019.2934799", "10.1109/tvcg.2019.2934541", "10.1109/tvcg.2013.65", "10.1109/tvcg.2018.2875702", "10.1109/iv.2004.1320207", "10.1068/p260471", "10.1145/1778765.1778816", "10.1109/tvcg.2018.2808489", "10.1109/tvcg.2018.2864912", "10.1016/j.apgeog.2015.12.006", "10.1111/j.1467-8659.2011.01960.x", "10.1109/tvcg.2018.2864843", "10.1109/pacificvis.2010.5429604", "10.1109/tvcg.2014.2346898", "10.1109/5.726791", "10.1177/1475090214540874", "10.1109/icde.2016.7498287", "10.1145/1556262.1556289", "10.1109/tvcg.2007.70535", "10.1109/vast.2012.6400489", "10.1145/1056808.1056914", "10.1016/j.neucom.2014.09.063", "10.1145/7529.8927", "10.1109/tvcg.2016.2598495", "10.1109/tvcg.2016.2607204", "10.1109/vast47406.2019.8986943", "10.3758/bf03205986", "10.1109/infvis.2005.1532142", "10.1145/1150402.1150479", "10.1109/tvcg.2017.2674978", "10.1109/tvcg.2019.2945960", "10.1109/tvcg.2017.2744098", "10.1109/tvcg.2017.2674999", "10.1109/tvcg.2011.279", "10.1109/tvcg.2014.2346594", "10.1109/tvcg.2017.2744184", "10.1111/cgf.12876", "10.1007/s4095-020-0191-7", "10.1007/s11390-015-1535-0", "10.1111/cgf.12640", "10.1109/tvcg.2016.2598667", "10.1111/cgf.13683", "10.1109/tvcg.2013.153", "10.1109/tvcg.2019.2934208", "10.1109/tvcg.2019.2934655", "10.1111/cgf.12655", "10.1007/s11023-010-9221-z", "10.1109/vast.2012.6400487", "10.1145/2702123.2702585", "10.1007/bf00310175", "10.1109/tvcg.2017.2744378", "10.1103/physreve.64.061907", "10.1109/ldav.2017.8231848", "10.1109/tvcg.2016.2598831"], "wos": 1, "children": [], "len": 1}, {"doi": "10.1109/tvcg.2020.3030432", "title": "Evaluation of Sampling Methods for Scatterplots", "year": "2020", "conferenceName": "VAST", "authors": "Jun Yuan;Shouxing Xiang;Jiazhi Xia;Lingyun Yu;Shixia Liu", "citationCount": "0", "affiliation": "Liu, SX (Corresponding Author), Tsinghua Univ, BNRist, Beijing, Peoples R China. Yuan, Jun; Xiang, Shouxing; Liu, Shixia, Tsinghua Univ, BNRist, Beijing, Peoples R China. Xia, Jiazhi, Cent South Univ, Changsha, Peoples R China. Yu, Lingyun, Xian Jiaotong Liverpool Univ, Suzhou, Peoples R China.", "countries": "China", "abstract": "Given a scatterplot with tens of thousands of points or even more, a natural question is which sampling method should be used to create a small but \u201cgood\u201d scatterplot for a better abstraction. We present the results of a user study that investigates the influence of different sampling strategies on multi-class scatterplots. The main goal of this study is to understand the capability of sampling methods in preserving the density, outliers, and overall shape of a scatterplot. To this end, we comprehensively review the literature and select seven typical sampling strategies as well as eight representative datasets. We then design four experiments to understand the performance of different strategies in maintaining: 1) region density; 2) class density; 3) outliers; and 4) overall shape in the sampling results. The results show that: 1) random sampling is preferred for preserving region density; 2) blue noise sampling and random sampling have comparable performance with the three multi-class sampling strategies in preserving class density; 3) outlier biased density based sampling, recursive subdivision based sampling, and blue noise sampling perform the best in keeping outliers; and 4) blue noise sampling outperforms the others in maintaining the overall shape of a scatterplot.", "keywords": "Scatterplot,data sampling,empirical evaluation", "link": "http://dx.doi.org/10.1109/TVCG.2020.3030432", "refList": ["10.1057/palgrave.ivs.9500122", "10.1109/tvcg.2016.2598867", "10.1109/tvcg.2015.2467591", "10.1111/cgf.13708", "10.1109/tvcg.2019.2934799", "10.1109/tvcg.2019.2934541", "10.1109/tvcg.2013.65", "10.1109/iv.2004.1320207", "10.1068/p260471", "10.1145/1778765.1778816", "10.1109/tvcg.2018.2808489", "10.1109/tvcg.2018.2864912", "10.1016/j.apgeog.2015.12.006", "10.1111/j.1467-8659.2011.01960.x", "10.1109/tvcg.2018.2864843", "10.1109/pacificvis.2010.5429604", "10.1109/tvcg.2014.2346898", "10.1109/5.726791", "10.1177/1475090214540874", "10.1145/1556262.1556289", "10.1109/tvcg.2007.70535", "10.1109/vast.2012.6400489", "10.1145/1056808.1056914", "10.1016/j.neucom.2014.09.063", "10.1145/7529.8927", "10.1109/tvcg.2016.2607204", "10.1109/vast47406.2019.8986943", "10.3758/bf03205986", "10.1109/infvis.2005.1532142", "10.1145/1150402.1150479", "10.1109/tvcg.2017.2674978", "10.1109/tvcg.2017.2744098", "10.1109/tvcg.2017.2674999", "10.1109/tvcg.2011.279", "10.1109/tvcg.2014.2346594", "10.1109/tvcg.2017.2744184", "10.1111/cgf.12876", "10.1109/1011101.2019.2945960", "10.1007/s4095-020-0191-7", "10.1007/s11390-015-1535-0", "10.1111/cgf.12640", "10.1109/tvcg.2016.2598667", "10.1111/cgf.13683", "10.1109/tvcg.2013.153", "10.1109/tvcg.2019.2934208", "10.1109/tvcg.2019.2934655", "10.1111/cgf.12655", "10.1007/s11023-010-9221-z", "10.1109/vast.2012.6400487", "10.1145/2702123.2702585", "10.1007/bf00310175", "10.1109/tvcg.2017.2744378", "10.1103/physreve.64.061907", "10.1109/ldav.2017.8231848", "10.1109/tvcg.2016.2598831"], "wos": 1, "children": [], "len": 1}, {"doi": "10.1109/tvcg.2020.3030365", "title": "Modeling the Influence of Visual Density on Cluster Perception in Scatterplots Using Topology", "year": "2020", "conferenceName": "InfoVis", "authors": "Ghulam Jilani Quadri;Paul Rosen", "citationCount": "0", "affiliation": "Quadri, GJ (Corresponding Author), Univ S Florida, Tampa, FL 33620 USA. Quadri, Ghulam Jilani; Rosen, Paul, Univ S Florida, Tampa, FL 33620 USA.", "countries": "USA", "abstract": "Scatterplots are used for a variety of visual analytics tasks, including cluster identification, and the visual encodings used on a scatterplot play a deciding role on the level of visual separation of clusters. For visualization designers, optimizing the visual encodings is crucial to maximizing the clarity of data. This requires accurately modeling human perception of cluster separation, which remains challenging. We present a multi-stage user study focusing on four factors-distribution size of clusters, number of points, size of points, and opacity of points-that influence cluster identification in scatterplots. From these parameters, we have constructed two models, a distance-based model, and a density-based model, using the merge tree data structure from Topological Data Analysis. Our analysis demonstrates that these factors play an important role in the number of clusters perceived, and it verifies that the distance-based and density-based models can reasonably estimate the number of clusters a user observes. Finally, we demonstrate how these models can be used to optimize visual encodings on real-world data.", "keywords": "Scatterplot,clustering,perception,empirical evaluation,visual encoding,crowdsourcing,topological data analysis", "link": "http://dx.doi.org/10.1109/TVCG.2020.3030365", "refList": ["10.1109/tvcg.2017.2744359", "10.1145/1778765", "10.1109/tvcg.2019.2934799", "10.1111/cgf.12889", "10.1109/tvcg.2011.127", "10.1111/cgf.13444", "10.1145/1964897.1964910", "10.1167/8.7.6", "10.1145/3173574.3173991", "10.1145/1556262.1556289", "10.1145/1056808.1056914", "10.2307/2288400", "10.1109/tvcg.2014.2346594", "10.1109/iv.2002.1028760", "10.1177/001316447303300111", "10.1007/bf02289823", "10.1109/tvcg.2017.2744339", "10.1111/j.1467-8659.2009.01694.x", "10.1109/tvcg.2014.2346979", "10.1090/mbk/069", "10.1109/tvcg.2013.65", "10.1109/mcg.2012.37", "10.1109/pacificvis.2010.5429604", "10.1002/acp.2350050106", "10.1109/infvis.2005.1532136", "10.1177/1473871612465214", "10.1109/tvcg.2017.2674978", "10.1002/jhbs.20078", "10.1007/978-3-642-35142-6\\_14", "10.1007/978-3-319-71507-0", "10.1109/mcg.201.7.6", "10.3758/bf03193961", "10.1364/josa.49.000280", "10.1145/3025453.3025905", "10.1109/tvcg.201.9.2934541", "10.1109/tvcg.2018.2829750", "10.1177/1473871615606187", "10.1111/cgf.13408", "10.1109/pacificvis.2016.7465252", "10.1109/pacificvis.2016.7465244", "10.1109/inevis.2005.1532142", "10.1111/cgf.13414", "10.1111/j.1467-8659.2012.03125.x", "10.1167/16.5.11", "10.1109/infvis.2005.1532142", "10.1145/2858036.2858155", "10.1038/nmeth1210-941", "10.1177/1473871616638892", "10.1109/tcbb.2014.2306840", "10.1111/cgf.13684", "10.1177/0301006615602599", "10.1214/aoms/1177731915", "10.1145/2702123.2702585", "10.1109/tvcg.2013.183", "10.1109/tvcg.2014.2346572", "10.1109/tvcg.2018.2875702", "10.1109/tvcg.2017.2754480", "10.1109/vast.2014.7042493", "10.1057/palgrave.ivs.9500122", "10.1109/tvcg.2014.2330617", "10.1109/tvcg.2019.2934541", "10.1068/p030033", "10.1140/epjds/s13688-017-0109-5", "10.1201/b17511", "10.1016/s0925-7721(02)00093-7", "10.1109/pacificvis.2012.6183557", "10.1109/tvcg.2014.2346983", "10.1109/5.726791", "10.1080/01621459.1926.10502165", "10.1109/tvcg.2007.70535", "10.1109/tvcg.2018.2864907", "10.1111/cgf.12109", "10.1109/tvcg.2017.2744184", "10.1146/annurev-statistics-031017-100045", "10.1111/cgf.13409", "10.1145/3002151.3002162", "10.1016/s0378-4371(98)00494-4", "10.3138/y308-2422-8615-1233", "10.1111/cgf.12632", "10.1145/3290605.3300771"], "wos": 1, "children": [], "len": 1}], "len": 7}, {"doi": "10.1109/tvcg.2019.2934432", "title": "Discriminability Tests for Visualization Effectiveness and Scalability", "year": "2019", "conferenceName": "InfoVis", "authors": "Rafael Veras;Christopher Collins", "citationCount": "1", "affiliation": "Veras, R (Corresponding Author), Ontario Tech Univ, Oshawa, ON, Canada. Veras, Rafael; Collins, Christopher, Ontario Tech Univ, Oshawa, ON, Canada.", "countries": "Canada", "abstract": "The scalability of a particular visualization approach is limited by the ability for people to discern differences between plots made with different datasets. Ideally, when the data changes, the visualization changes in perceptible ways. This relation breaks down when there is a mismatch between the encoding and the character of the dataset being viewed. Unfortunately, visualizations are often designed and evaluated without fully exploring how they will respond to a wide variety of datasets. We explore the use of an image similarity measure, the Multi-Scale Structural Similarity Index (MS-SSIM), for testing the discriminability of a data visualization across a variety of datasets. MS-SSIM is able to capture the similarity of two visualizations across multiple scales, including low level granular changes and high level patterns. Significant data changes that are not captured by the MS-SSIM indicate visualizations of low discriminability and effectiveness. The measure's utility is demonstrated with two empirical studies. In the first, we compare human similarity judgments and MS-SSIM scores for a collection of scatterplots. In the second, we compute the discriminability values for a set of basic visualizations and compare them with empirical measurements of effectiveness. In both cases, the analyses show that the computational measure is able to approximate empirical results. Our approach can be used to rank competing encodings on their discriminability and to aid in selecting visualizations for a particular type of data distribution.", "keywords": "Scalability,Discriminability,Simulation,Perception", "link": "http://dx.doi.org/10.1109/TVCG.2019.2934432", "refList": ["10.1109/tvcg.2012.233", "10.1109/tvcg.2017.2744359", "10.1109/tvcg.2012.230", "10.1111/cgf.12647", "10.1109/tvcg.2016.2598918", "10.1109/tvcg.2007.70529", "10.1145/2858036.2858435", "10.1109/vast.2009.5332628", "10.1145/3025453.3025912", "10.1145/1133265.1133318", "10.1109/tip.2010.2092435", "10.1109/tvcg.2010.132", "10.1109/tvcg.2018.2865264", "10.1175/jtech-d-11-00103.1", "10.1145/1190036.1190039", "10.1111/cgf.12127", "10.1109/infvis.2005.1532142", "10.1145/2858036.2858155", "10.1109/mcg.2014.18", "10.1145/3173574.3174172", "10.1109/tvcg.2009.153", "10.1057/palgrave.ivs.9500070", "10.1109/tvcg.2018.2790961", "10.1109/tvcg.2014.2346978", "10.1109/tvcg.2018.2810918", "10.1111/cgf.13409", "10.1109/tip.2003.819861", "10.1145/2642918.2647411", "10.1080/15230406.2016.1140074", "10.1109/jstsp.2009.2015374", "10.1109/tvcg.2010.237", "10.1109/mcg.2009.6", "10.1111/j.1467-8659.2009.01667.x", "10.1109/tvcg.2010.161", "10.1111/cgf.13446", "10.1109/tvcg.2014.2346325", "10.1109/tvcg.2009.111", "10.1147/jrd.2015.2411412"], "wos": 1, "children": [{"doi": "10.1109/tvcg.2020.3030394", "title": "Direct Volume Rendering with Nonparametric Models of Uncertainty", "year": "2020", "conferenceName": "SciVis", "authors": "Tushar M. Athawale;Bo Ma 0002;Elham Sakhaee;Christopher R. Johnson;Alireza Entezari", "citationCount": "0", "affiliation": "Athawale, TM (Corresponding Author), Univ Utah, Sci Comp \\& Imaging SCI Inst, Salt Lake City, UT 84112 USA. Athawale, Tushar M.; Johnson, Chris R., Univ Utah, Sci Comp \\& Imaging SCI Inst, Salt Lake City, UT 84112 USA. Ma, Bo; Sakhaee, Elham; Entezari, Alireza, Univ Florida, Dept CISE, Gainesville, FL 32611 USA.", "countries": "USA", "abstract": "We present a nonparametric statistical framework for the quantification, analysis, and propagation of data uncertainty in direct volume rendering (DVR). The state-of-the-art statistical DVR framework allows for preserving the transfer function (TF) of the ground truth function when visualizing uncertain data; however, the existing framework is restricted to parametric models of uncertainty. In this paper, we address the limitations of the existing DVR framework by extending the DVR framework for nonparametric distributions. We exploit the quantile interpolation technique to derive probability distributions representing uncertainty in viewing-ray sample intensities in closed form, which allows for accurate and efficient computation. We evaluate our proposed nonparametric statistical models through qualitative and quantitative comparisons with the mean-field and parametric statistical models, such as uniform and Gaussian, as well as Gaussian mixtures. In addition, we present an extension of the state-of-the-art rendering parametric framework to 2D TFs for improved DVR classifications. We show the applicability of our uncertainty quantification framework to ensemble, downsampled, and bivariate versions of scalar field datasets.", "keywords": "Volumes,uncertainty,nonparametric,2D transfer function", "link": "http://dx.doi.org/10.1109/TVCG.2020.3030394", "refList": ["10.1109/icdm.2012.80", "10.1145/1401890.1401904", "10.1109/tvcg.2017.2745139", "10.18128/d030.v6.0", "10.1111/cgf.12142", "10.1109/tvcg.2009.114", "10.1111/j.1467-8659.2009.01677.x", "10.1109/mcse.2007.55", "10.1109/icde.2012.16", "10.1198/106186008x320465", "10.1145/1835804.1835868", "10.1559/1523040054738936", "10.1109/tvcg.2019.2934432", "10.1109/34.1000236", "10.1109/infvis.2005.1532136", "10.1109/tvcg.2012.128", "10.1109/pacificvis.2017.8031573", "10.1109/tvcg.2016.2598920", "10.1109/tvcg.2018.2865021", "10.1109/infvis.2005.1532142", "10.1145/2858036.2858155", "10.1109/sp.2009.22", "10.1109/tvcg.2017.2744184", "10.1145/773153.773173", "10.1145/2660267.2660348", "10.1109/icdmw.2009.93", "10.1016/j.jtrangeo.2015.09.001", "10.1109/icde.2010.5447831", "10.1007/11681878\\_14", "10.1111/cgf.13409", "10.1007/s13278-014-0205-5", "10.1109/tvcg.2011.163", "10.1145/3035918.3035940", "10.1109/sp.2008.33", "10.1145/2882903.2882931"], "wos": 1, "children": [], "len": 1}], "len": 3}, {"doi": "10.1109/tvcg.2019.2934208", "title": "Evaluating Perceptual Bias During Geometric Scaling of Scatterplots", "year": "2019", "conferenceName": "VAST", "authors": "Yating Wei;Honghui Mei;Ying Zhao;Shuyue Zhou;Bingru Lin;Haojing Jiang;Wei Chen", "citationCount": "5", "affiliation": "Chen, W (Corresponding Author), Zhejiang Univ, State Key Lab CAD \\& CG, Hangzhou 310058, Zhejiang, Peoples R China. Zhao, Y (Corresponding Author), Cent South Univ, Sch Comp Sci \\& Engn, Changsha 410083, Hunan, Peoples R China. Wei, Yating; Mei, Honghui; Zhou, Shuyue; Lin, Bingru; Chen, Wei, Zhejiang Univ, State Key Lab CAD \\& CG, Hangzhou 310058, Zhejiang, Peoples R China. Zhao, Ying; Jiang, Haojing, Cent South Univ, Sch Comp Sci \\& Engn, Changsha 410083, Hunan, Peoples R China.", "countries": "China", "abstract": "Scatterplots are frequently scaled to fit display areas in multi-view and multi-device data analysis environments. A common method used for scaling is to enlarge or shrink the entire scatterplot together with the inside points synchronously and proportionally. This process is called geometric scaling. However, geometric scaling of scatterplots may cause a perceptual bias, that is, the perceived and physical values of visual features may be dissociated with respect to geometric scaling. For example, if a scatterplot is projected from a laptop to a large projector screen, then observers may feel that the scatterplot shown on the projector has fewer points than that viewed on the laptop. This paper presents an evaluation study on the perceptual bias of visual features in scatterplots caused by geometric scaling. The study focuses on three fundamental visual features (i.e., numerosity, correlation, and cluster separation) and three hypotheses that are formulated on the basis of our experience. We carefully design three controlled experiments by using well-prepared synthetic data and recruit participants to complete the experiments on the basis of their subjective experience. With a detailed analysis of the experimental results, we obtain a set of instructive findings. First, geometric scaling causes a bias that has a linear relationship with the scale ratio. Second, no significant difference exists between the biases measured from normally and uniformly distributed scatterplots. Third, changing the point radius can correct the bias to a certain extent. These findings can be used to inspire the design decisions of scatterplots in various scenarios.", "keywords": "Evaluation,scatterplot,geometric scaling,bias,perceptual consistency", "link": "http://dx.doi.org/10.1109/TVCG.2019.2934208", "refList": ["10.2307/2288843", "10.1109/tvcg.2017.2744359", "10.1109/tvcg.2015.2467732", "10.1109/tvcg.2014.2346979", "10.1126/science.216.4550.1138", "10.1109/tvcg.2017.2744138", "10.1111/j.1467-8659.2009.01467.x", "10.1145/2491568.2491577", "10.1109/mwc.2018.1700325", "10.1145/2449396.2449439", "10.1109/tvcg.2011.127", "10.1109/tvcg.2011.229", "10.1167/15.5.4", "10.1073/pnas.1113195108", "10.1145/2702123.2702545", "10.1109/vast.2009.5332628", "10.1109/tvcg.2018.2800013", "10.1007/s12650-018-0530-2", "10.1016/s0042-6989(97)00340-4", "10.1109/vast.2010.5652460", "10.1109/mcg.2018.2879067", "10.1109/tvcg.2018.2864912", "10.1109/pacificvis.2010.5429604", "10.1109/tcst.2018.2819965", "10.1167/10.2.10", "10.1145/2470654.2481318", "10.1145/1842993.1843002", "10.1167/12.6.8", "10.1109/tvcg.2013.124", "10.1057/ivs.2008.13", "10.1109/tvcg.2007.70596", "10.1109/tvcg.2018.2865266", "10.1145/3173574.3173664", "10.1109/tvcg.2015.2467671", "10.1016/j.cag.2017.07.004", "10.1177/0956797613501520", "10.1109/tvcg.2018.2865020", "10.1111/j.1467-8659.2012.03125.x", "10.3758/bf03205986", "10.3758/s13423-016-1174-7", "10.1109/tvcg.2017.2680452", "10.1109/mc.2006.109", "10.1109/tvcg.2017.2744098", "10.1038/srep32810", "10.1016/j.visres.2013.06.006", "10.1002/jhbs.20078", "10.1109/tvcg.2006.163", "10.1109/tvcg.2014.2346594", "10.1109/tvcg.2017.2744184", "10.1016/j.cognition.2007.10.009", "10.1109/tvcg.2018.2865142", "10.3758/app.72.7.1839", "10.1109/tvcg.2018.2810918", "10.1016/j.jvlc.2017.10.001", "10.1145/2682623", "10.1109/tvcg.2018.2864884", "10.1145/3025453.3025984", "10.1109/tvcg.2006.184", "10.1109/tvcg.2013.153", "10.1016/j.jvlc.2018.08.003", "10.1109/tvcg.2016.2520921", "10.1111/cgf.13446", "10.1017/s0022381612000187", "10.1145/2702123.2702406", "10.1109/vast.2012.6400487", "10.1109/tvcg.2013.183", "10.1177/1473871611415997", "10.1145/2702123.2702585", "10.1145/2993901.2993903", "10.1109/tvcg.2013.120", "10.1111/cgf.12632", "10.1145/1385569.1385602", "10.1109/tvcg.2017.2754480", "10.1111/j.1467-8659.2009.01694.x"], "wos": 1, "children": [{"doi": "10.1109/tvcg.2020.3030456", "title": "Cartographic Relief Shading with Neural Networks", "year": "2020", "conferenceName": "InfoVis", "authors": "Bernhard Jenny;Magnus Heitzler;Dilpreet Singh;Marianna Farmakis-Serebryakova;Jeffery Chieh Liu;Lorenz Hurni", "citationCount": "4", "affiliation": "Jenny, B (Corresponding Author), Monash Univ, Melbourne, Vic, Australia. Jenny, Bernhard; Singh, Dilpreet; Liu, Jeffery Chieh, Monash Univ, Melbourne, Vic, Australia. Heitzler, Magnus; Farmakis-Serebryakova, Marianna; Hurni, Lorenz, Swiss Fed Inst Technol, Inst Cartog \\& Geoinformat, Zurich, Switzerland.", "countries": "Switzerland;Australia", "abstract": "Shaded relief is an effective method for visualising terrain on topographic maps, especially when the direction of illumination is adapted locally to emphasise individual terrain features. However, digital shading algorithms are unable to fully match the expressiveness of hand-crafted masterpieces, which are created through a laborious process by highly specialised cartographers. We replicate hand-drawn relief shading using U-Net neural networks. The deep neural networks are trained with manual shaded relief images of the Swiss topographic map series and terrain models of the same area. The networks generate shaded relief that closely resemble hand-drawn shaded relief art. The networks learn essential design principles from manual relief shading such as removing unnecessary terrain details, locally adjusting the illumination direction to accentuate individual terrain features, and varying brightness to emphasise larger landforms. Neural network shadings are generated from digital elevation models in a few seconds, and a study with 18 relief shading experts found that they are of high quality.", "keywords": "Relief shading,shaded relief,hillshade,neural rendering,illustrative visualisation,image-to-image translation", "link": "http://dx.doi.org/10.1109/TVCG.2020.3030456", "refList": ["10.1145/1456650.1456652", "10.1145/1145/1556262.1556270", "10.1145/345513.345271", "10.1109/tvcg.2019.2934803", "10.1145/3180658", "10.1109/tridui.2006.1618264", "10.3389/fict.2018.00015", "10.1109/vr.2018.8447558", "10.1518/hfes.45.1.160.27234", "10.1145/3290605.3300377", "10.1089/cpb.2006.9.157", "10.1007/s00779-011-0500-3", "10.1109/vl.1996.545307", "10.1109/tvcg.2019.2934415", "10.1109/5.726791", "10.1145/3290605.3300288", "10.1109/tvcg.2017.2745941", "10.1109/vr.2001.913779", "10.1145/586081.586086", "10.18637/jss.v067.i01", "10.1145/1502800.1502805", "10.1145/1165734.1165736", "10.1145/3126594.3126613", "10.1109/tvcg.2008.109", "10.1109/tvcg.2017.2744184", "10.1016/j.cola.2019.100937", "10.1109/visual.2019.8933545", "10.1145/3290605.3300555", "10.1111/cgf.13431", "10.1109/tvcg.2019.2934395", "10.1109/vr.2019.8798340", "10.1145/3025453.3026046", "10.1109/vr.2019.8797871", "10.1145/3290605.3300752", "10.1109/tvcg.2016.2520921", "10.1109/tvcg.2018.2865191", "10.1145/1970378.1970384", "10.1109/tvcg.2019.2934208", "10.18637/jss.v069.i01", "10.1162/105474698565659", "10.1145/1124772.1124775", "10.1109/vrais.1997.583043"], "wos": 1, "children": [], "len": 1}, {"doi": "10.1109/tvcg.2020.3030443", "title": "CAVA: A Visual Analytics System for Exploratory Columnar Data Augmentation Using Knowledge Graphs", "year": "2020", "conferenceName": "VAST", "authors": "Dylan Cashman;Shenyu Xu;Subhajit Das;Florian Heimerl;Cong Liu;Shah Rukh Humayoun;Michael Gleicher;Alex Endert;Remco Chang", "citationCount": "0", "affiliation": "Cashman, D (Corresponding Author), Tufts Univ, Medford, MA 02155 USA. Cashman, Dylan; Liu, Cong; Chang, Remco, Tufts Univ, Medford, MA 02155 USA. Xu, Shenyu; Das, Subhajit; Endert, Alex, Georgia Tech, Atlanta, GA USA. Heimerl, Florian; Gleicher, Michael, Univ Wisconsin, Madison, WI 53706 USA. Humayoun, Shah Rukh, San Francisco State Univ, San Francisco, CA 94132 USA.", "countries": "USA", "abstract": "Most visual analytics systems assume that all foraging for data happens before the analytics process; once analysis begins, the set of data attributes considered is fixed. Such separation of data construction from analysis precludes iteration that can enable foraging informed by the needs that arise in-situ during the analysis. The separation of the foraging loop from the data analysis tasks can limit the pace and scope of analysis. In this paper, we present CAVA, a system that integrates data curation and data augmentation with the traditional data exploration and analysis tasks, enabling information foraging in-situ during analysis. Identifying attributes to add to the dataset is difficult because it requires human knowledge to determine which available attributes will be helpful for the ensuing analytical tasks. CAVA crawls knowledge graphs to provide users with a a broad set of attributes drawn from external data to choose from. Users can then specify complex operations on knowledge graphs to construct additional attributes. CAVA shows how visual analytics can help users forage for attributes by letting users visually explore the set of available data, and by serving as an interface for query construction. It also provides visualizations of the knowledge graph itself to help users understand complex joins such as multi-hop aggregations. We assess the ability of our system to enable users to perform complex data combinations without programming in a user study over two datasets. We then demonstrate the generalizability of CAVA through two additional usage scenarios. The results of the evaluation confirm that CAVA is effective in helping the user perform data foraging that leads to improved analysis outcomes, and offer evidence in support of integrating data augmentation as a part of the visual analytics pipeline.", "keywords": "Visual Analytics,Information Foraging,Data Augmentation", "link": "http://dx.doi.org/10.1109/TVCG.2020.3030443", "refList": ["10.1057/palgrave.ivs.9500122", "10.1109/tvcg.2016.2598867", "10.1111/cgf.13708", "10.1109/tvcg.2019.2934799", "10.1109/tvcg.2019.2934541", "10.1109/tvcg.2013.65", "10.1109/tvcg.2018.2875702", "10.1109/iv.2004.1320207", "10.1068/p260471", "10.1145/1778765.1778816", "10.1109/tvcg.2018.2808489", "10.1109/tvcg.2018.2864912", "10.1016/j.apgeog.2015.12.006", "10.1111/j.1467-8659.2011.01960.x", "10.1109/tvcg.2018.2864843", "10.1109/pacificvis.2010.5429604", "10.1109/tvcg.2014.2346898", "10.1109/5.726791", "10.1177/1475090214540874", "10.1109/icde.2016.7498287", "10.1145/1556262.1556289", "10.1109/tvcg.2007.70535", "10.1109/vast.2012.6400489", "10.1145/1056808.1056914", "10.1016/j.neucom.2014.09.063", "10.1145/7529.8927", "10.1109/tvcg.2016.2598495", "10.1109/tvcg.2016.2607204", "10.1109/vast47406.2019.8986943", "10.3758/bf03205986", "10.1109/infvis.2005.1532142", "10.1145/1150402.1150479", "10.1109/tvcg.2017.2674978", "10.1109/tvcg.2019.2945960", "10.1109/tvcg.2017.2744098", "10.1109/tvcg.2017.2674999", "10.1109/tvcg.2011.279", "10.1109/tvcg.2014.2346594", "10.1109/tvcg.2017.2744184", "10.1111/cgf.12876", "10.1007/s4095-020-0191-7", "10.1007/s11390-015-1535-0", "10.1111/cgf.12640", "10.1109/tvcg.2016.2598667", "10.1111/cgf.13683", "10.1109/tvcg.2013.153", "10.1109/tvcg.2019.2934208", "10.1109/tvcg.2019.2934655", "10.1111/cgf.12655", "10.1007/s11023-010-9221-z", "10.1109/vast.2012.6400487", "10.1145/2702123.2702585", "10.1007/bf00310175", "10.1109/tvcg.2017.2744378", "10.1103/physreve.64.061907", "10.1109/ldav.2017.8231848", "10.1109/tvcg.2016.2598831"], "wos": 1, "children": [], "len": 1}, {"doi": "10.1109/tvcg.2020.3030432", "title": "Evaluation of Sampling Methods for Scatterplots", "year": "2020", "conferenceName": "VAST", "authors": "Jun Yuan;Shouxing Xiang;Jiazhi Xia;Lingyun Yu;Shixia Liu", "citationCount": "0", "affiliation": "Liu, SX (Corresponding Author), Tsinghua Univ, BNRist, Beijing, Peoples R China. Yuan, Jun; Xiang, Shouxing; Liu, Shixia, Tsinghua Univ, BNRist, Beijing, Peoples R China. Xia, Jiazhi, Cent South Univ, Changsha, Peoples R China. Yu, Lingyun, Xian Jiaotong Liverpool Univ, Suzhou, Peoples R China.", "countries": "China", "abstract": "Given a scatterplot with tens of thousands of points or even more, a natural question is which sampling method should be used to create a small but \u201cgood\u201d scatterplot for a better abstraction. We present the results of a user study that investigates the influence of different sampling strategies on multi-class scatterplots. The main goal of this study is to understand the capability of sampling methods in preserving the density, outliers, and overall shape of a scatterplot. To this end, we comprehensively review the literature and select seven typical sampling strategies as well as eight representative datasets. We then design four experiments to understand the performance of different strategies in maintaining: 1) region density; 2) class density; 3) outliers; and 4) overall shape in the sampling results. The results show that: 1) random sampling is preferred for preserving region density; 2) blue noise sampling and random sampling have comparable performance with the three multi-class sampling strategies in preserving class density; 3) outlier biased density based sampling, recursive subdivision based sampling, and blue noise sampling perform the best in keeping outliers; and 4) blue noise sampling outperforms the others in maintaining the overall shape of a scatterplot.", "keywords": "Scatterplot,data sampling,empirical evaluation", "link": "http://dx.doi.org/10.1109/TVCG.2020.3030432", "refList": ["10.1057/palgrave.ivs.9500122", "10.1109/tvcg.2016.2598867", "10.1109/tvcg.2015.2467591", "10.1111/cgf.13708", "10.1109/tvcg.2019.2934799", "10.1109/tvcg.2019.2934541", "10.1109/tvcg.2013.65", "10.1109/iv.2004.1320207", "10.1068/p260471", "10.1145/1778765.1778816", "10.1109/tvcg.2018.2808489", "10.1109/tvcg.2018.2864912", "10.1016/j.apgeog.2015.12.006", "10.1111/j.1467-8659.2011.01960.x", "10.1109/tvcg.2018.2864843", "10.1109/pacificvis.2010.5429604", "10.1109/tvcg.2014.2346898", "10.1109/5.726791", "10.1177/1475090214540874", "10.1145/1556262.1556289", "10.1109/tvcg.2007.70535", "10.1109/vast.2012.6400489", "10.1145/1056808.1056914", "10.1016/j.neucom.2014.09.063", "10.1145/7529.8927", "10.1109/tvcg.2016.2607204", "10.1109/vast47406.2019.8986943", "10.3758/bf03205986", "10.1109/infvis.2005.1532142", "10.1145/1150402.1150479", "10.1109/tvcg.2017.2674978", "10.1109/tvcg.2017.2744098", "10.1109/tvcg.2017.2674999", "10.1109/tvcg.2011.279", "10.1109/tvcg.2014.2346594", "10.1109/tvcg.2017.2744184", "10.1111/cgf.12876", "10.1109/1011101.2019.2945960", "10.1007/s4095-020-0191-7", "10.1007/s11390-015-1535-0", "10.1111/cgf.12640", "10.1109/tvcg.2016.2598667", "10.1111/cgf.13683", "10.1109/tvcg.2013.153", "10.1109/tvcg.2019.2934208", "10.1109/tvcg.2019.2934655", "10.1111/cgf.12655", "10.1007/s11023-010-9221-z", "10.1109/vast.2012.6400487", "10.1145/2702123.2702585", "10.1007/bf00310175", "10.1109/tvcg.2017.2744378", "10.1103/physreve.64.061907", "10.1109/ldav.2017.8231848", "10.1109/tvcg.2016.2598831"], "wos": 1, "children": [], "len": 1}], "len": 7}, {"doi": "10.1109/tvcg.2019.2934300", "title": "GUIRO: User-Guided Matrix Reordering", "year": "2019", "conferenceName": "VAST", "authors": "Michael Behrisch;Tobias Schreck;Hanspeter Pfister", "citationCount": "1", "affiliation": "Behrisch, M (Corresponding Author), Harvard Univ, Sch Engn \\& Appl Sci, Cambridge, MA 02138 USA. Behrisch, Michael; Pfister, Hanspeter, Harvard Univ, Sch Engn \\& Appl Sci, Cambridge, MA 02138 USA. Schreck, Tobias, Graz Univ Technol, Graz, Austria.", "countries": "USA;Austria", "abstract": "Matrix representations are one of the main established and empirically proven to be effective visualization techniques for relational (or network) data. However, matrices\u2014similar to node-link diagrams\u2014are most effective if their layout reveals the underlying data topology. Given the many developed algorithms, a practical problem arises: \u201cWhich matrix reordering algorithm should I choose for my dataset at hand?\u201d To make matters worse, different reordering algorithms applied to the same dataset may let significantly different visual matrix patterns emerge. This leads to the question of trustworthiness and explainability of these fully automated, often heuristic, black-box processes. We present GUIRO, a Visual Analytics system that helps novices, network analysts, and algorithm designers to open the black-box. Users can investigate the usefulness and expressiveness of 70 accessible matrix reordering algorithms. For network analysts, we introduce a novel model space representation and two interaction techniques for a user-guided reordering of rows or columns, and especially groups thereof (submatrix reordering). These novel techniques contribute to the understanding of the global and local dataset topology. We support algorithm designers by giving them access to 16 reordering quality metrics and visual exploration means for comparing reordering implementations on a row/column permutation level. We evaluated GUIRO in a guided explorative user study with 12 subjects, a case study demonstrating its usefulness in a real-world scenario, and through an expert study gathering feedback on our design decisions. We found that our proposed methods help even inexperienced users to understand matrix patterns and allow a user-guided steering of reordering algorithms. GUIRO helps to increase the transparency of matrix reordering algorithms, thus helping a broad range of users to get a better insight into the complex reordering process, in turn supporting data and reordering algorithm insights.", "keywords": "Visual Analytics,matrix,black-box algorithms,seriation,ordering,sorting,steerable algorithm,interaction,2D projection", "link": "http://dx.doi.org/10.1109/TVCG.2019.2934300", "refList": ["10.1109/tvcg.2007.70582", "10.2307/276978", "10.1109/tvcg.2008.61", "10.3390/su10040973", "10.1101/121889", "10.1145/1345448.1345453", "10.1186/s12879-014-0695-9", "10.1186/1471-2105-9-155", "10.1145/1124772.1124891", "10.1109/tvcg.2010.159", "10.1111/j.2044-8317.1974.tb00534.x", "10.1109/tpami.2015.2470671", "10.1198/000313005x22770", "10.1109/tvcg.2012.219", "10.1002/sam.10071", "10.1016/j.ejor.2016.08.066", "10.1007/s00265-003-0651-y", "10.1109/biovis.2013.6664342", "10.3115/v1/p14-1062", "10.3389/fpsyg.2017.01349", "10.1109/tpami.2004.1265866", "10.1057/palgrave.ivs.9500086", "10.1007/s004260000031", "10.1111/cgf.12935", "10.1145/800195.805928", "10.1109/tvcg.2014.2346279", "10.2312/eurovisstar.20141174", "10.1109/tvcg.2012.256", "10.1093/bioinformatics/17.suppl\\_1.s22", "10.1109/infvis.2004.46", "10.1007/978-3-319-06793-3\\_5", "10.1109/tvcg.2006.147", "10.1109/tvcg.2015.2468078", "10.1093/bioinformatics/bti141", "10.1145/1168149.1168168", "10.1109/tvcg.2017.2745978", "10.1177/1473871613513228", "10.1109/mcg.2014.62", "10.1109/tvcg.2006.166", "10.1145/2470654.2470724", "10.1177/154193120605000909", "10.1109/sibgrapi.2007.21", "10.1145/3065386", "10.1109/tvcg.2006.160", "10.1287/opre.20.5.993", "10.1111/cgf.13446", "10.1057/palgrave.ivs.9500092", "10.1145/568522.568523", "10.1109/mcg.2013.66", "10.1109/tvcg.2018.2865940", "10.1109/tvcg.2012.208"], "wos": 1, "children": [{"doi": "10.1109/tvcg.2020.3030471", "title": "Visual Analysis of Discrimination in Machine Learning", "year": "2020", "conferenceName": "InfoVis", "authors": "Qianwen Wang;Zhenhua Xu;Zhutian Chen;Yong Wang;Shixia Liu;Huamin Qu", "citationCount": "0", "affiliation": "Wang, QW (Corresponding Author), Hong Kong Univ Sci \\& Technol, Hong Kong, Peoples R China. Wang, Qianwen; Xu, Zhenhua; Chen, Zhutian; Wang, Yong; Qu, Huamin, Hong Kong Univ Sci \\& Technol, Hong Kong, Peoples R China. Liu, Shixia, Tsinghua Univ, Beijing, Peoples R China.", "countries": "China", "abstract": "The growing use of automated decision-making in critical applications, such as crime prediction and college admission, has raised questions about fairness in machine learning. How can we decide whether different treatments are reasonable or discriminatory? In this paper, we investigate discrimination in machine learning from a visual analytics perspective and propose an interactive visualization tool, DiscriLens, to support a more comprehensive analysis. To reveal detailed information on algorithmic discrimination, DiscriLens identifies a collection of potentially discriminatory itemsets based on causal modeling and classification rules mining. By combining an extended Euler diagram with a matrix-based visualization, we develop a novel set visualization to facilitate the exploration and interpretation of discriminatory itemsets. A user study shows that users can interpret the visually encoded information in DiscriLens quickly and accurately. Use cases demonstrate that DiscriLens provides informative guidance in understanding and reducing algorithmic discrimination.", "keywords": "Machine Learning,Discrimination,Data Visualization", "link": "http://dx.doi.org/10.1109/TVCG.2020.3030471", "refList": ["10.1109/tvcg.2019.2934396", "10.2312/eurovisstar.20141170", "10.1145/3357384.3357910", "10.1111/cgf.12791", "10.1109/tvcg.2018.2861397", "10.1111/j.1467-8659.2011.01898.x", "10.1145/2702123.2702237", "10.1109/tvcg.2019.2934798", "10.1109/mcg.2017.21", "10.1109/tvcg.2019.2934300", "10.1109/tvcg.2017.2745085", "10.1109/tvcg.2018.2859997", "10.1145/3173574.3174237", "10.1109/tvcg.2018.2865126", "10.1145/1718487.1718520", "10.1109/tvcg.2017.2743858", "10.1109/pacificvis.2015.7156392", "10.1109/tvcg.2018.2864477", "10.1145/324133.324140", "10.1137/140976649", "10.1145/3219819.3220088", "10.1109/tvcg.2019.2934805", "10.1145/1134271.1134277", "10.1137/090772745", "10.1016/j.jelectrocard.2010.09.003", "10.1109/tvcg.2012.253", "10.1145/2556612", "10.1109/tvcg.2013.173", "10.1109/tvcg.2019.2934619", "10.1109/tvcg.2017.2745078"], "wos": 1, "children": [], "len": 1}], "len": 3}, {"doi": "10.1109/tvcg.2019.2934796", "title": "Improving the Robustness of Scagnostics", "year": "2019", "conferenceName": "InfoVis", "authors": "Yunhai Wang;Zeyu Wang 0005;Tingting Liu;Michael Correll;Zhanglin Cheng;Oliver Deussen;Michael Sedlmair", "citationCount": "1", "affiliation": "Wang, YH (Corresponding Author), Shandong Univ, Jinan, Peoples R China. Wang, Yunhai; Wang, Zeyu; Liu, Tingting, Shandong Univ, Jinan, Peoples R China. Wang, Zeyu; Cheng, Zhanglin; Deussen, Oliver, SIAT, Shenzhen VisuCA Key Lab, Shenzhen, Peoples R China. Correll, Michael, Tableau Res, Seattle, WA USA. Deussen, Oliver, Konstanz Univ, Constance, Germany. Sedlmair, Michael, Univ Stuttgart, VISUS, Stuttgart, Germany.", "countries": "USA;Germany;China", "abstract": "In this paper, we examine the robustness of scagnostics through a series of theoretical and empirical studies. First, we investigate the sensitivity of scagnostics by employing perturbing operations on more than 60M synthetic and real-world scatterplots. We found that two scagnostic measures, Outlying and Clumpy, are overly sensitive to data binning. To understand how these measures align with human judgments of visual features, we conducted a study with 24 participants, which reveals that i) humans are not sensitive to small perturbations of the data that cause large changes in both measures, and ii) the perception of clumpiness heavily depends on per-cluster topologies and structures. Motivated by these results, we propose Robust Scagnostics (RScag) by combining adaptive binning with a hierarchy-based form of scagnostics. An analysis shows that RScag improves on the robustness of original scagnostics, aligns better with human judgments, and is equally fast as the traditional scagnostic measures.", "keywords": "Scagnostics,scatterplots,sensitivity analysis,Robust Scagnostics", "link": "http://dx.doi.org/10.1109/TVCG.2019.2934796", "refList": ["10.1057/palgrave.ivs.9500122", "10.1109/tvcg.2014.2346979", "10.1111/j.1467-8659.2009.01467.x", "10.1109/vast.2008.4677368", "10.2307/2289444", "10.1109/tvcg.2011.229", "10.1109/iv.2004.1320207", "10.1109/vast.2009.5332628", "10.1111/insr.12095\\_11", "10.1109/tvcg.2010.184", "10.1109/tvcg.2015.2467323", "10.1109/vast.2010.5652460", "10.1111/j.1467-8659.2012.03069.x", "10.1145/1842993.1843002", "10.1198/106186008x320465", "10.1109/pacificvis.2016.7465244", "10.1109/tvcg.2013.20", "10.1111/cgf.12641", "10.1109/tvcg.2012.128", "10.1109/tvcg.2015.2467671", "10.1057/palgrave.ivs.9500091", "10.1007/978-1-4612-4400-4", "10.1111/cgf.13176", "10.1002/0470870958", "10.1109/tvcg.2018.2864907", "10.1111/j.1467-8659.2012.03125.x", "10.1109/vast.2012.6400490", "10.1109/infvis.2005.1532142", "10.1109/vast.2010.5652433", "10.1109/vast.2009.5332611", "10.1201/9781315140919", "10.1145/2858036.2858155", "10.1109/ldav.2013.6675164", "10.1515/itit-2014-1070", "10.1111/cgf.13684", "10.1109/tpami.1979.4766909", "10.2307/2289936", "10.1109/pacificvis.2014.42", "10.1109/tvcg.2016.2598467", "10.1109/tvcg.2013.153", "10.1111/cgf.13446", "10.1109/tvcg.2006.94", "10.1109/tvcg.2014.2346572", "10.1111/cgf.12632", "10.1109/tvcg.2017.2744339"], "wos": 1, "children": [], "len": 1}, {"doi": "10.1109/vast47406.2019.8986917", "title": "VIANA: Visual Interactive Annotation of Argumentation", "year": "2019", "conferenceName": "VAST", "authors": "Fabian Sperrle;Rita Sevastjanova;Rebecca Kehlbeck;Mennatallah El-Assady", "citationCount": "0", "affiliation": "Sperrle, F (Corresponding Author), Univ Konstanz, Constance, Germany. Sperrle, Fabian; Sevastjanova, Rita; Kehlbeck, Rebecca; El-Assady, Mennatallah, Univ Konstanz, Constance, Germany.", "countries": "Germany", "abstract": "Argumentation Mining addresses the challenging tasks of identifying boundaries of argumentative text fragments and extracting their relationships. Fully automated solutions do not reach satisfactory accuracy due to their insufficient incorporation of semantics and domain knowledge. Therefore, experts currently rely on time-consuming manual annotations. In this paper, we present a visual analytics system that augments the manual annotation process by automatically suggesting which text fragments to annotate next. The accuracy of those suggestions is improved over time by incorporating linguistic knowledge and language modeling to learn a measure of argument similarity from user interactions. Based on a long-term collaboration with domain experts, we identify and model five high-level analysis tasks. We enable close reading and note-taking, annotation of arguments, argument reconstruction, extraction of argument relations, and exploration of argument graphs. To avoid context switches, we transition between all views through seamless morphing, visually anchoring all text- and graph-based layers. We evaluate our system with a two-stage expert user study based on a corpus of presidential debates. The results show that experts prefer our system over existing solutions due to the speedup provided by the automatic suggestions and the tight integration between text and graph views.", "keywords": "Argumentation annotation,machine learning,user interaction,layered interfaces,semantic transitions", "link": "http://dx.doi.org/10.1109/VAST47406.2019.8986917", "refList": ["10.1007/978-3-642-40624-9\\_1", "10.3233/978-1-61499-436-7-185", "10.1145/371920.372071", "10.3233/978-1-61499-906-5-4", "10.1109/tvcg.2015.2467759", "10.18653/v1/d15-1050", "10.2307/2529310", "10.1109/mic.2003.1167344", "10.1145/312624.312682", "10.1145/2850417", "10.18653/v1/p17-2039", "10.1016/j.eswa.2016.02.013", "10.1007/978-0-387-85820-3\\_3", "10.1007/s11412-009-9080-x", "10.1109/tvcg.2008.127", "10.1145/2207676.2207741", "10.1109/cit.2012.217", "10.3233/aac-170022", "10.1109/tvcg.2017.2745080", "10.1007/978-3-319-44039-2\\_6", "10.1145/3290605.3300233", "10.1007/978-94-017-0431-1", "10.3233/978-1-61499-906-5-313", "10.1142/s0218213004001922", "10.1109/tvcg.2012.262", "10.1177/001316446002000104", "10.1109/tvcg.2018.2834341", "10.3233/978-1-61499-436-7-463", "10.1145/1772690.1772773", "10.1109/tvcg.2014.2346677", "10.1145/2523813", "10.1162/153244303322533223", "10.1109/tvcg.2007.70539", "10.1109/tvcg.2015.2467531", "10.1109/tvcg.2018.2864769", "10.1007/978-3-319-90092-6\\_14", "10.1137/1.9781611972801.19", "10.1109/vast.2012.6400485", "10.1007/s10579-013-9215-6", "10.3115/v1/d14-1162", "10.1111/cgf.13446", "10.1109/tvcg.2006.156", "10.1111/cgf.13092", "10.1145/2645710.2645759", "10.1109/bigdata.2017.8258140", "10.1145/2669557.2669572", "10.2312/eurovisstar.20151113"], "wos": 1, "children": [], "len": 1}, {"doi": "10.1109/tvcg.2020.3030376", "title": "Insight Beyond Numbers: The Impact of Qualitative Factors on Visual Data Analysis", "year": "2020", "conferenceName": "VAST", "authors": "Benjamin Karer;Hans Hagen;Dirk J. Lehmann", "citationCount": "0", "affiliation": "Karer, B (Corresponding Author), Fed Criminal Police Off Germany, Wiesbaden, Germany. Karer, Benjamin, Fed Criminal Police Off Germany, Wiesbaden, Germany. Hagen, Hans, TU Kaiserslautern, Kaiserslautern, Germany. Lehmann, Dirk J., Ostfalia Univ Appl Sci, Wolfenbuttel, Germany. Lehmann, Dirk J., IAV GmbH, Berlin, Germany.", "countries": "Germany", "abstract": "As of today, data analysis focuses primarily on the findings to be made inside the data and concentrates less on how those findings relate to the domain of investigation. Contemporary visualization as a field of research shows a strong tendency to adopt this data-centrism. Despite their decisive influence on the analysis result, qualitative aspects of the analysis process such as the structure, soundness, and complexity of the applied reasoning strategy are rarely discussed explicitly. We argue that if the purpose of visualization is the provision of domain insight rather than the depiction of data analysis results, a holistic perspective requires a qualitative component to to be added to the discussion of quantitative and human factors. To support this point, we demonstrate how considerations of qualitative factors in visual analysis can be applied to obtain explanations and possible solutions for a number of practical limitations inherent to the data-centric perspective on analysis. Based on this discussion of what we call qualitative visual analysis, we develop an inside-outside principle of nested levels of context that can serve as a conceptual basis for the development of visualization systems that optimally support the emergence of insight during analysis.", "keywords": "Visualization,Reasoning,Qualitative Aspects", "link": "http://dx.doi.org/10.1109/TVCG.2020.3030376", "refList": ["10.1057/ivs.2009.22", "10.1109/tvcg.2015.2467732", "10.1109/infvis.2000.885092", "10.1109/vast.2014.7042482", "10.1145/1498700.1498704", "10.1109/tvcg.2009.108", "10.1109/tvcg.2018.2829750", "10.1037/0033-295x.111.4.1036", "10.1109/tvcg.2012.199", "10.1109/38.267476", "10.1007/978-3-540-70956-5\\_2", "10.1109/tvcg.2015.2467613", "10.1109/tvcg.2015.2467195", "10.1109/tvcg.2014.2346419", "10.1109/vast.2017.8585669", "10.1109/tvcg.2010.132", "10.1145/22949.22950", "10.1109/tvcg.2014.2346984", "10.1017/cbo9780511816772", "10.1109/mcg.2003.1231171", "10.1111/coin.12227", "10.1109/tvcg.2018.2865138", "10.1109/38.788803", "10.1109/tvcg.2018.2864849", "10.1109/mcg.2012.120", "10.1109/tvcg.2007.70535", "10.1162/neco.2008.12-06-420", "10.1109/tvcg.2018.2865240", "10.1089/tmj.2010.0114", "10.1109/beliv.2018.8634267", "10.1109/tvcg.2014.2346481", "10.1207/s15327809jls0402\\_2", "10.1109/tvcg.2006.80", "10.1145/2858036.2858280", "10.1109/tvcg.2017.2674978", "10.1109/tvcg.2011.52", "10.1016/j.cag.2014.03.002", "10.1109/tvcg.2015.2513410", "10.1111/j.1756-8765.2011.01150.x", "10.1109/infvis.2005.1532142", "10.1002/spe.4380211102", "10.1186/s41235-018-0120-9", "10.1073/pnas.1807180116", "10.1109/tvcg.2012.133", "10.1109/tvcg.2012.273", "10.1111/j.1467-8659.2011.01928.x", "10.1145/353485.353486", "10.1109/tvcg.2015.2462356", "10.1109/mcg.2019.2923483", "10.1111/cgf.13264", "10.1057/palgrave.ivs.9500070", "10.1145/1168149.1168158", "10.1109/mcg.2019.2961716", "10.1016/s0167-739x(96)00029-5", "10.1111/j.1467-8659.2009.01667.x", "10.1177/1473871611415989", "10.1109/tvcg.2013.234", "10.1109/iv.2012.33", "10.1111/cgf.13446", "10.1057/ivs.2008.28", "10.1111/cgf.12379", "10.1037/0033-295x.112.1.159", "10.1109/tvcg.2010.161", "10.1109/tvcg.2017.2744319", "10.1145/989863.989880", "10.1007/s11390-016-1663-1", "10.1177/1473871615609787", "10.1016/j.cola.2019.100911"], "wos": 1, "children": [], "len": 1}, {"doi": "10.1109/tvcg.2020.3030395", "title": "Towards Modeling Visualization Processes as Dynamic Bayesian Networks", "year": "2020", "conferenceName": "InfoVis", "authors": "Christian Heine 0002", "citationCount": "0", "affiliation": "Heine, C (Corresponding Author), Univ Leipzig, Leipzig, Germany. Heine, Christian, Univ Leipzig, Leipzig, Germany.", "countries": "Germany", "abstract": "Visualization designs typically need to be evaluated with user studies, because their suitability for a particular task is hard to predict. What the field of visualization is currently lacking are theories and models that can be used to explain why certain designs work and others do not. This paper outlines a general framework for modeling visualization processes that can serve as the first step towards such a theory. It surveys related research in mathematical and computational psychology and argues for the use of dynamic Bayesian networks to describe these time-dependent, probabilistic processes. It is discussed how these models could be used to aid in design evaluation. The development of concrete models will be a long process. Thus, the paper outlines a research program sketching how to develop prototypes and their extensions from existing models, controlled experiments, and observational studies.", "keywords": "Visualization,model building,perception,cognition,dynamic Bayesian networks", "link": "http://dx.doi.org/10.1109/TVCG.2020.3030395", "refList": ["10.1057/ivs.2009.22", "10.1109/tvcg.2015.2467732", "10.1109/infvis.2000.885092", "10.1109/vast.2014.7042482", "10.1145/1498700.1498704", "10.1109/tvcg.2009.108", "10.1109/tvcg.2018.2829750", "10.1037/0033-295x.111.4.1036", "10.1109/tvcg.2012.199", "10.1111/cgf.13899", "10.1109/38.267476", "10.1007/978-3-540-70956-5\\_2", "10.1109/tvcg.2015.2467613", "10.1109/tvcg.2015.2467195", "10.1109/tvcg.2014.2346419", "10.1145/3290605.3300562", "10.1109/vl.1996.545307", "10.1109/vast.2017.8585669", "10.1109/infvis.2003.1249004", "10.1109/tvcg.2010.132", "10.1145/22949.22950", "10.1109/tvcg.2014.2346984", "10.1145/3290605.3300418", "10.1017/cbo9780511816772", "10.1109/mcg.2003.1231171", "10.1111/coin.12227", "10.1109/tvcg.2018.2865138", "10.1109/38.788803", "10.1109/tvcg.2018.2864849", "10.1109/mcg.2012.120", "10.1109/tvcg.2007.70535", "10.1162/neco.2008.12-06-420", "10.1109/tvcg.2018.2865240", "10.1089/tmj.2010.0114", "10.1109/beliv.2018.8634267", "10.1109/tvcg.2014.2346481", "10.1207/s15327809jls0402\\_2", "10.1109/tvcg.2006.80", "10.1145/2858036.2858280", "10.1109/tvcg.2017.2674978", "10.1109/tvcg.2011.52", "10.1016/j.cag.2014.03.002", "10.1109/tvcg.2015.2513410", "10.1111/j.1756-8765.2011.01150.x", "10.1109/infvis.2005.1532142", "10.1002/spe.4380211102", "10.1186/s41235-018-0120-9", "10.1073/pnas.1807180116", "10.1109/tvcg.2012.133", "10.1109/tvcg.2012.273", "10.1111/j.1467-8659.2011.01928.x", "10.1145/353485.353486", "10.1109/tvcg.2015.2462356", "10.1109/mcg.2019.2923483", "10.1111/cgf.13264", "10.1057/palgrave.ivs.9500070", "10.1145/1168149.1168158", "10.1109/mcg.2019.2961716", "10.1016/s0167-739x(96)00029-5", "10.1111/j.1467-8659.2009.01667.x", "10.1177/1473871611415989", "10.1109/tvcg.2013.234", "10.1109/iv.2012.33", "10.1111/cgf.13446", "10.1057/ivs.2008.28", "10.1111/cgf.12379", "10.1037/0033-295x.112.1.159", "10.1017/cb09781139033916.005", "10.1109/tvcg.2010.161", "10.1109/tvcg.2017.2744319", "10.1145/989863.989880", "10.1007/s11390-016-1663-1", "10.1177/1473871615609787", "10.1016/j.cola.2019.100911", "10.1057/palgrave.ivs.9500025"], "wos": 1, "children": [], "len": 1}, {"doi": "10.1109/pacificvis48177.2020.8199", "year": "2020", "title": "Efficient Morphing of Shape-preserving Star Coordinates", "conferenceName": "PacificVis", "authors": "Vladimir Molchanov;Sagad Hamid;Lars Linsen", "citationCount": "0", "affiliation": "Molchanov, V (Corresponding Author), Westfalische Wilhelms Univ Munster, Munster, Germany.\nMolchanov, Vladimir; Hamid, Sagad; Linsen, Lars, Westfalische Wilhelms Univ Munster, Munster, Germany.", "countries": "Germany", "abstract": "Data tours follow an exploratory multi-dimensional data visualization concept that provides animations of projections of the multidimensional data to a 2D visual space. To create an animation, a sequence of key projections is provided and morphings between each pair of consecutive key projections are computed, which then can be stitched together to form the data tour. The morphings should be smooth so that a user can easily follow the transformations, and their computations shall be fast to allow for their integration into an interactive visual exploration process. Moreover, if the key projections are chosen to satisfy additional conditions, it is desirable that these conditions are maintained during morphing. Shape preservation is such a desirable condition, as it avoids shape distortions that may otherwise be caused by a projection. We develop a novel efficient morphing algorithms for computing shape-preserving data tours, i.e., data tours constructed for a sequence of shape-preserving linear projections. We propose a stepping strategy for the morphing to avoid discontinuities in the evolution of the projections, where we represent the linear projections using a star-coordinates system. Our algorithms are less computationally involved, produce smoother morphings, and require less user-defined parameter settings than existing state-of-the-art approaches.", "keywords": "Human-centered computing; Visualization; Visualization techniques", "link": "https://doi.org/10.1109/PacificVis48177.2020.8199", "refList": ["10.2312/eurovisshort.20141152", "10.1109/tvcg.2013.182", "10.1109/tvcg.2008.153", "10.1109/tvcg.2015.2467591", "10.4135/9781412985130", "10.1111/cgf.12878", "10.1016/j.cag.2016.08.007", "10.1080/10618600.1995.10474674", "10.1109/infvis.2003.1249004", "10.1002/9781118445112.stat06472", "10.1109/visual.1997.663916", "10.1111/cgf.12117", "10.1137/0906011", "10.1109/tvcg.2018.2865118", "10.1126/science.290.5500.2319", "10.1111/cgf.12845", "10.1111/j.1467-8659.2012.03125.x", "10.1109/tvcg.2017.2705189", "10.1002/0471725293", "10.1111/cgf.12876", "10.1111/cgf.13404", "10.2307/2289161", "10.1111/cgf.13446", "10.1198/106186008x318440", "10.2307/1390747", "10.1109/tvcg.2012.35", "10.1109/tvcg.2015.2467132", "10.1109/tvcg.2006.94", "10.1109/t-c.1974.224051", "10.1109/pacificvis.2019.00018", "10.1109/tvcg.2017.2744339", "10.1109/tsmcb.2005.850151"], "wos": 1, "children": [], "len": 1}, {"doi": "10.1109/pacificvis.2019.00018", "year": "2019", "title": "Scatterplot Summarization by Constructing Fast and Robust Principal Graphs from Skeletons", "conferenceName": "PacificVis", "authors": "Jos{\\'{e}} Matute;Marcel Fischer;Alexandru C. Telea;Lars Linsen", "citationCount": "1", "affiliation": "Matute, J (Corresponding Author), Univ Munster, Munster, Germany.\nMatute, Jose; Fischer, Marcel; Linsen, Lars, Univ Munster, Munster, Germany.\nTelea, Alexandru C., Univ Groningen, Groningen, Netherlands.", "countries": "Germany;Netherlands", "abstract": "Principal curves are a long-standing and well-known method for summarizing large scatterplots. They are defined as self-consistent curves (or curve sets in the more general case) that locally pass through the middle of the scatterplot data. However, computing principal curves that capture well complex scatterplot topologies and are robust to noise is hard and/or slow for large scatterplots. We present a fast and robust approach for computing principal graphs (a generalization of principal curves for more complex topologies) inspired by the similarity to medial descriptors (curves locally centered in a shape). Compared to state-of-the-art methods for computing principal graphs, we outperform these in terms of computational scalability and robustness to noise and resolution. We also demonstrate the advantages of our method over other scatterplot summarization approaches.", "keywords": "", "link": "https://doi.org/10.1109/PacificVis.2019.00018", "refList": ["10.1016/j.cag.2014.01.006", "10.1016/s0167-8655(02)00032-6", "10.1006/jmva.2000.1917", "10.1111/cgf.12386", "10.1109/vast.2008.4677367", "10.1109/tpami.2004.1261076", "10.1111/cgf.12865", "10.1109/tvcg.2010.213", "10.1109/tvcg.2014.2346455", "10.1109/tvcg.2011.233", "10.1111/j.1467-8659.2009.01680.x", "10.1109/tvcg.2016.2515611", "10.1109/tit.1982.1056489", "10.1109/34.899944", "10.1007/bf01889678", "10.1137/s0036144599352836", "10.1145/2858036.2858155", "10.1002/jhbs.20078", "10.1198/jcgs.2011.09224", "10.1109/tvcg.2017.2744184", "10.1057/ivs.2010.2", "10.1111/j.1467-8659.2012.03107.x", "10.2307/2289936", "10.1109/pacificvis.2014.42", "10.1109/tpami.2008.21", "10.1111/cgf.13446", "10.2307/2290446", "10.1109/34.982884", "10.1109/tvcg.2006.94", "10.2307/2288711", "10.1117/12.304651", "10.5201/ipol.2013.87", "10.1109/mlsp.2008.4685520"], "wos": 1, "children": [{"doi": "10.1109/pacificvis48177.2020.8199", "year": "2020", "title": "Efficient Morphing of Shape-preserving Star Coordinates", "conferenceName": "PacificVis", "authors": "Vladimir Molchanov;Sagad Hamid;Lars Linsen", "citationCount": "0", "affiliation": "Molchanov, V (Corresponding Author), Westfalische Wilhelms Univ Munster, Munster, Germany.\nMolchanov, Vladimir; Hamid, Sagad; Linsen, Lars, Westfalische Wilhelms Univ Munster, Munster, Germany.", "countries": "Germany", "abstract": "Data tours follow an exploratory multi-dimensional data visualization concept that provides animations of projections of the multidimensional data to a 2D visual space. To create an animation, a sequence of key projections is provided and morphings between each pair of consecutive key projections are computed, which then can be stitched together to form the data tour. The morphings should be smooth so that a user can easily follow the transformations, and their computations shall be fast to allow for their integration into an interactive visual exploration process. Moreover, if the key projections are chosen to satisfy additional conditions, it is desirable that these conditions are maintained during morphing. Shape preservation is such a desirable condition, as it avoids shape distortions that may otherwise be caused by a projection. We develop a novel efficient morphing algorithms for computing shape-preserving data tours, i.e., data tours constructed for a sequence of shape-preserving linear projections. We propose a stepping strategy for the morphing to avoid discontinuities in the evolution of the projections, where we represent the linear projections using a star-coordinates system. Our algorithms are less computationally involved, produce smoother morphings, and require less user-defined parameter settings than existing state-of-the-art approaches.", "keywords": "Human-centered computing; Visualization; Visualization techniques", "link": "https://doi.org/10.1109/PacificVis48177.2020.8199", "refList": ["10.2312/eurovisshort.20141152", "10.1109/tvcg.2013.182", "10.1109/tvcg.2008.153", "10.1109/tvcg.2015.2467591", "10.4135/9781412985130", "10.1111/cgf.12878", "10.1016/j.cag.2016.08.007", "10.1080/10618600.1995.10474674", "10.1109/infvis.2003.1249004", "10.1002/9781118445112.stat06472", "10.1109/visual.1997.663916", "10.1111/cgf.12117", "10.1137/0906011", "10.1109/tvcg.2018.2865118", "10.1126/science.290.5500.2319", "10.1111/cgf.12845", "10.1111/j.1467-8659.2012.03125.x", "10.1109/tvcg.2017.2705189", "10.1002/0471725293", "10.1111/cgf.12876", "10.1111/cgf.13404", "10.2307/2289161", "10.1111/cgf.13446", "10.1198/106186008x318440", "10.2307/1390747", "10.1109/tvcg.2012.35", "10.1109/tvcg.2015.2467132", "10.1109/tvcg.2006.94", "10.1109/t-c.1974.224051", "10.1109/pacificvis.2019.00018", "10.1109/tvcg.2017.2744339", "10.1109/tsmcb.2005.850151"], "wos": 1, "children": [], "len": 1}], "len": 3}, {"doi": "10.1111/cgf.13684", "year": "2019", "title": "ClustMe: A Visual Quality Measure for Ranking Monochrome Scatterplots based on Cluster Patterns", "conferenceName": "EuroVis", "authors": "Mostafa M. Abbas;Micha{\\\"{e}}l Aupetit;Michael Sedlmair;Halima Bensmail", "citationCount": "4", "affiliation": "Abbas, MM (Corresponding Author), HBKU, QCRI, Doha, Qatar.\nAbbas, Mostafa M.; Aupetit, Michael; Bensmail, Halima, HBKU, QCRI, Doha, Qatar.\nSedlmair, Michael, Univ Stuttgart, VISUS, Stuttgart, Germany.", "countries": "Qatar;Germany", "abstract": "We propose ClustMe, a new visual quality measure to rank monochrome scatterplots based on cluster patterns. ClustMe is based on data collected from a human-subjects study, in which 34 participants judged synthetically generated cluster patterns in 1000 scatterplots. We generated these patterns by carefully varying the free parameters of a simple Gaussian Mixture Model with two components, and asked the participants to count the number of clusters they could see (1 or more than 1). Based on the results, we form ClustMe by selecting the model that best predicts these human judgments among 7 different state-of-the-art merging techniques (Demp). To quantitatively evaluate ClustMe, we conducted a second study, in which 31 human subjects ranked 435 pairs of scatterplots of real and synthetic data in terms of cluster patterns complexity. We use this data to compare ClustMe's performance to 4 other state-of-the-art clustering measures, including the well-known Clumpiness scagnostics. We found that of all measures, ClustMe is in strongest agreement with the human rankings.", "keywords": "", "link": "https://doi.org/10.1111/cgf.13684", "refList": ["10.1109/tvcg.2014.2330617", "10.1109/tvcg.2014.2346979", "10.1109/tvcg.2017.2744138", "10.1109/tvcg.2017.2701829", "10.2307/2529310", "10.1109/tvcg.2011.229", "10.1109/vast.2011.6102437", "10.1068/p030033", "10.1016/j.jvcir.2011.01.005", "10.1109/tnn.2005.845141", "10.1145/2669557.2669559", "10.1167/8.7.6", "10.1145/2993901.2993907", "10.1145/2803140.2803143", "10.1145/1842993.1843002", "10.1109/pacificvis.2016.7465244", "10.1109/tvcg.2013.124", "10.1057/ivs.2008.13", "10.1109/vast.2012.6400488", "10.1111/j.1467-9574.2008.00412.x", "10.1214/aos/1176344136", "10.1109/tvcg.2015.2467671", "10.3138/y308-2422-8615-1233", "10.1111/j.1467-8659.2012.03125.x", "10.1177/001316446002000104", "10.1145/2858036.2858155", "10.1007/s11634-010-0058-3", "10.1214/009053605000000417", "10.1109/tvcg.2009.153", "10.1023/a:1018510926151", "10.1109/tvcg.2014.2346978", "10.1007/s10816-016-9307-x", "10.1177/0301006615602599", "10.1109/pacificvis.2014.42", "10.1162/neco.1991.3.2.246", "10.1007/3-540-44491-2\\_3", "10.1109/tvcg.2013.153", "10.1111/cgf.13446", "10.1109/tvcg.2018.2846735", "10.2307/2291604", "10.1109/inf0vis.2005.14", "10.1198/016214502760047131", "10.1007/s00180-008-0119-7", "10.1109/t-c.1974.224051", "10.1111/cgf.12632", "10.1109/tvcg.2017.2744339", "10.1111/j.1467-8659.2009.01694.x"], "wos": 1, "children": [{"doi": "10.1109/tvcg.2019.2934796", "title": "Improving the Robustness of Scagnostics", "year": "2019", "conferenceName": "InfoVis", "authors": "Yunhai Wang;Zeyu Wang 0005;Tingting Liu;Michael Correll;Zhanglin Cheng;Oliver Deussen;Michael Sedlmair", "citationCount": "1", "affiliation": "Wang, YH (Corresponding Author), Shandong Univ, Jinan, Peoples R China. Wang, Yunhai; Wang, Zeyu; Liu, Tingting, Shandong Univ, Jinan, Peoples R China. Wang, Zeyu; Cheng, Zhanglin; Deussen, Oliver, SIAT, Shenzhen VisuCA Key Lab, Shenzhen, Peoples R China. Correll, Michael, Tableau Res, Seattle, WA USA. Deussen, Oliver, Konstanz Univ, Constance, Germany. Sedlmair, Michael, Univ Stuttgart, VISUS, Stuttgart, Germany.", "countries": "USA;Germany;China", "abstract": "In this paper, we examine the robustness of scagnostics through a series of theoretical and empirical studies. First, we investigate the sensitivity of scagnostics by employing perturbing operations on more than 60M synthetic and real-world scatterplots. We found that two scagnostic measures, Outlying and Clumpy, are overly sensitive to data binning. To understand how these measures align with human judgments of visual features, we conducted a study with 24 participants, which reveals that i) humans are not sensitive to small perturbations of the data that cause large changes in both measures, and ii) the perception of clumpiness heavily depends on per-cluster topologies and structures. Motivated by these results, we propose Robust Scagnostics (RScag) by combining adaptive binning with a hierarchy-based form of scagnostics. An analysis shows that RScag improves on the robustness of original scagnostics, aligns better with human judgments, and is equally fast as the traditional scagnostic measures.", "keywords": "Scagnostics,scatterplots,sensitivity analysis,Robust Scagnostics", "link": "http://dx.doi.org/10.1109/TVCG.2019.2934796", "refList": ["10.1057/palgrave.ivs.9500122", "10.1109/tvcg.2014.2346979", "10.1111/j.1467-8659.2009.01467.x", "10.1109/vast.2008.4677368", "10.2307/2289444", "10.1109/tvcg.2011.229", "10.1109/iv.2004.1320207", "10.1109/vast.2009.5332628", "10.1111/insr.12095\\_11", "10.1109/tvcg.2010.184", "10.1109/tvcg.2015.2467323", "10.1109/vast.2010.5652460", "10.1111/j.1467-8659.2012.03069.x", "10.1145/1842993.1843002", "10.1198/106186008x320465", "10.1109/pacificvis.2016.7465244", "10.1109/tvcg.2013.20", "10.1111/cgf.12641", "10.1109/tvcg.2012.128", "10.1109/tvcg.2015.2467671", "10.1057/palgrave.ivs.9500091", "10.1007/978-1-4612-4400-4", "10.1111/cgf.13176", "10.1002/0470870958", "10.1109/tvcg.2018.2864907", "10.1111/j.1467-8659.2012.03125.x", "10.1109/vast.2012.6400490", "10.1109/infvis.2005.1532142", "10.1109/vast.2010.5652433", "10.1109/vast.2009.5332611", "10.1201/9781315140919", "10.1145/2858036.2858155", "10.1109/ldav.2013.6675164", "10.1515/itit-2014-1070", "10.1111/cgf.13684", "10.1109/tpami.1979.4766909", "10.2307/2289936", "10.1109/pacificvis.2014.42", "10.1109/tvcg.2016.2598467", "10.1109/tvcg.2013.153", "10.1111/cgf.13446", "10.1109/tvcg.2006.94", "10.1109/tvcg.2014.2346572", "10.1111/cgf.12632", "10.1109/tvcg.2017.2744339"], "wos": 1, "children": [], "len": 1}, {"doi": "10.1109/tvcg.2020.3030365", "title": "Modeling the Influence of Visual Density on Cluster Perception in Scatterplots Using Topology", "year": "2020", "conferenceName": "InfoVis", "authors": "Ghulam Jilani Quadri;Paul Rosen", "citationCount": "0", "affiliation": "Quadri, GJ (Corresponding Author), Univ S Florida, Tampa, FL 33620 USA. Quadri, Ghulam Jilani; Rosen, Paul, Univ S Florida, Tampa, FL 33620 USA.", "countries": "USA", "abstract": "Scatterplots are used for a variety of visual analytics tasks, including cluster identification, and the visual encodings used on a scatterplot play a deciding role on the level of visual separation of clusters. For visualization designers, optimizing the visual encodings is crucial to maximizing the clarity of data. This requires accurately modeling human perception of cluster separation, which remains challenging. We present a multi-stage user study focusing on four factors-distribution size of clusters, number of points, size of points, and opacity of points-that influence cluster identification in scatterplots. From these parameters, we have constructed two models, a distance-based model, and a density-based model, using the merge tree data structure from Topological Data Analysis. Our analysis demonstrates that these factors play an important role in the number of clusters perceived, and it verifies that the distance-based and density-based models can reasonably estimate the number of clusters a user observes. Finally, we demonstrate how these models can be used to optimize visual encodings on real-world data.", "keywords": "Scatterplot,clustering,perception,empirical evaluation,visual encoding,crowdsourcing,topological data analysis", "link": "http://dx.doi.org/10.1109/TVCG.2020.3030365", "refList": ["10.1109/tvcg.2017.2744359", "10.1145/1778765", "10.1109/tvcg.2019.2934799", "10.1111/cgf.12889", "10.1109/tvcg.2011.127", "10.1111/cgf.13444", "10.1145/1964897.1964910", "10.1167/8.7.6", "10.1145/3173574.3173991", "10.1145/1556262.1556289", "10.1145/1056808.1056914", "10.2307/2288400", "10.1109/tvcg.2014.2346594", "10.1109/iv.2002.1028760", "10.1177/001316447303300111", "10.1007/bf02289823", "10.1109/tvcg.2017.2744339", "10.1111/j.1467-8659.2009.01694.x", "10.1109/tvcg.2014.2346979", "10.1090/mbk/069", "10.1109/tvcg.2013.65", "10.1109/mcg.2012.37", "10.1109/pacificvis.2010.5429604", "10.1002/acp.2350050106", "10.1109/infvis.2005.1532136", "10.1177/1473871612465214", "10.1109/tvcg.2017.2674978", "10.1002/jhbs.20078", "10.1007/978-3-642-35142-6\\_14", "10.1007/978-3-319-71507-0", "10.1109/mcg.201.7.6", "10.3758/bf03193961", "10.1364/josa.49.000280", "10.1145/3025453.3025905", "10.1109/tvcg.201.9.2934541", "10.1109/tvcg.2018.2829750", "10.1177/1473871615606187", "10.1111/cgf.13408", "10.1109/pacificvis.2016.7465252", "10.1109/pacificvis.2016.7465244", "10.1109/inevis.2005.1532142", "10.1111/cgf.13414", "10.1111/j.1467-8659.2012.03125.x", "10.1167/16.5.11", "10.1109/infvis.2005.1532142", "10.1145/2858036.2858155", "10.1038/nmeth1210-941", "10.1177/1473871616638892", "10.1109/tcbb.2014.2306840", "10.1111/cgf.13684", "10.1177/0301006615602599", "10.1214/aoms/1177731915", "10.1145/2702123.2702585", "10.1109/tvcg.2013.183", "10.1109/tvcg.2014.2346572", "10.1109/tvcg.2018.2875702", "10.1109/tvcg.2017.2754480", "10.1109/vast.2014.7042493", "10.1057/palgrave.ivs.9500122", "10.1109/tvcg.2014.2330617", "10.1109/tvcg.2019.2934541", "10.1068/p030033", "10.1140/epjds/s13688-017-0109-5", "10.1201/b17511", "10.1016/s0925-7721(02)00093-7", "10.1109/pacificvis.2012.6183557", "10.1109/tvcg.2014.2346983", "10.1109/5.726791", "10.1080/01621459.1926.10502165", "10.1109/tvcg.2007.70535", "10.1109/tvcg.2018.2864907", "10.1111/cgf.12109", "10.1109/tvcg.2017.2744184", "10.1146/annurev-statistics-031017-100045", "10.1111/cgf.13409", "10.1145/3002151.3002162", "10.1016/s0378-4371(98)00494-4", "10.3138/y308-2422-8615-1233", "10.1111/cgf.12632", "10.1145/3290605.3300771"], "wos": 1, "children": [], "len": 1}, {"doi": "10.1111/cgf.14034", "year": "2020", "title": "The State of the Art in Enhancing Trust in Machine Learning Models with the Use of Visualizations", "conferenceName": "EuroVis", "authors": "Angelos Chatzimparmpas;Rafael Messias Martins;Ilir Jusufi;Kostiantyn Kucher;Fabrice Rossi;Andreas Kerren", "citationCount": "2", "affiliation": "Chatzimparmpas, A (Corresponding Author), Linnaeus Univ, Dept Comp Sci \\& Media Technol, Vaxjo, Sweden.\nChatzimparmpas, A.; Martins, R. M.; Jusufi, I.; Kucher, K.; Kerren, A., Linnaeus Univ, Dept Comp Sci \\& Media Technol, Vaxjo, Sweden.\nRossi, F., PSL Univ, Univ Paris Dauphine, Ceremade, Paris, France.", "countries": "Sweden;France", "abstract": "Machine learning (ML) models are nowadays used in complex applications in various domains, such as medicine, bioinformatics, and other sciences. Due to their black box nature, however, it may sometimes be hard to understand and trust the results they provide. This has increased the demand for reliable visualization tools related to enhancing trust in ML models, which has become a prominent topic of research in the visualization community over the past decades. To provide an overview and present the frontiers of current research on the topic, we present a State-of-the-Art Report (STAR) on enhancing trust in ML models with the use of interactive visualization. We define and describe the background of the topic, introduce a categorization for visualization techniques that aim to accomplish this goal, and discuss insights and opportunities for future research directions. Among our contributions is a categorization of trust against different facets of interactive ML, expanded and improved from previous research. Our results are investigated from different analytical perspectives: (a) providing a statistical overview, (b) summarizing key findings, (c) performing topic analyses, and (d) exploring the data sets used in the individual papers, all with the support of an interactive web-based survey browser. We intend this survey to be beneficial for visualization researchers whose interests involve making ML models more trustworthy, as well as researchers and practitioners from other disciplines in their search for effective visualization techniques suitable for solving their tasks with confidence and conveying meaning to their data.", "keywords": "trustworthy machine learning; visualization; interpretable machine learning; explainable machine learning", "link": "https://doi.org/10.1111/cgf.14034", "refList": ["10.1109/mcg.2018.2878902", "10.1109/tvcg.2008.153", "10.2312/mlvis.20181130", "10.1109/tvcg.2016.2598828", "10.1145/3290605.3300911", "10.1145/2993901.2993909", "10.2312/mlvis.20191158", "10.1109/tvcg.2016.2598446", "10.1111/j.1467-8659.2009.01475.x", "10.1145/3290605.3300809", "10.1109/pacificvis.2018.00031", "10.1055/s-0029-1216348", "10.1007/978-3-319-90403-0\\_13", "10.1109/tvcg.2017.2745085", "10.1111/j.1467-8659.2011.01938.x", "10.1007/978-3-319-54024-5\\_6", "10.1016/s0167-9473(01)00065-2", "10.1111/cgf.12895", "10.2312/eurovisshort.20141152.17", "10.2312/eurova.20151098.22", "10.1111/cgf.13667", "10.3115/1072228.1072378", "10.1109/tbdata.2018.2877350.16", "10.1109/lars.2009.5418323.25", "10.1109/tvcg.2017.2744878", "10.1016/j.combustflame.2005.09.018", "10.1016/j.cag.2014.01.006", "10.1109/tvcg.2016.2570755", "10.2312/mlvis.20191158.1,19", "10.1518/hfes.46.1.50.30392", "10.1145/3301275.3302280", "10.1145/3351095.3372834.1", "10.1016/s0377-2217(01)00264-8", "10.1111/cgf.13424", "10.1007/978-3-319-23485-4\\_53", "10.1007/978-94-007-0753-5\\_3623", "10.1109/tvcg.2013.101", "10.1111/cgf.12884", "10.1111/j.1467-8659.2010.01835.x", "10.1021/ci9901338", "10.4230/lipics.itcs:2017", "10.1109/mis.2013.24", "10.1109/tvcg.2014.2346482", "10.1109/tvcg.2018.2865230", "10.1073/pnas.1807180116", "10.1109/dsaa.2018.00018", "10.1109/tvcg.2009.153", "10.3115/1219840.1219855", "10.1109/tvcg.2018.2864812", "10.1109/tvcg.2018.2872577", "10.2312/trvis.20191183", "10.1109/cvpr:2004.383", "10.1109/vast.2008.4677350", "10.1145/302979.303001", "10.1109/tvcg.2018.2864499", "10.1111/cgf.13672", "10.1109/tvcg.2014.2346626", "10.23915/distill.00010.18", "10.1109/tvcg.2017.2744805", "10.2312/mlvis:20191160.18", "10.23915/distill:00016", "10.1109/pacificvis.2016.7465260", "10.1111/cgf.13683", "10.23915/distill.00016.19", "10.1145/32906053.300803.22", "10.1109/tvcg.2014.2346574", "10.1177/1473871615600010", "10.1109/tvcg.2016.2598831", "10.1145/3230623", "10.1109/visual.2019.8933744", "10.1145/2993901.2993915", "10.1016/j.visinf.2017.01.006", "10.1145/2993901.2993914", "10.1109/tvcg.2014.2346984", "10.1109/5.726791", "10.23915/distill.00010", "10.1109/tvcg.2018.2864825", "10.2307/2394164", "10.1109/tvcg.2017.2744458", "10.1145/2993901.2993917.28", "10.1111/cgf.13711", "10.1109/tvcg.2016.2598664", "10.2307/2530428", "10.1109/icdar.1997.620583", "10.1109/tvcg.2017.2744718", "10.1111/cgf.13425", "10.1109/tvcg.2019.2903943", "10.1145/1518701.1518895", "10.1109/tvcg.2018.2864838", "10.1145/62038.62043", "10.1111/j.1467-8659.2011.01920.x", "10.1145/3025171.3025208", "10.1145/355112.355124", "10.1109/vast.2010.5652398", "10.1109/tvcg.2014.2346578", "10.1145/3173574.3174209", "10.4178/epih/e2014008", "10.1109/beliv.2018.8634201.25,28", "10.1016/j.eswa.2007.12.020", "10.1111/cgf:13406", "10.1109/mcg.2011.103", "10.1631/fitee.1700808", "10.1109/tvcg.2017.2745158", "10.1073/pnas.0307752101", "10.1109/tvcg.2018.2816223", "10.1109/tvcg.2017.2745141", "10.1145/32232.32234", "10.1109/tvcg.2019.2934267", "10.1109/tvcg.2018.2864477", "10.1145/3132169", "10.2312/eurova.20151100.19", "10.1145/3172944.3172964", "10.1145/2601248.2601268", "10.1109/isai-nlp.2018.8693002.1", "10.1111/cgf.13404", "10.1007/s100320200071", "10.2312/trvis.20191183.16", "10.1111/cgf.12755", "10.1145/2702123.2702509", "10.1145/1401890.1402008.25", "10.1109/tvcg.2012.65", "10.1177/1473871617733996", "10.2312/trvis.20191187.7", "10.21236/ada273556", "10.1109/vast.2010.5652450", "10.1111/j.1467-8659.2011.01940.x", "10.1177/875647939000600106", "10.1109/tvcg.2017.2711030", "10.1016/j.immuni.2016.04.014", "10.1109/tvcg.2019.2934209", "10.1016/0095-0696(78)90006-2", "10.1016/j.jclinepi.2015.04.014", "10.1016/j.ress.2013.02.013", "10.1111/cgf.12640", "10.1145/1015330.1015388.25", "10.1111/j.1467-8659.2009.01468.x", "10.1145/1541880.1541882", "10.1109/vast.2011.6102453", "10.1016/s0008-8846(98)00165-3", "10.2312/trvis.20191186.7", "10.1007/s13748-013-0040-3", "10.1109/tvcg.2015.2467757", "10.1109/tbdata.2018.2877350", "10.1109/vast.2017.8585613", "10.1080/10556789208805504", "10.1109/vast.2012.6400484", "10.1145/3025171.3025181", "10.1007/978-3-319-90403-0\\_12", "10.1109/mcg.2019.2922592", "10.1021/ci000392t", "10.1109/vast.2007.4389000", "10.1111/cgf.13406.16", "10.1111/cgf.13684", "10.2312/eurovisshort.20161166.17", "10.2312/evs:20191168", "10.1145/3041021.3055135", "10.1145/3301275.3302265", "10.1613/jair.4135", "10.1109/tvcg.2018.2864500", "10.1109/tvcg.2017.2744158", "10.1109/ssci.2015.33", "10.1111/cgf.13453", "10.2312/pe/eurovast/eurova11/049-052", "10.1145/3025171.3025181.13", "10.1145/371920.372094", "10.1109/tvcg.2017.2744938", "10.1111/j.1467-8659.2012.03108.x", "10.1109/tvcg.2019.2934251", "10.1145/3290605.3300809.18", "10.1109/ldav.2016.7874305", "10.1109/vast.2016.7883514", "10.1109/iccv.2015.425", "10.1145/3301275.3302324", "10.1109/tnnls.2013.2292894", "10.1109/tvcg.2018.2865044", "10.1109/tvcg.2013.157", "10.1371/journal.pcbi.0020161", "10.1186/s12916-019-1426-2", "10.1109/10.867928", "10.1111/cgf.13217", "10.1109/mcg.2019.2919033", "10.1145/2993901.2993910", "10.1109/tvcg.2017.2744738", "10.2307/258792", "10.1111/cgf.12655", "10.1016/j.dss.2014.03.001", "10.1109/tvcg.2019.2904069", "10.1111/cgf.13205", "10.1002/mds.22340", "10.1109/tvcg.2019.2934595", "10.1287/inte.2018.0957", "10.1109/cvpr.2007.382974", "10.1109/tvcg.2012.280", "10.1145/2678025.2701399.13", "10.2312/mlvis.20181130.13", "10.2312/eurova.20181106.16", "10.1109/tvcg.2018.2864475", "10.2312/mlvis.20191160.18,22", "10.1007/978-1-4612-4026-6.25", "10.1109/cvpr.2006.42", "10.1145/3172944.3172950", "10.1109/cvpr.2004.383.25", "10.1109/tvcg.2019.2934812", "10.1609/aimag.v35i4.2513", "10.2312/trvis.20191185.7", "10.1111/j.1467-8659.2009.01684.x", "10.1371/journal.pone.0129126", "10.1111/cgf.13092", "10.1162/coli\\_a\\_00237", "10.1109/tvcg.2017.2744818", "10.1109/vast.2011.6102448", "10.1109/tvcg.2009.111", "10.1109/tvcg.2019.2934619", "10.1016/s0377-2217(01)00264-8.25", "10.1111/cgf.12639", "10.1109/access.2019.2919343", "10.1186/s12874-019-0681-4", "10.1109/pacificvis.2015.7156366", "10.1109/pacificvis.2018.00029", "10.1109/tvcg.2019.2934261", "10.1080/13506280444000102.http://www.uvt.nl/ticc", "10.1109/vast.2018.8802509", "10.1111/cgf.13212", "10.1145/3200489", "10.1111/cgf.13176", "10.1177/1473871620904671", "10.1007/978-3-319-10590-1\\_53", "10.1111/j.1467-8659.2012.03126.x", "10.1111/cgf.13172", "10.1145/3025171.3025208.6,21", "10.1111/cgf.12366", "10.1109/tvcg.2019.2934659", "10.1109/cvprw.2009.5206848", "10.1016/j.media.2014.11.010", "10.1109/tvcg.2017.2744683", "10.1109/tvcg.2019.2934262", "10.1016/j.neucom.2006.11.018", "10.1177/1473871615571951", "10.1371/journal.pcbi.0020161.25", "10.1177/1473871611415994", "10.2312/trvis20191187", "10.2312/eurova", "10.1145/2858036.2858529", "10.1145/2207676.2207738", "10.1007/s11042-009-0417-2", "10.1145/3301275.3302317", "10.1038/s41746-019-0148-3", "10.1145/3351095.3372834", "10.1080/10691898.2011.11889627", "10.1109/tvcg.2018.2864504", "10.1109/vast.2017.8585720", "10.1109/mcg.2018.053491732", "10.1007/s10994-010-5207-6", "10.1109/tvcg.2019.2934433", "10.1016/j.cag.2017.05.005", "10.1109/tvcg.2012.279", "10.1145/3231622.3231641.19,20", "10.1145/1562849.1562851", "10.1007/11564126\\_", "10.1109/tvcg.2018.2846735", "10.3115/1225403.1225421", "10.1109/vast.2012.6400486", "10.2312/eurova.20191116.22", "10.1109/tvcg.2007.70443", "10.1080/027868291009242", "10.2312/eurova.20151100", "10.1145/2939502.2939503.19", "10.1016/j.cag.2014.02.004", "10.1145/2939672.2939778", "10.1109/vast.2010.5652484", "10.1111/cgf.12641", "10.1145/3301275.3302289", "10.1109/visual.2019.8933619", "10.1109/tvcg.2017.2672987", "10.1109/vast.2016.7883517.20", "10.1109/igarss.2017.8127684", "10.1016/j.jcae.2010.04.002", "10.1109/vast.2010.5652885", "10.1016/j.visinf.2019.03.002", "10.1007/s00371-018-1500-3", "10.1109/mcg.2018.042731661", "10.1109/34.598228", "10.1109/tvcg.2018.2865027", "10.1016/j.neucom.2017.01.105", "10.1111/cgf.12389", "10.1109/tvcg.2019.2934591", "10.1109/vast.2010.5652392.16", "10.1111/cgf.13416", "10.1080/02701367.1992.10608764", "10.1109/vast.2017.8585721", "10.1109/tvcg.2018.2843369", "10.1109/sbes.2010.27", "10.1109/vast.2015.7347637", "10.1145/1401890.1402008", "10.1016/j.bpj.2010.04.064", "10.1109/tvcg.2013.125", "10.1109/isai-nlp.2018.8693002", "10.1371/journal.pone.0160127", "10.1145/2856767.2856779", "10.1145/2678025.2701399", "10.1109/vast.2011.6102451", "10.1109/mcg.2010.18", "10.1021/ci4000213", "10.1109/vast.2012.6400492", "10.1007/11564126-49.25", "10.2312/eurova.20171114", "10.1109/vast.2010.5652443", "10.1145/3134599", "10.2312/pe/eurovast/eurovast10/013-018.19", "10.1109/tvcg.2019.2903946", "10.1109/tvcg.2015.2467717", "10.1177/1473871612460526", "10.1016/j.cag.2018.09.018", "10.1109/tvcg.2016.2598838", "10.1145/3172944.3172964.14", "10.1109/vast.2009.5333428", "10.1109/vast.2014.7042480", "10.2312/pe/eurovast/eurovast10/013-018", "10.1177/0962280215588241", "10.1145/2993901.2993917", "10.1109/cvpr.2008:4587581", "10.1109/tvcg.2015.2467551", "10.1016/j.visinf.2018.09.001", "10.1126/science.290.5500.2319", "10.2312/eurova.20151107", "10.1109/visual.2019.8933695", "10.13140/2.1.2393.1847", "10.1197/jamia.m1929", "10.1109/cvpr.2008.4587581.25", "10.1145/1518701.1518895.16", "10.1109/vds.2017.8573444", "10.2312/trvis:20191185", "10.1145/3359786", "10.13140/2.1.1341.1520", "10.2312/pe/eurovast/eurova11/049-052.17", "10.1109/tvcg.2014.2346660", "10.1145/3185517", "10.1109/adprl.2011.5967372", "10.1109/tvcg.2015.2467591", "10.1111/j.1751-9004.2009.00232.x", "10.1136/qshc.2004.010033", "10.1109/vast.2012.6400493", "10.1109/tvcg.2019.2934266", "10.1145/2971763.2971775", "10.1111/cgf.13730", "10.1109/vast.2012.6400488", "10.1111/cgf.13210", "10.1109/tvcg.2019.2934631", "10.1145/3172944.3172965", "10.1057/ivs.2010.2", "10.1109/tvcg.2017.2745258", "10.1016/j.jbusres.2019.07.039", "10.1162/jmlr.2003.3.4-5.993", "10.1109/pacificvis.2019.00044", "10.2312/pe/eurovast/eurova12/037-041", "10.1109/tvcg.2019.2934629", "10.1177/0018720814547570", "10.1145/3292500.3330908", "10.1111/j.1467-8659.2009.01467.x", "10.2312/eurova.20151098", "10.1177/1473871617713337", "10.1109/lars:2009.5418323", "10.1109/vast.2011.6102437", "10.1111/cgf.12878", "10.1561/1500000001", "10.1145/3025171.3025222", "10.1007/s11704-016-6028-y", "10.1016/j.procs.2017.05.216", "10.1109/cvpr.2007.382974.25", "10.1080/10447318.2020.1741118", "10.1109/vast.2012.6400489", "10.1145/3025171.3025172", "10.1109/tvcg.2017.2744098", "10.1109/tvcg.2005.66", "10.1016/j.dss.2009.05.016", "10.1007/978-1-4612-4026-6", "10.2312/evs.20191168.16,20,28", "10.2312/pe/eurovast/eurova12/037-041.17", "10.1145/3290605.3300803", "10.1145/1015330.1015388", "10.1111/cgf.13197", "10.1016/b978-1-55860-377-6.50048-7", "10.1111/cgf.13681", "10.1109/tvcg.2017.2744378", "10.1109/tvcg.2017.2744358", "10.1109/vast.2008.4677352"], "wos": 1, "children": [{"doi": "10.1109/tvcg.2020.3030368", "title": "Implicit Multidimensional Projection of Local Subspaces", "year": "2020", "conferenceName": "InfoVis", "authors": "Rongzheng Bian;Yumeng Xue;Liang Zhou;Jian Zhang 0070;Baoquan Chen;Daniel Weiskopf;Yunhai Wang", "citationCount": "1", "affiliation": "Wang, YH (Corresponding Author), Shandong Univ, Qingdao, Peoples R China. Zhou, L (Corresponding Author), Univ Utah, Salt Lake City, UT 84112 USA. Bian, Rongzheng; Xue, Yumeng; Wang, Yunhai, Shandong Univ, Qingdao, Peoples R China. Chen, Baoquan, Peking Univ, Beijing, Peoples R China. Zhang, Jian, Chinese Acad Sci, CNIC, Beijing, Peoples R China. Zhou, Liang, Univ Utah, Salt Lake City, UT 84112 USA. Weiskopf, Daniel, Univ Stuttgart, Stuttgart, Germany.", "countries": "USA;Germany;China", "abstract": "We propose a visualization method to understand the effect of multidimensional projection on local subspaces, using implicit function differentiation. Here, we understand the local subspace as the multidimensional local neighborhood of data points. Existing methods focus on the projection of multidimensional data points, and the neighborhood information is ignored. Our method is able to analyze the shape and directional information of the local subspace to gain more insights into the global structure of the data through the perception of local structures. Local subspaces are fitted by multidimensional ellipses that are spanned by basis vectors. An accurate and efficient vector transformation method is proposed based on analytical differentiation of multidimensional projections formulated as implicit functions. The results are visualized as glyphs and analyzed using a full set of specifically-designed interactions supported in our efficient web-based visualization tool. The usefulness of our method is demonstrated using various multi- and high-dimensional benchmark datasets. Our implicit differentiation vector transformation is evaluated through numerical comparisons; the overall method is evaluated through exploration examples and use cases.", "keywords": "High-dimensional data visualization,dimensionality reduction,local linear subspaces,user interaction", "link": "http://dx.doi.org/10.1109/TVCG.2020.3030368", "refList": ["10.3844/jcssp.2018.613.622", "10.1016/j.aci.2018.08.003", "10.3390/info9030065", "10.1016/j.visinf.2018.09.003", "10.1371/journal.pone.0118432", "10.1016/s0893-6080(05)80023-1", "10.1109/tvcg.2020.2986996", "10.1109/icst.2012.56", "10.1007/s10844-013-0250-y", "10.1109/tbdata.2018", "10.1145/1125451.1125659", "10.1109/tvcg.2013.125", "10.1177/1473871611412817", "10.1145/3290605.3300911", "10.1111/cgf.14034", "10.1007/s13721-013-0034-x", "10.1016/j.procs.2017.05.216", "10.1016/j.ins.2009.08.025", "10.1109/tvcg.2013.124", "10.1109/tvcg.2018.2864499", "10.1109/tvcg.2018.2864475", "10.1080/10447318.2020.1741118", "10.1016/j.imu.2019.100203", "10.1109/tvcg.2018.2865240", "10.1186/s12864-019-6413-7", "10.1109/tvcg.2015.2467551", "10.1002/widm.1249", "10.1007/978-3-319-66429-3\\_29", "10.1109/tvcg.2014.2346481", "10.1109/tvcg.2018.2864825", "10.1177/1473871620904671", "10.1109/tvcg.2019.2934267", "10.1136/bmjopen-2016-012799", "10.1109/smartgridcomm.2017.8340682", "10.1007/s10664-015-9401-9", "10.1145/1143844.1143874", "10.1111/cgf.12389", "10.1109/tvcg.2018.2872577", "10.1007/978-981-13-5802-9\\_20", "10.1016/j.ipm.2009.03.002", "10.5220/0006431602160222", "10.1109/mcg.2015.50", "10.1109/tvcg.2014.2346574", "10.1007/bf02289565", "10.1109/tvcg.2017.2744378", "10.1016/j.patrec.2008.08.010", "10.1023/a:1010933404324", "10.9735/2229-3981"], "wos": 1, "children": [], "len": 1}, {"doi": "10.1109/tvcg.2020.3030465", "title": "Visual Causality Analysis of Event Sequence Data", "year": "2020", "conferenceName": "VAST", "authors": "Zhuochen Jin;Shunan Guo;Nan Chen;Daniel Weiskopf;David Gotz;Nan Cao", "citationCount": "0", "affiliation": "Cao, N (Corresponding Author), Tongji Univ, IDVx Lab, Shanghai, Peoples R China. Jin, Zhuochen; Guo, Shunan; Chen, Nan; Cao, Nan, Tongji Univ, IDVx Lab, Shanghai, Peoples R China. Weiskopf, Daniel, Univ Stuttgart, Stuttgart, Germany. Gotz, David, Univ N Carolina, Chapel Hill, NC 27515 USA.", "countries": "USA;Germany;China", "abstract": "Causality is crucial to understanding the mechanisms behind complex systems and making decisions that lead to intended outcomes. Event sequence data is widely collected from many real-world processes, such as electronic health records, web clickstreams, and financial transactions, which transmit a great deal of information reflecting the causal relations among event types. Unfortunately, recovering causalities from observational event sequences is challenging, as the heterogeneous and high-dimensional event variables are often connected to rather complex underlying event excitation mechanisms that are hard to infer from limited observations. Many existing automated causal analysis techniques suffer from poor explainability and fail to include an adequate amount of human knowledge. In this paper, we introduce a visual analytics method for recovering causalities in event sequence data. We extend the Granger causality analysis algorithm on Hawkes processes to incorporate user feedback into causal model refinement. The visualization system includes an interactive causal analysis framework that supports bottom-up causal exploration, iterative causal verification and refinement, and causal comparison through a set of novel visualizations and interactions. We report two forms of evaluation: a quantitative evaluation of the model improvements resulting from the user-feedback mechanism, and a qualitative evaluation through case studies in different application domains to demonstrate the usefulness of the system.", "keywords": "Event sequence data,causality analysis,visual analytics", "link": "http://dx.doi.org/10.1109/TVCG.2020.3030465", "refList": ["10.5555/1642718", "10.1109/tvcg.2018.2865022", "10.5555/2074094.2074151", "10.1109/tvcg.2016.2618797", "10.1073/pnas.1320645111", "10.1109/tvcg.2017.2744843", "10.1109/iv.2017.69", "10.1109/tvcg.2019.2934399", "10.1145/3172944.3173007", "10.5555/1795555", "10.1109/mcg.2005.102", "10.1145/381641.381653", "10.1162/153244301753344614", "10.1111/cgf.14034", "10.1111/cgf.13198", "10.1017/cbo9780511519857", "10.1007/s10462-016-9475-9", "10.1075/ssol.2.2.07bor", "10.1007/978-1-4614-3223-4\\_3", "10.1109/infvis.2003.1249025", "10.1007/978-94-007-6094-313", "10.1145/2858036.2858387", "10.1109/tvcg.2007.70528", "10.1109/tvcg.2017.2674958", "10.1147/sj.454.0801", "10.1109/tvcg.2013.119", "10.1145/3173574.3173711", "10.1016/j.erss.2017.06.034", "10.1109/visual.2019.8933695", "10.1007/s11665-016-2173-6", "10.1016/0377-0427(87)90125-7", "10.2307/3601125", "10.1016/b978-0-444-88738-2.50018-x", "10.1109/mcg.2006.70", "10.1109/tvcg.2018.2865145", "10.1017/s1351324997001502", "10.1109/tvcg.2010.179", "10.1214/aos/1176344552", "10.1109/mcg.2009.22", "10.1007/978-3-319-26633-6\\_13", "10.1080/10447318.2014.905422", "10.1016/j.visinf.2019.03.004", "10.1057/palgrave.ivs.9500074", "10.1007/978-1-4614-3223-4"], "wos": 1, "children": [], "len": 1}], "len": 5}, {"doi": "10.1111/cgf.14001", "year": "2020", "title": "Sunspot Plots: Model-based Structure Enhancement for Dense Scatter Plots", "conferenceName": "EuroVis", "authors": "Thomas Trautner;Fabian Bolte;Sergej Stoppel;Stefan Bruckner", "citationCount": "0", "affiliation": "Trautner, T (Corresponding Author), Univ Bergen, Bergen, Norway.\nTrautner, T.; Bolte, F.; Stoppel, S.; Bruckner, S., Univ Bergen, Bergen, Norway.", "countries": "Norway", "abstract": "Scatter plots are a powerful and well-established technique for visualizing the relationships between two variables as a collection of discrete points. However, especially when dealing with large and dense data, scatter plots often exhibit problems such as overplotting, making the data interpretation arduous. Density plots are able to overcome these limitations in highly populated regions, but fail to provide accurate information of individual data points. This is particularly problematic in sparse regions where the density estimate may not provide a good representation of the underlying data. In this paper, we present sunspot plots, a visualization technique that communicates dense data as a continuous data distribution, while preserving the discrete nature of data samples in sparsely populated areas. We furthermore demonstrate the advantages of our approach on typical failure cases of scatter plots within synthetic and real-world data sets and validate its effectiveness in a user study.", "keywords": "", "link": "https://doi.org/10.1111/cgf.14001", "refList": ["10.1057/palgrave.ivs.9500122", "10.2312/eggh/hpg12/097-103", "10.1109/tvcg.2008.119", "10.1109/pacificvis.2011.5742387", "10.1038/331163a0", "10.1109/visual.2019.8933620", "10.2307/2683294", "10.1201/9781351072304", "10.2307/2289444", "10.1109/tvcg.2019.2934541", "10.1080/00949657508810123", "10.1109/tvcg.2013.65", "10.1109/infvis.1997.636789", "10.1109/2945.841121", "10.1109/mcse.2007.55", "10.1109/tvcg.2010.197", "10.1111/cgf.12871", "10.1109/infvis.2003.1249018", "10.1145/3173574.3173991", "10.1109/tvcg.2012.238", "10.1007/0-387-28695-0", "10.1109/pacificvis.2010.5429604", "10.18637/jss.v008.i03", "10.1109/tvcg.2007.70596", "10.1109/visual.1998.745301", "10.1007/0-387-37977-0\\_3", "10.1145/1556262.1556289", "10.2312/wiced.20161094", "10.1109/tvcg.2007.70535", "10.1145/1056808.1056914", "10.1109/tvcg.2003.1196007", "10.1109/iv.2004.1320190", "10.1111/cgf.12877", "10.1162/leon.2007.40.2.202a", "10.1109/tvcg.2017.2674978", "10.1057/ivs.2010.4", "10.1016/j.cag.2018.02.008", "10.1201/9781315140919", "10.1109/visual.2000.885677", "10.1002/jhbs.20078", "10.1109/tvcg.2014.2346594", "10.1109/tvcg.2017.2744184", "10.1109/visual.2001.964495", "10.1109/iv.2002.1028760", "10.1111/cgf.13684", "10.1109/hicss.2013.197", "10.1109/tvcg.2019.2903956", "10.1093/mnras/stt961", "10.1109/tvcg.2017.2668409", "10.1111/j.1467-8659.2009.01478.x", "10.1145/2702123.2702585", "10.2307/1418003", "10.2307/1390742", "10.1145/360825.360839", "10.1109/pacificvis.2009.4906843", "10.1057/ivs.2009.34", "10.2307/2288711"], "wos": 1, "children": [], "len": 1}], "len": 13}, {"doi": "10.1111/cgf.14000", "year": "2020", "title": "Evaluating Reordering Strategies for Cluster Identification in Parallel Coordinates", "conferenceName": "EuroVis", "authors": "Michael Blumenschein;Xuan Zhang;David Pomerenke;Daniel A. Keim;Johannes Fuchs", "citationCount": "0", "affiliation": "Blumenschein, M (Corresponding Author), Univ Konstanz, Constance, Germany.\nBlumenschein, Michael; Pomerenke, David; Keim, Daniel A.; Fuchs, Johannes, Univ Konstanz, Constance, Germany.\nZhang, Xuan, Rhein Westfal TH Aachen, Aachen, Germany.", "countries": "Germany", "abstract": "The ability to perceive patterns in parallel coordinates plots (PCPs) is heavily influenced by the ordering of the dimensions. While the community has proposed over 30 automatic ordering strategies, we still lack empirical guidance for choosing an appropriate strategy for a given task. In this paper, we first propose a classification of tasks and patterns and analyze which PCP reordering strategies help in detecting them. Based on our classification, we then conduct an empirical user study with 31 participants to evaluate reordering strategies for cluster identification tasks. We particularly measure time, identification quality, and the users' confidence for two different strategies using both synthetic and real-world datasets. Our results show that, somewhat unexpectedly, participants tend to focus on dissimilar rather than similar dimension pairs when detecting clusters, and are more confident in their answers. This is especially true when increasing the amount of clutter in the data. As a result of these findings, we propose a new reordering strategy based on the dissimilarity of neighboring dimension pairs.", "keywords": "", "link": "https://doi.org/10.1111/cgf.14000", "refList": ["10.1111/j.1467-8659.2008.01241.x", "10.2312/conf/eg2013/stars/095-116", "10.1109/tvcg.2014.2346979", "10.1117/12.838819", "10.2307/2290001", "10.1111/cgf.12638", "10.1007/978-3-642-30217-6\\_42", "10.1109/sc.2005.47", "10.1002/wics.145", "10.1109/tvcg.2011.229", "10.1109/vast.2009.5332628", "10.1109/vast.2017.8585613", "10.1145/2993901.2993907", "10.1007/bf00410640", "10.1109/tvcg.2010.184", "10.11591/ijece.v5i6", "10.1111/j.1467-8659.2011.01961.x", "10.1109/visual.1997.663916", "10.1111/j.1467-8659.2012.03129.x", "10.1109/visual.1999.809866", "10.1057/ivs.2008.13", "10.1016/j.visinf.2017.11.001", "10.2307/2282967", "10.1007/978-0-387-68628-8\\_10", "10.5888/pcd9.120082", "10.1109/tvcg.2007.70535", "10.1109/vast.2010.5652450", "10.1007/bf01898350", "10.1016/0010-0285(91)90009-d", "10.1007/978-3-642-24958-7\\_12", "10.1109/infvis.2005.1532142", "10.1057/palgrave.ivs.9500166", "10.1111/j.1467-8659.2008.01239.x", "10.1109/mcse.2015.55", "10.2312/pe/eurovast/eurova12/007-011.7", "10.1109/tvcg.2009.153", "10.1198/jcgs.2010.09136", "10.1145/2463676.2463696", "10.1109/infvis.2005.1532138", "10.1109/tvcg.2010.242", "10.5220/0006097400400051", "10.1109/visual.2019.8933706", "10.1109/atc.2015.7388338", "10.2312/pe/eurovast/eurova12/007-011", "10.5120/5044-7370", "10.1111/cgf.13446", "10.1109/icmla.2012.148", "10.1016/j.jvlc.2015.12.001", "10.1109/tvcg.2015.2466992", "10.1111/j.1467-8659.2009.01666.x", "10.5169/seals-266450", "10.1109/infvis.1998.729559", "10.1016/j.jvlc.2017.10.003", "10.1109/visual.1995.485139", "10.1007/978-0-387-39940-9\\_262", "10.1109/tvcg.2006.138"], "wos": 1, "children": [], "len": 1}], "len": 71}, {"doi": "10.1111/cgf.12919", "year": "2016", "title": "ConToVi: Multi-Party Conversation Exploration using Topic-Space Views", "conferenceName": "EuroVis", "authors": "Mennatallah El{-}Assady;Valentin Gold;Carmela Acevedo;Christopher Collins;Daniel A. Keim", "citationCount": "22", "affiliation": "El-Assady, M (Corresponding Author), Univ Konstanz, Constance, Germany.\nEl-Assady, Mennatallah; Gold, Valentin; Acevedo, Carmela; Keim, Daniel, Univ Konstanz, Constance, Germany.\nEl-Assady, Mennatallah; Collins, Christopher, Univ Ontario, Inst Technol, Toronto, ON, Canada.", "countries": "Canada;Germany", "abstract": "We introduce a novel visual analytics approach to analyze speaker behavior patterns in multi-party conversations. We propose Topic-Space Views to track the movement of speakers across the thematic landscape of a conversation. Our tool is designed to assist political science scholars in exploring the dynamics of a conversation over time to generate and prove hypotheses about speaker interactions and behavior patterns. Moreover, we introduce a glyph-based representation for each speaker turn based on linguistic and statistical cues to abstract relevant text features. We present animated views for exploring the general behavior and interactions of speakers over time and interactive steady visualizations for the detailed analysis of a selection of speakers. Using a visual sedimentation metaphor we enable the analysts to track subtle changes in the flow of a conversation over time while keeping an overview of all past speaker turns. We evaluate our approach on real-world datasets and the results have been insightful to our domain experts.", "keywords": "", "link": "https://doi.org/10.1111/cgf.12919", "refList": ["10.1109/vast.2014.7042493", "10.1057/palgrave.ivs.9500099", "10.1109/icdm.2011.135", "10.1109/tvcg.2013.212", "10.1109/visual.1997.663916", "10.1145/1835804.1835827", "10.1111/cgf.12378", "10.2312/conf/eg2013/stars/039-063", "10.1145/2254556.2254572", "10.1109/tvcg.2013.162", "10.1109/tvcg.2011.239", "10.1146/annurev.polisci.6.121901.085538", "10.1109/tvcg.2015.2467324", "10.1109/2945.981848", "10.1145/778712.778764", "10.1109/vast.2014.7042494", "10.1057/palgrave.cep.6110002", "10.1007/978-3-642-23333-3\\_8", "10.1145/1518701.1518784", "10.1109/tvcg.2010.209", "10.1145/331770331775", "10.1162/jmlr.2003.3.4-5.993", "10.1109/vast.2011.6102461", "10.1109/tvcg.2011.100", "10.1109/tvcg.2010.154", "10.1109/tvcg.2009.23", "10.1145/344949.345004"], "wos": 1, "children": [{"doi": "10.1111/cgf.13446", "year": "2018", "title": "Quality Metrics for Information Visualization", "conferenceName": "EuroVis", "authors": "Michael Behrisch;Michael Blumenschein;Nam Wook Kim;Lin Shao;Mennatallah El{-}Assady;Johannes Fuchs;Daniel Seebacher;Alexandra Diehl;Ulrik Brandes;Hanspeter Pfister;Tobias Schreck;Daniel Weiskopf;Daniel A. Keim", "citationCount": "25", "affiliation": "Behrisch, M (Corresponding Author), Harvard Univ, Cambridge, MA 02138 USA.\nBehrisch, M.; Kim, N. W.; Pfister, H., Harvard Univ, Cambridge, MA 02138 USA.\nBlumenschein, M.; El-Assady, M.; Fuchs, J.; Seebacher, D.; Diehl, A.; Keim, D. A., Univ Konstanz, Constance, Germany.\nShao, L.; Schreck, T., Graz Univ Technol, Graz, Austria.\nBrandes, U., Swiss Fed Inst Technol, Zurich, Switzerland.\nWeiskopf, D., Univ Stuttgart, Stuttgart, Germany.", "countries": "Switzerland;Germany;USA;Austria", "abstract": "The visualization community has developed to date many intuitions and understandings of how to judge the quality of views in visualizing data. The computation of a visualization's quality and usefulness ranges from measuring clutter and overlap, up to the existence and perception of specific (visual) patterns. This survey attempts to report, categorize and unify the diverse understandings and aims to establish a common vocabulary that will enable a wide audience to understand their differences and subtleties. For this purpose, we present a commonly applicable quality metric formalization that should detail and relate all constituting parts of a quality metric. We organize our corpus of reviewed research papers along the data types established in the information visualization community: multi- and high-dimensional, relational, sequential, geospatial and text data. For each data type, we select the visualization subdomains in which quality metrics are an active research field and report their findings, reason on the underlying concepts, describe goals and outline the constraints and requirements. One central goal of this survey is to provide guidance on future research opportunities for the field and outline how different visualization communities could benefit from each other by applying or transferring knowledge to their respective subdomain. Additionally, we aim to motivate the visualization community to compare computed measures to the perception of humans.", "keywords": "", "link": "https://doi.org/10.1111/cgf.13446", "refList": ["10.2307/276978", "10.1057/ivs.2009.10", "10.1109/tvcg.2015.2467732", "10.1109/tvcg.2014.2346420", "10.1016/j.cag.2018.01.010", "10.1109/tvcg.2017.2743959", "10.1109/tvcg.2011.127", "10.1109/tvcg.2015.2467759", "10.1109/tvcg.2013.187", "10.1109/tvcg.2007.70594", "10.1186/1471-2105-9-155", "10.1145/2702123.2702545", "10.1145/1645953.1646023", "10.1093/bioinformatics/btm312", "10.1109/pacificvis.2016.7465245", "10.1145/3038462.3038463", "10.1007/978-3-540-70956-5", "10.1109/tvcg.2017.2743939", "10.1111/cgf.12932", "10.1111/j.1467-8659.2012.03106.x", "10.1145/1133265.1133318", "10.1109/tvcg.2010.186", "10.1109/iv.2013.101", "10.1109/tvcg.2016.2598590", "10.2312/conf/eg2013/stars/039-063", "10.3758/bf03201236", "10.1111/cgf.12935", "10.1145/1056808.1056914", "10.1007/bf01898350", "10.2307/1390686", "10.1109/2945.981848", "10.1109/hicss.2008.422", "10.1109/tvcg.2011.201", "10.1109/pacificvis.2011.5742390", "10.2307/2288400", "10.1111/cgf.12872", "10.1109/tvcg.2017.2674999", "10.1109/tvcg.2006.163", "10.1109/tvcg.2013.150", "10.1109/tvcg.2009.171", "10.1109/tvcg.2017.2723397", "10.1117/12.2079841", "10.1109/pacificvis.2009.4906838", "10.1109/infvis.2004.1", "10.1109/tvcg.2008.166", "10.1287/opre.20.5.993", "10.7155/jgaa.00370", "10.1111/j.1467-8659.2008.01240.x", "10.1109/inf0vis.2005.14", "10.1109/tvcg.2009.23", "10.1109/infvis.1998.729559", "10.1177/0165551506078083", "10.1109/t-c.1974.224051", "10.1109/tvcg.2017.2744339", "10.1109/tvcg.2014.2346433", "10.1145/989863.989940", "10.1109/tvcg.2015.2509990", "10.2307/2288843", "10.1016/j.neucom.2017.01.105", "10.1073/pnas.43.10.923", "10.1111/cgf.12647", "10.1016/j.rse.2017.06.031", "10.1109/infvis.2005.1532145", "10.1109/2945.841121", "10.1109/tvcg.2011.229", "10.2312/eurova.20141140", "10.1111/j.2044-8317.1974.tb00534.x", "10.1109/pacificvis.2015.7156366", "10.1109/vast.2009.5332628", "10.1109/vast.2014.7042480", "10.1145/2993901.2993907", "10.1177/0951692899011001004", "10.1007/978-3-642-03655-2\\_43", "10.1198/106186008x320465", "10.1109/visual.1997.663916", "10.1111/cgf.12125", "10.1109/infvis.2003.1249009", "10.1109/icdm.2003.1250978", "10.1109/tvcg.2017.2745919", "10.1109/tvcg.2012.128", "10.1109/vast.2010.5652450", "10.1109/tvcg.2006.161", "10.1145/571647.571649", "10.1109/tvcg.2011.193", "10.1111/cgf.12633", "10.1109/tvcg.2017.2674978", "10.1109/vast.2010.5652433", "10.1109/tvcg.2017.2745978", "10.1515/itit-2014-1070", "10.1145/1374489.1374501", "10.1109/tvcg.2009.153", "10.2312/eurovisshort.20171128", "10.2312/eurovisshort.20151130", "10.1016/0925-7721(94)00014-x", "10.1057/palgrave.ivs.95000/3", "10.1145/302979.303030", "10.1002/widm.1071", "10.1109/pacificvis.2014.42", "10.1109/tvcg.2016.2598467", "10.1111/j.1467-8659.2009.01667.x", "10.2307/2287708", "10.1177/1473871613477091", "10.1145/967900.968153", "10.1109/tvcg.2010.162", "10.1145/568522.568523", "10.1016/j.cag.2004.03.022", "10.1109/tvcg.2015.2466992", "10.1145/2993901.2993903", "10.1147/jrd.2015.2411412", "10.1177/154193120504900508", "10.1109/tvcg.2006.138", "10.1111/cgf.13168", "10.1111/cgf.12380", "10.2312/conf/eg2013/stars/095-116", "10.1109/tvcg.2017.2745859", "10.1109/tvcg.2017.2701829", "10.1109/tvcg.2007.70529", "10.1007/bf01199431", "10.1117/12.697548", "10.1109/tvcg.2017.2653106", "10.1207/s15327906mbr2701\\_4", "10.1109/vl.1996.545307", "10.1109/tvcg.2017.2745140", "10.1111/j.1467-8659.2012.03069.x", "10.1111/j.1467-8659.2011.01961.x", "10.1109/pacificvis.2016.7465244", "10.1109/tvcg.2013.124", "10.1057/ivs.2008.13", "10.2312/vissym/eurovis06/195-202", "10.2312/vissym/eurovis07/163-170", "10.1109/tvcg.2015.2467324", "10.1109/tvcg.2011.167", "10.1109/pacificvis.2014.40", "10.1109/pacificvis.2012.6183570", "10.1111/j.1467-8659.2012.03125.x", "10.1075/idj.20.1.02bei", "10.1111/1467-8306.00061", "10.1145/2858036.2858155", "10.1109/tvcg.2012.108", "10.2312/vmv.20171261", "10.1109/tvcg.2015.2467531", "10.1145/1379092.1379130", "10.1109/tpami.1979.4766909", "10.1080/13875860903039172", "10.1109/mcg.2006.70", "10.1109/tvcg.2010.242", "10.1109/vast.2007.4389004", "10.1109/tvcg.2015.2467191", "10.2312/cgvc.20171276", "10.1016/0169-7439(87)80084-9", "10.2312/pe/eurovisshort/eurovisshort2012/097-101", "10.1016/j.neucom.2014.07.073", "10.2307/2685263", "10.1145/996546.996554", "10.1111/j.1467-8659.2009.01666.x", "10.1117/12.2083444", "10.1109/tvcg.2014.2346572", "10.1007/978-0-387-39940-9\\_262", "10.1007/bf00988593", "10.1145/1054972.1055078", "10.1111/j.1467-8659.2009.01467.x", "10.1111/cgf.13181", "10.1145/502512.502530", "10.1109/pacificvis.2010.5429600", "10.1111/j.1467-8659.2011.01923.x", "10.1109/mcg.2004.41", "10.1109/tvcg.2015.2467971", "10.1111/j.1467-8659.2011.01919.x", "10.1002/sam.10071", "10.1109/tvcg.2010.184", "10.1007/978-3-642-27848-8\\_648-1", "10.1109/tvcg.2010.132", "10.1145/22949.22950", "10.1145/1842993.1843002", "10.1109/infvis.2000.885096", "10.1016/j.ins.2015.04.017", "10.1109/iv.2009.43", "10.1016/j.visinf.2017.11.001", "10.1109/tvcg.2011.239", "10.1109/infovis.2005.40", "10.1111/cgf.12641", "10.1109/pacificvis.2016.7465262", "10.1145/2470654.2466443", "10.1007/s10844-011-0157-4", "10.1111/cgf.12919", "10.1016/j.jvlc.2016.07.003", "10.1109/tvcg.2016.2549018", "10.1057/palgrave.ivs.9500166", "10.3406/colan.1981.1409.1", "10.1093/bioinformatics/bti141", "10.1111/j.1467-8306.2004.09401004.x", "10.1145/1168149.1168168", "10.1109/tvcg.2017.2744184", "10.1117/12.2079420", "10.1109/iv.2005.62", "10.1145/102377.115768", "10.1109/tvcg.2014.2346677", "10.1109/tvcg.2014.2346426", "10.1111/j.1467-8659.2012.03107.x", "10.5220/0006097400400051", "10.2991/978-94-6239-186-4", "10.2307/2284077", "10.1109/iv.2008.89", "10.1016/j.jvlc.2015.12.001", "10.1109/pacificvis.2013.6596147", "10.1145/1242572.1242826", "10.1016/j.cag.2007.01.030", "10.1111/cgf.12632", "10.2312/eurovisstar.20151113", "10.1559/152304009788188808"], "wos": 1, "children": [{"doi": "10.1109/vast.2018.8802486", "title": "SMARTexplore: Simplifying High-Dimensional Data Analysis through a Table-Based Visual Analytics Approach", "year": "2018", "conferenceName": "VAST", "authors": "Michael Blumenschein;Michael Behrisch;Stefanie Schmid;Simon Butscher;Deborah Wahl;Karoline Villinger;Britta Renner;Harald Reiterer;Daniel A. Keim", "citationCount": "0", "affiliation": "Blumenschein, M (Corresponding Author), Univ Konstanz, Constance, Germany. Blumenschein, Michael; Schmid, Stefanie; Butscher, Simon; Wahl, Deborah R.; Villinger, Karoline; Renner, Britta; Reiterer, Harald; Keim, Daniel A., Univ Konstanz, Constance, Germany. Behrisch, Michael, Harvard Univ, Cambridge, MA 02138 USA.", "countries": "Germany;USA", "abstract": "We present SMARTEXPLORE, a novel visual analytics technique that simplifies the identification and understanding of clusters, correlations, and complex patterns in high-dimensional data. The analysis is integrated into an interactive table-based visualization that maintains a consistent and familiar representation throughout the analysis. The visualization is tightly coupled with pattern matching, subspace analysis, reordering, and layout algorithms. To increase the analyst's trust in the revealed patterns, SMARTEXPLORE automatically selects and computes statistical measures based on dimension and data properties. While existing approaches to analyzing high-dimensional data (e.g., planar projections and Parallel coordinates) have proven effective, they typically have steep learning curves for non-visualization experts. Our evaluation, based on three expert case studies, confirms that non-visualization experts successfully reveal patterns in high-dimensional data when using SMARTEXPLORE.", "keywords": "High-dimensional data,visual exploration,pattern-driven analysis,tabular visualization,subspace,aggregation", "link": "http://dx.doi.org/10.1109/VAST.2018.8802486", "refList": ["10.1177/1473871612460526", "10.1109/tvcg.2015.2489649", "10.1111/j.1467-8659.2008.01241.x", "10.1007/978-3-319-25087-8\\_29", "10.1007/b98835", "10.13140/rg.2.2.16570.90567", "10.1109/tvcg.2014.2346260", "10.1109/vast.2009.5332628", "10.2307/2528823", "10.1109/tvcg.2010.184", "10.1145/1133265.1133318", "10.1057/palgrave.ivs.9500072", "10.1111/j.1467-8659.2012.03110.x", "10.1145/1007730.1007731", "10.1057/palgrave.ivs.9500086", "10.1111/cgf.12935", "10.1109/tvcg.2014.2346279", "10.1007/bf01898350", "10.1109/tvcg.2013.173", "10.1109/tvcg.2017.2672987", "10.1109/tvcg.2014.2346248", "10.1109/infvis.2004.46", "10.1109/vast.2010.5652433", "10.1109/vast.2009.5332611", "10.1109/tvcg.2015.2467553", "10.1109/tvcg.2015.2468078", "10.1109/tvcg.2017.2744098", "10.1109/tvcg.2013.150", "10.1109/tvcg.2016.2640960", "10.1111/cgf.12630", "10.1007/978-1-4757-1904-8", "10.1109/tvcg.2011.188", "10.1109/tvcg.2010.138", "10.1109/tvcg.2017.2745078", "10.1109/tvcg.2017.2743978", "10.1111/cgf.12879", "10.1109/iv.2008.33", "10.1111/cgf.13446", "10.1007/s00371-018-1483-0", "10.1109/infvis.1998.729559", "10.1145/2669557.2669572", "10.1111/j.1467-8659.2008.01239.x"], "wos": 1, "children": [], "len": 1}, {"doi": "10.1109/tvcg.2019.2934541", "title": "A Recursive Subdivision Technique for Sampling Multi-class Scatterplots", "year": "2019", "conferenceName": "InfoVis", "authors": "Xin Chen;Tong Ge;Jian Zhang 0070;Baoquan Chen;Chi-Wing Fu;Oliver Deussen;Yunhai Wang", "citationCount": "5", "affiliation": "Chen, X (Corresponding Author), Shandong Univ, Jinan, Shandong, Peoples R China. Chen, Xin; Ge, Tong; Wang, Yunhai, Shandong Univ, Jinan, Shandong, Peoples R China. Chen, Baoquan, Peking Univ, Beijing, Peoples R China. Fu, Chi-Wing, Chinese Univ Hong Kong, Hong Kong, Peoples R China. Fu, Chi-Wing, SIAT, Guangdong Prov Key Lab CV \\& VR Tech, Shenzhen, Guangdong, Peoples R China. Zhang, Jian, Chinese Acad Sci, CNIC, Beijing, Peoples R China. Deussen, Oliver, Konstanz Univ, Constance, Germany. Deussen, Oliver, SIAT, Shenzhen VIsuCA Key Lab, Shenzhen, Guangdong, Peoples R China.", "countries": "Germany;China", "abstract": "We present a non-uniform recursive sampling technique for multi-class scatterplots, with the specific goal of faithfully presenting relative data and class densities, while preserving major outliers in the plots. Our technique is based on a customized binary kd-tree, in which leaf nodes are created by recursively subdividing the underlying multi-class density map. By backtracking, we merge leaf nodes until they encompass points of all classes for our subsequently applied outlier-aware multi-class sampling strategy. A quantitative evaluation shows that our approach can better preserve outliers and at the same time relative densities in multi-class scatterplots compared to the previous approaches, several case studies demonstrate the effectiveness of our approach in exploring complex and real world data.", "keywords": "Scatterplot,multi-class sampling,kd-tree,outlier,relative density", "link": "http://dx.doi.org/10.1109/TVCG.2019.2934541", "refList": ["10.1057/palgrave.ivs.9500122", "10.1109/tvcg.2006.170", "10.1109/tvcg.2008.119", "10.1109/tvcg.2007.70580", "10.2307/2289444", "10.1145/1964921.1964943", "10.1109/tvcg.2013.65", "10.1109/tvcg.2011.229", "10.1109/iv.2004.1320207", "10.1109/itoec.2018.8740621", "10.1145/1778765.1778816", "10.1109/tvcg.2010.197", "10.1201/b17511", "10.1109/tvcg.2018.2864912", "10.1007/0-387-28695-0", "10.1109/5.726791", "10.1109/visual.1998.745301", "10.1016/j.physa.2011.12.004", "10.1145/1556262.1556289", "10.1109/tvcg.2007.70535", "10.1109/tvcg.2017.2674978", "10.1109/tvcg.2004.1272729", "10.1145/335191.335388", "10.1109/tvcg.2014.2346594", "10.1109/tvcg.2017.2744184", "10.1109/iv.2002.1028760", "10.1145/1842993.1842999", "10.1109/tvcg.2018.2869149", "10.1038/nmeth.2490", "10.1109/tvcg.2013.153", "10.1111/cgf.13446", "10.1109/tvcg.2010.176", "10.1145/2702123.2702585", "10.1057/ivs.2009.34"], "wos": 1, "children": [{"doi": "10.1109/tvcg.2020.3030443", "title": "CAVA: A Visual Analytics System for Exploratory Columnar Data Augmentation Using Knowledge Graphs", "year": "2020", "conferenceName": "VAST", "authors": "Dylan Cashman;Shenyu Xu;Subhajit Das;Florian Heimerl;Cong Liu;Shah Rukh Humayoun;Michael Gleicher;Alex Endert;Remco Chang", "citationCount": "0", "affiliation": "Cashman, D (Corresponding Author), Tufts Univ, Medford, MA 02155 USA. Cashman, Dylan; Liu, Cong; Chang, Remco, Tufts Univ, Medford, MA 02155 USA. Xu, Shenyu; Das, Subhajit; Endert, Alex, Georgia Tech, Atlanta, GA USA. Heimerl, Florian; Gleicher, Michael, Univ Wisconsin, Madison, WI 53706 USA. Humayoun, Shah Rukh, San Francisco State Univ, San Francisco, CA 94132 USA.", "countries": "USA", "abstract": "Most visual analytics systems assume that all foraging for data happens before the analytics process; once analysis begins, the set of data attributes considered is fixed. Such separation of data construction from analysis precludes iteration that can enable foraging informed by the needs that arise in-situ during the analysis. The separation of the foraging loop from the data analysis tasks can limit the pace and scope of analysis. In this paper, we present CAVA, a system that integrates data curation and data augmentation with the traditional data exploration and analysis tasks, enabling information foraging in-situ during analysis. Identifying attributes to add to the dataset is difficult because it requires human knowledge to determine which available attributes will be helpful for the ensuing analytical tasks. CAVA crawls knowledge graphs to provide users with a a broad set of attributes drawn from external data to choose from. Users can then specify complex operations on knowledge graphs to construct additional attributes. CAVA shows how visual analytics can help users forage for attributes by letting users visually explore the set of available data, and by serving as an interface for query construction. It also provides visualizations of the knowledge graph itself to help users understand complex joins such as multi-hop aggregations. We assess the ability of our system to enable users to perform complex data combinations without programming in a user study over two datasets. We then demonstrate the generalizability of CAVA through two additional usage scenarios. The results of the evaluation confirm that CAVA is effective in helping the user perform data foraging that leads to improved analysis outcomes, and offer evidence in support of integrating data augmentation as a part of the visual analytics pipeline.", "keywords": "Visual Analytics,Information Foraging,Data Augmentation", "link": "http://dx.doi.org/10.1109/TVCG.2020.3030443", "refList": ["10.1057/palgrave.ivs.9500122", "10.1109/tvcg.2016.2598867", "10.1111/cgf.13708", "10.1109/tvcg.2019.2934799", "10.1109/tvcg.2019.2934541", "10.1109/tvcg.2013.65", "10.1109/tvcg.2018.2875702", "10.1109/iv.2004.1320207", "10.1068/p260471", "10.1145/1778765.1778816", "10.1109/tvcg.2018.2808489", "10.1109/tvcg.2018.2864912", "10.1016/j.apgeog.2015.12.006", "10.1111/j.1467-8659.2011.01960.x", "10.1109/tvcg.2018.2864843", "10.1109/pacificvis.2010.5429604", "10.1109/tvcg.2014.2346898", "10.1109/5.726791", "10.1177/1475090214540874", "10.1109/icde.2016.7498287", "10.1145/1556262.1556289", "10.1109/tvcg.2007.70535", "10.1109/vast.2012.6400489", "10.1145/1056808.1056914", "10.1016/j.neucom.2014.09.063", "10.1145/7529.8927", "10.1109/tvcg.2016.2598495", "10.1109/tvcg.2016.2607204", "10.1109/vast47406.2019.8986943", "10.3758/bf03205986", "10.1109/infvis.2005.1532142", "10.1145/1150402.1150479", "10.1109/tvcg.2017.2674978", "10.1109/tvcg.2019.2945960", "10.1109/tvcg.2017.2744098", "10.1109/tvcg.2017.2674999", "10.1109/tvcg.2011.279", "10.1109/tvcg.2014.2346594", "10.1109/tvcg.2017.2744184", "10.1111/cgf.12876", "10.1007/s4095-020-0191-7", "10.1007/s11390-015-1535-0", "10.1111/cgf.12640", "10.1109/tvcg.2016.2598667", "10.1111/cgf.13683", "10.1109/tvcg.2013.153", "10.1109/tvcg.2019.2934208", "10.1109/tvcg.2019.2934655", "10.1111/cgf.12655", "10.1007/s11023-010-9221-z", "10.1109/vast.2012.6400487", "10.1145/2702123.2702585", "10.1007/bf00310175", "10.1109/tvcg.2017.2744378", "10.1103/physreve.64.061907", "10.1109/ldav.2017.8231848", "10.1109/tvcg.2016.2598831"], "wos": 1, "children": [], "len": 1}, {"doi": "10.1109/tvcg.2020.3030432", "title": "Evaluation of Sampling Methods for Scatterplots", "year": "2020", "conferenceName": "VAST", "authors": "Jun Yuan;Shouxing Xiang;Jiazhi Xia;Lingyun Yu;Shixia Liu", "citationCount": "0", "affiliation": "Liu, SX (Corresponding Author), Tsinghua Univ, BNRist, Beijing, Peoples R China. Yuan, Jun; Xiang, Shouxing; Liu, Shixia, Tsinghua Univ, BNRist, Beijing, Peoples R China. Xia, Jiazhi, Cent South Univ, Changsha, Peoples R China. Yu, Lingyun, Xian Jiaotong Liverpool Univ, Suzhou, Peoples R China.", "countries": "China", "abstract": "Given a scatterplot with tens of thousands of points or even more, a natural question is which sampling method should be used to create a small but \u201cgood\u201d scatterplot for a better abstraction. We present the results of a user study that investigates the influence of different sampling strategies on multi-class scatterplots. The main goal of this study is to understand the capability of sampling methods in preserving the density, outliers, and overall shape of a scatterplot. To this end, we comprehensively review the literature and select seven typical sampling strategies as well as eight representative datasets. We then design four experiments to understand the performance of different strategies in maintaining: 1) region density; 2) class density; 3) outliers; and 4) overall shape in the sampling results. The results show that: 1) random sampling is preferred for preserving region density; 2) blue noise sampling and random sampling have comparable performance with the three multi-class sampling strategies in preserving class density; 3) outlier biased density based sampling, recursive subdivision based sampling, and blue noise sampling perform the best in keeping outliers; and 4) blue noise sampling outperforms the others in maintaining the overall shape of a scatterplot.", "keywords": "Scatterplot,data sampling,empirical evaluation", "link": "http://dx.doi.org/10.1109/TVCG.2020.3030432", "refList": ["10.1057/palgrave.ivs.9500122", "10.1109/tvcg.2016.2598867", "10.1109/tvcg.2015.2467591", "10.1111/cgf.13708", "10.1109/tvcg.2019.2934799", "10.1109/tvcg.2019.2934541", "10.1109/tvcg.2013.65", "10.1109/iv.2004.1320207", "10.1068/p260471", "10.1145/1778765.1778816", "10.1109/tvcg.2018.2808489", "10.1109/tvcg.2018.2864912", "10.1016/j.apgeog.2015.12.006", "10.1111/j.1467-8659.2011.01960.x", "10.1109/tvcg.2018.2864843", "10.1109/pacificvis.2010.5429604", "10.1109/tvcg.2014.2346898", "10.1109/5.726791", "10.1177/1475090214540874", "10.1145/1556262.1556289", "10.1109/tvcg.2007.70535", "10.1109/vast.2012.6400489", "10.1145/1056808.1056914", "10.1016/j.neucom.2014.09.063", "10.1145/7529.8927", "10.1109/tvcg.2016.2607204", "10.1109/vast47406.2019.8986943", "10.3758/bf03205986", "10.1109/infvis.2005.1532142", "10.1145/1150402.1150479", "10.1109/tvcg.2017.2674978", "10.1109/tvcg.2017.2744098", "10.1109/tvcg.2017.2674999", "10.1109/tvcg.2011.279", "10.1109/tvcg.2014.2346594", "10.1109/tvcg.2017.2744184", "10.1111/cgf.12876", "10.1109/1011101.2019.2945960", "10.1007/s4095-020-0191-7", "10.1007/s11390-015-1535-0", "10.1111/cgf.12640", "10.1109/tvcg.2016.2598667", "10.1111/cgf.13683", "10.1109/tvcg.2013.153", "10.1109/tvcg.2019.2934208", "10.1109/tvcg.2019.2934655", "10.1111/cgf.12655", "10.1007/s11023-010-9221-z", "10.1109/vast.2012.6400487", "10.1145/2702123.2702585", "10.1007/bf00310175", "10.1109/tvcg.2017.2744378", "10.1103/physreve.64.061907", "10.1109/ldav.2017.8231848", "10.1109/tvcg.2016.2598831"], "wos": 1, "children": [], "len": 1}, {"doi": "10.1109/tvcg.2020.3030365", "title": "Modeling the Influence of Visual Density on Cluster Perception in Scatterplots Using Topology", "year": "2020", "conferenceName": "InfoVis", "authors": "Ghulam Jilani Quadri;Paul Rosen", "citationCount": "0", "affiliation": "Quadri, GJ (Corresponding Author), Univ S Florida, Tampa, FL 33620 USA. Quadri, Ghulam Jilani; Rosen, Paul, Univ S Florida, Tampa, FL 33620 USA.", "countries": "USA", "abstract": "Scatterplots are used for a variety of visual analytics tasks, including cluster identification, and the visual encodings used on a scatterplot play a deciding role on the level of visual separation of clusters. For visualization designers, optimizing the visual encodings is crucial to maximizing the clarity of data. This requires accurately modeling human perception of cluster separation, which remains challenging. We present a multi-stage user study focusing on four factors-distribution size of clusters, number of points, size of points, and opacity of points-that influence cluster identification in scatterplots. From these parameters, we have constructed two models, a distance-based model, and a density-based model, using the merge tree data structure from Topological Data Analysis. Our analysis demonstrates that these factors play an important role in the number of clusters perceived, and it verifies that the distance-based and density-based models can reasonably estimate the number of clusters a user observes. Finally, we demonstrate how these models can be used to optimize visual encodings on real-world data.", "keywords": "Scatterplot,clustering,perception,empirical evaluation,visual encoding,crowdsourcing,topological data analysis", "link": "http://dx.doi.org/10.1109/TVCG.2020.3030365", "refList": ["10.1109/tvcg.2017.2744359", "10.1145/1778765", "10.1109/tvcg.2019.2934799", "10.1111/cgf.12889", "10.1109/tvcg.2011.127", "10.1111/cgf.13444", "10.1145/1964897.1964910", "10.1167/8.7.6", "10.1145/3173574.3173991", "10.1145/1556262.1556289", "10.1145/1056808.1056914", "10.2307/2288400", "10.1109/tvcg.2014.2346594", "10.1109/iv.2002.1028760", "10.1177/001316447303300111", "10.1007/bf02289823", "10.1109/tvcg.2017.2744339", "10.1111/j.1467-8659.2009.01694.x", "10.1109/tvcg.2014.2346979", "10.1090/mbk/069", "10.1109/tvcg.2013.65", "10.1109/mcg.2012.37", "10.1109/pacificvis.2010.5429604", "10.1002/acp.2350050106", "10.1109/infvis.2005.1532136", "10.1177/1473871612465214", "10.1109/tvcg.2017.2674978", "10.1002/jhbs.20078", "10.1007/978-3-642-35142-6\\_14", "10.1007/978-3-319-71507-0", "10.1109/mcg.201.7.6", "10.3758/bf03193961", "10.1364/josa.49.000280", "10.1145/3025453.3025905", "10.1109/tvcg.201.9.2934541", "10.1109/tvcg.2018.2829750", "10.1177/1473871615606187", "10.1111/cgf.13408", "10.1109/pacificvis.2016.7465252", "10.1109/pacificvis.2016.7465244", "10.1109/inevis.2005.1532142", "10.1111/cgf.13414", "10.1111/j.1467-8659.2012.03125.x", "10.1167/16.5.11", "10.1109/infvis.2005.1532142", "10.1145/2858036.2858155", "10.1038/nmeth1210-941", "10.1177/1473871616638892", "10.1109/tcbb.2014.2306840", "10.1111/cgf.13684", "10.1177/0301006615602599", "10.1214/aoms/1177731915", "10.1145/2702123.2702585", "10.1109/tvcg.2013.183", "10.1109/tvcg.2014.2346572", "10.1109/tvcg.2018.2875702", "10.1109/tvcg.2017.2754480", "10.1109/vast.2014.7042493", "10.1057/palgrave.ivs.9500122", "10.1109/tvcg.2014.2330617", "10.1109/tvcg.2019.2934541", "10.1068/p030033", "10.1140/epjds/s13688-017-0109-5", "10.1201/b17511", "10.1016/s0925-7721(02)00093-7", "10.1109/pacificvis.2012.6183557", "10.1109/tvcg.2014.2346983", "10.1109/5.726791", "10.1080/01621459.1926.10502165", "10.1109/tvcg.2007.70535", "10.1109/tvcg.2018.2864907", "10.1111/cgf.12109", "10.1109/tvcg.2017.2744184", "10.1146/annurev-statistics-031017-100045", "10.1111/cgf.13409", "10.1145/3002151.3002162", "10.1016/s0378-4371(98)00494-4", "10.3138/y308-2422-8615-1233", "10.1111/cgf.12632", "10.1145/3290605.3300771"], "wos": 1, "children": [], "len": 1}, {"doi": "10.1111/cgf.14001", "year": "2020", "title": "Sunspot Plots: Model-based Structure Enhancement for Dense Scatter Plots", "conferenceName": "EuroVis", "authors": "Thomas Trautner;Fabian Bolte;Sergej Stoppel;Stefan Bruckner", "citationCount": "0", "affiliation": "Trautner, T (Corresponding Author), Univ Bergen, Bergen, Norway.\nTrautner, T.; Bolte, F.; Stoppel, S.; Bruckner, S., Univ Bergen, Bergen, Norway.", "countries": "Norway", "abstract": "Scatter plots are a powerful and well-established technique for visualizing the relationships between two variables as a collection of discrete points. However, especially when dealing with large and dense data, scatter plots often exhibit problems such as overplotting, making the data interpretation arduous. Density plots are able to overcome these limitations in highly populated regions, but fail to provide accurate information of individual data points. This is particularly problematic in sparse regions where the density estimate may not provide a good representation of the underlying data. In this paper, we present sunspot plots, a visualization technique that communicates dense data as a continuous data distribution, while preserving the discrete nature of data samples in sparsely populated areas. We furthermore demonstrate the advantages of our approach on typical failure cases of scatter plots within synthetic and real-world data sets and validate its effectiveness in a user study.", "keywords": "", "link": "https://doi.org/10.1111/cgf.14001", "refList": ["10.1057/palgrave.ivs.9500122", "10.2312/eggh/hpg12/097-103", "10.1109/tvcg.2008.119", "10.1109/pacificvis.2011.5742387", "10.1038/331163a0", "10.1109/visual.2019.8933620", "10.2307/2683294", "10.1201/9781351072304", "10.2307/2289444", "10.1109/tvcg.2019.2934541", "10.1080/00949657508810123", "10.1109/tvcg.2013.65", "10.1109/infvis.1997.636789", "10.1109/2945.841121", "10.1109/mcse.2007.55", "10.1109/tvcg.2010.197", "10.1111/cgf.12871", "10.1109/infvis.2003.1249018", "10.1145/3173574.3173991", "10.1109/tvcg.2012.238", "10.1007/0-387-28695-0", "10.1109/pacificvis.2010.5429604", "10.18637/jss.v008.i03", "10.1109/tvcg.2007.70596", "10.1109/visual.1998.745301", "10.1007/0-387-37977-0\\_3", "10.1145/1556262.1556289", "10.2312/wiced.20161094", "10.1109/tvcg.2007.70535", "10.1145/1056808.1056914", "10.1109/tvcg.2003.1196007", "10.1109/iv.2004.1320190", "10.1111/cgf.12877", "10.1162/leon.2007.40.2.202a", "10.1109/tvcg.2017.2674978", "10.1057/ivs.2010.4", "10.1016/j.cag.2018.02.008", "10.1201/9781315140919", "10.1109/visual.2000.885677", "10.1002/jhbs.20078", "10.1109/tvcg.2014.2346594", "10.1109/tvcg.2017.2744184", "10.1109/visual.2001.964495", "10.1109/iv.2002.1028760", "10.1111/cgf.13684", "10.1109/hicss.2013.197", "10.1109/tvcg.2019.2903956", "10.1093/mnras/stt961", "10.1109/tvcg.2017.2668409", "10.1111/j.1467-8659.2009.01478.x", "10.1145/2702123.2702585", "10.2307/1418003", "10.2307/1390742", "10.1145/360825.360839", "10.1109/pacificvis.2009.4906843", "10.1057/ivs.2009.34", "10.2307/2288711"], "wos": 1, "children": [], "len": 1}], "len": 9}, {"doi": "10.1109/tvcg.2019.2934284", "title": "Color Crafting: Automating the Construction of Designer Quality Color Ramps", "year": "2019", "conferenceName": "InfoVis", "authors": "Stephen Smart;Keke Wu;Danielle Albers Szafir", "citationCount": "3", "affiliation": "Smart, S (Corresponding Author), Univ Colorado, Boulder, CO 80309 USA. Smart, Stephen; Wu, Keke; Szafir, Danielle Albers, Univ Colorado, Boulder, CO 80309 USA.", "countries": "USA", "abstract": "Visualizations often encode numeric data using sequential and diverging color ramps. Effective ramps use colors that are sufficiently discriminable, align well with the data, and are aesthetically pleasing. Designers rely on years of experience to create high-quality color ramps. However, it is challenging for novice visualization developers that lack this experience to craft effective ramps as most guidelines for constructing ramps are loosely defined qualitative heuristics that are often difficult to apply. Our goal is to enable visualization developers to readily create effective color encodings using a single seed color. We do this using an algorithmic approach that models designer practices by analyzing patterns in the structure of designer-crafted color ramps. We construct these models from a corpus of 222 expert-designed color ramps, and use the results to automatically generate ramps that mimic designer practices. We evaluate our approach through an empirical study comparing the outputs of our approach with designer-crafted color ramps. Our models produce ramps that support accurate and aesthetically pleasing visualizations at least as well as designer ramps and that outperform conventional mathematical approaches.", "keywords": "Visualization,Aesthetics in Visualization,Color Perception,Visual Design,Design Mining", "link": "http://dx.doi.org/10.1109/TVCG.2019.2934284", "refList": ["10.1145/3009924", "10.1109/tvcg.2015.2489649", "10.1109/tvcg.2017.2744359", "10.1002/(sici)1098-1098(199622)7:2", "10.1016/s0734-189x(83)80046-2", "10.1109/tvcg.2016.2599106", "10.1364/josaa.29.000313", "10.1109/tvcg.2016.2598918", "10.2307/2683294", "10.1109/tvcg.2017.2653106", "10.1016/j.ijhcs.2010.05.006", "10.1016/0146-664x(81)90006-x", "10.1007/978-3-642-10520-3\\_9", "10.1109/38.135886", "10.1146/annurev-psych-120710-100504", "10.1016/j.csda.2008.11.033", "10.1145/2461912.2461988", "10.1016/j.cub.2007.06.022", "10.1016/s0146-664x(79)80040-4", "10.1109/mcg.2004.1297012", "10.1109/iv.2009.94", "10.1109/tpami.2010.184", "10.3758/s13414-010-0027-0", "10.1145/22949.22950", "10.1109/visual.1995.480803", "10.1109/tvcg.2014.2346277", "10.2307/2684111", "10.1109/tvcg.2018.2865240", "10.1111/cgf.12633", "10.1109/38.7760", "10.1016/j.jspi.2015.04.007", "10.1109/iv.2008.24", "10.1145/2939502.2939506", "10.1111/cgf.12127", "10.1016/j.cag.2010.11.015", "10.1145/3025453.3026041", "10.1109/tvcg.2012.315", "10.2307/2288400", "10.1511/2005.5.436", "10.1016/s0097-8493(96)00072-6", "10.1109/mcg.2018.011461525", "10.1145/2470654.2466420", "10.1109/tvcg.2012.279", "10.1109/tvcg.2014.2346978", "10.1109/tvcg.2017.2743978", "10.1145/3406601.3406602", "10.1117/12.2084548", "10.1109/tvcg.2018.2865147", "10.1109/tvcg.2015.2467191", "10.1111/cgf.13446", "10.1109/tvcg.2017.2744320", "10.1111/j.1467-8659.2008.01203.x", "10.1145/2702613.2702975", "10.1007/978-3-319-26633-6\\_13", "10.1145/2207676.2208547", "10.1109/tvcg.2008.174", "10.1179/000870403235002042"], "wos": 1, "children": [{"doi": "10.1109/tvcg.2020.3028891", "title": "A Structured Review of Data Management Technology for Interactive Visualization and Analysis", "year": "2020", "conferenceName": "InfoVis", "authors": "Leilani Battle;Carlos Scheidegger", "citationCount": "0", "affiliation": "Battle, L (Corresponding Author), Univ Maryland, Dept Comp Sci, College Pk, MD 20742 USA. Battle, Leilani, Univ Maryland, Dept Comp Sci, College Pk, MD 20742 USA. Scheidegger, Carlos, Univ Arizona, Dept Comp Sci, HDC Lab, Tucson, AZ 85721 USA.", "countries": "USA", "abstract": "In the last two decades, interactive visualization and analysis have become a central tool in data-driven decision making. Concurrently to the contributions in data visualization, research in data management has produced technology that directly benefits interactive analysis. Here, we contribute a systematic review of 30 years of work in this adjacent field, and highlight techniques and principles we believe to be underappreciated in visualization work. We structure our review along two axes. First, we use task taxonomies from the visualization literature to structure the space of interactions in usual systems. Second, we created a categorization of data management work that strikes a balance between specificity and generality. Concretely, we contribute a characterization of 131 research papers along these two axes. We find that five notions in data management venues fit interactive visualization systems well: materialized views, approximate query processing, user modeling and query prediction, muiti-query optimization, lineage techniques, and indexing techniques. In addition, we find a preponderance of work in materialized views and approximate query processing, most targeting a limited subset of the interaction tasks in the taxonomy we used. This suggests natural avenues of future research both in visualization and data management. Our categorization both changes how we visualization researchers design and build our systems, and highlights where future work is necessary.", "keywords": "", "link": "http://dx.doi.org/10.1109/TVCG.2020.3028891", "refList": ["10.1109/tvcg.2012.233", "10.1016/s0022-5371(74)80015-0", "10.1109/tvcg.2017.2744359", "10.1037/0096-3445.136.4.623", "10.1109/tvcg.2015.2467732", "10.1109/tvcg.2012.196", "10.1037/a0029856", "10.1109/tvcg.2014.2346979", "10.1037/h0030300", "10.1109/tvcg.2016.2598918", "10.1109/beliv.2018.8634420", "10.1109/tvcg.2018.2864909", "10.1111/cgf.13079", "10.3389/fpsyg.2012.00355", "10.1145/2858036.2858465", "10.1080/01621459.1989.10478821", "10.1037/0278-7393.24.3.732", "10.1109/tvcg.2011.127", "10.1145/2858036.2858063", "10.4249/scholarpedia.3325", "10.4324/9781410611949", "10.1111/cgf.13444", "10.1145/2993901.2993909", "10.1037/0033-295x.96.2.267", "10.1006/ijhc.1017", "10.1086/405615", "10.1109/tvcg.2019.2934801", "10.1038/17953", "10.1037/xhp0000314", "10.1109/tvcg.2019.2934400", "10.1145/2470654.2470723", "10.1037/0096-1523.16.2.332", "10.1167/16.5.11", "10.3758/s13423-016-1174-7", "10.3758/bf03207704", "10.1146/annurev.psych.55.090902.141415", "10.2307/2288400", "10.3758/bf03204258", "10.1109/tvcg.2011.279", "10.1109/vissoft.2014.36", "10.3758/s13423-011-0055-3", "10.1145/3025453.3025922", "10.1109/tvcg.2019.2934284", "10.3758/bf03210498", "10.3758/bf03200774", "10.2307/1419876", "10.1038/s41562-017-0058", "10.1109/tvcg.2010.237", "10.1109/pacificvis.2012.6183556", "10.1109/infvis.1997.636792", "10.1093/acprof:oso/9780198523192.003.0005", "10.1073/pnas.1117465109", "10.1109/tvcg.2013.234", "10.1038/nn.3655", "10.1111/cgf.12379", "10.1146/annurev-psych-010416-044232", "10.1111/cgf.13695", "10.1037/0033-295x.107.3.500", "10.1109/tvcg.2013.183", "10.1146/annurev.psych.53.100901.135125", "10.1037//0022-3514.79.6.995", "10.1559/152304003100010929", "10.1109/tvcg.2018.2865147", "10.1037/0096-1523.18.3.849", "10.1111/j.1467-8659.2009.01694.x", "10.1145/3290605.3300771"], "wos": 1, "children": [], "len": 1}], "len": 3}, {"doi": "10.1109/tvcg.2019.2934799", "title": "Data Sampling in Multi-view and Multi-class Scatterplots via Set Cover Optimization", "year": "2019", "conferenceName": "InfoVis", "authors": "Ruizhen Hu;Tingkai Sha;Oliver van Kaick;Oliver Deussen;Hui Huang 0004", "citationCount": "4", "affiliation": "Hu, RZ (Corresponding Author), Shenzhen Univ, Visual Comp Res Ctr, Shenzhen, Guangdong, Peoples R China. Hu, Ruizhen; Sha, Tingkai; Huang, Hui, Shenzhen Univ, Visual Comp Res Ctr, Shenzhen, Guangdong, Peoples R China. van Kaick, Oliver, Carleton Univ, Sch Comp Sci, Ottawa, ON, Canada. Deussen, Oliver, Konstanz Univ, Constance, Germany. Deussen, Oliver, SIAT, Shenzhen VisuCA Key Lab, Shenzhen, Guangdong, Peoples R China.", "countries": "Canada;Germany;China", "abstract": "We present a method for data sampling in scatterplots by jointly optimizing point selection for different views or classes. Our method uses space-filling curves (Z-order curves) that partition a point set into subsets that, when covered each by one sample, provide a sampling or coreset with good approximation guarantees in relation to the original point set. For scatterplot matrices with multiple views, different views provide different space-filling curves, leading to different partitions of the given point set. For multi-class scatterplots, the focus on either per-class distribution or global distribution provides two different partitions of the given point set that need to be considered in the selection of the coreset. For both cases, we convert the coreset selection problem into an Exact Cover Problem (ECP), and demonstrate with quantitative and qualitative evaluations that an approximate solution that solves the ECP efficiently is able to provide high-quality samplings.", "keywords": "Sampling,Scatterplot,SPLOM,Exact Cover Problem", "link": "http://dx.doi.org/10.1109/TVCG.2019.2934799", "refList": ["10.1057/palgrave.ivs.9500122", "10.1109/tvcg.2006.170", "10.1109/tvcg.2008.119", "10.1111/j.1467-8659.2009.01467.x", "10.2307/2289444", "10.1109/tvcg.2013.65", "10.1109/tvcg.2011.229", "10.1109/iv.2004.1320207", "10.1109/itoec.2018.8740621", "10.1145/1778765.1778816", "10.1109/tvcg.2018.2864912", "10.1007/0-387-28695-0", "10.1109/visual.1998.745301", "10.1287/moor.4.3.233", "10.1145/1556262.1556289", "10.1109/tvcg.2007.70535", "10.2307/2284239", "10.1109/tvcg.2017.2674978", "10.1016/j.dss.2009.05.016", "10.1109/tvcg.2014.2346594", "10.1109/vds.2017.8573446", "10.1007/978-1-4684-2001-2\\_9", "10.1109/iv.2002.1028760", "10.1145/1842993.1842999", "10.1038/nmeth.2490", "10.1109/tvcg.2013.153", "10.1111/cgf.13446", "10.1109/tvcg.2010.176", "10.1145/2702123.2702585", "10.1057/ivs.2009.34", "10.1179/000870403235002042"], "wos": 1, "children": [{"doi": "10.1109/tvcg.2020.3030443", "title": "CAVA: A Visual Analytics System for Exploratory Columnar Data Augmentation Using Knowledge Graphs", "year": "2020", "conferenceName": "VAST", "authors": "Dylan Cashman;Shenyu Xu;Subhajit Das;Florian Heimerl;Cong Liu;Shah Rukh Humayoun;Michael Gleicher;Alex Endert;Remco Chang", "citationCount": "0", "affiliation": "Cashman, D (Corresponding Author), Tufts Univ, Medford, MA 02155 USA. Cashman, Dylan; Liu, Cong; Chang, Remco, Tufts Univ, Medford, MA 02155 USA. Xu, Shenyu; Das, Subhajit; Endert, Alex, Georgia Tech, Atlanta, GA USA. Heimerl, Florian; Gleicher, Michael, Univ Wisconsin, Madison, WI 53706 USA. Humayoun, Shah Rukh, San Francisco State Univ, San Francisco, CA 94132 USA.", "countries": "USA", "abstract": "Most visual analytics systems assume that all foraging for data happens before the analytics process; once analysis begins, the set of data attributes considered is fixed. Such separation of data construction from analysis precludes iteration that can enable foraging informed by the needs that arise in-situ during the analysis. The separation of the foraging loop from the data analysis tasks can limit the pace and scope of analysis. In this paper, we present CAVA, a system that integrates data curation and data augmentation with the traditional data exploration and analysis tasks, enabling information foraging in-situ during analysis. Identifying attributes to add to the dataset is difficult because it requires human knowledge to determine which available attributes will be helpful for the ensuing analytical tasks. CAVA crawls knowledge graphs to provide users with a a broad set of attributes drawn from external data to choose from. Users can then specify complex operations on knowledge graphs to construct additional attributes. CAVA shows how visual analytics can help users forage for attributes by letting users visually explore the set of available data, and by serving as an interface for query construction. It also provides visualizations of the knowledge graph itself to help users understand complex joins such as multi-hop aggregations. We assess the ability of our system to enable users to perform complex data combinations without programming in a user study over two datasets. We then demonstrate the generalizability of CAVA through two additional usage scenarios. The results of the evaluation confirm that CAVA is effective in helping the user perform data foraging that leads to improved analysis outcomes, and offer evidence in support of integrating data augmentation as a part of the visual analytics pipeline.", "keywords": "Visual Analytics,Information Foraging,Data Augmentation", "link": "http://dx.doi.org/10.1109/TVCG.2020.3030443", "refList": ["10.1057/palgrave.ivs.9500122", "10.1109/tvcg.2016.2598867", "10.1111/cgf.13708", "10.1109/tvcg.2019.2934799", "10.1109/tvcg.2019.2934541", "10.1109/tvcg.2013.65", "10.1109/tvcg.2018.2875702", "10.1109/iv.2004.1320207", "10.1068/p260471", "10.1145/1778765.1778816", "10.1109/tvcg.2018.2808489", "10.1109/tvcg.2018.2864912", "10.1016/j.apgeog.2015.12.006", "10.1111/j.1467-8659.2011.01960.x", "10.1109/tvcg.2018.2864843", "10.1109/pacificvis.2010.5429604", "10.1109/tvcg.2014.2346898", "10.1109/5.726791", "10.1177/1475090214540874", "10.1109/icde.2016.7498287", "10.1145/1556262.1556289", "10.1109/tvcg.2007.70535", "10.1109/vast.2012.6400489", "10.1145/1056808.1056914", "10.1016/j.neucom.2014.09.063", "10.1145/7529.8927", "10.1109/tvcg.2016.2598495", "10.1109/tvcg.2016.2607204", "10.1109/vast47406.2019.8986943", "10.3758/bf03205986", "10.1109/infvis.2005.1532142", "10.1145/1150402.1150479", "10.1109/tvcg.2017.2674978", "10.1109/tvcg.2019.2945960", "10.1109/tvcg.2017.2744098", "10.1109/tvcg.2017.2674999", "10.1109/tvcg.2011.279", "10.1109/tvcg.2014.2346594", "10.1109/tvcg.2017.2744184", "10.1111/cgf.12876", "10.1007/s4095-020-0191-7", "10.1007/s11390-015-1535-0", "10.1111/cgf.12640", "10.1109/tvcg.2016.2598667", "10.1111/cgf.13683", "10.1109/tvcg.2013.153", "10.1109/tvcg.2019.2934208", "10.1109/tvcg.2019.2934655", "10.1111/cgf.12655", "10.1007/s11023-010-9221-z", "10.1109/vast.2012.6400487", "10.1145/2702123.2702585", "10.1007/bf00310175", "10.1109/tvcg.2017.2744378", "10.1103/physreve.64.061907", "10.1109/ldav.2017.8231848", "10.1109/tvcg.2016.2598831"], "wos": 1, "children": [], "len": 1}, {"doi": "10.1109/tvcg.2020.3030432", "title": "Evaluation of Sampling Methods for Scatterplots", "year": "2020", "conferenceName": "VAST", "authors": "Jun Yuan;Shouxing Xiang;Jiazhi Xia;Lingyun Yu;Shixia Liu", "citationCount": "0", "affiliation": "Liu, SX (Corresponding Author), Tsinghua Univ, BNRist, Beijing, Peoples R China. Yuan, Jun; Xiang, Shouxing; Liu, Shixia, Tsinghua Univ, BNRist, Beijing, Peoples R China. Xia, Jiazhi, Cent South Univ, Changsha, Peoples R China. Yu, Lingyun, Xian Jiaotong Liverpool Univ, Suzhou, Peoples R China.", "countries": "China", "abstract": "Given a scatterplot with tens of thousands of points or even more, a natural question is which sampling method should be used to create a small but \u201cgood\u201d scatterplot for a better abstraction. We present the results of a user study that investigates the influence of different sampling strategies on multi-class scatterplots. The main goal of this study is to understand the capability of sampling methods in preserving the density, outliers, and overall shape of a scatterplot. To this end, we comprehensively review the literature and select seven typical sampling strategies as well as eight representative datasets. We then design four experiments to understand the performance of different strategies in maintaining: 1) region density; 2) class density; 3) outliers; and 4) overall shape in the sampling results. The results show that: 1) random sampling is preferred for preserving region density; 2) blue noise sampling and random sampling have comparable performance with the three multi-class sampling strategies in preserving class density; 3) outlier biased density based sampling, recursive subdivision based sampling, and blue noise sampling perform the best in keeping outliers; and 4) blue noise sampling outperforms the others in maintaining the overall shape of a scatterplot.", "keywords": "Scatterplot,data sampling,empirical evaluation", "link": "http://dx.doi.org/10.1109/TVCG.2020.3030432", "refList": ["10.1057/palgrave.ivs.9500122", "10.1109/tvcg.2016.2598867", "10.1109/tvcg.2015.2467591", "10.1111/cgf.13708", "10.1109/tvcg.2019.2934799", "10.1109/tvcg.2019.2934541", "10.1109/tvcg.2013.65", "10.1109/iv.2004.1320207", "10.1068/p260471", "10.1145/1778765.1778816", "10.1109/tvcg.2018.2808489", "10.1109/tvcg.2018.2864912", "10.1016/j.apgeog.2015.12.006", "10.1111/j.1467-8659.2011.01960.x", "10.1109/tvcg.2018.2864843", "10.1109/pacificvis.2010.5429604", "10.1109/tvcg.2014.2346898", "10.1109/5.726791", "10.1177/1475090214540874", "10.1145/1556262.1556289", "10.1109/tvcg.2007.70535", "10.1109/vast.2012.6400489", "10.1145/1056808.1056914", "10.1016/j.neucom.2014.09.063", "10.1145/7529.8927", "10.1109/tvcg.2016.2607204", "10.1109/vast47406.2019.8986943", "10.3758/bf03205986", "10.1109/infvis.2005.1532142", "10.1145/1150402.1150479", "10.1109/tvcg.2017.2674978", "10.1109/tvcg.2017.2744098", "10.1109/tvcg.2017.2674999", "10.1109/tvcg.2011.279", "10.1109/tvcg.2014.2346594", "10.1109/tvcg.2017.2744184", "10.1111/cgf.12876", "10.1109/1011101.2019.2945960", "10.1007/s4095-020-0191-7", "10.1007/s11390-015-1535-0", "10.1111/cgf.12640", "10.1109/tvcg.2016.2598667", "10.1111/cgf.13683", "10.1109/tvcg.2013.153", "10.1109/tvcg.2019.2934208", "10.1109/tvcg.2019.2934655", "10.1111/cgf.12655", "10.1007/s11023-010-9221-z", "10.1109/vast.2012.6400487", "10.1145/2702123.2702585", "10.1007/bf00310175", "10.1109/tvcg.2017.2744378", "10.1103/physreve.64.061907", "10.1109/ldav.2017.8231848", "10.1109/tvcg.2016.2598831"], "wos": 1, "children": [], "len": 1}, {"doi": "10.1109/tvcg.2020.3030365", "title": "Modeling the Influence of Visual Density on Cluster Perception in Scatterplots Using Topology", "year": "2020", "conferenceName": "InfoVis", "authors": "Ghulam Jilani Quadri;Paul Rosen", "citationCount": "0", "affiliation": "Quadri, GJ (Corresponding Author), Univ S Florida, Tampa, FL 33620 USA. Quadri, Ghulam Jilani; Rosen, Paul, Univ S Florida, Tampa, FL 33620 USA.", "countries": "USA", "abstract": "Scatterplots are used for a variety of visual analytics tasks, including cluster identification, and the visual encodings used on a scatterplot play a deciding role on the level of visual separation of clusters. For visualization designers, optimizing the visual encodings is crucial to maximizing the clarity of data. This requires accurately modeling human perception of cluster separation, which remains challenging. We present a multi-stage user study focusing on four factors-distribution size of clusters, number of points, size of points, and opacity of points-that influence cluster identification in scatterplots. From these parameters, we have constructed two models, a distance-based model, and a density-based model, using the merge tree data structure from Topological Data Analysis. Our analysis demonstrates that these factors play an important role in the number of clusters perceived, and it verifies that the distance-based and density-based models can reasonably estimate the number of clusters a user observes. Finally, we demonstrate how these models can be used to optimize visual encodings on real-world data.", "keywords": "Scatterplot,clustering,perception,empirical evaluation,visual encoding,crowdsourcing,topological data analysis", "link": "http://dx.doi.org/10.1109/TVCG.2020.3030365", "refList": ["10.1109/tvcg.2017.2744359", "10.1145/1778765", "10.1109/tvcg.2019.2934799", "10.1111/cgf.12889", "10.1109/tvcg.2011.127", "10.1111/cgf.13444", "10.1145/1964897.1964910", "10.1167/8.7.6", "10.1145/3173574.3173991", "10.1145/1556262.1556289", "10.1145/1056808.1056914", "10.2307/2288400", "10.1109/tvcg.2014.2346594", "10.1109/iv.2002.1028760", "10.1177/001316447303300111", "10.1007/bf02289823", "10.1109/tvcg.2017.2744339", "10.1111/j.1467-8659.2009.01694.x", "10.1109/tvcg.2014.2346979", "10.1090/mbk/069", "10.1109/tvcg.2013.65", "10.1109/mcg.2012.37", "10.1109/pacificvis.2010.5429604", "10.1002/acp.2350050106", "10.1109/infvis.2005.1532136", "10.1177/1473871612465214", "10.1109/tvcg.2017.2674978", "10.1002/jhbs.20078", "10.1007/978-3-642-35142-6\\_14", "10.1007/978-3-319-71507-0", "10.1109/mcg.201.7.6", "10.3758/bf03193961", "10.1364/josa.49.000280", "10.1145/3025453.3025905", "10.1109/tvcg.201.9.2934541", "10.1109/tvcg.2018.2829750", "10.1177/1473871615606187", "10.1111/cgf.13408", "10.1109/pacificvis.2016.7465252", "10.1109/pacificvis.2016.7465244", "10.1109/inevis.2005.1532142", "10.1111/cgf.13414", "10.1111/j.1467-8659.2012.03125.x", "10.1167/16.5.11", "10.1109/infvis.2005.1532142", "10.1145/2858036.2858155", "10.1038/nmeth1210-941", "10.1177/1473871616638892", "10.1109/tcbb.2014.2306840", "10.1111/cgf.13684", "10.1177/0301006615602599", "10.1214/aoms/1177731915", "10.1145/2702123.2702585", "10.1109/tvcg.2013.183", "10.1109/tvcg.2014.2346572", "10.1109/tvcg.2018.2875702", "10.1109/tvcg.2017.2754480", "10.1109/vast.2014.7042493", "10.1057/palgrave.ivs.9500122", "10.1109/tvcg.2014.2330617", "10.1109/tvcg.2019.2934541", "10.1068/p030033", "10.1140/epjds/s13688-017-0109-5", "10.1201/b17511", "10.1016/s0925-7721(02)00093-7", "10.1109/pacificvis.2012.6183557", "10.1109/tvcg.2014.2346983", "10.1109/5.726791", "10.1080/01621459.1926.10502165", "10.1109/tvcg.2007.70535", "10.1109/tvcg.2018.2864907", "10.1111/cgf.12109", "10.1109/tvcg.2017.2744184", "10.1146/annurev-statistics-031017-100045", "10.1111/cgf.13409", "10.1145/3002151.3002162", "10.1016/s0378-4371(98)00494-4", "10.3138/y308-2422-8615-1233", "10.1111/cgf.12632", "10.1145/3290605.3300771"], "wos": 1, "children": [], "len": 1}], "len": 7}, {"doi": "10.1109/tvcg.2019.2934432", "title": "Discriminability Tests for Visualization Effectiveness and Scalability", "year": "2019", "conferenceName": "InfoVis", "authors": "Rafael Veras;Christopher Collins", "citationCount": "1", "affiliation": "Veras, R (Corresponding Author), Ontario Tech Univ, Oshawa, ON, Canada. Veras, Rafael; Collins, Christopher, Ontario Tech Univ, Oshawa, ON, Canada.", "countries": "Canada", "abstract": "The scalability of a particular visualization approach is limited by the ability for people to discern differences between plots made with different datasets. Ideally, when the data changes, the visualization changes in perceptible ways. This relation breaks down when there is a mismatch between the encoding and the character of the dataset being viewed. Unfortunately, visualizations are often designed and evaluated without fully exploring how they will respond to a wide variety of datasets. We explore the use of an image similarity measure, the Multi-Scale Structural Similarity Index (MS-SSIM), for testing the discriminability of a data visualization across a variety of datasets. MS-SSIM is able to capture the similarity of two visualizations across multiple scales, including low level granular changes and high level patterns. Significant data changes that are not captured by the MS-SSIM indicate visualizations of low discriminability and effectiveness. The measure's utility is demonstrated with two empirical studies. In the first, we compare human similarity judgments and MS-SSIM scores for a collection of scatterplots. In the second, we compute the discriminability values for a set of basic visualizations and compare them with empirical measurements of effectiveness. In both cases, the analyses show that the computational measure is able to approximate empirical results. Our approach can be used to rank competing encodings on their discriminability and to aid in selecting visualizations for a particular type of data distribution.", "keywords": "Scalability,Discriminability,Simulation,Perception", "link": "http://dx.doi.org/10.1109/TVCG.2019.2934432", "refList": ["10.1109/tvcg.2012.233", "10.1109/tvcg.2017.2744359", "10.1109/tvcg.2012.230", "10.1111/cgf.12647", "10.1109/tvcg.2016.2598918", "10.1109/tvcg.2007.70529", "10.1145/2858036.2858435", "10.1109/vast.2009.5332628", "10.1145/3025453.3025912", "10.1145/1133265.1133318", "10.1109/tip.2010.2092435", "10.1109/tvcg.2010.132", "10.1109/tvcg.2018.2865264", "10.1175/jtech-d-11-00103.1", "10.1145/1190036.1190039", "10.1111/cgf.12127", "10.1109/infvis.2005.1532142", "10.1145/2858036.2858155", "10.1109/mcg.2014.18", "10.1145/3173574.3174172", "10.1109/tvcg.2009.153", "10.1057/palgrave.ivs.9500070", "10.1109/tvcg.2018.2790961", "10.1109/tvcg.2014.2346978", "10.1109/tvcg.2018.2810918", "10.1111/cgf.13409", "10.1109/tip.2003.819861", "10.1145/2642918.2647411", "10.1080/15230406.2016.1140074", "10.1109/jstsp.2009.2015374", "10.1109/tvcg.2010.237", "10.1109/mcg.2009.6", "10.1111/j.1467-8659.2009.01667.x", "10.1109/tvcg.2010.161", "10.1111/cgf.13446", "10.1109/tvcg.2014.2346325", "10.1109/tvcg.2009.111", "10.1147/jrd.2015.2411412"], "wos": 1, "children": [{"doi": "10.1109/tvcg.2020.3030394", "title": "Direct Volume Rendering with Nonparametric Models of Uncertainty", "year": "2020", "conferenceName": "SciVis", "authors": "Tushar M. Athawale;Bo Ma 0002;Elham Sakhaee;Christopher R. Johnson;Alireza Entezari", "citationCount": "0", "affiliation": "Athawale, TM (Corresponding Author), Univ Utah, Sci Comp \\& Imaging SCI Inst, Salt Lake City, UT 84112 USA. Athawale, Tushar M.; Johnson, Chris R., Univ Utah, Sci Comp \\& Imaging SCI Inst, Salt Lake City, UT 84112 USA. Ma, Bo; Sakhaee, Elham; Entezari, Alireza, Univ Florida, Dept CISE, Gainesville, FL 32611 USA.", "countries": "USA", "abstract": "We present a nonparametric statistical framework for the quantification, analysis, and propagation of data uncertainty in direct volume rendering (DVR). The state-of-the-art statistical DVR framework allows for preserving the transfer function (TF) of the ground truth function when visualizing uncertain data; however, the existing framework is restricted to parametric models of uncertainty. In this paper, we address the limitations of the existing DVR framework by extending the DVR framework for nonparametric distributions. We exploit the quantile interpolation technique to derive probability distributions representing uncertainty in viewing-ray sample intensities in closed form, which allows for accurate and efficient computation. We evaluate our proposed nonparametric statistical models through qualitative and quantitative comparisons with the mean-field and parametric statistical models, such as uniform and Gaussian, as well as Gaussian mixtures. In addition, we present an extension of the state-of-the-art rendering parametric framework to 2D TFs for improved DVR classifications. We show the applicability of our uncertainty quantification framework to ensemble, downsampled, and bivariate versions of scalar field datasets.", "keywords": "Volumes,uncertainty,nonparametric,2D transfer function", "link": "http://dx.doi.org/10.1109/TVCG.2020.3030394", "refList": ["10.1109/icdm.2012.80", "10.1145/1401890.1401904", "10.1109/tvcg.2017.2745139", "10.18128/d030.v6.0", "10.1111/cgf.12142", "10.1109/tvcg.2009.114", "10.1111/j.1467-8659.2009.01677.x", "10.1109/mcse.2007.55", "10.1109/icde.2012.16", "10.1198/106186008x320465", "10.1145/1835804.1835868", "10.1559/1523040054738936", "10.1109/tvcg.2019.2934432", "10.1109/34.1000236", "10.1109/infvis.2005.1532136", "10.1109/tvcg.2012.128", "10.1109/pacificvis.2017.8031573", "10.1109/tvcg.2016.2598920", "10.1109/tvcg.2018.2865021", "10.1109/infvis.2005.1532142", "10.1145/2858036.2858155", "10.1109/sp.2009.22", "10.1109/tvcg.2017.2744184", "10.1145/773153.773173", "10.1145/2660267.2660348", "10.1109/icdmw.2009.93", "10.1016/j.jtrangeo.2015.09.001", "10.1109/icde.2010.5447831", "10.1007/11681878\\_14", "10.1111/cgf.13409", "10.1007/s13278-014-0205-5", "10.1109/tvcg.2011.163", "10.1145/3035918.3035940", "10.1109/sp.2008.33", "10.1145/2882903.2882931"], "wos": 1, "children": [], "len": 1}], "len": 3}, {"doi": "10.1109/tvcg.2019.2934208", "title": "Evaluating Perceptual Bias During Geometric Scaling of Scatterplots", "year": "2019", "conferenceName": "VAST", "authors": "Yating Wei;Honghui Mei;Ying Zhao;Shuyue Zhou;Bingru Lin;Haojing Jiang;Wei Chen", "citationCount": "5", "affiliation": "Chen, W (Corresponding Author), Zhejiang Univ, State Key Lab CAD \\& CG, Hangzhou 310058, Zhejiang, Peoples R China. Zhao, Y (Corresponding Author), Cent South Univ, Sch Comp Sci \\& Engn, Changsha 410083, Hunan, Peoples R China. Wei, Yating; Mei, Honghui; Zhou, Shuyue; Lin, Bingru; Chen, Wei, Zhejiang Univ, State Key Lab CAD \\& CG, Hangzhou 310058, Zhejiang, Peoples R China. Zhao, Ying; Jiang, Haojing, Cent South Univ, Sch Comp Sci \\& Engn, Changsha 410083, Hunan, Peoples R China.", "countries": "China", "abstract": "Scatterplots are frequently scaled to fit display areas in multi-view and multi-device data analysis environments. A common method used for scaling is to enlarge or shrink the entire scatterplot together with the inside points synchronously and proportionally. This process is called geometric scaling. However, geometric scaling of scatterplots may cause a perceptual bias, that is, the perceived and physical values of visual features may be dissociated with respect to geometric scaling. For example, if a scatterplot is projected from a laptop to a large projector screen, then observers may feel that the scatterplot shown on the projector has fewer points than that viewed on the laptop. This paper presents an evaluation study on the perceptual bias of visual features in scatterplots caused by geometric scaling. The study focuses on three fundamental visual features (i.e., numerosity, correlation, and cluster separation) and three hypotheses that are formulated on the basis of our experience. We carefully design three controlled experiments by using well-prepared synthetic data and recruit participants to complete the experiments on the basis of their subjective experience. With a detailed analysis of the experimental results, we obtain a set of instructive findings. First, geometric scaling causes a bias that has a linear relationship with the scale ratio. Second, no significant difference exists between the biases measured from normally and uniformly distributed scatterplots. Third, changing the point radius can correct the bias to a certain extent. These findings can be used to inspire the design decisions of scatterplots in various scenarios.", "keywords": "Evaluation,scatterplot,geometric scaling,bias,perceptual consistency", "link": "http://dx.doi.org/10.1109/TVCG.2019.2934208", "refList": ["10.2307/2288843", "10.1109/tvcg.2017.2744359", "10.1109/tvcg.2015.2467732", "10.1109/tvcg.2014.2346979", "10.1126/science.216.4550.1138", "10.1109/tvcg.2017.2744138", "10.1111/j.1467-8659.2009.01467.x", "10.1145/2491568.2491577", "10.1109/mwc.2018.1700325", "10.1145/2449396.2449439", "10.1109/tvcg.2011.127", "10.1109/tvcg.2011.229", "10.1167/15.5.4", "10.1073/pnas.1113195108", "10.1145/2702123.2702545", "10.1109/vast.2009.5332628", "10.1109/tvcg.2018.2800013", "10.1007/s12650-018-0530-2", "10.1016/s0042-6989(97)00340-4", "10.1109/vast.2010.5652460", "10.1109/mcg.2018.2879067", "10.1109/tvcg.2018.2864912", "10.1109/pacificvis.2010.5429604", "10.1109/tcst.2018.2819965", "10.1167/10.2.10", "10.1145/2470654.2481318", "10.1145/1842993.1843002", "10.1167/12.6.8", "10.1109/tvcg.2013.124", "10.1057/ivs.2008.13", "10.1109/tvcg.2007.70596", "10.1109/tvcg.2018.2865266", "10.1145/3173574.3173664", "10.1109/tvcg.2015.2467671", "10.1016/j.cag.2017.07.004", "10.1177/0956797613501520", "10.1109/tvcg.2018.2865020", "10.1111/j.1467-8659.2012.03125.x", "10.3758/bf03205986", "10.3758/s13423-016-1174-7", "10.1109/tvcg.2017.2680452", "10.1109/mc.2006.109", "10.1109/tvcg.2017.2744098", "10.1038/srep32810", "10.1016/j.visres.2013.06.006", "10.1002/jhbs.20078", "10.1109/tvcg.2006.163", "10.1109/tvcg.2014.2346594", "10.1109/tvcg.2017.2744184", "10.1016/j.cognition.2007.10.009", "10.1109/tvcg.2018.2865142", "10.3758/app.72.7.1839", "10.1109/tvcg.2018.2810918", "10.1016/j.jvlc.2017.10.001", "10.1145/2682623", "10.1109/tvcg.2018.2864884", "10.1145/3025453.3025984", "10.1109/tvcg.2006.184", "10.1109/tvcg.2013.153", "10.1016/j.jvlc.2018.08.003", "10.1109/tvcg.2016.2520921", "10.1111/cgf.13446", "10.1017/s0022381612000187", "10.1145/2702123.2702406", "10.1109/vast.2012.6400487", "10.1109/tvcg.2013.183", "10.1177/1473871611415997", "10.1145/2702123.2702585", "10.1145/2993901.2993903", "10.1109/tvcg.2013.120", "10.1111/cgf.12632", "10.1145/1385569.1385602", "10.1109/tvcg.2017.2754480", "10.1111/j.1467-8659.2009.01694.x"], "wos": 1, "children": [{"doi": "10.1109/tvcg.2020.3030456", "title": "Cartographic Relief Shading with Neural Networks", "year": "2020", "conferenceName": "InfoVis", "authors": "Bernhard Jenny;Magnus Heitzler;Dilpreet Singh;Marianna Farmakis-Serebryakova;Jeffery Chieh Liu;Lorenz Hurni", "citationCount": "4", "affiliation": "Jenny, B (Corresponding Author), Monash Univ, Melbourne, Vic, Australia. Jenny, Bernhard; Singh, Dilpreet; Liu, Jeffery Chieh, Monash Univ, Melbourne, Vic, Australia. Heitzler, Magnus; Farmakis-Serebryakova, Marianna; Hurni, Lorenz, Swiss Fed Inst Technol, Inst Cartog \\& Geoinformat, Zurich, Switzerland.", "countries": "Switzerland;Australia", "abstract": "Shaded relief is an effective method for visualising terrain on topographic maps, especially when the direction of illumination is adapted locally to emphasise individual terrain features. However, digital shading algorithms are unable to fully match the expressiveness of hand-crafted masterpieces, which are created through a laborious process by highly specialised cartographers. We replicate hand-drawn relief shading using U-Net neural networks. The deep neural networks are trained with manual shaded relief images of the Swiss topographic map series and terrain models of the same area. The networks generate shaded relief that closely resemble hand-drawn shaded relief art. The networks learn essential design principles from manual relief shading such as removing unnecessary terrain details, locally adjusting the illumination direction to accentuate individual terrain features, and varying brightness to emphasise larger landforms. Neural network shadings are generated from digital elevation models in a few seconds, and a study with 18 relief shading experts found that they are of high quality.", "keywords": "Relief shading,shaded relief,hillshade,neural rendering,illustrative visualisation,image-to-image translation", "link": "http://dx.doi.org/10.1109/TVCG.2020.3030456", "refList": ["10.1145/1456650.1456652", "10.1145/1145/1556262.1556270", "10.1145/345513.345271", "10.1109/tvcg.2019.2934803", "10.1145/3180658", "10.1109/tridui.2006.1618264", "10.3389/fict.2018.00015", "10.1109/vr.2018.8447558", "10.1518/hfes.45.1.160.27234", "10.1145/3290605.3300377", "10.1089/cpb.2006.9.157", "10.1007/s00779-011-0500-3", "10.1109/vl.1996.545307", "10.1109/tvcg.2019.2934415", "10.1109/5.726791", "10.1145/3290605.3300288", "10.1109/tvcg.2017.2745941", "10.1109/vr.2001.913779", "10.1145/586081.586086", "10.18637/jss.v067.i01", "10.1145/1502800.1502805", "10.1145/1165734.1165736", "10.1145/3126594.3126613", "10.1109/tvcg.2008.109", "10.1109/tvcg.2017.2744184", "10.1016/j.cola.2019.100937", "10.1109/visual.2019.8933545", "10.1145/3290605.3300555", "10.1111/cgf.13431", "10.1109/tvcg.2019.2934395", "10.1109/vr.2019.8798340", "10.1145/3025453.3026046", "10.1109/vr.2019.8797871", "10.1145/3290605.3300752", "10.1109/tvcg.2016.2520921", "10.1109/tvcg.2018.2865191", "10.1145/1970378.1970384", "10.1109/tvcg.2019.2934208", "10.18637/jss.v069.i01", "10.1162/105474698565659", "10.1145/1124772.1124775", "10.1109/vrais.1997.583043"], "wos": 1, "children": [], "len": 1}, {"doi": "10.1109/tvcg.2020.3030443", "title": "CAVA: A Visual Analytics System for Exploratory Columnar Data Augmentation Using Knowledge Graphs", "year": "2020", "conferenceName": "VAST", "authors": "Dylan Cashman;Shenyu Xu;Subhajit Das;Florian Heimerl;Cong Liu;Shah Rukh Humayoun;Michael Gleicher;Alex Endert;Remco Chang", "citationCount": "0", "affiliation": "Cashman, D (Corresponding Author), Tufts Univ, Medford, MA 02155 USA. Cashman, Dylan; Liu, Cong; Chang, Remco, Tufts Univ, Medford, MA 02155 USA. Xu, Shenyu; Das, Subhajit; Endert, Alex, Georgia Tech, Atlanta, GA USA. Heimerl, Florian; Gleicher, Michael, Univ Wisconsin, Madison, WI 53706 USA. Humayoun, Shah Rukh, San Francisco State Univ, San Francisco, CA 94132 USA.", "countries": "USA", "abstract": "Most visual analytics systems assume that all foraging for data happens before the analytics process; once analysis begins, the set of data attributes considered is fixed. Such separation of data construction from analysis precludes iteration that can enable foraging informed by the needs that arise in-situ during the analysis. The separation of the foraging loop from the data analysis tasks can limit the pace and scope of analysis. In this paper, we present CAVA, a system that integrates data curation and data augmentation with the traditional data exploration and analysis tasks, enabling information foraging in-situ during analysis. Identifying attributes to add to the dataset is difficult because it requires human knowledge to determine which available attributes will be helpful for the ensuing analytical tasks. CAVA crawls knowledge graphs to provide users with a a broad set of attributes drawn from external data to choose from. Users can then specify complex operations on knowledge graphs to construct additional attributes. CAVA shows how visual analytics can help users forage for attributes by letting users visually explore the set of available data, and by serving as an interface for query construction. It also provides visualizations of the knowledge graph itself to help users understand complex joins such as multi-hop aggregations. We assess the ability of our system to enable users to perform complex data combinations without programming in a user study over two datasets. We then demonstrate the generalizability of CAVA through two additional usage scenarios. The results of the evaluation confirm that CAVA is effective in helping the user perform data foraging that leads to improved analysis outcomes, and offer evidence in support of integrating data augmentation as a part of the visual analytics pipeline.", "keywords": "Visual Analytics,Information Foraging,Data Augmentation", "link": "http://dx.doi.org/10.1109/TVCG.2020.3030443", "refList": ["10.1057/palgrave.ivs.9500122", "10.1109/tvcg.2016.2598867", "10.1111/cgf.13708", "10.1109/tvcg.2019.2934799", "10.1109/tvcg.2019.2934541", "10.1109/tvcg.2013.65", "10.1109/tvcg.2018.2875702", "10.1109/iv.2004.1320207", "10.1068/p260471", "10.1145/1778765.1778816", "10.1109/tvcg.2018.2808489", "10.1109/tvcg.2018.2864912", "10.1016/j.apgeog.2015.12.006", "10.1111/j.1467-8659.2011.01960.x", "10.1109/tvcg.2018.2864843", "10.1109/pacificvis.2010.5429604", "10.1109/tvcg.2014.2346898", "10.1109/5.726791", "10.1177/1475090214540874", "10.1109/icde.2016.7498287", "10.1145/1556262.1556289", "10.1109/tvcg.2007.70535", "10.1109/vast.2012.6400489", "10.1145/1056808.1056914", "10.1016/j.neucom.2014.09.063", "10.1145/7529.8927", "10.1109/tvcg.2016.2598495", "10.1109/tvcg.2016.2607204", "10.1109/vast47406.2019.8986943", "10.3758/bf03205986", "10.1109/infvis.2005.1532142", "10.1145/1150402.1150479", "10.1109/tvcg.2017.2674978", "10.1109/tvcg.2019.2945960", "10.1109/tvcg.2017.2744098", "10.1109/tvcg.2017.2674999", "10.1109/tvcg.2011.279", "10.1109/tvcg.2014.2346594", "10.1109/tvcg.2017.2744184", "10.1111/cgf.12876", "10.1007/s4095-020-0191-7", "10.1007/s11390-015-1535-0", "10.1111/cgf.12640", "10.1109/tvcg.2016.2598667", "10.1111/cgf.13683", "10.1109/tvcg.2013.153", "10.1109/tvcg.2019.2934208", "10.1109/tvcg.2019.2934655", "10.1111/cgf.12655", "10.1007/s11023-010-9221-z", "10.1109/vast.2012.6400487", "10.1145/2702123.2702585", "10.1007/bf00310175", "10.1109/tvcg.2017.2744378", "10.1103/physreve.64.061907", "10.1109/ldav.2017.8231848", "10.1109/tvcg.2016.2598831"], "wos": 1, "children": [], "len": 1}, {"doi": "10.1109/tvcg.2020.3030432", "title": "Evaluation of Sampling Methods for Scatterplots", "year": "2020", "conferenceName": "VAST", "authors": "Jun Yuan;Shouxing Xiang;Jiazhi Xia;Lingyun Yu;Shixia Liu", "citationCount": "0", "affiliation": "Liu, SX (Corresponding Author), Tsinghua Univ, BNRist, Beijing, Peoples R China. Yuan, Jun; Xiang, Shouxing; Liu, Shixia, Tsinghua Univ, BNRist, Beijing, Peoples R China. Xia, Jiazhi, Cent South Univ, Changsha, Peoples R China. Yu, Lingyun, Xian Jiaotong Liverpool Univ, Suzhou, Peoples R China.", "countries": "China", "abstract": "Given a scatterplot with tens of thousands of points or even more, a natural question is which sampling method should be used to create a small but \u201cgood\u201d scatterplot for a better abstraction. We present the results of a user study that investigates the influence of different sampling strategies on multi-class scatterplots. The main goal of this study is to understand the capability of sampling methods in preserving the density, outliers, and overall shape of a scatterplot. To this end, we comprehensively review the literature and select seven typical sampling strategies as well as eight representative datasets. We then design four experiments to understand the performance of different strategies in maintaining: 1) region density; 2) class density; 3) outliers; and 4) overall shape in the sampling results. The results show that: 1) random sampling is preferred for preserving region density; 2) blue noise sampling and random sampling have comparable performance with the three multi-class sampling strategies in preserving class density; 3) outlier biased density based sampling, recursive subdivision based sampling, and blue noise sampling perform the best in keeping outliers; and 4) blue noise sampling outperforms the others in maintaining the overall shape of a scatterplot.", "keywords": "Scatterplot,data sampling,empirical evaluation", "link": "http://dx.doi.org/10.1109/TVCG.2020.3030432", "refList": ["10.1057/palgrave.ivs.9500122", "10.1109/tvcg.2016.2598867", "10.1109/tvcg.2015.2467591", "10.1111/cgf.13708", "10.1109/tvcg.2019.2934799", "10.1109/tvcg.2019.2934541", "10.1109/tvcg.2013.65", "10.1109/iv.2004.1320207", "10.1068/p260471", "10.1145/1778765.1778816", "10.1109/tvcg.2018.2808489", "10.1109/tvcg.2018.2864912", "10.1016/j.apgeog.2015.12.006", "10.1111/j.1467-8659.2011.01960.x", "10.1109/tvcg.2018.2864843", "10.1109/pacificvis.2010.5429604", "10.1109/tvcg.2014.2346898", "10.1109/5.726791", "10.1177/1475090214540874", "10.1145/1556262.1556289", "10.1109/tvcg.2007.70535", "10.1109/vast.2012.6400489", "10.1145/1056808.1056914", "10.1016/j.neucom.2014.09.063", "10.1145/7529.8927", "10.1109/tvcg.2016.2607204", "10.1109/vast47406.2019.8986943", "10.3758/bf03205986", "10.1109/infvis.2005.1532142", "10.1145/1150402.1150479", "10.1109/tvcg.2017.2674978", "10.1109/tvcg.2017.2744098", "10.1109/tvcg.2017.2674999", "10.1109/tvcg.2011.279", "10.1109/tvcg.2014.2346594", "10.1109/tvcg.2017.2744184", "10.1111/cgf.12876", "10.1109/1011101.2019.2945960", "10.1007/s4095-020-0191-7", "10.1007/s11390-015-1535-0", "10.1111/cgf.12640", "10.1109/tvcg.2016.2598667", "10.1111/cgf.13683", "10.1109/tvcg.2013.153", "10.1109/tvcg.2019.2934208", "10.1109/tvcg.2019.2934655", "10.1111/cgf.12655", "10.1007/s11023-010-9221-z", "10.1109/vast.2012.6400487", "10.1145/2702123.2702585", "10.1007/bf00310175", "10.1109/tvcg.2017.2744378", "10.1103/physreve.64.061907", "10.1109/ldav.2017.8231848", "10.1109/tvcg.2016.2598831"], "wos": 1, "children": [], "len": 1}], "len": 7}, {"doi": "10.1109/tvcg.2019.2934300", "title": "GUIRO: User-Guided Matrix Reordering", "year": "2019", "conferenceName": "VAST", "authors": "Michael Behrisch;Tobias Schreck;Hanspeter Pfister", "citationCount": "1", "affiliation": "Behrisch, M (Corresponding Author), Harvard Univ, Sch Engn \\& Appl Sci, Cambridge, MA 02138 USA. Behrisch, Michael; Pfister, Hanspeter, Harvard Univ, Sch Engn \\& Appl Sci, Cambridge, MA 02138 USA. Schreck, Tobias, Graz Univ Technol, Graz, Austria.", "countries": "USA;Austria", "abstract": "Matrix representations are one of the main established and empirically proven to be effective visualization techniques for relational (or network) data. However, matrices\u2014similar to node-link diagrams\u2014are most effective if their layout reveals the underlying data topology. Given the many developed algorithms, a practical problem arises: \u201cWhich matrix reordering algorithm should I choose for my dataset at hand?\u201d To make matters worse, different reordering algorithms applied to the same dataset may let significantly different visual matrix patterns emerge. This leads to the question of trustworthiness and explainability of these fully automated, often heuristic, black-box processes. We present GUIRO, a Visual Analytics system that helps novices, network analysts, and algorithm designers to open the black-box. Users can investigate the usefulness and expressiveness of 70 accessible matrix reordering algorithms. For network analysts, we introduce a novel model space representation and two interaction techniques for a user-guided reordering of rows or columns, and especially groups thereof (submatrix reordering). These novel techniques contribute to the understanding of the global and local dataset topology. We support algorithm designers by giving them access to 16 reordering quality metrics and visual exploration means for comparing reordering implementations on a row/column permutation level. We evaluated GUIRO in a guided explorative user study with 12 subjects, a case study demonstrating its usefulness in a real-world scenario, and through an expert study gathering feedback on our design decisions. We found that our proposed methods help even inexperienced users to understand matrix patterns and allow a user-guided steering of reordering algorithms. GUIRO helps to increase the transparency of matrix reordering algorithms, thus helping a broad range of users to get a better insight into the complex reordering process, in turn supporting data and reordering algorithm insights.", "keywords": "Visual Analytics,matrix,black-box algorithms,seriation,ordering,sorting,steerable algorithm,interaction,2D projection", "link": "http://dx.doi.org/10.1109/TVCG.2019.2934300", "refList": ["10.1109/tvcg.2007.70582", "10.2307/276978", "10.1109/tvcg.2008.61", "10.3390/su10040973", "10.1101/121889", "10.1145/1345448.1345453", "10.1186/s12879-014-0695-9", "10.1186/1471-2105-9-155", "10.1145/1124772.1124891", "10.1109/tvcg.2010.159", "10.1111/j.2044-8317.1974.tb00534.x", "10.1109/tpami.2015.2470671", "10.1198/000313005x22770", "10.1109/tvcg.2012.219", "10.1002/sam.10071", "10.1016/j.ejor.2016.08.066", "10.1007/s00265-003-0651-y", "10.1109/biovis.2013.6664342", "10.3115/v1/p14-1062", "10.3389/fpsyg.2017.01349", "10.1109/tpami.2004.1265866", "10.1057/palgrave.ivs.9500086", "10.1007/s004260000031", "10.1111/cgf.12935", "10.1145/800195.805928", "10.1109/tvcg.2014.2346279", "10.2312/eurovisstar.20141174", "10.1109/tvcg.2012.256", "10.1093/bioinformatics/17.suppl\\_1.s22", "10.1109/infvis.2004.46", "10.1007/978-3-319-06793-3\\_5", "10.1109/tvcg.2006.147", "10.1109/tvcg.2015.2468078", "10.1093/bioinformatics/bti141", "10.1145/1168149.1168168", "10.1109/tvcg.2017.2745978", "10.1177/1473871613513228", "10.1109/mcg.2014.62", "10.1109/tvcg.2006.166", "10.1145/2470654.2470724", "10.1177/154193120605000909", "10.1109/sibgrapi.2007.21", "10.1145/3065386", "10.1109/tvcg.2006.160", "10.1287/opre.20.5.993", "10.1111/cgf.13446", "10.1057/palgrave.ivs.9500092", "10.1145/568522.568523", "10.1109/mcg.2013.66", "10.1109/tvcg.2018.2865940", "10.1109/tvcg.2012.208"], "wos": 1, "children": [{"doi": "10.1109/tvcg.2020.3030471", "title": "Visual Analysis of Discrimination in Machine Learning", "year": "2020", "conferenceName": "InfoVis", "authors": "Qianwen Wang;Zhenhua Xu;Zhutian Chen;Yong Wang;Shixia Liu;Huamin Qu", "citationCount": "0", "affiliation": "Wang, QW (Corresponding Author), Hong Kong Univ Sci \\& Technol, Hong Kong, Peoples R China. Wang, Qianwen; Xu, Zhenhua; Chen, Zhutian; Wang, Yong; Qu, Huamin, Hong Kong Univ Sci \\& Technol, Hong Kong, Peoples R China. Liu, Shixia, Tsinghua Univ, Beijing, Peoples R China.", "countries": "China", "abstract": "The growing use of automated decision-making in critical applications, such as crime prediction and college admission, has raised questions about fairness in machine learning. How can we decide whether different treatments are reasonable or discriminatory? In this paper, we investigate discrimination in machine learning from a visual analytics perspective and propose an interactive visualization tool, DiscriLens, to support a more comprehensive analysis. To reveal detailed information on algorithmic discrimination, DiscriLens identifies a collection of potentially discriminatory itemsets based on causal modeling and classification rules mining. By combining an extended Euler diagram with a matrix-based visualization, we develop a novel set visualization to facilitate the exploration and interpretation of discriminatory itemsets. A user study shows that users can interpret the visually encoded information in DiscriLens quickly and accurately. Use cases demonstrate that DiscriLens provides informative guidance in understanding and reducing algorithmic discrimination.", "keywords": "Machine Learning,Discrimination,Data Visualization", "link": "http://dx.doi.org/10.1109/TVCG.2020.3030471", "refList": ["10.1109/tvcg.2019.2934396", "10.2312/eurovisstar.20141170", "10.1145/3357384.3357910", "10.1111/cgf.12791", "10.1109/tvcg.2018.2861397", "10.1111/j.1467-8659.2011.01898.x", "10.1145/2702123.2702237", "10.1109/tvcg.2019.2934798", "10.1109/mcg.2017.21", "10.1109/tvcg.2019.2934300", "10.1109/tvcg.2017.2745085", "10.1109/tvcg.2018.2859997", "10.1145/3173574.3174237", "10.1109/tvcg.2018.2865126", "10.1145/1718487.1718520", "10.1109/tvcg.2017.2743858", "10.1109/pacificvis.2015.7156392", "10.1109/tvcg.2018.2864477", "10.1145/324133.324140", "10.1137/140976649", "10.1145/3219819.3220088", "10.1109/tvcg.2019.2934805", "10.1145/1134271.1134277", "10.1137/090772745", "10.1016/j.jelectrocard.2010.09.003", "10.1109/tvcg.2012.253", "10.1145/2556612", "10.1109/tvcg.2013.173", "10.1109/tvcg.2019.2934619", "10.1109/tvcg.2017.2745078"], "wos": 1, "children": [], "len": 1}], "len": 3}, {"doi": "10.1109/tvcg.2019.2934796", "title": "Improving the Robustness of Scagnostics", "year": "2019", "conferenceName": "InfoVis", "authors": "Yunhai Wang;Zeyu Wang 0005;Tingting Liu;Michael Correll;Zhanglin Cheng;Oliver Deussen;Michael Sedlmair", "citationCount": "1", "affiliation": "Wang, YH (Corresponding Author), Shandong Univ, Jinan, Peoples R China. Wang, Yunhai; Wang, Zeyu; Liu, Tingting, Shandong Univ, Jinan, Peoples R China. Wang, Zeyu; Cheng, Zhanglin; Deussen, Oliver, SIAT, Shenzhen VisuCA Key Lab, Shenzhen, Peoples R China. Correll, Michael, Tableau Res, Seattle, WA USA. Deussen, Oliver, Konstanz Univ, Constance, Germany. Sedlmair, Michael, Univ Stuttgart, VISUS, Stuttgart, Germany.", "countries": "USA;Germany;China", "abstract": "In this paper, we examine the robustness of scagnostics through a series of theoretical and empirical studies. First, we investigate the sensitivity of scagnostics by employing perturbing operations on more than 60M synthetic and real-world scatterplots. We found that two scagnostic measures, Outlying and Clumpy, are overly sensitive to data binning. To understand how these measures align with human judgments of visual features, we conducted a study with 24 participants, which reveals that i) humans are not sensitive to small perturbations of the data that cause large changes in both measures, and ii) the perception of clumpiness heavily depends on per-cluster topologies and structures. Motivated by these results, we propose Robust Scagnostics (RScag) by combining adaptive binning with a hierarchy-based form of scagnostics. An analysis shows that RScag improves on the robustness of original scagnostics, aligns better with human judgments, and is equally fast as the traditional scagnostic measures.", "keywords": "Scagnostics,scatterplots,sensitivity analysis,Robust Scagnostics", "link": "http://dx.doi.org/10.1109/TVCG.2019.2934796", "refList": ["10.1057/palgrave.ivs.9500122", "10.1109/tvcg.2014.2346979", "10.1111/j.1467-8659.2009.01467.x", "10.1109/vast.2008.4677368", "10.2307/2289444", "10.1109/tvcg.2011.229", "10.1109/iv.2004.1320207", "10.1109/vast.2009.5332628", "10.1111/insr.12095\\_11", "10.1109/tvcg.2010.184", "10.1109/tvcg.2015.2467323", "10.1109/vast.2010.5652460", "10.1111/j.1467-8659.2012.03069.x", "10.1145/1842993.1843002", "10.1198/106186008x320465", "10.1109/pacificvis.2016.7465244", "10.1109/tvcg.2013.20", "10.1111/cgf.12641", "10.1109/tvcg.2012.128", "10.1109/tvcg.2015.2467671", "10.1057/palgrave.ivs.9500091", "10.1007/978-1-4612-4400-4", "10.1111/cgf.13176", "10.1002/0470870958", "10.1109/tvcg.2018.2864907", "10.1111/j.1467-8659.2012.03125.x", "10.1109/vast.2012.6400490", "10.1109/infvis.2005.1532142", "10.1109/vast.2010.5652433", "10.1109/vast.2009.5332611", "10.1201/9781315140919", "10.1145/2858036.2858155", "10.1109/ldav.2013.6675164", "10.1515/itit-2014-1070", "10.1111/cgf.13684", "10.1109/tpami.1979.4766909", "10.2307/2289936", "10.1109/pacificvis.2014.42", "10.1109/tvcg.2016.2598467", "10.1109/tvcg.2013.153", "10.1111/cgf.13446", "10.1109/tvcg.2006.94", "10.1109/tvcg.2014.2346572", "10.1111/cgf.12632", "10.1109/tvcg.2017.2744339"], "wos": 1, "children": [], "len": 1}, {"doi": "10.1109/vast47406.2019.8986917", "title": "VIANA: Visual Interactive Annotation of Argumentation", "year": "2019", "conferenceName": "VAST", "authors": "Fabian Sperrle;Rita Sevastjanova;Rebecca Kehlbeck;Mennatallah El-Assady", "citationCount": "0", "affiliation": "Sperrle, F (Corresponding Author), Univ Konstanz, Constance, Germany. Sperrle, Fabian; Sevastjanova, Rita; Kehlbeck, Rebecca; El-Assady, Mennatallah, Univ Konstanz, Constance, Germany.", "countries": "Germany", "abstract": "Argumentation Mining addresses the challenging tasks of identifying boundaries of argumentative text fragments and extracting their relationships. Fully automated solutions do not reach satisfactory accuracy due to their insufficient incorporation of semantics and domain knowledge. Therefore, experts currently rely on time-consuming manual annotations. In this paper, we present a visual analytics system that augments the manual annotation process by automatically suggesting which text fragments to annotate next. The accuracy of those suggestions is improved over time by incorporating linguistic knowledge and language modeling to learn a measure of argument similarity from user interactions. Based on a long-term collaboration with domain experts, we identify and model five high-level analysis tasks. We enable close reading and note-taking, annotation of arguments, argument reconstruction, extraction of argument relations, and exploration of argument graphs. To avoid context switches, we transition between all views through seamless morphing, visually anchoring all text- and graph-based layers. We evaluate our system with a two-stage expert user study based on a corpus of presidential debates. The results show that experts prefer our system over existing solutions due to the speedup provided by the automatic suggestions and the tight integration between text and graph views.", "keywords": "Argumentation annotation,machine learning,user interaction,layered interfaces,semantic transitions", "link": "http://dx.doi.org/10.1109/VAST47406.2019.8986917", "refList": ["10.1007/978-3-642-40624-9\\_1", "10.3233/978-1-61499-436-7-185", "10.1145/371920.372071", "10.3233/978-1-61499-906-5-4", "10.1109/tvcg.2015.2467759", "10.18653/v1/d15-1050", "10.2307/2529310", "10.1109/mic.2003.1167344", "10.1145/312624.312682", "10.1145/2850417", "10.18653/v1/p17-2039", "10.1016/j.eswa.2016.02.013", "10.1007/978-0-387-85820-3\\_3", "10.1007/s11412-009-9080-x", "10.1109/tvcg.2008.127", "10.1145/2207676.2207741", "10.1109/cit.2012.217", "10.3233/aac-170022", "10.1109/tvcg.2017.2745080", "10.1007/978-3-319-44039-2\\_6", "10.1145/3290605.3300233", "10.1007/978-94-017-0431-1", "10.3233/978-1-61499-906-5-313", "10.1142/s0218213004001922", "10.1109/tvcg.2012.262", "10.1177/001316446002000104", "10.1109/tvcg.2018.2834341", "10.3233/978-1-61499-436-7-463", "10.1145/1772690.1772773", "10.1109/tvcg.2014.2346677", "10.1145/2523813", "10.1162/153244303322533223", "10.1109/tvcg.2007.70539", "10.1109/tvcg.2015.2467531", "10.1109/tvcg.2018.2864769", "10.1007/978-3-319-90092-6\\_14", "10.1137/1.9781611972801.19", "10.1109/vast.2012.6400485", "10.1007/s10579-013-9215-6", "10.3115/v1/d14-1162", "10.1111/cgf.13446", "10.1109/tvcg.2006.156", "10.1111/cgf.13092", "10.1145/2645710.2645759", "10.1109/bigdata.2017.8258140", "10.1145/2669557.2669572", "10.2312/eurovisstar.20151113"], "wos": 1, "children": [], "len": 1}, {"doi": "10.1109/tvcg.2020.3030376", "title": "Insight Beyond Numbers: The Impact of Qualitative Factors on Visual Data Analysis", "year": "2020", "conferenceName": "VAST", "authors": "Benjamin Karer;Hans Hagen;Dirk J. Lehmann", "citationCount": "0", "affiliation": "Karer, B (Corresponding Author), Fed Criminal Police Off Germany, Wiesbaden, Germany. Karer, Benjamin, Fed Criminal Police Off Germany, Wiesbaden, Germany. Hagen, Hans, TU Kaiserslautern, Kaiserslautern, Germany. Lehmann, Dirk J., Ostfalia Univ Appl Sci, Wolfenbuttel, Germany. Lehmann, Dirk J., IAV GmbH, Berlin, Germany.", "countries": "Germany", "abstract": "As of today, data analysis focuses primarily on the findings to be made inside the data and concentrates less on how those findings relate to the domain of investigation. Contemporary visualization as a field of research shows a strong tendency to adopt this data-centrism. Despite their decisive influence on the analysis result, qualitative aspects of the analysis process such as the structure, soundness, and complexity of the applied reasoning strategy are rarely discussed explicitly. We argue that if the purpose of visualization is the provision of domain insight rather than the depiction of data analysis results, a holistic perspective requires a qualitative component to to be added to the discussion of quantitative and human factors. To support this point, we demonstrate how considerations of qualitative factors in visual analysis can be applied to obtain explanations and possible solutions for a number of practical limitations inherent to the data-centric perspective on analysis. Based on this discussion of what we call qualitative visual analysis, we develop an inside-outside principle of nested levels of context that can serve as a conceptual basis for the development of visualization systems that optimally support the emergence of insight during analysis.", "keywords": "Visualization,Reasoning,Qualitative Aspects", "link": "http://dx.doi.org/10.1109/TVCG.2020.3030376", "refList": ["10.1057/ivs.2009.22", "10.1109/tvcg.2015.2467732", "10.1109/infvis.2000.885092", "10.1109/vast.2014.7042482", "10.1145/1498700.1498704", "10.1109/tvcg.2009.108", "10.1109/tvcg.2018.2829750", "10.1037/0033-295x.111.4.1036", "10.1109/tvcg.2012.199", "10.1109/38.267476", "10.1007/978-3-540-70956-5\\_2", "10.1109/tvcg.2015.2467613", "10.1109/tvcg.2015.2467195", "10.1109/tvcg.2014.2346419", "10.1109/vast.2017.8585669", "10.1109/tvcg.2010.132", "10.1145/22949.22950", "10.1109/tvcg.2014.2346984", "10.1017/cbo9780511816772", "10.1109/mcg.2003.1231171", "10.1111/coin.12227", "10.1109/tvcg.2018.2865138", "10.1109/38.788803", "10.1109/tvcg.2018.2864849", "10.1109/mcg.2012.120", "10.1109/tvcg.2007.70535", "10.1162/neco.2008.12-06-420", "10.1109/tvcg.2018.2865240", "10.1089/tmj.2010.0114", "10.1109/beliv.2018.8634267", "10.1109/tvcg.2014.2346481", "10.1207/s15327809jls0402\\_2", "10.1109/tvcg.2006.80", "10.1145/2858036.2858280", "10.1109/tvcg.2017.2674978", "10.1109/tvcg.2011.52", "10.1016/j.cag.2014.03.002", "10.1109/tvcg.2015.2513410", "10.1111/j.1756-8765.2011.01150.x", "10.1109/infvis.2005.1532142", "10.1002/spe.4380211102", "10.1186/s41235-018-0120-9", "10.1073/pnas.1807180116", "10.1109/tvcg.2012.133", "10.1109/tvcg.2012.273", "10.1111/j.1467-8659.2011.01928.x", "10.1145/353485.353486", "10.1109/tvcg.2015.2462356", "10.1109/mcg.2019.2923483", "10.1111/cgf.13264", "10.1057/palgrave.ivs.9500070", "10.1145/1168149.1168158", "10.1109/mcg.2019.2961716", "10.1016/s0167-739x(96)00029-5", "10.1111/j.1467-8659.2009.01667.x", "10.1177/1473871611415989", "10.1109/tvcg.2013.234", "10.1109/iv.2012.33", "10.1111/cgf.13446", "10.1057/ivs.2008.28", "10.1111/cgf.12379", "10.1037/0033-295x.112.1.159", "10.1109/tvcg.2010.161", "10.1109/tvcg.2017.2744319", "10.1145/989863.989880", "10.1007/s11390-016-1663-1", "10.1177/1473871615609787", "10.1016/j.cola.2019.100911"], "wos": 1, "children": [], "len": 1}, {"doi": "10.1109/tvcg.2020.3030395", "title": "Towards Modeling Visualization Processes as Dynamic Bayesian Networks", "year": "2020", "conferenceName": "InfoVis", "authors": "Christian Heine 0002", "citationCount": "0", "affiliation": "Heine, C (Corresponding Author), Univ Leipzig, Leipzig, Germany. Heine, Christian, Univ Leipzig, Leipzig, Germany.", "countries": "Germany", "abstract": "Visualization designs typically need to be evaluated with user studies, because their suitability for a particular task is hard to predict. What the field of visualization is currently lacking are theories and models that can be used to explain why certain designs work and others do not. This paper outlines a general framework for modeling visualization processes that can serve as the first step towards such a theory. It surveys related research in mathematical and computational psychology and argues for the use of dynamic Bayesian networks to describe these time-dependent, probabilistic processes. It is discussed how these models could be used to aid in design evaluation. The development of concrete models will be a long process. Thus, the paper outlines a research program sketching how to develop prototypes and their extensions from existing models, controlled experiments, and observational studies.", "keywords": "Visualization,model building,perception,cognition,dynamic Bayesian networks", "link": "http://dx.doi.org/10.1109/TVCG.2020.3030395", "refList": ["10.1057/ivs.2009.22", "10.1109/tvcg.2015.2467732", "10.1109/infvis.2000.885092", "10.1109/vast.2014.7042482", "10.1145/1498700.1498704", "10.1109/tvcg.2009.108", "10.1109/tvcg.2018.2829750", "10.1037/0033-295x.111.4.1036", "10.1109/tvcg.2012.199", "10.1111/cgf.13899", "10.1109/38.267476", "10.1007/978-3-540-70956-5\\_2", "10.1109/tvcg.2015.2467613", "10.1109/tvcg.2015.2467195", "10.1109/tvcg.2014.2346419", "10.1145/3290605.3300562", "10.1109/vl.1996.545307", "10.1109/vast.2017.8585669", "10.1109/infvis.2003.1249004", "10.1109/tvcg.2010.132", "10.1145/22949.22950", "10.1109/tvcg.2014.2346984", "10.1145/3290605.3300418", "10.1017/cbo9780511816772", "10.1109/mcg.2003.1231171", "10.1111/coin.12227", "10.1109/tvcg.2018.2865138", "10.1109/38.788803", "10.1109/tvcg.2018.2864849", "10.1109/mcg.2012.120", "10.1109/tvcg.2007.70535", "10.1162/neco.2008.12-06-420", "10.1109/tvcg.2018.2865240", "10.1089/tmj.2010.0114", "10.1109/beliv.2018.8634267", "10.1109/tvcg.2014.2346481", "10.1207/s15327809jls0402\\_2", "10.1109/tvcg.2006.80", "10.1145/2858036.2858280", "10.1109/tvcg.2017.2674978", "10.1109/tvcg.2011.52", "10.1016/j.cag.2014.03.002", "10.1109/tvcg.2015.2513410", "10.1111/j.1756-8765.2011.01150.x", "10.1109/infvis.2005.1532142", "10.1002/spe.4380211102", "10.1186/s41235-018-0120-9", "10.1073/pnas.1807180116", "10.1109/tvcg.2012.133", "10.1109/tvcg.2012.273", "10.1111/j.1467-8659.2011.01928.x", "10.1145/353485.353486", "10.1109/tvcg.2015.2462356", "10.1109/mcg.2019.2923483", "10.1111/cgf.13264", "10.1057/palgrave.ivs.9500070", "10.1145/1168149.1168158", "10.1109/mcg.2019.2961716", "10.1016/s0167-739x(96)00029-5", "10.1111/j.1467-8659.2009.01667.x", "10.1177/1473871611415989", "10.1109/tvcg.2013.234", "10.1109/iv.2012.33", "10.1111/cgf.13446", "10.1057/ivs.2008.28", "10.1111/cgf.12379", "10.1037/0033-295x.112.1.159", "10.1017/cb09781139033916.005", "10.1109/tvcg.2010.161", "10.1109/tvcg.2017.2744319", "10.1145/989863.989880", "10.1007/s11390-016-1663-1", "10.1177/1473871615609787", "10.1016/j.cola.2019.100911", "10.1057/palgrave.ivs.9500025"], "wos": 1, "children": [], "len": 1}, {"doi": "10.1109/pacificvis48177.2020.8199", "year": "2020", "title": "Efficient Morphing of Shape-preserving Star Coordinates", "conferenceName": "PacificVis", "authors": "Vladimir Molchanov;Sagad Hamid;Lars Linsen", "citationCount": "0", "affiliation": "Molchanov, V (Corresponding Author), Westfalische Wilhelms Univ Munster, Munster, Germany.\nMolchanov, Vladimir; Hamid, Sagad; Linsen, Lars, Westfalische Wilhelms Univ Munster, Munster, Germany.", "countries": "Germany", "abstract": "Data tours follow an exploratory multi-dimensional data visualization concept that provides animations of projections of the multidimensional data to a 2D visual space. To create an animation, a sequence of key projections is provided and morphings between each pair of consecutive key projections are computed, which then can be stitched together to form the data tour. The morphings should be smooth so that a user can easily follow the transformations, and their computations shall be fast to allow for their integration into an interactive visual exploration process. Moreover, if the key projections are chosen to satisfy additional conditions, it is desirable that these conditions are maintained during morphing. Shape preservation is such a desirable condition, as it avoids shape distortions that may otherwise be caused by a projection. We develop a novel efficient morphing algorithms for computing shape-preserving data tours, i.e., data tours constructed for a sequence of shape-preserving linear projections. We propose a stepping strategy for the morphing to avoid discontinuities in the evolution of the projections, where we represent the linear projections using a star-coordinates system. Our algorithms are less computationally involved, produce smoother morphings, and require less user-defined parameter settings than existing state-of-the-art approaches.", "keywords": "Human-centered computing; Visualization; Visualization techniques", "link": "https://doi.org/10.1109/PacificVis48177.2020.8199", "refList": ["10.2312/eurovisshort.20141152", "10.1109/tvcg.2013.182", "10.1109/tvcg.2008.153", "10.1109/tvcg.2015.2467591", "10.4135/9781412985130", "10.1111/cgf.12878", "10.1016/j.cag.2016.08.007", "10.1080/10618600.1995.10474674", "10.1109/infvis.2003.1249004", "10.1002/9781118445112.stat06472", "10.1109/visual.1997.663916", "10.1111/cgf.12117", "10.1137/0906011", "10.1109/tvcg.2018.2865118", "10.1126/science.290.5500.2319", "10.1111/cgf.12845", "10.1111/j.1467-8659.2012.03125.x", "10.1109/tvcg.2017.2705189", "10.1002/0471725293", "10.1111/cgf.12876", "10.1111/cgf.13404", "10.2307/2289161", "10.1111/cgf.13446", "10.1198/106186008x318440", "10.2307/1390747", "10.1109/tvcg.2012.35", "10.1109/tvcg.2015.2467132", "10.1109/tvcg.2006.94", "10.1109/t-c.1974.224051", "10.1109/pacificvis.2019.00018", "10.1109/tvcg.2017.2744339", "10.1109/tsmcb.2005.850151"], "wos": 1, "children": [], "len": 1}, {"doi": "10.1109/pacificvis.2019.00018", "year": "2019", "title": "Scatterplot Summarization by Constructing Fast and Robust Principal Graphs from Skeletons", "conferenceName": "PacificVis", "authors": "Jos{\\'{e}} Matute;Marcel Fischer;Alexandru C. Telea;Lars Linsen", "citationCount": "1", "affiliation": "Matute, J (Corresponding Author), Univ Munster, Munster, Germany.\nMatute, Jose; Fischer, Marcel; Linsen, Lars, Univ Munster, Munster, Germany.\nTelea, Alexandru C., Univ Groningen, Groningen, Netherlands.", "countries": "Germany;Netherlands", "abstract": "Principal curves are a long-standing and well-known method for summarizing large scatterplots. They are defined as self-consistent curves (or curve sets in the more general case) that locally pass through the middle of the scatterplot data. However, computing principal curves that capture well complex scatterplot topologies and are robust to noise is hard and/or slow for large scatterplots. We present a fast and robust approach for computing principal graphs (a generalization of principal curves for more complex topologies) inspired by the similarity to medial descriptors (curves locally centered in a shape). Compared to state-of-the-art methods for computing principal graphs, we outperform these in terms of computational scalability and robustness to noise and resolution. We also demonstrate the advantages of our method over other scatterplot summarization approaches.", "keywords": "", "link": "https://doi.org/10.1109/PacificVis.2019.00018", "refList": ["10.1016/j.cag.2014.01.006", "10.1016/s0167-8655(02)00032-6", "10.1006/jmva.2000.1917", "10.1111/cgf.12386", "10.1109/vast.2008.4677367", "10.1109/tpami.2004.1261076", "10.1111/cgf.12865", "10.1109/tvcg.2010.213", "10.1109/tvcg.2014.2346455", "10.1109/tvcg.2011.233", "10.1111/j.1467-8659.2009.01680.x", "10.1109/tvcg.2016.2515611", "10.1109/tit.1982.1056489", "10.1109/34.899944", "10.1007/bf01889678", "10.1137/s0036144599352836", "10.1145/2858036.2858155", "10.1002/jhbs.20078", "10.1198/jcgs.2011.09224", "10.1109/tvcg.2017.2744184", "10.1057/ivs.2010.2", "10.1111/j.1467-8659.2012.03107.x", "10.2307/2289936", "10.1109/pacificvis.2014.42", "10.1109/tpami.2008.21", "10.1111/cgf.13446", "10.2307/2290446", "10.1109/34.982884", "10.1109/tvcg.2006.94", "10.2307/2288711", "10.1117/12.304651", "10.5201/ipol.2013.87", "10.1109/mlsp.2008.4685520"], "wos": 1, "children": [{"doi": "10.1109/pacificvis48177.2020.8199", "year": "2020", "title": "Efficient Morphing of Shape-preserving Star Coordinates", "conferenceName": "PacificVis", "authors": "Vladimir Molchanov;Sagad Hamid;Lars Linsen", "citationCount": "0", "affiliation": "Molchanov, V (Corresponding Author), Westfalische Wilhelms Univ Munster, Munster, Germany.\nMolchanov, Vladimir; Hamid, Sagad; Linsen, Lars, Westfalische Wilhelms Univ Munster, Munster, Germany.", "countries": "Germany", "abstract": "Data tours follow an exploratory multi-dimensional data visualization concept that provides animations of projections of the multidimensional data to a 2D visual space. To create an animation, a sequence of key projections is provided and morphings between each pair of consecutive key projections are computed, which then can be stitched together to form the data tour. The morphings should be smooth so that a user can easily follow the transformations, and their computations shall be fast to allow for their integration into an interactive visual exploration process. Moreover, if the key projections are chosen to satisfy additional conditions, it is desirable that these conditions are maintained during morphing. Shape preservation is such a desirable condition, as it avoids shape distortions that may otherwise be caused by a projection. We develop a novel efficient morphing algorithms for computing shape-preserving data tours, i.e., data tours constructed for a sequence of shape-preserving linear projections. We propose a stepping strategy for the morphing to avoid discontinuities in the evolution of the projections, where we represent the linear projections using a star-coordinates system. Our algorithms are less computationally involved, produce smoother morphings, and require less user-defined parameter settings than existing state-of-the-art approaches.", "keywords": "Human-centered computing; Visualization; Visualization techniques", "link": "https://doi.org/10.1109/PacificVis48177.2020.8199", "refList": ["10.2312/eurovisshort.20141152", "10.1109/tvcg.2013.182", "10.1109/tvcg.2008.153", "10.1109/tvcg.2015.2467591", "10.4135/9781412985130", "10.1111/cgf.12878", "10.1016/j.cag.2016.08.007", "10.1080/10618600.1995.10474674", "10.1109/infvis.2003.1249004", "10.1002/9781118445112.stat06472", "10.1109/visual.1997.663916", "10.1111/cgf.12117", "10.1137/0906011", "10.1109/tvcg.2018.2865118", "10.1126/science.290.5500.2319", "10.1111/cgf.12845", "10.1111/j.1467-8659.2012.03125.x", "10.1109/tvcg.2017.2705189", "10.1002/0471725293", "10.1111/cgf.12876", "10.1111/cgf.13404", "10.2307/2289161", "10.1111/cgf.13446", "10.1198/106186008x318440", "10.2307/1390747", "10.1109/tvcg.2012.35", "10.1109/tvcg.2015.2467132", "10.1109/tvcg.2006.94", "10.1109/t-c.1974.224051", "10.1109/pacificvis.2019.00018", "10.1109/tvcg.2017.2744339", "10.1109/tsmcb.2005.850151"], "wos": 1, "children": [], "len": 1}], "len": 3}, {"doi": "10.1111/cgf.13684", "year": "2019", "title": "ClustMe: A Visual Quality Measure for Ranking Monochrome Scatterplots based on Cluster Patterns", "conferenceName": "EuroVis", "authors": "Mostafa M. Abbas;Micha{\\\"{e}}l Aupetit;Michael Sedlmair;Halima Bensmail", "citationCount": "4", "affiliation": "Abbas, MM (Corresponding Author), HBKU, QCRI, Doha, Qatar.\nAbbas, Mostafa M.; Aupetit, Michael; Bensmail, Halima, HBKU, QCRI, Doha, Qatar.\nSedlmair, Michael, Univ Stuttgart, VISUS, Stuttgart, Germany.", "countries": "Qatar;Germany", "abstract": "We propose ClustMe, a new visual quality measure to rank monochrome scatterplots based on cluster patterns. ClustMe is based on data collected from a human-subjects study, in which 34 participants judged synthetically generated cluster patterns in 1000 scatterplots. We generated these patterns by carefully varying the free parameters of a simple Gaussian Mixture Model with two components, and asked the participants to count the number of clusters they could see (1 or more than 1). Based on the results, we form ClustMe by selecting the model that best predicts these human judgments among 7 different state-of-the-art merging techniques (Demp). To quantitatively evaluate ClustMe, we conducted a second study, in which 31 human subjects ranked 435 pairs of scatterplots of real and synthetic data in terms of cluster patterns complexity. We use this data to compare ClustMe's performance to 4 other state-of-the-art clustering measures, including the well-known Clumpiness scagnostics. We found that of all measures, ClustMe is in strongest agreement with the human rankings.", "keywords": "", "link": "https://doi.org/10.1111/cgf.13684", "refList": ["10.1109/tvcg.2014.2330617", "10.1109/tvcg.2014.2346979", "10.1109/tvcg.2017.2744138", "10.1109/tvcg.2017.2701829", "10.2307/2529310", "10.1109/tvcg.2011.229", "10.1109/vast.2011.6102437", "10.1068/p030033", "10.1016/j.jvcir.2011.01.005", "10.1109/tnn.2005.845141", "10.1145/2669557.2669559", "10.1167/8.7.6", "10.1145/2993901.2993907", "10.1145/2803140.2803143", "10.1145/1842993.1843002", "10.1109/pacificvis.2016.7465244", "10.1109/tvcg.2013.124", "10.1057/ivs.2008.13", "10.1109/vast.2012.6400488", "10.1111/j.1467-9574.2008.00412.x", "10.1214/aos/1176344136", "10.1109/tvcg.2015.2467671", "10.3138/y308-2422-8615-1233", "10.1111/j.1467-8659.2012.03125.x", "10.1177/001316446002000104", "10.1145/2858036.2858155", "10.1007/s11634-010-0058-3", "10.1214/009053605000000417", "10.1109/tvcg.2009.153", "10.1023/a:1018510926151", "10.1109/tvcg.2014.2346978", "10.1007/s10816-016-9307-x", "10.1177/0301006615602599", "10.1109/pacificvis.2014.42", "10.1162/neco.1991.3.2.246", "10.1007/3-540-44491-2\\_3", "10.1109/tvcg.2013.153", "10.1111/cgf.13446", "10.1109/tvcg.2018.2846735", "10.2307/2291604", "10.1109/inf0vis.2005.14", "10.1198/016214502760047131", "10.1007/s00180-008-0119-7", "10.1109/t-c.1974.224051", "10.1111/cgf.12632", "10.1109/tvcg.2017.2744339", "10.1111/j.1467-8659.2009.01694.x"], "wos": 1, "children": [{"doi": "10.1109/tvcg.2019.2934796", "title": "Improving the Robustness of Scagnostics", "year": "2019", "conferenceName": "InfoVis", "authors": "Yunhai Wang;Zeyu Wang 0005;Tingting Liu;Michael Correll;Zhanglin Cheng;Oliver Deussen;Michael Sedlmair", "citationCount": "1", "affiliation": "Wang, YH (Corresponding Author), Shandong Univ, Jinan, Peoples R China. Wang, Yunhai; Wang, Zeyu; Liu, Tingting, Shandong Univ, Jinan, Peoples R China. Wang, Zeyu; Cheng, Zhanglin; Deussen, Oliver, SIAT, Shenzhen VisuCA Key Lab, Shenzhen, Peoples R China. Correll, Michael, Tableau Res, Seattle, WA USA. Deussen, Oliver, Konstanz Univ, Constance, Germany. Sedlmair, Michael, Univ Stuttgart, VISUS, Stuttgart, Germany.", "countries": "USA;Germany;China", "abstract": "In this paper, we examine the robustness of scagnostics through a series of theoretical and empirical studies. First, we investigate the sensitivity of scagnostics by employing perturbing operations on more than 60M synthetic and real-world scatterplots. We found that two scagnostic measures, Outlying and Clumpy, are overly sensitive to data binning. To understand how these measures align with human judgments of visual features, we conducted a study with 24 participants, which reveals that i) humans are not sensitive to small perturbations of the data that cause large changes in both measures, and ii) the perception of clumpiness heavily depends on per-cluster topologies and structures. Motivated by these results, we propose Robust Scagnostics (RScag) by combining adaptive binning with a hierarchy-based form of scagnostics. An analysis shows that RScag improves on the robustness of original scagnostics, aligns better with human judgments, and is equally fast as the traditional scagnostic measures.", "keywords": "Scagnostics,scatterplots,sensitivity analysis,Robust Scagnostics", "link": "http://dx.doi.org/10.1109/TVCG.2019.2934796", "refList": ["10.1057/palgrave.ivs.9500122", "10.1109/tvcg.2014.2346979", "10.1111/j.1467-8659.2009.01467.x", "10.1109/vast.2008.4677368", "10.2307/2289444", "10.1109/tvcg.2011.229", "10.1109/iv.2004.1320207", "10.1109/vast.2009.5332628", "10.1111/insr.12095\\_11", "10.1109/tvcg.2010.184", "10.1109/tvcg.2015.2467323", "10.1109/vast.2010.5652460", "10.1111/j.1467-8659.2012.03069.x", "10.1145/1842993.1843002", "10.1198/106186008x320465", "10.1109/pacificvis.2016.7465244", "10.1109/tvcg.2013.20", "10.1111/cgf.12641", "10.1109/tvcg.2012.128", "10.1109/tvcg.2015.2467671", "10.1057/palgrave.ivs.9500091", "10.1007/978-1-4612-4400-4", "10.1111/cgf.13176", "10.1002/0470870958", "10.1109/tvcg.2018.2864907", "10.1111/j.1467-8659.2012.03125.x", "10.1109/vast.2012.6400490", "10.1109/infvis.2005.1532142", "10.1109/vast.2010.5652433", "10.1109/vast.2009.5332611", "10.1201/9781315140919", "10.1145/2858036.2858155", "10.1109/ldav.2013.6675164", "10.1515/itit-2014-1070", "10.1111/cgf.13684", "10.1109/tpami.1979.4766909", "10.2307/2289936", "10.1109/pacificvis.2014.42", "10.1109/tvcg.2016.2598467", "10.1109/tvcg.2013.153", "10.1111/cgf.13446", "10.1109/tvcg.2006.94", "10.1109/tvcg.2014.2346572", "10.1111/cgf.12632", "10.1109/tvcg.2017.2744339"], "wos": 1, "children": [], "len": 1}, {"doi": "10.1109/tvcg.2020.3030365", "title": "Modeling the Influence of Visual Density on Cluster Perception in Scatterplots Using Topology", "year": "2020", "conferenceName": "InfoVis", "authors": "Ghulam Jilani Quadri;Paul Rosen", "citationCount": "0", "affiliation": "Quadri, GJ (Corresponding Author), Univ S Florida, Tampa, FL 33620 USA. Quadri, Ghulam Jilani; Rosen, Paul, Univ S Florida, Tampa, FL 33620 USA.", "countries": "USA", "abstract": "Scatterplots are used for a variety of visual analytics tasks, including cluster identification, and the visual encodings used on a scatterplot play a deciding role on the level of visual separation of clusters. For visualization designers, optimizing the visual encodings is crucial to maximizing the clarity of data. This requires accurately modeling human perception of cluster separation, which remains challenging. We present a multi-stage user study focusing on four factors-distribution size of clusters, number of points, size of points, and opacity of points-that influence cluster identification in scatterplots. From these parameters, we have constructed two models, a distance-based model, and a density-based model, using the merge tree data structure from Topological Data Analysis. Our analysis demonstrates that these factors play an important role in the number of clusters perceived, and it verifies that the distance-based and density-based models can reasonably estimate the number of clusters a user observes. Finally, we demonstrate how these models can be used to optimize visual encodings on real-world data.", "keywords": "Scatterplot,clustering,perception,empirical evaluation,visual encoding,crowdsourcing,topological data analysis", "link": "http://dx.doi.org/10.1109/TVCG.2020.3030365", "refList": ["10.1109/tvcg.2017.2744359", "10.1145/1778765", "10.1109/tvcg.2019.2934799", "10.1111/cgf.12889", "10.1109/tvcg.2011.127", "10.1111/cgf.13444", "10.1145/1964897.1964910", "10.1167/8.7.6", "10.1145/3173574.3173991", "10.1145/1556262.1556289", "10.1145/1056808.1056914", "10.2307/2288400", "10.1109/tvcg.2014.2346594", "10.1109/iv.2002.1028760", "10.1177/001316447303300111", "10.1007/bf02289823", "10.1109/tvcg.2017.2744339", "10.1111/j.1467-8659.2009.01694.x", "10.1109/tvcg.2014.2346979", "10.1090/mbk/069", "10.1109/tvcg.2013.65", "10.1109/mcg.2012.37", "10.1109/pacificvis.2010.5429604", "10.1002/acp.2350050106", "10.1109/infvis.2005.1532136", "10.1177/1473871612465214", "10.1109/tvcg.2017.2674978", "10.1002/jhbs.20078", "10.1007/978-3-642-35142-6\\_14", "10.1007/978-3-319-71507-0", "10.1109/mcg.201.7.6", "10.3758/bf03193961", "10.1364/josa.49.000280", "10.1145/3025453.3025905", "10.1109/tvcg.201.9.2934541", "10.1109/tvcg.2018.2829750", "10.1177/1473871615606187", "10.1111/cgf.13408", "10.1109/pacificvis.2016.7465252", "10.1109/pacificvis.2016.7465244", "10.1109/inevis.2005.1532142", "10.1111/cgf.13414", "10.1111/j.1467-8659.2012.03125.x", "10.1167/16.5.11", "10.1109/infvis.2005.1532142", "10.1145/2858036.2858155", "10.1038/nmeth1210-941", "10.1177/1473871616638892", "10.1109/tcbb.2014.2306840", "10.1111/cgf.13684", "10.1177/0301006615602599", "10.1214/aoms/1177731915", "10.1145/2702123.2702585", "10.1109/tvcg.2013.183", "10.1109/tvcg.2014.2346572", "10.1109/tvcg.2018.2875702", "10.1109/tvcg.2017.2754480", "10.1109/vast.2014.7042493", "10.1057/palgrave.ivs.9500122", "10.1109/tvcg.2014.2330617", "10.1109/tvcg.2019.2934541", "10.1068/p030033", "10.1140/epjds/s13688-017-0109-5", "10.1201/b17511", "10.1016/s0925-7721(02)00093-7", "10.1109/pacificvis.2012.6183557", "10.1109/tvcg.2014.2346983", "10.1109/5.726791", "10.1080/01621459.1926.10502165", "10.1109/tvcg.2007.70535", "10.1109/tvcg.2018.2864907", "10.1111/cgf.12109", "10.1109/tvcg.2017.2744184", "10.1146/annurev-statistics-031017-100045", "10.1111/cgf.13409", "10.1145/3002151.3002162", "10.1016/s0378-4371(98)00494-4", "10.3138/y308-2422-8615-1233", "10.1111/cgf.12632", "10.1145/3290605.3300771"], "wos": 1, "children": [], "len": 1}, {"doi": "10.1111/cgf.14034", "year": "2020", "title": "The State of the Art in Enhancing Trust in Machine Learning Models with the Use of Visualizations", "conferenceName": "EuroVis", "authors": "Angelos Chatzimparmpas;Rafael Messias Martins;Ilir Jusufi;Kostiantyn Kucher;Fabrice Rossi;Andreas Kerren", "citationCount": "2", "affiliation": "Chatzimparmpas, A (Corresponding Author), Linnaeus Univ, Dept Comp Sci \\& Media Technol, Vaxjo, Sweden.\nChatzimparmpas, A.; Martins, R. M.; Jusufi, I.; Kucher, K.; Kerren, A., Linnaeus Univ, Dept Comp Sci \\& Media Technol, Vaxjo, Sweden.\nRossi, F., PSL Univ, Univ Paris Dauphine, Ceremade, Paris, France.", "countries": "Sweden;France", "abstract": "Machine learning (ML) models are nowadays used in complex applications in various domains, such as medicine, bioinformatics, and other sciences. Due to their black box nature, however, it may sometimes be hard to understand and trust the results they provide. This has increased the demand for reliable visualization tools related to enhancing trust in ML models, which has become a prominent topic of research in the visualization community over the past decades. To provide an overview and present the frontiers of current research on the topic, we present a State-of-the-Art Report (STAR) on enhancing trust in ML models with the use of interactive visualization. We define and describe the background of the topic, introduce a categorization for visualization techniques that aim to accomplish this goal, and discuss insights and opportunities for future research directions. Among our contributions is a categorization of trust against different facets of interactive ML, expanded and improved from previous research. Our results are investigated from different analytical perspectives: (a) providing a statistical overview, (b) summarizing key findings, (c) performing topic analyses, and (d) exploring the data sets used in the individual papers, all with the support of an interactive web-based survey browser. We intend this survey to be beneficial for visualization researchers whose interests involve making ML models more trustworthy, as well as researchers and practitioners from other disciplines in their search for effective visualization techniques suitable for solving their tasks with confidence and conveying meaning to their data.", "keywords": "trustworthy machine learning; visualization; interpretable machine learning; explainable machine learning", "link": "https://doi.org/10.1111/cgf.14034", "refList": ["10.1109/mcg.2018.2878902", "10.1109/tvcg.2008.153", "10.2312/mlvis.20181130", "10.1109/tvcg.2016.2598828", "10.1145/3290605.3300911", "10.1145/2993901.2993909", "10.2312/mlvis.20191158", "10.1109/tvcg.2016.2598446", "10.1111/j.1467-8659.2009.01475.x", "10.1145/3290605.3300809", "10.1109/pacificvis.2018.00031", "10.1055/s-0029-1216348", "10.1007/978-3-319-90403-0\\_13", "10.1109/tvcg.2017.2745085", "10.1111/j.1467-8659.2011.01938.x", "10.1007/978-3-319-54024-5\\_6", "10.1016/s0167-9473(01)00065-2", "10.1111/cgf.12895", "10.2312/eurovisshort.20141152.17", "10.2312/eurova.20151098.22", "10.1111/cgf.13667", "10.3115/1072228.1072378", "10.1109/tbdata.2018.2877350.16", "10.1109/lars.2009.5418323.25", "10.1109/tvcg.2017.2744878", "10.1016/j.combustflame.2005.09.018", "10.1016/j.cag.2014.01.006", "10.1109/tvcg.2016.2570755", "10.2312/mlvis.20191158.1,19", "10.1518/hfes.46.1.50.30392", "10.1145/3301275.3302280", "10.1145/3351095.3372834.1", "10.1016/s0377-2217(01)00264-8", "10.1111/cgf.13424", "10.1007/978-3-319-23485-4\\_53", "10.1007/978-94-007-0753-5\\_3623", "10.1109/tvcg.2013.101", "10.1111/cgf.12884", "10.1111/j.1467-8659.2010.01835.x", "10.1021/ci9901338", "10.4230/lipics.itcs:2017", "10.1109/mis.2013.24", "10.1109/tvcg.2014.2346482", "10.1109/tvcg.2018.2865230", "10.1073/pnas.1807180116", "10.1109/dsaa.2018.00018", "10.1109/tvcg.2009.153", "10.3115/1219840.1219855", "10.1109/tvcg.2018.2864812", "10.1109/tvcg.2018.2872577", "10.2312/trvis.20191183", "10.1109/cvpr:2004.383", "10.1109/vast.2008.4677350", "10.1145/302979.303001", "10.1109/tvcg.2018.2864499", "10.1111/cgf.13672", "10.1109/tvcg.2014.2346626", "10.23915/distill.00010.18", "10.1109/tvcg.2017.2744805", "10.2312/mlvis:20191160.18", "10.23915/distill:00016", "10.1109/pacificvis.2016.7465260", "10.1111/cgf.13683", "10.23915/distill.00016.19", "10.1145/32906053.300803.22", "10.1109/tvcg.2014.2346574", "10.1177/1473871615600010", "10.1109/tvcg.2016.2598831", "10.1145/3230623", "10.1109/visual.2019.8933744", "10.1145/2993901.2993915", "10.1016/j.visinf.2017.01.006", "10.1145/2993901.2993914", "10.1109/tvcg.2014.2346984", "10.1109/5.726791", "10.23915/distill.00010", "10.1109/tvcg.2018.2864825", "10.2307/2394164", "10.1109/tvcg.2017.2744458", "10.1145/2993901.2993917.28", "10.1111/cgf.13711", "10.1109/tvcg.2016.2598664", "10.2307/2530428", "10.1109/icdar.1997.620583", "10.1109/tvcg.2017.2744718", "10.1111/cgf.13425", "10.1109/tvcg.2019.2903943", "10.1145/1518701.1518895", "10.1109/tvcg.2018.2864838", "10.1145/62038.62043", "10.1111/j.1467-8659.2011.01920.x", "10.1145/3025171.3025208", "10.1145/355112.355124", "10.1109/vast.2010.5652398", "10.1109/tvcg.2014.2346578", "10.1145/3173574.3174209", "10.4178/epih/e2014008", "10.1109/beliv.2018.8634201.25,28", "10.1016/j.eswa.2007.12.020", "10.1111/cgf:13406", "10.1109/mcg.2011.103", "10.1631/fitee.1700808", "10.1109/tvcg.2017.2745158", "10.1073/pnas.0307752101", "10.1109/tvcg.2018.2816223", "10.1109/tvcg.2017.2745141", "10.1145/32232.32234", "10.1109/tvcg.2019.2934267", "10.1109/tvcg.2018.2864477", "10.1145/3132169", "10.2312/eurova.20151100.19", "10.1145/3172944.3172964", "10.1145/2601248.2601268", "10.1109/isai-nlp.2018.8693002.1", "10.1111/cgf.13404", "10.1007/s100320200071", "10.2312/trvis.20191183.16", "10.1111/cgf.12755", "10.1145/2702123.2702509", "10.1145/1401890.1402008.25", "10.1109/tvcg.2012.65", "10.1177/1473871617733996", "10.2312/trvis.20191187.7", "10.21236/ada273556", "10.1109/vast.2010.5652450", "10.1111/j.1467-8659.2011.01940.x", "10.1177/875647939000600106", "10.1109/tvcg.2017.2711030", "10.1016/j.immuni.2016.04.014", "10.1109/tvcg.2019.2934209", "10.1016/0095-0696(78)90006-2", "10.1016/j.jclinepi.2015.04.014", "10.1016/j.ress.2013.02.013", "10.1111/cgf.12640", "10.1145/1015330.1015388.25", "10.1111/j.1467-8659.2009.01468.x", "10.1145/1541880.1541882", "10.1109/vast.2011.6102453", "10.1016/s0008-8846(98)00165-3", "10.2312/trvis.20191186.7", "10.1007/s13748-013-0040-3", "10.1109/tvcg.2015.2467757", "10.1109/tbdata.2018.2877350", "10.1109/vast.2017.8585613", "10.1080/10556789208805504", "10.1109/vast.2012.6400484", "10.1145/3025171.3025181", "10.1007/978-3-319-90403-0\\_12", "10.1109/mcg.2019.2922592", "10.1021/ci000392t", "10.1109/vast.2007.4389000", "10.1111/cgf.13406.16", "10.1111/cgf.13684", "10.2312/eurovisshort.20161166.17", "10.2312/evs:20191168", "10.1145/3041021.3055135", "10.1145/3301275.3302265", "10.1613/jair.4135", "10.1109/tvcg.2018.2864500", "10.1109/tvcg.2017.2744158", "10.1109/ssci.2015.33", "10.1111/cgf.13453", "10.2312/pe/eurovast/eurova11/049-052", "10.1145/3025171.3025181.13", "10.1145/371920.372094", "10.1109/tvcg.2017.2744938", "10.1111/j.1467-8659.2012.03108.x", "10.1109/tvcg.2019.2934251", "10.1145/3290605.3300809.18", "10.1109/ldav.2016.7874305", "10.1109/vast.2016.7883514", "10.1109/iccv.2015.425", "10.1145/3301275.3302324", "10.1109/tnnls.2013.2292894", "10.1109/tvcg.2018.2865044", "10.1109/tvcg.2013.157", "10.1371/journal.pcbi.0020161", "10.1186/s12916-019-1426-2", "10.1109/10.867928", "10.1111/cgf.13217", "10.1109/mcg.2019.2919033", "10.1145/2993901.2993910", "10.1109/tvcg.2017.2744738", "10.2307/258792", "10.1111/cgf.12655", "10.1016/j.dss.2014.03.001", "10.1109/tvcg.2019.2904069", "10.1111/cgf.13205", "10.1002/mds.22340", "10.1109/tvcg.2019.2934595", "10.1287/inte.2018.0957", "10.1109/cvpr.2007.382974", "10.1109/tvcg.2012.280", "10.1145/2678025.2701399.13", "10.2312/mlvis.20181130.13", "10.2312/eurova.20181106.16", "10.1109/tvcg.2018.2864475", "10.2312/mlvis.20191160.18,22", "10.1007/978-1-4612-4026-6.25", "10.1109/cvpr.2006.42", "10.1145/3172944.3172950", "10.1109/cvpr.2004.383.25", "10.1109/tvcg.2019.2934812", "10.1609/aimag.v35i4.2513", "10.2312/trvis.20191185.7", "10.1111/j.1467-8659.2009.01684.x", "10.1371/journal.pone.0129126", "10.1111/cgf.13092", "10.1162/coli\\_a\\_00237", "10.1109/tvcg.2017.2744818", "10.1109/vast.2011.6102448", "10.1109/tvcg.2009.111", "10.1109/tvcg.2019.2934619", "10.1016/s0377-2217(01)00264-8.25", "10.1111/cgf.12639", "10.1109/access.2019.2919343", "10.1186/s12874-019-0681-4", "10.1109/pacificvis.2015.7156366", "10.1109/pacificvis.2018.00029", "10.1109/tvcg.2019.2934261", "10.1080/13506280444000102.http://www.uvt.nl/ticc", "10.1109/vast.2018.8802509", "10.1111/cgf.13212", "10.1145/3200489", "10.1111/cgf.13176", "10.1177/1473871620904671", "10.1007/978-3-319-10590-1\\_53", "10.1111/j.1467-8659.2012.03126.x", "10.1111/cgf.13172", "10.1145/3025171.3025208.6,21", "10.1111/cgf.12366", "10.1109/tvcg.2019.2934659", "10.1109/cvprw.2009.5206848", "10.1016/j.media.2014.11.010", "10.1109/tvcg.2017.2744683", "10.1109/tvcg.2019.2934262", "10.1016/j.neucom.2006.11.018", "10.1177/1473871615571951", "10.1371/journal.pcbi.0020161.25", "10.1177/1473871611415994", "10.2312/trvis20191187", "10.2312/eurova", "10.1145/2858036.2858529", "10.1145/2207676.2207738", "10.1007/s11042-009-0417-2", "10.1145/3301275.3302317", "10.1038/s41746-019-0148-3", "10.1145/3351095.3372834", "10.1080/10691898.2011.11889627", "10.1109/tvcg.2018.2864504", "10.1109/vast.2017.8585720", "10.1109/mcg.2018.053491732", "10.1007/s10994-010-5207-6", "10.1109/tvcg.2019.2934433", "10.1016/j.cag.2017.05.005", "10.1109/tvcg.2012.279", "10.1145/3231622.3231641.19,20", "10.1145/1562849.1562851", "10.1007/11564126\\_", "10.1109/tvcg.2018.2846735", "10.3115/1225403.1225421", "10.1109/vast.2012.6400486", "10.2312/eurova.20191116.22", "10.1109/tvcg.2007.70443", "10.1080/027868291009242", "10.2312/eurova.20151100", "10.1145/2939502.2939503.19", "10.1016/j.cag.2014.02.004", "10.1145/2939672.2939778", "10.1109/vast.2010.5652484", "10.1111/cgf.12641", "10.1145/3301275.3302289", "10.1109/visual.2019.8933619", "10.1109/tvcg.2017.2672987", "10.1109/vast.2016.7883517.20", "10.1109/igarss.2017.8127684", "10.1016/j.jcae.2010.04.002", "10.1109/vast.2010.5652885", "10.1016/j.visinf.2019.03.002", "10.1007/s00371-018-1500-3", "10.1109/mcg.2018.042731661", "10.1109/34.598228", "10.1109/tvcg.2018.2865027", "10.1016/j.neucom.2017.01.105", "10.1111/cgf.12389", "10.1109/tvcg.2019.2934591", "10.1109/vast.2010.5652392.16", "10.1111/cgf.13416", "10.1080/02701367.1992.10608764", "10.1109/vast.2017.8585721", "10.1109/tvcg.2018.2843369", "10.1109/sbes.2010.27", "10.1109/vast.2015.7347637", "10.1145/1401890.1402008", "10.1016/j.bpj.2010.04.064", "10.1109/tvcg.2013.125", "10.1109/isai-nlp.2018.8693002", "10.1371/journal.pone.0160127", "10.1145/2856767.2856779", "10.1145/2678025.2701399", "10.1109/vast.2011.6102451", "10.1109/mcg.2010.18", "10.1021/ci4000213", "10.1109/vast.2012.6400492", "10.1007/11564126-49.25", "10.2312/eurova.20171114", "10.1109/vast.2010.5652443", "10.1145/3134599", "10.2312/pe/eurovast/eurovast10/013-018.19", "10.1109/tvcg.2019.2903946", "10.1109/tvcg.2015.2467717", "10.1177/1473871612460526", "10.1016/j.cag.2018.09.018", "10.1109/tvcg.2016.2598838", "10.1145/3172944.3172964.14", "10.1109/vast.2009.5333428", "10.1109/vast.2014.7042480", "10.2312/pe/eurovast/eurovast10/013-018", "10.1177/0962280215588241", "10.1145/2993901.2993917", "10.1109/cvpr.2008:4587581", "10.1109/tvcg.2015.2467551", "10.1016/j.visinf.2018.09.001", "10.1126/science.290.5500.2319", "10.2312/eurova.20151107", "10.1109/visual.2019.8933695", "10.13140/2.1.2393.1847", "10.1197/jamia.m1929", "10.1109/cvpr.2008.4587581.25", "10.1145/1518701.1518895.16", "10.1109/vds.2017.8573444", "10.2312/trvis:20191185", "10.1145/3359786", "10.13140/2.1.1341.1520", "10.2312/pe/eurovast/eurova11/049-052.17", "10.1109/tvcg.2014.2346660", "10.1145/3185517", "10.1109/adprl.2011.5967372", "10.1109/tvcg.2015.2467591", "10.1111/j.1751-9004.2009.00232.x", "10.1136/qshc.2004.010033", "10.1109/vast.2012.6400493", "10.1109/tvcg.2019.2934266", "10.1145/2971763.2971775", "10.1111/cgf.13730", "10.1109/vast.2012.6400488", "10.1111/cgf.13210", "10.1109/tvcg.2019.2934631", "10.1145/3172944.3172965", "10.1057/ivs.2010.2", "10.1109/tvcg.2017.2745258", "10.1016/j.jbusres.2019.07.039", "10.1162/jmlr.2003.3.4-5.993", "10.1109/pacificvis.2019.00044", "10.2312/pe/eurovast/eurova12/037-041", "10.1109/tvcg.2019.2934629", "10.1177/0018720814547570", "10.1145/3292500.3330908", "10.1111/j.1467-8659.2009.01467.x", "10.2312/eurova.20151098", "10.1177/1473871617713337", "10.1109/lars:2009.5418323", "10.1109/vast.2011.6102437", "10.1111/cgf.12878", "10.1561/1500000001", "10.1145/3025171.3025222", "10.1007/s11704-016-6028-y", "10.1016/j.procs.2017.05.216", "10.1109/cvpr.2007.382974.25", "10.1080/10447318.2020.1741118", "10.1109/vast.2012.6400489", "10.1145/3025171.3025172", "10.1109/tvcg.2017.2744098", "10.1109/tvcg.2005.66", "10.1016/j.dss.2009.05.016", "10.1007/978-1-4612-4026-6", "10.2312/evs.20191168.16,20,28", "10.2312/pe/eurovast/eurova12/037-041.17", "10.1145/3290605.3300803", "10.1145/1015330.1015388", "10.1111/cgf.13197", "10.1016/b978-1-55860-377-6.50048-7", "10.1111/cgf.13681", "10.1109/tvcg.2017.2744378", "10.1109/tvcg.2017.2744358", "10.1109/vast.2008.4677352"], "wos": 1, "children": [{"doi": "10.1109/tvcg.2020.3030368", "title": "Implicit Multidimensional Projection of Local Subspaces", "year": "2020", "conferenceName": "InfoVis", "authors": "Rongzheng Bian;Yumeng Xue;Liang Zhou;Jian Zhang 0070;Baoquan Chen;Daniel Weiskopf;Yunhai Wang", "citationCount": "1", "affiliation": "Wang, YH (Corresponding Author), Shandong Univ, Qingdao, Peoples R China. Zhou, L (Corresponding Author), Univ Utah, Salt Lake City, UT 84112 USA. Bian, Rongzheng; Xue, Yumeng; Wang, Yunhai, Shandong Univ, Qingdao, Peoples R China. Chen, Baoquan, Peking Univ, Beijing, Peoples R China. Zhang, Jian, Chinese Acad Sci, CNIC, Beijing, Peoples R China. Zhou, Liang, Univ Utah, Salt Lake City, UT 84112 USA. Weiskopf, Daniel, Univ Stuttgart, Stuttgart, Germany.", "countries": "USA;Germany;China", "abstract": "We propose a visualization method to understand the effect of multidimensional projection on local subspaces, using implicit function differentiation. Here, we understand the local subspace as the multidimensional local neighborhood of data points. Existing methods focus on the projection of multidimensional data points, and the neighborhood information is ignored. Our method is able to analyze the shape and directional information of the local subspace to gain more insights into the global structure of the data through the perception of local structures. Local subspaces are fitted by multidimensional ellipses that are spanned by basis vectors. An accurate and efficient vector transformation method is proposed based on analytical differentiation of multidimensional projections formulated as implicit functions. The results are visualized as glyphs and analyzed using a full set of specifically-designed interactions supported in our efficient web-based visualization tool. The usefulness of our method is demonstrated using various multi- and high-dimensional benchmark datasets. Our implicit differentiation vector transformation is evaluated through numerical comparisons; the overall method is evaluated through exploration examples and use cases.", "keywords": "High-dimensional data visualization,dimensionality reduction,local linear subspaces,user interaction", "link": "http://dx.doi.org/10.1109/TVCG.2020.3030368", "refList": ["10.3844/jcssp.2018.613.622", "10.1016/j.aci.2018.08.003", "10.3390/info9030065", "10.1016/j.visinf.2018.09.003", "10.1371/journal.pone.0118432", "10.1016/s0893-6080(05)80023-1", "10.1109/tvcg.2020.2986996", "10.1109/icst.2012.56", "10.1007/s10844-013-0250-y", "10.1109/tbdata.2018", "10.1145/1125451.1125659", "10.1109/tvcg.2013.125", "10.1177/1473871611412817", "10.1145/3290605.3300911", "10.1111/cgf.14034", "10.1007/s13721-013-0034-x", "10.1016/j.procs.2017.05.216", "10.1016/j.ins.2009.08.025", "10.1109/tvcg.2013.124", "10.1109/tvcg.2018.2864499", "10.1109/tvcg.2018.2864475", "10.1080/10447318.2020.1741118", "10.1016/j.imu.2019.100203", "10.1109/tvcg.2018.2865240", "10.1186/s12864-019-6413-7", "10.1109/tvcg.2015.2467551", "10.1002/widm.1249", "10.1007/978-3-319-66429-3\\_29", "10.1109/tvcg.2014.2346481", "10.1109/tvcg.2018.2864825", "10.1177/1473871620904671", "10.1109/tvcg.2019.2934267", "10.1136/bmjopen-2016-012799", "10.1109/smartgridcomm.2017.8340682", "10.1007/s10664-015-9401-9", "10.1145/1143844.1143874", "10.1111/cgf.12389", "10.1109/tvcg.2018.2872577", "10.1007/978-981-13-5802-9\\_20", "10.1016/j.ipm.2009.03.002", "10.5220/0006431602160222", "10.1109/mcg.2015.50", "10.1109/tvcg.2014.2346574", "10.1007/bf02289565", "10.1109/tvcg.2017.2744378", "10.1016/j.patrec.2008.08.010", "10.1023/a:1010933404324", "10.9735/2229-3981"], "wos": 1, "children": [], "len": 1}, {"doi": "10.1109/tvcg.2020.3030465", "title": "Visual Causality Analysis of Event Sequence Data", "year": "2020", "conferenceName": "VAST", "authors": "Zhuochen Jin;Shunan Guo;Nan Chen;Daniel Weiskopf;David Gotz;Nan Cao", "citationCount": "0", "affiliation": "Cao, N (Corresponding Author), Tongji Univ, IDVx Lab, Shanghai, Peoples R China. Jin, Zhuochen; Guo, Shunan; Chen, Nan; Cao, Nan, Tongji Univ, IDVx Lab, Shanghai, Peoples R China. Weiskopf, Daniel, Univ Stuttgart, Stuttgart, Germany. Gotz, David, Univ N Carolina, Chapel Hill, NC 27515 USA.", "countries": "USA;Germany;China", "abstract": "Causality is crucial to understanding the mechanisms behind complex systems and making decisions that lead to intended outcomes. Event sequence data is widely collected from many real-world processes, such as electronic health records, web clickstreams, and financial transactions, which transmit a great deal of information reflecting the causal relations among event types. Unfortunately, recovering causalities from observational event sequences is challenging, as the heterogeneous and high-dimensional event variables are often connected to rather complex underlying event excitation mechanisms that are hard to infer from limited observations. Many existing automated causal analysis techniques suffer from poor explainability and fail to include an adequate amount of human knowledge. In this paper, we introduce a visual analytics method for recovering causalities in event sequence data. We extend the Granger causality analysis algorithm on Hawkes processes to incorporate user feedback into causal model refinement. The visualization system includes an interactive causal analysis framework that supports bottom-up causal exploration, iterative causal verification and refinement, and causal comparison through a set of novel visualizations and interactions. We report two forms of evaluation: a quantitative evaluation of the model improvements resulting from the user-feedback mechanism, and a qualitative evaluation through case studies in different application domains to demonstrate the usefulness of the system.", "keywords": "Event sequence data,causality analysis,visual analytics", "link": "http://dx.doi.org/10.1109/TVCG.2020.3030465", "refList": ["10.5555/1642718", "10.1109/tvcg.2018.2865022", "10.5555/2074094.2074151", "10.1109/tvcg.2016.2618797", "10.1073/pnas.1320645111", "10.1109/tvcg.2017.2744843", "10.1109/iv.2017.69", "10.1109/tvcg.2019.2934399", "10.1145/3172944.3173007", "10.5555/1795555", "10.1109/mcg.2005.102", "10.1145/381641.381653", "10.1162/153244301753344614", "10.1111/cgf.14034", "10.1111/cgf.13198", "10.1017/cbo9780511519857", "10.1007/s10462-016-9475-9", "10.1075/ssol.2.2.07bor", "10.1007/978-1-4614-3223-4\\_3", "10.1109/infvis.2003.1249025", "10.1007/978-94-007-6094-313", "10.1145/2858036.2858387", "10.1109/tvcg.2007.70528", "10.1109/tvcg.2017.2674958", "10.1147/sj.454.0801", "10.1109/tvcg.2013.119", "10.1145/3173574.3173711", "10.1016/j.erss.2017.06.034", "10.1109/visual.2019.8933695", "10.1007/s11665-016-2173-6", "10.1016/0377-0427(87)90125-7", "10.2307/3601125", "10.1016/b978-0-444-88738-2.50018-x", "10.1109/mcg.2006.70", "10.1109/tvcg.2018.2865145", "10.1017/s1351324997001502", "10.1109/tvcg.2010.179", "10.1214/aos/1176344552", "10.1109/mcg.2009.22", "10.1007/978-3-319-26633-6\\_13", "10.1080/10447318.2014.905422", "10.1016/j.visinf.2019.03.004", "10.1057/palgrave.ivs.9500074", "10.1007/978-1-4614-3223-4"], "wos": 1, "children": [], "len": 1}], "len": 5}, {"doi": "10.1111/cgf.14001", "year": "2020", "title": "Sunspot Plots: Model-based Structure Enhancement for Dense Scatter Plots", "conferenceName": "EuroVis", "authors": "Thomas Trautner;Fabian Bolte;Sergej Stoppel;Stefan Bruckner", "citationCount": "0", "affiliation": "Trautner, T (Corresponding Author), Univ Bergen, Bergen, Norway.\nTrautner, T.; Bolte, F.; Stoppel, S.; Bruckner, S., Univ Bergen, Bergen, Norway.", "countries": "Norway", "abstract": "Scatter plots are a powerful and well-established technique for visualizing the relationships between two variables as a collection of discrete points. However, especially when dealing with large and dense data, scatter plots often exhibit problems such as overplotting, making the data interpretation arduous. Density plots are able to overcome these limitations in highly populated regions, but fail to provide accurate information of individual data points. This is particularly problematic in sparse regions where the density estimate may not provide a good representation of the underlying data. In this paper, we present sunspot plots, a visualization technique that communicates dense data as a continuous data distribution, while preserving the discrete nature of data samples in sparsely populated areas. We furthermore demonstrate the advantages of our approach on typical failure cases of scatter plots within synthetic and real-world data sets and validate its effectiveness in a user study.", "keywords": "", "link": "https://doi.org/10.1111/cgf.14001", "refList": ["10.1057/palgrave.ivs.9500122", "10.2312/eggh/hpg12/097-103", "10.1109/tvcg.2008.119", "10.1109/pacificvis.2011.5742387", "10.1038/331163a0", "10.1109/visual.2019.8933620", "10.2307/2683294", "10.1201/9781351072304", "10.2307/2289444", "10.1109/tvcg.2019.2934541", "10.1080/00949657508810123", "10.1109/tvcg.2013.65", "10.1109/infvis.1997.636789", "10.1109/2945.841121", "10.1109/mcse.2007.55", "10.1109/tvcg.2010.197", "10.1111/cgf.12871", "10.1109/infvis.2003.1249018", "10.1145/3173574.3173991", "10.1109/tvcg.2012.238", "10.1007/0-387-28695-0", "10.1109/pacificvis.2010.5429604", "10.18637/jss.v008.i03", "10.1109/tvcg.2007.70596", "10.1109/visual.1998.745301", "10.1007/0-387-37977-0\\_3", "10.1145/1556262.1556289", "10.2312/wiced.20161094", "10.1109/tvcg.2007.70535", "10.1145/1056808.1056914", "10.1109/tvcg.2003.1196007", "10.1109/iv.2004.1320190", "10.1111/cgf.12877", "10.1162/leon.2007.40.2.202a", "10.1109/tvcg.2017.2674978", "10.1057/ivs.2010.4", "10.1016/j.cag.2018.02.008", "10.1201/9781315140919", "10.1109/visual.2000.885677", "10.1002/jhbs.20078", "10.1109/tvcg.2014.2346594", "10.1109/tvcg.2017.2744184", "10.1109/visual.2001.964495", "10.1109/iv.2002.1028760", "10.1111/cgf.13684", "10.1109/hicss.2013.197", "10.1109/tvcg.2019.2903956", "10.1093/mnras/stt961", "10.1109/tvcg.2017.2668409", "10.1111/j.1467-8659.2009.01478.x", "10.1145/2702123.2702585", "10.2307/1418003", "10.2307/1390742", "10.1145/360825.360839", "10.1109/pacificvis.2009.4906843", "10.1057/ivs.2009.34", "10.2307/2288711"], "wos": 1, "children": [], "len": 1}], "len": 13}, {"doi": "10.1111/cgf.14000", "year": "2020", "title": "Evaluating Reordering Strategies for Cluster Identification in Parallel Coordinates", "conferenceName": "EuroVis", "authors": "Michael Blumenschein;Xuan Zhang;David Pomerenke;Daniel A. Keim;Johannes Fuchs", "citationCount": "0", "affiliation": "Blumenschein, M (Corresponding Author), Univ Konstanz, Constance, Germany.\nBlumenschein, Michael; Pomerenke, David; Keim, Daniel A.; Fuchs, Johannes, Univ Konstanz, Constance, Germany.\nZhang, Xuan, Rhein Westfal TH Aachen, Aachen, Germany.", "countries": "Germany", "abstract": "The ability to perceive patterns in parallel coordinates plots (PCPs) is heavily influenced by the ordering of the dimensions. While the community has proposed over 30 automatic ordering strategies, we still lack empirical guidance for choosing an appropriate strategy for a given task. In this paper, we first propose a classification of tasks and patterns and analyze which PCP reordering strategies help in detecting them. Based on our classification, we then conduct an empirical user study with 31 participants to evaluate reordering strategies for cluster identification tasks. We particularly measure time, identification quality, and the users' confidence for two different strategies using both synthetic and real-world datasets. Our results show that, somewhat unexpectedly, participants tend to focus on dissimilar rather than similar dimension pairs when detecting clusters, and are more confident in their answers. This is especially true when increasing the amount of clutter in the data. As a result of these findings, we propose a new reordering strategy based on the dissimilarity of neighboring dimension pairs.", "keywords": "", "link": "https://doi.org/10.1111/cgf.14000", "refList": ["10.1111/j.1467-8659.2008.01241.x", "10.2312/conf/eg2013/stars/095-116", "10.1109/tvcg.2014.2346979", "10.1117/12.838819", "10.2307/2290001", "10.1111/cgf.12638", "10.1007/978-3-642-30217-6\\_42", "10.1109/sc.2005.47", "10.1002/wics.145", "10.1109/tvcg.2011.229", "10.1109/vast.2009.5332628", "10.1109/vast.2017.8585613", "10.1145/2993901.2993907", "10.1007/bf00410640", "10.1109/tvcg.2010.184", "10.11591/ijece.v5i6", "10.1111/j.1467-8659.2011.01961.x", "10.1109/visual.1997.663916", "10.1111/j.1467-8659.2012.03129.x", "10.1109/visual.1999.809866", "10.1057/ivs.2008.13", "10.1016/j.visinf.2017.11.001", "10.2307/2282967", "10.1007/978-0-387-68628-8\\_10", "10.5888/pcd9.120082", "10.1109/tvcg.2007.70535", "10.1109/vast.2010.5652450", "10.1007/bf01898350", "10.1016/0010-0285(91)90009-d", "10.1007/978-3-642-24958-7\\_12", "10.1109/infvis.2005.1532142", "10.1057/palgrave.ivs.9500166", "10.1111/j.1467-8659.2008.01239.x", "10.1109/mcse.2015.55", "10.2312/pe/eurovast/eurova12/007-011.7", "10.1109/tvcg.2009.153", "10.1198/jcgs.2010.09136", "10.1145/2463676.2463696", "10.1109/infvis.2005.1532138", "10.1109/tvcg.2010.242", "10.5220/0006097400400051", "10.1109/visual.2019.8933706", "10.1109/atc.2015.7388338", "10.2312/pe/eurovast/eurova12/007-011", "10.5120/5044-7370", "10.1111/cgf.13446", "10.1109/icmla.2012.148", "10.1016/j.jvlc.2015.12.001", "10.1109/tvcg.2015.2466992", "10.1111/j.1467-8659.2009.01666.x", "10.5169/seals-266450", "10.1109/infvis.1998.729559", "10.1016/j.jvlc.2017.10.003", "10.1109/visual.1995.485139", "10.1007/978-0-387-39940-9\\_262", "10.1109/tvcg.2006.138"], "wos": 1, "children": [], "len": 1}], "len": 71}, {"doi": "10.1111/cgf.13425", "year": "2018", "title": "ThreadReconstructor: Modeling Reply-Chains to Untangle Conversational Text through Visual Analytics", "conferenceName": "EuroVis", "authors": "Mennatallah El{-}Assady;Rita Sevastjanova;Daniel A. Keim;Christopher Collins", "citationCount": "3", "affiliation": "El-Assady, M (Corresponding Author), Univ Konstanz, Constance, Germany.\nEl-Assady, M (Corresponding Author), Univ Ontario Inst Technol, Oshawa, ON, Canada.\nEl-Assady, Mennatallah; Sevastjanova, Rita; Keim, Daniel, Univ Konstanz, Constance, Germany.\nEl-Assady, Mennatallah; Collins, Christopher, Univ Ontario Inst Technol, Oshawa, ON, Canada.", "countries": "Canada;Germany", "abstract": "We present ThreadReconstructor, a visual analytics approach for detecting and analyzing the implicit conversational structure of discussions, e.g., in political debates and forums. Our work is motivated by the need to reveal and understand single threads in massive online conversations and verbatim text transcripts. We combine supervised and unsupervised machine learning models to generate a basic structure that is enriched by user-defined queries and rule-based heuristics. Depending on the data and tasks, users can modify and create various reconstruction models that are presented and compared in the visualization interface. Our tool enables the exploration of the generated threaded structures and the analysis of the untangled reply-chains, comparing different models and their agreement. To understand the inner-workings of the models, we visualize their decision spaces, including all considered candidate relations. In addition to a quantitative evaluation, we report qualitative feedback from an expert user study with four forum moderators and one machine learning expert, showing the effectiveness of our approach.", "keywords": "", "link": "https://doi.org/10.1111/cgf.13425", "refList": ["10.1109/tvcg.2015.2509990", "10.1007/978-3-642-15470-6\\_7", "10.1109/gefs.2013.6601048", "10.1145/1316902.1316919", "10.1111/cgf.13181", "10.3115/1219840.1219885", "10.1145/1988688.1988705", "10.21275/v5i4.nov162954", "10.1016/j.visinf.2017.01.006", "10.1109/tvcg.2013.232", "10.1111/cgf.12378", "10.1145/2488388.2488514", "10.1109/tvcg.2017.2745080", "10.1109/icdmw.2015.65", "10.1111/cgf.12919", "10.18653/v1/p17-4009", "10.1145/1645953.164626", "10.1109/tvcg.2016.2598444", "10.1145/1031607.1031644", "10.1613/jair.953", "10.1109/ssci.2015.33", "10.1109/infvis.2003.1249028", "10.1145/2669557.2669572", "10.1145/1571941.1571966", "10.1023/a:1010933404324"], "wos": 1, "children": [{"doi": "10.1111/cgf.14034", "year": "2020", "title": "The State of the Art in Enhancing Trust in Machine Learning Models with the Use of Visualizations", "conferenceName": "EuroVis", "authors": "Angelos Chatzimparmpas;Rafael Messias Martins;Ilir Jusufi;Kostiantyn Kucher;Fabrice Rossi;Andreas Kerren", "citationCount": "2", "affiliation": "Chatzimparmpas, A (Corresponding Author), Linnaeus Univ, Dept Comp Sci \\& Media Technol, Vaxjo, Sweden.\nChatzimparmpas, A.; Martins, R. M.; Jusufi, I.; Kucher, K.; Kerren, A., Linnaeus Univ, Dept Comp Sci \\& Media Technol, Vaxjo, Sweden.\nRossi, F., PSL Univ, Univ Paris Dauphine, Ceremade, Paris, France.", "countries": "Sweden;France", "abstract": "Machine learning (ML) models are nowadays used in complex applications in various domains, such as medicine, bioinformatics, and other sciences. Due to their black box nature, however, it may sometimes be hard to understand and trust the results they provide. This has increased the demand for reliable visualization tools related to enhancing trust in ML models, which has become a prominent topic of research in the visualization community over the past decades. To provide an overview and present the frontiers of current research on the topic, we present a State-of-the-Art Report (STAR) on enhancing trust in ML models with the use of interactive visualization. We define and describe the background of the topic, introduce a categorization for visualization techniques that aim to accomplish this goal, and discuss insights and opportunities for future research directions. Among our contributions is a categorization of trust against different facets of interactive ML, expanded and improved from previous research. Our results are investigated from different analytical perspectives: (a) providing a statistical overview, (b) summarizing key findings, (c) performing topic analyses, and (d) exploring the data sets used in the individual papers, all with the support of an interactive web-based survey browser. We intend this survey to be beneficial for visualization researchers whose interests involve making ML models more trustworthy, as well as researchers and practitioners from other disciplines in their search for effective visualization techniques suitable for solving their tasks with confidence and conveying meaning to their data.", "keywords": "trustworthy machine learning; visualization; interpretable machine learning; explainable machine learning", "link": "https://doi.org/10.1111/cgf.14034", "refList": ["10.1109/mcg.2018.2878902", "10.1109/tvcg.2008.153", "10.2312/mlvis.20181130", "10.1109/tvcg.2016.2598828", "10.1145/3290605.3300911", "10.1145/2993901.2993909", "10.2312/mlvis.20191158", "10.1109/tvcg.2016.2598446", "10.1111/j.1467-8659.2009.01475.x", "10.1145/3290605.3300809", "10.1109/pacificvis.2018.00031", "10.1055/s-0029-1216348", "10.1007/978-3-319-90403-0\\_13", "10.1109/tvcg.2017.2745085", "10.1111/j.1467-8659.2011.01938.x", "10.1007/978-3-319-54024-5\\_6", "10.1016/s0167-9473(01)00065-2", "10.1111/cgf.12895", "10.2312/eurovisshort.20141152.17", "10.2312/eurova.20151098.22", "10.1111/cgf.13667", "10.3115/1072228.1072378", "10.1109/tbdata.2018.2877350.16", "10.1109/lars.2009.5418323.25", "10.1109/tvcg.2017.2744878", "10.1016/j.combustflame.2005.09.018", "10.1016/j.cag.2014.01.006", "10.1109/tvcg.2016.2570755", "10.2312/mlvis.20191158.1,19", "10.1518/hfes.46.1.50.30392", "10.1145/3301275.3302280", "10.1145/3351095.3372834.1", "10.1016/s0377-2217(01)00264-8", "10.1111/cgf.13424", "10.1007/978-3-319-23485-4\\_53", "10.1007/978-94-007-0753-5\\_3623", "10.1109/tvcg.2013.101", "10.1111/cgf.12884", "10.1111/j.1467-8659.2010.01835.x", "10.1021/ci9901338", "10.4230/lipics.itcs:2017", "10.1109/mis.2013.24", "10.1109/tvcg.2014.2346482", "10.1109/tvcg.2018.2865230", "10.1073/pnas.1807180116", "10.1109/dsaa.2018.00018", "10.1109/tvcg.2009.153", "10.3115/1219840.1219855", "10.1109/tvcg.2018.2864812", "10.1109/tvcg.2018.2872577", "10.2312/trvis.20191183", "10.1109/cvpr:2004.383", "10.1109/vast.2008.4677350", "10.1145/302979.303001", "10.1109/tvcg.2018.2864499", "10.1111/cgf.13672", "10.1109/tvcg.2014.2346626", "10.23915/distill.00010.18", "10.1109/tvcg.2017.2744805", "10.2312/mlvis:20191160.18", "10.23915/distill:00016", "10.1109/pacificvis.2016.7465260", "10.1111/cgf.13683", "10.23915/distill.00016.19", "10.1145/32906053.300803.22", "10.1109/tvcg.2014.2346574", "10.1177/1473871615600010", "10.1109/tvcg.2016.2598831", "10.1145/3230623", "10.1109/visual.2019.8933744", "10.1145/2993901.2993915", "10.1016/j.visinf.2017.01.006", "10.1145/2993901.2993914", "10.1109/tvcg.2014.2346984", "10.1109/5.726791", "10.23915/distill.00010", "10.1109/tvcg.2018.2864825", "10.2307/2394164", "10.1109/tvcg.2017.2744458", "10.1145/2993901.2993917.28", "10.1111/cgf.13711", "10.1109/tvcg.2016.2598664", "10.2307/2530428", "10.1109/icdar.1997.620583", "10.1109/tvcg.2017.2744718", "10.1111/cgf.13425", "10.1109/tvcg.2019.2903943", "10.1145/1518701.1518895", "10.1109/tvcg.2018.2864838", "10.1145/62038.62043", "10.1111/j.1467-8659.2011.01920.x", "10.1145/3025171.3025208", "10.1145/355112.355124", "10.1109/vast.2010.5652398", "10.1109/tvcg.2014.2346578", "10.1145/3173574.3174209", "10.4178/epih/e2014008", "10.1109/beliv.2018.8634201.25,28", "10.1016/j.eswa.2007.12.020", "10.1111/cgf:13406", "10.1109/mcg.2011.103", "10.1631/fitee.1700808", "10.1109/tvcg.2017.2745158", "10.1073/pnas.0307752101", "10.1109/tvcg.2018.2816223", "10.1109/tvcg.2017.2745141", "10.1145/32232.32234", "10.1109/tvcg.2019.2934267", "10.1109/tvcg.2018.2864477", "10.1145/3132169", "10.2312/eurova.20151100.19", "10.1145/3172944.3172964", "10.1145/2601248.2601268", "10.1109/isai-nlp.2018.8693002.1", "10.1111/cgf.13404", "10.1007/s100320200071", "10.2312/trvis.20191183.16", "10.1111/cgf.12755", "10.1145/2702123.2702509", "10.1145/1401890.1402008.25", "10.1109/tvcg.2012.65", "10.1177/1473871617733996", "10.2312/trvis.20191187.7", "10.21236/ada273556", "10.1109/vast.2010.5652450", "10.1111/j.1467-8659.2011.01940.x", "10.1177/875647939000600106", "10.1109/tvcg.2017.2711030", "10.1016/j.immuni.2016.04.014", "10.1109/tvcg.2019.2934209", "10.1016/0095-0696(78)90006-2", "10.1016/j.jclinepi.2015.04.014", "10.1016/j.ress.2013.02.013", "10.1111/cgf.12640", "10.1145/1015330.1015388.25", "10.1111/j.1467-8659.2009.01468.x", "10.1145/1541880.1541882", "10.1109/vast.2011.6102453", "10.1016/s0008-8846(98)00165-3", "10.2312/trvis.20191186.7", "10.1007/s13748-013-0040-3", "10.1109/tvcg.2015.2467757", "10.1109/tbdata.2018.2877350", "10.1109/vast.2017.8585613", "10.1080/10556789208805504", "10.1109/vast.2012.6400484", "10.1145/3025171.3025181", "10.1007/978-3-319-90403-0\\_12", "10.1109/mcg.2019.2922592", "10.1021/ci000392t", "10.1109/vast.2007.4389000", "10.1111/cgf.13406.16", "10.1111/cgf.13684", "10.2312/eurovisshort.20161166.17", "10.2312/evs:20191168", "10.1145/3041021.3055135", "10.1145/3301275.3302265", "10.1613/jair.4135", "10.1109/tvcg.2018.2864500", "10.1109/tvcg.2017.2744158", "10.1109/ssci.2015.33", "10.1111/cgf.13453", "10.2312/pe/eurovast/eurova11/049-052", "10.1145/3025171.3025181.13", "10.1145/371920.372094", "10.1109/tvcg.2017.2744938", "10.1111/j.1467-8659.2012.03108.x", "10.1109/tvcg.2019.2934251", "10.1145/3290605.3300809.18", "10.1109/ldav.2016.7874305", "10.1109/vast.2016.7883514", "10.1109/iccv.2015.425", "10.1145/3301275.3302324", "10.1109/tnnls.2013.2292894", "10.1109/tvcg.2018.2865044", "10.1109/tvcg.2013.157", "10.1371/journal.pcbi.0020161", "10.1186/s12916-019-1426-2", "10.1109/10.867928", "10.1111/cgf.13217", "10.1109/mcg.2019.2919033", "10.1145/2993901.2993910", "10.1109/tvcg.2017.2744738", "10.2307/258792", "10.1111/cgf.12655", "10.1016/j.dss.2014.03.001", "10.1109/tvcg.2019.2904069", "10.1111/cgf.13205", "10.1002/mds.22340", "10.1109/tvcg.2019.2934595", "10.1287/inte.2018.0957", "10.1109/cvpr.2007.382974", "10.1109/tvcg.2012.280", "10.1145/2678025.2701399.13", "10.2312/mlvis.20181130.13", "10.2312/eurova.20181106.16", "10.1109/tvcg.2018.2864475", "10.2312/mlvis.20191160.18,22", "10.1007/978-1-4612-4026-6.25", "10.1109/cvpr.2006.42", "10.1145/3172944.3172950", "10.1109/cvpr.2004.383.25", "10.1109/tvcg.2019.2934812", "10.1609/aimag.v35i4.2513", "10.2312/trvis.20191185.7", "10.1111/j.1467-8659.2009.01684.x", "10.1371/journal.pone.0129126", "10.1111/cgf.13092", "10.1162/coli\\_a\\_00237", "10.1109/tvcg.2017.2744818", "10.1109/vast.2011.6102448", "10.1109/tvcg.2009.111", "10.1109/tvcg.2019.2934619", "10.1016/s0377-2217(01)00264-8.25", "10.1111/cgf.12639", "10.1109/access.2019.2919343", "10.1186/s12874-019-0681-4", "10.1109/pacificvis.2015.7156366", "10.1109/pacificvis.2018.00029", "10.1109/tvcg.2019.2934261", "10.1080/13506280444000102.http://www.uvt.nl/ticc", "10.1109/vast.2018.8802509", "10.1111/cgf.13212", "10.1145/3200489", "10.1111/cgf.13176", "10.1177/1473871620904671", "10.1007/978-3-319-10590-1\\_53", "10.1111/j.1467-8659.2012.03126.x", "10.1111/cgf.13172", "10.1145/3025171.3025208.6,21", "10.1111/cgf.12366", "10.1109/tvcg.2019.2934659", "10.1109/cvprw.2009.5206848", "10.1016/j.media.2014.11.010", "10.1109/tvcg.2017.2744683", "10.1109/tvcg.2019.2934262", "10.1016/j.neucom.2006.11.018", "10.1177/1473871615571951", "10.1371/journal.pcbi.0020161.25", "10.1177/1473871611415994", "10.2312/trvis20191187", "10.2312/eurova", "10.1145/2858036.2858529", "10.1145/2207676.2207738", "10.1007/s11042-009-0417-2", "10.1145/3301275.3302317", "10.1038/s41746-019-0148-3", "10.1145/3351095.3372834", "10.1080/10691898.2011.11889627", "10.1109/tvcg.2018.2864504", "10.1109/vast.2017.8585720", "10.1109/mcg.2018.053491732", "10.1007/s10994-010-5207-6", "10.1109/tvcg.2019.2934433", "10.1016/j.cag.2017.05.005", "10.1109/tvcg.2012.279", "10.1145/3231622.3231641.19,20", "10.1145/1562849.1562851", "10.1007/11564126\\_", "10.1109/tvcg.2018.2846735", "10.3115/1225403.1225421", "10.1109/vast.2012.6400486", "10.2312/eurova.20191116.22", "10.1109/tvcg.2007.70443", "10.1080/027868291009242", "10.2312/eurova.20151100", "10.1145/2939502.2939503.19", "10.1016/j.cag.2014.02.004", "10.1145/2939672.2939778", "10.1109/vast.2010.5652484", "10.1111/cgf.12641", "10.1145/3301275.3302289", "10.1109/visual.2019.8933619", "10.1109/tvcg.2017.2672987", "10.1109/vast.2016.7883517.20", "10.1109/igarss.2017.8127684", "10.1016/j.jcae.2010.04.002", "10.1109/vast.2010.5652885", "10.1016/j.visinf.2019.03.002", "10.1007/s00371-018-1500-3", "10.1109/mcg.2018.042731661", "10.1109/34.598228", "10.1109/tvcg.2018.2865027", "10.1016/j.neucom.2017.01.105", "10.1111/cgf.12389", "10.1109/tvcg.2019.2934591", "10.1109/vast.2010.5652392.16", "10.1111/cgf.13416", "10.1080/02701367.1992.10608764", "10.1109/vast.2017.8585721", "10.1109/tvcg.2018.2843369", "10.1109/sbes.2010.27", "10.1109/vast.2015.7347637", "10.1145/1401890.1402008", "10.1016/j.bpj.2010.04.064", "10.1109/tvcg.2013.125", "10.1109/isai-nlp.2018.8693002", "10.1371/journal.pone.0160127", "10.1145/2856767.2856779", "10.1145/2678025.2701399", "10.1109/vast.2011.6102451", "10.1109/mcg.2010.18", "10.1021/ci4000213", "10.1109/vast.2012.6400492", "10.1007/11564126-49.25", "10.2312/eurova.20171114", "10.1109/vast.2010.5652443", "10.1145/3134599", "10.2312/pe/eurovast/eurovast10/013-018.19", "10.1109/tvcg.2019.2903946", "10.1109/tvcg.2015.2467717", "10.1177/1473871612460526", "10.1016/j.cag.2018.09.018", "10.1109/tvcg.2016.2598838", "10.1145/3172944.3172964.14", "10.1109/vast.2009.5333428", "10.1109/vast.2014.7042480", "10.2312/pe/eurovast/eurovast10/013-018", "10.1177/0962280215588241", "10.1145/2993901.2993917", "10.1109/cvpr.2008:4587581", "10.1109/tvcg.2015.2467551", "10.1016/j.visinf.2018.09.001", "10.1126/science.290.5500.2319", "10.2312/eurova.20151107", "10.1109/visual.2019.8933695", "10.13140/2.1.2393.1847", "10.1197/jamia.m1929", "10.1109/cvpr.2008.4587581.25", "10.1145/1518701.1518895.16", "10.1109/vds.2017.8573444", "10.2312/trvis:20191185", "10.1145/3359786", "10.13140/2.1.1341.1520", "10.2312/pe/eurovast/eurova11/049-052.17", "10.1109/tvcg.2014.2346660", "10.1145/3185517", "10.1109/adprl.2011.5967372", "10.1109/tvcg.2015.2467591", "10.1111/j.1751-9004.2009.00232.x", "10.1136/qshc.2004.010033", "10.1109/vast.2012.6400493", "10.1109/tvcg.2019.2934266", "10.1145/2971763.2971775", "10.1111/cgf.13730", "10.1109/vast.2012.6400488", "10.1111/cgf.13210", "10.1109/tvcg.2019.2934631", "10.1145/3172944.3172965", "10.1057/ivs.2010.2", "10.1109/tvcg.2017.2745258", "10.1016/j.jbusres.2019.07.039", "10.1162/jmlr.2003.3.4-5.993", "10.1109/pacificvis.2019.00044", "10.2312/pe/eurovast/eurova12/037-041", "10.1109/tvcg.2019.2934629", "10.1177/0018720814547570", "10.1145/3292500.3330908", "10.1111/j.1467-8659.2009.01467.x", "10.2312/eurova.20151098", "10.1177/1473871617713337", "10.1109/lars:2009.5418323", "10.1109/vast.2011.6102437", "10.1111/cgf.12878", "10.1561/1500000001", "10.1145/3025171.3025222", "10.1007/s11704-016-6028-y", "10.1016/j.procs.2017.05.216", "10.1109/cvpr.2007.382974.25", "10.1080/10447318.2020.1741118", "10.1109/vast.2012.6400489", "10.1145/3025171.3025172", "10.1109/tvcg.2017.2744098", "10.1109/tvcg.2005.66", "10.1016/j.dss.2009.05.016", "10.1007/978-1-4612-4026-6", "10.2312/evs.20191168.16,20,28", "10.2312/pe/eurovast/eurova12/037-041.17", "10.1145/3290605.3300803", "10.1145/1015330.1015388", "10.1111/cgf.13197", "10.1016/b978-1-55860-377-6.50048-7", "10.1111/cgf.13681", "10.1109/tvcg.2017.2744378", "10.1109/tvcg.2017.2744358", "10.1109/vast.2008.4677352"], "wos": 1, "children": [{"doi": "10.1109/tvcg.2020.3030368", "title": "Implicit Multidimensional Projection of Local Subspaces", "year": "2020", "conferenceName": "InfoVis", "authors": "Rongzheng Bian;Yumeng Xue;Liang Zhou;Jian Zhang 0070;Baoquan Chen;Daniel Weiskopf;Yunhai Wang", "citationCount": "1", "affiliation": "Wang, YH (Corresponding Author), Shandong Univ, Qingdao, Peoples R China. Zhou, L (Corresponding Author), Univ Utah, Salt Lake City, UT 84112 USA. Bian, Rongzheng; Xue, Yumeng; Wang, Yunhai, Shandong Univ, Qingdao, Peoples R China. Chen, Baoquan, Peking Univ, Beijing, Peoples R China. Zhang, Jian, Chinese Acad Sci, CNIC, Beijing, Peoples R China. Zhou, Liang, Univ Utah, Salt Lake City, UT 84112 USA. Weiskopf, Daniel, Univ Stuttgart, Stuttgart, Germany.", "countries": "USA;Germany;China", "abstract": "We propose a visualization method to understand the effect of multidimensional projection on local subspaces, using implicit function differentiation. Here, we understand the local subspace as the multidimensional local neighborhood of data points. Existing methods focus on the projection of multidimensional data points, and the neighborhood information is ignored. Our method is able to analyze the shape and directional information of the local subspace to gain more insights into the global structure of the data through the perception of local structures. Local subspaces are fitted by multidimensional ellipses that are spanned by basis vectors. An accurate and efficient vector transformation method is proposed based on analytical differentiation of multidimensional projections formulated as implicit functions. The results are visualized as glyphs and analyzed using a full set of specifically-designed interactions supported in our efficient web-based visualization tool. The usefulness of our method is demonstrated using various multi- and high-dimensional benchmark datasets. Our implicit differentiation vector transformation is evaluated through numerical comparisons; the overall method is evaluated through exploration examples and use cases.", "keywords": "High-dimensional data visualization,dimensionality reduction,local linear subspaces,user interaction", "link": "http://dx.doi.org/10.1109/TVCG.2020.3030368", "refList": ["10.3844/jcssp.2018.613.622", "10.1016/j.aci.2018.08.003", "10.3390/info9030065", "10.1016/j.visinf.2018.09.003", "10.1371/journal.pone.0118432", "10.1016/s0893-6080(05)80023-1", "10.1109/tvcg.2020.2986996", "10.1109/icst.2012.56", "10.1007/s10844-013-0250-y", "10.1109/tbdata.2018", "10.1145/1125451.1125659", "10.1109/tvcg.2013.125", "10.1177/1473871611412817", "10.1145/3290605.3300911", "10.1111/cgf.14034", "10.1007/s13721-013-0034-x", "10.1016/j.procs.2017.05.216", "10.1016/j.ins.2009.08.025", "10.1109/tvcg.2013.124", "10.1109/tvcg.2018.2864499", "10.1109/tvcg.2018.2864475", "10.1080/10447318.2020.1741118", "10.1016/j.imu.2019.100203", "10.1109/tvcg.2018.2865240", "10.1186/s12864-019-6413-7", "10.1109/tvcg.2015.2467551", "10.1002/widm.1249", "10.1007/978-3-319-66429-3\\_29", "10.1109/tvcg.2014.2346481", "10.1109/tvcg.2018.2864825", "10.1177/1473871620904671", "10.1109/tvcg.2019.2934267", "10.1136/bmjopen-2016-012799", "10.1109/smartgridcomm.2017.8340682", "10.1007/s10664-015-9401-9", "10.1145/1143844.1143874", "10.1111/cgf.12389", "10.1109/tvcg.2018.2872577", "10.1007/978-981-13-5802-9\\_20", "10.1016/j.ipm.2009.03.002", "10.5220/0006431602160222", "10.1109/mcg.2015.50", "10.1109/tvcg.2014.2346574", "10.1007/bf02289565", "10.1109/tvcg.2017.2744378", "10.1016/j.patrec.2008.08.010", "10.1023/a:1010933404324", "10.9735/2229-3981"], "wos": 1, "children": [], "len": 1}, {"doi": "10.1109/tvcg.2020.3030465", "title": "Visual Causality Analysis of Event Sequence Data", "year": "2020", "conferenceName": "VAST", "authors": "Zhuochen Jin;Shunan Guo;Nan Chen;Daniel Weiskopf;David Gotz;Nan Cao", "citationCount": "0", "affiliation": "Cao, N (Corresponding Author), Tongji Univ, IDVx Lab, Shanghai, Peoples R China. Jin, Zhuochen; Guo, Shunan; Chen, Nan; Cao, Nan, Tongji Univ, IDVx Lab, Shanghai, Peoples R China. Weiskopf, Daniel, Univ Stuttgart, Stuttgart, Germany. Gotz, David, Univ N Carolina, Chapel Hill, NC 27515 USA.", "countries": "USA;Germany;China", "abstract": "Causality is crucial to understanding the mechanisms behind complex systems and making decisions that lead to intended outcomes. Event sequence data is widely collected from many real-world processes, such as electronic health records, web clickstreams, and financial transactions, which transmit a great deal of information reflecting the causal relations among event types. Unfortunately, recovering causalities from observational event sequences is challenging, as the heterogeneous and high-dimensional event variables are often connected to rather complex underlying event excitation mechanisms that are hard to infer from limited observations. Many existing automated causal analysis techniques suffer from poor explainability and fail to include an adequate amount of human knowledge. In this paper, we introduce a visual analytics method for recovering causalities in event sequence data. We extend the Granger causality analysis algorithm on Hawkes processes to incorporate user feedback into causal model refinement. The visualization system includes an interactive causal analysis framework that supports bottom-up causal exploration, iterative causal verification and refinement, and causal comparison through a set of novel visualizations and interactions. We report two forms of evaluation: a quantitative evaluation of the model improvements resulting from the user-feedback mechanism, and a qualitative evaluation through case studies in different application domains to demonstrate the usefulness of the system.", "keywords": "Event sequence data,causality analysis,visual analytics", "link": "http://dx.doi.org/10.1109/TVCG.2020.3030465", "refList": ["10.5555/1642718", "10.1109/tvcg.2018.2865022", "10.5555/2074094.2074151", "10.1109/tvcg.2016.2618797", "10.1073/pnas.1320645111", "10.1109/tvcg.2017.2744843", "10.1109/iv.2017.69", "10.1109/tvcg.2019.2934399", "10.1145/3172944.3173007", "10.5555/1795555", "10.1109/mcg.2005.102", "10.1145/381641.381653", "10.1162/153244301753344614", "10.1111/cgf.14034", "10.1111/cgf.13198", "10.1017/cbo9780511519857", "10.1007/s10462-016-9475-9", "10.1075/ssol.2.2.07bor", "10.1007/978-1-4614-3223-4\\_3", "10.1109/infvis.2003.1249025", "10.1007/978-94-007-6094-313", "10.1145/2858036.2858387", "10.1109/tvcg.2007.70528", "10.1109/tvcg.2017.2674958", "10.1147/sj.454.0801", "10.1109/tvcg.2013.119", "10.1145/3173574.3173711", "10.1016/j.erss.2017.06.034", "10.1109/visual.2019.8933695", "10.1007/s11665-016-2173-6", "10.1016/0377-0427(87)90125-7", "10.2307/3601125", "10.1016/b978-0-444-88738-2.50018-x", "10.1109/mcg.2006.70", "10.1109/tvcg.2018.2865145", "10.1017/s1351324997001502", "10.1109/tvcg.2010.179", "10.1214/aos/1176344552", "10.1109/mcg.2009.22", "10.1007/978-3-319-26633-6\\_13", "10.1080/10447318.2014.905422", "10.1016/j.visinf.2019.03.004", "10.1057/palgrave.ivs.9500074", "10.1007/978-1-4614-3223-4"], "wos": 1, "children": [], "len": 1}], "len": 5}], "len": 7}, {"doi": "10.1111/cgf.13965", "year": "2020", "title": "Bombalytics: Visualization of Competition and Collaboration Strategies of Players in a Bomb Laying Game", "conferenceName": "EuroVis", "authors": "Shivam Agarwal;G{\\\"{u}}nter Wallner;Fabian Beck", "citationCount": "0", "affiliation": "Agarwal, S (Corresponding Author), Univ Duisburg Essen, Duisburg, Germany.\nAgarwal, Shivam; Beck, Fabian, Univ Duisburg Essen, Duisburg, Germany.\nWallner, Gunter, Eindhoven Univ Technol, Eindhoven, Netherlands.\nWallner, Gunter, Univ Appl Arts Vienna, Vienna, Austria.", "countries": "Germany;Austria;Netherlands", "abstract": "Competition and collaboration form complex interaction patterns between the agents and objects involved. Only by understanding these interaction patterns, we can reveal the strategies the participating parties applied. In this paper, we study such competition and collaboration behavior for a computer game. Serving as a testbed for artificial intelligence, the multiplayer bomb laying game Pommerman provides a rich source of advanced behavior of computer agents. We propose a visualization approach that shows an overview of multiple games, with a detailed timeline-based visualization for exploring the specifics of each game. Since an analyst can only fully understand the data when considering the direct and indirect interactions between agents, we suggest various visual encodings of these interactions. Based on feedback from expert users and an application example, we demonstrate that the approach helps identify central competition strategies and provides insights on collaboration.", "keywords": "", "link": "https://doi.org/10.1111/cgf.13965", "refList": ["10.1145/1822348.1822349", "10.1016/j.cag.2013.11.010", "10.1145/2793107.2793112", "10.1109/tvcg.2019.2934630", "10.1145/3343055.3360747", "10.1016/j.intcom.2010.04.004", "10.1109/cig.2019.8848091", "10.1007/s11554-013-0347-0", "10.1007/s12650-019-00566-5", "10.1109/bigdata.2018.8622571", "10.1007/978-3-319-63519-4", "10.1109/tciaig.2014.2365470", "10.1016/j.entcom.2013.02.002", "10.1609/aimag.v34i3.2492", "10.1145/3311350.3357716", "10.1109/tvcg.2018.2864885", "10.1177/1473871617718377", "10.1109/tvcg.2018.2864504", "10.1111/cgf.12919", "10.1109/tvcg.2019.2934243", "10.1109/tvcg.2018.2859969", "10.1145/3235765.3235812", "10.1109/tvcg.2017.2745320", "10.1109/tvcg.2016.2598415", "10.1109/tciaig.2012.2188528", "10.1109/iscas.2019.8702471", "10.2307/350902", "10.1109/mc.2018.2890217", "10.1145/3027063.3053146", "10.1111/cgf.13436", "10.1145/3130859.3131439", "10.1016/j.compedu.2011.11.015"], "wos": 1, "children": [], "len": 1}, {"doi": "10.1111/cgf.13181", "year": "2017", "title": "NEREx: Named-Entity Relationship Exploration in Multi-Party Conversations", "conferenceName": "EuroVis", "authors": "Mennatallah El{-}Assady;Rita Sevastjanova;Bela Gipp;Daniel A. Keim;Christopher Collins", "citationCount": "13", "affiliation": "El-Assady, M (Corresponding Author), Univ Konstanz, Constance, Germany.\nEl-Assady, M (Corresponding Author), Univ Ontario Inst Technol, Oshawa, ON, Canada.\nEl-Assady, Mennatallah; Sevastjanova, Rita; Gipp, Bela; Keim, Daniel, Univ Konstanz, Constance, Germany.\nEl-Assady, Mennatallah; Collins, Christopher, Univ Ontario Inst Technol, Oshawa, ON, Canada.", "countries": "Canada;Germany", "abstract": "We present NEREx, an interactive visual analytics approach for the exploratory analysis of verbatim conversational transcripts. By revealing different perspectives on multi-party conversations, NEREx gives an entry point for the analysis through high-level overviews and provides mechanisms to form and verify hypotheses through linked detail-views. Using a tailored named-entity extraction, we abstract important entities into ten categories and extract their relations with a distance-restricted entity-relationship model. This model complies with the often ungrammatical structure of verbatim transcripts, relating two entities if they are present in the same sentence within a small distance window. Our tool enables the exploratory analysis of multi-party conversations using several linked views that reveal thematic and temporal structures in the text. In addition to distant-reading, we integrated close-reading views for a text-level investigation process. Beyond the exploratory and temporal analysis of conversations, NEREx helps users generate and validate hypotheses and perform comparative analyses of multiple conversations. We demonstrate the applicability of our approach on real-world data from the 2016 U.S. Presidential Debates through a qualitative study with three domain experts from political science.", "keywords": "", "link": "https://doi.org/10.1111/cgf.13181", "refList": ["10.1109/vast.2014.7042493", "10.1109/tvcg.2014.2346435", "10.1007/978-3-540-68125-0\\_9", "10.3115/1219840.1219885", "10.2312/eurovisstar.20151113", "10.1017/s1755773912000173", "10.1109/tvcg.2009.165", "10.1111/cgf.12125", "10.1111/cgf.12378", "10.1177/1473871615575079", "10.1145/778712.778764", "10.1111/cgf.12919", "10.1109/tvcg.2012.323", "10.3115/1119176.1119206", "10.1057/palgrave.ivs.9500180", "10.3115/974557.974586", "10.3115/1219044.1219066", "10.1109/tvcg.2011.100", "10.1162/153244303322533205", "10.1109/icdm.2009.81", "10.1145/2669557.2669572", "10.1007/bf00136985"], "wos": 1, "children": [{"doi": "10.1109/pacificvis.2019.00026", "year": "2019", "title": "Visual Quality Guidance for Document Exploration with Focus+Context Techniques", "conferenceName": "PacificVis", "authors": "Qi Han;Dennis Thom;Markus John;Steffen Koch;Thomas Ertl;Florian Heimerl", "citationCount": "1", "affiliation": "Han, Q (Corresponding Author), Univ Stuttgart, Inst Visualisat \\& Interact Syst, Stuttgart, Germany.\nHan, Qi; Thom, Dennis; John, Markus; Koch, Steffen; Ertl, Thomas, Univ Stuttgart, Inst Visualisat \\& Interact Syst, Stuttgart, Germany.\nHeimerl, Florian, Univ Wisconsin, Dept Comp Sci, Madison, WI USA.", "countries": "Germany;USA", "abstract": "Magic lens based focus+context techniques are powerful means for exploring document spatializations. Typically, they only offer additional summarized or abstracted views on focused documents. As a consequence, users might miss important information that is either not shown in aggregated form or that never happens to get focused. In this work, we present the design process and user study results for improving a magic lens based document exploration approach with exemplary visual quality cues to guide users in steering the exploration and support them in interpreting the summarization results. We contribute a thorough analysis of potential sources of information loss involved in these techniques, which include the visual spatialization of text documents, user-steered exploration, and the visual summarization. With lessons learned from previous research, we highlight the various ways those information losses could hamper the exploration. Furthermore, we formally define measures for the aforementioned different types of information losses and bias. Finally, we present the visual cues to depict these quality measures that are seamlessly integrated into the exploration approach. These visual cues guide users during the exploration and reduce the risk of misinterpretation and accelerate insight generation. We conclude with the results of a controlled user study and discuss the benefits and challenges of integrating quality guidance in exploration techniques.", "keywords": "Document Visualization; Focus plus Context; Visual Guidance; Uncertainty Visualization; Document Spatialization; Text Mining; Visual Analytics", "link": "https://doi.org/10.1109/PacificVis.2019.00026", "refList": ["10.1177/1473871612460526", "10.1016/j.cag.2014.01.006", "10.1109/tvcg.2007.70443", "10.1109/tvcg.2015.2467591", "10.1109/vast.2016.7883507", "10.1145/1456650.1456652", "10.1109/vast.2009.5333443", "10.1109/tvcg.2017.2744138", "10.1016/j.neucom.2006.11.018", "10.1111/cgf.13181", "10.1109/vast.2011.6102456", "10.1109/tvcg.2016.2598445", "10.1177/1536867x0300300204", "10.1109/bigdata.2015.7363807", "10.1109/vast.2011.6102449", "10.1109/pacificvis.2015.7156366", "10.1111/cgf.12871", "10.1109/tvcg.2013.186", "10.1111/j.1467-8659.2010.01835.x", "10.1145/1842993.1843002", "10.1145/2207676.2207741", "10.1007/978-1-4471-6497-5\\_1", "10.1109/tvcg.2013.162", "10.1109/t-c.1969.222678", "10.1145/2911451.2911546", "10.1109/tvcg.2012.285", "10.1109/tvcg.2014.2346743", "10.1109/tvcg.2015.2467691", "10.1109/tvcg.2016.2598466", "10.1109/2945.981848", "10.1109/vast.2007.4389006", "10.1145/302979.303148", "10.1109/vast.2014.7042494", "10.1109/infvis.1995.528686", "10.1109/tvcg.2012.277", "10.1109/tvcg.2017.2723397", "10.1177/0963721413481473", "10.1109/visual.2000.885678", "10.1109/tvcg.2018.2865233", "10.1109/tvcg.2013.153", "10.1016/0169-7439(87)80084-9", "10.1111/cgf.12655", "10.1109/tvcg.2018.2846735", "10.3115/1117729.1117730", "10.1109/tvcg.2015.2467717", "10.1145/22339.22342", "10.1109/vast.2011.6102488", "10.1109/tvcg.2016.2598468", "10.1109/tvcg.2016.2599058", "10.1109/tvcg.2014.2346433", "10.1109/tvcg.2006.138"], "wos": 1, "children": [], "len": 1}, {"doi": "10.1109/pacificvis.2019.00037", "year": "2019", "title": "A Visual Approach for the Comparative Analysis of Character Networks in Narrative Texts", "conferenceName": "PacificVis", "authors": "Markus John;Martin Baumann", "citationCount": "1", "affiliation": "John, M (Corresponding Author), Univ Stuttgart, Inst Visualizat \\& Interact Syst VIS, Stuttgart, Germany.\nJohn, Markus; Baumann, Martin; Schuetz, David; Koch, Steffen; Ertl, Thomas, Univ Stuttgart, Inst Visualizat \\& Interact Syst VIS, Stuttgart, Germany.", "countries": "Germany", "abstract": "The analysis of a novel's plot and characters are challenging and time-consuming tasks in literary criticism. Typically, humanities scholars want to describe and compare characters' personality traits, their roles, their relationships, and the evolution of these aspects over the course of a novel. Nowadays, due to the digitization of literature, humanities scholars can be supported in these endeavors with computational methods. In this paper, we present an approach that offers several means to analyze the plot and characters of a novel visually. Analysts can easily switch between an adjacency matrix and a node-link representation, which provide an overview of the characters and the relationships between them. Both views enable analysts to select different text ranges of the novel for studying the commonalities and differences of the character constellations within these ranges. We offer interactive visual representations to help investigate the relationships between the characters in more detail. Additionally, we link the visual representations with the novels' texts to support the inspection and verification of previously generated ideas and hypotheses. To demonstrate the benefits and limitations of our approach, we present two usage scenarios. The first one is based on a fictitious analysis and the second one discusses applications that were carried out during joint workshops with humanities scholars. Finally, we present and discuss the insights gained by an expert study and the design decisions of our approach.", "keywords": "Visual text analysis; document analysis; close reading; distant reading; digital humanities; graph comparison", "link": "https://doi.org/10.1109/PacificVis.2019.00037", "refList": ["10.1177/1473871611416549", "10.1145/2702123.2702476", "10.1111/cgf.13181", "10.1111/cgf.12791", "10.1111/cgf.13170", "10.1111/j.1467-8659.2011.01898.x", "10.1109/tvcg.2011.185", "10.1109/vast.2009.5333248", "10.1109/tvcg.2015.2467971", "10.1080/10447318.2010.516722", "10.1136/qshc.2004.010033", "10.1109/tvcg.2011.169", "10.3115/v1/p14-5010", "10.1109/tmm.2016.2614184", "10.1109/tvcg.2009.106", "10.1111/cgf.12124", "10.1109/iv.2016.28", "10.1145/2470654.2470724", "10.1057/palgrave.ivs.9500180", "10.1109/pacificvis.2011.5742388", "10.2190/ec.44.1.a", "10.13140/2.1.1341.1520", "10.1109/tvcg.2011.232", "10.1109/vast.2007.4389004", "10.1057/palgrave.ivs.9500092", "10.1007/978-0-85729-079-3"], "wos": 1, "children": [], "len": 1}, {"doi": "10.1111/cgf.13446", "year": "2018", "title": "Quality Metrics for Information Visualization", "conferenceName": "EuroVis", "authors": "Michael Behrisch;Michael Blumenschein;Nam Wook Kim;Lin Shao;Mennatallah El{-}Assady;Johannes Fuchs;Daniel Seebacher;Alexandra Diehl;Ulrik Brandes;Hanspeter Pfister;Tobias Schreck;Daniel Weiskopf;Daniel A. Keim", "citationCount": "25", "affiliation": "Behrisch, M (Corresponding Author), Harvard Univ, Cambridge, MA 02138 USA.\nBehrisch, M.; Kim, N. W.; Pfister, H., Harvard Univ, Cambridge, MA 02138 USA.\nBlumenschein, M.; El-Assady, M.; Fuchs, J.; Seebacher, D.; Diehl, A.; Keim, D. A., Univ Konstanz, Constance, Germany.\nShao, L.; Schreck, T., Graz Univ Technol, Graz, Austria.\nBrandes, U., Swiss Fed Inst Technol, Zurich, Switzerland.\nWeiskopf, D., Univ Stuttgart, Stuttgart, Germany.", "countries": "Switzerland;Germany;USA;Austria", "abstract": "The visualization community has developed to date many intuitions and understandings of how to judge the quality of views in visualizing data. The computation of a visualization's quality and usefulness ranges from measuring clutter and overlap, up to the existence and perception of specific (visual) patterns. This survey attempts to report, categorize and unify the diverse understandings and aims to establish a common vocabulary that will enable a wide audience to understand their differences and subtleties. For this purpose, we present a commonly applicable quality metric formalization that should detail and relate all constituting parts of a quality metric. We organize our corpus of reviewed research papers along the data types established in the information visualization community: multi- and high-dimensional, relational, sequential, geospatial and text data. For each data type, we select the visualization subdomains in which quality metrics are an active research field and report their findings, reason on the underlying concepts, describe goals and outline the constraints and requirements. One central goal of this survey is to provide guidance on future research opportunities for the field and outline how different visualization communities could benefit from each other by applying or transferring knowledge to their respective subdomain. Additionally, we aim to motivate the visualization community to compare computed measures to the perception of humans.", "keywords": "", "link": "https://doi.org/10.1111/cgf.13446", "refList": ["10.2307/276978", "10.1057/ivs.2009.10", "10.1109/tvcg.2015.2467732", "10.1109/tvcg.2014.2346420", "10.1016/j.cag.2018.01.010", "10.1109/tvcg.2017.2743959", "10.1109/tvcg.2011.127", "10.1109/tvcg.2015.2467759", "10.1109/tvcg.2013.187", "10.1109/tvcg.2007.70594", "10.1186/1471-2105-9-155", "10.1145/2702123.2702545", "10.1145/1645953.1646023", "10.1093/bioinformatics/btm312", "10.1109/pacificvis.2016.7465245", "10.1145/3038462.3038463", "10.1007/978-3-540-70956-5", "10.1109/tvcg.2017.2743939", "10.1111/cgf.12932", "10.1111/j.1467-8659.2012.03106.x", "10.1145/1133265.1133318", "10.1109/tvcg.2010.186", "10.1109/iv.2013.101", "10.1109/tvcg.2016.2598590", "10.2312/conf/eg2013/stars/039-063", "10.3758/bf03201236", "10.1111/cgf.12935", "10.1145/1056808.1056914", "10.1007/bf01898350", "10.2307/1390686", "10.1109/2945.981848", "10.1109/hicss.2008.422", "10.1109/tvcg.2011.201", "10.1109/pacificvis.2011.5742390", "10.2307/2288400", "10.1111/cgf.12872", "10.1109/tvcg.2017.2674999", "10.1109/tvcg.2006.163", "10.1109/tvcg.2013.150", "10.1109/tvcg.2009.171", "10.1109/tvcg.2017.2723397", "10.1117/12.2079841", "10.1109/pacificvis.2009.4906838", "10.1109/infvis.2004.1", "10.1109/tvcg.2008.166", "10.1287/opre.20.5.993", "10.7155/jgaa.00370", "10.1111/j.1467-8659.2008.01240.x", "10.1109/inf0vis.2005.14", "10.1109/tvcg.2009.23", "10.1109/infvis.1998.729559", "10.1177/0165551506078083", "10.1109/t-c.1974.224051", "10.1109/tvcg.2017.2744339", "10.1109/tvcg.2014.2346433", "10.1145/989863.989940", "10.1109/tvcg.2015.2509990", "10.2307/2288843", "10.1016/j.neucom.2017.01.105", "10.1073/pnas.43.10.923", "10.1111/cgf.12647", "10.1016/j.rse.2017.06.031", "10.1109/infvis.2005.1532145", "10.1109/2945.841121", "10.1109/tvcg.2011.229", "10.2312/eurova.20141140", "10.1111/j.2044-8317.1974.tb00534.x", "10.1109/pacificvis.2015.7156366", "10.1109/vast.2009.5332628", "10.1109/vast.2014.7042480", "10.1145/2993901.2993907", "10.1177/0951692899011001004", "10.1007/978-3-642-03655-2\\_43", "10.1198/106186008x320465", "10.1109/visual.1997.663916", "10.1111/cgf.12125", "10.1109/infvis.2003.1249009", "10.1109/icdm.2003.1250978", "10.1109/tvcg.2017.2745919", "10.1109/tvcg.2012.128", "10.1109/vast.2010.5652450", "10.1109/tvcg.2006.161", "10.1145/571647.571649", "10.1109/tvcg.2011.193", "10.1111/cgf.12633", "10.1109/tvcg.2017.2674978", "10.1109/vast.2010.5652433", "10.1109/tvcg.2017.2745978", "10.1515/itit-2014-1070", "10.1145/1374489.1374501", "10.1109/tvcg.2009.153", "10.2312/eurovisshort.20171128", "10.2312/eurovisshort.20151130", "10.1016/0925-7721(94)00014-x", "10.1057/palgrave.ivs.95000/3", "10.1145/302979.303030", "10.1002/widm.1071", "10.1109/pacificvis.2014.42", "10.1109/tvcg.2016.2598467", "10.1111/j.1467-8659.2009.01667.x", "10.2307/2287708", "10.1177/1473871613477091", "10.1145/967900.968153", "10.1109/tvcg.2010.162", "10.1145/568522.568523", "10.1016/j.cag.2004.03.022", "10.1109/tvcg.2015.2466992", "10.1145/2993901.2993903", "10.1147/jrd.2015.2411412", "10.1177/154193120504900508", "10.1109/tvcg.2006.138", "10.1111/cgf.13168", "10.1111/cgf.12380", "10.2312/conf/eg2013/stars/095-116", "10.1109/tvcg.2017.2745859", "10.1109/tvcg.2017.2701829", "10.1109/tvcg.2007.70529", "10.1007/bf01199431", "10.1117/12.697548", "10.1109/tvcg.2017.2653106", "10.1207/s15327906mbr2701\\_4", "10.1109/vl.1996.545307", "10.1109/tvcg.2017.2745140", "10.1111/j.1467-8659.2012.03069.x", "10.1111/j.1467-8659.2011.01961.x", "10.1109/pacificvis.2016.7465244", "10.1109/tvcg.2013.124", "10.1057/ivs.2008.13", "10.2312/vissym/eurovis06/195-202", "10.2312/vissym/eurovis07/163-170", "10.1109/tvcg.2015.2467324", "10.1109/tvcg.2011.167", "10.1109/pacificvis.2014.40", "10.1109/pacificvis.2012.6183570", "10.1111/j.1467-8659.2012.03125.x", "10.1075/idj.20.1.02bei", "10.1111/1467-8306.00061", "10.1145/2858036.2858155", "10.1109/tvcg.2012.108", "10.2312/vmv.20171261", "10.1109/tvcg.2015.2467531", "10.1145/1379092.1379130", "10.1109/tpami.1979.4766909", "10.1080/13875860903039172", "10.1109/mcg.2006.70", "10.1109/tvcg.2010.242", "10.1109/vast.2007.4389004", "10.1109/tvcg.2015.2467191", "10.2312/cgvc.20171276", "10.1016/0169-7439(87)80084-9", "10.2312/pe/eurovisshort/eurovisshort2012/097-101", "10.1016/j.neucom.2014.07.073", "10.2307/2685263", "10.1145/996546.996554", "10.1111/j.1467-8659.2009.01666.x", "10.1117/12.2083444", "10.1109/tvcg.2014.2346572", "10.1007/978-0-387-39940-9\\_262", "10.1007/bf00988593", "10.1145/1054972.1055078", "10.1111/j.1467-8659.2009.01467.x", "10.1111/cgf.13181", "10.1145/502512.502530", "10.1109/pacificvis.2010.5429600", "10.1111/j.1467-8659.2011.01923.x", "10.1109/mcg.2004.41", "10.1109/tvcg.2015.2467971", "10.1111/j.1467-8659.2011.01919.x", "10.1002/sam.10071", "10.1109/tvcg.2010.184", "10.1007/978-3-642-27848-8\\_648-1", "10.1109/tvcg.2010.132", "10.1145/22949.22950", "10.1145/1842993.1843002", "10.1109/infvis.2000.885096", "10.1016/j.ins.2015.04.017", "10.1109/iv.2009.43", "10.1016/j.visinf.2017.11.001", "10.1109/tvcg.2011.239", "10.1109/infovis.2005.40", "10.1111/cgf.12641", "10.1109/pacificvis.2016.7465262", "10.1145/2470654.2466443", "10.1007/s10844-011-0157-4", "10.1111/cgf.12919", "10.1016/j.jvlc.2016.07.003", "10.1109/tvcg.2016.2549018", "10.1057/palgrave.ivs.9500166", "10.3406/colan.1981.1409.1", "10.1093/bioinformatics/bti141", "10.1111/j.1467-8306.2004.09401004.x", "10.1145/1168149.1168168", "10.1109/tvcg.2017.2744184", "10.1117/12.2079420", "10.1109/iv.2005.62", "10.1145/102377.115768", "10.1109/tvcg.2014.2346677", "10.1109/tvcg.2014.2346426", "10.1111/j.1467-8659.2012.03107.x", "10.5220/0006097400400051", "10.2991/978-94-6239-186-4", "10.2307/2284077", "10.1109/iv.2008.89", "10.1016/j.jvlc.2015.12.001", "10.1109/pacificvis.2013.6596147", "10.1145/1242572.1242826", "10.1016/j.cag.2007.01.030", "10.1111/cgf.12632", "10.2312/eurovisstar.20151113", "10.1559/152304009788188808"], "wos": 1, "children": [{"doi": "10.1109/vast.2018.8802486", "title": "SMARTexplore: Simplifying High-Dimensional Data Analysis through a Table-Based Visual Analytics Approach", "year": "2018", "conferenceName": "VAST", "authors": "Michael Blumenschein;Michael Behrisch;Stefanie Schmid;Simon Butscher;Deborah Wahl;Karoline Villinger;Britta Renner;Harald Reiterer;Daniel A. Keim", "citationCount": "0", "affiliation": "Blumenschein, M (Corresponding Author), Univ Konstanz, Constance, Germany. Blumenschein, Michael; Schmid, Stefanie; Butscher, Simon; Wahl, Deborah R.; Villinger, Karoline; Renner, Britta; Reiterer, Harald; Keim, Daniel A., Univ Konstanz, Constance, Germany. Behrisch, Michael, Harvard Univ, Cambridge, MA 02138 USA.", "countries": "Germany;USA", "abstract": "We present SMARTEXPLORE, a novel visual analytics technique that simplifies the identification and understanding of clusters, correlations, and complex patterns in high-dimensional data. The analysis is integrated into an interactive table-based visualization that maintains a consistent and familiar representation throughout the analysis. The visualization is tightly coupled with pattern matching, subspace analysis, reordering, and layout algorithms. To increase the analyst's trust in the revealed patterns, SMARTEXPLORE automatically selects and computes statistical measures based on dimension and data properties. While existing approaches to analyzing high-dimensional data (e.g., planar projections and Parallel coordinates) have proven effective, they typically have steep learning curves for non-visualization experts. Our evaluation, based on three expert case studies, confirms that non-visualization experts successfully reveal patterns in high-dimensional data when using SMARTEXPLORE.", "keywords": "High-dimensional data,visual exploration,pattern-driven analysis,tabular visualization,subspace,aggregation", "link": "http://dx.doi.org/10.1109/VAST.2018.8802486", "refList": ["10.1177/1473871612460526", "10.1109/tvcg.2015.2489649", "10.1111/j.1467-8659.2008.01241.x", "10.1007/978-3-319-25087-8\\_29", "10.1007/b98835", "10.13140/rg.2.2.16570.90567", "10.1109/tvcg.2014.2346260", "10.1109/vast.2009.5332628", "10.2307/2528823", "10.1109/tvcg.2010.184", "10.1145/1133265.1133318", "10.1057/palgrave.ivs.9500072", "10.1111/j.1467-8659.2012.03110.x", "10.1145/1007730.1007731", "10.1057/palgrave.ivs.9500086", "10.1111/cgf.12935", "10.1109/tvcg.2014.2346279", "10.1007/bf01898350", "10.1109/tvcg.2013.173", "10.1109/tvcg.2017.2672987", "10.1109/tvcg.2014.2346248", "10.1109/infvis.2004.46", "10.1109/vast.2010.5652433", "10.1109/vast.2009.5332611", "10.1109/tvcg.2015.2467553", "10.1109/tvcg.2015.2468078", "10.1109/tvcg.2017.2744098", "10.1109/tvcg.2013.150", "10.1109/tvcg.2016.2640960", "10.1111/cgf.12630", "10.1007/978-1-4757-1904-8", "10.1109/tvcg.2011.188", "10.1109/tvcg.2010.138", "10.1109/tvcg.2017.2745078", "10.1109/tvcg.2017.2743978", "10.1111/cgf.12879", "10.1109/iv.2008.33", "10.1111/cgf.13446", "10.1007/s00371-018-1483-0", "10.1109/infvis.1998.729559", "10.1145/2669557.2669572", "10.1111/j.1467-8659.2008.01239.x"], "wos": 1, "children": [], "len": 1}, {"doi": "10.1109/tvcg.2019.2934541", "title": "A Recursive Subdivision Technique for Sampling Multi-class Scatterplots", "year": "2019", "conferenceName": "InfoVis", "authors": "Xin Chen;Tong Ge;Jian Zhang 0070;Baoquan Chen;Chi-Wing Fu;Oliver Deussen;Yunhai Wang", "citationCount": "5", "affiliation": "Chen, X (Corresponding Author), Shandong Univ, Jinan, Shandong, Peoples R China. Chen, Xin; Ge, Tong; Wang, Yunhai, Shandong Univ, Jinan, Shandong, Peoples R China. Chen, Baoquan, Peking Univ, Beijing, Peoples R China. Fu, Chi-Wing, Chinese Univ Hong Kong, Hong Kong, Peoples R China. Fu, Chi-Wing, SIAT, Guangdong Prov Key Lab CV \\& VR Tech, Shenzhen, Guangdong, Peoples R China. Zhang, Jian, Chinese Acad Sci, CNIC, Beijing, Peoples R China. Deussen, Oliver, Konstanz Univ, Constance, Germany. Deussen, Oliver, SIAT, Shenzhen VIsuCA Key Lab, Shenzhen, Guangdong, Peoples R China.", "countries": "Germany;China", "abstract": "We present a non-uniform recursive sampling technique for multi-class scatterplots, with the specific goal of faithfully presenting relative data and class densities, while preserving major outliers in the plots. Our technique is based on a customized binary kd-tree, in which leaf nodes are created by recursively subdividing the underlying multi-class density map. By backtracking, we merge leaf nodes until they encompass points of all classes for our subsequently applied outlier-aware multi-class sampling strategy. A quantitative evaluation shows that our approach can better preserve outliers and at the same time relative densities in multi-class scatterplots compared to the previous approaches, several case studies demonstrate the effectiveness of our approach in exploring complex and real world data.", "keywords": "Scatterplot,multi-class sampling,kd-tree,outlier,relative density", "link": "http://dx.doi.org/10.1109/TVCG.2019.2934541", "refList": ["10.1057/palgrave.ivs.9500122", "10.1109/tvcg.2006.170", "10.1109/tvcg.2008.119", "10.1109/tvcg.2007.70580", "10.2307/2289444", "10.1145/1964921.1964943", "10.1109/tvcg.2013.65", "10.1109/tvcg.2011.229", "10.1109/iv.2004.1320207", "10.1109/itoec.2018.8740621", "10.1145/1778765.1778816", "10.1109/tvcg.2010.197", "10.1201/b17511", "10.1109/tvcg.2018.2864912", "10.1007/0-387-28695-0", "10.1109/5.726791", "10.1109/visual.1998.745301", "10.1016/j.physa.2011.12.004", "10.1145/1556262.1556289", "10.1109/tvcg.2007.70535", "10.1109/tvcg.2017.2674978", "10.1109/tvcg.2004.1272729", "10.1145/335191.335388", "10.1109/tvcg.2014.2346594", "10.1109/tvcg.2017.2744184", "10.1109/iv.2002.1028760", "10.1145/1842993.1842999", "10.1109/tvcg.2018.2869149", "10.1038/nmeth.2490", "10.1109/tvcg.2013.153", "10.1111/cgf.13446", "10.1109/tvcg.2010.176", "10.1145/2702123.2702585", "10.1057/ivs.2009.34"], "wos": 1, "children": [{"doi": "10.1109/tvcg.2020.3030443", "title": "CAVA: A Visual Analytics System for Exploratory Columnar Data Augmentation Using Knowledge Graphs", "year": "2020", "conferenceName": "VAST", "authors": "Dylan Cashman;Shenyu Xu;Subhajit Das;Florian Heimerl;Cong Liu;Shah Rukh Humayoun;Michael Gleicher;Alex Endert;Remco Chang", "citationCount": "0", "affiliation": "Cashman, D (Corresponding Author), Tufts Univ, Medford, MA 02155 USA. Cashman, Dylan; Liu, Cong; Chang, Remco, Tufts Univ, Medford, MA 02155 USA. Xu, Shenyu; Das, Subhajit; Endert, Alex, Georgia Tech, Atlanta, GA USA. Heimerl, Florian; Gleicher, Michael, Univ Wisconsin, Madison, WI 53706 USA. Humayoun, Shah Rukh, San Francisco State Univ, San Francisco, CA 94132 USA.", "countries": "USA", "abstract": "Most visual analytics systems assume that all foraging for data happens before the analytics process; once analysis begins, the set of data attributes considered is fixed. Such separation of data construction from analysis precludes iteration that can enable foraging informed by the needs that arise in-situ during the analysis. The separation of the foraging loop from the data analysis tasks can limit the pace and scope of analysis. In this paper, we present CAVA, a system that integrates data curation and data augmentation with the traditional data exploration and analysis tasks, enabling information foraging in-situ during analysis. Identifying attributes to add to the dataset is difficult because it requires human knowledge to determine which available attributes will be helpful for the ensuing analytical tasks. CAVA crawls knowledge graphs to provide users with a a broad set of attributes drawn from external data to choose from. Users can then specify complex operations on knowledge graphs to construct additional attributes. CAVA shows how visual analytics can help users forage for attributes by letting users visually explore the set of available data, and by serving as an interface for query construction. It also provides visualizations of the knowledge graph itself to help users understand complex joins such as multi-hop aggregations. We assess the ability of our system to enable users to perform complex data combinations without programming in a user study over two datasets. We then demonstrate the generalizability of CAVA through two additional usage scenarios. The results of the evaluation confirm that CAVA is effective in helping the user perform data foraging that leads to improved analysis outcomes, and offer evidence in support of integrating data augmentation as a part of the visual analytics pipeline.", "keywords": "Visual Analytics,Information Foraging,Data Augmentation", "link": "http://dx.doi.org/10.1109/TVCG.2020.3030443", "refList": ["10.1057/palgrave.ivs.9500122", "10.1109/tvcg.2016.2598867", "10.1111/cgf.13708", "10.1109/tvcg.2019.2934799", "10.1109/tvcg.2019.2934541", "10.1109/tvcg.2013.65", "10.1109/tvcg.2018.2875702", "10.1109/iv.2004.1320207", "10.1068/p260471", "10.1145/1778765.1778816", "10.1109/tvcg.2018.2808489", "10.1109/tvcg.2018.2864912", "10.1016/j.apgeog.2015.12.006", "10.1111/j.1467-8659.2011.01960.x", "10.1109/tvcg.2018.2864843", "10.1109/pacificvis.2010.5429604", "10.1109/tvcg.2014.2346898", "10.1109/5.726791", "10.1177/1475090214540874", "10.1109/icde.2016.7498287", "10.1145/1556262.1556289", "10.1109/tvcg.2007.70535", "10.1109/vast.2012.6400489", "10.1145/1056808.1056914", "10.1016/j.neucom.2014.09.063", "10.1145/7529.8927", "10.1109/tvcg.2016.2598495", "10.1109/tvcg.2016.2607204", "10.1109/vast47406.2019.8986943", "10.3758/bf03205986", "10.1109/infvis.2005.1532142", "10.1145/1150402.1150479", "10.1109/tvcg.2017.2674978", "10.1109/tvcg.2019.2945960", "10.1109/tvcg.2017.2744098", "10.1109/tvcg.2017.2674999", "10.1109/tvcg.2011.279", "10.1109/tvcg.2014.2346594", "10.1109/tvcg.2017.2744184", "10.1111/cgf.12876", "10.1007/s4095-020-0191-7", "10.1007/s11390-015-1535-0", "10.1111/cgf.12640", "10.1109/tvcg.2016.2598667", "10.1111/cgf.13683", "10.1109/tvcg.2013.153", "10.1109/tvcg.2019.2934208", "10.1109/tvcg.2019.2934655", "10.1111/cgf.12655", "10.1007/s11023-010-9221-z", "10.1109/vast.2012.6400487", "10.1145/2702123.2702585", "10.1007/bf00310175", "10.1109/tvcg.2017.2744378", "10.1103/physreve.64.061907", "10.1109/ldav.2017.8231848", "10.1109/tvcg.2016.2598831"], "wos": 1, "children": [], "len": 1}, {"doi": "10.1109/tvcg.2020.3030432", "title": "Evaluation of Sampling Methods for Scatterplots", "year": "2020", "conferenceName": "VAST", "authors": "Jun Yuan;Shouxing Xiang;Jiazhi Xia;Lingyun Yu;Shixia Liu", "citationCount": "0", "affiliation": "Liu, SX (Corresponding Author), Tsinghua Univ, BNRist, Beijing, Peoples R China. Yuan, Jun; Xiang, Shouxing; Liu, Shixia, Tsinghua Univ, BNRist, Beijing, Peoples R China. Xia, Jiazhi, Cent South Univ, Changsha, Peoples R China. Yu, Lingyun, Xian Jiaotong Liverpool Univ, Suzhou, Peoples R China.", "countries": "China", "abstract": "Given a scatterplot with tens of thousands of points or even more, a natural question is which sampling method should be used to create a small but \u201cgood\u201d scatterplot for a better abstraction. We present the results of a user study that investigates the influence of different sampling strategies on multi-class scatterplots. The main goal of this study is to understand the capability of sampling methods in preserving the density, outliers, and overall shape of a scatterplot. To this end, we comprehensively review the literature and select seven typical sampling strategies as well as eight representative datasets. We then design four experiments to understand the performance of different strategies in maintaining: 1) region density; 2) class density; 3) outliers; and 4) overall shape in the sampling results. The results show that: 1) random sampling is preferred for preserving region density; 2) blue noise sampling and random sampling have comparable performance with the three multi-class sampling strategies in preserving class density; 3) outlier biased density based sampling, recursive subdivision based sampling, and blue noise sampling perform the best in keeping outliers; and 4) blue noise sampling outperforms the others in maintaining the overall shape of a scatterplot.", "keywords": "Scatterplot,data sampling,empirical evaluation", "link": "http://dx.doi.org/10.1109/TVCG.2020.3030432", "refList": ["10.1057/palgrave.ivs.9500122", "10.1109/tvcg.2016.2598867", "10.1109/tvcg.2015.2467591", "10.1111/cgf.13708", "10.1109/tvcg.2019.2934799", "10.1109/tvcg.2019.2934541", "10.1109/tvcg.2013.65", "10.1109/iv.2004.1320207", "10.1068/p260471", "10.1145/1778765.1778816", "10.1109/tvcg.2018.2808489", "10.1109/tvcg.2018.2864912", "10.1016/j.apgeog.2015.12.006", "10.1111/j.1467-8659.2011.01960.x", "10.1109/tvcg.2018.2864843", "10.1109/pacificvis.2010.5429604", "10.1109/tvcg.2014.2346898", "10.1109/5.726791", "10.1177/1475090214540874", "10.1145/1556262.1556289", "10.1109/tvcg.2007.70535", "10.1109/vast.2012.6400489", "10.1145/1056808.1056914", "10.1016/j.neucom.2014.09.063", "10.1145/7529.8927", "10.1109/tvcg.2016.2607204", "10.1109/vast47406.2019.8986943", "10.3758/bf03205986", "10.1109/infvis.2005.1532142", "10.1145/1150402.1150479", "10.1109/tvcg.2017.2674978", "10.1109/tvcg.2017.2744098", "10.1109/tvcg.2017.2674999", "10.1109/tvcg.2011.279", "10.1109/tvcg.2014.2346594", "10.1109/tvcg.2017.2744184", "10.1111/cgf.12876", "10.1109/1011101.2019.2945960", "10.1007/s4095-020-0191-7", "10.1007/s11390-015-1535-0", "10.1111/cgf.12640", "10.1109/tvcg.2016.2598667", "10.1111/cgf.13683", "10.1109/tvcg.2013.153", "10.1109/tvcg.2019.2934208", "10.1109/tvcg.2019.2934655", "10.1111/cgf.12655", "10.1007/s11023-010-9221-z", "10.1109/vast.2012.6400487", "10.1145/2702123.2702585", "10.1007/bf00310175", "10.1109/tvcg.2017.2744378", "10.1103/physreve.64.061907", "10.1109/ldav.2017.8231848", "10.1109/tvcg.2016.2598831"], "wos": 1, "children": [], "len": 1}, {"doi": "10.1109/tvcg.2020.3030365", "title": "Modeling the Influence of Visual Density on Cluster Perception in Scatterplots Using Topology", "year": "2020", "conferenceName": "InfoVis", "authors": "Ghulam Jilani Quadri;Paul Rosen", "citationCount": "0", "affiliation": "Quadri, GJ (Corresponding Author), Univ S Florida, Tampa, FL 33620 USA. Quadri, Ghulam Jilani; Rosen, Paul, Univ S Florida, Tampa, FL 33620 USA.", "countries": "USA", "abstract": "Scatterplots are used for a variety of visual analytics tasks, including cluster identification, and the visual encodings used on a scatterplot play a deciding role on the level of visual separation of clusters. For visualization designers, optimizing the visual encodings is crucial to maximizing the clarity of data. This requires accurately modeling human perception of cluster separation, which remains challenging. We present a multi-stage user study focusing on four factors-distribution size of clusters, number of points, size of points, and opacity of points-that influence cluster identification in scatterplots. From these parameters, we have constructed two models, a distance-based model, and a density-based model, using the merge tree data structure from Topological Data Analysis. Our analysis demonstrates that these factors play an important role in the number of clusters perceived, and it verifies that the distance-based and density-based models can reasonably estimate the number of clusters a user observes. Finally, we demonstrate how these models can be used to optimize visual encodings on real-world data.", "keywords": "Scatterplot,clustering,perception,empirical evaluation,visual encoding,crowdsourcing,topological data analysis", "link": "http://dx.doi.org/10.1109/TVCG.2020.3030365", "refList": ["10.1109/tvcg.2017.2744359", "10.1145/1778765", "10.1109/tvcg.2019.2934799", "10.1111/cgf.12889", "10.1109/tvcg.2011.127", "10.1111/cgf.13444", "10.1145/1964897.1964910", "10.1167/8.7.6", "10.1145/3173574.3173991", "10.1145/1556262.1556289", "10.1145/1056808.1056914", "10.2307/2288400", "10.1109/tvcg.2014.2346594", "10.1109/iv.2002.1028760", "10.1177/001316447303300111", "10.1007/bf02289823", "10.1109/tvcg.2017.2744339", "10.1111/j.1467-8659.2009.01694.x", "10.1109/tvcg.2014.2346979", "10.1090/mbk/069", "10.1109/tvcg.2013.65", "10.1109/mcg.2012.37", "10.1109/pacificvis.2010.5429604", "10.1002/acp.2350050106", "10.1109/infvis.2005.1532136", "10.1177/1473871612465214", "10.1109/tvcg.2017.2674978", "10.1002/jhbs.20078", "10.1007/978-3-642-35142-6\\_14", "10.1007/978-3-319-71507-0", "10.1109/mcg.201.7.6", "10.3758/bf03193961", "10.1364/josa.49.000280", "10.1145/3025453.3025905", "10.1109/tvcg.201.9.2934541", "10.1109/tvcg.2018.2829750", "10.1177/1473871615606187", "10.1111/cgf.13408", "10.1109/pacificvis.2016.7465252", "10.1109/pacificvis.2016.7465244", "10.1109/inevis.2005.1532142", "10.1111/cgf.13414", "10.1111/j.1467-8659.2012.03125.x", "10.1167/16.5.11", "10.1109/infvis.2005.1532142", "10.1145/2858036.2858155", "10.1038/nmeth1210-941", "10.1177/1473871616638892", "10.1109/tcbb.2014.2306840", "10.1111/cgf.13684", "10.1177/0301006615602599", "10.1214/aoms/1177731915", "10.1145/2702123.2702585", "10.1109/tvcg.2013.183", "10.1109/tvcg.2014.2346572", "10.1109/tvcg.2018.2875702", "10.1109/tvcg.2017.2754480", "10.1109/vast.2014.7042493", "10.1057/palgrave.ivs.9500122", "10.1109/tvcg.2014.2330617", "10.1109/tvcg.2019.2934541", "10.1068/p030033", "10.1140/epjds/s13688-017-0109-5", "10.1201/b17511", "10.1016/s0925-7721(02)00093-7", "10.1109/pacificvis.2012.6183557", "10.1109/tvcg.2014.2346983", "10.1109/5.726791", "10.1080/01621459.1926.10502165", "10.1109/tvcg.2007.70535", "10.1109/tvcg.2018.2864907", "10.1111/cgf.12109", "10.1109/tvcg.2017.2744184", "10.1146/annurev-statistics-031017-100045", "10.1111/cgf.13409", "10.1145/3002151.3002162", "10.1016/s0378-4371(98)00494-4", "10.3138/y308-2422-8615-1233", "10.1111/cgf.12632", "10.1145/3290605.3300771"], "wos": 1, "children": [], "len": 1}, {"doi": "10.1111/cgf.14001", "year": "2020", "title": "Sunspot Plots: Model-based Structure Enhancement for Dense Scatter Plots", "conferenceName": "EuroVis", "authors": "Thomas Trautner;Fabian Bolte;Sergej Stoppel;Stefan Bruckner", "citationCount": "0", "affiliation": "Trautner, T (Corresponding Author), Univ Bergen, Bergen, Norway.\nTrautner, T.; Bolte, F.; Stoppel, S.; Bruckner, S., Univ Bergen, Bergen, Norway.", "countries": "Norway", "abstract": "Scatter plots are a powerful and well-established technique for visualizing the relationships between two variables as a collection of discrete points. However, especially when dealing with large and dense data, scatter plots often exhibit problems such as overplotting, making the data interpretation arduous. Density plots are able to overcome these limitations in highly populated regions, but fail to provide accurate information of individual data points. This is particularly problematic in sparse regions where the density estimate may not provide a good representation of the underlying data. In this paper, we present sunspot plots, a visualization technique that communicates dense data as a continuous data distribution, while preserving the discrete nature of data samples in sparsely populated areas. We furthermore demonstrate the advantages of our approach on typical failure cases of scatter plots within synthetic and real-world data sets and validate its effectiveness in a user study.", "keywords": "", "link": "https://doi.org/10.1111/cgf.14001", "refList": ["10.1057/palgrave.ivs.9500122", "10.2312/eggh/hpg12/097-103", "10.1109/tvcg.2008.119", "10.1109/pacificvis.2011.5742387", "10.1038/331163a0", "10.1109/visual.2019.8933620", "10.2307/2683294", "10.1201/9781351072304", "10.2307/2289444", "10.1109/tvcg.2019.2934541", "10.1080/00949657508810123", "10.1109/tvcg.2013.65", "10.1109/infvis.1997.636789", "10.1109/2945.841121", "10.1109/mcse.2007.55", "10.1109/tvcg.2010.197", "10.1111/cgf.12871", "10.1109/infvis.2003.1249018", "10.1145/3173574.3173991", "10.1109/tvcg.2012.238", "10.1007/0-387-28695-0", "10.1109/pacificvis.2010.5429604", "10.18637/jss.v008.i03", "10.1109/tvcg.2007.70596", "10.1109/visual.1998.745301", "10.1007/0-387-37977-0\\_3", "10.1145/1556262.1556289", "10.2312/wiced.20161094", "10.1109/tvcg.2007.70535", "10.1145/1056808.1056914", "10.1109/tvcg.2003.1196007", "10.1109/iv.2004.1320190", "10.1111/cgf.12877", "10.1162/leon.2007.40.2.202a", "10.1109/tvcg.2017.2674978", "10.1057/ivs.2010.4", "10.1016/j.cag.2018.02.008", "10.1201/9781315140919", "10.1109/visual.2000.885677", "10.1002/jhbs.20078", "10.1109/tvcg.2014.2346594", "10.1109/tvcg.2017.2744184", "10.1109/visual.2001.964495", "10.1109/iv.2002.1028760", "10.1111/cgf.13684", "10.1109/hicss.2013.197", "10.1109/tvcg.2019.2903956", "10.1093/mnras/stt961", "10.1109/tvcg.2017.2668409", "10.1111/j.1467-8659.2009.01478.x", "10.1145/2702123.2702585", "10.2307/1418003", "10.2307/1390742", "10.1145/360825.360839", "10.1109/pacificvis.2009.4906843", "10.1057/ivs.2009.34", "10.2307/2288711"], "wos": 1, "children": [], "len": 1}], "len": 9}, {"doi": "10.1109/tvcg.2019.2934284", "title": "Color Crafting: Automating the Construction of Designer Quality Color Ramps", "year": "2019", "conferenceName": "InfoVis", "authors": "Stephen Smart;Keke Wu;Danielle Albers Szafir", "citationCount": "3", "affiliation": "Smart, S (Corresponding Author), Univ Colorado, Boulder, CO 80309 USA. Smart, Stephen; Wu, Keke; Szafir, Danielle Albers, Univ Colorado, Boulder, CO 80309 USA.", "countries": "USA", "abstract": "Visualizations often encode numeric data using sequential and diverging color ramps. Effective ramps use colors that are sufficiently discriminable, align well with the data, and are aesthetically pleasing. Designers rely on years of experience to create high-quality color ramps. However, it is challenging for novice visualization developers that lack this experience to craft effective ramps as most guidelines for constructing ramps are loosely defined qualitative heuristics that are often difficult to apply. Our goal is to enable visualization developers to readily create effective color encodings using a single seed color. We do this using an algorithmic approach that models designer practices by analyzing patterns in the structure of designer-crafted color ramps. We construct these models from a corpus of 222 expert-designed color ramps, and use the results to automatically generate ramps that mimic designer practices. We evaluate our approach through an empirical study comparing the outputs of our approach with designer-crafted color ramps. Our models produce ramps that support accurate and aesthetically pleasing visualizations at least as well as designer ramps and that outperform conventional mathematical approaches.", "keywords": "Visualization,Aesthetics in Visualization,Color Perception,Visual Design,Design Mining", "link": "http://dx.doi.org/10.1109/TVCG.2019.2934284", "refList": ["10.1145/3009924", "10.1109/tvcg.2015.2489649", "10.1109/tvcg.2017.2744359", "10.1002/(sici)1098-1098(199622)7:2", "10.1016/s0734-189x(83)80046-2", "10.1109/tvcg.2016.2599106", "10.1364/josaa.29.000313", "10.1109/tvcg.2016.2598918", "10.2307/2683294", "10.1109/tvcg.2017.2653106", "10.1016/j.ijhcs.2010.05.006", "10.1016/0146-664x(81)90006-x", "10.1007/978-3-642-10520-3\\_9", "10.1109/38.135886", "10.1146/annurev-psych-120710-100504", "10.1016/j.csda.2008.11.033", "10.1145/2461912.2461988", "10.1016/j.cub.2007.06.022", "10.1016/s0146-664x(79)80040-4", "10.1109/mcg.2004.1297012", "10.1109/iv.2009.94", "10.1109/tpami.2010.184", "10.3758/s13414-010-0027-0", "10.1145/22949.22950", "10.1109/visual.1995.480803", "10.1109/tvcg.2014.2346277", "10.2307/2684111", "10.1109/tvcg.2018.2865240", "10.1111/cgf.12633", "10.1109/38.7760", "10.1016/j.jspi.2015.04.007", "10.1109/iv.2008.24", "10.1145/2939502.2939506", "10.1111/cgf.12127", "10.1016/j.cag.2010.11.015", "10.1145/3025453.3026041", "10.1109/tvcg.2012.315", "10.2307/2288400", "10.1511/2005.5.436", "10.1016/s0097-8493(96)00072-6", "10.1109/mcg.2018.011461525", "10.1145/2470654.2466420", "10.1109/tvcg.2012.279", "10.1109/tvcg.2014.2346978", "10.1109/tvcg.2017.2743978", "10.1145/3406601.3406602", "10.1117/12.2084548", "10.1109/tvcg.2018.2865147", "10.1109/tvcg.2015.2467191", "10.1111/cgf.13446", "10.1109/tvcg.2017.2744320", "10.1111/j.1467-8659.2008.01203.x", "10.1145/2702613.2702975", "10.1007/978-3-319-26633-6\\_13", "10.1145/2207676.2208547", "10.1109/tvcg.2008.174", "10.1179/000870403235002042"], "wos": 1, "children": [{"doi": "10.1109/tvcg.2020.3028891", "title": "A Structured Review of Data Management Technology for Interactive Visualization and Analysis", "year": "2020", "conferenceName": "InfoVis", "authors": "Leilani Battle;Carlos Scheidegger", "citationCount": "0", "affiliation": "Battle, L (Corresponding Author), Univ Maryland, Dept Comp Sci, College Pk, MD 20742 USA. Battle, Leilani, Univ Maryland, Dept Comp Sci, College Pk, MD 20742 USA. Scheidegger, Carlos, Univ Arizona, Dept Comp Sci, HDC Lab, Tucson, AZ 85721 USA.", "countries": "USA", "abstract": "In the last two decades, interactive visualization and analysis have become a central tool in data-driven decision making. Concurrently to the contributions in data visualization, research in data management has produced technology that directly benefits interactive analysis. Here, we contribute a systematic review of 30 years of work in this adjacent field, and highlight techniques and principles we believe to be underappreciated in visualization work. We structure our review along two axes. First, we use task taxonomies from the visualization literature to structure the space of interactions in usual systems. Second, we created a categorization of data management work that strikes a balance between specificity and generality. Concretely, we contribute a characterization of 131 research papers along these two axes. We find that five notions in data management venues fit interactive visualization systems well: materialized views, approximate query processing, user modeling and query prediction, muiti-query optimization, lineage techniques, and indexing techniques. In addition, we find a preponderance of work in materialized views and approximate query processing, most targeting a limited subset of the interaction tasks in the taxonomy we used. This suggests natural avenues of future research both in visualization and data management. Our categorization both changes how we visualization researchers design and build our systems, and highlights where future work is necessary.", "keywords": "", "link": "http://dx.doi.org/10.1109/TVCG.2020.3028891", "refList": ["10.1109/tvcg.2012.233", "10.1016/s0022-5371(74)80015-0", "10.1109/tvcg.2017.2744359", "10.1037/0096-3445.136.4.623", "10.1109/tvcg.2015.2467732", "10.1109/tvcg.2012.196", "10.1037/a0029856", "10.1109/tvcg.2014.2346979", "10.1037/h0030300", "10.1109/tvcg.2016.2598918", "10.1109/beliv.2018.8634420", "10.1109/tvcg.2018.2864909", "10.1111/cgf.13079", "10.3389/fpsyg.2012.00355", "10.1145/2858036.2858465", "10.1080/01621459.1989.10478821", "10.1037/0278-7393.24.3.732", "10.1109/tvcg.2011.127", "10.1145/2858036.2858063", "10.4249/scholarpedia.3325", "10.4324/9781410611949", "10.1111/cgf.13444", "10.1145/2993901.2993909", "10.1037/0033-295x.96.2.267", "10.1006/ijhc.1017", "10.1086/405615", "10.1109/tvcg.2019.2934801", "10.1038/17953", "10.1037/xhp0000314", "10.1109/tvcg.2019.2934400", "10.1145/2470654.2470723", "10.1037/0096-1523.16.2.332", "10.1167/16.5.11", "10.3758/s13423-016-1174-7", "10.3758/bf03207704", "10.1146/annurev.psych.55.090902.141415", "10.2307/2288400", "10.3758/bf03204258", "10.1109/tvcg.2011.279", "10.1109/vissoft.2014.36", "10.3758/s13423-011-0055-3", "10.1145/3025453.3025922", "10.1109/tvcg.2019.2934284", "10.3758/bf03210498", "10.3758/bf03200774", "10.2307/1419876", "10.1038/s41562-017-0058", "10.1109/tvcg.2010.237", "10.1109/pacificvis.2012.6183556", "10.1109/infvis.1997.636792", "10.1093/acprof:oso/9780198523192.003.0005", "10.1073/pnas.1117465109", "10.1109/tvcg.2013.234", "10.1038/nn.3655", "10.1111/cgf.12379", "10.1146/annurev-psych-010416-044232", "10.1111/cgf.13695", "10.1037/0033-295x.107.3.500", "10.1109/tvcg.2013.183", "10.1146/annurev.psych.53.100901.135125", "10.1037//0022-3514.79.6.995", "10.1559/152304003100010929", "10.1109/tvcg.2018.2865147", "10.1037/0096-1523.18.3.849", "10.1111/j.1467-8659.2009.01694.x", "10.1145/3290605.3300771"], "wos": 1, "children": [], "len": 1}], "len": 3}, {"doi": "10.1109/tvcg.2019.2934799", "title": "Data Sampling in Multi-view and Multi-class Scatterplots via Set Cover Optimization", "year": "2019", "conferenceName": "InfoVis", "authors": "Ruizhen Hu;Tingkai Sha;Oliver van Kaick;Oliver Deussen;Hui Huang 0004", "citationCount": "4", "affiliation": "Hu, RZ (Corresponding Author), Shenzhen Univ, Visual Comp Res Ctr, Shenzhen, Guangdong, Peoples R China. Hu, Ruizhen; Sha, Tingkai; Huang, Hui, Shenzhen Univ, Visual Comp Res Ctr, Shenzhen, Guangdong, Peoples R China. van Kaick, Oliver, Carleton Univ, Sch Comp Sci, Ottawa, ON, Canada. Deussen, Oliver, Konstanz Univ, Constance, Germany. Deussen, Oliver, SIAT, Shenzhen VisuCA Key Lab, Shenzhen, Guangdong, Peoples R China.", "countries": "Canada;Germany;China", "abstract": "We present a method for data sampling in scatterplots by jointly optimizing point selection for different views or classes. Our method uses space-filling curves (Z-order curves) that partition a point set into subsets that, when covered each by one sample, provide a sampling or coreset with good approximation guarantees in relation to the original point set. For scatterplot matrices with multiple views, different views provide different space-filling curves, leading to different partitions of the given point set. For multi-class scatterplots, the focus on either per-class distribution or global distribution provides two different partitions of the given point set that need to be considered in the selection of the coreset. For both cases, we convert the coreset selection problem into an Exact Cover Problem (ECP), and demonstrate with quantitative and qualitative evaluations that an approximate solution that solves the ECP efficiently is able to provide high-quality samplings.", "keywords": "Sampling,Scatterplot,SPLOM,Exact Cover Problem", "link": "http://dx.doi.org/10.1109/TVCG.2019.2934799", "refList": ["10.1057/palgrave.ivs.9500122", "10.1109/tvcg.2006.170", "10.1109/tvcg.2008.119", "10.1111/j.1467-8659.2009.01467.x", "10.2307/2289444", "10.1109/tvcg.2013.65", "10.1109/tvcg.2011.229", "10.1109/iv.2004.1320207", "10.1109/itoec.2018.8740621", "10.1145/1778765.1778816", "10.1109/tvcg.2018.2864912", "10.1007/0-387-28695-0", "10.1109/visual.1998.745301", "10.1287/moor.4.3.233", "10.1145/1556262.1556289", "10.1109/tvcg.2007.70535", "10.2307/2284239", "10.1109/tvcg.2017.2674978", "10.1016/j.dss.2009.05.016", "10.1109/tvcg.2014.2346594", "10.1109/vds.2017.8573446", "10.1007/978-1-4684-2001-2\\_9", "10.1109/iv.2002.1028760", "10.1145/1842993.1842999", "10.1038/nmeth.2490", "10.1109/tvcg.2013.153", "10.1111/cgf.13446", "10.1109/tvcg.2010.176", "10.1145/2702123.2702585", "10.1057/ivs.2009.34", "10.1179/000870403235002042"], "wos": 1, "children": [{"doi": "10.1109/tvcg.2020.3030443", "title": "CAVA: A Visual Analytics System for Exploratory Columnar Data Augmentation Using Knowledge Graphs", "year": "2020", "conferenceName": "VAST", "authors": "Dylan Cashman;Shenyu Xu;Subhajit Das;Florian Heimerl;Cong Liu;Shah Rukh Humayoun;Michael Gleicher;Alex Endert;Remco Chang", "citationCount": "0", "affiliation": "Cashman, D (Corresponding Author), Tufts Univ, Medford, MA 02155 USA. Cashman, Dylan; Liu, Cong; Chang, Remco, Tufts Univ, Medford, MA 02155 USA. Xu, Shenyu; Das, Subhajit; Endert, Alex, Georgia Tech, Atlanta, GA USA. Heimerl, Florian; Gleicher, Michael, Univ Wisconsin, Madison, WI 53706 USA. Humayoun, Shah Rukh, San Francisco State Univ, San Francisco, CA 94132 USA.", "countries": "USA", "abstract": "Most visual analytics systems assume that all foraging for data happens before the analytics process; once analysis begins, the set of data attributes considered is fixed. Such separation of data construction from analysis precludes iteration that can enable foraging informed by the needs that arise in-situ during the analysis. The separation of the foraging loop from the data analysis tasks can limit the pace and scope of analysis. In this paper, we present CAVA, a system that integrates data curation and data augmentation with the traditional data exploration and analysis tasks, enabling information foraging in-situ during analysis. Identifying attributes to add to the dataset is difficult because it requires human knowledge to determine which available attributes will be helpful for the ensuing analytical tasks. CAVA crawls knowledge graphs to provide users with a a broad set of attributes drawn from external data to choose from. Users can then specify complex operations on knowledge graphs to construct additional attributes. CAVA shows how visual analytics can help users forage for attributes by letting users visually explore the set of available data, and by serving as an interface for query construction. It also provides visualizations of the knowledge graph itself to help users understand complex joins such as multi-hop aggregations. We assess the ability of our system to enable users to perform complex data combinations without programming in a user study over two datasets. We then demonstrate the generalizability of CAVA through two additional usage scenarios. The results of the evaluation confirm that CAVA is effective in helping the user perform data foraging that leads to improved analysis outcomes, and offer evidence in support of integrating data augmentation as a part of the visual analytics pipeline.", "keywords": "Visual Analytics,Information Foraging,Data Augmentation", "link": "http://dx.doi.org/10.1109/TVCG.2020.3030443", "refList": ["10.1057/palgrave.ivs.9500122", "10.1109/tvcg.2016.2598867", "10.1111/cgf.13708", "10.1109/tvcg.2019.2934799", "10.1109/tvcg.2019.2934541", "10.1109/tvcg.2013.65", "10.1109/tvcg.2018.2875702", "10.1109/iv.2004.1320207", "10.1068/p260471", "10.1145/1778765.1778816", "10.1109/tvcg.2018.2808489", "10.1109/tvcg.2018.2864912", "10.1016/j.apgeog.2015.12.006", "10.1111/j.1467-8659.2011.01960.x", "10.1109/tvcg.2018.2864843", "10.1109/pacificvis.2010.5429604", "10.1109/tvcg.2014.2346898", "10.1109/5.726791", "10.1177/1475090214540874", "10.1109/icde.2016.7498287", "10.1145/1556262.1556289", "10.1109/tvcg.2007.70535", "10.1109/vast.2012.6400489", "10.1145/1056808.1056914", "10.1016/j.neucom.2014.09.063", "10.1145/7529.8927", "10.1109/tvcg.2016.2598495", "10.1109/tvcg.2016.2607204", "10.1109/vast47406.2019.8986943", "10.3758/bf03205986", "10.1109/infvis.2005.1532142", "10.1145/1150402.1150479", "10.1109/tvcg.2017.2674978", "10.1109/tvcg.2019.2945960", "10.1109/tvcg.2017.2744098", "10.1109/tvcg.2017.2674999", "10.1109/tvcg.2011.279", "10.1109/tvcg.2014.2346594", "10.1109/tvcg.2017.2744184", "10.1111/cgf.12876", "10.1007/s4095-020-0191-7", "10.1007/s11390-015-1535-0", "10.1111/cgf.12640", "10.1109/tvcg.2016.2598667", "10.1111/cgf.13683", "10.1109/tvcg.2013.153", "10.1109/tvcg.2019.2934208", "10.1109/tvcg.2019.2934655", "10.1111/cgf.12655", "10.1007/s11023-010-9221-z", "10.1109/vast.2012.6400487", "10.1145/2702123.2702585", "10.1007/bf00310175", "10.1109/tvcg.2017.2744378", "10.1103/physreve.64.061907", "10.1109/ldav.2017.8231848", "10.1109/tvcg.2016.2598831"], "wos": 1, "children": [], "len": 1}, {"doi": "10.1109/tvcg.2020.3030432", "title": "Evaluation of Sampling Methods for Scatterplots", "year": "2020", "conferenceName": "VAST", "authors": "Jun Yuan;Shouxing Xiang;Jiazhi Xia;Lingyun Yu;Shixia Liu", "citationCount": "0", "affiliation": "Liu, SX (Corresponding Author), Tsinghua Univ, BNRist, Beijing, Peoples R China. Yuan, Jun; Xiang, Shouxing; Liu, Shixia, Tsinghua Univ, BNRist, Beijing, Peoples R China. Xia, Jiazhi, Cent South Univ, Changsha, Peoples R China. Yu, Lingyun, Xian Jiaotong Liverpool Univ, Suzhou, Peoples R China.", "countries": "China", "abstract": "Given a scatterplot with tens of thousands of points or even more, a natural question is which sampling method should be used to create a small but \u201cgood\u201d scatterplot for a better abstraction. We present the results of a user study that investigates the influence of different sampling strategies on multi-class scatterplots. The main goal of this study is to understand the capability of sampling methods in preserving the density, outliers, and overall shape of a scatterplot. To this end, we comprehensively review the literature and select seven typical sampling strategies as well as eight representative datasets. We then design four experiments to understand the performance of different strategies in maintaining: 1) region density; 2) class density; 3) outliers; and 4) overall shape in the sampling results. The results show that: 1) random sampling is preferred for preserving region density; 2) blue noise sampling and random sampling have comparable performance with the three multi-class sampling strategies in preserving class density; 3) outlier biased density based sampling, recursive subdivision based sampling, and blue noise sampling perform the best in keeping outliers; and 4) blue noise sampling outperforms the others in maintaining the overall shape of a scatterplot.", "keywords": "Scatterplot,data sampling,empirical evaluation", "link": "http://dx.doi.org/10.1109/TVCG.2020.3030432", "refList": ["10.1057/palgrave.ivs.9500122", "10.1109/tvcg.2016.2598867", "10.1109/tvcg.2015.2467591", "10.1111/cgf.13708", "10.1109/tvcg.2019.2934799", "10.1109/tvcg.2019.2934541", "10.1109/tvcg.2013.65", "10.1109/iv.2004.1320207", "10.1068/p260471", "10.1145/1778765.1778816", "10.1109/tvcg.2018.2808489", "10.1109/tvcg.2018.2864912", "10.1016/j.apgeog.2015.12.006", "10.1111/j.1467-8659.2011.01960.x", "10.1109/tvcg.2018.2864843", "10.1109/pacificvis.2010.5429604", "10.1109/tvcg.2014.2346898", "10.1109/5.726791", "10.1177/1475090214540874", "10.1145/1556262.1556289", "10.1109/tvcg.2007.70535", "10.1109/vast.2012.6400489", "10.1145/1056808.1056914", "10.1016/j.neucom.2014.09.063", "10.1145/7529.8927", "10.1109/tvcg.2016.2607204", "10.1109/vast47406.2019.8986943", "10.3758/bf03205986", "10.1109/infvis.2005.1532142", "10.1145/1150402.1150479", "10.1109/tvcg.2017.2674978", "10.1109/tvcg.2017.2744098", "10.1109/tvcg.2017.2674999", "10.1109/tvcg.2011.279", "10.1109/tvcg.2014.2346594", "10.1109/tvcg.2017.2744184", "10.1111/cgf.12876", "10.1109/1011101.2019.2945960", "10.1007/s4095-020-0191-7", "10.1007/s11390-015-1535-0", "10.1111/cgf.12640", "10.1109/tvcg.2016.2598667", "10.1111/cgf.13683", "10.1109/tvcg.2013.153", "10.1109/tvcg.2019.2934208", "10.1109/tvcg.2019.2934655", "10.1111/cgf.12655", "10.1007/s11023-010-9221-z", "10.1109/vast.2012.6400487", "10.1145/2702123.2702585", "10.1007/bf00310175", "10.1109/tvcg.2017.2744378", "10.1103/physreve.64.061907", "10.1109/ldav.2017.8231848", "10.1109/tvcg.2016.2598831"], "wos": 1, "children": [], "len": 1}, {"doi": "10.1109/tvcg.2020.3030365", "title": "Modeling the Influence of Visual Density on Cluster Perception in Scatterplots Using Topology", "year": "2020", "conferenceName": "InfoVis", "authors": "Ghulam Jilani Quadri;Paul Rosen", "citationCount": "0", "affiliation": "Quadri, GJ (Corresponding Author), Univ S Florida, Tampa, FL 33620 USA. Quadri, Ghulam Jilani; Rosen, Paul, Univ S Florida, Tampa, FL 33620 USA.", "countries": "USA", "abstract": "Scatterplots are used for a variety of visual analytics tasks, including cluster identification, and the visual encodings used on a scatterplot play a deciding role on the level of visual separation of clusters. For visualization designers, optimizing the visual encodings is crucial to maximizing the clarity of data. This requires accurately modeling human perception of cluster separation, which remains challenging. We present a multi-stage user study focusing on four factors-distribution size of clusters, number of points, size of points, and opacity of points-that influence cluster identification in scatterplots. From these parameters, we have constructed two models, a distance-based model, and a density-based model, using the merge tree data structure from Topological Data Analysis. Our analysis demonstrates that these factors play an important role in the number of clusters perceived, and it verifies that the distance-based and density-based models can reasonably estimate the number of clusters a user observes. Finally, we demonstrate how these models can be used to optimize visual encodings on real-world data.", "keywords": "Scatterplot,clustering,perception,empirical evaluation,visual encoding,crowdsourcing,topological data analysis", "link": "http://dx.doi.org/10.1109/TVCG.2020.3030365", "refList": ["10.1109/tvcg.2017.2744359", "10.1145/1778765", "10.1109/tvcg.2019.2934799", "10.1111/cgf.12889", "10.1109/tvcg.2011.127", "10.1111/cgf.13444", "10.1145/1964897.1964910", "10.1167/8.7.6", "10.1145/3173574.3173991", "10.1145/1556262.1556289", "10.1145/1056808.1056914", "10.2307/2288400", "10.1109/tvcg.2014.2346594", "10.1109/iv.2002.1028760", "10.1177/001316447303300111", "10.1007/bf02289823", "10.1109/tvcg.2017.2744339", "10.1111/j.1467-8659.2009.01694.x", "10.1109/tvcg.2014.2346979", "10.1090/mbk/069", "10.1109/tvcg.2013.65", "10.1109/mcg.2012.37", "10.1109/pacificvis.2010.5429604", "10.1002/acp.2350050106", "10.1109/infvis.2005.1532136", "10.1177/1473871612465214", "10.1109/tvcg.2017.2674978", "10.1002/jhbs.20078", "10.1007/978-3-642-35142-6\\_14", "10.1007/978-3-319-71507-0", "10.1109/mcg.201.7.6", "10.3758/bf03193961", "10.1364/josa.49.000280", "10.1145/3025453.3025905", "10.1109/tvcg.201.9.2934541", "10.1109/tvcg.2018.2829750", "10.1177/1473871615606187", "10.1111/cgf.13408", "10.1109/pacificvis.2016.7465252", "10.1109/pacificvis.2016.7465244", "10.1109/inevis.2005.1532142", "10.1111/cgf.13414", "10.1111/j.1467-8659.2012.03125.x", "10.1167/16.5.11", "10.1109/infvis.2005.1532142", "10.1145/2858036.2858155", "10.1038/nmeth1210-941", "10.1177/1473871616638892", "10.1109/tcbb.2014.2306840", "10.1111/cgf.13684", "10.1177/0301006615602599", "10.1214/aoms/1177731915", "10.1145/2702123.2702585", "10.1109/tvcg.2013.183", "10.1109/tvcg.2014.2346572", "10.1109/tvcg.2018.2875702", "10.1109/tvcg.2017.2754480", "10.1109/vast.2014.7042493", "10.1057/palgrave.ivs.9500122", "10.1109/tvcg.2014.2330617", "10.1109/tvcg.2019.2934541", "10.1068/p030033", "10.1140/epjds/s13688-017-0109-5", "10.1201/b17511", "10.1016/s0925-7721(02)00093-7", "10.1109/pacificvis.2012.6183557", "10.1109/tvcg.2014.2346983", "10.1109/5.726791", "10.1080/01621459.1926.10502165", "10.1109/tvcg.2007.70535", "10.1109/tvcg.2018.2864907", "10.1111/cgf.12109", "10.1109/tvcg.2017.2744184", "10.1146/annurev-statistics-031017-100045", "10.1111/cgf.13409", "10.1145/3002151.3002162", "10.1016/s0378-4371(98)00494-4", "10.3138/y308-2422-8615-1233", "10.1111/cgf.12632", "10.1145/3290605.3300771"], "wos": 1, "children": [], "len": 1}], "len": 7}, {"doi": "10.1109/tvcg.2019.2934432", "title": "Discriminability Tests for Visualization Effectiveness and Scalability", "year": "2019", "conferenceName": "InfoVis", "authors": "Rafael Veras;Christopher Collins", "citationCount": "1", "affiliation": "Veras, R (Corresponding Author), Ontario Tech Univ, Oshawa, ON, Canada. Veras, Rafael; Collins, Christopher, Ontario Tech Univ, Oshawa, ON, Canada.", "countries": "Canada", "abstract": "The scalability of a particular visualization approach is limited by the ability for people to discern differences between plots made with different datasets. Ideally, when the data changes, the visualization changes in perceptible ways. This relation breaks down when there is a mismatch between the encoding and the character of the dataset being viewed. Unfortunately, visualizations are often designed and evaluated without fully exploring how they will respond to a wide variety of datasets. We explore the use of an image similarity measure, the Multi-Scale Structural Similarity Index (MS-SSIM), for testing the discriminability of a data visualization across a variety of datasets. MS-SSIM is able to capture the similarity of two visualizations across multiple scales, including low level granular changes and high level patterns. Significant data changes that are not captured by the MS-SSIM indicate visualizations of low discriminability and effectiveness. The measure's utility is demonstrated with two empirical studies. In the first, we compare human similarity judgments and MS-SSIM scores for a collection of scatterplots. In the second, we compute the discriminability values for a set of basic visualizations and compare them with empirical measurements of effectiveness. In both cases, the analyses show that the computational measure is able to approximate empirical results. Our approach can be used to rank competing encodings on their discriminability and to aid in selecting visualizations for a particular type of data distribution.", "keywords": "Scalability,Discriminability,Simulation,Perception", "link": "http://dx.doi.org/10.1109/TVCG.2019.2934432", "refList": ["10.1109/tvcg.2012.233", "10.1109/tvcg.2017.2744359", "10.1109/tvcg.2012.230", "10.1111/cgf.12647", "10.1109/tvcg.2016.2598918", "10.1109/tvcg.2007.70529", "10.1145/2858036.2858435", "10.1109/vast.2009.5332628", "10.1145/3025453.3025912", "10.1145/1133265.1133318", "10.1109/tip.2010.2092435", "10.1109/tvcg.2010.132", "10.1109/tvcg.2018.2865264", "10.1175/jtech-d-11-00103.1", "10.1145/1190036.1190039", "10.1111/cgf.12127", "10.1109/infvis.2005.1532142", "10.1145/2858036.2858155", "10.1109/mcg.2014.18", "10.1145/3173574.3174172", "10.1109/tvcg.2009.153", "10.1057/palgrave.ivs.9500070", "10.1109/tvcg.2018.2790961", "10.1109/tvcg.2014.2346978", "10.1109/tvcg.2018.2810918", "10.1111/cgf.13409", "10.1109/tip.2003.819861", "10.1145/2642918.2647411", "10.1080/15230406.2016.1140074", "10.1109/jstsp.2009.2015374", "10.1109/tvcg.2010.237", "10.1109/mcg.2009.6", "10.1111/j.1467-8659.2009.01667.x", "10.1109/tvcg.2010.161", "10.1111/cgf.13446", "10.1109/tvcg.2014.2346325", "10.1109/tvcg.2009.111", "10.1147/jrd.2015.2411412"], "wos": 1, "children": [{"doi": "10.1109/tvcg.2020.3030394", "title": "Direct Volume Rendering with Nonparametric Models of Uncertainty", "year": "2020", "conferenceName": "SciVis", "authors": "Tushar M. Athawale;Bo Ma 0002;Elham Sakhaee;Christopher R. Johnson;Alireza Entezari", "citationCount": "0", "affiliation": "Athawale, TM (Corresponding Author), Univ Utah, Sci Comp \\& Imaging SCI Inst, Salt Lake City, UT 84112 USA. Athawale, Tushar M.; Johnson, Chris R., Univ Utah, Sci Comp \\& Imaging SCI Inst, Salt Lake City, UT 84112 USA. Ma, Bo; Sakhaee, Elham; Entezari, Alireza, Univ Florida, Dept CISE, Gainesville, FL 32611 USA.", "countries": "USA", "abstract": "We present a nonparametric statistical framework for the quantification, analysis, and propagation of data uncertainty in direct volume rendering (DVR). The state-of-the-art statistical DVR framework allows for preserving the transfer function (TF) of the ground truth function when visualizing uncertain data; however, the existing framework is restricted to parametric models of uncertainty. In this paper, we address the limitations of the existing DVR framework by extending the DVR framework for nonparametric distributions. We exploit the quantile interpolation technique to derive probability distributions representing uncertainty in viewing-ray sample intensities in closed form, which allows for accurate and efficient computation. We evaluate our proposed nonparametric statistical models through qualitative and quantitative comparisons with the mean-field and parametric statistical models, such as uniform and Gaussian, as well as Gaussian mixtures. In addition, we present an extension of the state-of-the-art rendering parametric framework to 2D TFs for improved DVR classifications. We show the applicability of our uncertainty quantification framework to ensemble, downsampled, and bivariate versions of scalar field datasets.", "keywords": "Volumes,uncertainty,nonparametric,2D transfer function", "link": "http://dx.doi.org/10.1109/TVCG.2020.3030394", "refList": ["10.1109/icdm.2012.80", "10.1145/1401890.1401904", "10.1109/tvcg.2017.2745139", "10.18128/d030.v6.0", "10.1111/cgf.12142", "10.1109/tvcg.2009.114", "10.1111/j.1467-8659.2009.01677.x", "10.1109/mcse.2007.55", "10.1109/icde.2012.16", "10.1198/106186008x320465", "10.1145/1835804.1835868", "10.1559/1523040054738936", "10.1109/tvcg.2019.2934432", "10.1109/34.1000236", "10.1109/infvis.2005.1532136", "10.1109/tvcg.2012.128", "10.1109/pacificvis.2017.8031573", "10.1109/tvcg.2016.2598920", "10.1109/tvcg.2018.2865021", "10.1109/infvis.2005.1532142", "10.1145/2858036.2858155", "10.1109/sp.2009.22", "10.1109/tvcg.2017.2744184", "10.1145/773153.773173", "10.1145/2660267.2660348", "10.1109/icdmw.2009.93", "10.1016/j.jtrangeo.2015.09.001", "10.1109/icde.2010.5447831", "10.1007/11681878\\_14", "10.1111/cgf.13409", "10.1007/s13278-014-0205-5", "10.1109/tvcg.2011.163", "10.1145/3035918.3035940", "10.1109/sp.2008.33", "10.1145/2882903.2882931"], "wos": 1, "children": [], "len": 1}], "len": 3}, {"doi": "10.1109/tvcg.2019.2934208", "title": "Evaluating Perceptual Bias During Geometric Scaling of Scatterplots", "year": "2019", "conferenceName": "VAST", "authors": "Yating Wei;Honghui Mei;Ying Zhao;Shuyue Zhou;Bingru Lin;Haojing Jiang;Wei Chen", "citationCount": "5", "affiliation": "Chen, W (Corresponding Author), Zhejiang Univ, State Key Lab CAD \\& CG, Hangzhou 310058, Zhejiang, Peoples R China. Zhao, Y (Corresponding Author), Cent South Univ, Sch Comp Sci \\& Engn, Changsha 410083, Hunan, Peoples R China. Wei, Yating; Mei, Honghui; Zhou, Shuyue; Lin, Bingru; Chen, Wei, Zhejiang Univ, State Key Lab CAD \\& CG, Hangzhou 310058, Zhejiang, Peoples R China. Zhao, Ying; Jiang, Haojing, Cent South Univ, Sch Comp Sci \\& Engn, Changsha 410083, Hunan, Peoples R China.", "countries": "China", "abstract": "Scatterplots are frequently scaled to fit display areas in multi-view and multi-device data analysis environments. A common method used for scaling is to enlarge or shrink the entire scatterplot together with the inside points synchronously and proportionally. This process is called geometric scaling. However, geometric scaling of scatterplots may cause a perceptual bias, that is, the perceived and physical values of visual features may be dissociated with respect to geometric scaling. For example, if a scatterplot is projected from a laptop to a large projector screen, then observers may feel that the scatterplot shown on the projector has fewer points than that viewed on the laptop. This paper presents an evaluation study on the perceptual bias of visual features in scatterplots caused by geometric scaling. The study focuses on three fundamental visual features (i.e., numerosity, correlation, and cluster separation) and three hypotheses that are formulated on the basis of our experience. We carefully design three controlled experiments by using well-prepared synthetic data and recruit participants to complete the experiments on the basis of their subjective experience. With a detailed analysis of the experimental results, we obtain a set of instructive findings. First, geometric scaling causes a bias that has a linear relationship with the scale ratio. Second, no significant difference exists between the biases measured from normally and uniformly distributed scatterplots. Third, changing the point radius can correct the bias to a certain extent. These findings can be used to inspire the design decisions of scatterplots in various scenarios.", "keywords": "Evaluation,scatterplot,geometric scaling,bias,perceptual consistency", "link": "http://dx.doi.org/10.1109/TVCG.2019.2934208", "refList": ["10.2307/2288843", "10.1109/tvcg.2017.2744359", "10.1109/tvcg.2015.2467732", "10.1109/tvcg.2014.2346979", "10.1126/science.216.4550.1138", "10.1109/tvcg.2017.2744138", "10.1111/j.1467-8659.2009.01467.x", "10.1145/2491568.2491577", "10.1109/mwc.2018.1700325", "10.1145/2449396.2449439", "10.1109/tvcg.2011.127", "10.1109/tvcg.2011.229", "10.1167/15.5.4", "10.1073/pnas.1113195108", "10.1145/2702123.2702545", "10.1109/vast.2009.5332628", "10.1109/tvcg.2018.2800013", "10.1007/s12650-018-0530-2", "10.1016/s0042-6989(97)00340-4", "10.1109/vast.2010.5652460", "10.1109/mcg.2018.2879067", "10.1109/tvcg.2018.2864912", "10.1109/pacificvis.2010.5429604", "10.1109/tcst.2018.2819965", "10.1167/10.2.10", "10.1145/2470654.2481318", "10.1145/1842993.1843002", "10.1167/12.6.8", "10.1109/tvcg.2013.124", "10.1057/ivs.2008.13", "10.1109/tvcg.2007.70596", "10.1109/tvcg.2018.2865266", "10.1145/3173574.3173664", "10.1109/tvcg.2015.2467671", "10.1016/j.cag.2017.07.004", "10.1177/0956797613501520", "10.1109/tvcg.2018.2865020", "10.1111/j.1467-8659.2012.03125.x", "10.3758/bf03205986", "10.3758/s13423-016-1174-7", "10.1109/tvcg.2017.2680452", "10.1109/mc.2006.109", "10.1109/tvcg.2017.2744098", "10.1038/srep32810", "10.1016/j.visres.2013.06.006", "10.1002/jhbs.20078", "10.1109/tvcg.2006.163", "10.1109/tvcg.2014.2346594", "10.1109/tvcg.2017.2744184", "10.1016/j.cognition.2007.10.009", "10.1109/tvcg.2018.2865142", "10.3758/app.72.7.1839", "10.1109/tvcg.2018.2810918", "10.1016/j.jvlc.2017.10.001", "10.1145/2682623", "10.1109/tvcg.2018.2864884", "10.1145/3025453.3025984", "10.1109/tvcg.2006.184", "10.1109/tvcg.2013.153", "10.1016/j.jvlc.2018.08.003", "10.1109/tvcg.2016.2520921", "10.1111/cgf.13446", "10.1017/s0022381612000187", "10.1145/2702123.2702406", "10.1109/vast.2012.6400487", "10.1109/tvcg.2013.183", "10.1177/1473871611415997", "10.1145/2702123.2702585", "10.1145/2993901.2993903", "10.1109/tvcg.2013.120", "10.1111/cgf.12632", "10.1145/1385569.1385602", "10.1109/tvcg.2017.2754480", "10.1111/j.1467-8659.2009.01694.x"], "wos": 1, "children": [{"doi": "10.1109/tvcg.2020.3030456", "title": "Cartographic Relief Shading with Neural Networks", "year": "2020", "conferenceName": "InfoVis", "authors": "Bernhard Jenny;Magnus Heitzler;Dilpreet Singh;Marianna Farmakis-Serebryakova;Jeffery Chieh Liu;Lorenz Hurni", "citationCount": "4", "affiliation": "Jenny, B (Corresponding Author), Monash Univ, Melbourne, Vic, Australia. Jenny, Bernhard; Singh, Dilpreet; Liu, Jeffery Chieh, Monash Univ, Melbourne, Vic, Australia. Heitzler, Magnus; Farmakis-Serebryakova, Marianna; Hurni, Lorenz, Swiss Fed Inst Technol, Inst Cartog \\& Geoinformat, Zurich, Switzerland.", "countries": "Switzerland;Australia", "abstract": "Shaded relief is an effective method for visualising terrain on topographic maps, especially when the direction of illumination is adapted locally to emphasise individual terrain features. However, digital shading algorithms are unable to fully match the expressiveness of hand-crafted masterpieces, which are created through a laborious process by highly specialised cartographers. We replicate hand-drawn relief shading using U-Net neural networks. The deep neural networks are trained with manual shaded relief images of the Swiss topographic map series and terrain models of the same area. The networks generate shaded relief that closely resemble hand-drawn shaded relief art. The networks learn essential design principles from manual relief shading such as removing unnecessary terrain details, locally adjusting the illumination direction to accentuate individual terrain features, and varying brightness to emphasise larger landforms. Neural network shadings are generated from digital elevation models in a few seconds, and a study with 18 relief shading experts found that they are of high quality.", "keywords": "Relief shading,shaded relief,hillshade,neural rendering,illustrative visualisation,image-to-image translation", "link": "http://dx.doi.org/10.1109/TVCG.2020.3030456", "refList": ["10.1145/1456650.1456652", "10.1145/1145/1556262.1556270", "10.1145/345513.345271", "10.1109/tvcg.2019.2934803", "10.1145/3180658", "10.1109/tridui.2006.1618264", "10.3389/fict.2018.00015", "10.1109/vr.2018.8447558", "10.1518/hfes.45.1.160.27234", "10.1145/3290605.3300377", "10.1089/cpb.2006.9.157", "10.1007/s00779-011-0500-3", "10.1109/vl.1996.545307", "10.1109/tvcg.2019.2934415", "10.1109/5.726791", "10.1145/3290605.3300288", "10.1109/tvcg.2017.2745941", "10.1109/vr.2001.913779", "10.1145/586081.586086", "10.18637/jss.v067.i01", "10.1145/1502800.1502805", "10.1145/1165734.1165736", "10.1145/3126594.3126613", "10.1109/tvcg.2008.109", "10.1109/tvcg.2017.2744184", "10.1016/j.cola.2019.100937", "10.1109/visual.2019.8933545", "10.1145/3290605.3300555", "10.1111/cgf.13431", "10.1109/tvcg.2019.2934395", "10.1109/vr.2019.8798340", "10.1145/3025453.3026046", "10.1109/vr.2019.8797871", "10.1145/3290605.3300752", "10.1109/tvcg.2016.2520921", "10.1109/tvcg.2018.2865191", "10.1145/1970378.1970384", "10.1109/tvcg.2019.2934208", "10.18637/jss.v069.i01", "10.1162/105474698565659", "10.1145/1124772.1124775", "10.1109/vrais.1997.583043"], "wos": 1, "children": [], "len": 1}, {"doi": "10.1109/tvcg.2020.3030443", "title": "CAVA: A Visual Analytics System for Exploratory Columnar Data Augmentation Using Knowledge Graphs", "year": "2020", "conferenceName": "VAST", "authors": "Dylan Cashman;Shenyu Xu;Subhajit Das;Florian Heimerl;Cong Liu;Shah Rukh Humayoun;Michael Gleicher;Alex Endert;Remco Chang", "citationCount": "0", "affiliation": "Cashman, D (Corresponding Author), Tufts Univ, Medford, MA 02155 USA. Cashman, Dylan; Liu, Cong; Chang, Remco, Tufts Univ, Medford, MA 02155 USA. Xu, Shenyu; Das, Subhajit; Endert, Alex, Georgia Tech, Atlanta, GA USA. Heimerl, Florian; Gleicher, Michael, Univ Wisconsin, Madison, WI 53706 USA. Humayoun, Shah Rukh, San Francisco State Univ, San Francisco, CA 94132 USA.", "countries": "USA", "abstract": "Most visual analytics systems assume that all foraging for data happens before the analytics process; once analysis begins, the set of data attributes considered is fixed. Such separation of data construction from analysis precludes iteration that can enable foraging informed by the needs that arise in-situ during the analysis. The separation of the foraging loop from the data analysis tasks can limit the pace and scope of analysis. In this paper, we present CAVA, a system that integrates data curation and data augmentation with the traditional data exploration and analysis tasks, enabling information foraging in-situ during analysis. Identifying attributes to add to the dataset is difficult because it requires human knowledge to determine which available attributes will be helpful for the ensuing analytical tasks. CAVA crawls knowledge graphs to provide users with a a broad set of attributes drawn from external data to choose from. Users can then specify complex operations on knowledge graphs to construct additional attributes. CAVA shows how visual analytics can help users forage for attributes by letting users visually explore the set of available data, and by serving as an interface for query construction. It also provides visualizations of the knowledge graph itself to help users understand complex joins such as multi-hop aggregations. We assess the ability of our system to enable users to perform complex data combinations without programming in a user study over two datasets. We then demonstrate the generalizability of CAVA through two additional usage scenarios. The results of the evaluation confirm that CAVA is effective in helping the user perform data foraging that leads to improved analysis outcomes, and offer evidence in support of integrating data augmentation as a part of the visual analytics pipeline.", "keywords": "Visual Analytics,Information Foraging,Data Augmentation", "link": "http://dx.doi.org/10.1109/TVCG.2020.3030443", "refList": ["10.1057/palgrave.ivs.9500122", "10.1109/tvcg.2016.2598867", "10.1111/cgf.13708", "10.1109/tvcg.2019.2934799", "10.1109/tvcg.2019.2934541", "10.1109/tvcg.2013.65", "10.1109/tvcg.2018.2875702", "10.1109/iv.2004.1320207", "10.1068/p260471", "10.1145/1778765.1778816", "10.1109/tvcg.2018.2808489", "10.1109/tvcg.2018.2864912", "10.1016/j.apgeog.2015.12.006", "10.1111/j.1467-8659.2011.01960.x", "10.1109/tvcg.2018.2864843", "10.1109/pacificvis.2010.5429604", "10.1109/tvcg.2014.2346898", "10.1109/5.726791", "10.1177/1475090214540874", "10.1109/icde.2016.7498287", "10.1145/1556262.1556289", "10.1109/tvcg.2007.70535", "10.1109/vast.2012.6400489", "10.1145/1056808.1056914", "10.1016/j.neucom.2014.09.063", "10.1145/7529.8927", "10.1109/tvcg.2016.2598495", "10.1109/tvcg.2016.2607204", "10.1109/vast47406.2019.8986943", "10.3758/bf03205986", "10.1109/infvis.2005.1532142", "10.1145/1150402.1150479", "10.1109/tvcg.2017.2674978", "10.1109/tvcg.2019.2945960", "10.1109/tvcg.2017.2744098", "10.1109/tvcg.2017.2674999", "10.1109/tvcg.2011.279", "10.1109/tvcg.2014.2346594", "10.1109/tvcg.2017.2744184", "10.1111/cgf.12876", "10.1007/s4095-020-0191-7", "10.1007/s11390-015-1535-0", "10.1111/cgf.12640", "10.1109/tvcg.2016.2598667", "10.1111/cgf.13683", "10.1109/tvcg.2013.153", "10.1109/tvcg.2019.2934208", "10.1109/tvcg.2019.2934655", "10.1111/cgf.12655", "10.1007/s11023-010-9221-z", "10.1109/vast.2012.6400487", "10.1145/2702123.2702585", "10.1007/bf00310175", "10.1109/tvcg.2017.2744378", "10.1103/physreve.64.061907", "10.1109/ldav.2017.8231848", "10.1109/tvcg.2016.2598831"], "wos": 1, "children": [], "len": 1}, {"doi": "10.1109/tvcg.2020.3030432", "title": "Evaluation of Sampling Methods for Scatterplots", "year": "2020", "conferenceName": "VAST", "authors": "Jun Yuan;Shouxing Xiang;Jiazhi Xia;Lingyun Yu;Shixia Liu", "citationCount": "0", "affiliation": "Liu, SX (Corresponding Author), Tsinghua Univ, BNRist, Beijing, Peoples R China. Yuan, Jun; Xiang, Shouxing; Liu, Shixia, Tsinghua Univ, BNRist, Beijing, Peoples R China. Xia, Jiazhi, Cent South Univ, Changsha, Peoples R China. Yu, Lingyun, Xian Jiaotong Liverpool Univ, Suzhou, Peoples R China.", "countries": "China", "abstract": "Given a scatterplot with tens of thousands of points or even more, a natural question is which sampling method should be used to create a small but \u201cgood\u201d scatterplot for a better abstraction. We present the results of a user study that investigates the influence of different sampling strategies on multi-class scatterplots. The main goal of this study is to understand the capability of sampling methods in preserving the density, outliers, and overall shape of a scatterplot. To this end, we comprehensively review the literature and select seven typical sampling strategies as well as eight representative datasets. We then design four experiments to understand the performance of different strategies in maintaining: 1) region density; 2) class density; 3) outliers; and 4) overall shape in the sampling results. The results show that: 1) random sampling is preferred for preserving region density; 2) blue noise sampling and random sampling have comparable performance with the three multi-class sampling strategies in preserving class density; 3) outlier biased density based sampling, recursive subdivision based sampling, and blue noise sampling perform the best in keeping outliers; and 4) blue noise sampling outperforms the others in maintaining the overall shape of a scatterplot.", "keywords": "Scatterplot,data sampling,empirical evaluation", "link": "http://dx.doi.org/10.1109/TVCG.2020.3030432", "refList": ["10.1057/palgrave.ivs.9500122", "10.1109/tvcg.2016.2598867", "10.1109/tvcg.2015.2467591", "10.1111/cgf.13708", "10.1109/tvcg.2019.2934799", "10.1109/tvcg.2019.2934541", "10.1109/tvcg.2013.65", "10.1109/iv.2004.1320207", "10.1068/p260471", "10.1145/1778765.1778816", "10.1109/tvcg.2018.2808489", "10.1109/tvcg.2018.2864912", "10.1016/j.apgeog.2015.12.006", "10.1111/j.1467-8659.2011.01960.x", "10.1109/tvcg.2018.2864843", "10.1109/pacificvis.2010.5429604", "10.1109/tvcg.2014.2346898", "10.1109/5.726791", "10.1177/1475090214540874", "10.1145/1556262.1556289", "10.1109/tvcg.2007.70535", "10.1109/vast.2012.6400489", "10.1145/1056808.1056914", "10.1016/j.neucom.2014.09.063", "10.1145/7529.8927", "10.1109/tvcg.2016.2607204", "10.1109/vast47406.2019.8986943", "10.3758/bf03205986", "10.1109/infvis.2005.1532142", "10.1145/1150402.1150479", "10.1109/tvcg.2017.2674978", "10.1109/tvcg.2017.2744098", "10.1109/tvcg.2017.2674999", "10.1109/tvcg.2011.279", "10.1109/tvcg.2014.2346594", "10.1109/tvcg.2017.2744184", "10.1111/cgf.12876", "10.1109/1011101.2019.2945960", "10.1007/s4095-020-0191-7", "10.1007/s11390-015-1535-0", "10.1111/cgf.12640", "10.1109/tvcg.2016.2598667", "10.1111/cgf.13683", "10.1109/tvcg.2013.153", "10.1109/tvcg.2019.2934208", "10.1109/tvcg.2019.2934655", "10.1111/cgf.12655", "10.1007/s11023-010-9221-z", "10.1109/vast.2012.6400487", "10.1145/2702123.2702585", "10.1007/bf00310175", "10.1109/tvcg.2017.2744378", "10.1103/physreve.64.061907", "10.1109/ldav.2017.8231848", "10.1109/tvcg.2016.2598831"], "wos": 1, "children": [], "len": 1}], "len": 7}, {"doi": "10.1109/tvcg.2019.2934300", "title": "GUIRO: User-Guided Matrix Reordering", "year": "2019", "conferenceName": "VAST", "authors": "Michael Behrisch;Tobias Schreck;Hanspeter Pfister", "citationCount": "1", "affiliation": "Behrisch, M (Corresponding Author), Harvard Univ, Sch Engn \\& Appl Sci, Cambridge, MA 02138 USA. Behrisch, Michael; Pfister, Hanspeter, Harvard Univ, Sch Engn \\& Appl Sci, Cambridge, MA 02138 USA. Schreck, Tobias, Graz Univ Technol, Graz, Austria.", "countries": "USA;Austria", "abstract": "Matrix representations are one of the main established and empirically proven to be effective visualization techniques for relational (or network) data. However, matrices\u2014similar to node-link diagrams\u2014are most effective if their layout reveals the underlying data topology. Given the many developed algorithms, a practical problem arises: \u201cWhich matrix reordering algorithm should I choose for my dataset at hand?\u201d To make matters worse, different reordering algorithms applied to the same dataset may let significantly different visual matrix patterns emerge. This leads to the question of trustworthiness and explainability of these fully automated, often heuristic, black-box processes. We present GUIRO, a Visual Analytics system that helps novices, network analysts, and algorithm designers to open the black-box. Users can investigate the usefulness and expressiveness of 70 accessible matrix reordering algorithms. For network analysts, we introduce a novel model space representation and two interaction techniques for a user-guided reordering of rows or columns, and especially groups thereof (submatrix reordering). These novel techniques contribute to the understanding of the global and local dataset topology. We support algorithm designers by giving them access to 16 reordering quality metrics and visual exploration means for comparing reordering implementations on a row/column permutation level. We evaluated GUIRO in a guided explorative user study with 12 subjects, a case study demonstrating its usefulness in a real-world scenario, and through an expert study gathering feedback on our design decisions. We found that our proposed methods help even inexperienced users to understand matrix patterns and allow a user-guided steering of reordering algorithms. GUIRO helps to increase the transparency of matrix reordering algorithms, thus helping a broad range of users to get a better insight into the complex reordering process, in turn supporting data and reordering algorithm insights.", "keywords": "Visual Analytics,matrix,black-box algorithms,seriation,ordering,sorting,steerable algorithm,interaction,2D projection", "link": "http://dx.doi.org/10.1109/TVCG.2019.2934300", "refList": ["10.1109/tvcg.2007.70582", "10.2307/276978", "10.1109/tvcg.2008.61", "10.3390/su10040973", "10.1101/121889", "10.1145/1345448.1345453", "10.1186/s12879-014-0695-9", "10.1186/1471-2105-9-155", "10.1145/1124772.1124891", "10.1109/tvcg.2010.159", "10.1111/j.2044-8317.1974.tb00534.x", "10.1109/tpami.2015.2470671", "10.1198/000313005x22770", "10.1109/tvcg.2012.219", "10.1002/sam.10071", "10.1016/j.ejor.2016.08.066", "10.1007/s00265-003-0651-y", "10.1109/biovis.2013.6664342", "10.3115/v1/p14-1062", "10.3389/fpsyg.2017.01349", "10.1109/tpami.2004.1265866", "10.1057/palgrave.ivs.9500086", "10.1007/s004260000031", "10.1111/cgf.12935", "10.1145/800195.805928", "10.1109/tvcg.2014.2346279", "10.2312/eurovisstar.20141174", "10.1109/tvcg.2012.256", "10.1093/bioinformatics/17.suppl\\_1.s22", "10.1109/infvis.2004.46", "10.1007/978-3-319-06793-3\\_5", "10.1109/tvcg.2006.147", "10.1109/tvcg.2015.2468078", "10.1093/bioinformatics/bti141", "10.1145/1168149.1168168", "10.1109/tvcg.2017.2745978", "10.1177/1473871613513228", "10.1109/mcg.2014.62", "10.1109/tvcg.2006.166", "10.1145/2470654.2470724", "10.1177/154193120605000909", "10.1109/sibgrapi.2007.21", "10.1145/3065386", "10.1109/tvcg.2006.160", "10.1287/opre.20.5.993", "10.1111/cgf.13446", "10.1057/palgrave.ivs.9500092", "10.1145/568522.568523", "10.1109/mcg.2013.66", "10.1109/tvcg.2018.2865940", "10.1109/tvcg.2012.208"], "wos": 1, "children": [{"doi": "10.1109/tvcg.2020.3030471", "title": "Visual Analysis of Discrimination in Machine Learning", "year": "2020", "conferenceName": "InfoVis", "authors": "Qianwen Wang;Zhenhua Xu;Zhutian Chen;Yong Wang;Shixia Liu;Huamin Qu", "citationCount": "0", "affiliation": "Wang, QW (Corresponding Author), Hong Kong Univ Sci \\& Technol, Hong Kong, Peoples R China. Wang, Qianwen; Xu, Zhenhua; Chen, Zhutian; Wang, Yong; Qu, Huamin, Hong Kong Univ Sci \\& Technol, Hong Kong, Peoples R China. Liu, Shixia, Tsinghua Univ, Beijing, Peoples R China.", "countries": "China", "abstract": "The growing use of automated decision-making in critical applications, such as crime prediction and college admission, has raised questions about fairness in machine learning. How can we decide whether different treatments are reasonable or discriminatory? In this paper, we investigate discrimination in machine learning from a visual analytics perspective and propose an interactive visualization tool, DiscriLens, to support a more comprehensive analysis. To reveal detailed information on algorithmic discrimination, DiscriLens identifies a collection of potentially discriminatory itemsets based on causal modeling and classification rules mining. By combining an extended Euler diagram with a matrix-based visualization, we develop a novel set visualization to facilitate the exploration and interpretation of discriminatory itemsets. A user study shows that users can interpret the visually encoded information in DiscriLens quickly and accurately. Use cases demonstrate that DiscriLens provides informative guidance in understanding and reducing algorithmic discrimination.", "keywords": "Machine Learning,Discrimination,Data Visualization", "link": "http://dx.doi.org/10.1109/TVCG.2020.3030471", "refList": ["10.1109/tvcg.2019.2934396", "10.2312/eurovisstar.20141170", "10.1145/3357384.3357910", "10.1111/cgf.12791", "10.1109/tvcg.2018.2861397", "10.1111/j.1467-8659.2011.01898.x", "10.1145/2702123.2702237", "10.1109/tvcg.2019.2934798", "10.1109/mcg.2017.21", "10.1109/tvcg.2019.2934300", "10.1109/tvcg.2017.2745085", "10.1109/tvcg.2018.2859997", "10.1145/3173574.3174237", "10.1109/tvcg.2018.2865126", "10.1145/1718487.1718520", "10.1109/tvcg.2017.2743858", "10.1109/pacificvis.2015.7156392", "10.1109/tvcg.2018.2864477", "10.1145/324133.324140", "10.1137/140976649", "10.1145/3219819.3220088", "10.1109/tvcg.2019.2934805", "10.1145/1134271.1134277", "10.1137/090772745", "10.1016/j.jelectrocard.2010.09.003", "10.1109/tvcg.2012.253", "10.1145/2556612", "10.1109/tvcg.2013.173", "10.1109/tvcg.2019.2934619", "10.1109/tvcg.2017.2745078"], "wos": 1, "children": [], "len": 1}], "len": 3}, {"doi": "10.1109/tvcg.2019.2934796", "title": "Improving the Robustness of Scagnostics", "year": "2019", "conferenceName": "InfoVis", "authors": "Yunhai Wang;Zeyu Wang 0005;Tingting Liu;Michael Correll;Zhanglin Cheng;Oliver Deussen;Michael Sedlmair", "citationCount": "1", "affiliation": "Wang, YH (Corresponding Author), Shandong Univ, Jinan, Peoples R China. Wang, Yunhai; Wang, Zeyu; Liu, Tingting, Shandong Univ, Jinan, Peoples R China. Wang, Zeyu; Cheng, Zhanglin; Deussen, Oliver, SIAT, Shenzhen VisuCA Key Lab, Shenzhen, Peoples R China. Correll, Michael, Tableau Res, Seattle, WA USA. Deussen, Oliver, Konstanz Univ, Constance, Germany. Sedlmair, Michael, Univ Stuttgart, VISUS, Stuttgart, Germany.", "countries": "USA;Germany;China", "abstract": "In this paper, we examine the robustness of scagnostics through a series of theoretical and empirical studies. First, we investigate the sensitivity of scagnostics by employing perturbing operations on more than 60M synthetic and real-world scatterplots. We found that two scagnostic measures, Outlying and Clumpy, are overly sensitive to data binning. To understand how these measures align with human judgments of visual features, we conducted a study with 24 participants, which reveals that i) humans are not sensitive to small perturbations of the data that cause large changes in both measures, and ii) the perception of clumpiness heavily depends on per-cluster topologies and structures. Motivated by these results, we propose Robust Scagnostics (RScag) by combining adaptive binning with a hierarchy-based form of scagnostics. An analysis shows that RScag improves on the robustness of original scagnostics, aligns better with human judgments, and is equally fast as the traditional scagnostic measures.", "keywords": "Scagnostics,scatterplots,sensitivity analysis,Robust Scagnostics", "link": "http://dx.doi.org/10.1109/TVCG.2019.2934796", "refList": ["10.1057/palgrave.ivs.9500122", "10.1109/tvcg.2014.2346979", "10.1111/j.1467-8659.2009.01467.x", "10.1109/vast.2008.4677368", "10.2307/2289444", "10.1109/tvcg.2011.229", "10.1109/iv.2004.1320207", "10.1109/vast.2009.5332628", "10.1111/insr.12095\\_11", "10.1109/tvcg.2010.184", "10.1109/tvcg.2015.2467323", "10.1109/vast.2010.5652460", "10.1111/j.1467-8659.2012.03069.x", "10.1145/1842993.1843002", "10.1198/106186008x320465", "10.1109/pacificvis.2016.7465244", "10.1109/tvcg.2013.20", "10.1111/cgf.12641", "10.1109/tvcg.2012.128", "10.1109/tvcg.2015.2467671", "10.1057/palgrave.ivs.9500091", "10.1007/978-1-4612-4400-4", "10.1111/cgf.13176", "10.1002/0470870958", "10.1109/tvcg.2018.2864907", "10.1111/j.1467-8659.2012.03125.x", "10.1109/vast.2012.6400490", "10.1109/infvis.2005.1532142", "10.1109/vast.2010.5652433", "10.1109/vast.2009.5332611", "10.1201/9781315140919", "10.1145/2858036.2858155", "10.1109/ldav.2013.6675164", "10.1515/itit-2014-1070", "10.1111/cgf.13684", "10.1109/tpami.1979.4766909", "10.2307/2289936", "10.1109/pacificvis.2014.42", "10.1109/tvcg.2016.2598467", "10.1109/tvcg.2013.153", "10.1111/cgf.13446", "10.1109/tvcg.2006.94", "10.1109/tvcg.2014.2346572", "10.1111/cgf.12632", "10.1109/tvcg.2017.2744339"], "wos": 1, "children": [], "len": 1}, {"doi": "10.1109/vast47406.2019.8986917", "title": "VIANA: Visual Interactive Annotation of Argumentation", "year": "2019", "conferenceName": "VAST", "authors": "Fabian Sperrle;Rita Sevastjanova;Rebecca Kehlbeck;Mennatallah El-Assady", "citationCount": "0", "affiliation": "Sperrle, F (Corresponding Author), Univ Konstanz, Constance, Germany. Sperrle, Fabian; Sevastjanova, Rita; Kehlbeck, Rebecca; El-Assady, Mennatallah, Univ Konstanz, Constance, Germany.", "countries": "Germany", "abstract": "Argumentation Mining addresses the challenging tasks of identifying boundaries of argumentative text fragments and extracting their relationships. Fully automated solutions do not reach satisfactory accuracy due to their insufficient incorporation of semantics and domain knowledge. Therefore, experts currently rely on time-consuming manual annotations. In this paper, we present a visual analytics system that augments the manual annotation process by automatically suggesting which text fragments to annotate next. The accuracy of those suggestions is improved over time by incorporating linguistic knowledge and language modeling to learn a measure of argument similarity from user interactions. Based on a long-term collaboration with domain experts, we identify and model five high-level analysis tasks. We enable close reading and note-taking, annotation of arguments, argument reconstruction, extraction of argument relations, and exploration of argument graphs. To avoid context switches, we transition between all views through seamless morphing, visually anchoring all text- and graph-based layers. We evaluate our system with a two-stage expert user study based on a corpus of presidential debates. The results show that experts prefer our system over existing solutions due to the speedup provided by the automatic suggestions and the tight integration between text and graph views.", "keywords": "Argumentation annotation,machine learning,user interaction,layered interfaces,semantic transitions", "link": "http://dx.doi.org/10.1109/VAST47406.2019.8986917", "refList": ["10.1007/978-3-642-40624-9\\_1", "10.3233/978-1-61499-436-7-185", "10.1145/371920.372071", "10.3233/978-1-61499-906-5-4", "10.1109/tvcg.2015.2467759", "10.18653/v1/d15-1050", "10.2307/2529310", "10.1109/mic.2003.1167344", "10.1145/312624.312682", "10.1145/2850417", "10.18653/v1/p17-2039", "10.1016/j.eswa.2016.02.013", "10.1007/978-0-387-85820-3\\_3", "10.1007/s11412-009-9080-x", "10.1109/tvcg.2008.127", "10.1145/2207676.2207741", "10.1109/cit.2012.217", "10.3233/aac-170022", "10.1109/tvcg.2017.2745080", "10.1007/978-3-319-44039-2\\_6", "10.1145/3290605.3300233", "10.1007/978-94-017-0431-1", "10.3233/978-1-61499-906-5-313", "10.1142/s0218213004001922", "10.1109/tvcg.2012.262", "10.1177/001316446002000104", "10.1109/tvcg.2018.2834341", "10.3233/978-1-61499-436-7-463", "10.1145/1772690.1772773", "10.1109/tvcg.2014.2346677", "10.1145/2523813", "10.1162/153244303322533223", "10.1109/tvcg.2007.70539", "10.1109/tvcg.2015.2467531", "10.1109/tvcg.2018.2864769", "10.1007/978-3-319-90092-6\\_14", "10.1137/1.9781611972801.19", "10.1109/vast.2012.6400485", "10.1007/s10579-013-9215-6", "10.3115/v1/d14-1162", "10.1111/cgf.13446", "10.1109/tvcg.2006.156", "10.1111/cgf.13092", "10.1145/2645710.2645759", "10.1109/bigdata.2017.8258140", "10.1145/2669557.2669572", "10.2312/eurovisstar.20151113"], "wos": 1, "children": [], "len": 1}, {"doi": "10.1109/tvcg.2020.3030376", "title": "Insight Beyond Numbers: The Impact of Qualitative Factors on Visual Data Analysis", "year": "2020", "conferenceName": "VAST", "authors": "Benjamin Karer;Hans Hagen;Dirk J. Lehmann", "citationCount": "0", "affiliation": "Karer, B (Corresponding Author), Fed Criminal Police Off Germany, Wiesbaden, Germany. Karer, Benjamin, Fed Criminal Police Off Germany, Wiesbaden, Germany. Hagen, Hans, TU Kaiserslautern, Kaiserslautern, Germany. Lehmann, Dirk J., Ostfalia Univ Appl Sci, Wolfenbuttel, Germany. Lehmann, Dirk J., IAV GmbH, Berlin, Germany.", "countries": "Germany", "abstract": "As of today, data analysis focuses primarily on the findings to be made inside the data and concentrates less on how those findings relate to the domain of investigation. Contemporary visualization as a field of research shows a strong tendency to adopt this data-centrism. Despite their decisive influence on the analysis result, qualitative aspects of the analysis process such as the structure, soundness, and complexity of the applied reasoning strategy are rarely discussed explicitly. We argue that if the purpose of visualization is the provision of domain insight rather than the depiction of data analysis results, a holistic perspective requires a qualitative component to to be added to the discussion of quantitative and human factors. To support this point, we demonstrate how considerations of qualitative factors in visual analysis can be applied to obtain explanations and possible solutions for a number of practical limitations inherent to the data-centric perspective on analysis. Based on this discussion of what we call qualitative visual analysis, we develop an inside-outside principle of nested levels of context that can serve as a conceptual basis for the development of visualization systems that optimally support the emergence of insight during analysis.", "keywords": "Visualization,Reasoning,Qualitative Aspects", "link": "http://dx.doi.org/10.1109/TVCG.2020.3030376", "refList": ["10.1057/ivs.2009.22", "10.1109/tvcg.2015.2467732", "10.1109/infvis.2000.885092", "10.1109/vast.2014.7042482", "10.1145/1498700.1498704", "10.1109/tvcg.2009.108", "10.1109/tvcg.2018.2829750", "10.1037/0033-295x.111.4.1036", "10.1109/tvcg.2012.199", "10.1109/38.267476", "10.1007/978-3-540-70956-5\\_2", "10.1109/tvcg.2015.2467613", "10.1109/tvcg.2015.2467195", "10.1109/tvcg.2014.2346419", "10.1109/vast.2017.8585669", "10.1109/tvcg.2010.132", "10.1145/22949.22950", "10.1109/tvcg.2014.2346984", "10.1017/cbo9780511816772", "10.1109/mcg.2003.1231171", "10.1111/coin.12227", "10.1109/tvcg.2018.2865138", "10.1109/38.788803", "10.1109/tvcg.2018.2864849", "10.1109/mcg.2012.120", "10.1109/tvcg.2007.70535", "10.1162/neco.2008.12-06-420", "10.1109/tvcg.2018.2865240", "10.1089/tmj.2010.0114", "10.1109/beliv.2018.8634267", "10.1109/tvcg.2014.2346481", "10.1207/s15327809jls0402\\_2", "10.1109/tvcg.2006.80", "10.1145/2858036.2858280", "10.1109/tvcg.2017.2674978", "10.1109/tvcg.2011.52", "10.1016/j.cag.2014.03.002", "10.1109/tvcg.2015.2513410", "10.1111/j.1756-8765.2011.01150.x", "10.1109/infvis.2005.1532142", "10.1002/spe.4380211102", "10.1186/s41235-018-0120-9", "10.1073/pnas.1807180116", "10.1109/tvcg.2012.133", "10.1109/tvcg.2012.273", "10.1111/j.1467-8659.2011.01928.x", "10.1145/353485.353486", "10.1109/tvcg.2015.2462356", "10.1109/mcg.2019.2923483", "10.1111/cgf.13264", "10.1057/palgrave.ivs.9500070", "10.1145/1168149.1168158", "10.1109/mcg.2019.2961716", "10.1016/s0167-739x(96)00029-5", "10.1111/j.1467-8659.2009.01667.x", "10.1177/1473871611415989", "10.1109/tvcg.2013.234", "10.1109/iv.2012.33", "10.1111/cgf.13446", "10.1057/ivs.2008.28", "10.1111/cgf.12379", "10.1037/0033-295x.112.1.159", "10.1109/tvcg.2010.161", "10.1109/tvcg.2017.2744319", "10.1145/989863.989880", "10.1007/s11390-016-1663-1", "10.1177/1473871615609787", "10.1016/j.cola.2019.100911"], "wos": 1, "children": [], "len": 1}, {"doi": "10.1109/tvcg.2020.3030395", "title": "Towards Modeling Visualization Processes as Dynamic Bayesian Networks", "year": "2020", "conferenceName": "InfoVis", "authors": "Christian Heine 0002", "citationCount": "0", "affiliation": "Heine, C (Corresponding Author), Univ Leipzig, Leipzig, Germany. Heine, Christian, Univ Leipzig, Leipzig, Germany.", "countries": "Germany", "abstract": "Visualization designs typically need to be evaluated with user studies, because their suitability for a particular task is hard to predict. What the field of visualization is currently lacking are theories and models that can be used to explain why certain designs work and others do not. This paper outlines a general framework for modeling visualization processes that can serve as the first step towards such a theory. It surveys related research in mathematical and computational psychology and argues for the use of dynamic Bayesian networks to describe these time-dependent, probabilistic processes. It is discussed how these models could be used to aid in design evaluation. The development of concrete models will be a long process. Thus, the paper outlines a research program sketching how to develop prototypes and their extensions from existing models, controlled experiments, and observational studies.", "keywords": "Visualization,model building,perception,cognition,dynamic Bayesian networks", "link": "http://dx.doi.org/10.1109/TVCG.2020.3030395", "refList": ["10.1057/ivs.2009.22", "10.1109/tvcg.2015.2467732", "10.1109/infvis.2000.885092", "10.1109/vast.2014.7042482", "10.1145/1498700.1498704", "10.1109/tvcg.2009.108", "10.1109/tvcg.2018.2829750", "10.1037/0033-295x.111.4.1036", "10.1109/tvcg.2012.199", "10.1111/cgf.13899", "10.1109/38.267476", "10.1007/978-3-540-70956-5\\_2", "10.1109/tvcg.2015.2467613", "10.1109/tvcg.2015.2467195", "10.1109/tvcg.2014.2346419", "10.1145/3290605.3300562", "10.1109/vl.1996.545307", "10.1109/vast.2017.8585669", "10.1109/infvis.2003.1249004", "10.1109/tvcg.2010.132", "10.1145/22949.22950", "10.1109/tvcg.2014.2346984", "10.1145/3290605.3300418", "10.1017/cbo9780511816772", "10.1109/mcg.2003.1231171", "10.1111/coin.12227", "10.1109/tvcg.2018.2865138", "10.1109/38.788803", "10.1109/tvcg.2018.2864849", "10.1109/mcg.2012.120", "10.1109/tvcg.2007.70535", "10.1162/neco.2008.12-06-420", "10.1109/tvcg.2018.2865240", "10.1089/tmj.2010.0114", "10.1109/beliv.2018.8634267", "10.1109/tvcg.2014.2346481", "10.1207/s15327809jls0402\\_2", "10.1109/tvcg.2006.80", "10.1145/2858036.2858280", "10.1109/tvcg.2017.2674978", "10.1109/tvcg.2011.52", "10.1016/j.cag.2014.03.002", "10.1109/tvcg.2015.2513410", "10.1111/j.1756-8765.2011.01150.x", "10.1109/infvis.2005.1532142", "10.1002/spe.4380211102", "10.1186/s41235-018-0120-9", "10.1073/pnas.1807180116", "10.1109/tvcg.2012.133", "10.1109/tvcg.2012.273", "10.1111/j.1467-8659.2011.01928.x", "10.1145/353485.353486", "10.1109/tvcg.2015.2462356", "10.1109/mcg.2019.2923483", "10.1111/cgf.13264", "10.1057/palgrave.ivs.9500070", "10.1145/1168149.1168158", "10.1109/mcg.2019.2961716", "10.1016/s0167-739x(96)00029-5", "10.1111/j.1467-8659.2009.01667.x", "10.1177/1473871611415989", "10.1109/tvcg.2013.234", "10.1109/iv.2012.33", "10.1111/cgf.13446", "10.1057/ivs.2008.28", "10.1111/cgf.12379", "10.1037/0033-295x.112.1.159", "10.1017/cb09781139033916.005", "10.1109/tvcg.2010.161", "10.1109/tvcg.2017.2744319", "10.1145/989863.989880", "10.1007/s11390-016-1663-1", "10.1177/1473871615609787", "10.1016/j.cola.2019.100911", "10.1057/palgrave.ivs.9500025"], "wos": 1, "children": [], "len": 1}, {"doi": "10.1109/pacificvis48177.2020.8199", "year": "2020", "title": "Efficient Morphing of Shape-preserving Star Coordinates", "conferenceName": "PacificVis", "authors": "Vladimir Molchanov;Sagad Hamid;Lars Linsen", "citationCount": "0", "affiliation": "Molchanov, V (Corresponding Author), Westfalische Wilhelms Univ Munster, Munster, Germany.\nMolchanov, Vladimir; Hamid, Sagad; Linsen, Lars, Westfalische Wilhelms Univ Munster, Munster, Germany.", "countries": "Germany", "abstract": "Data tours follow an exploratory multi-dimensional data visualization concept that provides animations of projections of the multidimensional data to a 2D visual space. To create an animation, a sequence of key projections is provided and morphings between each pair of consecutive key projections are computed, which then can be stitched together to form the data tour. The morphings should be smooth so that a user can easily follow the transformations, and their computations shall be fast to allow for their integration into an interactive visual exploration process. Moreover, if the key projections are chosen to satisfy additional conditions, it is desirable that these conditions are maintained during morphing. Shape preservation is such a desirable condition, as it avoids shape distortions that may otherwise be caused by a projection. We develop a novel efficient morphing algorithms for computing shape-preserving data tours, i.e., data tours constructed for a sequence of shape-preserving linear projections. We propose a stepping strategy for the morphing to avoid discontinuities in the evolution of the projections, where we represent the linear projections using a star-coordinates system. Our algorithms are less computationally involved, produce smoother morphings, and require less user-defined parameter settings than existing state-of-the-art approaches.", "keywords": "Human-centered computing; Visualization; Visualization techniques", "link": "https://doi.org/10.1109/PacificVis48177.2020.8199", "refList": ["10.2312/eurovisshort.20141152", "10.1109/tvcg.2013.182", "10.1109/tvcg.2008.153", "10.1109/tvcg.2015.2467591", "10.4135/9781412985130", "10.1111/cgf.12878", "10.1016/j.cag.2016.08.007", "10.1080/10618600.1995.10474674", "10.1109/infvis.2003.1249004", "10.1002/9781118445112.stat06472", "10.1109/visual.1997.663916", "10.1111/cgf.12117", "10.1137/0906011", "10.1109/tvcg.2018.2865118", "10.1126/science.290.5500.2319", "10.1111/cgf.12845", "10.1111/j.1467-8659.2012.03125.x", "10.1109/tvcg.2017.2705189", "10.1002/0471725293", "10.1111/cgf.12876", "10.1111/cgf.13404", "10.2307/2289161", "10.1111/cgf.13446", "10.1198/106186008x318440", "10.2307/1390747", "10.1109/tvcg.2012.35", "10.1109/tvcg.2015.2467132", "10.1109/tvcg.2006.94", "10.1109/t-c.1974.224051", "10.1109/pacificvis.2019.00018", "10.1109/tvcg.2017.2744339", "10.1109/tsmcb.2005.850151"], "wos": 1, "children": [], "len": 1}, {"doi": "10.1109/pacificvis.2019.00018", "year": "2019", "title": "Scatterplot Summarization by Constructing Fast and Robust Principal Graphs from Skeletons", "conferenceName": "PacificVis", "authors": "Jos{\\'{e}} Matute;Marcel Fischer;Alexandru C. Telea;Lars Linsen", "citationCount": "1", "affiliation": "Matute, J (Corresponding Author), Univ Munster, Munster, Germany.\nMatute, Jose; Fischer, Marcel; Linsen, Lars, Univ Munster, Munster, Germany.\nTelea, Alexandru C., Univ Groningen, Groningen, Netherlands.", "countries": "Germany;Netherlands", "abstract": "Principal curves are a long-standing and well-known method for summarizing large scatterplots. They are defined as self-consistent curves (or curve sets in the more general case) that locally pass through the middle of the scatterplot data. However, computing principal curves that capture well complex scatterplot topologies and are robust to noise is hard and/or slow for large scatterplots. We present a fast and robust approach for computing principal graphs (a generalization of principal curves for more complex topologies) inspired by the similarity to medial descriptors (curves locally centered in a shape). Compared to state-of-the-art methods for computing principal graphs, we outperform these in terms of computational scalability and robustness to noise and resolution. We also demonstrate the advantages of our method over other scatterplot summarization approaches.", "keywords": "", "link": "https://doi.org/10.1109/PacificVis.2019.00018", "refList": ["10.1016/j.cag.2014.01.006", "10.1016/s0167-8655(02)00032-6", "10.1006/jmva.2000.1917", "10.1111/cgf.12386", "10.1109/vast.2008.4677367", "10.1109/tpami.2004.1261076", "10.1111/cgf.12865", "10.1109/tvcg.2010.213", "10.1109/tvcg.2014.2346455", "10.1109/tvcg.2011.233", "10.1111/j.1467-8659.2009.01680.x", "10.1109/tvcg.2016.2515611", "10.1109/tit.1982.1056489", "10.1109/34.899944", "10.1007/bf01889678", "10.1137/s0036144599352836", "10.1145/2858036.2858155", "10.1002/jhbs.20078", "10.1198/jcgs.2011.09224", "10.1109/tvcg.2017.2744184", "10.1057/ivs.2010.2", "10.1111/j.1467-8659.2012.03107.x", "10.2307/2289936", "10.1109/pacificvis.2014.42", "10.1109/tpami.2008.21", "10.1111/cgf.13446", "10.2307/2290446", "10.1109/34.982884", "10.1109/tvcg.2006.94", "10.2307/2288711", "10.1117/12.304651", "10.5201/ipol.2013.87", "10.1109/mlsp.2008.4685520"], "wos": 1, "children": [{"doi": "10.1109/pacificvis48177.2020.8199", "year": "2020", "title": "Efficient Morphing of Shape-preserving Star Coordinates", "conferenceName": "PacificVis", "authors": "Vladimir Molchanov;Sagad Hamid;Lars Linsen", "citationCount": "0", "affiliation": "Molchanov, V (Corresponding Author), Westfalische Wilhelms Univ Munster, Munster, Germany.\nMolchanov, Vladimir; Hamid, Sagad; Linsen, Lars, Westfalische Wilhelms Univ Munster, Munster, Germany.", "countries": "Germany", "abstract": "Data tours follow an exploratory multi-dimensional data visualization concept that provides animations of projections of the multidimensional data to a 2D visual space. To create an animation, a sequence of key projections is provided and morphings between each pair of consecutive key projections are computed, which then can be stitched together to form the data tour. The morphings should be smooth so that a user can easily follow the transformations, and their computations shall be fast to allow for their integration into an interactive visual exploration process. Moreover, if the key projections are chosen to satisfy additional conditions, it is desirable that these conditions are maintained during morphing. Shape preservation is such a desirable condition, as it avoids shape distortions that may otherwise be caused by a projection. We develop a novel efficient morphing algorithms for computing shape-preserving data tours, i.e., data tours constructed for a sequence of shape-preserving linear projections. We propose a stepping strategy for the morphing to avoid discontinuities in the evolution of the projections, where we represent the linear projections using a star-coordinates system. Our algorithms are less computationally involved, produce smoother morphings, and require less user-defined parameter settings than existing state-of-the-art approaches.", "keywords": "Human-centered computing; Visualization; Visualization techniques", "link": "https://doi.org/10.1109/PacificVis48177.2020.8199", "refList": ["10.2312/eurovisshort.20141152", "10.1109/tvcg.2013.182", "10.1109/tvcg.2008.153", "10.1109/tvcg.2015.2467591", "10.4135/9781412985130", "10.1111/cgf.12878", "10.1016/j.cag.2016.08.007", "10.1080/10618600.1995.10474674", "10.1109/infvis.2003.1249004", "10.1002/9781118445112.stat06472", "10.1109/visual.1997.663916", "10.1111/cgf.12117", "10.1137/0906011", "10.1109/tvcg.2018.2865118", "10.1126/science.290.5500.2319", "10.1111/cgf.12845", "10.1111/j.1467-8659.2012.03125.x", "10.1109/tvcg.2017.2705189", "10.1002/0471725293", "10.1111/cgf.12876", "10.1111/cgf.13404", "10.2307/2289161", "10.1111/cgf.13446", "10.1198/106186008x318440", "10.2307/1390747", "10.1109/tvcg.2012.35", "10.1109/tvcg.2015.2467132", "10.1109/tvcg.2006.94", "10.1109/t-c.1974.224051", "10.1109/pacificvis.2019.00018", "10.1109/tvcg.2017.2744339", "10.1109/tsmcb.2005.850151"], "wos": 1, "children": [], "len": 1}], "len": 3}, {"doi": "10.1111/cgf.13684", "year": "2019", "title": "ClustMe: A Visual Quality Measure for Ranking Monochrome Scatterplots based on Cluster Patterns", "conferenceName": "EuroVis", "authors": "Mostafa M. Abbas;Micha{\\\"{e}}l Aupetit;Michael Sedlmair;Halima Bensmail", "citationCount": "4", "affiliation": "Abbas, MM (Corresponding Author), HBKU, QCRI, Doha, Qatar.\nAbbas, Mostafa M.; Aupetit, Michael; Bensmail, Halima, HBKU, QCRI, Doha, Qatar.\nSedlmair, Michael, Univ Stuttgart, VISUS, Stuttgart, Germany.", "countries": "Qatar;Germany", "abstract": "We propose ClustMe, a new visual quality measure to rank monochrome scatterplots based on cluster patterns. ClustMe is based on data collected from a human-subjects study, in which 34 participants judged synthetically generated cluster patterns in 1000 scatterplots. We generated these patterns by carefully varying the free parameters of a simple Gaussian Mixture Model with two components, and asked the participants to count the number of clusters they could see (1 or more than 1). Based on the results, we form ClustMe by selecting the model that best predicts these human judgments among 7 different state-of-the-art merging techniques (Demp). To quantitatively evaluate ClustMe, we conducted a second study, in which 31 human subjects ranked 435 pairs of scatterplots of real and synthetic data in terms of cluster patterns complexity. We use this data to compare ClustMe's performance to 4 other state-of-the-art clustering measures, including the well-known Clumpiness scagnostics. We found that of all measures, ClustMe is in strongest agreement with the human rankings.", "keywords": "", "link": "https://doi.org/10.1111/cgf.13684", "refList": ["10.1109/tvcg.2014.2330617", "10.1109/tvcg.2014.2346979", "10.1109/tvcg.2017.2744138", "10.1109/tvcg.2017.2701829", "10.2307/2529310", "10.1109/tvcg.2011.229", "10.1109/vast.2011.6102437", "10.1068/p030033", "10.1016/j.jvcir.2011.01.005", "10.1109/tnn.2005.845141", "10.1145/2669557.2669559", "10.1167/8.7.6", "10.1145/2993901.2993907", "10.1145/2803140.2803143", "10.1145/1842993.1843002", "10.1109/pacificvis.2016.7465244", "10.1109/tvcg.2013.124", "10.1057/ivs.2008.13", "10.1109/vast.2012.6400488", "10.1111/j.1467-9574.2008.00412.x", "10.1214/aos/1176344136", "10.1109/tvcg.2015.2467671", "10.3138/y308-2422-8615-1233", "10.1111/j.1467-8659.2012.03125.x", "10.1177/001316446002000104", "10.1145/2858036.2858155", "10.1007/s11634-010-0058-3", "10.1214/009053605000000417", "10.1109/tvcg.2009.153", "10.1023/a:1018510926151", "10.1109/tvcg.2014.2346978", "10.1007/s10816-016-9307-x", "10.1177/0301006615602599", "10.1109/pacificvis.2014.42", "10.1162/neco.1991.3.2.246", "10.1007/3-540-44491-2\\_3", "10.1109/tvcg.2013.153", "10.1111/cgf.13446", "10.1109/tvcg.2018.2846735", "10.2307/2291604", "10.1109/inf0vis.2005.14", "10.1198/016214502760047131", "10.1007/s00180-008-0119-7", "10.1109/t-c.1974.224051", "10.1111/cgf.12632", "10.1109/tvcg.2017.2744339", "10.1111/j.1467-8659.2009.01694.x"], "wos": 1, "children": [{"doi": "10.1109/tvcg.2019.2934796", "title": "Improving the Robustness of Scagnostics", "year": "2019", "conferenceName": "InfoVis", "authors": "Yunhai Wang;Zeyu Wang 0005;Tingting Liu;Michael Correll;Zhanglin Cheng;Oliver Deussen;Michael Sedlmair", "citationCount": "1", "affiliation": "Wang, YH (Corresponding Author), Shandong Univ, Jinan, Peoples R China. Wang, Yunhai; Wang, Zeyu; Liu, Tingting, Shandong Univ, Jinan, Peoples R China. Wang, Zeyu; Cheng, Zhanglin; Deussen, Oliver, SIAT, Shenzhen VisuCA Key Lab, Shenzhen, Peoples R China. Correll, Michael, Tableau Res, Seattle, WA USA. Deussen, Oliver, Konstanz Univ, Constance, Germany. Sedlmair, Michael, Univ Stuttgart, VISUS, Stuttgart, Germany.", "countries": "USA;Germany;China", "abstract": "In this paper, we examine the robustness of scagnostics through a series of theoretical and empirical studies. First, we investigate the sensitivity of scagnostics by employing perturbing operations on more than 60M synthetic and real-world scatterplots. We found that two scagnostic measures, Outlying and Clumpy, are overly sensitive to data binning. To understand how these measures align with human judgments of visual features, we conducted a study with 24 participants, which reveals that i) humans are not sensitive to small perturbations of the data that cause large changes in both measures, and ii) the perception of clumpiness heavily depends on per-cluster topologies and structures. Motivated by these results, we propose Robust Scagnostics (RScag) by combining adaptive binning with a hierarchy-based form of scagnostics. An analysis shows that RScag improves on the robustness of original scagnostics, aligns better with human judgments, and is equally fast as the traditional scagnostic measures.", "keywords": "Scagnostics,scatterplots,sensitivity analysis,Robust Scagnostics", "link": "http://dx.doi.org/10.1109/TVCG.2019.2934796", "refList": ["10.1057/palgrave.ivs.9500122", "10.1109/tvcg.2014.2346979", "10.1111/j.1467-8659.2009.01467.x", "10.1109/vast.2008.4677368", "10.2307/2289444", "10.1109/tvcg.2011.229", "10.1109/iv.2004.1320207", "10.1109/vast.2009.5332628", "10.1111/insr.12095\\_11", "10.1109/tvcg.2010.184", "10.1109/tvcg.2015.2467323", "10.1109/vast.2010.5652460", "10.1111/j.1467-8659.2012.03069.x", "10.1145/1842993.1843002", "10.1198/106186008x320465", "10.1109/pacificvis.2016.7465244", "10.1109/tvcg.2013.20", "10.1111/cgf.12641", "10.1109/tvcg.2012.128", "10.1109/tvcg.2015.2467671", "10.1057/palgrave.ivs.9500091", "10.1007/978-1-4612-4400-4", "10.1111/cgf.13176", "10.1002/0470870958", "10.1109/tvcg.2018.2864907", "10.1111/j.1467-8659.2012.03125.x", "10.1109/vast.2012.6400490", "10.1109/infvis.2005.1532142", "10.1109/vast.2010.5652433", "10.1109/vast.2009.5332611", "10.1201/9781315140919", "10.1145/2858036.2858155", "10.1109/ldav.2013.6675164", "10.1515/itit-2014-1070", "10.1111/cgf.13684", "10.1109/tpami.1979.4766909", "10.2307/2289936", "10.1109/pacificvis.2014.42", "10.1109/tvcg.2016.2598467", "10.1109/tvcg.2013.153", "10.1111/cgf.13446", "10.1109/tvcg.2006.94", "10.1109/tvcg.2014.2346572", "10.1111/cgf.12632", "10.1109/tvcg.2017.2744339"], "wos": 1, "children": [], "len": 1}, {"doi": "10.1109/tvcg.2020.3030365", "title": "Modeling the Influence of Visual Density on Cluster Perception in Scatterplots Using Topology", "year": "2020", "conferenceName": "InfoVis", "authors": "Ghulam Jilani Quadri;Paul Rosen", "citationCount": "0", "affiliation": "Quadri, GJ (Corresponding Author), Univ S Florida, Tampa, FL 33620 USA. Quadri, Ghulam Jilani; Rosen, Paul, Univ S Florida, Tampa, FL 33620 USA.", "countries": "USA", "abstract": "Scatterplots are used for a variety of visual analytics tasks, including cluster identification, and the visual encodings used on a scatterplot play a deciding role on the level of visual separation of clusters. For visualization designers, optimizing the visual encodings is crucial to maximizing the clarity of data. This requires accurately modeling human perception of cluster separation, which remains challenging. We present a multi-stage user study focusing on four factors-distribution size of clusters, number of points, size of points, and opacity of points-that influence cluster identification in scatterplots. From these parameters, we have constructed two models, a distance-based model, and a density-based model, using the merge tree data structure from Topological Data Analysis. Our analysis demonstrates that these factors play an important role in the number of clusters perceived, and it verifies that the distance-based and density-based models can reasonably estimate the number of clusters a user observes. Finally, we demonstrate how these models can be used to optimize visual encodings on real-world data.", "keywords": "Scatterplot,clustering,perception,empirical evaluation,visual encoding,crowdsourcing,topological data analysis", "link": "http://dx.doi.org/10.1109/TVCG.2020.3030365", "refList": ["10.1109/tvcg.2017.2744359", "10.1145/1778765", "10.1109/tvcg.2019.2934799", "10.1111/cgf.12889", "10.1109/tvcg.2011.127", "10.1111/cgf.13444", "10.1145/1964897.1964910", "10.1167/8.7.6", "10.1145/3173574.3173991", "10.1145/1556262.1556289", "10.1145/1056808.1056914", "10.2307/2288400", "10.1109/tvcg.2014.2346594", "10.1109/iv.2002.1028760", "10.1177/001316447303300111", "10.1007/bf02289823", "10.1109/tvcg.2017.2744339", "10.1111/j.1467-8659.2009.01694.x", "10.1109/tvcg.2014.2346979", "10.1090/mbk/069", "10.1109/tvcg.2013.65", "10.1109/mcg.2012.37", "10.1109/pacificvis.2010.5429604", "10.1002/acp.2350050106", "10.1109/infvis.2005.1532136", "10.1177/1473871612465214", "10.1109/tvcg.2017.2674978", "10.1002/jhbs.20078", "10.1007/978-3-642-35142-6\\_14", "10.1007/978-3-319-71507-0", "10.1109/mcg.201.7.6", "10.3758/bf03193961", "10.1364/josa.49.000280", "10.1145/3025453.3025905", "10.1109/tvcg.201.9.2934541", "10.1109/tvcg.2018.2829750", "10.1177/1473871615606187", "10.1111/cgf.13408", "10.1109/pacificvis.2016.7465252", "10.1109/pacificvis.2016.7465244", "10.1109/inevis.2005.1532142", "10.1111/cgf.13414", "10.1111/j.1467-8659.2012.03125.x", "10.1167/16.5.11", "10.1109/infvis.2005.1532142", "10.1145/2858036.2858155", "10.1038/nmeth1210-941", "10.1177/1473871616638892", "10.1109/tcbb.2014.2306840", "10.1111/cgf.13684", "10.1177/0301006615602599", "10.1214/aoms/1177731915", "10.1145/2702123.2702585", "10.1109/tvcg.2013.183", "10.1109/tvcg.2014.2346572", "10.1109/tvcg.2018.2875702", "10.1109/tvcg.2017.2754480", "10.1109/vast.2014.7042493", "10.1057/palgrave.ivs.9500122", "10.1109/tvcg.2014.2330617", "10.1109/tvcg.2019.2934541", "10.1068/p030033", "10.1140/epjds/s13688-017-0109-5", "10.1201/b17511", "10.1016/s0925-7721(02)00093-7", "10.1109/pacificvis.2012.6183557", "10.1109/tvcg.2014.2346983", "10.1109/5.726791", "10.1080/01621459.1926.10502165", "10.1109/tvcg.2007.70535", "10.1109/tvcg.2018.2864907", "10.1111/cgf.12109", "10.1109/tvcg.2017.2744184", "10.1146/annurev-statistics-031017-100045", "10.1111/cgf.13409", "10.1145/3002151.3002162", "10.1016/s0378-4371(98)00494-4", "10.3138/y308-2422-8615-1233", "10.1111/cgf.12632", "10.1145/3290605.3300771"], "wos": 1, "children": [], "len": 1}, {"doi": "10.1111/cgf.14034", "year": "2020", "title": "The State of the Art in Enhancing Trust in Machine Learning Models with the Use of Visualizations", "conferenceName": "EuroVis", "authors": "Angelos Chatzimparmpas;Rafael Messias Martins;Ilir Jusufi;Kostiantyn Kucher;Fabrice Rossi;Andreas Kerren", "citationCount": "2", "affiliation": "Chatzimparmpas, A (Corresponding Author), Linnaeus Univ, Dept Comp Sci \\& Media Technol, Vaxjo, Sweden.\nChatzimparmpas, A.; Martins, R. M.; Jusufi, I.; Kucher, K.; Kerren, A., Linnaeus Univ, Dept Comp Sci \\& Media Technol, Vaxjo, Sweden.\nRossi, F., PSL Univ, Univ Paris Dauphine, Ceremade, Paris, France.", "countries": "Sweden;France", "abstract": "Machine learning (ML) models are nowadays used in complex applications in various domains, such as medicine, bioinformatics, and other sciences. Due to their black box nature, however, it may sometimes be hard to understand and trust the results they provide. This has increased the demand for reliable visualization tools related to enhancing trust in ML models, which has become a prominent topic of research in the visualization community over the past decades. To provide an overview and present the frontiers of current research on the topic, we present a State-of-the-Art Report (STAR) on enhancing trust in ML models with the use of interactive visualization. We define and describe the background of the topic, introduce a categorization for visualization techniques that aim to accomplish this goal, and discuss insights and opportunities for future research directions. Among our contributions is a categorization of trust against different facets of interactive ML, expanded and improved from previous research. Our results are investigated from different analytical perspectives: (a) providing a statistical overview, (b) summarizing key findings, (c) performing topic analyses, and (d) exploring the data sets used in the individual papers, all with the support of an interactive web-based survey browser. We intend this survey to be beneficial for visualization researchers whose interests involve making ML models more trustworthy, as well as researchers and practitioners from other disciplines in their search for effective visualization techniques suitable for solving their tasks with confidence and conveying meaning to their data.", "keywords": "trustworthy machine learning; visualization; interpretable machine learning; explainable machine learning", "link": "https://doi.org/10.1111/cgf.14034", "refList": ["10.1109/mcg.2018.2878902", "10.1109/tvcg.2008.153", "10.2312/mlvis.20181130", "10.1109/tvcg.2016.2598828", "10.1145/3290605.3300911", "10.1145/2993901.2993909", "10.2312/mlvis.20191158", "10.1109/tvcg.2016.2598446", "10.1111/j.1467-8659.2009.01475.x", "10.1145/3290605.3300809", "10.1109/pacificvis.2018.00031", "10.1055/s-0029-1216348", "10.1007/978-3-319-90403-0\\_13", "10.1109/tvcg.2017.2745085", "10.1111/j.1467-8659.2011.01938.x", "10.1007/978-3-319-54024-5\\_6", "10.1016/s0167-9473(01)00065-2", "10.1111/cgf.12895", "10.2312/eurovisshort.20141152.17", "10.2312/eurova.20151098.22", "10.1111/cgf.13667", "10.3115/1072228.1072378", "10.1109/tbdata.2018.2877350.16", "10.1109/lars.2009.5418323.25", "10.1109/tvcg.2017.2744878", "10.1016/j.combustflame.2005.09.018", "10.1016/j.cag.2014.01.006", "10.1109/tvcg.2016.2570755", "10.2312/mlvis.20191158.1,19", "10.1518/hfes.46.1.50.30392", "10.1145/3301275.3302280", "10.1145/3351095.3372834.1", "10.1016/s0377-2217(01)00264-8", "10.1111/cgf.13424", "10.1007/978-3-319-23485-4\\_53", "10.1007/978-94-007-0753-5\\_3623", "10.1109/tvcg.2013.101", "10.1111/cgf.12884", "10.1111/j.1467-8659.2010.01835.x", "10.1021/ci9901338", "10.4230/lipics.itcs:2017", "10.1109/mis.2013.24", "10.1109/tvcg.2014.2346482", "10.1109/tvcg.2018.2865230", "10.1073/pnas.1807180116", "10.1109/dsaa.2018.00018", "10.1109/tvcg.2009.153", "10.3115/1219840.1219855", "10.1109/tvcg.2018.2864812", "10.1109/tvcg.2018.2872577", "10.2312/trvis.20191183", "10.1109/cvpr:2004.383", "10.1109/vast.2008.4677350", "10.1145/302979.303001", "10.1109/tvcg.2018.2864499", "10.1111/cgf.13672", "10.1109/tvcg.2014.2346626", "10.23915/distill.00010.18", "10.1109/tvcg.2017.2744805", "10.2312/mlvis:20191160.18", "10.23915/distill:00016", "10.1109/pacificvis.2016.7465260", "10.1111/cgf.13683", "10.23915/distill.00016.19", "10.1145/32906053.300803.22", "10.1109/tvcg.2014.2346574", "10.1177/1473871615600010", "10.1109/tvcg.2016.2598831", "10.1145/3230623", "10.1109/visual.2019.8933744", "10.1145/2993901.2993915", "10.1016/j.visinf.2017.01.006", "10.1145/2993901.2993914", "10.1109/tvcg.2014.2346984", "10.1109/5.726791", "10.23915/distill.00010", "10.1109/tvcg.2018.2864825", "10.2307/2394164", "10.1109/tvcg.2017.2744458", "10.1145/2993901.2993917.28", "10.1111/cgf.13711", "10.1109/tvcg.2016.2598664", "10.2307/2530428", "10.1109/icdar.1997.620583", "10.1109/tvcg.2017.2744718", "10.1111/cgf.13425", "10.1109/tvcg.2019.2903943", "10.1145/1518701.1518895", "10.1109/tvcg.2018.2864838", "10.1145/62038.62043", "10.1111/j.1467-8659.2011.01920.x", "10.1145/3025171.3025208", "10.1145/355112.355124", "10.1109/vast.2010.5652398", "10.1109/tvcg.2014.2346578", "10.1145/3173574.3174209", "10.4178/epih/e2014008", "10.1109/beliv.2018.8634201.25,28", "10.1016/j.eswa.2007.12.020", "10.1111/cgf:13406", "10.1109/mcg.2011.103", "10.1631/fitee.1700808", "10.1109/tvcg.2017.2745158", "10.1073/pnas.0307752101", "10.1109/tvcg.2018.2816223", "10.1109/tvcg.2017.2745141", "10.1145/32232.32234", "10.1109/tvcg.2019.2934267", "10.1109/tvcg.2018.2864477", "10.1145/3132169", "10.2312/eurova.20151100.19", "10.1145/3172944.3172964", "10.1145/2601248.2601268", "10.1109/isai-nlp.2018.8693002.1", "10.1111/cgf.13404", "10.1007/s100320200071", "10.2312/trvis.20191183.16", "10.1111/cgf.12755", "10.1145/2702123.2702509", "10.1145/1401890.1402008.25", "10.1109/tvcg.2012.65", "10.1177/1473871617733996", "10.2312/trvis.20191187.7", "10.21236/ada273556", "10.1109/vast.2010.5652450", "10.1111/j.1467-8659.2011.01940.x", "10.1177/875647939000600106", "10.1109/tvcg.2017.2711030", "10.1016/j.immuni.2016.04.014", "10.1109/tvcg.2019.2934209", "10.1016/0095-0696(78)90006-2", "10.1016/j.jclinepi.2015.04.014", "10.1016/j.ress.2013.02.013", "10.1111/cgf.12640", "10.1145/1015330.1015388.25", "10.1111/j.1467-8659.2009.01468.x", "10.1145/1541880.1541882", "10.1109/vast.2011.6102453", "10.1016/s0008-8846(98)00165-3", "10.2312/trvis.20191186.7", "10.1007/s13748-013-0040-3", "10.1109/tvcg.2015.2467757", "10.1109/tbdata.2018.2877350", "10.1109/vast.2017.8585613", "10.1080/10556789208805504", "10.1109/vast.2012.6400484", "10.1145/3025171.3025181", "10.1007/978-3-319-90403-0\\_12", "10.1109/mcg.2019.2922592", "10.1021/ci000392t", "10.1109/vast.2007.4389000", "10.1111/cgf.13406.16", "10.1111/cgf.13684", "10.2312/eurovisshort.20161166.17", "10.2312/evs:20191168", "10.1145/3041021.3055135", "10.1145/3301275.3302265", "10.1613/jair.4135", "10.1109/tvcg.2018.2864500", "10.1109/tvcg.2017.2744158", "10.1109/ssci.2015.33", "10.1111/cgf.13453", "10.2312/pe/eurovast/eurova11/049-052", "10.1145/3025171.3025181.13", "10.1145/371920.372094", "10.1109/tvcg.2017.2744938", "10.1111/j.1467-8659.2012.03108.x", "10.1109/tvcg.2019.2934251", "10.1145/3290605.3300809.18", "10.1109/ldav.2016.7874305", "10.1109/vast.2016.7883514", "10.1109/iccv.2015.425", "10.1145/3301275.3302324", "10.1109/tnnls.2013.2292894", "10.1109/tvcg.2018.2865044", "10.1109/tvcg.2013.157", "10.1371/journal.pcbi.0020161", "10.1186/s12916-019-1426-2", "10.1109/10.867928", "10.1111/cgf.13217", "10.1109/mcg.2019.2919033", "10.1145/2993901.2993910", "10.1109/tvcg.2017.2744738", "10.2307/258792", "10.1111/cgf.12655", "10.1016/j.dss.2014.03.001", "10.1109/tvcg.2019.2904069", "10.1111/cgf.13205", "10.1002/mds.22340", "10.1109/tvcg.2019.2934595", "10.1287/inte.2018.0957", "10.1109/cvpr.2007.382974", "10.1109/tvcg.2012.280", "10.1145/2678025.2701399.13", "10.2312/mlvis.20181130.13", "10.2312/eurova.20181106.16", "10.1109/tvcg.2018.2864475", "10.2312/mlvis.20191160.18,22", "10.1007/978-1-4612-4026-6.25", "10.1109/cvpr.2006.42", "10.1145/3172944.3172950", "10.1109/cvpr.2004.383.25", "10.1109/tvcg.2019.2934812", "10.1609/aimag.v35i4.2513", "10.2312/trvis.20191185.7", "10.1111/j.1467-8659.2009.01684.x", "10.1371/journal.pone.0129126", "10.1111/cgf.13092", "10.1162/coli\\_a\\_00237", "10.1109/tvcg.2017.2744818", "10.1109/vast.2011.6102448", "10.1109/tvcg.2009.111", "10.1109/tvcg.2019.2934619", "10.1016/s0377-2217(01)00264-8.25", "10.1111/cgf.12639", "10.1109/access.2019.2919343", "10.1186/s12874-019-0681-4", "10.1109/pacificvis.2015.7156366", "10.1109/pacificvis.2018.00029", "10.1109/tvcg.2019.2934261", "10.1080/13506280444000102.http://www.uvt.nl/ticc", "10.1109/vast.2018.8802509", "10.1111/cgf.13212", "10.1145/3200489", "10.1111/cgf.13176", "10.1177/1473871620904671", "10.1007/978-3-319-10590-1\\_53", "10.1111/j.1467-8659.2012.03126.x", "10.1111/cgf.13172", "10.1145/3025171.3025208.6,21", "10.1111/cgf.12366", "10.1109/tvcg.2019.2934659", "10.1109/cvprw.2009.5206848", "10.1016/j.media.2014.11.010", "10.1109/tvcg.2017.2744683", "10.1109/tvcg.2019.2934262", "10.1016/j.neucom.2006.11.018", "10.1177/1473871615571951", "10.1371/journal.pcbi.0020161.25", "10.1177/1473871611415994", "10.2312/trvis20191187", "10.2312/eurova", "10.1145/2858036.2858529", "10.1145/2207676.2207738", "10.1007/s11042-009-0417-2", "10.1145/3301275.3302317", "10.1038/s41746-019-0148-3", "10.1145/3351095.3372834", "10.1080/10691898.2011.11889627", "10.1109/tvcg.2018.2864504", "10.1109/vast.2017.8585720", "10.1109/mcg.2018.053491732", "10.1007/s10994-010-5207-6", "10.1109/tvcg.2019.2934433", "10.1016/j.cag.2017.05.005", "10.1109/tvcg.2012.279", "10.1145/3231622.3231641.19,20", "10.1145/1562849.1562851", "10.1007/11564126\\_", "10.1109/tvcg.2018.2846735", "10.3115/1225403.1225421", "10.1109/vast.2012.6400486", "10.2312/eurova.20191116.22", "10.1109/tvcg.2007.70443", "10.1080/027868291009242", "10.2312/eurova.20151100", "10.1145/2939502.2939503.19", "10.1016/j.cag.2014.02.004", "10.1145/2939672.2939778", "10.1109/vast.2010.5652484", "10.1111/cgf.12641", "10.1145/3301275.3302289", "10.1109/visual.2019.8933619", "10.1109/tvcg.2017.2672987", "10.1109/vast.2016.7883517.20", "10.1109/igarss.2017.8127684", "10.1016/j.jcae.2010.04.002", "10.1109/vast.2010.5652885", "10.1016/j.visinf.2019.03.002", "10.1007/s00371-018-1500-3", "10.1109/mcg.2018.042731661", "10.1109/34.598228", "10.1109/tvcg.2018.2865027", "10.1016/j.neucom.2017.01.105", "10.1111/cgf.12389", "10.1109/tvcg.2019.2934591", "10.1109/vast.2010.5652392.16", "10.1111/cgf.13416", "10.1080/02701367.1992.10608764", "10.1109/vast.2017.8585721", "10.1109/tvcg.2018.2843369", "10.1109/sbes.2010.27", "10.1109/vast.2015.7347637", "10.1145/1401890.1402008", "10.1016/j.bpj.2010.04.064", "10.1109/tvcg.2013.125", "10.1109/isai-nlp.2018.8693002", "10.1371/journal.pone.0160127", "10.1145/2856767.2856779", "10.1145/2678025.2701399", "10.1109/vast.2011.6102451", "10.1109/mcg.2010.18", "10.1021/ci4000213", "10.1109/vast.2012.6400492", "10.1007/11564126-49.25", "10.2312/eurova.20171114", "10.1109/vast.2010.5652443", "10.1145/3134599", "10.2312/pe/eurovast/eurovast10/013-018.19", "10.1109/tvcg.2019.2903946", "10.1109/tvcg.2015.2467717", "10.1177/1473871612460526", "10.1016/j.cag.2018.09.018", "10.1109/tvcg.2016.2598838", "10.1145/3172944.3172964.14", "10.1109/vast.2009.5333428", "10.1109/vast.2014.7042480", "10.2312/pe/eurovast/eurovast10/013-018", "10.1177/0962280215588241", "10.1145/2993901.2993917", "10.1109/cvpr.2008:4587581", "10.1109/tvcg.2015.2467551", "10.1016/j.visinf.2018.09.001", "10.1126/science.290.5500.2319", "10.2312/eurova.20151107", "10.1109/visual.2019.8933695", "10.13140/2.1.2393.1847", "10.1197/jamia.m1929", "10.1109/cvpr.2008.4587581.25", "10.1145/1518701.1518895.16", "10.1109/vds.2017.8573444", "10.2312/trvis:20191185", "10.1145/3359786", "10.13140/2.1.1341.1520", "10.2312/pe/eurovast/eurova11/049-052.17", "10.1109/tvcg.2014.2346660", "10.1145/3185517", "10.1109/adprl.2011.5967372", "10.1109/tvcg.2015.2467591", "10.1111/j.1751-9004.2009.00232.x", "10.1136/qshc.2004.010033", "10.1109/vast.2012.6400493", "10.1109/tvcg.2019.2934266", "10.1145/2971763.2971775", "10.1111/cgf.13730", "10.1109/vast.2012.6400488", "10.1111/cgf.13210", "10.1109/tvcg.2019.2934631", "10.1145/3172944.3172965", "10.1057/ivs.2010.2", "10.1109/tvcg.2017.2745258", "10.1016/j.jbusres.2019.07.039", "10.1162/jmlr.2003.3.4-5.993", "10.1109/pacificvis.2019.00044", "10.2312/pe/eurovast/eurova12/037-041", "10.1109/tvcg.2019.2934629", "10.1177/0018720814547570", "10.1145/3292500.3330908", "10.1111/j.1467-8659.2009.01467.x", "10.2312/eurova.20151098", "10.1177/1473871617713337", "10.1109/lars:2009.5418323", "10.1109/vast.2011.6102437", "10.1111/cgf.12878", "10.1561/1500000001", "10.1145/3025171.3025222", "10.1007/s11704-016-6028-y", "10.1016/j.procs.2017.05.216", "10.1109/cvpr.2007.382974.25", "10.1080/10447318.2020.1741118", "10.1109/vast.2012.6400489", "10.1145/3025171.3025172", "10.1109/tvcg.2017.2744098", "10.1109/tvcg.2005.66", "10.1016/j.dss.2009.05.016", "10.1007/978-1-4612-4026-6", "10.2312/evs.20191168.16,20,28", "10.2312/pe/eurovast/eurova12/037-041.17", "10.1145/3290605.3300803", "10.1145/1015330.1015388", "10.1111/cgf.13197", "10.1016/b978-1-55860-377-6.50048-7", "10.1111/cgf.13681", "10.1109/tvcg.2017.2744378", "10.1109/tvcg.2017.2744358", "10.1109/vast.2008.4677352"], "wos": 1, "children": [{"doi": "10.1109/tvcg.2020.3030368", "title": "Implicit Multidimensional Projection of Local Subspaces", "year": "2020", "conferenceName": "InfoVis", "authors": "Rongzheng Bian;Yumeng Xue;Liang Zhou;Jian Zhang 0070;Baoquan Chen;Daniel Weiskopf;Yunhai Wang", "citationCount": "1", "affiliation": "Wang, YH (Corresponding Author), Shandong Univ, Qingdao, Peoples R China. Zhou, L (Corresponding Author), Univ Utah, Salt Lake City, UT 84112 USA. Bian, Rongzheng; Xue, Yumeng; Wang, Yunhai, Shandong Univ, Qingdao, Peoples R China. Chen, Baoquan, Peking Univ, Beijing, Peoples R China. Zhang, Jian, Chinese Acad Sci, CNIC, Beijing, Peoples R China. Zhou, Liang, Univ Utah, Salt Lake City, UT 84112 USA. Weiskopf, Daniel, Univ Stuttgart, Stuttgart, Germany.", "countries": "USA;Germany;China", "abstract": "We propose a visualization method to understand the effect of multidimensional projection on local subspaces, using implicit function differentiation. Here, we understand the local subspace as the multidimensional local neighborhood of data points. Existing methods focus on the projection of multidimensional data points, and the neighborhood information is ignored. Our method is able to analyze the shape and directional information of the local subspace to gain more insights into the global structure of the data through the perception of local structures. Local subspaces are fitted by multidimensional ellipses that are spanned by basis vectors. An accurate and efficient vector transformation method is proposed based on analytical differentiation of multidimensional projections formulated as implicit functions. The results are visualized as glyphs and analyzed using a full set of specifically-designed interactions supported in our efficient web-based visualization tool. The usefulness of our method is demonstrated using various multi- and high-dimensional benchmark datasets. Our implicit differentiation vector transformation is evaluated through numerical comparisons; the overall method is evaluated through exploration examples and use cases.", "keywords": "High-dimensional data visualization,dimensionality reduction,local linear subspaces,user interaction", "link": "http://dx.doi.org/10.1109/TVCG.2020.3030368", "refList": ["10.3844/jcssp.2018.613.622", "10.1016/j.aci.2018.08.003", "10.3390/info9030065", "10.1016/j.visinf.2018.09.003", "10.1371/journal.pone.0118432", "10.1016/s0893-6080(05)80023-1", "10.1109/tvcg.2020.2986996", "10.1109/icst.2012.56", "10.1007/s10844-013-0250-y", "10.1109/tbdata.2018", "10.1145/1125451.1125659", "10.1109/tvcg.2013.125", "10.1177/1473871611412817", "10.1145/3290605.3300911", "10.1111/cgf.14034", "10.1007/s13721-013-0034-x", "10.1016/j.procs.2017.05.216", "10.1016/j.ins.2009.08.025", "10.1109/tvcg.2013.124", "10.1109/tvcg.2018.2864499", "10.1109/tvcg.2018.2864475", "10.1080/10447318.2020.1741118", "10.1016/j.imu.2019.100203", "10.1109/tvcg.2018.2865240", "10.1186/s12864-019-6413-7", "10.1109/tvcg.2015.2467551", "10.1002/widm.1249", "10.1007/978-3-319-66429-3\\_29", "10.1109/tvcg.2014.2346481", "10.1109/tvcg.2018.2864825", "10.1177/1473871620904671", "10.1109/tvcg.2019.2934267", "10.1136/bmjopen-2016-012799", "10.1109/smartgridcomm.2017.8340682", "10.1007/s10664-015-9401-9", "10.1145/1143844.1143874", "10.1111/cgf.12389", "10.1109/tvcg.2018.2872577", "10.1007/978-981-13-5802-9\\_20", "10.1016/j.ipm.2009.03.002", "10.5220/0006431602160222", "10.1109/mcg.2015.50", "10.1109/tvcg.2014.2346574", "10.1007/bf02289565", "10.1109/tvcg.2017.2744378", "10.1016/j.patrec.2008.08.010", "10.1023/a:1010933404324", "10.9735/2229-3981"], "wos": 1, "children": [], "len": 1}, {"doi": "10.1109/tvcg.2020.3030465", "title": "Visual Causality Analysis of Event Sequence Data", "year": "2020", "conferenceName": "VAST", "authors": "Zhuochen Jin;Shunan Guo;Nan Chen;Daniel Weiskopf;David Gotz;Nan Cao", "citationCount": "0", "affiliation": "Cao, N (Corresponding Author), Tongji Univ, IDVx Lab, Shanghai, Peoples R China. Jin, Zhuochen; Guo, Shunan; Chen, Nan; Cao, Nan, Tongji Univ, IDVx Lab, Shanghai, Peoples R China. Weiskopf, Daniel, Univ Stuttgart, Stuttgart, Germany. Gotz, David, Univ N Carolina, Chapel Hill, NC 27515 USA.", "countries": "USA;Germany;China", "abstract": "Causality is crucial to understanding the mechanisms behind complex systems and making decisions that lead to intended outcomes. Event sequence data is widely collected from many real-world processes, such as electronic health records, web clickstreams, and financial transactions, which transmit a great deal of information reflecting the causal relations among event types. Unfortunately, recovering causalities from observational event sequences is challenging, as the heterogeneous and high-dimensional event variables are often connected to rather complex underlying event excitation mechanisms that are hard to infer from limited observations. Many existing automated causal analysis techniques suffer from poor explainability and fail to include an adequate amount of human knowledge. In this paper, we introduce a visual analytics method for recovering causalities in event sequence data. We extend the Granger causality analysis algorithm on Hawkes processes to incorporate user feedback into causal model refinement. The visualization system includes an interactive causal analysis framework that supports bottom-up causal exploration, iterative causal verification and refinement, and causal comparison through a set of novel visualizations and interactions. We report two forms of evaluation: a quantitative evaluation of the model improvements resulting from the user-feedback mechanism, and a qualitative evaluation through case studies in different application domains to demonstrate the usefulness of the system.", "keywords": "Event sequence data,causality analysis,visual analytics", "link": "http://dx.doi.org/10.1109/TVCG.2020.3030465", "refList": ["10.5555/1642718", "10.1109/tvcg.2018.2865022", "10.5555/2074094.2074151", "10.1109/tvcg.2016.2618797", "10.1073/pnas.1320645111", "10.1109/tvcg.2017.2744843", "10.1109/iv.2017.69", "10.1109/tvcg.2019.2934399", "10.1145/3172944.3173007", "10.5555/1795555", "10.1109/mcg.2005.102", "10.1145/381641.381653", "10.1162/153244301753344614", "10.1111/cgf.14034", "10.1111/cgf.13198", "10.1017/cbo9780511519857", "10.1007/s10462-016-9475-9", "10.1075/ssol.2.2.07bor", "10.1007/978-1-4614-3223-4\\_3", "10.1109/infvis.2003.1249025", "10.1007/978-94-007-6094-313", "10.1145/2858036.2858387", "10.1109/tvcg.2007.70528", "10.1109/tvcg.2017.2674958", "10.1147/sj.454.0801", "10.1109/tvcg.2013.119", "10.1145/3173574.3173711", "10.1016/j.erss.2017.06.034", "10.1109/visual.2019.8933695", "10.1007/s11665-016-2173-6", "10.1016/0377-0427(87)90125-7", "10.2307/3601125", "10.1016/b978-0-444-88738-2.50018-x", "10.1109/mcg.2006.70", "10.1109/tvcg.2018.2865145", "10.1017/s1351324997001502", "10.1109/tvcg.2010.179", "10.1214/aos/1176344552", "10.1109/mcg.2009.22", "10.1007/978-3-319-26633-6\\_13", "10.1080/10447318.2014.905422", "10.1016/j.visinf.2019.03.004", "10.1057/palgrave.ivs.9500074", "10.1007/978-1-4614-3223-4"], "wos": 1, "children": [], "len": 1}], "len": 5}, {"doi": "10.1111/cgf.14001", "year": "2020", "title": "Sunspot Plots: Model-based Structure Enhancement for Dense Scatter Plots", "conferenceName": "EuroVis", "authors": "Thomas Trautner;Fabian Bolte;Sergej Stoppel;Stefan Bruckner", "citationCount": "0", "affiliation": "Trautner, T (Corresponding Author), Univ Bergen, Bergen, Norway.\nTrautner, T.; Bolte, F.; Stoppel, S.; Bruckner, S., Univ Bergen, Bergen, Norway.", "countries": "Norway", "abstract": "Scatter plots are a powerful and well-established technique for visualizing the relationships between two variables as a collection of discrete points. However, especially when dealing with large and dense data, scatter plots often exhibit problems such as overplotting, making the data interpretation arduous. Density plots are able to overcome these limitations in highly populated regions, but fail to provide accurate information of individual data points. This is particularly problematic in sparse regions where the density estimate may not provide a good representation of the underlying data. In this paper, we present sunspot plots, a visualization technique that communicates dense data as a continuous data distribution, while preserving the discrete nature of data samples in sparsely populated areas. We furthermore demonstrate the advantages of our approach on typical failure cases of scatter plots within synthetic and real-world data sets and validate its effectiveness in a user study.", "keywords": "", "link": "https://doi.org/10.1111/cgf.14001", "refList": ["10.1057/palgrave.ivs.9500122", "10.2312/eggh/hpg12/097-103", "10.1109/tvcg.2008.119", "10.1109/pacificvis.2011.5742387", "10.1038/331163a0", "10.1109/visual.2019.8933620", "10.2307/2683294", "10.1201/9781351072304", "10.2307/2289444", "10.1109/tvcg.2019.2934541", "10.1080/00949657508810123", "10.1109/tvcg.2013.65", "10.1109/infvis.1997.636789", "10.1109/2945.841121", "10.1109/mcse.2007.55", "10.1109/tvcg.2010.197", "10.1111/cgf.12871", "10.1109/infvis.2003.1249018", "10.1145/3173574.3173991", "10.1109/tvcg.2012.238", "10.1007/0-387-28695-0", "10.1109/pacificvis.2010.5429604", "10.18637/jss.v008.i03", "10.1109/tvcg.2007.70596", "10.1109/visual.1998.745301", "10.1007/0-387-37977-0\\_3", "10.1145/1556262.1556289", "10.2312/wiced.20161094", "10.1109/tvcg.2007.70535", "10.1145/1056808.1056914", "10.1109/tvcg.2003.1196007", "10.1109/iv.2004.1320190", "10.1111/cgf.12877", "10.1162/leon.2007.40.2.202a", "10.1109/tvcg.2017.2674978", "10.1057/ivs.2010.4", "10.1016/j.cag.2018.02.008", "10.1201/9781315140919", "10.1109/visual.2000.885677", "10.1002/jhbs.20078", "10.1109/tvcg.2014.2346594", "10.1109/tvcg.2017.2744184", "10.1109/visual.2001.964495", "10.1109/iv.2002.1028760", "10.1111/cgf.13684", "10.1109/hicss.2013.197", "10.1109/tvcg.2019.2903956", "10.1093/mnras/stt961", "10.1109/tvcg.2017.2668409", "10.1111/j.1467-8659.2009.01478.x", "10.1145/2702123.2702585", "10.2307/1418003", "10.2307/1390742", "10.1145/360825.360839", "10.1109/pacificvis.2009.4906843", "10.1057/ivs.2009.34", "10.2307/2288711"], "wos": 1, "children": [], "len": 1}], "len": 13}, {"doi": "10.1111/cgf.14000", "year": "2020", "title": "Evaluating Reordering Strategies for Cluster Identification in Parallel Coordinates", "conferenceName": "EuroVis", "authors": "Michael Blumenschein;Xuan Zhang;David Pomerenke;Daniel A. Keim;Johannes Fuchs", "citationCount": "0", "affiliation": "Blumenschein, M (Corresponding Author), Univ Konstanz, Constance, Germany.\nBlumenschein, Michael; Pomerenke, David; Keim, Daniel A.; Fuchs, Johannes, Univ Konstanz, Constance, Germany.\nZhang, Xuan, Rhein Westfal TH Aachen, Aachen, Germany.", "countries": "Germany", "abstract": "The ability to perceive patterns in parallel coordinates plots (PCPs) is heavily influenced by the ordering of the dimensions. While the community has proposed over 30 automatic ordering strategies, we still lack empirical guidance for choosing an appropriate strategy for a given task. In this paper, we first propose a classification of tasks and patterns and analyze which PCP reordering strategies help in detecting them. Based on our classification, we then conduct an empirical user study with 31 participants to evaluate reordering strategies for cluster identification tasks. We particularly measure time, identification quality, and the users' confidence for two different strategies using both synthetic and real-world datasets. Our results show that, somewhat unexpectedly, participants tend to focus on dissimilar rather than similar dimension pairs when detecting clusters, and are more confident in their answers. This is especially true when increasing the amount of clutter in the data. As a result of these findings, we propose a new reordering strategy based on the dissimilarity of neighboring dimension pairs.", "keywords": "", "link": "https://doi.org/10.1111/cgf.14000", "refList": ["10.1111/j.1467-8659.2008.01241.x", "10.2312/conf/eg2013/stars/095-116", "10.1109/tvcg.2014.2346979", "10.1117/12.838819", "10.2307/2290001", "10.1111/cgf.12638", "10.1007/978-3-642-30217-6\\_42", "10.1109/sc.2005.47", "10.1002/wics.145", "10.1109/tvcg.2011.229", "10.1109/vast.2009.5332628", "10.1109/vast.2017.8585613", "10.1145/2993901.2993907", "10.1007/bf00410640", "10.1109/tvcg.2010.184", "10.11591/ijece.v5i6", "10.1111/j.1467-8659.2011.01961.x", "10.1109/visual.1997.663916", "10.1111/j.1467-8659.2012.03129.x", "10.1109/visual.1999.809866", "10.1057/ivs.2008.13", "10.1016/j.visinf.2017.11.001", "10.2307/2282967", "10.1007/978-0-387-68628-8\\_10", "10.5888/pcd9.120082", "10.1109/tvcg.2007.70535", "10.1109/vast.2010.5652450", "10.1007/bf01898350", "10.1016/0010-0285(91)90009-d", "10.1007/978-3-642-24958-7\\_12", "10.1109/infvis.2005.1532142", "10.1057/palgrave.ivs.9500166", "10.1111/j.1467-8659.2008.01239.x", "10.1109/mcse.2015.55", "10.2312/pe/eurovast/eurova12/007-011.7", "10.1109/tvcg.2009.153", "10.1198/jcgs.2010.09136", "10.1145/2463676.2463696", "10.1109/infvis.2005.1532138", "10.1109/tvcg.2010.242", "10.5220/0006097400400051", "10.1109/visual.2019.8933706", "10.1109/atc.2015.7388338", "10.2312/pe/eurovast/eurova12/007-011", "10.5120/5044-7370", "10.1111/cgf.13446", "10.1109/icmla.2012.148", "10.1016/j.jvlc.2015.12.001", "10.1109/tvcg.2015.2466992", "10.1111/j.1467-8659.2009.01666.x", "10.5169/seals-266450", "10.1109/infvis.1998.729559", "10.1016/j.jvlc.2017.10.003", "10.1109/visual.1995.485139", "10.1007/978-0-387-39940-9\\_262", "10.1109/tvcg.2006.138"], "wos": 1, "children": [], "len": 1}], "len": 71}, {"doi": "10.1111/cgf.13425", "year": "2018", "title": "ThreadReconstructor: Modeling Reply-Chains to Untangle Conversational Text through Visual Analytics", "conferenceName": "EuroVis", "authors": "Mennatallah El{-}Assady;Rita Sevastjanova;Daniel A. Keim;Christopher Collins", "citationCount": "3", "affiliation": "El-Assady, M (Corresponding Author), Univ Konstanz, Constance, Germany.\nEl-Assady, M (Corresponding Author), Univ Ontario Inst Technol, Oshawa, ON, Canada.\nEl-Assady, Mennatallah; Sevastjanova, Rita; Keim, Daniel, Univ Konstanz, Constance, Germany.\nEl-Assady, Mennatallah; Collins, Christopher, Univ Ontario Inst Technol, Oshawa, ON, Canada.", "countries": "Canada;Germany", "abstract": "We present ThreadReconstructor, a visual analytics approach for detecting and analyzing the implicit conversational structure of discussions, e.g., in political debates and forums. Our work is motivated by the need to reveal and understand single threads in massive online conversations and verbatim text transcripts. We combine supervised and unsupervised machine learning models to generate a basic structure that is enriched by user-defined queries and rule-based heuristics. Depending on the data and tasks, users can modify and create various reconstruction models that are presented and compared in the visualization interface. Our tool enables the exploration of the generated threaded structures and the analysis of the untangled reply-chains, comparing different models and their agreement. To understand the inner-workings of the models, we visualize their decision spaces, including all considered candidate relations. In addition to a quantitative evaluation, we report qualitative feedback from an expert user study with four forum moderators and one machine learning expert, showing the effectiveness of our approach.", "keywords": "", "link": "https://doi.org/10.1111/cgf.13425", "refList": ["10.1109/tvcg.2015.2509990", "10.1007/978-3-642-15470-6\\_7", "10.1109/gefs.2013.6601048", "10.1145/1316902.1316919", "10.1111/cgf.13181", "10.3115/1219840.1219885", "10.1145/1988688.1988705", "10.21275/v5i4.nov162954", "10.1016/j.visinf.2017.01.006", "10.1109/tvcg.2013.232", "10.1111/cgf.12378", "10.1145/2488388.2488514", "10.1109/tvcg.2017.2745080", "10.1109/icdmw.2015.65", "10.1111/cgf.12919", "10.18653/v1/p17-4009", "10.1145/1645953.164626", "10.1109/tvcg.2016.2598444", "10.1145/1031607.1031644", "10.1613/jair.953", "10.1109/ssci.2015.33", "10.1109/infvis.2003.1249028", "10.1145/2669557.2669572", "10.1145/1571941.1571966", "10.1023/a:1010933404324"], "wos": 1, "children": [{"doi": "10.1111/cgf.14034", "year": "2020", "title": "The State of the Art in Enhancing Trust in Machine Learning Models with the Use of Visualizations", "conferenceName": "EuroVis", "authors": "Angelos Chatzimparmpas;Rafael Messias Martins;Ilir Jusufi;Kostiantyn Kucher;Fabrice Rossi;Andreas Kerren", "citationCount": "2", "affiliation": "Chatzimparmpas, A (Corresponding Author), Linnaeus Univ, Dept Comp Sci \\& Media Technol, Vaxjo, Sweden.\nChatzimparmpas, A.; Martins, R. M.; Jusufi, I.; Kucher, K.; Kerren, A., Linnaeus Univ, Dept Comp Sci \\& Media Technol, Vaxjo, Sweden.\nRossi, F., PSL Univ, Univ Paris Dauphine, Ceremade, Paris, France.", "countries": "Sweden;France", "abstract": "Machine learning (ML) models are nowadays used in complex applications in various domains, such as medicine, bioinformatics, and other sciences. Due to their black box nature, however, it may sometimes be hard to understand and trust the results they provide. This has increased the demand for reliable visualization tools related to enhancing trust in ML models, which has become a prominent topic of research in the visualization community over the past decades. To provide an overview and present the frontiers of current research on the topic, we present a State-of-the-Art Report (STAR) on enhancing trust in ML models with the use of interactive visualization. We define and describe the background of the topic, introduce a categorization for visualization techniques that aim to accomplish this goal, and discuss insights and opportunities for future research directions. Among our contributions is a categorization of trust against different facets of interactive ML, expanded and improved from previous research. Our results are investigated from different analytical perspectives: (a) providing a statistical overview, (b) summarizing key findings, (c) performing topic analyses, and (d) exploring the data sets used in the individual papers, all with the support of an interactive web-based survey browser. We intend this survey to be beneficial for visualization researchers whose interests involve making ML models more trustworthy, as well as researchers and practitioners from other disciplines in their search for effective visualization techniques suitable for solving their tasks with confidence and conveying meaning to their data.", "keywords": "trustworthy machine learning; visualization; interpretable machine learning; explainable machine learning", "link": "https://doi.org/10.1111/cgf.14034", "refList": ["10.1109/mcg.2018.2878902", "10.1109/tvcg.2008.153", "10.2312/mlvis.20181130", "10.1109/tvcg.2016.2598828", "10.1145/3290605.3300911", "10.1145/2993901.2993909", "10.2312/mlvis.20191158", "10.1109/tvcg.2016.2598446", "10.1111/j.1467-8659.2009.01475.x", "10.1145/3290605.3300809", "10.1109/pacificvis.2018.00031", "10.1055/s-0029-1216348", "10.1007/978-3-319-90403-0\\_13", "10.1109/tvcg.2017.2745085", "10.1111/j.1467-8659.2011.01938.x", "10.1007/978-3-319-54024-5\\_6", "10.1016/s0167-9473(01)00065-2", "10.1111/cgf.12895", "10.2312/eurovisshort.20141152.17", "10.2312/eurova.20151098.22", "10.1111/cgf.13667", "10.3115/1072228.1072378", "10.1109/tbdata.2018.2877350.16", "10.1109/lars.2009.5418323.25", "10.1109/tvcg.2017.2744878", "10.1016/j.combustflame.2005.09.018", "10.1016/j.cag.2014.01.006", "10.1109/tvcg.2016.2570755", "10.2312/mlvis.20191158.1,19", "10.1518/hfes.46.1.50.30392", "10.1145/3301275.3302280", "10.1145/3351095.3372834.1", "10.1016/s0377-2217(01)00264-8", "10.1111/cgf.13424", "10.1007/978-3-319-23485-4\\_53", "10.1007/978-94-007-0753-5\\_3623", "10.1109/tvcg.2013.101", "10.1111/cgf.12884", "10.1111/j.1467-8659.2010.01835.x", "10.1021/ci9901338", "10.4230/lipics.itcs:2017", "10.1109/mis.2013.24", "10.1109/tvcg.2014.2346482", "10.1109/tvcg.2018.2865230", "10.1073/pnas.1807180116", "10.1109/dsaa.2018.00018", "10.1109/tvcg.2009.153", "10.3115/1219840.1219855", "10.1109/tvcg.2018.2864812", "10.1109/tvcg.2018.2872577", "10.2312/trvis.20191183", "10.1109/cvpr:2004.383", "10.1109/vast.2008.4677350", "10.1145/302979.303001", "10.1109/tvcg.2018.2864499", "10.1111/cgf.13672", "10.1109/tvcg.2014.2346626", "10.23915/distill.00010.18", "10.1109/tvcg.2017.2744805", "10.2312/mlvis:20191160.18", "10.23915/distill:00016", "10.1109/pacificvis.2016.7465260", "10.1111/cgf.13683", "10.23915/distill.00016.19", "10.1145/32906053.300803.22", "10.1109/tvcg.2014.2346574", "10.1177/1473871615600010", "10.1109/tvcg.2016.2598831", "10.1145/3230623", "10.1109/visual.2019.8933744", "10.1145/2993901.2993915", "10.1016/j.visinf.2017.01.006", "10.1145/2993901.2993914", "10.1109/tvcg.2014.2346984", "10.1109/5.726791", "10.23915/distill.00010", "10.1109/tvcg.2018.2864825", "10.2307/2394164", "10.1109/tvcg.2017.2744458", "10.1145/2993901.2993917.28", "10.1111/cgf.13711", "10.1109/tvcg.2016.2598664", "10.2307/2530428", "10.1109/icdar.1997.620583", "10.1109/tvcg.2017.2744718", "10.1111/cgf.13425", "10.1109/tvcg.2019.2903943", "10.1145/1518701.1518895", "10.1109/tvcg.2018.2864838", "10.1145/62038.62043", "10.1111/j.1467-8659.2011.01920.x", "10.1145/3025171.3025208", "10.1145/355112.355124", "10.1109/vast.2010.5652398", "10.1109/tvcg.2014.2346578", "10.1145/3173574.3174209", "10.4178/epih/e2014008", "10.1109/beliv.2018.8634201.25,28", "10.1016/j.eswa.2007.12.020", "10.1111/cgf:13406", "10.1109/mcg.2011.103", "10.1631/fitee.1700808", "10.1109/tvcg.2017.2745158", "10.1073/pnas.0307752101", "10.1109/tvcg.2018.2816223", "10.1109/tvcg.2017.2745141", "10.1145/32232.32234", "10.1109/tvcg.2019.2934267", "10.1109/tvcg.2018.2864477", "10.1145/3132169", "10.2312/eurova.20151100.19", "10.1145/3172944.3172964", "10.1145/2601248.2601268", "10.1109/isai-nlp.2018.8693002.1", "10.1111/cgf.13404", "10.1007/s100320200071", "10.2312/trvis.20191183.16", "10.1111/cgf.12755", "10.1145/2702123.2702509", "10.1145/1401890.1402008.25", "10.1109/tvcg.2012.65", "10.1177/1473871617733996", "10.2312/trvis.20191187.7", "10.21236/ada273556", "10.1109/vast.2010.5652450", "10.1111/j.1467-8659.2011.01940.x", "10.1177/875647939000600106", "10.1109/tvcg.2017.2711030", "10.1016/j.immuni.2016.04.014", "10.1109/tvcg.2019.2934209", "10.1016/0095-0696(78)90006-2", "10.1016/j.jclinepi.2015.04.014", "10.1016/j.ress.2013.02.013", "10.1111/cgf.12640", "10.1145/1015330.1015388.25", "10.1111/j.1467-8659.2009.01468.x", "10.1145/1541880.1541882", "10.1109/vast.2011.6102453", "10.1016/s0008-8846(98)00165-3", "10.2312/trvis.20191186.7", "10.1007/s13748-013-0040-3", "10.1109/tvcg.2015.2467757", "10.1109/tbdata.2018.2877350", "10.1109/vast.2017.8585613", "10.1080/10556789208805504", "10.1109/vast.2012.6400484", "10.1145/3025171.3025181", "10.1007/978-3-319-90403-0\\_12", "10.1109/mcg.2019.2922592", "10.1021/ci000392t", "10.1109/vast.2007.4389000", "10.1111/cgf.13406.16", "10.1111/cgf.13684", "10.2312/eurovisshort.20161166.17", "10.2312/evs:20191168", "10.1145/3041021.3055135", "10.1145/3301275.3302265", "10.1613/jair.4135", "10.1109/tvcg.2018.2864500", "10.1109/tvcg.2017.2744158", "10.1109/ssci.2015.33", "10.1111/cgf.13453", "10.2312/pe/eurovast/eurova11/049-052", "10.1145/3025171.3025181.13", "10.1145/371920.372094", "10.1109/tvcg.2017.2744938", "10.1111/j.1467-8659.2012.03108.x", "10.1109/tvcg.2019.2934251", "10.1145/3290605.3300809.18", "10.1109/ldav.2016.7874305", "10.1109/vast.2016.7883514", "10.1109/iccv.2015.425", "10.1145/3301275.3302324", "10.1109/tnnls.2013.2292894", "10.1109/tvcg.2018.2865044", "10.1109/tvcg.2013.157", "10.1371/journal.pcbi.0020161", "10.1186/s12916-019-1426-2", "10.1109/10.867928", "10.1111/cgf.13217", "10.1109/mcg.2019.2919033", "10.1145/2993901.2993910", "10.1109/tvcg.2017.2744738", "10.2307/258792", "10.1111/cgf.12655", "10.1016/j.dss.2014.03.001", "10.1109/tvcg.2019.2904069", "10.1111/cgf.13205", "10.1002/mds.22340", "10.1109/tvcg.2019.2934595", "10.1287/inte.2018.0957", "10.1109/cvpr.2007.382974", "10.1109/tvcg.2012.280", "10.1145/2678025.2701399.13", "10.2312/mlvis.20181130.13", "10.2312/eurova.20181106.16", "10.1109/tvcg.2018.2864475", "10.2312/mlvis.20191160.18,22", "10.1007/978-1-4612-4026-6.25", "10.1109/cvpr.2006.42", "10.1145/3172944.3172950", "10.1109/cvpr.2004.383.25", "10.1109/tvcg.2019.2934812", "10.1609/aimag.v35i4.2513", "10.2312/trvis.20191185.7", "10.1111/j.1467-8659.2009.01684.x", "10.1371/journal.pone.0129126", "10.1111/cgf.13092", "10.1162/coli\\_a\\_00237", "10.1109/tvcg.2017.2744818", "10.1109/vast.2011.6102448", "10.1109/tvcg.2009.111", "10.1109/tvcg.2019.2934619", "10.1016/s0377-2217(01)00264-8.25", "10.1111/cgf.12639", "10.1109/access.2019.2919343", "10.1186/s12874-019-0681-4", "10.1109/pacificvis.2015.7156366", "10.1109/pacificvis.2018.00029", "10.1109/tvcg.2019.2934261", "10.1080/13506280444000102.http://www.uvt.nl/ticc", "10.1109/vast.2018.8802509", "10.1111/cgf.13212", "10.1145/3200489", "10.1111/cgf.13176", "10.1177/1473871620904671", "10.1007/978-3-319-10590-1\\_53", "10.1111/j.1467-8659.2012.03126.x", "10.1111/cgf.13172", "10.1145/3025171.3025208.6,21", "10.1111/cgf.12366", "10.1109/tvcg.2019.2934659", "10.1109/cvprw.2009.5206848", "10.1016/j.media.2014.11.010", "10.1109/tvcg.2017.2744683", "10.1109/tvcg.2019.2934262", "10.1016/j.neucom.2006.11.018", "10.1177/1473871615571951", "10.1371/journal.pcbi.0020161.25", "10.1177/1473871611415994", "10.2312/trvis20191187", "10.2312/eurova", "10.1145/2858036.2858529", "10.1145/2207676.2207738", "10.1007/s11042-009-0417-2", "10.1145/3301275.3302317", "10.1038/s41746-019-0148-3", "10.1145/3351095.3372834", "10.1080/10691898.2011.11889627", "10.1109/tvcg.2018.2864504", "10.1109/vast.2017.8585720", "10.1109/mcg.2018.053491732", "10.1007/s10994-010-5207-6", "10.1109/tvcg.2019.2934433", "10.1016/j.cag.2017.05.005", "10.1109/tvcg.2012.279", "10.1145/3231622.3231641.19,20", "10.1145/1562849.1562851", "10.1007/11564126\\_", "10.1109/tvcg.2018.2846735", "10.3115/1225403.1225421", "10.1109/vast.2012.6400486", "10.2312/eurova.20191116.22", "10.1109/tvcg.2007.70443", "10.1080/027868291009242", "10.2312/eurova.20151100", "10.1145/2939502.2939503.19", "10.1016/j.cag.2014.02.004", "10.1145/2939672.2939778", "10.1109/vast.2010.5652484", "10.1111/cgf.12641", "10.1145/3301275.3302289", "10.1109/visual.2019.8933619", "10.1109/tvcg.2017.2672987", "10.1109/vast.2016.7883517.20", "10.1109/igarss.2017.8127684", "10.1016/j.jcae.2010.04.002", "10.1109/vast.2010.5652885", "10.1016/j.visinf.2019.03.002", "10.1007/s00371-018-1500-3", "10.1109/mcg.2018.042731661", "10.1109/34.598228", "10.1109/tvcg.2018.2865027", "10.1016/j.neucom.2017.01.105", "10.1111/cgf.12389", "10.1109/tvcg.2019.2934591", "10.1109/vast.2010.5652392.16", "10.1111/cgf.13416", "10.1080/02701367.1992.10608764", "10.1109/vast.2017.8585721", "10.1109/tvcg.2018.2843369", "10.1109/sbes.2010.27", "10.1109/vast.2015.7347637", "10.1145/1401890.1402008", "10.1016/j.bpj.2010.04.064", "10.1109/tvcg.2013.125", "10.1109/isai-nlp.2018.8693002", "10.1371/journal.pone.0160127", "10.1145/2856767.2856779", "10.1145/2678025.2701399", "10.1109/vast.2011.6102451", "10.1109/mcg.2010.18", "10.1021/ci4000213", "10.1109/vast.2012.6400492", "10.1007/11564126-49.25", "10.2312/eurova.20171114", "10.1109/vast.2010.5652443", "10.1145/3134599", "10.2312/pe/eurovast/eurovast10/013-018.19", "10.1109/tvcg.2019.2903946", "10.1109/tvcg.2015.2467717", "10.1177/1473871612460526", "10.1016/j.cag.2018.09.018", "10.1109/tvcg.2016.2598838", "10.1145/3172944.3172964.14", "10.1109/vast.2009.5333428", "10.1109/vast.2014.7042480", "10.2312/pe/eurovast/eurovast10/013-018", "10.1177/0962280215588241", "10.1145/2993901.2993917", "10.1109/cvpr.2008:4587581", "10.1109/tvcg.2015.2467551", "10.1016/j.visinf.2018.09.001", "10.1126/science.290.5500.2319", "10.2312/eurova.20151107", "10.1109/visual.2019.8933695", "10.13140/2.1.2393.1847", "10.1197/jamia.m1929", "10.1109/cvpr.2008.4587581.25", "10.1145/1518701.1518895.16", "10.1109/vds.2017.8573444", "10.2312/trvis:20191185", "10.1145/3359786", "10.13140/2.1.1341.1520", "10.2312/pe/eurovast/eurova11/049-052.17", "10.1109/tvcg.2014.2346660", "10.1145/3185517", "10.1109/adprl.2011.5967372", "10.1109/tvcg.2015.2467591", "10.1111/j.1751-9004.2009.00232.x", "10.1136/qshc.2004.010033", "10.1109/vast.2012.6400493", "10.1109/tvcg.2019.2934266", "10.1145/2971763.2971775", "10.1111/cgf.13730", "10.1109/vast.2012.6400488", "10.1111/cgf.13210", "10.1109/tvcg.2019.2934631", "10.1145/3172944.3172965", "10.1057/ivs.2010.2", "10.1109/tvcg.2017.2745258", "10.1016/j.jbusres.2019.07.039", "10.1162/jmlr.2003.3.4-5.993", "10.1109/pacificvis.2019.00044", "10.2312/pe/eurovast/eurova12/037-041", "10.1109/tvcg.2019.2934629", "10.1177/0018720814547570", "10.1145/3292500.3330908", "10.1111/j.1467-8659.2009.01467.x", "10.2312/eurova.20151098", "10.1177/1473871617713337", "10.1109/lars:2009.5418323", "10.1109/vast.2011.6102437", "10.1111/cgf.12878", "10.1561/1500000001", "10.1145/3025171.3025222", "10.1007/s11704-016-6028-y", "10.1016/j.procs.2017.05.216", "10.1109/cvpr.2007.382974.25", "10.1080/10447318.2020.1741118", "10.1109/vast.2012.6400489", "10.1145/3025171.3025172", "10.1109/tvcg.2017.2744098", "10.1109/tvcg.2005.66", "10.1016/j.dss.2009.05.016", "10.1007/978-1-4612-4026-6", "10.2312/evs.20191168.16,20,28", "10.2312/pe/eurovast/eurova12/037-041.17", "10.1145/3290605.3300803", "10.1145/1015330.1015388", "10.1111/cgf.13197", "10.1016/b978-1-55860-377-6.50048-7", "10.1111/cgf.13681", "10.1109/tvcg.2017.2744378", "10.1109/tvcg.2017.2744358", "10.1109/vast.2008.4677352"], "wos": 1, "children": [{"doi": "10.1109/tvcg.2020.3030368", "title": "Implicit Multidimensional Projection of Local Subspaces", "year": "2020", "conferenceName": "InfoVis", "authors": "Rongzheng Bian;Yumeng Xue;Liang Zhou;Jian Zhang 0070;Baoquan Chen;Daniel Weiskopf;Yunhai Wang", "citationCount": "1", "affiliation": "Wang, YH (Corresponding Author), Shandong Univ, Qingdao, Peoples R China. Zhou, L (Corresponding Author), Univ Utah, Salt Lake City, UT 84112 USA. Bian, Rongzheng; Xue, Yumeng; Wang, Yunhai, Shandong Univ, Qingdao, Peoples R China. Chen, Baoquan, Peking Univ, Beijing, Peoples R China. Zhang, Jian, Chinese Acad Sci, CNIC, Beijing, Peoples R China. Zhou, Liang, Univ Utah, Salt Lake City, UT 84112 USA. Weiskopf, Daniel, Univ Stuttgart, Stuttgart, Germany.", "countries": "USA;Germany;China", "abstract": "We propose a visualization method to understand the effect of multidimensional projection on local subspaces, using implicit function differentiation. Here, we understand the local subspace as the multidimensional local neighborhood of data points. Existing methods focus on the projection of multidimensional data points, and the neighborhood information is ignored. Our method is able to analyze the shape and directional information of the local subspace to gain more insights into the global structure of the data through the perception of local structures. Local subspaces are fitted by multidimensional ellipses that are spanned by basis vectors. An accurate and efficient vector transformation method is proposed based on analytical differentiation of multidimensional projections formulated as implicit functions. The results are visualized as glyphs and analyzed using a full set of specifically-designed interactions supported in our efficient web-based visualization tool. The usefulness of our method is demonstrated using various multi- and high-dimensional benchmark datasets. Our implicit differentiation vector transformation is evaluated through numerical comparisons; the overall method is evaluated through exploration examples and use cases.", "keywords": "High-dimensional data visualization,dimensionality reduction,local linear subspaces,user interaction", "link": "http://dx.doi.org/10.1109/TVCG.2020.3030368", "refList": ["10.3844/jcssp.2018.613.622", "10.1016/j.aci.2018.08.003", "10.3390/info9030065", "10.1016/j.visinf.2018.09.003", "10.1371/journal.pone.0118432", "10.1016/s0893-6080(05)80023-1", "10.1109/tvcg.2020.2986996", "10.1109/icst.2012.56", "10.1007/s10844-013-0250-y", "10.1109/tbdata.2018", "10.1145/1125451.1125659", "10.1109/tvcg.2013.125", "10.1177/1473871611412817", "10.1145/3290605.3300911", "10.1111/cgf.14034", "10.1007/s13721-013-0034-x", "10.1016/j.procs.2017.05.216", "10.1016/j.ins.2009.08.025", "10.1109/tvcg.2013.124", "10.1109/tvcg.2018.2864499", "10.1109/tvcg.2018.2864475", "10.1080/10447318.2020.1741118", "10.1016/j.imu.2019.100203", "10.1109/tvcg.2018.2865240", "10.1186/s12864-019-6413-7", "10.1109/tvcg.2015.2467551", "10.1002/widm.1249", "10.1007/978-3-319-66429-3\\_29", "10.1109/tvcg.2014.2346481", "10.1109/tvcg.2018.2864825", "10.1177/1473871620904671", "10.1109/tvcg.2019.2934267", "10.1136/bmjopen-2016-012799", "10.1109/smartgridcomm.2017.8340682", "10.1007/s10664-015-9401-9", "10.1145/1143844.1143874", "10.1111/cgf.12389", "10.1109/tvcg.2018.2872577", "10.1007/978-981-13-5802-9\\_20", "10.1016/j.ipm.2009.03.002", "10.5220/0006431602160222", "10.1109/mcg.2015.50", "10.1109/tvcg.2014.2346574", "10.1007/bf02289565", "10.1109/tvcg.2017.2744378", "10.1016/j.patrec.2008.08.010", "10.1023/a:1010933404324", "10.9735/2229-3981"], "wos": 1, "children": [], "len": 1}, {"doi": "10.1109/tvcg.2020.3030465", "title": "Visual Causality Analysis of Event Sequence Data", "year": "2020", "conferenceName": "VAST", "authors": "Zhuochen Jin;Shunan Guo;Nan Chen;Daniel Weiskopf;David Gotz;Nan Cao", "citationCount": "0", "affiliation": "Cao, N (Corresponding Author), Tongji Univ, IDVx Lab, Shanghai, Peoples R China. Jin, Zhuochen; Guo, Shunan; Chen, Nan; Cao, Nan, Tongji Univ, IDVx Lab, Shanghai, Peoples R China. Weiskopf, Daniel, Univ Stuttgart, Stuttgart, Germany. Gotz, David, Univ N Carolina, Chapel Hill, NC 27515 USA.", "countries": "USA;Germany;China", "abstract": "Causality is crucial to understanding the mechanisms behind complex systems and making decisions that lead to intended outcomes. Event sequence data is widely collected from many real-world processes, such as electronic health records, web clickstreams, and financial transactions, which transmit a great deal of information reflecting the causal relations among event types. Unfortunately, recovering causalities from observational event sequences is challenging, as the heterogeneous and high-dimensional event variables are often connected to rather complex underlying event excitation mechanisms that are hard to infer from limited observations. Many existing automated causal analysis techniques suffer from poor explainability and fail to include an adequate amount of human knowledge. In this paper, we introduce a visual analytics method for recovering causalities in event sequence data. We extend the Granger causality analysis algorithm on Hawkes processes to incorporate user feedback into causal model refinement. The visualization system includes an interactive causal analysis framework that supports bottom-up causal exploration, iterative causal verification and refinement, and causal comparison through a set of novel visualizations and interactions. We report two forms of evaluation: a quantitative evaluation of the model improvements resulting from the user-feedback mechanism, and a qualitative evaluation through case studies in different application domains to demonstrate the usefulness of the system.", "keywords": "Event sequence data,causality analysis,visual analytics", "link": "http://dx.doi.org/10.1109/TVCG.2020.3030465", "refList": ["10.5555/1642718", "10.1109/tvcg.2018.2865022", "10.5555/2074094.2074151", "10.1109/tvcg.2016.2618797", "10.1073/pnas.1320645111", "10.1109/tvcg.2017.2744843", "10.1109/iv.2017.69", "10.1109/tvcg.2019.2934399", "10.1145/3172944.3173007", "10.5555/1795555", "10.1109/mcg.2005.102", "10.1145/381641.381653", "10.1162/153244301753344614", "10.1111/cgf.14034", "10.1111/cgf.13198", "10.1017/cbo9780511519857", "10.1007/s10462-016-9475-9", "10.1075/ssol.2.2.07bor", "10.1007/978-1-4614-3223-4\\_3", "10.1109/infvis.2003.1249025", "10.1007/978-94-007-6094-313", "10.1145/2858036.2858387", "10.1109/tvcg.2007.70528", "10.1109/tvcg.2017.2674958", "10.1147/sj.454.0801", "10.1109/tvcg.2013.119", "10.1145/3173574.3173711", "10.1016/j.erss.2017.06.034", "10.1109/visual.2019.8933695", "10.1007/s11665-016-2173-6", "10.1016/0377-0427(87)90125-7", "10.2307/3601125", "10.1016/b978-0-444-88738-2.50018-x", "10.1109/mcg.2006.70", "10.1109/tvcg.2018.2865145", "10.1017/s1351324997001502", "10.1109/tvcg.2010.179", "10.1214/aos/1176344552", "10.1109/mcg.2009.22", "10.1007/978-3-319-26633-6\\_13", "10.1080/10447318.2014.905422", "10.1016/j.visinf.2019.03.004", "10.1057/palgrave.ivs.9500074", "10.1007/978-1-4614-3223-4"], "wos": 1, "children": [], "len": 1}], "len": 5}], "len": 7}], "len": 85}, {"doi": "10.1111/cgf.13179", "year": "2017", "title": "Interactive Ambiguity Resolution of Named Entities in Fictional Literature", "conferenceName": "EuroVis", "authors": "Florian Stoffel;Wolfgang Jentner;Michael Behrisch;Johannes Fuchs;Daniel A. Keim", "citationCount": "1", "affiliation": "Stoffel, F (Corresponding Author), Univ Konstanz, Constance, Germany.\nStoffel, Florian; Jentner, Wolfgang; Behrisch, Michael; Fuchs, Johannes; Keim, Daniel, Univ Konstanz, Constance, Germany.", "countries": "Germany", "abstract": "Named entity recognition (NER) denotes the task to detect entities and their corresponding classes, such as person or location, in unstructured text data. For most applications, state of the art NER software is producing reasonable results. However, as a consequence of the methodological limitations and the well-known pitfalls when analyzing natural language data, the NER results are likely to contain ambiguities. In this paper, we present an interactive NER ambiguity resolution technique, which enables users to create (post-processing) rules for named entity recognition data based on the content and entity context of the analyzed documents. We specifically address the problem that in use-cases where ambiguities are problematic, such as the attribution of fictional characters with traits, it is often unfeasible to train models on custom data to improve state of the art NER software. We derive an iterative process model for improving NER results, show an interactive NER ambiguity resolution prototype, illustrate our approach with contemporary literature, and discuss our work and future research.", "keywords": "", "link": "https://doi.org/10.1111/cgf.13179", "refList": ["10.1109/tvcg.2007.70582", "10.2312/pe.eurovast.eurova13.007-011.3", "10.1109/tvcg.2016.2598465", "10.1007/978-3-540-76298-0\\_52", "10.1007/s10579-010-9135-7", "10.1145/2702123.2702217", "10.1145/1390156.1390177", "10.1145/1321440.1321475", "10.1111/0824-7935.00129", "10.3115/v1/d11-1072", "10.1075/bct.19.2", "10.1109/caia.1991.120841", "10.1111/cgf.12935", "10.1075/bct.19.03nad.1", "10.1016/b978-0-12-558701-3.50007-7", "10.1111/cgf.12919", "10.1007/s10588-008-9029-z", "10.1007/978-1-4614-3223-4\\_13", "10.1111/j.1467-8640.2012.00460.x", "10.1111/cgf.12124", "10.1162/153244303322533223", "10.1162/tacl\\_a\\_00179", "10.1057/palgrave.ivs.9500180", "10.1109/infvis.2004.1", "10.3115/974557.974586", "10.1109/tvcg.2006.160", "10.2312/eurovisshort.20151130.4", "10.1561/1500000003", "10.1002/asi.21001", "10.3115/v1/e14-1048", "10.1145/2661829.2661854.3", "10.1109/tvcg.2013.160", "10.1007/978-1-4614-3223-4", "10.1075/bct.19.03nad.1,3,5"], "wos": 1, "children": [], "len": 1}], "len": 171}, {"doi": "10.1111/cgf.13196", "year": "2017", "title": "Adaptable Radial Axes Plots for Improved Multivariate Data Visualization", "conferenceName": "EuroVis", "authors": "Manuel Rubio{-}S{\\'{a}}nchez;Alberto S{\\'{a}}nchez;D. J. Lehmann", "citationCount": "8", "affiliation": "Rubio-Sanchez, M (Corresponding Author), Univ Rey Juan Carlos, Madrid, Spain.\nRubio-Sanchez, M.; Sanchez, A.; Lehmann, D. J., Univ Rey Juan Carlos, Madrid, Spain.\nSanchez, A., Ctr Computat Simulat, Madrid, Spain.\nLehmann, D. J., Univ Magdeburg, Magdeburg, Germany.", "countries": "Spain;Germany", "abstract": "Radial axes plots are multivariate visualization techniques that extend scatterplots in order to represent high-dimensional data as points on an observable display. Well-known methods include star coordinates or principal component biplots, which represent data attributes as vectors that define axes, and produce linear dimensionality reduction mappings. In this paper we propose a hybrid approach that bridges the gap between star coordinates and principal component biplots, which we denominate adaptable radial axes plots. It is based on solving convex optimization problems where users can: (a) update the axis vectors interactively, as in star coordinates, while producing mappings that enable to estimate attribute values optimally through labeled axes, similarly to principal component biplots; (b) use different norms in order to explore additional nonlinear mappings of the data; and (c) include weights and constraints in the optimization problems for sorting the data along one axis. The result is a flexible technique that complements, extends, and enhances current radial methods for data analysis.", "keywords": "", "link": "https://doi.org/10.1111/cgf.13196", "refList": ["10.1109/tvcg.2013.182", "10.1111/j.1467-8659.2011.01958.x", "10.1057/palgrave.ivs.9500099", "10.2307/2334381", "10.1109/tvcg.2014.2346258", "10.1007/s00357-016-9213-7", "10.1109/pacificvis.2015.7156391", "10.1145/22949.22950", "10.1109/tvcg.2015.2467324", "10.1111/cgf.12641", "10.1109/infvis.2005.1532136", "10.1109/pacificvis.2014.58", "10.2307/2288400", "10.1145/1400214.1400234", "10.1007/978-1-84800-155-8\\_7", "10.1111/cgf.12116", "10.1145/1054972.1055031", "10.1109/tvcg.2009.23", "10.1007/bf02288367", "10.1109/tvcg.2010.209"], "wos": 1, "children": [{"doi": "10.1109/tvcg.2018.2865118", "title": "Shape-preserving Star Coordinates", "year": "2018", "conferenceName": "InfoVis", "authors": "Vladimir Molchanov;Lars Linsen", "citationCount": "1", "affiliation": "Molchanov, V (Corresponding Author), Westfalische Wilhelms Univ Munster, Munster, Germany. Molchanov, Vladimir; Linsen, Lars, Westfalische Wilhelms Univ Munster, Munster, Germany.", "countries": "Germany", "abstract": "Dimensionality reduction is commonly applied to multidimensional data to reduce the complexity of their analysis. In visual analysis systems, projections embed multidimensional data into 2D or 3D spaces for graphical representation. To facilitate a robust and accurate analysis, essential characteristics of the multidimensional data shall be preserved when projecting. Orthographic star coordinates is a state-of-the-art linear projection method that avoids distortion of multidimensional clusters by restricting interactive exploration to orthographic projections. However, existing numerical methods for computing orthographic star coordinates have a number of limitations when putting them into practice. We overcome these limitations by proposing the novel concept of shape-preserving star coordinates where shape preservation is assured using a superset of orthographic projections. Our scheme is explicit, exact, simple, fast, parameter-free, and stable. To maintain a valid shape-preserving star-coordinates configuration during user interaction with one of the star-coordinates axes, we derive an algorithm that only requires us to modify the configuration of one additional compensatory axis. Different design goals can be targeted by using different strategies for selecting the compensatory axis. We propose and discuss four strategies including a strategy that approximates orthographic star coordinates very well and a data-driven strategy. We further present shape-preserving morphing strategies between two shape-preserving configurations, which can be adapted for the generation of data tours. We apply our concept to multiple data analysis scenarios to document its applicability and validate its desired properties.", "keywords": "Star coordinates,multidimensional data projection,multivariate data visualization", "link": "http://dx.doi.org/10.1109/TVCG.2018.2865118", "refList": ["10.1007/978-1-4612-4214", "10.2312/eurovisshort.20141152", "10.1109/tvcg.2013.182", "10.1057/palgrave.ivs.9500099", "10.2307/2334381", "10.1109/tvcg.2014.2346258", "10.1016/j.cag.2016.08.007", "10.1111/cgf.13196", "10.1080/10618600.1995.10474674", "10.1111/cgf.12117", "10.1137/0906011", "10.1109/tvcg.2015.2467324", "10.3390/pr5040075", "10.2307/2289161", "10.1109/tvcg.2015.2467132", "10.1109/t-c.1974.224051", "10.1177/1473871612439357", "10.2312/vcbm.20151204", "10.1109/tvcg.2010.209"], "wos": 1, "children": [{"doi": "10.1109/pacificvis48177.2020.8199", "year": "2020", "title": "Efficient Morphing of Shape-preserving Star Coordinates", "conferenceName": "PacificVis", "authors": "Vladimir Molchanov;Sagad Hamid;Lars Linsen", "citationCount": "0", "affiliation": "Molchanov, V (Corresponding Author), Westfalische Wilhelms Univ Munster, Munster, Germany.\nMolchanov, Vladimir; Hamid, Sagad; Linsen, Lars, Westfalische Wilhelms Univ Munster, Munster, Germany.", "countries": "Germany", "abstract": "Data tours follow an exploratory multi-dimensional data visualization concept that provides animations of projections of the multidimensional data to a 2D visual space. To create an animation, a sequence of key projections is provided and morphings between each pair of consecutive key projections are computed, which then can be stitched together to form the data tour. The morphings should be smooth so that a user can easily follow the transformations, and their computations shall be fast to allow for their integration into an interactive visual exploration process. Moreover, if the key projections are chosen to satisfy additional conditions, it is desirable that these conditions are maintained during morphing. Shape preservation is such a desirable condition, as it avoids shape distortions that may otherwise be caused by a projection. We develop a novel efficient morphing algorithms for computing shape-preserving data tours, i.e., data tours constructed for a sequence of shape-preserving linear projections. We propose a stepping strategy for the morphing to avoid discontinuities in the evolution of the projections, where we represent the linear projections using a star-coordinates system. Our algorithms are less computationally involved, produce smoother morphings, and require less user-defined parameter settings than existing state-of-the-art approaches.", "keywords": "Human-centered computing; Visualization; Visualization techniques", "link": "https://doi.org/10.1109/PacificVis48177.2020.8199", "refList": ["10.2312/eurovisshort.20141152", "10.1109/tvcg.2013.182", "10.1109/tvcg.2008.153", "10.1109/tvcg.2015.2467591", "10.4135/9781412985130", "10.1111/cgf.12878", "10.1016/j.cag.2016.08.007", "10.1080/10618600.1995.10474674", "10.1109/infvis.2003.1249004", "10.1002/9781118445112.stat06472", "10.1109/visual.1997.663916", "10.1111/cgf.12117", "10.1137/0906011", "10.1109/tvcg.2018.2865118", "10.1126/science.290.5500.2319", "10.1111/cgf.12845", "10.1111/j.1467-8659.2012.03125.x", "10.1109/tvcg.2017.2705189", "10.1002/0471725293", "10.1111/cgf.12876", "10.1111/cgf.13404", "10.2307/2289161", "10.1111/cgf.13446", "10.1198/106186008x318440", "10.2307/1390747", "10.1109/tvcg.2012.35", "10.1109/tvcg.2015.2467132", "10.1109/tvcg.2006.94", "10.1109/t-c.1974.224051", "10.1109/pacificvis.2019.00018", "10.1109/tvcg.2017.2744339", "10.1109/tsmcb.2005.850151"], "wos": 1, "children": [], "len": 1}], "len": 3}], "len": 5}, {"doi": "10.1111/cgf.13197", "year": "2017", "title": "Linear Discriminative Star Coordinates for Exploring Class and Cluster Separation of High Dimensional Data", "conferenceName": "EuroVis", "authors": "Yunhai Wang;Jingting Li;Feiping Nie;Holger Theisel;Minglun Gong;Dirk J. Lehmann", "citationCount": "11", "affiliation": "Wang, YH (Corresponding Author), Shandong Univ, Jinan, Peoples R China.\nWang, Yunhai; Li, Jingting, Shandong Univ, Jinan, Peoples R China.\nNie, Feiping, Northwestern Polytech Univ, Xian, Peoples R China.\nTheisel, Holger; Lehmann, Dirk J., Univ Magdeburg, Magdeburg, Germany.\nGong, Minglun, Mem Univ, St John, NF, Canada.", "countries": "Canada;Germany;China", "abstract": "One main task for domain experts in analysing their nD data is to detect and interpret class/cluster separations and outliers. In fact, an important question is, which features/dimensions separate classes best or allow a cluster-based data classification. Common approaches rely on projections from nD to 2D, which comes with some challenges, such as: The space of projection contains an infinite number of items. How to find the right one? The projection approaches suffers from distortions and misleading effects. How to rely to the projected class/cluster separation? The projections involve the complete set of dimensions/features. How to identify irrelevant dimensions? Thus, to address these challenges, we introduce a visual analytics concept for the feature selection based on linear discriminative star coordinates (DSC), which generate optimal cluster separating views in a linear sense for both labeled and unlabeled data. This way the user is able to explore how each dimension contributes to clustering. To support to explore relations between clusters and data dimensions, we provide a set of cluster-aware interactions allowing to smartly iterate through subspaces of both records and features in a guided manner. We demonstrate our features selection approach for optimal cluster/class separation analysis with a couple of experiments on real-life benchmark high-dimensional data sets.", "keywords": "", "link": "https://doi.org/10.1111/cgf.13197", "refList": ["10.1109/tvcg.2013.182", "10.1111/j.1467-8659.2008.01241.x", "10.2307/1269768", "10.1162/153244303322753616", "10.1109/tvcg.2014.2346258", "10.1007/s00180-011-0271-3", "10.1080/13506280444000102.http://www.uvt.nl/ticc", "10.1016/j.patrec.2009.09.011", "10.1145/1273496.1273562", "10.1145/1007730.1007731", "10.1137/0906011", "10.1109/tvcg.2011.220", "10.1109/tvcg.2015.2467324", "10.1109/vast.2012.6400488", "10.1007/bf01898350", "10.1057/palgrave.ivs.9500053", "10.1109/tvcg.2014.2346482", "10.1109/tvcg.2011.178", "10.1109/tvcg.2010.207", "10.1109/icdar.1997.620583", "10.1109/infvis.2005.1532138", "10.1109/tnn.2009.2015760", "10.1109/tvcg.2013.153", "10.1109/vast.2009.5332629", "10.1145/1148020.1148024", "10.1109/t-c.1974.224051", "10.1057/palgrave.ivs.9500091"], "wos": 1, "children": [{"doi": "10.1109/tvcg.2019.2934251", "title": "Supporting Analysis of Dimensionality Reduction Results with Contrastive Learning", "year": "2019", "conferenceName": "VAST", "authors": "Takanori Fujiwara;Oh-Hyun Kwon;Kwan-Liu Ma", "citationCount": "6", "affiliation": "Fujiwara, T (Corresponding Author), Univ Calif Davis, Davis, CA 95616 USA. Fujiwara, Takanori; Kwon, Oh-Hyun; Ma, Kwan-Liu, Univ Calif Davis, Davis, CA 95616 USA.", "countries": "USA", "abstract": "Dimensionality reduction (DR) is frequently used for analyzing and visualizing high-dimensional data as it provides a good first glance of the data. However, to interpret the DR result for gaining useful insights from the data, it would take additional analysis effort such as identifying clusters and understanding their characteristics. While there are many automatic methods (e.g., density-based clustering methods) to identify clusters, effective methods for understanding a cluster's characteristics are still lacking. A cluster can be mostly characterized by its distribution of feature values. Reviewing the original feature values is not a straightforward task when the number of features is large. To address this challenge, we present a visual analytics method that effectively highlights the essential features of a cluster in a DR result. To extract the essential features, we introduce an enhanced usage of contrastive principal component analysis (cPCA). Our method, called ccPCA (contrasting clusters in PCA), can calculate each feature's relative contribution to the contrast between one cluster and other clusters. With ccPCA, we have created an interactive system including a scalable visualization of clusters' feature contributions. We demonstrate the effectiveness of our method and system with case studies using several publicly available datasets.", "keywords": "Dimensionality reduction,contrastive learning,principal component analysis,high-dimensional data,visual analytics", "link": "http://dx.doi.org/10.1109/TVCG.2019.2934251", "refList": ["10.4135/9781412952644.nv-3", "10.1109/tvcg.2015.2467591", "10.1109/tvcg.2016.2598838", "10.1007/s00371-013-0892-3", "10.1007/b98835", "10.1080/00949657508810123", "10.1016/s0377-2217(01)00264-8", "10.1109/tvcg.2011.185", "10.1038/s41467-018-04608-8", "10.1007/978-3-642-37456-2\\_14", "10.1016/0022-247x(85)90131-3", "10.1145/2669557.2669559", "10.1002/widm.30", "10.1109/tnn.2005.845141", "10.1214/aoms/1177729694", "10.1007/s11263-007-0075-7", "10.1007/bf00130487", "10.1109/tvcg.2017.2745085", "10.1111/cgf.12194", "10.1037/h0071325", "10.1111/cgf.12935", "10.1093/biomet/66.3.605", "10.1109/tvcg.2012.256", "10.1016/j.jvlc.2018.08.006", "10.1093/bioinformatics/17.suppl\\_1.s22", "10.1109/sibgrapi.2017.53", "10.1145/2872427.2883041", "10.1007/978-0-387-78189-1\\_8", "10.1109/tvcg.2016.2640960", "10.1109/tvcg.2017.2745258", "10.1109/tpami.2003.1217609", "10.1007/978-1-4757-1904-8", "10.1093/carcin/19.8.1329", "10.1109/tvcg.2017.2744318", "10.1016/j.eswa.2010.08.067", "10.1111/cgf.12640", "10.1109/visual.1990.146402", "10.2307/2346830", "10.1111/cgf.13197", "10.1371/journal.pone.0129126", "10.1109/nnsp.1999.788121", "10.1109/tvcg.2015.2467717", "10.1109/sibgrapi.2016.048", "10.1002/cem.1122", "10.1109/sibgrapi.2016.45"], "wos": 1, "children": [{"doi": "10.1109/tvcg.2020.3030354", "title": "Explainable Matrix - Visualization for Global and Local Interpretability of Random Forest Classification Ensembles", "year": "2020", "conferenceName": "VAST", "authors": "M\u00e1rio Popolin Neto;Fernando Vieira Paulovich", "citationCount": "0", "affiliation": "Neto, MP (Corresponding Author), Fed Inst Sao Paulo IFSP, Sao Paulo, SP, Brazil. Neto, MP (Corresponding Author), Univ Sao Paulo, Sao Paulo, SP, Brazil. Neto, Mario Popolin, Fed Inst Sao Paulo IFSP, Sao Paulo, SP, Brazil. Neto, Mario Popolin; Paulovich, Fernando V., Univ Sao Paulo, Sao Paulo, SP, Brazil. Paulovich, Fernando V., Dalhousie Univ, Halifax, NS, Canada.", "countries": "Canada;Brazil", "abstract": "Over the past decades, classification models have proven to be essential machine learning tools given their potential and applicability in various domains. In these years, the north of the majority of the researchers had been to improve quantitative metrics, notwithstanding the lack of information about models' decisions such metrics convey. This paradigm has recently shifted, and strategies beyond tables and numbers to assist in interpreting models' decisions are increasing in importance. Part of this trend, visualization techniques have been extensively used to support classification models' interpretability, with a significant focus on rule-based models. Despite the advances, the existing approaches present limitations in terms of visual scalability, and the visualization of large and complex models, such as the ones produced by the Random Forest (RF) technique, remains a challenge. In this paper, we propose Explainable Matrix (ExMatrix), a novel visualization method for RF interpretability that can handle models with massive quantities of rules. It employs a simple yet powerful matrix-like visual metaphor, where rows are rules, columns are features, and cells are rules predicates, enabling the analysis of entire models and auditing classification results. ExMatrix applicability is confirmed via different examples, showing how it can be used in practice to promote RF models interpretability.", "keywords": "Random forest visualization,logic rules visualization,classification model interpretability,explainable artificial intelligence", "link": "http://dx.doi.org/10.1109/TVCG.2020.3030354", "refList": ["10.1109/tvcg.2016.2598838", "10.1145/956750.956837.1-58113-737-0", "10.1007/s11749-016-0481-7", "10.1016/j.dss.2010.12.003", "10.1109/mcg.2011.103", "10.1109/vl.1996.545307", "10.1109/tvcg.2019.2934251", "10.1145/2939672.2939874", "10.1109/tvcg.2010.79", "10.1109/tvcg.2018.2864475", "10.1111/cgf.12935", "10.1111/insr.12016", "10.1145/2594473.2594475", "10.1109/vast.2017.8585720", "10.1109/tvcg.2014.2331979", "10.1038/s41586-018-0337-2", "10.1109/tvcg.2018.2864812", "10.1109/vast.2012.6400492", "10.1145/3236009", "10.1057/jors.2008.161", "10.1109/cbms.2006.169", "10.1038/ng.142", "10.1111/j.1469-1809.1936.tb02137.x", "10.1111/cgf.13092", "10.1109/vast.2010.5652443", "10.1155/2018/5145348", "10.1109/tvcg.2017.2744378", "10.1023/a:1010933404324", "10.1109/vast.2010.5652398", "10.1109/vast.2011.6102453"], "wos": 1, "children": [], "len": 1}, {"doi": "10.1109/tvcg.2020.3030398", "title": "Multiscale Snapshots: Visual Analysis of Temporal Summaries in Dynamic Graphs", "year": "2020", "conferenceName": "VAST", "authors": "Eren Cakmak;Udo Schlegel;Dominik J\u00e4ckle;Daniel A. Keim;Tobias Schreck", "citationCount": "0", "affiliation": "Cakmak, E (Corresponding Author), Univ Konstanz, Constance, Germany. Cakmak, Eren; Schlegel, Udo; Keim, Daniel, Univ Konstanz, Constance, Germany. Schreck, Tobias, Graz Univ Technol, Graz, Austria.", "countries": "Germany;Austria", "abstract": "The overview-driven visual analysis of large-scale dynamic graphs poses a major challenge. We propose Multiscale Snapshots, a visual analytics approach to analyze temporal summaries of dynamic graphs at multiple temporal scales. First, we recursively generate temporal summaries to abstract overlapping sequences of graphs into compact snapshots. Second, we apply graph embeddings to the snapshots to learn low-dimensional representations of each sequence of graphs to speed up specific analytical tasks (e.g., similarity search). Third, we visualize the evolving data from a coarse to fine-granular snapshots to semi-automatically analyze temporal states, trends, and outliers. The approach enables us to discover similar temporal summaries (e.g., reoccurring states), reduces the temporal data to speed up automatic analysis, and to explore both structural and temporal properties of a dynamic graph. We demonstrate the usefulness of our approach by a quantitative evaluation and the application to a real-world dataset.", "keywords": "Dynamic Graph,Dynamic Network,Unsupervised Graph Learning,Graph Embedding,Multiscale Visualization", "link": "http://dx.doi.org/10.1109/TVCG.2020.3030398", "refList": ["10.1007/s00442-002-1137-8", "10.1111/cgf.13668", "10.1086/282697", "10.1109/tvcg.2002.1044518", "10.1890/0012-9658(2000)081{[}0008:ppbatp]2.0.co", "2", "10.1101/2020.04.08.032524", "10.1111/j.1461-0248.2009.01391.x", "10.1016/0040-5809(80)90016-7", "10.1109/tvcg.2009.181", "10.1145/2669557.2669559", "10.1109/vl.1996.545307", "10.1109/tvcg.2013.254", "10.1109/tvcg.2019.2934251", "10.1073/pnas.93.6.2608", "10.2312/cgvc", "10.1080/14786440109462720", "10.1111/1440-1703.12057", "10.2307/1940591", "10.1037/h0071325", "10.1073/pnas.1215506110", "10.1126/science.283.5407.1528", "10.1109/tvcg.2013.198", "10.7717/peerj.824", "10.1126/science.290.5500.2319", "10.1038/nature06512", "10.1109/2945.981847", "10.1109/tvcg.2006.192", "10.1098/rsta.1994.0106", "10.1126/science.1227079", "10.1109/tvcg.2015.2468078", "10.1098/rspb.2015.2258", "10.2312/cgvc.20181210", "10.1177/1473871617692841", "10.1007/s11284-017-1469-9", "10.1109/wi.2006.118", "10.1038/nature25504", "10.1109/tvcg.2017.2745258", "10.1109/tvcg.2013.109", "10.1126/science.290.5500.2323", "10.1109/iv.2013.8", "10.1038/344734a0", "10.1890/0012-9658(1998)079{[}0201:acoams]2.0.co", "2", "10.1109/tvcg.2018.2846735", "10.1038/srep14750", "10.1111/cgf.12396", "10.1007/bf02289565", "10.1890/07-1246.1", "10.1046/j.1461-0248.2002.00312.x", "10.1145/3139295.3139303", "10.1177/1473871613487087"], "wos": 1, "children": [], "len": 1}, {"doi": "10.1111/cgf.14034", "year": "2020", "title": "The State of the Art in Enhancing Trust in Machine Learning Models with the Use of Visualizations", "conferenceName": "EuroVis", "authors": "Angelos Chatzimparmpas;Rafael Messias Martins;Ilir Jusufi;Kostiantyn Kucher;Fabrice Rossi;Andreas Kerren", "citationCount": "2", "affiliation": "Chatzimparmpas, A (Corresponding Author), Linnaeus Univ, Dept Comp Sci \\& Media Technol, Vaxjo, Sweden.\nChatzimparmpas, A.; Martins, R. M.; Jusufi, I.; Kucher, K.; Kerren, A., Linnaeus Univ, Dept Comp Sci \\& Media Technol, Vaxjo, Sweden.\nRossi, F., PSL Univ, Univ Paris Dauphine, Ceremade, Paris, France.", "countries": "Sweden;France", "abstract": "Machine learning (ML) models are nowadays used in complex applications in various domains, such as medicine, bioinformatics, and other sciences. Due to their black box nature, however, it may sometimes be hard to understand and trust the results they provide. This has increased the demand for reliable visualization tools related to enhancing trust in ML models, which has become a prominent topic of research in the visualization community over the past decades. To provide an overview and present the frontiers of current research on the topic, we present a State-of-the-Art Report (STAR) on enhancing trust in ML models with the use of interactive visualization. We define and describe the background of the topic, introduce a categorization for visualization techniques that aim to accomplish this goal, and discuss insights and opportunities for future research directions. Among our contributions is a categorization of trust against different facets of interactive ML, expanded and improved from previous research. Our results are investigated from different analytical perspectives: (a) providing a statistical overview, (b) summarizing key findings, (c) performing topic analyses, and (d) exploring the data sets used in the individual papers, all with the support of an interactive web-based survey browser. We intend this survey to be beneficial for visualization researchers whose interests involve making ML models more trustworthy, as well as researchers and practitioners from other disciplines in their search for effective visualization techniques suitable for solving their tasks with confidence and conveying meaning to their data.", "keywords": "trustworthy machine learning; visualization; interpretable machine learning; explainable machine learning", "link": "https://doi.org/10.1111/cgf.14034", "refList": ["10.1109/mcg.2018.2878902", "10.1109/tvcg.2008.153", "10.2312/mlvis.20181130", "10.1109/tvcg.2016.2598828", "10.1145/3290605.3300911", "10.1145/2993901.2993909", "10.2312/mlvis.20191158", "10.1109/tvcg.2016.2598446", "10.1111/j.1467-8659.2009.01475.x", "10.1145/3290605.3300809", "10.1109/pacificvis.2018.00031", "10.1055/s-0029-1216348", "10.1007/978-3-319-90403-0\\_13", "10.1109/tvcg.2017.2745085", "10.1111/j.1467-8659.2011.01938.x", "10.1007/978-3-319-54024-5\\_6", "10.1016/s0167-9473(01)00065-2", "10.1111/cgf.12895", "10.2312/eurovisshort.20141152.17", "10.2312/eurova.20151098.22", "10.1111/cgf.13667", "10.3115/1072228.1072378", "10.1109/tbdata.2018.2877350.16", "10.1109/lars.2009.5418323.25", "10.1109/tvcg.2017.2744878", "10.1016/j.combustflame.2005.09.018", "10.1016/j.cag.2014.01.006", "10.1109/tvcg.2016.2570755", "10.2312/mlvis.20191158.1,19", "10.1518/hfes.46.1.50.30392", "10.1145/3301275.3302280", "10.1145/3351095.3372834.1", "10.1016/s0377-2217(01)00264-8", "10.1111/cgf.13424", "10.1007/978-3-319-23485-4\\_53", "10.1007/978-94-007-0753-5\\_3623", "10.1109/tvcg.2013.101", "10.1111/cgf.12884", "10.1111/j.1467-8659.2010.01835.x", "10.1021/ci9901338", "10.4230/lipics.itcs:2017", "10.1109/mis.2013.24", "10.1109/tvcg.2014.2346482", "10.1109/tvcg.2018.2865230", "10.1073/pnas.1807180116", "10.1109/dsaa.2018.00018", "10.1109/tvcg.2009.153", "10.3115/1219840.1219855", "10.1109/tvcg.2018.2864812", "10.1109/tvcg.2018.2872577", "10.2312/trvis.20191183", "10.1109/cvpr:2004.383", "10.1109/vast.2008.4677350", "10.1145/302979.303001", "10.1109/tvcg.2018.2864499", "10.1111/cgf.13672", "10.1109/tvcg.2014.2346626", "10.23915/distill.00010.18", "10.1109/tvcg.2017.2744805", "10.2312/mlvis:20191160.18", "10.23915/distill:00016", "10.1109/pacificvis.2016.7465260", "10.1111/cgf.13683", "10.23915/distill.00016.19", "10.1145/32906053.300803.22", "10.1109/tvcg.2014.2346574", "10.1177/1473871615600010", "10.1109/tvcg.2016.2598831", "10.1145/3230623", "10.1109/visual.2019.8933744", "10.1145/2993901.2993915", "10.1016/j.visinf.2017.01.006", "10.1145/2993901.2993914", "10.1109/tvcg.2014.2346984", "10.1109/5.726791", "10.23915/distill.00010", "10.1109/tvcg.2018.2864825", "10.2307/2394164", "10.1109/tvcg.2017.2744458", "10.1145/2993901.2993917.28", "10.1111/cgf.13711", "10.1109/tvcg.2016.2598664", "10.2307/2530428", "10.1109/icdar.1997.620583", "10.1109/tvcg.2017.2744718", "10.1111/cgf.13425", "10.1109/tvcg.2019.2903943", "10.1145/1518701.1518895", "10.1109/tvcg.2018.2864838", "10.1145/62038.62043", "10.1111/j.1467-8659.2011.01920.x", "10.1145/3025171.3025208", "10.1145/355112.355124", "10.1109/vast.2010.5652398", "10.1109/tvcg.2014.2346578", "10.1145/3173574.3174209", "10.4178/epih/e2014008", "10.1109/beliv.2018.8634201.25,28", "10.1016/j.eswa.2007.12.020", "10.1111/cgf:13406", "10.1109/mcg.2011.103", "10.1631/fitee.1700808", "10.1109/tvcg.2017.2745158", "10.1073/pnas.0307752101", "10.1109/tvcg.2018.2816223", "10.1109/tvcg.2017.2745141", "10.1145/32232.32234", "10.1109/tvcg.2019.2934267", "10.1109/tvcg.2018.2864477", "10.1145/3132169", "10.2312/eurova.20151100.19", "10.1145/3172944.3172964", "10.1145/2601248.2601268", "10.1109/isai-nlp.2018.8693002.1", "10.1111/cgf.13404", "10.1007/s100320200071", "10.2312/trvis.20191183.16", "10.1111/cgf.12755", "10.1145/2702123.2702509", "10.1145/1401890.1402008.25", "10.1109/tvcg.2012.65", "10.1177/1473871617733996", "10.2312/trvis.20191187.7", "10.21236/ada273556", "10.1109/vast.2010.5652450", "10.1111/j.1467-8659.2011.01940.x", "10.1177/875647939000600106", "10.1109/tvcg.2017.2711030", "10.1016/j.immuni.2016.04.014", "10.1109/tvcg.2019.2934209", "10.1016/0095-0696(78)90006-2", "10.1016/j.jclinepi.2015.04.014", "10.1016/j.ress.2013.02.013", "10.1111/cgf.12640", "10.1145/1015330.1015388.25", "10.1111/j.1467-8659.2009.01468.x", "10.1145/1541880.1541882", "10.1109/vast.2011.6102453", "10.1016/s0008-8846(98)00165-3", "10.2312/trvis.20191186.7", "10.1007/s13748-013-0040-3", "10.1109/tvcg.2015.2467757", "10.1109/tbdata.2018.2877350", "10.1109/vast.2017.8585613", "10.1080/10556789208805504", "10.1109/vast.2012.6400484", "10.1145/3025171.3025181", "10.1007/978-3-319-90403-0\\_12", "10.1109/mcg.2019.2922592", "10.1021/ci000392t", "10.1109/vast.2007.4389000", "10.1111/cgf.13406.16", "10.1111/cgf.13684", "10.2312/eurovisshort.20161166.17", "10.2312/evs:20191168", "10.1145/3041021.3055135", "10.1145/3301275.3302265", "10.1613/jair.4135", "10.1109/tvcg.2018.2864500", "10.1109/tvcg.2017.2744158", "10.1109/ssci.2015.33", "10.1111/cgf.13453", "10.2312/pe/eurovast/eurova11/049-052", "10.1145/3025171.3025181.13", "10.1145/371920.372094", "10.1109/tvcg.2017.2744938", "10.1111/j.1467-8659.2012.03108.x", "10.1109/tvcg.2019.2934251", "10.1145/3290605.3300809.18", "10.1109/ldav.2016.7874305", "10.1109/vast.2016.7883514", "10.1109/iccv.2015.425", "10.1145/3301275.3302324", "10.1109/tnnls.2013.2292894", "10.1109/tvcg.2018.2865044", "10.1109/tvcg.2013.157", "10.1371/journal.pcbi.0020161", "10.1186/s12916-019-1426-2", "10.1109/10.867928", "10.1111/cgf.13217", "10.1109/mcg.2019.2919033", "10.1145/2993901.2993910", "10.1109/tvcg.2017.2744738", "10.2307/258792", "10.1111/cgf.12655", "10.1016/j.dss.2014.03.001", "10.1109/tvcg.2019.2904069", "10.1111/cgf.13205", "10.1002/mds.22340", "10.1109/tvcg.2019.2934595", "10.1287/inte.2018.0957", "10.1109/cvpr.2007.382974", "10.1109/tvcg.2012.280", "10.1145/2678025.2701399.13", "10.2312/mlvis.20181130.13", "10.2312/eurova.20181106.16", "10.1109/tvcg.2018.2864475", "10.2312/mlvis.20191160.18,22", "10.1007/978-1-4612-4026-6.25", "10.1109/cvpr.2006.42", "10.1145/3172944.3172950", "10.1109/cvpr.2004.383.25", "10.1109/tvcg.2019.2934812", "10.1609/aimag.v35i4.2513", "10.2312/trvis.20191185.7", "10.1111/j.1467-8659.2009.01684.x", "10.1371/journal.pone.0129126", "10.1111/cgf.13092", "10.1162/coli\\_a\\_00237", "10.1109/tvcg.2017.2744818", "10.1109/vast.2011.6102448", "10.1109/tvcg.2009.111", "10.1109/tvcg.2019.2934619", "10.1016/s0377-2217(01)00264-8.25", "10.1111/cgf.12639", "10.1109/access.2019.2919343", "10.1186/s12874-019-0681-4", "10.1109/pacificvis.2015.7156366", "10.1109/pacificvis.2018.00029", "10.1109/tvcg.2019.2934261", "10.1080/13506280444000102.http://www.uvt.nl/ticc", "10.1109/vast.2018.8802509", "10.1111/cgf.13212", "10.1145/3200489", "10.1111/cgf.13176", "10.1177/1473871620904671", "10.1007/978-3-319-10590-1\\_53", "10.1111/j.1467-8659.2012.03126.x", "10.1111/cgf.13172", "10.1145/3025171.3025208.6,21", "10.1111/cgf.12366", "10.1109/tvcg.2019.2934659", "10.1109/cvprw.2009.5206848", "10.1016/j.media.2014.11.010", "10.1109/tvcg.2017.2744683", "10.1109/tvcg.2019.2934262", "10.1016/j.neucom.2006.11.018", "10.1177/1473871615571951", "10.1371/journal.pcbi.0020161.25", "10.1177/1473871611415994", "10.2312/trvis20191187", "10.2312/eurova", "10.1145/2858036.2858529", "10.1145/2207676.2207738", "10.1007/s11042-009-0417-2", "10.1145/3301275.3302317", "10.1038/s41746-019-0148-3", "10.1145/3351095.3372834", "10.1080/10691898.2011.11889627", "10.1109/tvcg.2018.2864504", "10.1109/vast.2017.8585720", "10.1109/mcg.2018.053491732", "10.1007/s10994-010-5207-6", "10.1109/tvcg.2019.2934433", "10.1016/j.cag.2017.05.005", "10.1109/tvcg.2012.279", "10.1145/3231622.3231641.19,20", "10.1145/1562849.1562851", "10.1007/11564126\\_", "10.1109/tvcg.2018.2846735", "10.3115/1225403.1225421", "10.1109/vast.2012.6400486", "10.2312/eurova.20191116.22", "10.1109/tvcg.2007.70443", "10.1080/027868291009242", "10.2312/eurova.20151100", "10.1145/2939502.2939503.19", "10.1016/j.cag.2014.02.004", "10.1145/2939672.2939778", "10.1109/vast.2010.5652484", "10.1111/cgf.12641", "10.1145/3301275.3302289", "10.1109/visual.2019.8933619", "10.1109/tvcg.2017.2672987", "10.1109/vast.2016.7883517.20", "10.1109/igarss.2017.8127684", "10.1016/j.jcae.2010.04.002", "10.1109/vast.2010.5652885", "10.1016/j.visinf.2019.03.002", "10.1007/s00371-018-1500-3", "10.1109/mcg.2018.042731661", "10.1109/34.598228", "10.1109/tvcg.2018.2865027", "10.1016/j.neucom.2017.01.105", "10.1111/cgf.12389", "10.1109/tvcg.2019.2934591", "10.1109/vast.2010.5652392.16", "10.1111/cgf.13416", "10.1080/02701367.1992.10608764", "10.1109/vast.2017.8585721", "10.1109/tvcg.2018.2843369", "10.1109/sbes.2010.27", "10.1109/vast.2015.7347637", "10.1145/1401890.1402008", "10.1016/j.bpj.2010.04.064", "10.1109/tvcg.2013.125", "10.1109/isai-nlp.2018.8693002", "10.1371/journal.pone.0160127", "10.1145/2856767.2856779", "10.1145/2678025.2701399", "10.1109/vast.2011.6102451", "10.1109/mcg.2010.18", "10.1021/ci4000213", "10.1109/vast.2012.6400492", "10.1007/11564126-49.25", "10.2312/eurova.20171114", "10.1109/vast.2010.5652443", "10.1145/3134599", "10.2312/pe/eurovast/eurovast10/013-018.19", "10.1109/tvcg.2019.2903946", "10.1109/tvcg.2015.2467717", "10.1177/1473871612460526", "10.1016/j.cag.2018.09.018", "10.1109/tvcg.2016.2598838", "10.1145/3172944.3172964.14", "10.1109/vast.2009.5333428", "10.1109/vast.2014.7042480", "10.2312/pe/eurovast/eurovast10/013-018", "10.1177/0962280215588241", "10.1145/2993901.2993917", "10.1109/cvpr.2008:4587581", "10.1109/tvcg.2015.2467551", "10.1016/j.visinf.2018.09.001", "10.1126/science.290.5500.2319", "10.2312/eurova.20151107", "10.1109/visual.2019.8933695", "10.13140/2.1.2393.1847", "10.1197/jamia.m1929", "10.1109/cvpr.2008.4587581.25", "10.1145/1518701.1518895.16", "10.1109/vds.2017.8573444", "10.2312/trvis:20191185", "10.1145/3359786", "10.13140/2.1.1341.1520", "10.2312/pe/eurovast/eurova11/049-052.17", "10.1109/tvcg.2014.2346660", "10.1145/3185517", "10.1109/adprl.2011.5967372", "10.1109/tvcg.2015.2467591", "10.1111/j.1751-9004.2009.00232.x", "10.1136/qshc.2004.010033", "10.1109/vast.2012.6400493", "10.1109/tvcg.2019.2934266", "10.1145/2971763.2971775", "10.1111/cgf.13730", "10.1109/vast.2012.6400488", "10.1111/cgf.13210", "10.1109/tvcg.2019.2934631", "10.1145/3172944.3172965", "10.1057/ivs.2010.2", "10.1109/tvcg.2017.2745258", "10.1016/j.jbusres.2019.07.039", "10.1162/jmlr.2003.3.4-5.993", "10.1109/pacificvis.2019.00044", "10.2312/pe/eurovast/eurova12/037-041", "10.1109/tvcg.2019.2934629", "10.1177/0018720814547570", "10.1145/3292500.3330908", "10.1111/j.1467-8659.2009.01467.x", "10.2312/eurova.20151098", "10.1177/1473871617713337", "10.1109/lars:2009.5418323", "10.1109/vast.2011.6102437", "10.1111/cgf.12878", "10.1561/1500000001", "10.1145/3025171.3025222", "10.1007/s11704-016-6028-y", "10.1016/j.procs.2017.05.216", "10.1109/cvpr.2007.382974.25", "10.1080/10447318.2020.1741118", "10.1109/vast.2012.6400489", "10.1145/3025171.3025172", "10.1109/tvcg.2017.2744098", "10.1109/tvcg.2005.66", "10.1016/j.dss.2009.05.016", "10.1007/978-1-4612-4026-6", "10.2312/evs.20191168.16,20,28", "10.2312/pe/eurovast/eurova12/037-041.17", "10.1145/3290605.3300803", "10.1145/1015330.1015388", "10.1111/cgf.13197", "10.1016/b978-1-55860-377-6.50048-7", "10.1111/cgf.13681", "10.1109/tvcg.2017.2744378", "10.1109/tvcg.2017.2744358", "10.1109/vast.2008.4677352"], "wos": 1, "children": [{"doi": "10.1109/tvcg.2020.3030368", "title": "Implicit Multidimensional Projection of Local Subspaces", "year": "2020", "conferenceName": "InfoVis", "authors": "Rongzheng Bian;Yumeng Xue;Liang Zhou;Jian Zhang 0070;Baoquan Chen;Daniel Weiskopf;Yunhai Wang", "citationCount": "1", "affiliation": "Wang, YH (Corresponding Author), Shandong Univ, Qingdao, Peoples R China. Zhou, L (Corresponding Author), Univ Utah, Salt Lake City, UT 84112 USA. Bian, Rongzheng; Xue, Yumeng; Wang, Yunhai, Shandong Univ, Qingdao, Peoples R China. Chen, Baoquan, Peking Univ, Beijing, Peoples R China. Zhang, Jian, Chinese Acad Sci, CNIC, Beijing, Peoples R China. Zhou, Liang, Univ Utah, Salt Lake City, UT 84112 USA. Weiskopf, Daniel, Univ Stuttgart, Stuttgart, Germany.", "countries": "USA;Germany;China", "abstract": "We propose a visualization method to understand the effect of multidimensional projection on local subspaces, using implicit function differentiation. Here, we understand the local subspace as the multidimensional local neighborhood of data points. Existing methods focus on the projection of multidimensional data points, and the neighborhood information is ignored. Our method is able to analyze the shape and directional information of the local subspace to gain more insights into the global structure of the data through the perception of local structures. Local subspaces are fitted by multidimensional ellipses that are spanned by basis vectors. An accurate and efficient vector transformation method is proposed based on analytical differentiation of multidimensional projections formulated as implicit functions. The results are visualized as glyphs and analyzed using a full set of specifically-designed interactions supported in our efficient web-based visualization tool. The usefulness of our method is demonstrated using various multi- and high-dimensional benchmark datasets. Our implicit differentiation vector transformation is evaluated through numerical comparisons; the overall method is evaluated through exploration examples and use cases.", "keywords": "High-dimensional data visualization,dimensionality reduction,local linear subspaces,user interaction", "link": "http://dx.doi.org/10.1109/TVCG.2020.3030368", "refList": ["10.3844/jcssp.2018.613.622", "10.1016/j.aci.2018.08.003", "10.3390/info9030065", "10.1016/j.visinf.2018.09.003", "10.1371/journal.pone.0118432", "10.1016/s0893-6080(05)80023-1", "10.1109/tvcg.2020.2986996", "10.1109/icst.2012.56", "10.1007/s10844-013-0250-y", "10.1109/tbdata.2018", "10.1145/1125451.1125659", "10.1109/tvcg.2013.125", "10.1177/1473871611412817", "10.1145/3290605.3300911", "10.1111/cgf.14034", "10.1007/s13721-013-0034-x", "10.1016/j.procs.2017.05.216", "10.1016/j.ins.2009.08.025", "10.1109/tvcg.2013.124", "10.1109/tvcg.2018.2864499", "10.1109/tvcg.2018.2864475", "10.1080/10447318.2020.1741118", "10.1016/j.imu.2019.100203", "10.1109/tvcg.2018.2865240", "10.1186/s12864-019-6413-7", "10.1109/tvcg.2015.2467551", "10.1002/widm.1249", "10.1007/978-3-319-66429-3\\_29", "10.1109/tvcg.2014.2346481", "10.1109/tvcg.2018.2864825", "10.1177/1473871620904671", "10.1109/tvcg.2019.2934267", "10.1136/bmjopen-2016-012799", "10.1109/smartgridcomm.2017.8340682", "10.1007/s10664-015-9401-9", "10.1145/1143844.1143874", "10.1111/cgf.12389", "10.1109/tvcg.2018.2872577", "10.1007/978-981-13-5802-9\\_20", "10.1016/j.ipm.2009.03.002", "10.5220/0006431602160222", "10.1109/mcg.2015.50", "10.1109/tvcg.2014.2346574", "10.1007/bf02289565", "10.1109/tvcg.2017.2744378", "10.1016/j.patrec.2008.08.010", "10.1023/a:1010933404324", "10.9735/2229-3981"], "wos": 1, "children": [], "len": 1}, {"doi": "10.1109/tvcg.2020.3030465", "title": "Visual Causality Analysis of Event Sequence Data", "year": "2020", "conferenceName": "VAST", "authors": "Zhuochen Jin;Shunan Guo;Nan Chen;Daniel Weiskopf;David Gotz;Nan Cao", "citationCount": "0", "affiliation": "Cao, N (Corresponding Author), Tongji Univ, IDVx Lab, Shanghai, Peoples R China. Jin, Zhuochen; Guo, Shunan; Chen, Nan; Cao, Nan, Tongji Univ, IDVx Lab, Shanghai, Peoples R China. Weiskopf, Daniel, Univ Stuttgart, Stuttgart, Germany. Gotz, David, Univ N Carolina, Chapel Hill, NC 27515 USA.", "countries": "USA;Germany;China", "abstract": "Causality is crucial to understanding the mechanisms behind complex systems and making decisions that lead to intended outcomes. Event sequence data is widely collected from many real-world processes, such as electronic health records, web clickstreams, and financial transactions, which transmit a great deal of information reflecting the causal relations among event types. Unfortunately, recovering causalities from observational event sequences is challenging, as the heterogeneous and high-dimensional event variables are often connected to rather complex underlying event excitation mechanisms that are hard to infer from limited observations. Many existing automated causal analysis techniques suffer from poor explainability and fail to include an adequate amount of human knowledge. In this paper, we introduce a visual analytics method for recovering causalities in event sequence data. We extend the Granger causality analysis algorithm on Hawkes processes to incorporate user feedback into causal model refinement. The visualization system includes an interactive causal analysis framework that supports bottom-up causal exploration, iterative causal verification and refinement, and causal comparison through a set of novel visualizations and interactions. We report two forms of evaluation: a quantitative evaluation of the model improvements resulting from the user-feedback mechanism, and a qualitative evaluation through case studies in different application domains to demonstrate the usefulness of the system.", "keywords": "Event sequence data,causality analysis,visual analytics", "link": "http://dx.doi.org/10.1109/TVCG.2020.3030465", "refList": ["10.5555/1642718", "10.1109/tvcg.2018.2865022", "10.5555/2074094.2074151", "10.1109/tvcg.2016.2618797", "10.1073/pnas.1320645111", "10.1109/tvcg.2017.2744843", "10.1109/iv.2017.69", "10.1109/tvcg.2019.2934399", "10.1145/3172944.3173007", "10.5555/1795555", "10.1109/mcg.2005.102", "10.1145/381641.381653", "10.1162/153244301753344614", "10.1111/cgf.14034", "10.1111/cgf.13198", "10.1017/cbo9780511519857", "10.1007/s10462-016-9475-9", "10.1075/ssol.2.2.07bor", "10.1007/978-1-4614-3223-4\\_3", "10.1109/infvis.2003.1249025", "10.1007/978-94-007-6094-313", "10.1145/2858036.2858387", "10.1109/tvcg.2007.70528", "10.1109/tvcg.2017.2674958", "10.1147/sj.454.0801", "10.1109/tvcg.2013.119", "10.1145/3173574.3173711", "10.1016/j.erss.2017.06.034", "10.1109/visual.2019.8933695", "10.1007/s11665-016-2173-6", "10.1016/0377-0427(87)90125-7", "10.2307/3601125", "10.1016/b978-0-444-88738-2.50018-x", "10.1109/mcg.2006.70", "10.1109/tvcg.2018.2865145", "10.1017/s1351324997001502", "10.1109/tvcg.2010.179", "10.1214/aos/1176344552", "10.1109/mcg.2009.22", "10.1007/978-3-319-26633-6\\_13", "10.1080/10447318.2014.905422", "10.1016/j.visinf.2019.03.004", "10.1057/palgrave.ivs.9500074", "10.1007/978-1-4614-3223-4"], "wos": 1, "children": [], "len": 1}], "len": 5}], "len": 11}, {"doi": "10.1111/cgf.14034", "year": "2020", "title": "The State of the Art in Enhancing Trust in Machine Learning Models with the Use of Visualizations", "conferenceName": "EuroVis", "authors": "Angelos Chatzimparmpas;Rafael Messias Martins;Ilir Jusufi;Kostiantyn Kucher;Fabrice Rossi;Andreas Kerren", "citationCount": "2", "affiliation": "Chatzimparmpas, A (Corresponding Author), Linnaeus Univ, Dept Comp Sci \\& Media Technol, Vaxjo, Sweden.\nChatzimparmpas, A.; Martins, R. M.; Jusufi, I.; Kucher, K.; Kerren, A., Linnaeus Univ, Dept Comp Sci \\& Media Technol, Vaxjo, Sweden.\nRossi, F., PSL Univ, Univ Paris Dauphine, Ceremade, Paris, France.", "countries": "Sweden;France", "abstract": "Machine learning (ML) models are nowadays used in complex applications in various domains, such as medicine, bioinformatics, and other sciences. Due to their black box nature, however, it may sometimes be hard to understand and trust the results they provide. This has increased the demand for reliable visualization tools related to enhancing trust in ML models, which has become a prominent topic of research in the visualization community over the past decades. To provide an overview and present the frontiers of current research on the topic, we present a State-of-the-Art Report (STAR) on enhancing trust in ML models with the use of interactive visualization. We define and describe the background of the topic, introduce a categorization for visualization techniques that aim to accomplish this goal, and discuss insights and opportunities for future research directions. Among our contributions is a categorization of trust against different facets of interactive ML, expanded and improved from previous research. Our results are investigated from different analytical perspectives: (a) providing a statistical overview, (b) summarizing key findings, (c) performing topic analyses, and (d) exploring the data sets used in the individual papers, all with the support of an interactive web-based survey browser. We intend this survey to be beneficial for visualization researchers whose interests involve making ML models more trustworthy, as well as researchers and practitioners from other disciplines in their search for effective visualization techniques suitable for solving their tasks with confidence and conveying meaning to their data.", "keywords": "trustworthy machine learning; visualization; interpretable machine learning; explainable machine learning", "link": "https://doi.org/10.1111/cgf.14034", "refList": ["10.1109/mcg.2018.2878902", "10.1109/tvcg.2008.153", "10.2312/mlvis.20181130", "10.1109/tvcg.2016.2598828", "10.1145/3290605.3300911", "10.1145/2993901.2993909", "10.2312/mlvis.20191158", "10.1109/tvcg.2016.2598446", "10.1111/j.1467-8659.2009.01475.x", "10.1145/3290605.3300809", "10.1109/pacificvis.2018.00031", "10.1055/s-0029-1216348", "10.1007/978-3-319-90403-0\\_13", "10.1109/tvcg.2017.2745085", "10.1111/j.1467-8659.2011.01938.x", "10.1007/978-3-319-54024-5\\_6", "10.1016/s0167-9473(01)00065-2", "10.1111/cgf.12895", "10.2312/eurovisshort.20141152.17", "10.2312/eurova.20151098.22", "10.1111/cgf.13667", "10.3115/1072228.1072378", "10.1109/tbdata.2018.2877350.16", "10.1109/lars.2009.5418323.25", "10.1109/tvcg.2017.2744878", "10.1016/j.combustflame.2005.09.018", "10.1016/j.cag.2014.01.006", "10.1109/tvcg.2016.2570755", "10.2312/mlvis.20191158.1,19", "10.1518/hfes.46.1.50.30392", "10.1145/3301275.3302280", "10.1145/3351095.3372834.1", "10.1016/s0377-2217(01)00264-8", "10.1111/cgf.13424", "10.1007/978-3-319-23485-4\\_53", "10.1007/978-94-007-0753-5\\_3623", "10.1109/tvcg.2013.101", "10.1111/cgf.12884", "10.1111/j.1467-8659.2010.01835.x", "10.1021/ci9901338", "10.4230/lipics.itcs:2017", "10.1109/mis.2013.24", "10.1109/tvcg.2014.2346482", "10.1109/tvcg.2018.2865230", "10.1073/pnas.1807180116", "10.1109/dsaa.2018.00018", "10.1109/tvcg.2009.153", "10.3115/1219840.1219855", "10.1109/tvcg.2018.2864812", "10.1109/tvcg.2018.2872577", "10.2312/trvis.20191183", "10.1109/cvpr:2004.383", "10.1109/vast.2008.4677350", "10.1145/302979.303001", "10.1109/tvcg.2018.2864499", "10.1111/cgf.13672", "10.1109/tvcg.2014.2346626", "10.23915/distill.00010.18", "10.1109/tvcg.2017.2744805", "10.2312/mlvis:20191160.18", "10.23915/distill:00016", "10.1109/pacificvis.2016.7465260", "10.1111/cgf.13683", "10.23915/distill.00016.19", "10.1145/32906053.300803.22", "10.1109/tvcg.2014.2346574", "10.1177/1473871615600010", "10.1109/tvcg.2016.2598831", "10.1145/3230623", "10.1109/visual.2019.8933744", "10.1145/2993901.2993915", "10.1016/j.visinf.2017.01.006", "10.1145/2993901.2993914", "10.1109/tvcg.2014.2346984", "10.1109/5.726791", "10.23915/distill.00010", "10.1109/tvcg.2018.2864825", "10.2307/2394164", "10.1109/tvcg.2017.2744458", "10.1145/2993901.2993917.28", "10.1111/cgf.13711", "10.1109/tvcg.2016.2598664", "10.2307/2530428", "10.1109/icdar.1997.620583", "10.1109/tvcg.2017.2744718", "10.1111/cgf.13425", "10.1109/tvcg.2019.2903943", "10.1145/1518701.1518895", "10.1109/tvcg.2018.2864838", "10.1145/62038.62043", "10.1111/j.1467-8659.2011.01920.x", "10.1145/3025171.3025208", "10.1145/355112.355124", "10.1109/vast.2010.5652398", "10.1109/tvcg.2014.2346578", "10.1145/3173574.3174209", "10.4178/epih/e2014008", "10.1109/beliv.2018.8634201.25,28", "10.1016/j.eswa.2007.12.020", "10.1111/cgf:13406", "10.1109/mcg.2011.103", "10.1631/fitee.1700808", "10.1109/tvcg.2017.2745158", "10.1073/pnas.0307752101", "10.1109/tvcg.2018.2816223", "10.1109/tvcg.2017.2745141", "10.1145/32232.32234", "10.1109/tvcg.2019.2934267", "10.1109/tvcg.2018.2864477", "10.1145/3132169", "10.2312/eurova.20151100.19", "10.1145/3172944.3172964", "10.1145/2601248.2601268", "10.1109/isai-nlp.2018.8693002.1", "10.1111/cgf.13404", "10.1007/s100320200071", "10.2312/trvis.20191183.16", "10.1111/cgf.12755", "10.1145/2702123.2702509", "10.1145/1401890.1402008.25", "10.1109/tvcg.2012.65", "10.1177/1473871617733996", "10.2312/trvis.20191187.7", "10.21236/ada273556", "10.1109/vast.2010.5652450", "10.1111/j.1467-8659.2011.01940.x", "10.1177/875647939000600106", "10.1109/tvcg.2017.2711030", "10.1016/j.immuni.2016.04.014", "10.1109/tvcg.2019.2934209", "10.1016/0095-0696(78)90006-2", "10.1016/j.jclinepi.2015.04.014", "10.1016/j.ress.2013.02.013", "10.1111/cgf.12640", "10.1145/1015330.1015388.25", "10.1111/j.1467-8659.2009.01468.x", "10.1145/1541880.1541882", "10.1109/vast.2011.6102453", "10.1016/s0008-8846(98)00165-3", "10.2312/trvis.20191186.7", "10.1007/s13748-013-0040-3", "10.1109/tvcg.2015.2467757", "10.1109/tbdata.2018.2877350", "10.1109/vast.2017.8585613", "10.1080/10556789208805504", "10.1109/vast.2012.6400484", "10.1145/3025171.3025181", "10.1007/978-3-319-90403-0\\_12", "10.1109/mcg.2019.2922592", "10.1021/ci000392t", "10.1109/vast.2007.4389000", "10.1111/cgf.13406.16", "10.1111/cgf.13684", "10.2312/eurovisshort.20161166.17", "10.2312/evs:20191168", "10.1145/3041021.3055135", "10.1145/3301275.3302265", "10.1613/jair.4135", "10.1109/tvcg.2018.2864500", "10.1109/tvcg.2017.2744158", "10.1109/ssci.2015.33", "10.1111/cgf.13453", "10.2312/pe/eurovast/eurova11/049-052", "10.1145/3025171.3025181.13", "10.1145/371920.372094", "10.1109/tvcg.2017.2744938", "10.1111/j.1467-8659.2012.03108.x", "10.1109/tvcg.2019.2934251", "10.1145/3290605.3300809.18", "10.1109/ldav.2016.7874305", "10.1109/vast.2016.7883514", "10.1109/iccv.2015.425", "10.1145/3301275.3302324", "10.1109/tnnls.2013.2292894", "10.1109/tvcg.2018.2865044", "10.1109/tvcg.2013.157", "10.1371/journal.pcbi.0020161", "10.1186/s12916-019-1426-2", "10.1109/10.867928", "10.1111/cgf.13217", "10.1109/mcg.2019.2919033", "10.1145/2993901.2993910", "10.1109/tvcg.2017.2744738", "10.2307/258792", "10.1111/cgf.12655", "10.1016/j.dss.2014.03.001", "10.1109/tvcg.2019.2904069", "10.1111/cgf.13205", "10.1002/mds.22340", "10.1109/tvcg.2019.2934595", "10.1287/inte.2018.0957", "10.1109/cvpr.2007.382974", "10.1109/tvcg.2012.280", "10.1145/2678025.2701399.13", "10.2312/mlvis.20181130.13", "10.2312/eurova.20181106.16", "10.1109/tvcg.2018.2864475", "10.2312/mlvis.20191160.18,22", "10.1007/978-1-4612-4026-6.25", "10.1109/cvpr.2006.42", "10.1145/3172944.3172950", "10.1109/cvpr.2004.383.25", "10.1109/tvcg.2019.2934812", "10.1609/aimag.v35i4.2513", "10.2312/trvis.20191185.7", "10.1111/j.1467-8659.2009.01684.x", "10.1371/journal.pone.0129126", "10.1111/cgf.13092", "10.1162/coli\\_a\\_00237", "10.1109/tvcg.2017.2744818", "10.1109/vast.2011.6102448", "10.1109/tvcg.2009.111", "10.1109/tvcg.2019.2934619", "10.1016/s0377-2217(01)00264-8.25", "10.1111/cgf.12639", "10.1109/access.2019.2919343", "10.1186/s12874-019-0681-4", "10.1109/pacificvis.2015.7156366", "10.1109/pacificvis.2018.00029", "10.1109/tvcg.2019.2934261", "10.1080/13506280444000102.http://www.uvt.nl/ticc", "10.1109/vast.2018.8802509", "10.1111/cgf.13212", "10.1145/3200489", "10.1111/cgf.13176", "10.1177/1473871620904671", "10.1007/978-3-319-10590-1\\_53", "10.1111/j.1467-8659.2012.03126.x", "10.1111/cgf.13172", "10.1145/3025171.3025208.6,21", "10.1111/cgf.12366", "10.1109/tvcg.2019.2934659", "10.1109/cvprw.2009.5206848", "10.1016/j.media.2014.11.010", "10.1109/tvcg.2017.2744683", "10.1109/tvcg.2019.2934262", "10.1016/j.neucom.2006.11.018", "10.1177/1473871615571951", "10.1371/journal.pcbi.0020161.25", "10.1177/1473871611415994", "10.2312/trvis20191187", "10.2312/eurova", "10.1145/2858036.2858529", "10.1145/2207676.2207738", "10.1007/s11042-009-0417-2", "10.1145/3301275.3302317", "10.1038/s41746-019-0148-3", "10.1145/3351095.3372834", "10.1080/10691898.2011.11889627", "10.1109/tvcg.2018.2864504", "10.1109/vast.2017.8585720", "10.1109/mcg.2018.053491732", "10.1007/s10994-010-5207-6", "10.1109/tvcg.2019.2934433", "10.1016/j.cag.2017.05.005", "10.1109/tvcg.2012.279", "10.1145/3231622.3231641.19,20", "10.1145/1562849.1562851", "10.1007/11564126\\_", "10.1109/tvcg.2018.2846735", "10.3115/1225403.1225421", "10.1109/vast.2012.6400486", "10.2312/eurova.20191116.22", "10.1109/tvcg.2007.70443", "10.1080/027868291009242", "10.2312/eurova.20151100", "10.1145/2939502.2939503.19", "10.1016/j.cag.2014.02.004", "10.1145/2939672.2939778", "10.1109/vast.2010.5652484", "10.1111/cgf.12641", "10.1145/3301275.3302289", "10.1109/visual.2019.8933619", "10.1109/tvcg.2017.2672987", "10.1109/vast.2016.7883517.20", "10.1109/igarss.2017.8127684", "10.1016/j.jcae.2010.04.002", "10.1109/vast.2010.5652885", "10.1016/j.visinf.2019.03.002", "10.1007/s00371-018-1500-3", "10.1109/mcg.2018.042731661", "10.1109/34.598228", "10.1109/tvcg.2018.2865027", "10.1016/j.neucom.2017.01.105", "10.1111/cgf.12389", "10.1109/tvcg.2019.2934591", "10.1109/vast.2010.5652392.16", "10.1111/cgf.13416", "10.1080/02701367.1992.10608764", "10.1109/vast.2017.8585721", "10.1109/tvcg.2018.2843369", "10.1109/sbes.2010.27", "10.1109/vast.2015.7347637", "10.1145/1401890.1402008", "10.1016/j.bpj.2010.04.064", "10.1109/tvcg.2013.125", "10.1109/isai-nlp.2018.8693002", "10.1371/journal.pone.0160127", "10.1145/2856767.2856779", "10.1145/2678025.2701399", "10.1109/vast.2011.6102451", "10.1109/mcg.2010.18", "10.1021/ci4000213", "10.1109/vast.2012.6400492", "10.1007/11564126-49.25", "10.2312/eurova.20171114", "10.1109/vast.2010.5652443", "10.1145/3134599", "10.2312/pe/eurovast/eurovast10/013-018.19", "10.1109/tvcg.2019.2903946", "10.1109/tvcg.2015.2467717", "10.1177/1473871612460526", "10.1016/j.cag.2018.09.018", "10.1109/tvcg.2016.2598838", "10.1145/3172944.3172964.14", "10.1109/vast.2009.5333428", "10.1109/vast.2014.7042480", "10.2312/pe/eurovast/eurovast10/013-018", "10.1177/0962280215588241", "10.1145/2993901.2993917", "10.1109/cvpr.2008:4587581", "10.1109/tvcg.2015.2467551", "10.1016/j.visinf.2018.09.001", "10.1126/science.290.5500.2319", "10.2312/eurova.20151107", "10.1109/visual.2019.8933695", "10.13140/2.1.2393.1847", "10.1197/jamia.m1929", "10.1109/cvpr.2008.4587581.25", "10.1145/1518701.1518895.16", "10.1109/vds.2017.8573444", "10.2312/trvis:20191185", "10.1145/3359786", "10.13140/2.1.1341.1520", "10.2312/pe/eurovast/eurova11/049-052.17", "10.1109/tvcg.2014.2346660", "10.1145/3185517", "10.1109/adprl.2011.5967372", "10.1109/tvcg.2015.2467591", "10.1111/j.1751-9004.2009.00232.x", "10.1136/qshc.2004.010033", "10.1109/vast.2012.6400493", "10.1109/tvcg.2019.2934266", "10.1145/2971763.2971775", "10.1111/cgf.13730", "10.1109/vast.2012.6400488", "10.1111/cgf.13210", "10.1109/tvcg.2019.2934631", "10.1145/3172944.3172965", "10.1057/ivs.2010.2", "10.1109/tvcg.2017.2745258", "10.1016/j.jbusres.2019.07.039", "10.1162/jmlr.2003.3.4-5.993", "10.1109/pacificvis.2019.00044", "10.2312/pe/eurovast/eurova12/037-041", "10.1109/tvcg.2019.2934629", "10.1177/0018720814547570", "10.1145/3292500.3330908", "10.1111/j.1467-8659.2009.01467.x", "10.2312/eurova.20151098", "10.1177/1473871617713337", "10.1109/lars:2009.5418323", "10.1109/vast.2011.6102437", "10.1111/cgf.12878", "10.1561/1500000001", "10.1145/3025171.3025222", "10.1007/s11704-016-6028-y", "10.1016/j.procs.2017.05.216", "10.1109/cvpr.2007.382974.25", "10.1080/10447318.2020.1741118", "10.1109/vast.2012.6400489", "10.1145/3025171.3025172", "10.1109/tvcg.2017.2744098", "10.1109/tvcg.2005.66", "10.1016/j.dss.2009.05.016", "10.1007/978-1-4612-4026-6", "10.2312/evs.20191168.16,20,28", "10.2312/pe/eurovast/eurova12/037-041.17", "10.1145/3290605.3300803", "10.1145/1015330.1015388", "10.1111/cgf.13197", "10.1016/b978-1-55860-377-6.50048-7", "10.1111/cgf.13681", "10.1109/tvcg.2017.2744378", "10.1109/tvcg.2017.2744358", "10.1109/vast.2008.4677352"], "wos": 1, "children": [{"doi": "10.1109/tvcg.2020.3030368", "title": "Implicit Multidimensional Projection of Local Subspaces", "year": "2020", "conferenceName": "InfoVis", "authors": "Rongzheng Bian;Yumeng Xue;Liang Zhou;Jian Zhang 0070;Baoquan Chen;Daniel Weiskopf;Yunhai Wang", "citationCount": "1", "affiliation": "Wang, YH (Corresponding Author), Shandong Univ, Qingdao, Peoples R China. Zhou, L (Corresponding Author), Univ Utah, Salt Lake City, UT 84112 USA. Bian, Rongzheng; Xue, Yumeng; Wang, Yunhai, Shandong Univ, Qingdao, Peoples R China. Chen, Baoquan, Peking Univ, Beijing, Peoples R China. Zhang, Jian, Chinese Acad Sci, CNIC, Beijing, Peoples R China. Zhou, Liang, Univ Utah, Salt Lake City, UT 84112 USA. Weiskopf, Daniel, Univ Stuttgart, Stuttgart, Germany.", "countries": "USA;Germany;China", "abstract": "We propose a visualization method to understand the effect of multidimensional projection on local subspaces, using implicit function differentiation. Here, we understand the local subspace as the multidimensional local neighborhood of data points. Existing methods focus on the projection of multidimensional data points, and the neighborhood information is ignored. Our method is able to analyze the shape and directional information of the local subspace to gain more insights into the global structure of the data through the perception of local structures. Local subspaces are fitted by multidimensional ellipses that are spanned by basis vectors. An accurate and efficient vector transformation method is proposed based on analytical differentiation of multidimensional projections formulated as implicit functions. The results are visualized as glyphs and analyzed using a full set of specifically-designed interactions supported in our efficient web-based visualization tool. The usefulness of our method is demonstrated using various multi- and high-dimensional benchmark datasets. Our implicit differentiation vector transformation is evaluated through numerical comparisons; the overall method is evaluated through exploration examples and use cases.", "keywords": "High-dimensional data visualization,dimensionality reduction,local linear subspaces,user interaction", "link": "http://dx.doi.org/10.1109/TVCG.2020.3030368", "refList": ["10.3844/jcssp.2018.613.622", "10.1016/j.aci.2018.08.003", "10.3390/info9030065", "10.1016/j.visinf.2018.09.003", "10.1371/journal.pone.0118432", "10.1016/s0893-6080(05)80023-1", "10.1109/tvcg.2020.2986996", "10.1109/icst.2012.56", "10.1007/s10844-013-0250-y", "10.1109/tbdata.2018", "10.1145/1125451.1125659", "10.1109/tvcg.2013.125", "10.1177/1473871611412817", "10.1145/3290605.3300911", "10.1111/cgf.14034", "10.1007/s13721-013-0034-x", "10.1016/j.procs.2017.05.216", "10.1016/j.ins.2009.08.025", "10.1109/tvcg.2013.124", "10.1109/tvcg.2018.2864499", "10.1109/tvcg.2018.2864475", "10.1080/10447318.2020.1741118", "10.1016/j.imu.2019.100203", "10.1109/tvcg.2018.2865240", "10.1186/s12864-019-6413-7", "10.1109/tvcg.2015.2467551", "10.1002/widm.1249", "10.1007/978-3-319-66429-3\\_29", "10.1109/tvcg.2014.2346481", "10.1109/tvcg.2018.2864825", "10.1177/1473871620904671", "10.1109/tvcg.2019.2934267", "10.1136/bmjopen-2016-012799", "10.1109/smartgridcomm.2017.8340682", "10.1007/s10664-015-9401-9", "10.1145/1143844.1143874", "10.1111/cgf.12389", "10.1109/tvcg.2018.2872577", "10.1007/978-981-13-5802-9\\_20", "10.1016/j.ipm.2009.03.002", "10.5220/0006431602160222", "10.1109/mcg.2015.50", "10.1109/tvcg.2014.2346574", "10.1007/bf02289565", "10.1109/tvcg.2017.2744378", "10.1016/j.patrec.2008.08.010", "10.1023/a:1010933404324", "10.9735/2229-3981"], "wos": 1, "children": [], "len": 1}, {"doi": "10.1109/tvcg.2020.3030465", "title": "Visual Causality Analysis of Event Sequence Data", "year": "2020", "conferenceName": "VAST", "authors": "Zhuochen Jin;Shunan Guo;Nan Chen;Daniel Weiskopf;David Gotz;Nan Cao", "citationCount": "0", "affiliation": "Cao, N (Corresponding Author), Tongji Univ, IDVx Lab, Shanghai, Peoples R China. Jin, Zhuochen; Guo, Shunan; Chen, Nan; Cao, Nan, Tongji Univ, IDVx Lab, Shanghai, Peoples R China. Weiskopf, Daniel, Univ Stuttgart, Stuttgart, Germany. Gotz, David, Univ N Carolina, Chapel Hill, NC 27515 USA.", "countries": "USA;Germany;China", "abstract": "Causality is crucial to understanding the mechanisms behind complex systems and making decisions that lead to intended outcomes. Event sequence data is widely collected from many real-world processes, such as electronic health records, web clickstreams, and financial transactions, which transmit a great deal of information reflecting the causal relations among event types. Unfortunately, recovering causalities from observational event sequences is challenging, as the heterogeneous and high-dimensional event variables are often connected to rather complex underlying event excitation mechanisms that are hard to infer from limited observations. Many existing automated causal analysis techniques suffer from poor explainability and fail to include an adequate amount of human knowledge. In this paper, we introduce a visual analytics method for recovering causalities in event sequence data. We extend the Granger causality analysis algorithm on Hawkes processes to incorporate user feedback into causal model refinement. The visualization system includes an interactive causal analysis framework that supports bottom-up causal exploration, iterative causal verification and refinement, and causal comparison through a set of novel visualizations and interactions. We report two forms of evaluation: a quantitative evaluation of the model improvements resulting from the user-feedback mechanism, and a qualitative evaluation through case studies in different application domains to demonstrate the usefulness of the system.", "keywords": "Event sequence data,causality analysis,visual analytics", "link": "http://dx.doi.org/10.1109/TVCG.2020.3030465", "refList": ["10.5555/1642718", "10.1109/tvcg.2018.2865022", "10.5555/2074094.2074151", "10.1109/tvcg.2016.2618797", "10.1073/pnas.1320645111", "10.1109/tvcg.2017.2744843", "10.1109/iv.2017.69", "10.1109/tvcg.2019.2934399", "10.1145/3172944.3173007", "10.5555/1795555", "10.1109/mcg.2005.102", "10.1145/381641.381653", "10.1162/153244301753344614", "10.1111/cgf.14034", "10.1111/cgf.13198", "10.1017/cbo9780511519857", "10.1007/s10462-016-9475-9", "10.1075/ssol.2.2.07bor", "10.1007/978-1-4614-3223-4\\_3", "10.1109/infvis.2003.1249025", "10.1007/978-94-007-6094-313", "10.1145/2858036.2858387", "10.1109/tvcg.2007.70528", "10.1109/tvcg.2017.2674958", "10.1147/sj.454.0801", "10.1109/tvcg.2013.119", "10.1145/3173574.3173711", "10.1016/j.erss.2017.06.034", "10.1109/visual.2019.8933695", "10.1007/s11665-016-2173-6", "10.1016/0377-0427(87)90125-7", "10.2307/3601125", "10.1016/b978-0-444-88738-2.50018-x", "10.1109/mcg.2006.70", "10.1109/tvcg.2018.2865145", "10.1017/s1351324997001502", "10.1109/tvcg.2010.179", "10.1214/aos/1176344552", "10.1109/mcg.2009.22", "10.1007/978-3-319-26633-6\\_13", "10.1080/10447318.2014.905422", "10.1016/j.visinf.2019.03.004", "10.1057/palgrave.ivs.9500074", "10.1007/978-1-4614-3223-4"], "wos": 1, "children": [], "len": 1}], "len": 5}], "len": 19}], "len": 355}, "index": 454, "embedding": [-1.9913235902786255, 4.21384334564209, -1.03950035572052, -2.4301393032073975, -0.2773471772670746, 0.16650904715061188, -0.7477038502693176, 1.7771539688110352, 6.095118522644043, 4.751896858215332, 1.9697364568710327, 4.165945529937744, 7.552440643310547, -0.8706381320953369, 8.357006072998047, 1.7449593544006348, 4.382840156555176, 0.06584581732749939, 3.853017807006836, 4.7379536628723145, -0.06630208343267441, 0.7720455527305603, 3.886624336242676, 7.581169128417969, -2.4589109420776367, 10.490607261657715, -0.4969606399536133, 3.5069832801818848, 2.199964761734009, 2.401966094970703, 3.8733885288238525, 4.387233734130859], "projection": [2.0586156845092773, 11.373382568359375], "size": 178, "height": 7, "width": 62}