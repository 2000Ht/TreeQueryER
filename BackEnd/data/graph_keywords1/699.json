{"data": {"doi": "10.1109/tvcg.2017.2744898", "title": "VIGOR: Interactive Visual Exploration of Graph Query Results", "year": "2017", "conferenceName": "VAST", "authors": "Robert Pienta;Fred Hohman;Alex Endert;Acar Tamersoy;Kevin A. Roundy;Christopher Gates 0002;Shamkant B. Navathe;Duen Horng Chau", "citationCount": "5", "affiliation": "Pienta, R (Corresponding Author), Georgia Tech, Atlanta, GA 30332 USA. Pienta, Robert; Hohman, Fred; Endert, Alex; Navathe, Shamkant; Chau, Duen Horng, Georgia Tech, Atlanta, GA 30332 USA. Tamersoy, Acar; Roundy, Kevin; Gates, Chris, Symantec Res Labs, Mountain View, CA USA.", "countries": "USA", "abstract": "Finding patterns in graphs has become a vital challenge in many domains from biological systems, network security, to finance (e.g., finding money laundering rings of bankers and business owners). While there is significant interest in graph databases and querying techniques, less research has focused on helping analysts make sense of underlying patterns within a group of subgraph results. Visualizing graph query results is challenging, requiring effective summarization of a large number of subgraphs, each having potentially shared node-values, rich node features, and flexible structure across queries. We present VIGOR, a novel interactive visual analytics system, for exploring and making sense of query results. VIGOR uses multiple coordinated views, leveraging different data representations and organizations to streamline analysts sensemaking process. VIGOR contributes: (1) an exemplar-based interaction technique, where an analyst starts with a specific result and relaxes constraints to find other similar results or starts with only the structure (i.e., without node value constraints), and adds constraints to narrow in on specific results; and (2) a novel feature-aware subgraph result summarization. Through a collaboration with Symantec, we demonstrate how VIGOR helps tackle real-world problems through the discovery of security blindspots in a cybersecurity dataset with over 11,000 incidents. We also evaluate VIGOR with a within-subjects study, demonstrating VIGOR's ease of use over a leading graph database management system, and its ability to help analysts understand their results at higher speed and make fewer errors.", "keywords": "graph querying,subgraph results,query result visualization", "link": "http://dx.doi.org/10.1109/TVCG.2017.2744898", "refList": ["10.1145/1322432.1322433", "10.1145/2702123.2702476", "10.1109/35021bigcomp.2015.7072812", "10.1145/2909132.2909246", "10.1111/j.1467-8659.2011.01898.x", "10.1006/jvlc.1997.0037", "10.1023/a:1009745219419", "10.1002/widm.30", "10.1109/bigdata.2014.7004278", "10.1109/52.329404", "10.1109/2945.841119", "10.1137/1.9781611973440.11", "10.1109/icde.2008.4497505", "10.1016/j.aml.2007.01.006", "10.1037/h0071325", "10.1093/bioinformatics/bti556", "10.2312/eurovisstar.20141174", "10.1109/tvcg.2015.2467717", "10.1109/tvcg.2015.2468078", "10.1145/2470654.2466444", "10.1002/qre.441", "10.1145/345513.345282", "10.1109/icdmw.2008.99", "10.1145/1242572.1242600", "10.1147/sj.164.0324", "10.1007/978-1-84996-074-8\\_4", "10.1002/spe.4380180302", "10.1073/pnas.0307545100", "10.1007/bf02289565", "10.1145/1541880.1541882", "10.1093/comjnl/9.1.60"], "wos": 1, "children": [{"doi": "10.1109/tvcg.2018.2865139", "title": "Structure-Based Suggestive Exploration: A New Approach for Effective Exploration of Large Networks", "year": "2018", "conferenceName": "InfoVis", "authors": "Wei Chen;Fangzhou Guo;Dongming Han;Jacheng Pan;Xiaotao Nie;Jiazhi Xia;Xiaolong Zhang", "citationCount": "5", "affiliation": "Chen, W (Corresponding Author), Zhejiang Univ, State Key Labo CAD \\& CG, Hangzhou, Zhejiang, Peoples R China. Chen, Wei; Guo, Fangzhou; Han, Dongming; Pan, Jacheng; Nie, Xiaotao, Zhejiang Univ, State Key Labo CAD \\& CG, Hangzhou, Zhejiang, Peoples R China. Xia, Jiazhi, Cent S Univ, Changsha, Hunan, Peoples R China. Zhang, Xiaolong, Penn State Univ, University Pk, PA 16802 USA.", "countries": "USA;China", "abstract": "When analyzing a visualized network, users need to explore different sections of the network to gain insight. However, effective exploration of large networks is often a challenge. While various tools are available for users to explore the global and local features of a network, these tools usually require significant interaction activities, such as repetitive navigation actions to follow network nodes and edges. In this paper, we propose a structure-based suggestive exploration approach to support effective exploration of large networks by suggesting appropriate structures upon user request. Encoding nodes with vectorized representations by transforming information of surrounding structures of nodes into a high dimensional space, our approach can identify similar structures within a large network, enable user interaction with multiple similar structures simultaneously, and guide the exploration of unexplored structures. We develop a web-based visual exploration system to incorporate this suggestive exploration approach and compare performances of our approach under different vectorizing methods and networks. We also present the usability and effectiveness of our approach through a controlled user study with two datasets.", "keywords": "Large Network Exploration,Structure-Based Exploration,Suggestive Exploration", "link": "http://dx.doi.org/10.1109/TVCG.2018.2865139", "refList": ["10.1109/tvcg.2007.70582", "10.1109/tvcg.2006.120", "10.1109/mc.2013.242", "10.1109/tvcg.2009.108", "10.1145/2939672.2939754", "10.1016/j.comnet.2011.08.019", "10.1145/2702123.2702476", "10.1109/tvcg.2017.2744938", "10.1007/s00371-013-0892-3", "10.1137/1.9781611974973.67", "10.1109/vast.2009.5333893", "10.1109/tst.2013.6509098", "10.1109/35021bigcomp.2015.7072812", "10.1145/2909132.2909246", "10.1111/j.1467-8659.2011.01957.x", "10.1111/j.1467-8659.2011.01898.x", "10.1177/1473871612455749", "10.1109/tvcg.2013.167", "10.1145/3097983.3098061", "10.1007/978-1-4613-0303-9\\_28", "10.1109/vast.2014.7042485", "10.1109/tmm.2016.2614220", "10.1145/1376616.1376675", "10.1145/2623330.2623732", "10.14778/1920841.1920887", "10.1109/tvcg.2017.2745219", "10.1109/tvcg.2017.2743858", "10.1109/tvcg.2008.151", "10.1145/1150402.1150479", "10.1093/bioinformatics/bth436", "10.1109/tvcg.2015.2468078", "10.1109/tvcg.2016.2598958", "10.1111/cgf.12883", "10.1145/1556262.1556300", "10.1109/icdm.2012.159", "10.1145/2470654.2466444", "10.1109/tvcg.2013.109", "10.1109/infvis.2004.1", "10.1109/icdmw.2008.99", "10.1002/aris.1440370106", "10.1007/978-3-319-05813-9\\_11", "10.1371/journal.pone.0098679", "10.1109/tvcg.2006.106", "10.1111/j.1467-8659.2011.01935.x", "10.1111/cgf.12397", "10.1111/cgf.13184", "10.1111/cgf.12642", "10.1109/tvcg.2016.2598831", "10.1109/tvcg.2017.2744898"], "wos": 1, "children": [{"doi": "10.1109/tvcg.2019.2934396", "title": "A Deep Generative Model for Graph Layout", "year": "2019", "conferenceName": "InfoVis", "authors": "Oh-Hyun Kwon;Kwan-Liu Ma", "citationCount": "4", "affiliation": "Kwon, OH (Corresponding Author), Univ Calif Davis, Davis, CA 95616 USA. Kwon, Oh-Hyun; Ma, Kwan-Liu, Univ Calif Davis, Davis, CA 95616 USA.", "countries": "USA", "abstract": "Different layouts can characterize different aspects of the same graph. Finding a \u201cgood\u201d layout of a graph is thus an important task for graph visualization. In practice, users often visualize a graph in multiple layouts by using different methods and varying parameter settings until they find a layout that best suits the purpose of the visualization. However, this trial-and-error process is often haphazard and time-consuming. To provide users with an intuitive way to navigate the layout design space, we present a technique to systematically visualize a graph in diverse layouts using deep generative models. We design an encoder-decoder architecture to learn a model from a collection of example layouts, where the encoder represents training examples in a latent space and the decoder produces layouts from the latent space. In particular, we train the model to construct a two-dimensional latent space for users to easily explore and generate various layouts. We demonstrate our approach through quantitative and qualitative evaluations of the generated layouts. The results of our evaluations show that our model is capable of learning and generalizing abstract concepts of graph layouts, not just memorizing the training examples. In summary, this paper presents a fundamentally new approach to graph visualization where a machine learning model learns to visualize a graph from examples without manually-defined heuristics.", "keywords": "Graph,network,visualization,layout,machine learning,deep learning,neural network,generative model,autoencoder", "link": "http://dx.doi.org/10.1109/TVCG.2019.2934396", "refList": ["10.1103/physreve.74.036104", "10.1145/234535.234538", "10.2307/2412323", "10.1109/tvcg.2007.70580", "10.7155/jgaa.00405", "10.1177/1473871612455749", "10.1109/tvcg.2011.185", "10.1073/pnas.122653799", "10.1007/3-540-58950-3", "10.1145/2897824.2925974", "10.1007/3-540-44541-2\\_17", "10.1007/bf00410640", "10.1021/acscentsci.7b00572", "10.1007/s10208-011-9093-5", "10.1109/tvcg.2015.2467451", "10.1016/0020-0190(89)90102-6", "10.3402/qhw.v6i2.5918", "10.1111/cgf.13187", "10.1214/aoms/1177729586", "10.1109/tvcg.2014.2346277", "10.1109/tvcg.2017.2743858", "10.1007/978-3-662-44043-8\\_3", "10.1038/30918", "10.1109/mcg.2018.2881501", "10.1016/j.camwa.2004.08.015", "10.1109/tvcg.2010.269", "10.1006/s1045-926x(02)00016-2", "10.1016/0925-7721(94)00014-x", "10.1145/2049662.2049670", "10.1145/2049662.2049663", "10.1103/physrevx.4.011047", "10.1371/journal.pone.0098679", "10.1145/2487788.2488173", "10.1007/978-3-030-01418-6\\_41", "10.1007/978-3-030-04414-5\\_12", "10.1109/tvcg.2018.2865139", "10.1142/s0219525903001067", "10.7155/jgaa.00051"], "wos": 1, "children": [{"doi": "10.1109/tvcg.2020.3030367", "title": "Lyra 2: Designing Interactive Visualizations by Demonstration", "year": "2020", "conferenceName": "InfoVis", "authors": "Jonathan Zong;Dhiraj Barnwal;Rupayan Neogy;Arvind Satyanarayan", "citationCount": "0", "affiliation": "Zong, J (Corresponding Author), MIT, Cambridge, MA 02139 USA. Zong, Jonathan; Neogy, Rupayan; Satyanarayan, Arvind, MIT, Cambridge, MA 02139 USA. Barnwal, Dhiraj, Indian Inst Technol Kharagpur, Kharagpur, W Bengal, India.", "countries": "India;USA", "abstract": "Recent graphical interfaces offer direct manipulation mechanisms for authoring visualizations, but are largely restricted to static output. To author interactive visualizations, users must instead turn to textual specification, but such approaches impose a higher technical burden. To bridge this gap, we introduce Lyra 2, a system that extends a prior visualization design environment with novel methods for authoring interaction techniques by demonstration. Users perform an interaction (e.g., button clicks, drags, or key presses) directly on the visualization they are editing. The system interprets this performance using a set of heuristics and enumerates suggestions of possible interaction designs. These heuristics account for the properties of the interaction (e.g., target and event type) as well as the visualization (e.g., mark and scale types, and multiple views). Interaction design suggestions are displayed as thumbnails; users can preview and test these suggestions, iteratively refine them through additional demonstrations, and finally apply and customize them via property inspectors. We evaluate our approach through a gallery of diverse examples, and evaluate its usability through a first-use study and via an analysis of its cognitive dimensions. We find that, in Lyra 2, interaction design by demonstration enables users to rapidly express a wide range of interactive visualizations.", "keywords": "Direct manipulation,interactive visualization,interaction design by demonstration", "link": "http://dx.doi.org/10.1109/TVCG.2020.3030367", "refList": ["10.1109/tvcg.2019.2934396", "10.1613/jair.301", "10.1016/j.automatica.2009.07.008", "10.1016/j.visinf.2018.12.001", "10.1016/j.neucom.2007.11.026", "10.1109/tvcg.2015.2392771", "10.1109/tvcg.2019.2934798", "10.1613/jair.3912", "10.1109/tvcg.2012.212", "10.1109/tvcg.2018.2816203", "10.1111/cgf.13193", "10.1109/21.87055", "10.1109/tvcg.2018.2864899", "10.1016/j.visinf.2017.11.002", "10.1007/s11432-018-9801-4", "10.1109/tvcg.2013.196", "10.1145/302979.303030", "10.1109/tvcg.2013.191", "10.1007/978-3-642-36955-1\\_16", "10.1109/vast.2017.8585487", "10.1109/cvpr.2016.90", "10.1038/nature14236", "10.1145/568522.568523", "10.1016/j.neunet.2014.09.003", "10.1016/j.visinf.2018.04.011", "10.1109/iccv.2019.00880", "10.1109/tvcg.2016.2598831"], "wos": 1, "children": [], "len": 1}, {"doi": "10.1109/tvcg.2020.3030467", "title": "PlotThread: Creating Expressive Storyline Visualizations using Reinforcement Learning", "year": "2020", "conferenceName": "InfoVis", "authors": "Tan Tang;Renzhong Li;Xinke Wu;Shuhan Liu;Johannes Knittel;Steffen Koch;Lingyun Yu;Peiran Ren;Thomas Ertl;Yingcai Wu", "citationCount": "1", "affiliation": "Wu, YC (Corresponding Author), Zhejiang Univ, Zhejiang Lab, Hangzhou, Peoples R China. Wu, YC (Corresponding Author), Zhejiang Univ, Stare Key Lab CAD\\&CG, Hangzhou, Peoples R China. Tang, Tan; Li, Renzhong; Wu, Xinke; Liu, Shuhan; Wu, Yingcai, Zhejiang Univ, Zhejiang Lab, Hangzhou, Peoples R China. Tang, Tan; Li, Renzhong; Wu, Xinke; Liu, Shuhan; Wu, Yingcai, Zhejiang Univ, Stare Key Lab CAD\\&CG, Hangzhou, Peoples R China. Knittel, Johannes; Koch, Steffen; Ertl, Thomas, Univ Stuttgart, VIS VISUS, Stuttgart, Germany. Yu, Lingyun, Xian Jiaotong Liverpool Univ, Dept Comp Sci \\& Software Engn, Suzhou, Peoples R China. Ren, Peiran, Alibaba Grp, Hangzhou, Peoples R China.", "countries": "Germany;China", "abstract": "Storyline visualizations are an effective means to present the evolution of plots and reveal the scenic interactions among characters. However, the design of storyline visualizations is a difficult task as users need to balance between aesthetic goals and narrative constraints. Despite that the optimization-based methods have been improved significantly in terms of producing aesthetic and legible layouts, the existing (semi-) automatic methods are still limited regarding 1) efficient exploration of the storyline design space and 2) flexible customization of storyline layouts. In this work, we propose a reinforcement learning framework to train an AI agent that assists users in exploring the design space efficiently and generating well-optimized storylines. Based on the framework, we introduce PlotThread, an authoring tool that integrates a set of flexible interactions to support easy customization of storyline visualizations. To seamlessly integrate the AI agent into the authoring process, we employ a mixed-initiative approach where both the agent and designers work on the same canvas to boost the collaborative design of storylines. We evaluate the reinforcement learning model through qualitative and quantitative experiments and demonstrate the usage of PlotThread using a collection of use cases.", "keywords": "Storyline visualization,reinforcement learning,mixed-initiative design", "link": "http://dx.doi.org/10.1109/TVCG.2020.3030467", "refList": ["10.1109/tvcg.2019.2934396", "10.1613/jair.301", "10.1016/j.automatica.2009.07.008", "10.1016/j.visinf.2018.12.001", "10.1016/j.neucom.2007.11.026", "10.1109/tvcg.2015.2392771", "10.1109/tvcg.2019.2934798", "10.1613/jair.3912", "10.1109/tvcg.2012.212", "10.1109/tvcg.2018.2816203", "10.1111/cgf.13193", "10.1109/21.87055", "10.1109/tvcg.2018.2864899", "10.1016/j.visinf.2017.11.002", "10.1007/s11432-018-9801-4", "10.1109/tvcg.2013.196", "10.1145/302979.303030", "10.1109/tvcg.2013.191", "10.1007/978-3-642-36955-1\\_16", "10.1109/vast.2017.8585487", "10.1109/cvpr.2016.90", "10.1038/nature14236", "10.1145/568522.568523", "10.1016/j.neunet.2014.09.003", "10.1016/j.visinf.2018.04.011", "10.1109/iccv.2019.00880", "10.1109/tvcg.2016.2598831"], "wos": 1, "children": [], "len": 1}, {"doi": "10.1109/tvcg.2020.3030459", "title": "Scalability of Network Visualisation from a Cognitive Load Perspective", "year": "2020", "conferenceName": "InfoVis", "authors": "Vahan Yoghourdjian;Yalong Yang;Tim Dwyer;Lawrence Lee;Michael Wybrow;Kim Marriott", "citationCount": "0", "affiliation": "Yoghourdjian, V (Corresponding Author), Monash Univ, Fac Informat Technol, Dept Human Ctr Comp, Melbourne, Vic, Australia. Yoghourdjian, Vahan; Yang, Yalong; Dwyer, Tim; Wybrow, Michael; Marriott, Kim, Monash Univ, Fac Informat Technol, Dept Human Ctr Comp, Melbourne, Vic, Australia. Lawrence, Lee, Monash Univ, Fac Business \\& Econ, Melbourne, Vic, Australia. Yang, Yalong, Harvard Univ, Sch Engn \\& Appl Sci, Cambridge, MA 02138 USA.", "countries": "USA;Australia", "abstract": "Node-link diagrams are widely used to visualise networks. However, even the best network layout algorithms ultimately result in \u2018hairball\u2019 visualisations when the graph reaches a certain degree of complexity, requiring simplification through aggregation or interaction (such as filtering) to remain usable. Until now, there has been little data to indicate at what level of complexity node-link diagrams become ineffective or how visual complexity affects cognitive load. To this end, we conducted a controlled study to understand workload limits for a task that requires a detailed understanding of the network topology-finding the shortest path between two nodes. We tested performance on graphs with 25 to 175 nodes with varying density. We collected performance measures (accuracy and response time), subjective feedback, and physiological measures (EEG, pupil dilation, and heart rate variability). To the best of our knowledge this is the first network visualisation study to include physiological measures. Our results show that people have significant difficulty finding the shortest path in high density node-link diagrams with more than 50 nodes and even low density graphs with more than 100 nodes. From our collected EEG data we observe functional differences in brain activity between hard and easy tasks. We found that cognitive load increased up to certain level of difficulty after which it decreased, likely because participants had given up. We also explored the effects of global network layout features such as size or number of crossings, and features of the shortest path such as length or straightness on task difficulty. We found that global features generally had a greater impact than those of the shortest path.", "keywords": "Data Visualisation,Network Visualisation,Cognitive Load,EEG", "link": "http://dx.doi.org/10.1109/TVCG.2020.3030459", "refList": ["10.1109/tvcg.2019.2934396", "10.1109/tvcg.2016.2598867", "10.1109/tvcg.2016.2570755", "10.1007/s00371-013-0892-3", "10.1007/b98835", "10.1109/isda.2014.7066252", "10.1109/tvcg.2015.2467251", "10.1177/1473871612455749", "10.1109/tvcg.2012.299", "10.1007/3-540-58950-3", "10.1111/cgf.12878", "10.1109/mcse.2007.55", "10.1109/tvcg.2012.238", "10.1145/264645.264657", "10.1109/tvcg.2015.2467451", "10.1109/tvcg.2013.151", "10.1016/0020-0190(89)90102-6", "10.1109/tvcg.2019.2934307", "10.1109/tvcg.2015.2468151", "10.1109/tvcg.2017.2745919", "10.3402/qhw.v6i2.5918", "10.1111/cgf.13440", "10.1109/tvcg.2011.220", "10.1111/cgf.13187", "10.1109/t-c.1969.222678", "10.1109/tvcg.2017.2743858", "10.1126/science.290.5500.2319", "10.1109/cahpc.2018.8645912", "10.1109/tvcg.2015.2465151", "10.1109/tvcg.2016.2598958", "10.1109/tvcg.2017.2751473", "10.1002/spe.4380211102", "10.1109/tpds.2018.2869805", "10.1016/j.jpdc.2019.04.008", "10.1109/pacificvis.2017.8031574", "10.1006/s1045-926x(02)00016-2", "10.1109/tvcg.2017.2674999", "10.1145/2872427.2883041", "10.1145/3292500.3330989", "10.1109/tvcg.2017.2744878", "10.1145/2049662.2049670", "10.1145/2049662.2049663", "10.1109/sbac-pad.2018.00060", "10.1007/978-3-662-45803-7\\_27", "10.1109/pacificvis.2011.5742389", "10.1371/journal.pone.0098679", "10.1111/j.1469-1809.1936.tb02137.x", "10.1007/bf02289565", "10.1109/tvcg.2017.2689016", "10.1007/3-540-63938-1\\_"], "wos": 1, "children": [], "len": 1}, {"doi": "10.1109/tvcg.2020.3030471", "title": "Visual Analysis of Discrimination in Machine Learning", "year": "2020", "conferenceName": "InfoVis", "authors": "Qianwen Wang;Zhenhua Xu;Zhutian Chen;Yong Wang;Shixia Liu;Huamin Qu", "citationCount": "0", "affiliation": "Wang, QW (Corresponding Author), Hong Kong Univ Sci \\& Technol, Hong Kong, Peoples R China. Wang, Qianwen; Xu, Zhenhua; Chen, Zhutian; Wang, Yong; Qu, Huamin, Hong Kong Univ Sci \\& Technol, Hong Kong, Peoples R China. Liu, Shixia, Tsinghua Univ, Beijing, Peoples R China.", "countries": "China", "abstract": "The growing use of automated decision-making in critical applications, such as crime prediction and college admission, has raised questions about fairness in machine learning. How can we decide whether different treatments are reasonable or discriminatory? In this paper, we investigate discrimination in machine learning from a visual analytics perspective and propose an interactive visualization tool, DiscriLens, to support a more comprehensive analysis. To reveal detailed information on algorithmic discrimination, DiscriLens identifies a collection of potentially discriminatory itemsets based on causal modeling and classification rules mining. By combining an extended Euler diagram with a matrix-based visualization, we develop a novel set visualization to facilitate the exploration and interpretation of discriminatory itemsets. A user study shows that users can interpret the visually encoded information in DiscriLens quickly and accurately. Use cases demonstrate that DiscriLens provides informative guidance in understanding and reducing algorithmic discrimination.", "keywords": "Machine Learning,Discrimination,Data Visualization", "link": "http://dx.doi.org/10.1109/TVCG.2020.3030471", "refList": ["10.1109/tvcg.2019.2934396", "10.2312/eurovisstar.20141170", "10.1145/3357384.3357910", "10.1111/cgf.12791", "10.1109/tvcg.2018.2861397", "10.1111/j.1467-8659.2011.01898.x", "10.1145/2702123.2702237", "10.1109/tvcg.2019.2934798", "10.1109/mcg.2017.21", "10.1109/tvcg.2019.2934300", "10.1109/tvcg.2017.2745085", "10.1109/tvcg.2018.2859997", "10.1145/3173574.3174237", "10.1109/tvcg.2018.2865126", "10.1145/1718487.1718520", "10.1109/tvcg.2017.2743858", "10.1109/pacificvis.2015.7156392", "10.1109/tvcg.2018.2864477", "10.1145/324133.324140", "10.1137/140976649", "10.1145/3219819.3220088", "10.1109/tvcg.2019.2934805", "10.1145/1134271.1134277", "10.1137/090772745", "10.1016/j.jelectrocard.2010.09.003", "10.1109/tvcg.2012.253", "10.1145/2556612", "10.1109/tvcg.2013.173", "10.1109/tvcg.2019.2934619", "10.1109/tvcg.2017.2745078"], "wos": 1, "children": [], "len": 1}, {"doi": "10.1109/pacificvis48177.2020.4722", "year": "2020", "title": "A Study of Mental Maps in Immersive Network Visualization", "conferenceName": "PacificVis", "authors": "Joseph Kotlarek;Oh{-}Hyun Kwon;Kwan{-}Liu Ma;Peter Eades;Andreas Kerren;Karsten Klein;Falk Schreiber", "citationCount": "0", "affiliation": "Kotlarek, J (Corresponding Author), Univ Calif Davis, Davis, CA 95616 USA.\nKotlarek, Joseph; Kwon, Oh-Hyun; Ma, Kwan-Liu, Univ Calif Davis, Davis, CA 95616 USA.\nEades, Peter, Univ Sydney, Sydney, NSW, Australia.\nKerren, Andreas, Linnaeus Univ, Vaxjo, Sweden.\nKlein, Karsten; Schreiber, Falk, Univ Konstanz, Constance, Germany.", "countries": "Sweden;Germany;USA;Australia", "abstract": "The visualization of a network influences the quality of the mental map that the viewer develops to understand the network. In this study, we investigate the effects of a 3D immersive visualization environment compared to a traditional 2D desktop environment on the comprehension of a network's structure. We compare the two visualization environments using three tasks-interpreting network structure, memorizing a set of nodes, and identifying the structural changes-commonly used for evaluating the quality of a mental map in network visualization. The results show that participants were able to interpret network structure more accurately when viewing the network in an immersive environment, particularly for larger networks. However, we found that 2D visualizations performed better than immersive visualization for tasks that required spatial memory.", "keywords": "Human-centered computing; Visualization; Visualization techniques; Graph drawings; Human-centered computing; Visualization; Empirical studies in visualization", "link": "https://doi.org/10.1109/PacificVis48177.2020.4722", "refList": ["10.1103/physreve.74.036104", "10.1109/tvcg.2019.2934396", "10.1007/978-3-540-87730-1\\_9", "10.1117/12.2005484", "10.1177/1473871612455749", "10.1109/pacificvis.2017.8031577", "10.1007/978-3-319-73207-7", "10.1109/38.888006", "10.1109/2945.841119", "10.1109/mc.2005.297", "10.1007/s10055-018-0346-3", "10.1109/tvcg.2016.2599107", "10.1109/icsmc.1992.271688", "10.1038/30918", "10.1006/jvlc.1995.1010", "10.1089/109493101300117938", "10.1109/vrais.1998.658488", "10.1109/pacificvis.2015.7156357", "10.1109/tvcg.2010.78", "10.1109/tvcg.2016.2520921", "10.1007/978-3-030-01388-22", "10.1145/229459.229467", "10.1145/1056808.1056875", "10.1109/tvcg.2017.2744079", "10.1109/bdva.2015.7314293", "10.1086/jar.33.4.3629752", "10.1016/j.ijhcs.2013.08.004"], "wos": 1, "children": [], "len": 1}], "len": 11}, {"doi": "10.1109/tvcg.2020.3030440", "title": "Context-aware Sampling of Large Networks via Graph Representation Learning", "year": "2020", "conferenceName": "InfoVis", "authors": "Zhiguang Zhou;Chen Shi;Xilong Shen;Lihong Cai;Haoxuan Wang;Yuhua Liu;Ying Zhao;Wei Chen", "citationCount": "0", "affiliation": "Zhao, Y (Corresponding Author), Cent South Univ, Changsha, Peoples R China. Chen, W (Corresponding Author), Zhejiang Univ, State Key Lab CAD \\& CG, Hangzhou, Peoples R China. Zhou, Zhiguang; Shi, Chen; Shen, Xilong; Cai, Lihong; Wang, Haoxuan; Liu, Yuhua, Zhejiang Univ Finance \\& Econ, Sch Informat, Hangzhou, Peoples R China. Zhao, Ying, Cent South Univ, Changsha, Peoples R China. Chen, Wei, Zhejiang Univ, State Key Lab CAD \\& CG, Hangzhou, Peoples R China.", "countries": "China", "abstract": "Numerous sampling strategies have been proposed to simplify large-scale networks for highly readable visualizations. It is of great challenge to preserve contextual structures formed by nodes and edges with tight relationships in a sampled graph, because they are easily overlooked during the process of sampling due to their irregular distribution and immunity to scale. In this paper, a new graph sampling method is proposed oriented to the preservation of contextual structures. We first utilize a graph representation learning (GRL) model to transform nodes into vectors so that the contextual structures in a network can be effectively extracted and organized. Then, we propose a multi-objective blue noise sampling model to select a subset of nodes in the vectorized space to preserve contextual structures with the retention of relative data and cluster densities in addition to those features of significance, such as bridging nodes and graph connections. We also design a set of visual interfaces enabling users to interactively conduct context-aware sampling, visually compare results with various sampling strategies, and deeply explore large networks. Case studies and quantitative comparisons based on real-world datasets have demonstrated the effectiveness of our method in the abstraction and exploration of large networks.", "keywords": "Graph sampling,Graph representation learning,Blue noise sampling,Graph evaluation", "link": "http://dx.doi.org/10.1109/TVCG.2020.3030440", "refList": ["10.1145/2491159.2491168", "10.1016/j.physa.2015.04.035", "10.1145/1830252.1830274", "10.1109/icdmw.2007.91", "10.1002/net.21834", "10.1109/tvcg.2018.2864503", "10.1016/j.cag.2018.01.010", "10.1109/icc.2016.7511156", "10.1111/cgf.13444", "10.1145/956750.956831", "10.1145/364099.364331", "10.1007/s00180-016-0663-5", "10.1109/tvcg.2013.223", "10.1007/s12650-018-0530-2", "10.1103/physreve.73.016102", "10.1109/access.2018.2870684", "10.1007/978-3-319-06793-3\\_1", "10.2312/vissym/eurovis05/239-246", "10.1016/j.ins.2015.02.014", "10.1145/2339530.2339723", "10.1109/icde.2015.7113345", "10.1109/tvcg.2011.233", "10.14778/2809974.2809980", "10.1109/glocom.2015.7417471", "10.1145/2578153.2578175", "10.1214/aoms/1177705148", "10.1109/tvcg.2008.130", "10.14232/actacyb.20.1.2011.6", "10.1504/ijitm.2019.099809", "10.1109/tvcg.2018.2865020", "10.1145/956750", "10.1002/cpe.4330060203", "10.1145/1150402.1150479", "10.1103/physreve.72.036118", "10.1109/tvcg.2017.2744098", "10.1145/2020408.2020512", "10.1142/s0129183114400075", "10.1109/jsac.2011.111005", "10.1016/j.camwa.2011.11.057", "10.1145/2470654.2466444", "10.1109/tvcg.2017.2674999", "10.1214/aos/1013203451", "10.1109/icdcsw.2011.34", "10.1016/j.physa.2013.11.015", "10.1145/1081870.1081893", "10.1109/tnet.2008.2001730", "10.1109/access.2016.2633485", "10.1145/1879141.1879192", "10.1371/journal.pone.0098679", "10.1126/science.220.4598.671", "10.1109/pacificvis.2015.7156355", "10.1088/1475-7516/2011/08/011", "10.1007/978-3-319-27261-0\\_41", "10.1111/cgf.13410", "10.1109/tvcg.2018.2865139", "10.1109/tvcg.2016.2598831", "10.1016/j.physa.2014.06.065"], "wos": 1, "children": [], "len": 1}, {"doi": "10.1109/tvcg.2020.3030447", "title": "DRGraph: An Efficient Graph Layout Algorithm for Large-scale Graphs by Dimensionality Reduction", "year": "2020", "conferenceName": "InfoVis", "authors": "Minfeng Zhu;Wei Chen;Yuanzhe Hu;Yuxuan Hou;Liangjun Liu;Kaiyuan Zhang", "citationCount": "0", "affiliation": "Chen, W (Corresponding Author), Zhejiang Univ, State Key Lab CAD\\&CG, Hangzhou, Peoples R China. Zhu, Minfeng; Chen, Wei; Hu, Yuanzhe; Hou, Yuxuan; Liu, Liangjun; Zhang, Kaiyuan, Zhejiang Univ, State Key Lab CAD\\&CG, Hangzhou, Peoples R China.", "countries": "China", "abstract": "Efficient layout of large-scale graphs remains a challenging problem: the force-directed and dimensionality reduction-based methods suffer from high overhead for graph distance and gradient computation. In this paper, we present a new graph layout algorithm, called DRGraph, that enhances the nonlinear dimensionality reduction process with three schemes: approximating graph distances by means of a sparse distance matrix, estimating the gradient by using the negative sampling technique, and accelerating the optimization process through a multi-level layout scheme. DRGraph achieves a linear complexity for the computation and memory consumption, and scales up to large-scale graphs with millions of nodes. Experimental results and comparisons with state-of-the-art graph layout methods demonstrate that DRGraph can generate visually comparable layouts with a faster running time and a lower memory requirement.", "keywords": "graph visualization,graph layout,dimensionality reduction,force-directed layout", "link": "http://dx.doi.org/10.1109/TVCG.2020.3030447", "refList": ["10.1109/tvcg.2007.70582", "10.1371/journal.pone.0136497", "10.1109/tvcg.2016.2598867", "10.1145/234535.234538", "10.1145/3018661.3018731", "10.1109/34.491619", "10.1145/2939672.2939754", "10.1145/3269206.3271788", "10.1016/j.comnet.2011.08.019", "10.1007/s11263-011-0442-2", "10.1016/s0020-0190(98)00108-2", "10.1109/tvcg.2018.2865151", "10.1007/978-3-319-61188-4\\_2", "10.1177/1473871612455749", "10.1177/1473871616666394", "10.1109/tvcg.2015.2467035", "10.1186/1471-2105-10-375", "10.1145/3097983.3098061", "10.1109/tvcg.2018.2864911", "10.1145/3025453.3025628", "10.1109/tvcg.2015.2467451", "10.1109/2945.841119", "10.1016/j.swevo.2015.10.002", "10.1016/0020-0190(89)90102-6", "10.1109/infvis.2003.1249009", "10.1109/tvcg.2017.2745919", "10.1111/cgf.13187", "10.1111/cgf.13440", "10.1109/tvcg.2012.245", "10.1109/tvcg.2017.2743858", "10.1177/1473871618821740", "10.1186/s12859-015-0585-1", "10.1002/nav.3800020109", "10.1145/263407.263521", "10.1002/spe.4380211102", "10.1006/s1045-926x(02)00016-2", "10.1109/cvpr.2012.6247667", "10.1023/b:jogo.0000042115.44455.f3", "10.1109/pacificvis.2017.8031607", "10.1002/nav.3800030404", "10.1109/cvpr.2008.4587500", "10.1109/pacificvis.2011.5742389", "10.1371/journal.pone.0098679", "10.1090/s0002-9904-1920-03322-7", "10.1109/iv.2013.3", "10.1145/568522.568523", "10.1109/tvcg.2006.156", "10.1109/tvcg.2012.236", "10.1109/tvcg.2018.2865139", "10.1145/3219819.3220025", "10.1007/3-540-63938-1\\_"], "wos": 1, "children": [], "len": 1}, {"doi": "10.1109/tvcg.2020.3030393", "title": "Exemplar-based Layout Fine-tuning for Node-link Diagrams", "year": "2020", "conferenceName": "InfoVis", "authors": "Jiacheng Pan;Wei Chen;Xiaodong Zhao;Shuyue Zhou;Wei Zeng;Minfeng Zhu;Jian Chen;Siwei Fu;Yingcai Wu", "citationCount": "1", "affiliation": "Chen, W; Wu, YC (Corresponding Author), Zhejiang Univ, State Key Lab CAD\\&CG, Hangzhou, Peoples R China. Wu, YC (Corresponding Author), Zhejiang Lab, Hangzhou, Peoples R China. Pan, Jiacheng; Chen, Wei; Zhao, Xiaodong; Zhou, Shuyue; Zhu, Minfeng; Wu, Yingcai, Zhejiang Univ, State Key Lab CAD\\&CG, Hangzhou, Peoples R China. Fu, Siwei; Wu, Yingcai, Zhejiang Lab, Hangzhou, Peoples R China. Zeng, Wei, Chinese Acad Sci, Shenzhen Inst Adv Technol, Shenzhen, Peoples R China. Chen, Jian, Ohio State Univ, Columbus, OH 43210 USA.", "countries": "USA;China", "abstract": "We design and evaluate a novel layout fine-tuning technique for node-link diagrams that facilitates exemplar-based adjustment of a group of substructures in batching mode. The key idea is to transfer user modifications on a local substructure to other substructures in the entire graph that are topologically similar to the exemplar. We first precompute a canonical representation for each substructure with node embedding techniques and then use it for on-the-fly substructure retrieval. We design and develop a light-weight interactive system to enable intuitive adjustment, modification transfer, and visual graph exploration. We also report some results of quantitative comparisons, three case studies, and a within-participant user study.", "keywords": "Node-link diagram,graph layout,graph visualization,user interactions", "link": "http://dx.doi.org/10.1109/TVCG.2020.3030393", "refList": ["10.1109/tvcg.2007.70582", "10.1371/journal.pone.0136497", "10.1109/tvcg.2016.2598867", "10.1145/234535.234538", "10.1145/3018661.3018731", "10.1109/34.491619", "10.1145/2939672.2939754", "10.1145/3269206.3271788", "10.1016/j.comnet.2011.08.019", "10.1007/s11263-011-0442-2", "10.1016/s0020-0190(98)00108-2", "10.1109/tvcg.2018.2865151", "10.1177/1473871612455749", "10.1177/1473871616666394", "10.1109/tvcg.2015.2467035", "10.1186/1471-2105-10-375", "10.1145/3097983.3098061", "10.1109/tvcg.2018.2864911", "10.1145/3025453.3025628", "10.1109/tvcg.2015.2467451", "10.1016/j.swevo.2015.10.002", "10.1016/0020-0190(89)90102-6", "10.1109/infvis.2003.1249009", "10.1109/tvcg.2017.2745919", "10.1111/cgf.13187", "10.1111/cgf.13440", "10.1109/tvcg.2012.245", "10.1109/tvcg.2017.2743858", "10.1177/1473871618821740", "10.1186/s12859-015-0585-1", "10.1002/nav.3800020109", "10.1145/263407.263521", "10.1002/spe.4380211102", "10.1006/s1045-926x(02)00016-2", "10.1109/cvpr.2012.6247667", "10.1023/b:jogo.0000042115.44455.f3", "10.1109/pacificvis.2017.8031607", "10.1002/nav.3800030404", "10.1109/infvis.2004.1", "10.1109/cvpr.2008.4587500", "10.1109/pacificvis.2011.5742389", "10.1140/epjb/e2011-10979-2", "10.1371/journal.pone.0098679", "10.1090/s0002-9904-1920-03322-7", "10.1109/iv.2013.3", "10.1145/568522.568523", "10.1109/tvcg.2006.156", "10.1109/tvcg.2012.236", "10.1109/tvcg.2018.2865139", "10.1145/3219819.3220025", "10.1007/3-540-63938-1\\_"], "wos": 1, "children": [], "len": 1}], "len": 19}, {"doi": "10.1109/tvcg.2018.2865149", "title": "Juniper: A Tree+Table Approach to Multivariate Graph Visualization", "year": "2018", "conferenceName": "InfoVis", "authors": "Carolina Nobre;Marc Streit;Alexander Lex", "citationCount": "7", "affiliation": "Nobre, C (Corresponding Author), Univ Utah, Salt Lake City, UT 84112 USA. Nobre, Carolina; Lex, Alexander, Univ Utah, Salt Lake City, UT 84112 USA. Streit, Marc, Johannes Kepler Univ Linz, Linz, Austria.", "countries": "USA;Austria", "abstract": "Analyzing large, multivariate graphs is an important problem in many domains, yet such graphs are challenging to visualize. In this paper, we introduce a novel, scalable, tree-table multivariate graph visualization technique, which makes many tasks related to multivariate graph analysis easier to achieve. The core principle we follow is to selectively query for nodes or subgraphs of interest and visualize these subgraphs as a spanning tree of the graph. The tree is laid out linearly, which enables us to juxtapose the nodes with a table visualization where diverse attributes can be shown. We also use this table as an adjacency matrix, so that the resulting technique is a hybrid node-link/adjacency matrix technique. We implement this concept in Juniper and complement it with a set of interaction techniques that enable analysts to dynamically grow, restructure, and aggregate the tree, as well as change the layout or show paths between nodes. We demonstrate the utility of our tool in usage scenarios for different multivariate networks: a bipartite network of scholars, papers, and citation metrics and a multitype network of story characters, places, books, etc.", "keywords": "Multivariate graphs,networks,tree-based graph visualization,adjacency matrix,spanning trees,visualization", "link": "http://dx.doi.org/10.1109/TVCG.2018.2865149", "refList": ["10.1109/tvcg.2007.70582", "10.1109/infvis.2000.885091", "10.1109/tvcg.2016.2615308", "10.1109/tvcg.2008.117", "10.1109/tvcg.2009.108", "10.1109/pacificvis.2013.6596127", "10.1111/j.1467-8659.2011.01898.x", "10.1109/visual.1991.175815", "10.1093/bioinformatics/btp454", "10.1093/bioinformatics/btq675", "10.1109/tvcg.2011.247", "10.1111/j.1467-8659.2012.03110.x", "10.1145/2207676.2208293", "10.1056/nejmsa066082", "10.1109/infvis.2003.1249009", "10.1038/nmeth.1436", "10.1073/pnas.95.25.14863", "10.1109/cw.2002.1180907", "10.1109/tvcg.2014.2346248", "10.1111/j.1467-8659.2009.01710.x", "10.1109/tvcg.2006.147", "10.1109/tvcg.2015.2468078", "10.1093/bioinformatics/btx324", "10.1111/cgf.12883", "10.1145/1168149.1168168", "10.1109/pacificvis.2010.5429609", "10.1093/bioinformatics/btn068", "10.1109/tvcg.2006.106", "10.2307/2685881", "10.1057/palgrave.ivs.9500092", "10.1109/tvcg.2016.2598885", "10.1111/j.1467-8659.2009.01687.x", "10.1109/tvcg.2018.2811488", "10.1145/22339.22342", "10.1111/cgf.13184", "10.1111/cgf.12642", "10.1109/biovis.2012.6378600", "10.1109/tvcg.2017.2744898"], "wos": 1, "children": [{"doi": "10.1109/tvcg.2019.2934670", "title": "AirVis: Visual Analytics of Air Pollution Propagation", "year": "2019", "conferenceName": "VAST", "authors": "Zikun Deng;Di Weng;Jiahui Chen;Ren Liu;Zhibin Wang;Jie Bao 0003;Yu Zheng 0004;Yingcai Wu", "citationCount": "6", "affiliation": "Wu, YC (Corresponding Author), Zhejiang Univ, State Key Lab CAD \\& CG, Hangzhou, Peoples R China. Deng, Zikun; Weng, Di; Chen, Jiahui; Liu, Ren; Wu, Yingcai, Zhejiang Univ, State Key Lab CAD \\& CG, Hangzhou, Peoples R China. Wang, Zhibin, Zhejiang Univ, Res Ctr Air Pollut \\& Hlth, Hangzhou, Peoples R China. Bao, Jie; Zheng, Yu, JD Intelligent City Res, Beijing, Peoples R China.", "countries": "China", "abstract": "Air pollution has become a serious public health problem for many cities around the world. To find the causes of air pollution, the propagation processes of air pollutants must be studied at a large spatial scale. However, the complex and dynamic wind fields lead to highly uncertain pollutant transportation. The state-of-the-art data mining approaches cannot fully support the extensive analysis of such uncertain spatiotemporal propagation processes across multiple districts without the integration of domain knowledge. The limitation of these automated approaches motivates us to design and develop AirVis, a novel visual analytics system that assists domain experts in efficiently capturing and interpreting the uncertain propagation patterns of air pollution based on graph visualizations. Designing such a system poses three challenges: a) the extraction of propagation patterns; b) the scalability of pattern presentations; and c) the analysis of propagation processes. To address these challenges, we develop a novel pattern mining framework to model pollutant transportation and extract frequent propagation patterns efficiently from large-scale atmospheric data. Furthermore, we organize the extracted patterns hierarchically based on the minimum description length (MDL) principle and empower expert users to explore and analyze these patterns effectively on the basis of pattern topologies. We demonstrated the effectiveness of our approach through two case studies conducted with a real-world dataset and positive feedback from domain experts.", "keywords": "Air pollution propagation,pattern mining,graph visualization", "link": "http://dx.doi.org/10.1109/TVCG.2019.2934670", "refList": ["10.1109/tvcg.2016.2598919", "10.1093/bib/bbr069", "10.1145/2487575.2488188", "10.1109/tvcg.2013.193", "10.1016/j.atmosenv.2014.12.011", "10.1109/tvcg.2013.226", "10.1109/tvcg.2018.2864503", "10.1109/tvcg.2015.2468111", "10.1109/icicta.2015.183", "10.1016/j.atmosenv.2014.05.039", "10.1111/cgf.12791", "10.1111/j.1467-8659.2009.01451.x", "10.1111/j.1467-8659.2011.01898.x", "10.5194/acp-12-5031-2012", "10.1016/j.atmosenv.2008.05.053", "10.1109/tvcg.2016.2535234", "10.1016/j.atmosres.2014.12.003", "10.1109/tvcg.2015.2467194", "10.1109/tvcg.2013.263", "10.1109/icdm.2002.1184038", "10.1145/2783258.2788573", "10.1109/tvcg.2018.2865149", "10.1109/tbdata.2017.2723899", "10.1109/tvcg.2012.311", "10.1109/vl.1996.545307", "10.1007/s12650-018-0481-7", "10.1016/j.envpol.2007.06.012", "10.3155/1047-3289.61.6.660", "10.1080/13658810701349037", "10.1145/3097983.3098090", "10.1109/tvcg.2007.70523", "10.1115/1.2128636", "10.1109/tvcg.2015.2467619", "10.3978/j.issn.2072-1439.2016.01.19", "10.1109/tkde.2005.127", "10.1017/s0269888912000331", "10.2312/conf/eg2013/stars/039-063", "10.1109/tvcg.2014.2346271", "10.1175/bams-d-14-00110.1", "10.1016/0005-1098(78)90005-5", "10.1007/s10618-006-0044-8", "10.1109/tvcg.2018.2865126", "10.2307/1912791", "10.3390/su6085322", "10.1007/s12650-018-0489-z", "10.2312/eurovisstar.20151109", "10.1109/tvcg.2011.181", "10.1126/science.298.5594.824", "10.1162/jmlr.2003.3.4-5.951", "10.1109/asonam.2014.6921638", "10.1111/j.1467-8659.2008.01213.x", "10.1038/s41598-017-18107-1", "10.1109/tvcg.2018.2865041", "10.1109/tits.2019.2901117", "10.1038/srep20668", "10.1109/tvcg.2012.265", "10.1109/tpami.2016.2608884", "10.1109/tvcg.2012.213", "10.1145/1376616.1376661", "10.1007/s00521-019-04567-1", "10.1109/tvcg.2017.2745083", "10.1126/science.243.4892.745", "10.1109/tvcg.2018.2864826", "10.1109/tnn.2003.820440", "10.1109/tvcg.2016.2598885", "10.1145/3219819.3219822", "10.1073/pnas.1502596112", "10.1016/j.envsoft.2009.01.004", "10.1002/pmic.200700095", "10.1145/2254556.2254651", "10.1109/tvcg.2016.2598432", "10.1109/tvcg.2011.202"], "wos": 1, "children": [{"doi": "10.1109/tvcg.2020.3028958", "title": "Auditing the Sensitivity of Graph-based Ranking with Visual Analytics", "year": "2020", "conferenceName": "VAST", "authors": "Tiankai Xie;Yuxin Ma;Hanghang Tong;My T. Thai;Ross Maciejewski", "citationCount": "0", "affiliation": "Xie, TK (Corresponding Author), Arizona State Univ, Tempe, AZ 85287 USA. Xie, Tiankai; Ma, Yuxin; Maciejewski, Ross, Arizona State Univ, Tempe, AZ 85287 USA. Tong, Hanghang, Univ Illinois, Urbana, IL USA. Thai, My T., Univ Florida, Gainesville, FL 32611 USA.", "countries": "USA", "abstract": "Graph mining plays a pivotal role across a number of disciplines, and a variety of algorithms have been developed to answer who/what type questions. For example, what items shall we recommend to a given user on an e-commerce platform? The answers to such questions are typically returned in the form of a ranked list, and graph-based ranking methods are widely used in industrial information retrieval settings. However, these ranking algorithms have a variety of sensitivities, and even small changes in rank can lead to vast reductions in product sales and page hits. As such, there is a need for tools and methods that can help model developers and analysts explore the sensitivities of graph ranking algorithms with respect to perturbations within the graph structure. In this paper, we present a visual analytics framework for explaining and exploring the sensitivity of any graph-based ranking algorithm by performing perturbation-based what-if analysis. We demonstrate our framework through three case studies inspecting the sensitivity of two classic graph-based ranking algorithms (PageRank and HITS) as applied to rankings in political news media and social networks.", "keywords": "Graph-based ranking,sensitivity analysis,visual analytics", "link": "http://dx.doi.org/10.1109/TVCG.2020.3028958", "refList": ["10.1109/wsc.2017.8247800", "10.1023/a:1022649401552", "10.1515/1559-0410.11416", "10.1109/tvcg.2016.2598919", "10.1177/1473871611416549", "10.1109/tvcg.2019.2934630", "10.1140/epjds29", "10.1109/tvcg.2019.2934670", "10.1016/j.eswa.2015.09.004", "10.1145/2702123.2702509", "10.1016/j.visinf.2018.12.001", "10.2307/3002000", "10.1109/tvcg.2019.2934399", "10.1007/s41060-016-0032-z", "10.1111/cgf.13198", "10.14778/2350229.2350254", "10.1145/2939672.2939764", "10.1016/j.visinf.2017.01.006", "10.1145/2858036.2858529", "10.1109/vast.2017.8585647", "10.1007/bf01187020", "10.1109/icdm.2015.26", "10.1145/2362383.2362387", "10.1177/0049124104268644", "10.1109/vast.2011.6102442", "10.1109/infvis.2003.1249025", "10.1109/tvcg.2018.2864475", "10.1109/tvcg.2007.70528", "10.1109/tvcg.2015.2467691", "10.1111/cgf.13210", "10.1214/aos/1176344136", "10.1109/tvcg.2015.2424872", "10.1016/j.visinf.2018.09.001", "10.1177/089443939100900106", "10.1109/tvcg.2015.2467931", "10.1162/neco.1997.9.8.1735", "10.1007/s11162-011-9241-4", "10.1111/cgf.13680", "10.1145/3065386", "10.1109/tvcg.2018.2864889", "10.1177/003804070808100402", "10.1109/icdm.2010.62", "10.1038/s41598-020-59669-x", "10.1162/153244303321897717", "10.1109/tvcg.2019.2934619", "10.1007/bf00356088", "10.1109/tvcg.2016.2598432", "10.1109/tvcg.2016.2598831"], "wos": 1, "children": [], "len": 1}, {"doi": "10.1109/tvcg.2020.3030410", "title": "Revisiting the Modifiable Areal Unit Problem in Deep Traffic Prediction with Visual Analytics", "year": "2020", "conferenceName": "VAST", "authors": "Wei Zeng 0002;Chengqiao Lin;Juncong Lin;Jincheng Jiang;Jiazhi Xia;Cagatay Turkay;Wei Chen", "citationCount": "0", "affiliation": "Lin, JC (Corresponding Author), Xiamen Univ, Xiamen, Peoples R China. Zeng, Wei; Jiang, Jincheng, Chinese Acad Sci, Shenzhen Inst Adv Technol, Shenzhen, Peoples R China. Lin, Chengqiao; Lin, Juncong, Xiamen Univ, Xiamen, Peoples R China. Xia, Jiazhi, Cent South Univ, Changsha, Peoples R China. Turkay, Cagatay, Univ Warwick, Coventry, W Midlands, England. Chen, Wei, Zhejiang Univ, State Key Lab CAD \\& CG, Hangzhou, Zhejiang, Peoples R China.", "countries": "China;England", "abstract": "Deep learning methods are being increasingly used for urban traffic prediction where spatiotemporal traffic data is aggregated into sequentially organized matrices that are then fed into convolution-based residual neural networks. However, the widely known modifiable areal unit problem within such aggregation processes can lead to perturbations in the network inputs. This issue can significantly destabilize the feature embeddings and the predictions - rendering deep networks much less useful for the experts. This paper approaches this challenge by leveraging unit visualization techniques that enable the investigation of many-to-many relationships between dynamically varied multi-scalar aggregations of urban traffic data and neural network predictions. Through regular exchanges with a domain expert, we design and develop a visual analytics solution that integrates 1) a Bivariate Map equipped with an advanced bivariate colormap to simultaneously depict input traffic and prediction errors across space, 2) a Moran's I Scatterplot that provides local indicators of spatial association analysis, and 3) a Multi-scale Attribution View that arranges non-linear dot plots in a tree layout to promote model analysis and comparison across scales. We evaluate our approach through a series of case studies involving a real-world dataset of Shenzhen taxi trips, and through interviews with domain experts. We observe that geographical scale variations have important impact on prediction performances, and interactive visual exploration of dynamically varying inputs and outputs benefit experts in the development of deep traffic prediction models.", "keywords": "MAUP,traffic prediction,deep learning,model diagnostic,visual analytics", "link": "http://dx.doi.org/10.1109/TVCG.2020.3030410", "refList": ["10.1038/srep26377", "10.1109/mcg.2011.88", "10.1080/13658816.2015.1119279", "10.1109/tvcg.2013.226", "10.1109/pacificvis.2011.5742387", "10.1038/s41467-017-01882-w", "10.1109/tvcg.2019.2934670", "10.1111/j.1467-8659.2009.01440.x", "10.1111/cgf.13712", "10.1016/j.compenvurbsys.2008.09.006", "10.1109/pacificvis.2014.50", "10.1109/tvcg.2018.2816219", "10.1109/tvcg.2016.2535234", "10.1109/tvcg.2014.2346893", "10.3390/ijgi8080344", "10.1109/tvcg.2013.246", "10.1007/s10940-005-9003-6", "10.1016/j.compenvurbsys.2008.05.001", "10.1007/s10661-019-7831-3", "10.1111/j.1538-4632.2007.00699.x", "10.1016/j.aap.2016.08.015", "10.1080/13658816.2018.1541177", "10.1109/pacificvis.2012.6183572", "10.1109/tvcg.2011.181", "10.1137/090759069", "10.1109/pacificvis.2011.5742390", "10.1214/10-aos799", "10.1109/tits.2017.2683539", "10.1109/tits.2015.2436897", "10.3390/ijerph16071150", "10.1109/tvcg.2009.145", "10.1109/tvcg.2012.265", "10.1080/10106049.2017.1404140", "10.3390/ijgi8020063", "10.3390/info6020134", "10.1080/13658816.2014.955027", "10.1109/tits.2016.2639320", "10.2307/143141", "10.1109/tvcg.2016.2598432"], "wos": 1, "children": [], "len": 1}, {"doi": "10.1109/tvcg.2020.3030370", "title": "TaxThemis: Interactive Mining and Exploration of Suspicious Tax Evasion Groups", "year": "2020", "conferenceName": "VAST", "authors": "Yating Lin;Kamkwai Wong;Yong Wang;Rong Zhang;Bo Dong;Huamin Qu;Qinghua Zheng", "citationCount": "0", "affiliation": "Lin, YT (Corresponding Author), Xi An Jiao Tong Univ, MOEKLINNS Lab, Xian, Shaanxi, Peoples R China. Lin, Yating; Zheng, Qinghua, Xi An Jiao Tong Univ, MOEKLINNS Lab, Xian, Shaanxi, Peoples R China. Wong, Kamkwai; Wang, Yong; Zhang, Rong; Qu, Huamin, Hong Kong Univ Sci \\& Technol, Hong Kong, Peoples R China. Dong, Bo, Xi An Jiao Tong Univ, Natl Engn Lab Big Data Analyt, Xian, Shaanxi, Peoples R China.", "countries": "China", "abstract": "Tax evasion is a serious economic problem for many countries, as it can undermine the government's tax system and lead to an unfair business competition environment. Recent research has applied data analytics techniques to analyze and detect tax evasion behaviors of individual taxpayers. However, they have failed to support the analysis and exploration of the related party transaction tax evasion (RPTTE) behaviors (e.g., transfer pricing), where a group of taxpayers is involved. In this paper, we present TaxThemis, an interactive visual analytics system to help tax officers mine and explore suspicious tax evasion groups through analyzing heterogeneous tax-related data. A taxpayer network is constructed and fused with the respective trade network to detect suspicious RPTTE groups. Rich visualizations are designed to facilitate the exploration and investigation of suspicious transactions between related taxpayers with profit and topological data analysis. Specifically, we propose a calendar heatmap with a carefully-designed encoding scheme to intuitively show the evidence of transferring revenue through related party transactions. We demonstrate the usefulness and effectiveness of TaxThemis through two case studies on real-world tax-related data and interviews with domain experts.", "keywords": "Visual Analytics,Tax Network,Tax Evasion Detection,Anomaly detection,Multidimensional data", "link": "http://dx.doi.org/10.1109/TVCG.2020.3030370", "refList": ["10.1111/cgf.12886", "10.2307/2277827", "10.1109/tvcg.2010.44", "10.1109/tits.2014.2315794", "10.1109/tvcg.2019.2934670", "10.1038/s41467-019-08987-4", "10.1111/cgf.12920", "10.1109/vast.2017.8585721", "10.1080/15230406.2015.1093431", "10.1109/tvcg.2018.2843369", "10.1038/srep01001", "10.1109/tvcg.2017.2744018", "10.1109/tvcg.2017.2744159", "10.1068/b130199p", "10.1109/tvcg.2009.143", "10.1016/j.visinf.2017.01.006", "10.1109/tvcg.2019.2892483", "10.1109/pacificvis.2017.8031583", "10.1109/pacificvis48177.2020.2785", "10.2307/2686111", "10.1109/tvcg.2015.2467199", "10.1111/cgf.12114", "10.1109/tvcg.2018.2865126", "10.1111/j.1538-4632.1996.tb00936.x", "10.1109/tvcg.2019.2934619", "10.2307/2332142", "10.1007/978-3-319-10590-1\\_53", "10.1109/cvpr.2016.485", "10.1109/cvpr.2017.17", "10.2307/2986645", "10.1109/tvcg.2014.2346321", "10.1017/s0140525x16001837", "10.1109/tvcg.2016.2598541", "10.1371/journal.pone.0207377", "10.1109/tvcg.2014.2346265", "10.1007/s4095-020-0191-7", "10.3141/1644-14", "10.1109/tvcg.2017.2744158", "10.1109/cvpr.2016.90", "10.1109/tvcg.2018.2865027", "10.1109/tvcg.2017.2785807", "10.1109/tvcg.2017.2744358", "10.1111/j.1538-4632.1995.tb00338.x", "10.1080/03081068808717359", "10.1109/tvcg.2016.2598831"], "wos": 1, "children": [], "len": 1}, {"doi": "10.1109/tvcg.2020.3030469", "title": "Topology Density Map for Urban Data Visualization and Analysis", "year": "2020", "conferenceName": "VAST", "authors": "Zezheng Feng;Haotian Li;Wei Zeng 0004;Shuang-Hua Yang;Huamin Qu", "citationCount": "0", "affiliation": "Zeng, W (Corresponding Author), Chinese Acad Sci, Shenzhen Inst Adv Technol, Shenzhen, Peoples R China. Feng, Zezheng; Li, Haotian; Qu, Huamin, Hong Kong Univ Sci \\& Technol, Hong Kong, Peoples R China. Zeng, Wei, Chinese Acad Sci, Shenzhen Inst Adv Technol, Shenzhen, Peoples R China. Yang, Shuang-Hua, Southern Univ Sci \\& Technol, Shenzhen, Peoples R China.", "countries": "China", "abstract": "Density map is an effective visualization technique for depicting the scalar field distribution in 2D space. Conventional methods for constructing density maps are mainly based on Euclidean distance, limiting their applicability in urban analysis that shall consider road network and urban traffic. In this work, we propose a new method named Topology Density Map, targeting for accurate and intuitive density maps in the context of urban environment. Based on the various constraints of road connections and traffic conditions, the method first constructs a directed acyclic graph (DAG) that propagates nonlinear scalar fields along 1D road networks. Next, the method extends the scalar fields to a 2D space by identifying key intersecting points in the DAG and calculating the scalar fields for every point, yielding a weighted Voronoi diagram like effect of space division. Two case studies demonstrate that the Topology Density Map supplies accurate information to users and provides an intuitive visualization for decision making. An interview with domain experts demonstrates the feasibility, usability, and effectiveness of our method.", "keywords": "Density map,network topology,urban data", "link": "http://dx.doi.org/10.1109/TVCG.2020.3030469", "refList": ["10.1109/vast.2009.5332584", "10.1109/tvcg.2013.193", "10.1080/03081060.2013.844903", "10.1109/tvcg.2018.2864503", "10.1145/2702123.2702419", "10.1109/tvcg.2019.2934670", "10.1109/tits.2015.2496783", "10.1177/1473871615581216", "10.3141/1617-02", "10.1145/2024156.2024169", "10.1111/cgf.13712", "10.1016/j.ejor.2007.02.005", "10.1109/tvcg.2014.2346893", "10.1007/11871842\\_29", "10.1109/vast.2010.5652478", "10.1016/j.visinf.2019.10.002", "10.1109/tvcg.2016.2616404", "10.1109/vl.1996.545307", "10.1145/2629592", "10.1155/2018/2696037", "10.1061/(asce)0733-947x(1998)124:4(368", "10.3141/1899-21", "10.1023/a:1026123329433", "10.1109/mcg.2010.79", "10.1057/palgrave.ivs.9500174", "10.1109/tcyb.2019.2963681", "10.1109/tvcg.2015.2467554", "10.1111/cgf.12114", "10.1145/2814575", "10.1016/j.jcps.2014.08.002", "10.1109/2945.981847", "10.1080/03052150210909", "10.1109/tciaig.2012.2186810", "10.1109/tits.2017.2683539", "10.1109/iv.2004.1320137", "10.1016/0377-2217(80)90126-5", "10.1109/tvcg.2016.2640960", "10.1109/tvcg.2015.2467196", "10.1145/3097983.3098056", "10.1007/s11432-018-9801-4", "10.1109/vast.2014.7042490", "10.1061/(asce)0733-947x(2006)132:2(122", "10.1016/j.tra.2008.03.011", "10.1109/tits.2014.2298892", "10.1016/j.trb.2005.12.003", "10.1007/bf01840357", "10.1109/vast.2011.6102454", "10.1109/tvcg.2013.145", "10.1007/bf02289588", "10.1109/pacificvis.2014.56", "10.1109/mcg.2018.053491730", "10.1109/tvcg.2009.111", "10.1057/palgrave.ivs.9500184", "10.1109/tvcg.2013.173", "10.1109/tvcg.2016.2598432", "10.1007/978-0-85729-079-3"], "wos": 1, "children": [], "len": 1}], "len": 9}, {"doi": "10.1109/vast47406.2019.8986909", "title": "Origraph: Interactive Network Wrangling", "year": "2019", "conferenceName": "VAST", "authors": "Alex Bigelow;Carolina Nobre;Miriah D. Meyer;Alexander Lex", "citationCount": "2", "affiliation": "Bigelow, A (Corresponding Author), Univ Utah, Salt Lake City, UT 84112 USA. Bigelow, Alex; Nobre, Carolina; Meyer, Miriah; Lex, Alexander, Univ Utah, Salt Lake City, UT 84112 USA.", "countries": "USA", "abstract": "Networks are a natural way of thinking about many datasets. The data on which a network is based, however, is rarely collected in a form that suits the analysis process, making it necessary to create and reshape networks. Data wrangling is widely acknowledged to be a critical part of the data analysis pipeline, yet interactive network wrangling has received little attention in the visualization research community. In this paper, we discuss a set of operations that are important for wrangling network datasets and introduce a visual data wrangling tool, Origraph, that enables analysts to apply these operations to their datasets. Key operations include creating a network from source data such as tables, reshaping a network by introducing new node or edge classes, filtering nodes or edges, and deriving new node or edge attributes. Our tool, Origraph, enables analysts to execute these operations with little to no programming, and to immediately visualize the results. Origraph provides views to investigate the network model, a sample of the network, and node and edge attributes. In addition, we introduce interfaces designed to aid analysts in specifying arguments for sensible network wrangling operations. We demonstrate the usefulness of Origraph in two Use Cases: first, we investigate gender bias in the film industry, and then the influence of money on the political support for the war in Yemen.", "keywords": "Graph visualization,Data abstraction,Data wrangling,Human-centered computing [Information visualization],[Human-centered computing]: Visualization systems and tools,Information systems [Graph-based database models]", "link": "http://dx.doi.org/10.1109/VAST47406.2019.8986909", "refList": ["10.1101/gr.1239303", "10.1145/1054972.1055032", "10.1016/b978-0-12-382229-1.00002-3", "10.1109/tvcg.2017.2744843", "10.1109/tvcg.2013.154", "10.1007/978-1-4614-7163-9315-1", "10.1073/pnas.1607151113", "10.18637/jss.v040.i01", "10.1145/1124772.1124891", "10.1177/1473871611415994", "10.1109/tvcg.2018.2865149", "10.1145/2598153.2598175", "10.1177/1473871613488591", "10.1109/tvcg.2018.2859973", "10.1186/1471-2105-14-s19-s3", "10.1056/nejmsa066082", "10.1007/978-3-642-36763-2\\_48", "10.1016/j.socscimed.2016.01.049", "10.1111/j.1467-8659.2008.01231.x", "10.1002/cne.24084", "10.2138/am-2017-6104ccbyncnd", "10.1109/tvcg.2014.2346248", "10.1111/j.1467-8659.2009.01710.x", "10.1007/978-3-642-03658-3\\_47", "10.1007/978-3-319-06793-3\\_5", "10.3390/genes9110519", "10.1145/3290605.3300356", "10.1111/cgf.12883", "10.1177/1473871612462152", "10.1016/j.jelectrocard.2010.09.003", "10.1111/cgf.13610", "10.1109/vast.2010.5652520", "10.1111/evo.13318", "10.1109/tvcg.2018.2811488", "10.1109/tvcg.2009.111", "10.1111/cgf.13184", "10.1109/tvcg.2009.116", "10.1109/biovis.2012.6378600"], "wos": 1, "children": [{"doi": "10.1109/tvcg.2020.3030462", "title": "Table Scraps: An Actionable Framework for Multi-Table Data Wrangling From An Artifact Study of Computational Journalism", "year": "2020", "conferenceName": "InfoVis", "authors": "Stephen Kasica;Charles Berret;Tamara Munzner", "citationCount": "0", "affiliation": "Kasica, S (Corresponding Author), Univ British Columbia, Dept Comp Sci, Vancouver, BC, Canada. Kasica, Stephen; Munzner, Tamara, Univ British Columbia, Dept Comp Sci, Vancouver, BC, Canada. Berret, Charles, Univ British Columbia, Sch Journalism Writing \\& Media, Vancouver, BC, Canada.", "countries": "Canada", "abstract": "For the many journalists who use data and computation to report the news, data wrangling is an integral part of their work. Despite an abundance of literature on data wrangling in the context of enterprise data analysis, little is known about the specific operations, processes, and pain points journalists encounter while performing this tedious, time-consuming task. To better understand the needs of this user group, we conduct a technical observation study of 50 public repositories of data and analysis code authored by 33 professional journalists at 26 news organizations. We develop two detailed and cross-cutting taxonomies of data wrangling in computational journalism, for actions and for processes. We observe the extensive use of multiple tables, a notable gap in previous wrangling analyses. We develop a concise, actionable framework for general multi-table data wrangling that includes wrangling operations documented in our taxonomy that are without clear parallels in other work. This framework, the first to incorporate tables as first-class objects, will support future interactive wrangling tools for both computational journalism and general-purpose use. We assess the generative and descriptive power of our framework through discussion of its relationship to our set of taxonomies.", "keywords": "Computational journalism,Data journalism,Data wrangling", "link": "http://dx.doi.org/10.1109/TVCG.2020.3030462", "refList": ["10.1145/1378773.1378792", "10.1109/tvcg.2012.219", "10.1109/vast47406.2019.8986909", "10.1145/1084805.1084812", "10.1007/s00778-008-0098-x", "10.1016/j.websem.2008.09.005", "10.18637/jss.v040.i01", "10.1145/989863.989865", "10.1109/tvcg.2015.2467551", "10.5281/zenodo.3509134", "10.1109/tvcg.2019.2934539", "10.1109/tvcg.2019.2934593", "10.1109/tse.2018.2796554", "10.17349/jmc117309", "10.1109/2945.981851", "10.1109/vast.2011.6102440", "10.1177/1473871611415994", "10.1145/2001269.2001288"], "wos": 1, "children": [], "len": 1}], "len": 3}, {"doi": "10.1109/tvcg.2019.2934285", "title": "Visualizing a Moving Target: A Design Study on Task Parallel Programs in the Presence of Evolving Data and Concerns", "year": "2019", "conferenceName": "InfoVis", "authors": "Katy Williams;Alex Bigelow;Katherine E. Isaacs", "citationCount": "5", "affiliation": "Williams, K (Corresponding Author), Univ Arizona, Tucson, AZ 85721 USA. Williams, Katy; Bigelow, Alex; Isaacs, Kate, Univ Arizona, Tucson, AZ 85721 USA.", "countries": "USA", "abstract": "Common pitfalls in visualization projects include lack of data availability and the domain users' needs and focus changing too rapidly for the design process to complete. While it is often prudent to avoid such projects, we argue it can be beneficial to engage them in some cases as the visualization process can help refine data collection, solving a \u201cchicken and egg\u201d problem of having the data and tools to analyze it. We found this to be the case in the domain of task parallel computing where such data and tooling is an open area of research. Despite these hurdles, we conducted a design study. Through a tightly-coupled iterative design process, we built Atria, a multi-view execution graph visualization to support performance analysis. Atria simplifies the initial representation of the execution graph by aggregating nodes as related to their line of code. We deployed Atria on multiple platforms, some requiring design alteration. We describe how we adapted the design study methodology to the \u201cmoving target\u201d of both the data and the domain experts' concerns and how this movement kept both the visualization and programming project healthy. We reflect on our process and discuss what factors allow the project to be successful in the presence of changing data and user needs.", "keywords": "design studies,software visualization,parallel computing,graph visualization", "link": "http://dx.doi.org/10.1109/TVCG.2019.2934285", "refList": ["10.1007/978-3-642-31476-6\\_7", "10.1109/tvcg.2018.2859974", "10.1145/3337821.3337915", "10.1109/tse.1981.234519", "10.1109/32.221135", "10.1111/cgf.13433", "10.1109/tvcg.2011.185", "10.1109/tvcg.2018.2865076", "10.1109/tvcg.2018.2865149", "10.1109/tvcg.2014.2346323", "10.3233/978-1-61499-649-1-87", "10.1145/2993901.2993911", "10.1109/mcg.2011.103", "10.1002/1097-024x(200009)30:11", "10.1177/1094342006064482", "10.1057/palgrave.ivs.9500116", "10.1177/1473871615621602", "10.1109/tvcg.2013.124", "10.1109/infvis.2003.1249009", "10.1145/642611.642616", "10.1109/tvcg.2015.2467452", "10.1109/cw.2002.1180907", "10.1145/3125571.3125585", "10.1145/2807591.2807634", "10.1109/infvis.2002.1173148", "10.1145/2676870.2676883", "10.1145/1168149.1168168", "10.1007/978-3-030-17872-7\\_14", "10.1145/2993901.2993916", "10.1109/iotdi.2015.41", "10.1109/infvis.2004.1", "10.1080/14639220903165169", "10.1109/hpdc.2000.868632", "10.1145/882262.882291", "10.1109/mcse.2013.98", "10.1109/tvcg.2012.213", "10.1109/tvcg.2018.2811488", "10.1109/tvcg.2017.2744319", "10.1007/978-3-642-31476-67", "10.1109/mcg.2018.2874523", "10.1109/sc.2012.71"], "wos": 1, "children": [{"doi": "10.1109/tvcg.2020.3030355", "title": "Guidelines For Pursuing and Revealing Data Abstractions", "year": "2020", "conferenceName": "InfoVis", "authors": "Alex Bigelow;Katy Williams;Katherine E. Isaacs", "citationCount": "0", "affiliation": "Bigelow, A (Corresponding Author), Univ Arizona, Tucson, AZ 85721 USA. Bigelow, Alex; Williams, Katy; Isaacs, Katherine E., Univ Arizona, Tucson, AZ 85721 USA.", "countries": "USA", "abstract": "Many data abstraction types, such as networks or set relationships, remain unfamiliar to data workers beyond the visualization research community. We conduct a survey and series of interviews about how people describe their data, either directly or indirectly. We refer to the latter as latent data abstractions. We conduct a Grounded Theory analysis that (1) interprets the extent to which latent data abstractions exist, (2) reveals the far-reaching effects that the interventionist pursuit of such abstractions can have on data workers, (3) describes why and when data workers may resist such explorations, and (4) suggests how to take advantage of opportunities and mitigate risks through transparency about visualization research perspectives and agendas. We then use the themes and codes discovered in the Grounded Theory analysis to develop guidelines for data abstraction in visualization projects. To continue the discussion, we make our dataset open along with a visual interface for further exploration.", "keywords": "Data abstraction,Grounded theory,Survey design,Data wrangling", "link": "http://dx.doi.org/10.1109/TVCG.2020.3030355", "refList": ["10.1080/2159676x.2016.1251701", "10.1109/infvis.2000.885092", "10.1145/2702123.2702298", "10.4135/9781848607941.n14", "10.1007/978-1-4939", "10.1109/tvcg.2014.2346331", "10.1109/tvcg.2017.2744843", "10.1177/1473871613510429", "10.1007/978-1-4939-0378-8\\_2", "10.1145/2598153.2598175", "10.1109/tvcg.2019.2934285", "10.1177/1473871613488591", "10.1145/2501105.2501106", "10.1109/tvcg.2019.2934538", "10.1109/tvcg.2019.2934539", "10.1017/s1049096510990781", "10.1145/3025453.3025837", "10.1145/3290605.3300474", "10.1145/3290605.3300356", "10.1002/nur.1025", "10.1145/2993901.2993916", "10.1145/3392826", "10.1086/269268", "10.1109/tvcg.2018.2865241", "10.1145/2998181.2998331", "10.1145/291224.291229", "10.1057/ivs.2009.13", "10.1145/2047196.2047205", "10.1109/tvcg.2012.213", "10.1145/3274405", "10.1109/tvcg.2013.145", "10.1016/0040-6031(92)85160-w", "10.1109/iv.2013.45", "10.1109/tvcg.2009.111", "10.1109/mcg.2019.2914844", "10.1109/tvcg.2009.116"], "wos": 1, "children": [], "len": 1}], "len": 3}, {"doi": "10.1109/tvcg.2020.3029413", "title": "A Design Space of Vision Science Methods for Visualization Research", "year": "2020", "conferenceName": "InfoVis", "authors": "Madison A. Elliott;Christine Nothelfer;Cindy Xiong;Danielle Albers Szafir", "citationCount": "0", "affiliation": "Elliott, MA (Corresponding Author), Univ British Columbia, Vancouver, BC, Canada. Elliott, Madison A., Univ British Columbia, Vancouver, BC, Canada. Nothelfer, Christine, Northwestern Univ, Evanston, IL 60208 USA. Xiong, Cindy, Univ Massachusetts, Amherst, MA 01003 USA. Szafir, Danielle Albers, Univ Colorado, Boulder, CO 80309 USA.", "countries": "Canada;USA", "abstract": "A growing number of efforts aim to understand what people see when using a visualization. These efforts provide scientific grounding to complement design intuitions, leading to more effective visualization practice. However, published visualization research currently reflects a limited set of available methods for understanding how people process visualized data. Alternative methods from vision science offer a rich suite of tools for understanding visualizations, but no curated collection of these methods exists in either perception or visualization research. We introduce a design space of experimental methods for empirically investigating the perceptual processes involved with viewing data visualizations to ultimately inform visualization design guidelines. This paper provides a shared lexicon for facilitating experimental visualization research. We discuss popular experimental paradigms, adjustment types, response types, and dependent measures used in vision science research, rooting each in visualization examples. We then discuss the advantages and limitations of each technique. Researchers can use this design space to create innovative studies and progress scientific understanding of design choices and evaluations in visualization. We highlight a history of collaborative success between visualization and vision science research and advocate for a deeper relationship between the two fields that can elaborate on and extend the methodological design space for understanding visualization and vision.", "keywords": "Perception,human vision,empirical research,evaluation,HCI", "link": "http://dx.doi.org/10.1109/TVCG.2020.3029413", "refList": ["10.1109/tvcg.2019.2934790", "10.1177/146879410200200205", "10.2312/eurovisshort", "10.1109/tvcg.2015.2467811", "10.1111/j.1467-6486.2009.00859.x", "10.1177/1473871613510429", "10.1109/tvcg.2018.2864836", "10.1109/tvcg.2018.2865076", "10.1109/tvcg.2013.231", "10.1002/cphy.c100079", "10.1177/0886109909354981", "10.1109/tvcg.2018.2865149", "10.1080/1750984x.2017.1317357", "10.1007/978-3-7643-8472-2\\_6", "10.1093/bioinformatics/btq110", "10.1111/cgf.13728", "10.2307/1511837", "10.1109/tvcg.2019.2934539", "10.3233/efi-2004-22201", "10.1002/chp.1340180402", "10.1111/2041-210x.12034", "10.1111/j.2041-210x.2011.00169.x", "10.1109/tvcg.2015.2467452", "10.1002/chp", "10.1177/1077800410383121", "10.1177/1744987107081254", "10.1002/cpbi.96", "10.1109/tvcg.2018.2864526", "10.1109/beliv.2018.8634026", "10.2307/1511637", "10.1109/tvcg.2014.2346431", "10.1111/cgf.12883", "10.1109/tvcg.2019.2934281", "10.1145/2993901.2993916", "10.2307/3178066", "10.1145/2993901.2993913", "10.1145/1182475.1182476", "10.1016/j.destud.2004.06.002", "10.1177/1609406918763214", "10.2312/eurovisshort.20151137", "10.1145/882262.882291", "10.1177/174498710501000305", "10.1017/s1049096513001789", "10.1109/tvcg.2012.213", "10.1093/nar/gkz239", "10.1093/sysbio/sys062", "10.1109/tvcg.2019.2898186", "10.1109/tvcg.2018.2811488", "10.1007/s11135-006-9044-4", "10.1109/tvcg.2009.111", "10.1111/2041-210x.12066", "10.1109/mcg.2018.2874523", "10.1177/1609406920909938"], "wos": 1, "children": [], "len": 1}, {"doi": "10.1109/tvcg.2020.3030405", "title": "Insights From Experiments With Rigor in an EvoBio Design Study", "year": "2020", "conferenceName": "InfoVis", "authors": "Jennifer Rogers;Austin H. Patton;Luke Harmon;Alexander Lex;Miriah D. Meyer", "citationCount": "0", "affiliation": "Rogers, J (Corresponding Author), Univ Utah, Salt Lake City, UT 84112 USA. Rogers, Jen; Lex, Alexander; Meyer, Miriah, Univ Utah, Salt Lake City, UT 84112 USA. Patton, Austin H., Washington State Univ, Pullman, WA 99164 USA. Harmon, Luke, Univ Idaho, Moscow, ID 83843 USA.", "countries": "USA", "abstract": "Design study is an established approach of conducting problem-driven visualization research. The academic visualization community has produced a large body of work for reporting on design studies, informed by a handful of theoretical frameworks, and applied to a broad range of application areas. The result is an abundance of reported insights into visualization design, with an emphasis on novel visualization techniques and systems as the primary contribution of these studies. In recent work we proposed a new, interpretivist perspective on design study and six companion criteria for rigor that highlight the opportunities for researchers to contribute knowledge that extends beyond visualization idioms and software. In this work we conducted a year-long collaboration with evolutionary biologists to develop an interactive tool for visual exploration of multivariate datasets and phylogenetic trees. During this design study we experimented with methods to support three of the rigor criteria: ABUNDANT, REFLEXIVE, and TRANSPARENT. As a result we contribute two novel visualization techniques for the analysis of multivariate phylogenetic datasets, three methodological recommendations for conducting design studies drawn from reflections over our process of experimentation, and two writing devices for reporting interpretivist design study. We offer this work as an example for implementing the rigor criteria to produce a diverse range of knowledge contributions.", "keywords": "Methodologies,Application Motivated Visualization,Guidelines,Life Sciences Visualization,Health,Medicine,Biology,Bioinformatics,Genomics", "link": "http://dx.doi.org/10.1109/TVCG.2020.3030405", "refList": ["10.1109/tvcg.2019.2934790", "10.1177/146879410200200205", "10.2312/eurovisshort", "10.1109/tvcg.2015.2467811", "10.1111/j.1467-6486.2009.00859.x", "10.1177/1473871613510429", "10.1109/tvcg.2018.2864836", "10.1109/tvcg.2018.2865076", "10.1109/tvcg.2013.231", "10.1002/cphy.c100079", "10.1109/tvcg.2018.2865149", "10.1080/1750984x.2017.1317357", "10.1007/978-3-7643-8472-2\\_6", "10.1111/cgf.13728", "10.2307/1511837", "10.1109/tvcg.2019.2934539", "10.3233/efi-2004-22201", "10.1080/17493460802276893", "10.1002/chp.1340180402", "10.1111/2041-210x.12034", "10.1111/j.2041-210x.2011.00169.x", "10.1109/tvcg.2015.2467452", "10.1002/chp", "10.1177/1077800410383121", "10.1002/cpbi.96", "10.1109/tvcg.2018.2864526", "10.1109/beliv.2018.8634026", "10.2307/1511637", "10.1109/tvcg.2014.2346431", "10.1111/cgf.12883", "10.1109/tvcg.2019.2934281", "10.1145/2993901.2993916", "10.2307/3178066", "10.1145/2993901.2993913", "10.1145/1182475.1182476", "10.1016/j.destud.2004.06.002", "10.1177/1609406918763214", "10.2312/eurovisshort.20151137", "10.1145/882262.882291", "10.1109/tvcg.2012.213", "10.1109/tvcg.2019.2898186", "10.1109/tvcg.2018.2811488", "10.1007/s11135-006-9044-4", "10.1109/tvcg.2009.111", "10.1111/2041-210x.12066", "10.1109/mcg.2018.2874523", "10.1177/1609406920909938"], "wos": 1, "children": [], "len": 1}, {"doi": "10.1111/cgf.13728", "year": "2019", "title": "The State of the Art in Visualizing Multivariate Networks", "conferenceName": "EuroVis", "authors": "Carolina Nobre;Miriah D. Meyer;Marc Streit;Alexander Lex", "citationCount": "5", "affiliation": "Nobre, C (Corresponding Author), Univ Utah, Salt Lake City, UT 84112 USA.\nNobre, C.; Meyer, M.; Lex, A., Univ Utah, Salt Lake City, UT 84112 USA.\nStreit, M., Johannes Kepler Univ Linz, Linz, Austria.", "countries": "USA;Austria", "abstract": "Multivariate networks are made up of nodes and their relationships (links), but also data about those nodes and links as attributes. Most real-world networks are associated with several attributes, and many analysis tasks depend on analyzing both, relationships and attributes. Visualization of multivariate networks, however, is challenging, especially when both the topology of the network and the attributes need to be considered concurrently. In this state-of-the-art report, we analyze current practices and classify techniques along four axes: layouts, view operations, layout operations, and data operations. We also provide an analysis of tasks specific to multivariate networks and give recommendations for which technique to use in which scenario. Finally, we survey application areas and evaluation methodologies.", "keywords": "", "link": "https://doi.org/10.1111/cgf.13728", "refList": ["10.2312/eurovisstar.20151110", "10.1111/cgf.12106", "10.1109/iv.2016.19", "10.1111/j.1467-8659.2011.02087.x", "10.1111/j.1467-8659.2008.01214.x", "10.1109/tvcg.2014.2346893", "10.1145/1124772.1124891", "10.1109/vast.2014.7042484", "10.1109/tvcg.2018.2865149", "10.1080/10447318.2010.516722", "10.1109/icsmc.2011.6084125", "10.1109/mcg.2011.103", "10.1117/12.378894", "10.1145/2207676.2208293", "10.1109/tvcg.2009.122", "10.1111/cgf.12935", "10.1016/s0020-0255(02)00191-3", "10.1038/nmeth.1436", "10.1109/tvcg.2011.187", "10.1109/32.177365", "10.1007/978-3-642-03658-3\\_47", "10.1109/tvcg.2006.147", "10.1109/pacificvis.2011.5742390", "10.1145/2470654.2466444", "10.1109/tvcg.2006.166", "10.1145/2470654.2470724", "10.1109/tvcg.2014.2346441", "10.1109/vizsec.2005.1532070", "10.1101/gr.092759.109", "10.1111/cgf.13184", "10.1109/tvcg.2018.2865940", "10.1016/j.scico.2012.05.002", "10.1109/biovis.2012.6378600", "10.1111/cgf.13213", "10.1109/noms.2006.1687547", "10.1109/tvcg.2008.141", "10.1007/978-3-540-78243-8\\_13", "10.1145/1029208.1029217", "10.1145/345513.345271", "10.1109/tvcg.2015.2467811", "10.1109/visual.1991.175815", "10.1186/1471-2105-10-375", "10.1007/978-3-319-06793-3\\_1", "10.1186/1471-2105-13-275", "10.1109/tvcg.2010.79", "10.1109/tvcg.2011.217", "10.1186/1471-2105-14-s19-s3", "10.3389/fmicb.2017.00010", "10.1109/infvis.2003.1249009", "10.1111/cgf.13187", "10.1111/j.1467-8659.2008.01231.x", "10.1109/tvcg.2011.144", "10.1145/2556288.2557010", "10.1111/j.1467-8659.2009.01710.x", "10.1109/infvis.2004.46", "10.1109/iv.2009.97", "10.1109/tvcg.2008.34", "10.1109/infvis.2003.1249011", "10.1109/iv.2016.41", "10.1109/pacificvis.2010.5429609", "10.1109/tvcg.2006.160", "10.1109/tvcg.2010.205", "10.1109/38.486685", "10.1109/tvcg.2006.106", "10.1057/palgrave.ivs.9500092", "10.1145/568522.568523", "10.1111/j.1467-8659.2008.01221.x", "10.1109/iv.2010.15", "10.1145/22339.22342", "10.1109/csmr.2009.17", "10.1109/tvcg.2017.2744898", "10.1109/tvcg.2008.117", "10.1186/1752-0509-3-82", "10.1109/tvcg.2008.61", "10.1109/pacificvis.2013.6596127", "10.1109/tvcg.2007.70529", "10.1186/1471-2105-15-198", "10.1109/tvcg.2009.128", "10.2312/eurovisshort.20151124", "10.1093/bioinformatics/btq675", "10.1109/tvcg.2009.143", "10.1109/tvcg.2014.2346752", "10.1109/tvcg.2013.124", "10.1007/s00450-007-0036-y", "10.1093/bioinformatics/17.suppl\\_1.s22", "10.2312/eurovisstar.20151109", "10.1007/978-3-319-06793-3\\_5", "10.1109/vissof.2007.4290706", "10.1109/tvcg.2009.145", "10.1109/mcas.2003.1228503", "10.1109/infvis.2005.1532128", "10.1145/989863.989941", "10.1109/infvis.1999.801860", "10.1111/j.1467-8659.2009.01687.x", "10.1109/tvcg.2013.120", "10.1109/tvcg.2007.70582", "10.1109/tvcg.2009.167", "10.1109/pacificvis.2010.5429590", "10.1109/infvis.2000.885091", "10.1109/tvcg.2012.189", "10.1109/tvcg.2009.108", "10.1109/tvcg.2013.154", "10.1111/j.1467-8659.2011.01898.x", "10.1109/tvcg.2010.159", "10.1016/s0306-4573(98)00024-7", "10.1109/tvcg.2013.223", "10.1002/sam.10071", "10.2312/vissym/eurovis07/083-090", "10.1109/infvis.2002.1173156", "10.1186/1471-2105-7-109", "10.1177/1473871612455983", "10.1073/pnas.95.25.14863", "10.1007/978-3-319-06793-3\\_2", "10.1111/cgf.12883", "10.1007/978-3-540-78243-8\\_9", "10.1057/palgrave.ivs.9500180", "10.1109/pacificvis.2012.6183556", "10.1117/12.872578", "10.1145/1168149.1168169", "10.1109/iv.2013.3", "10.1109/tvcg.2011.186", "10.2307/2685881", "10.1109/pacificvis.2015.7156354", "10.1109/tvcg.2016.2598885", "10.1109/tvcg.2018.2811488", "10.1109/infvis.2005.1532129", "10.1111/j.1467-8659.2009.01450.x", "10.1057/palgrave.ivs.9500162", "10.1109/tvcg.2009.116", "10.1109/2945.468391"], "wos": 1, "children": [{"doi": "10.1109/tvcg.2020.3029413", "title": "A Design Space of Vision Science Methods for Visualization Research", "year": "2020", "conferenceName": "InfoVis", "authors": "Madison A. Elliott;Christine Nothelfer;Cindy Xiong;Danielle Albers Szafir", "citationCount": "0", "affiliation": "Elliott, MA (Corresponding Author), Univ British Columbia, Vancouver, BC, Canada. Elliott, Madison A., Univ British Columbia, Vancouver, BC, Canada. Nothelfer, Christine, Northwestern Univ, Evanston, IL 60208 USA. Xiong, Cindy, Univ Massachusetts, Amherst, MA 01003 USA. Szafir, Danielle Albers, Univ Colorado, Boulder, CO 80309 USA.", "countries": "Canada;USA", "abstract": "A growing number of efforts aim to understand what people see when using a visualization. These efforts provide scientific grounding to complement design intuitions, leading to more effective visualization practice. However, published visualization research currently reflects a limited set of available methods for understanding how people process visualized data. Alternative methods from vision science offer a rich suite of tools for understanding visualizations, but no curated collection of these methods exists in either perception or visualization research. We introduce a design space of experimental methods for empirically investigating the perceptual processes involved with viewing data visualizations to ultimately inform visualization design guidelines. This paper provides a shared lexicon for facilitating experimental visualization research. We discuss popular experimental paradigms, adjustment types, response types, and dependent measures used in vision science research, rooting each in visualization examples. We then discuss the advantages and limitations of each technique. Researchers can use this design space to create innovative studies and progress scientific understanding of design choices and evaluations in visualization. We highlight a history of collaborative success between visualization and vision science research and advocate for a deeper relationship between the two fields that can elaborate on and extend the methodological design space for understanding visualization and vision.", "keywords": "Perception,human vision,empirical research,evaluation,HCI", "link": "http://dx.doi.org/10.1109/TVCG.2020.3029413", "refList": ["10.1109/tvcg.2019.2934790", "10.1177/146879410200200205", "10.2312/eurovisshort", "10.1109/tvcg.2015.2467811", "10.1111/j.1467-6486.2009.00859.x", "10.1177/1473871613510429", "10.1109/tvcg.2018.2864836", "10.1109/tvcg.2018.2865076", "10.1109/tvcg.2013.231", "10.1002/cphy.c100079", "10.1177/0886109909354981", "10.1109/tvcg.2018.2865149", "10.1080/1750984x.2017.1317357", "10.1007/978-3-7643-8472-2\\_6", "10.1093/bioinformatics/btq110", "10.1111/cgf.13728", "10.2307/1511837", "10.1109/tvcg.2019.2934539", "10.3233/efi-2004-22201", "10.1002/chp.1340180402", "10.1111/2041-210x.12034", "10.1111/j.2041-210x.2011.00169.x", "10.1109/tvcg.2015.2467452", "10.1002/chp", "10.1177/1077800410383121", "10.1177/1744987107081254", "10.1002/cpbi.96", "10.1109/tvcg.2018.2864526", "10.1109/beliv.2018.8634026", "10.2307/1511637", "10.1109/tvcg.2014.2346431", "10.1111/cgf.12883", "10.1109/tvcg.2019.2934281", "10.1145/2993901.2993916", "10.2307/3178066", "10.1145/2993901.2993913", "10.1145/1182475.1182476", "10.1016/j.destud.2004.06.002", "10.1177/1609406918763214", "10.2312/eurovisshort.20151137", "10.1145/882262.882291", "10.1177/174498710501000305", "10.1017/s1049096513001789", "10.1109/tvcg.2012.213", "10.1093/nar/gkz239", "10.1093/sysbio/sys062", "10.1109/tvcg.2019.2898186", "10.1109/tvcg.2018.2811488", "10.1007/s11135-006-9044-4", "10.1109/tvcg.2009.111", "10.1111/2041-210x.12066", "10.1109/mcg.2018.2874523", "10.1177/1609406920909938"], "wos": 1, "children": [], "len": 1}, {"doi": "10.1109/tvcg.2020.3030405", "title": "Insights From Experiments With Rigor in an EvoBio Design Study", "year": "2020", "conferenceName": "InfoVis", "authors": "Jennifer Rogers;Austin H. Patton;Luke Harmon;Alexander Lex;Miriah D. Meyer", "citationCount": "0", "affiliation": "Rogers, J (Corresponding Author), Univ Utah, Salt Lake City, UT 84112 USA. Rogers, Jen; Lex, Alexander; Meyer, Miriah, Univ Utah, Salt Lake City, UT 84112 USA. Patton, Austin H., Washington State Univ, Pullman, WA 99164 USA. Harmon, Luke, Univ Idaho, Moscow, ID 83843 USA.", "countries": "USA", "abstract": "Design study is an established approach of conducting problem-driven visualization research. The academic visualization community has produced a large body of work for reporting on design studies, informed by a handful of theoretical frameworks, and applied to a broad range of application areas. The result is an abundance of reported insights into visualization design, with an emphasis on novel visualization techniques and systems as the primary contribution of these studies. In recent work we proposed a new, interpretivist perspective on design study and six companion criteria for rigor that highlight the opportunities for researchers to contribute knowledge that extends beyond visualization idioms and software. In this work we conducted a year-long collaboration with evolutionary biologists to develop an interactive tool for visual exploration of multivariate datasets and phylogenetic trees. During this design study we experimented with methods to support three of the rigor criteria: ABUNDANT, REFLEXIVE, and TRANSPARENT. As a result we contribute two novel visualization techniques for the analysis of multivariate phylogenetic datasets, three methodological recommendations for conducting design studies drawn from reflections over our process of experimentation, and two writing devices for reporting interpretivist design study. We offer this work as an example for implementing the rigor criteria to produce a diverse range of knowledge contributions.", "keywords": "Methodologies,Application Motivated Visualization,Guidelines,Life Sciences Visualization,Health,Medicine,Biology,Bioinformatics,Genomics", "link": "http://dx.doi.org/10.1109/TVCG.2020.3030405", "refList": ["10.1109/tvcg.2019.2934790", "10.1177/146879410200200205", "10.2312/eurovisshort", "10.1109/tvcg.2015.2467811", "10.1111/j.1467-6486.2009.00859.x", "10.1177/1473871613510429", "10.1109/tvcg.2018.2864836", "10.1109/tvcg.2018.2865076", "10.1109/tvcg.2013.231", "10.1002/cphy.c100079", "10.1109/tvcg.2018.2865149", "10.1080/1750984x.2017.1317357", "10.1007/978-3-7643-8472-2\\_6", "10.1111/cgf.13728", "10.2307/1511837", "10.1109/tvcg.2019.2934539", "10.3233/efi-2004-22201", "10.1080/17493460802276893", "10.1002/chp.1340180402", "10.1111/2041-210x.12034", "10.1111/j.2041-210x.2011.00169.x", "10.1109/tvcg.2015.2467452", "10.1002/chp", "10.1177/1077800410383121", "10.1002/cpbi.96", "10.1109/tvcg.2018.2864526", "10.1109/beliv.2018.8634026", "10.2307/1511637", "10.1109/tvcg.2014.2346431", "10.1111/cgf.12883", "10.1109/tvcg.2019.2934281", "10.1145/2993901.2993916", "10.2307/3178066", "10.1145/2993901.2993913", "10.1145/1182475.1182476", "10.1016/j.destud.2004.06.002", "10.1177/1609406918763214", "10.2312/eurovisshort.20151137", "10.1145/882262.882291", "10.1109/tvcg.2012.213", "10.1109/tvcg.2019.2898186", "10.1109/tvcg.2018.2811488", "10.1007/s11135-006-9044-4", "10.1109/tvcg.2009.111", "10.1111/2041-210x.12066", "10.1109/mcg.2018.2874523", "10.1177/1609406920909938"], "wos": 1, "children": [], "len": 1}, {"doi": "10.1111/cgf.13963", "year": "2020", "title": "MotionGlyphs: Visual Abstraction of Spatio-Temporal Networks in Collective Animal Behavior", "conferenceName": "EuroVis", "authors": "Eren Cakmak;Hanna Sch{\\\"{a}}fer;Juri Buchm{\\\"{u}}ller;Johannes Fuchs;Tobias Schreck;A. Jordan;Daniel A. Keim", "citationCount": "0", "affiliation": "Cakmak, E (Corresponding Author), Univ Konstanz, Constance, Germany.\nCakmak, E (Corresponding Author), Ctr Adv Study Collect Behav, Constance, Germany.\nCakmak, E.; Schaefer, H.; Buchmueller, J.; Fuchs, J.; Jordan, A.; Keim, D., Univ Konstanz, Constance, Germany.\nCakmak, E.; Jordan, A.; Keim, D., Ctr Adv Study Collect Behav, Constance, Germany.\nSchreck, T., Graz Univ Technol, Graz, Austria.\nJordan, A., Max Planck Inst Anim Behav, Radolfzell am Bodensee, Germany.", "countries": "Germany;Austria", "abstract": "Domain experts for collective animal behavior analyze relationships between single animal movers and groups of animals over time and space to detect emergent group properties. A common way to interpret this type of data is to visualize it as a spatio-temporal network. Collective behavior data sets are often large, and may hence result in dense and highly connected node-link diagrams, resulting in issues of node-overlap and edge clutter. In this design study, in an iterative design process, we developed glyphs as a design for seamlessly encoding relationships and movement characteristics of a single mover or clusters of movers. Based on these glyph designs, we developed a visual exploration prototype, MotionGlyphs, that supports domain experts in interactively filtering, clustering, and animating spatio-temporal networks for collective animal behavior analysis. By means of an expert evaluation, we show how MotionGlyphs supports important tasks and analysis goals of our domain experts, and we give evidence of the usefulness for analyzing spatio-temporal networks of collective animal behavior.", "keywords": "", "link": "https://doi.org/10.1111/cgf.13963", "refList": ["10.1109/tvcg.2007.70582", "10.1111/cgf.13213", "10.1109/pacificvis.2014.13", "10.1145/2093973.2094038", "10.1111/j.1467-8659.2009.01664.x", "10.1109/tvcg.2010.44", "10.1111/cgf.12106", "10.1111/cgf.12791", "10.1080/15230406.2014.890071", "10.1111/tgis.12100", "10.1111/j.1467-8659.2009.01451.x", "10.1179/000870409x12525737905042", "10.1111/cgf.12923", "10.1006/ijhc.2002.1017", "10.1145/1124772.1124891", "10.1109/tvcg.2011.213", "10.1109/vast.2014.7042484", "10.1007/s12650-016-0375-5", "10.1109/vlhcc.2012.6344514", "10.1073/pnas.1420068112", "10.1006/ijhc.1017", "10.1007/s00371-017-1461-y", "10.1109/infvis.2003.1249008", "10.1111/cgf.13728", "10.2312/conf/eg2013/stars/039-063", "10.1109/tvcg.2014.2346271", "10.1109/hicss.2011.339", "10.1068/p3104", "10.1145/2931002.2931012", "10.1109/asonam.2012.39", "10.1179/000870403235002042", "10.1145/2556288.2557010", "10.1145/2470654.2466443", "10.1109/tvcg.2011.209", "10.1016/j.tree.2013.06.002", "10.1111/1365-2656.12418", "10.1111/cgf.12872", "10.1145/2470654.2466444", "10.1109/tvcg.2014.2322594", "10.1109/tvcg.2008.125", "10.1109/tvcg.2014.2346426", "10.1109/tvcg.2006.166", "10.1111/cgf.12615", "10.1057/palgrave.ivs.9500170", "10.1007/3-540-36151-0", "10.1117/12.872578", "10.1016/j.tics.2008.10.002", "10.1006/jtbi.2002.3065", "10.1109/tvcg.2010.78", "10.1109/iv.2013.3", "10.1073/pnas.1001763107", "10.1109/pacificvis.2015.7156354", "10.1371/journal.pbio.1001805", "10.5220/0005303801230130", "10.1111/j.1467-8659.2009.01687.x", "10.1007/s10844-011-0159-2", "10.1007/s12650-018-00543-4", "10.1145/2669557.2669572", "10.1111/cgf.13184", "10.1186/s40462-015-0032-y", "10.1016/j.ins.2016.06.048", "10.1109/tvcg.2017.2744898"], "wos": 1, "children": [], "len": 1}, {"doi": "10.1111/cgf.13987", "year": "2020", "title": "Augmenting Node-Link Diagrams with Topographic Attribute Maps", "conferenceName": "EuroVis", "authors": "Reinhold Preiner;Johanna Schmidt;Katharina Kr{\\\"{o}}sl;Tobias Schreck;Gabriel Mistelbauer", "citationCount": "0", "affiliation": "Preiner, R (Corresponding Author), Graz Univ Technol, Inst Comp Graph \\& Knowledge Visualizat, Graz, Austria.\nPreiner, R.; Schreck, T., Graz Univ Technol, Inst Comp Graph \\& Knowledge Visualizat, Graz, Austria.\nSchmidt, J.; Kroesl, K., Virtual Real \\& Visualisierung Forsch GmbH, VRVis Zentrum, Vienna, Austria.\nKroesl, K., TU Wien, Inst Visual Comp \\& Human Ctr Technol, Vienna, Austria.\nMistelbauer, G., Otto von Guericke Univ, Dept Simulat \\& Graph, Magdeburg, Germany.", "countries": "Germany;Austria", "abstract": "We propose a novel visualization technique for graphs that are attributed with scalar data. In many scenarios, these attributes (e.g., birth date in a family network) provide ambient context information for the graph structure, whose consideration is important for different visual graph analysis tasks. Graph attributes are usually conveyed using different visual representations (e.g., color, size, shape) or by reordering the graph structure according to the attribute domain (e.g., timelines). While visual encodings allow graphs to be arranged in a readable layout, assessing contextual information such as the relative similarities of attributes across the graph is often cumbersome. In contrast, attribute-based graph reordering serves the comparison task of attributes, but typically strongly impairs the readability of the structural information given by the graph's topology. In this work, we augment force-directed node-link diagrams with a continuous ambient representation of the attribute context. This way, we provide a consistent overview of the graph's topological structure as well as its attributes, supporting a wide range of graph-related analysis tasks. We resort to an intuitive height field metaphor, illustrated by a topographic map rendering using contour lines and suitable color maps. Contour lines visually connect nodes of similar attribute values, and depict their relative arrangement within the global context. Moreover, our contextual representation supports visualizing attribute value ranges associated with graph nodes (e.g., lifespans in a family network) as trajectories routed through this height field. We discuss how user interaction with both the structural and the contextual information fosters exploratory graph analysis tasks. The effectiveness and versatility of our technique is confirmed in a user study and case studies from various application domains.", "keywords": "", "link": "https://doi.org/10.1111/cgf.13987", "refList": ["10.1109/tvcg.2013.269", "10.1109/pacificvis.2010.5429590", "10.1073/pnas.0307654100", "10.1145/2505515.2505758", "10.1559/152304082783948286", "10.1109/pacificvis.2014.47", "10.1093/bioinformatics/btp432", "10.1111/j.1467-8659.2011.01898.x", "10.1111/cgf.12931", "10.1111/cgf.12880", "10.1109/tvcg.2014.2346422", "10.1111/j.1467-8659.2009.01706.x", "10.1109/tvcg.2016.2598795", "10.1111/cgf.12800", "10.1109/tvcg.2014.2315995", "10.1111/cgf.12656", "10.1111/cgf.13728", "10.1109/tvcg.2009.122", "10.1111/cgf.13211", "10.1109/tvcg.2007.70596", "10.1109/infvis.2002.1173152", "10.1109/tvcg.2015.2467691", "10.1109/tvcg.2003.1196007", "10.1109/infvis.2005.1532150", "10.1145/3243250.3243266", "10.1080/02693799008941549", "10.1371/journal.pone.0058779", "10.1109/infvis.1995.528686", "10.1111/cgf.12872", "10.1002/spe.4380211102", "10.1109/38.974518", "10.1145/3097983.3098130", "10.1002/aris.1440370106", "10.1145/1360612.1360691", "10.1109/mc.2016.145", "10.2307/3006914", "10.1111/j.1467-8659.2009.01683.x", "10.1145/1639714.1639784"], "wos": 1, "children": [], "len": 1}], "len": 9}], "len": 33}, {"doi": "10.1109/tvcg.2019.2934264", "title": "The Validity, Generalizability and Feasibility of Summative Evaluation Methods in Visual Analytics", "year": "2019", "conferenceName": "VAST", "authors": "Mosab Khayat;Morteza Karimzadeh;David S. Ebert;Arif Ghafoor", "citationCount": "1", "affiliation": "Khayat, M (Corresponding Author), Purdue Univ, W Lafayette, IN 47907 USA. Khayat, Mosab; Karimzadeh, Morteza; Ebert, David S.; Ghafoor, Arif, Purdue Univ, W Lafayette, IN 47907 USA. Karimzadeh, Morteza, Univ Colorado, Boulder, CO 80309 USA.", "countries": "USA", "abstract": "Many evaluation methods have been used to assess the usefulness of Visual Analytics (VA) solutions. These methods stem from a variety of origins with different assumptions and goals, which cause confusion about their proofing capabilities. Moreover, the lack of discussion about the evaluation processes may limit our potential to develop new evaluation methods specialized for VA. In this paper, we present an analysis of evaluation methods that have been used to summatively evaluate VA solutions. We provide a survey and taxonomy of the evaluation methods that have appeared in the VAST literature in the past two years. We then analyze these methods in terms of validity and generalizability of their findings, as well as the feasibility of using them. We propose a new metric called summative quality to compare evaluation methods according to their ability to prove usefulness, and make recommendations for selecting evaluation methods based on their summative quality in the VA domain.", "keywords": "Summative evaluation,usefulness,evaluation process,taxonomy,visual analytics", "link": "http://dx.doi.org/10.1109/TVCG.2019.2934264", "refList": ["10.1109/tvcg.2017.2744478", "10.1109/tvcg.2018.2865025", "10.1109/tvcg.2006.85", "10.1109/tvcg.2014.2346331", "10.1109/beliv.2018.8634420", "10.1109/tvcg.2017.2745181", "10.1111/cgf.13677", "10.1109/tvcg.2018.2864844", "10.1109/tvcg.2013.126", "10.1109/tvcg.2018.2864811", "10.1109/infvis.2005.1532147", "10.1177/0956797613504966", "10.1145/2669557.2669579", "10.1109/mcg.2005.102", "10.1109/visual.2003.1250426", "10.1136/bmj.39489.470347.ad", "10.1109/tvcg.2017.2744080", "10.1109/mcg.2009.53", "10.1111/j.1467-8527.2005.00307.x", "10.1109/tvcg.2010.132", "10.1109/tvcg.2018.2864886", "10.1109/tvcg.2018.2864843", "10.1109/tvcg.2018.2865028", "10.1109/tvcg.2018.2865051", "10.1109/tvcg.2018.2865044", "10.1109/tvcg.2018.2865026", "10.1007/978-3-540-71080-6\\_6", "10.1109/tvcg.2018.2865020", "10.1177/1473871611407399", "10.1109/tvcg.2018.2864504", "10.1109/tvcg.2018.2864526", "10.1109/tvcg.2005.53", "10.1109/tvcg.2018.2864905", "10.1049/sej.1991.0040", "10.1109/tvcg.2015.2513410", "10.1109/tvcg.2017.2711030", "10.1109/tvcg.2011.279", "10.1109/vast.2017.8585505", "10.1147/jrd.2010.2042914", "10.1016/s0378-7206(98)00044-5", "10.1145/2993901.2993913", "10.1109/tvcg.2018.2865041", "10.1109/tvcg.2018.2864812", "10.1109/tvcg.2017.2744758", "10.1145/1168149.1168158", "10.1109/tvcg.2017.2745279", "10.1109/tvcg.2012.213", "10.1109/tvcg.2017.2744738", "10.1109/tvcg.2017.2745083", "10.1109/tvcg.2018.2864826", "10.1145/1377966.1377974", "10.1109/apec.2009.4802646", "10.1145/1168149.1168152", "10.1016/j.jss.2008.03.059", "10.1109/vast.2017.8585484", "10.1109/tvcg.2017.2744818", "10.1109/tvcg.2017.2744358", "10.1109/tvcg.2018.2864499", "10.1109/tvcg.2018.2865042", "10.1109/tvcg.2017.2744898"], "wos": 1, "children": [{"doi": "10.1109/tvcg.2020.3030388", "title": "Visualization of Human Spine Biomechanics for Spinal Surgery", "year": "2020", "conferenceName": "SciVis", "authors": "Pepe Eulzer;Sabine Bauer;Francis Kilian;Kai Lawonn", "citationCount": "0", "affiliation": "Eulzer, P (Corresponding Author), Univ Jena, Jena, Germany. Eulzer, Pepe; Lawonn, Kai, Univ Jena, Jena, Germany. Bauer, Sabine, Univ Koblenz Landau, Koblenz, Germany. Kilian, Francis, Cath Clin Koblenz Montabaur, Dept Spine Surg, Koblenz, Germany.", "countries": "Germany", "abstract": "We propose a visualization application, designed for the exploration of human spine simulation data. Our goal is to support research in biomechanical spine simulation and advance efforts to implement simulation-backed analysis in surgical applications. Biomechanical simulation is a state-of-the-art technique for analyzing load distributions of spinal structures. Through the inclusion of patient-specific data, such simulations may facilitate personalized treatment and customized surgical interventions. Difficulties in spine modelling and simulation can be partly attributed to poor result representation, which may also be a hindrance when introducing such techniques into a clinical environment. Comparisons of measurements across multiple similar anatomical structures and the integration of temporal data make commonly available diagrams and charts insufficient for an intuitive and systematic display of results. Therefore, we facilitate methods such as multiple coordinated views, abstraction and focus and context to display simulation outcomes in a dedicated tool. $\\mathrm{By}$ linking the result data with patient-specific anatomy, we make relevant parameters tangible for clinicians. Furthermore, we introduce new concepts to show the directions of impact force vectors, which were not accessible before. We integrated our toolset into a spine segmentation and simulation pipeline and evaluated our methods with both surgeons and biomechanical researchers. When comparing our methods against standard representations that are currently in use, we found increases in accuracy and speed in data exploration tasks. $\\mathrm{in}$ a qualitative review, domain experts deemed the tool highly useful when dealing with simulation result data, which typically combines time-dependent patient movement and the resulting force distributions on spinal structures.", "keywords": "Medical visualization,bioinformatics,coordinated views,focus and context,biomechanical simulation", "link": "http://dx.doi.org/10.1109/TVCG.2020.3030388", "refList": ["10.1109/tvcg.2018.2864903", "10.1177/1473871613510429", "10.1093/ehjqcco/qcz052", "10.1109/tvcg.2007.70594", "10.1109/tvcg.2018.2865076", "10.1055/s-0039-1687862", "10.1109/visual.1990.146375", "10.1109/tvcg.2017.2744198", "10.1016/j.ijmedinf.2014.10.001", "10.1109/tvcg.2013.124", "10.1016/j.jacc", "10.1111/cgf.13167", "10.17705/1thci.00055", "10.1136/bmjqs.2009.037895", "10.1109/tvcg.2013.238", "10.1109/tvcg.2018.2865240", "10.1186/1471-2261-6-34", "10.1109/tvcg.2019.2934264", "10.1109/tvcg.2013.200", "10.1109/tvcg.2011.209", "10.1109/tvcg.2014.2346682", "10.1109/tvcg.2015.2467091", "10.1136/bmjopen-2019-033208", "10.1109/beliv.2018.8634027", "10.1109/tvcg.2012.213", "10.1109/tvcg.2015.2467191", "10.1109/tvcg.2015.2467325", "10.1145/2133806.2133821", "10.1145/1806799.1806866", "10.1108/02635570610688869", "10.1002/hbm.20701", "10.1561/1100000039", "10.1145/3025453.3025645", "10.1109/tvcg.2009.111", "10.1109/tvcg.2013.120", "10.1109/tvcg.2016.2599030"], "wos": 1, "children": [], "len": 1}], "len": 3}, {"doi": "10.1111/cgf.13728", "year": "2019", "title": "The State of the Art in Visualizing Multivariate Networks", "conferenceName": "EuroVis", "authors": "Carolina Nobre;Miriah D. Meyer;Marc Streit;Alexander Lex", "citationCount": "5", "affiliation": "Nobre, C (Corresponding Author), Univ Utah, Salt Lake City, UT 84112 USA.\nNobre, C.; Meyer, M.; Lex, A., Univ Utah, Salt Lake City, UT 84112 USA.\nStreit, M., Johannes Kepler Univ Linz, Linz, Austria.", "countries": "USA;Austria", "abstract": "Multivariate networks are made up of nodes and their relationships (links), but also data about those nodes and links as attributes. Most real-world networks are associated with several attributes, and many analysis tasks depend on analyzing both, relationships and attributes. Visualization of multivariate networks, however, is challenging, especially when both the topology of the network and the attributes need to be considered concurrently. In this state-of-the-art report, we analyze current practices and classify techniques along four axes: layouts, view operations, layout operations, and data operations. We also provide an analysis of tasks specific to multivariate networks and give recommendations for which technique to use in which scenario. Finally, we survey application areas and evaluation methodologies.", "keywords": "", "link": "https://doi.org/10.1111/cgf.13728", "refList": ["10.2312/eurovisstar.20151110", "10.1111/cgf.12106", "10.1109/iv.2016.19", "10.1111/j.1467-8659.2011.02087.x", "10.1111/j.1467-8659.2008.01214.x", "10.1109/tvcg.2014.2346893", "10.1145/1124772.1124891", "10.1109/vast.2014.7042484", "10.1109/tvcg.2018.2865149", "10.1080/10447318.2010.516722", "10.1109/icsmc.2011.6084125", "10.1109/mcg.2011.103", "10.1117/12.378894", "10.1145/2207676.2208293", "10.1109/tvcg.2009.122", "10.1111/cgf.12935", "10.1016/s0020-0255(02)00191-3", "10.1038/nmeth.1436", "10.1109/tvcg.2011.187", "10.1109/32.177365", "10.1007/978-3-642-03658-3\\_47", "10.1109/tvcg.2006.147", "10.1109/pacificvis.2011.5742390", "10.1145/2470654.2466444", "10.1109/tvcg.2006.166", "10.1145/2470654.2470724", "10.1109/tvcg.2014.2346441", "10.1109/vizsec.2005.1532070", "10.1101/gr.092759.109", "10.1111/cgf.13184", "10.1109/tvcg.2018.2865940", "10.1016/j.scico.2012.05.002", "10.1109/biovis.2012.6378600", "10.1111/cgf.13213", "10.1109/noms.2006.1687547", "10.1109/tvcg.2008.141", "10.1007/978-3-540-78243-8\\_13", "10.1145/1029208.1029217", "10.1145/345513.345271", "10.1109/tvcg.2015.2467811", "10.1109/visual.1991.175815", "10.1186/1471-2105-10-375", "10.1007/978-3-319-06793-3\\_1", "10.1186/1471-2105-13-275", "10.1109/tvcg.2010.79", "10.1109/tvcg.2011.217", "10.1186/1471-2105-14-s19-s3", "10.3389/fmicb.2017.00010", "10.1109/infvis.2003.1249009", "10.1111/cgf.13187", "10.1111/j.1467-8659.2008.01231.x", "10.1109/tvcg.2011.144", "10.1145/2556288.2557010", "10.1111/j.1467-8659.2009.01710.x", "10.1109/infvis.2004.46", "10.1109/iv.2009.97", "10.1109/tvcg.2008.34", "10.1109/infvis.2003.1249011", "10.1109/iv.2016.41", "10.1109/pacificvis.2010.5429609", "10.1109/tvcg.2006.160", "10.1109/tvcg.2010.205", "10.1109/38.486685", "10.1109/tvcg.2006.106", "10.1057/palgrave.ivs.9500092", "10.1145/568522.568523", "10.1111/j.1467-8659.2008.01221.x", "10.1109/iv.2010.15", "10.1145/22339.22342", "10.1109/csmr.2009.17", "10.1109/tvcg.2017.2744898", "10.1109/tvcg.2008.117", "10.1186/1752-0509-3-82", "10.1109/tvcg.2008.61", "10.1109/pacificvis.2013.6596127", "10.1109/tvcg.2007.70529", "10.1186/1471-2105-15-198", "10.1109/tvcg.2009.128", "10.2312/eurovisshort.20151124", "10.1093/bioinformatics/btq675", "10.1109/tvcg.2009.143", "10.1109/tvcg.2014.2346752", "10.1109/tvcg.2013.124", "10.1007/s00450-007-0036-y", "10.1093/bioinformatics/17.suppl\\_1.s22", "10.2312/eurovisstar.20151109", "10.1007/978-3-319-06793-3\\_5", "10.1109/vissof.2007.4290706", "10.1109/tvcg.2009.145", "10.1109/mcas.2003.1228503", "10.1109/infvis.2005.1532128", "10.1145/989863.989941", "10.1109/infvis.1999.801860", "10.1111/j.1467-8659.2009.01687.x", "10.1109/tvcg.2013.120", "10.1109/tvcg.2007.70582", "10.1109/tvcg.2009.167", "10.1109/pacificvis.2010.5429590", "10.1109/infvis.2000.885091", "10.1109/tvcg.2012.189", "10.1109/tvcg.2009.108", "10.1109/tvcg.2013.154", "10.1111/j.1467-8659.2011.01898.x", "10.1109/tvcg.2010.159", "10.1016/s0306-4573(98)00024-7", "10.1109/tvcg.2013.223", "10.1002/sam.10071", "10.2312/vissym/eurovis07/083-090", "10.1109/infvis.2002.1173156", "10.1186/1471-2105-7-109", "10.1177/1473871612455983", "10.1073/pnas.95.25.14863", "10.1007/978-3-319-06793-3\\_2", "10.1111/cgf.12883", "10.1007/978-3-540-78243-8\\_9", "10.1057/palgrave.ivs.9500180", "10.1109/pacificvis.2012.6183556", "10.1117/12.872578", "10.1145/1168149.1168169", "10.1109/iv.2013.3", "10.1109/tvcg.2011.186", "10.2307/2685881", "10.1109/pacificvis.2015.7156354", "10.1109/tvcg.2016.2598885", "10.1109/tvcg.2018.2811488", "10.1109/infvis.2005.1532129", "10.1111/j.1467-8659.2009.01450.x", "10.1057/palgrave.ivs.9500162", "10.1109/tvcg.2009.116", "10.1109/2945.468391"], "wos": 1, "children": [{"doi": "10.1109/tvcg.2020.3029413", "title": "A Design Space of Vision Science Methods for Visualization Research", "year": "2020", "conferenceName": "InfoVis", "authors": "Madison A. Elliott;Christine Nothelfer;Cindy Xiong;Danielle Albers Szafir", "citationCount": "0", "affiliation": "Elliott, MA (Corresponding Author), Univ British Columbia, Vancouver, BC, Canada. Elliott, Madison A., Univ British Columbia, Vancouver, BC, Canada. Nothelfer, Christine, Northwestern Univ, Evanston, IL 60208 USA. Xiong, Cindy, Univ Massachusetts, Amherst, MA 01003 USA. Szafir, Danielle Albers, Univ Colorado, Boulder, CO 80309 USA.", "countries": "Canada;USA", "abstract": "A growing number of efforts aim to understand what people see when using a visualization. These efforts provide scientific grounding to complement design intuitions, leading to more effective visualization practice. However, published visualization research currently reflects a limited set of available methods for understanding how people process visualized data. Alternative methods from vision science offer a rich suite of tools for understanding visualizations, but no curated collection of these methods exists in either perception or visualization research. We introduce a design space of experimental methods for empirically investigating the perceptual processes involved with viewing data visualizations to ultimately inform visualization design guidelines. This paper provides a shared lexicon for facilitating experimental visualization research. We discuss popular experimental paradigms, adjustment types, response types, and dependent measures used in vision science research, rooting each in visualization examples. We then discuss the advantages and limitations of each technique. Researchers can use this design space to create innovative studies and progress scientific understanding of design choices and evaluations in visualization. We highlight a history of collaborative success between visualization and vision science research and advocate for a deeper relationship between the two fields that can elaborate on and extend the methodological design space for understanding visualization and vision.", "keywords": "Perception,human vision,empirical research,evaluation,HCI", "link": "http://dx.doi.org/10.1109/TVCG.2020.3029413", "refList": ["10.1109/tvcg.2019.2934790", "10.1177/146879410200200205", "10.2312/eurovisshort", "10.1109/tvcg.2015.2467811", "10.1111/j.1467-6486.2009.00859.x", "10.1177/1473871613510429", "10.1109/tvcg.2018.2864836", "10.1109/tvcg.2018.2865076", "10.1109/tvcg.2013.231", "10.1002/cphy.c100079", "10.1177/0886109909354981", "10.1109/tvcg.2018.2865149", "10.1080/1750984x.2017.1317357", "10.1007/978-3-7643-8472-2\\_6", "10.1093/bioinformatics/btq110", "10.1111/cgf.13728", "10.2307/1511837", "10.1109/tvcg.2019.2934539", "10.3233/efi-2004-22201", "10.1002/chp.1340180402", "10.1111/2041-210x.12034", "10.1111/j.2041-210x.2011.00169.x", "10.1109/tvcg.2015.2467452", "10.1002/chp", "10.1177/1077800410383121", "10.1177/1744987107081254", "10.1002/cpbi.96", "10.1109/tvcg.2018.2864526", "10.1109/beliv.2018.8634026", "10.2307/1511637", "10.1109/tvcg.2014.2346431", "10.1111/cgf.12883", "10.1109/tvcg.2019.2934281", "10.1145/2993901.2993916", "10.2307/3178066", "10.1145/2993901.2993913", "10.1145/1182475.1182476", "10.1016/j.destud.2004.06.002", "10.1177/1609406918763214", "10.2312/eurovisshort.20151137", "10.1145/882262.882291", "10.1177/174498710501000305", "10.1017/s1049096513001789", "10.1109/tvcg.2012.213", "10.1093/nar/gkz239", "10.1093/sysbio/sys062", "10.1109/tvcg.2019.2898186", "10.1109/tvcg.2018.2811488", "10.1007/s11135-006-9044-4", "10.1109/tvcg.2009.111", "10.1111/2041-210x.12066", "10.1109/mcg.2018.2874523", "10.1177/1609406920909938"], "wos": 1, "children": [], "len": 1}, {"doi": "10.1109/tvcg.2020.3030405", "title": "Insights From Experiments With Rigor in an EvoBio Design Study", "year": "2020", "conferenceName": "InfoVis", "authors": "Jennifer Rogers;Austin H. Patton;Luke Harmon;Alexander Lex;Miriah D. Meyer", "citationCount": "0", "affiliation": "Rogers, J (Corresponding Author), Univ Utah, Salt Lake City, UT 84112 USA. Rogers, Jen; Lex, Alexander; Meyer, Miriah, Univ Utah, Salt Lake City, UT 84112 USA. Patton, Austin H., Washington State Univ, Pullman, WA 99164 USA. Harmon, Luke, Univ Idaho, Moscow, ID 83843 USA.", "countries": "USA", "abstract": "Design study is an established approach of conducting problem-driven visualization research. The academic visualization community has produced a large body of work for reporting on design studies, informed by a handful of theoretical frameworks, and applied to a broad range of application areas. The result is an abundance of reported insights into visualization design, with an emphasis on novel visualization techniques and systems as the primary contribution of these studies. In recent work we proposed a new, interpretivist perspective on design study and six companion criteria for rigor that highlight the opportunities for researchers to contribute knowledge that extends beyond visualization idioms and software. In this work we conducted a year-long collaboration with evolutionary biologists to develop an interactive tool for visual exploration of multivariate datasets and phylogenetic trees. During this design study we experimented with methods to support three of the rigor criteria: ABUNDANT, REFLEXIVE, and TRANSPARENT. As a result we contribute two novel visualization techniques for the analysis of multivariate phylogenetic datasets, three methodological recommendations for conducting design studies drawn from reflections over our process of experimentation, and two writing devices for reporting interpretivist design study. We offer this work as an example for implementing the rigor criteria to produce a diverse range of knowledge contributions.", "keywords": "Methodologies,Application Motivated Visualization,Guidelines,Life Sciences Visualization,Health,Medicine,Biology,Bioinformatics,Genomics", "link": "http://dx.doi.org/10.1109/TVCG.2020.3030405", "refList": ["10.1109/tvcg.2019.2934790", "10.1177/146879410200200205", "10.2312/eurovisshort", "10.1109/tvcg.2015.2467811", "10.1111/j.1467-6486.2009.00859.x", "10.1177/1473871613510429", "10.1109/tvcg.2018.2864836", "10.1109/tvcg.2018.2865076", "10.1109/tvcg.2013.231", "10.1002/cphy.c100079", "10.1109/tvcg.2018.2865149", "10.1080/1750984x.2017.1317357", "10.1007/978-3-7643-8472-2\\_6", "10.1111/cgf.13728", "10.2307/1511837", "10.1109/tvcg.2019.2934539", "10.3233/efi-2004-22201", "10.1080/17493460802276893", "10.1002/chp.1340180402", "10.1111/2041-210x.12034", "10.1111/j.2041-210x.2011.00169.x", "10.1109/tvcg.2015.2467452", "10.1002/chp", "10.1177/1077800410383121", "10.1002/cpbi.96", "10.1109/tvcg.2018.2864526", "10.1109/beliv.2018.8634026", "10.2307/1511637", "10.1109/tvcg.2014.2346431", "10.1111/cgf.12883", "10.1109/tvcg.2019.2934281", "10.1145/2993901.2993916", "10.2307/3178066", "10.1145/2993901.2993913", "10.1145/1182475.1182476", "10.1016/j.destud.2004.06.002", "10.1177/1609406918763214", "10.2312/eurovisshort.20151137", "10.1145/882262.882291", "10.1109/tvcg.2012.213", "10.1109/tvcg.2019.2898186", "10.1109/tvcg.2018.2811488", "10.1007/s11135-006-9044-4", "10.1109/tvcg.2009.111", "10.1111/2041-210x.12066", "10.1109/mcg.2018.2874523", "10.1177/1609406920909938"], "wos": 1, "children": [], "len": 1}, {"doi": "10.1111/cgf.13963", "year": "2020", "title": "MotionGlyphs: Visual Abstraction of Spatio-Temporal Networks in Collective Animal Behavior", "conferenceName": "EuroVis", "authors": "Eren Cakmak;Hanna Sch{\\\"{a}}fer;Juri Buchm{\\\"{u}}ller;Johannes Fuchs;Tobias Schreck;A. Jordan;Daniel A. Keim", "citationCount": "0", "affiliation": "Cakmak, E (Corresponding Author), Univ Konstanz, Constance, Germany.\nCakmak, E (Corresponding Author), Ctr Adv Study Collect Behav, Constance, Germany.\nCakmak, E.; Schaefer, H.; Buchmueller, J.; Fuchs, J.; Jordan, A.; Keim, D., Univ Konstanz, Constance, Germany.\nCakmak, E.; Jordan, A.; Keim, D., Ctr Adv Study Collect Behav, Constance, Germany.\nSchreck, T., Graz Univ Technol, Graz, Austria.\nJordan, A., Max Planck Inst Anim Behav, Radolfzell am Bodensee, Germany.", "countries": "Germany;Austria", "abstract": "Domain experts for collective animal behavior analyze relationships between single animal movers and groups of animals over time and space to detect emergent group properties. A common way to interpret this type of data is to visualize it as a spatio-temporal network. Collective behavior data sets are often large, and may hence result in dense and highly connected node-link diagrams, resulting in issues of node-overlap and edge clutter. In this design study, in an iterative design process, we developed glyphs as a design for seamlessly encoding relationships and movement characteristics of a single mover or clusters of movers. Based on these glyph designs, we developed a visual exploration prototype, MotionGlyphs, that supports domain experts in interactively filtering, clustering, and animating spatio-temporal networks for collective animal behavior analysis. By means of an expert evaluation, we show how MotionGlyphs supports important tasks and analysis goals of our domain experts, and we give evidence of the usefulness for analyzing spatio-temporal networks of collective animal behavior.", "keywords": "", "link": "https://doi.org/10.1111/cgf.13963", "refList": ["10.1109/tvcg.2007.70582", "10.1111/cgf.13213", "10.1109/pacificvis.2014.13", "10.1145/2093973.2094038", "10.1111/j.1467-8659.2009.01664.x", "10.1109/tvcg.2010.44", "10.1111/cgf.12106", "10.1111/cgf.12791", "10.1080/15230406.2014.890071", "10.1111/tgis.12100", "10.1111/j.1467-8659.2009.01451.x", "10.1179/000870409x12525737905042", "10.1111/cgf.12923", "10.1006/ijhc.2002.1017", "10.1145/1124772.1124891", "10.1109/tvcg.2011.213", "10.1109/vast.2014.7042484", "10.1007/s12650-016-0375-5", "10.1109/vlhcc.2012.6344514", "10.1073/pnas.1420068112", "10.1006/ijhc.1017", "10.1007/s00371-017-1461-y", "10.1109/infvis.2003.1249008", "10.1111/cgf.13728", "10.2312/conf/eg2013/stars/039-063", "10.1109/tvcg.2014.2346271", "10.1109/hicss.2011.339", "10.1068/p3104", "10.1145/2931002.2931012", "10.1109/asonam.2012.39", "10.1179/000870403235002042", "10.1145/2556288.2557010", "10.1145/2470654.2466443", "10.1109/tvcg.2011.209", "10.1016/j.tree.2013.06.002", "10.1111/1365-2656.12418", "10.1111/cgf.12872", "10.1145/2470654.2466444", "10.1109/tvcg.2014.2322594", "10.1109/tvcg.2008.125", "10.1109/tvcg.2014.2346426", "10.1109/tvcg.2006.166", "10.1111/cgf.12615", "10.1057/palgrave.ivs.9500170", "10.1007/3-540-36151-0", "10.1117/12.872578", "10.1016/j.tics.2008.10.002", "10.1006/jtbi.2002.3065", "10.1109/tvcg.2010.78", "10.1109/iv.2013.3", "10.1073/pnas.1001763107", "10.1109/pacificvis.2015.7156354", "10.1371/journal.pbio.1001805", "10.5220/0005303801230130", "10.1111/j.1467-8659.2009.01687.x", "10.1007/s10844-011-0159-2", "10.1007/s12650-018-00543-4", "10.1145/2669557.2669572", "10.1111/cgf.13184", "10.1186/s40462-015-0032-y", "10.1016/j.ins.2016.06.048", "10.1109/tvcg.2017.2744898"], "wos": 1, "children": [], "len": 1}, {"doi": "10.1111/cgf.13987", "year": "2020", "title": "Augmenting Node-Link Diagrams with Topographic Attribute Maps", "conferenceName": "EuroVis", "authors": "Reinhold Preiner;Johanna Schmidt;Katharina Kr{\\\"{o}}sl;Tobias Schreck;Gabriel Mistelbauer", "citationCount": "0", "affiliation": "Preiner, R (Corresponding Author), Graz Univ Technol, Inst Comp Graph \\& Knowledge Visualizat, Graz, Austria.\nPreiner, R.; Schreck, T., Graz Univ Technol, Inst Comp Graph \\& Knowledge Visualizat, Graz, Austria.\nSchmidt, J.; Kroesl, K., Virtual Real \\& Visualisierung Forsch GmbH, VRVis Zentrum, Vienna, Austria.\nKroesl, K., TU Wien, Inst Visual Comp \\& Human Ctr Technol, Vienna, Austria.\nMistelbauer, G., Otto von Guericke Univ, Dept Simulat \\& Graph, Magdeburg, Germany.", "countries": "Germany;Austria", "abstract": "We propose a novel visualization technique for graphs that are attributed with scalar data. In many scenarios, these attributes (e.g., birth date in a family network) provide ambient context information for the graph structure, whose consideration is important for different visual graph analysis tasks. Graph attributes are usually conveyed using different visual representations (e.g., color, size, shape) or by reordering the graph structure according to the attribute domain (e.g., timelines). While visual encodings allow graphs to be arranged in a readable layout, assessing contextual information such as the relative similarities of attributes across the graph is often cumbersome. In contrast, attribute-based graph reordering serves the comparison task of attributes, but typically strongly impairs the readability of the structural information given by the graph's topology. In this work, we augment force-directed node-link diagrams with a continuous ambient representation of the attribute context. This way, we provide a consistent overview of the graph's topological structure as well as its attributes, supporting a wide range of graph-related analysis tasks. We resort to an intuitive height field metaphor, illustrated by a topographic map rendering using contour lines and suitable color maps. Contour lines visually connect nodes of similar attribute values, and depict their relative arrangement within the global context. Moreover, our contextual representation supports visualizing attribute value ranges associated with graph nodes (e.g., lifespans in a family network) as trajectories routed through this height field. We discuss how user interaction with both the structural and the contextual information fosters exploratory graph analysis tasks. The effectiveness and versatility of our technique is confirmed in a user study and case studies from various application domains.", "keywords": "", "link": "https://doi.org/10.1111/cgf.13987", "refList": ["10.1109/tvcg.2013.269", "10.1109/pacificvis.2010.5429590", "10.1073/pnas.0307654100", "10.1145/2505515.2505758", "10.1559/152304082783948286", "10.1109/pacificvis.2014.47", "10.1093/bioinformatics/btp432", "10.1111/j.1467-8659.2011.01898.x", "10.1111/cgf.12931", "10.1111/cgf.12880", "10.1109/tvcg.2014.2346422", "10.1111/j.1467-8659.2009.01706.x", "10.1109/tvcg.2016.2598795", "10.1111/cgf.12800", "10.1109/tvcg.2014.2315995", "10.1111/cgf.12656", "10.1111/cgf.13728", "10.1109/tvcg.2009.122", "10.1111/cgf.13211", "10.1109/tvcg.2007.70596", "10.1109/infvis.2002.1173152", "10.1109/tvcg.2015.2467691", "10.1109/tvcg.2003.1196007", "10.1109/infvis.2005.1532150", "10.1145/3243250.3243266", "10.1080/02693799008941549", "10.1371/journal.pone.0058779", "10.1109/infvis.1995.528686", "10.1111/cgf.12872", "10.1002/spe.4380211102", "10.1109/38.974518", "10.1145/3097983.3098130", "10.1002/aris.1440370106", "10.1145/1360612.1360691", "10.1109/mc.2016.145", "10.2307/3006914", "10.1111/j.1467-8659.2009.01683.x", "10.1145/1639714.1639784"], "wos": 1, "children": [], "len": 1}], "len": 9}, {"doi": "10.1111/cgf.13963", "year": "2020", "title": "MotionGlyphs: Visual Abstraction of Spatio-Temporal Networks in Collective Animal Behavior", "conferenceName": "EuroVis", "authors": "Eren Cakmak;Hanna Sch{\\\"{a}}fer;Juri Buchm{\\\"{u}}ller;Johannes Fuchs;Tobias Schreck;A. Jordan;Daniel A. Keim", "citationCount": "0", "affiliation": "Cakmak, E (Corresponding Author), Univ Konstanz, Constance, Germany.\nCakmak, E (Corresponding Author), Ctr Adv Study Collect Behav, Constance, Germany.\nCakmak, E.; Schaefer, H.; Buchmueller, J.; Fuchs, J.; Jordan, A.; Keim, D., Univ Konstanz, Constance, Germany.\nCakmak, E.; Jordan, A.; Keim, D., Ctr Adv Study Collect Behav, Constance, Germany.\nSchreck, T., Graz Univ Technol, Graz, Austria.\nJordan, A., Max Planck Inst Anim Behav, Radolfzell am Bodensee, Germany.", "countries": "Germany;Austria", "abstract": "Domain experts for collective animal behavior analyze relationships between single animal movers and groups of animals over time and space to detect emergent group properties. A common way to interpret this type of data is to visualize it as a spatio-temporal network. Collective behavior data sets are often large, and may hence result in dense and highly connected node-link diagrams, resulting in issues of node-overlap and edge clutter. In this design study, in an iterative design process, we developed glyphs as a design for seamlessly encoding relationships and movement characteristics of a single mover or clusters of movers. Based on these glyph designs, we developed a visual exploration prototype, MotionGlyphs, that supports domain experts in interactively filtering, clustering, and animating spatio-temporal networks for collective animal behavior analysis. By means of an expert evaluation, we show how MotionGlyphs supports important tasks and analysis goals of our domain experts, and we give evidence of the usefulness for analyzing spatio-temporal networks of collective animal behavior.", "keywords": "", "link": "https://doi.org/10.1111/cgf.13963", "refList": ["10.1109/tvcg.2007.70582", "10.1111/cgf.13213", "10.1109/pacificvis.2014.13", "10.1145/2093973.2094038", "10.1111/j.1467-8659.2009.01664.x", "10.1109/tvcg.2010.44", "10.1111/cgf.12106", "10.1111/cgf.12791", "10.1080/15230406.2014.890071", "10.1111/tgis.12100", "10.1111/j.1467-8659.2009.01451.x", "10.1179/000870409x12525737905042", "10.1111/cgf.12923", "10.1006/ijhc.2002.1017", "10.1145/1124772.1124891", "10.1109/tvcg.2011.213", "10.1109/vast.2014.7042484", "10.1007/s12650-016-0375-5", "10.1109/vlhcc.2012.6344514", "10.1073/pnas.1420068112", "10.1006/ijhc.1017", "10.1007/s00371-017-1461-y", "10.1109/infvis.2003.1249008", "10.1111/cgf.13728", "10.2312/conf/eg2013/stars/039-063", "10.1109/tvcg.2014.2346271", "10.1109/hicss.2011.339", "10.1068/p3104", "10.1145/2931002.2931012", "10.1109/asonam.2012.39", "10.1179/000870403235002042", "10.1145/2556288.2557010", "10.1145/2470654.2466443", "10.1109/tvcg.2011.209", "10.1016/j.tree.2013.06.002", "10.1111/1365-2656.12418", "10.1111/cgf.12872", "10.1145/2470654.2466444", "10.1109/tvcg.2014.2322594", "10.1109/tvcg.2008.125", "10.1109/tvcg.2014.2346426", "10.1109/tvcg.2006.166", "10.1111/cgf.12615", "10.1057/palgrave.ivs.9500170", "10.1007/3-540-36151-0", "10.1117/12.872578", "10.1016/j.tics.2008.10.002", "10.1006/jtbi.2002.3065", "10.1109/tvcg.2010.78", "10.1109/iv.2013.3", "10.1073/pnas.1001763107", "10.1109/pacificvis.2015.7156354", "10.1371/journal.pbio.1001805", "10.5220/0005303801230130", "10.1111/j.1467-8659.2009.01687.x", "10.1007/s10844-011-0159-2", "10.1007/s12650-018-00543-4", "10.1145/2669557.2669572", "10.1111/cgf.13184", "10.1186/s40462-015-0032-y", "10.1016/j.ins.2016.06.048", "10.1109/tvcg.2017.2744898"], "wos": 1, "children": [], "len": 1}], "len": 71}, "index": 699, "embedding": [-0.17398200929164886, 3.2324533462524414, -1.0404996871948242, -2.2971394062042236, -0.6897369623184204, 0.16650904715061188, -0.664513111114502, 0.92957603931427, 1.0877398252487183, 2.7190611362457275, 0.9188047647476196, 2.1421680450439453, 4.567134857177734, 1.6243507862091064, 4.886282444000244, 3.0636589527130127, 2.619450569152832, 0.06877747178077698, 1.8454155921936035, 4.549417495727539, -0.06630208343267441, 0.37034985423088074, 1.9803918600082397, 5.353489875793457, -2.3829734325408936, 5.918438911437988, -0.5834015607833862, 3.5958123207092285, 2.0624849796295166, -0.36225083470344543, 2.579996109008789, 3.261650323867798], "projection": [1.6952561140060425, 10.677818298339844], "size": 36, "height": 4, "width": 15}