{"data": {"doi": "10.1109/tvcg.2017.2744080", "title": "How Do Ancestral Traits Shape Family Trees Over Generations?", "year": "2017", "conferenceName": "VAST", "authors": "Siwei Fu;Hao Dong 0008;Weiwei Cui;Jian Zhao;Huamin Qu", "citationCount": "3", "affiliation": "Fu, SW (Corresponding Author), Hong Kong Univ Sci \\& Technol, Hong Kong, Peoples R China. Fu, Siwei; Qu, Huamin, Hong Kong Univ Sci \\& Technol, Hong Kong, Peoples R China. Dong, Hao, Princeton Univ, Princeton, NJ 08544 USA. Cui, Weiwei, Microsoft Res, Redmond, WA USA. Zhao, Jian, FX Palo Alto Lab, Palo Alto, CA USA.", "countries": "USA;China", "abstract": "Whether and how does the structure of family trees differ by ancestral traits over generations? This is a fundamental question regarding the structural heterogeneity of family trees for the multi-generational transmission research. However, previous work mostly focuses on parent-child scenarios due to the lack of proper tools to handle the complexity of extending the research to multi-generational processes. Through an iterative design study with social scientists and historians, we develop TreeEvo that assists users to generate and test empirical hypotheses for multi-generational research. TreeEvo summarizes and organizes family trees by structural features in a dynamic manner based on a traditional Sankey diagram. A pixel-based technique is further proposed to compactly encode trees with complex structures in each Sankey Node. Detailed information of trees is accessible through a space-efficient visualization with semantic zooming. Moreover, TreeEvo embeds Multinomial Logit Model (MLM) to examine statistical associations between tree structure and ancestral traits. We demonstrate the effectiveness and usefulness of TreeEvo through an in-depth case-study with domain experts using a real-world dataset (containing 54,128 family trees of 126,196 individuals).", "keywords": "Quantitative social science,Design study,Multiple tree visualization,Sankey diagram", "link": "http://dx.doi.org/10.1109/TVCG.2017.2744080", "refList": ["10.1109/tvcg.2012.226", "10.1145/274644.274699", "10.1111/j.1467-8659.2008.01214.x", "10.4135/9781412985130", "10.1007/s13524-011-0014-7", "10.1109/tvcg.2007.70556", "10.1109/tvcg.2010.159", "10.1109/infvis.2005.1532152", "10.1186/1471-2105-6-74", "10.1109/vl.1996.545307", "10.1109/infvis.2002.1173150", "10.1109/tvcg.2014.2346433", "10.1146/annurev.anthro.28.1.397", "10.1109/wcre.2008.55", "10.1017/cbo9780511806452", "10.1109/iv.2004.1320261", "10.1093/jhered/ess060", "10.1145/1029949.1029974", "10.1109/tvcg.2013.200", "10.1146/annurev-soc-073014-112157", "10.1177/0003122415576516", "10.1145/102377.115768", "10.1177/1094428114560024", "10.1111/j.1467-9574.1988.tb01238.x", "10.1117/12.643272", "10.1007/s13524-015-0397-y", "10.1007/s13524-016-0486-6", "10.1109/tvcg.2012.213", "10.1057/ivs.2009.29", "10.1145/1842993.1843035", "10.1109/tvcg.2014.2346276", "10.2307/2685881", "10.1111/j.1467-8659.2011.01936.x", "10.1145/259963.260396", "10.1186/1471-2105-15-259", "10.1017/cb09780511806452"], "wos": 1, "children": [{"doi": "10.1109/tvcg.2019.2934535", "title": "BarcodeTree: Scalable Comparison of Multiple Hierarchies", "year": "2019", "conferenceName": "InfoVis", "authors": "Guozheng Li 0002;Yu Zhang 0043;Yu Dong;Jie Liang 0004;Jinson Zhang;Jinsong Wang;Michael J. McGuffin;Xiaoru Yuan", "citationCount": "2", "affiliation": "Li, GZ (Corresponding Author), Minist Educ, Key Lab Machine Percept, Beijing, Peoples R China. Li, Guozheng; Yuan, Xiaoru, Minist Educ, Key Lab Machine Percept, Beijing, Peoples R China. Li, Guozheng; Yuan, Xiaoru, Peking Univ, Natl Engn Lab Big Data Anal \\& Applicat, Beijing, Peoples R China. Zhang, Yu, Univ Oxford, Oxford, England. Zhang, Yu, Peking Univ, Beijing, Peoples R China. Dong, Yu; Liang, Jie; Zhang, Jinson, Univ Technol Sydney, Sydney, NSW, Australia. Wang, Jinsong, Southwest Elect \\& Telecom Engn Inst, Mianyang, Peoples R China. McGuffin, Michael J., Ecole Technol Super, Montreal, PQ, Canada.", "countries": "Canada;China;England;Australia", "abstract": "We propose BarcodeTree (BCT), a novel visualization technique for comparing topological structures and node attribute values of multiple trees. BCT can provide an overview of one hundred shallow and stable trees simultaneously, without aggregating individual nodes. Each BCT is shown within a single row using a style similar to a barcode, allowing trees to be stacked vertically with matching nodes aligned horizontally to ease comparison and maintain space efficiency. We design several visual cues and interactive techniques to help users understand the topological structure and compare trees. In an experiment comparing two variants of BCT with icicle plots, the results suggest that BCTs make it easier to visually compare trees by reducing the vertical distance between different trees. We also present two case studies involving a dataset of hundreds of trees to demonstrate BCT's utility.", "keywords": "tree visualization,comparison,multiple trees", "link": "http://dx.doi.org/10.1109/TVCG.2019.2934535", "refList": ["10.1207/s15327051hci0701\\_3", "10.1109/vlhcc.2014.6883017", "10.1109/infvis.2000.885091", "10.1109/tvcg.2012.226", "10.1109/tvcg.2008.141", "10.1177/1473871611416549", "10.1109/tvcg.2007.70529", "10.1109/tvcg.2015.2467733", "10.1109/tse.1981.234519", "10.1111/j.1467-8659.2011.01963.x", "10.1111/j.1467-8659.2008.01214.x", "10.1109/infvis.2002.1173151", "10.1109/iv.2003.1218020", "10.1057/ivs.2009.4", "10.1109/tvcg.2013.231", "10.1109/tvcg.2007.70556", "10.1109/vast.2011.6102439", "10.1109/visual.1991.175815", "10.1109/infvis.2001.963290", "10.1109/tvcg.2017.2744080", "10.1111/j.1467-8659.2008.01205.x", "10.1109/mcg.2011.103", "10.1109/vl.1996.545307", "10.1109/infvis.2002.1173150", "10.1145/1294948.1294971", "10.1109/tvcg.2010.79", "10.1109/infvis.2001.963283", "10.1007/bf01908061", "10.1080/10635150590946961", "10.1177/1473871612455983", "10.1109/tvcg.2018.2865265", "10.1109/iv.2004.1320261", "10.1109/tvcg.2011.193", "10.1109/tvcg.2017.2744199", "10.1109/tvcg.2016.2598469", "10.1109/infvis.2002.1173148", "10.1145/102377.115768", "10.1145/633292.633484", "10.1109/tvcg.2015.2507595", "10.1109/infvis.2004.70", "10.1109/tvcg.2018.2864884", "10.1145/882262.882291", "10.1057/ivs.2009.29", "10.2307/2685881", "10.1057/palgrave.ivs.9500157", "10.1111/cgf.13164", "10.3897/bdj.4.e9787", "10.2312/vissym/eurovis05/053-060", "10.1109/infvis.2003.1249028", "10.1109/tvcg.2014.2346433"], "wos": 1, "children": [{"doi": "10.1109/tvcg.2020.3030411", "title": "Co-Bridges: Pair-wise Visual Connection and Comparison for Multi-item Data Streams", "year": "2020", "conferenceName": "VAST", "authors": "Siming Chen;Natalia V. Andrienko;Gennady L. Andrienko;Jie Li 0006;Xiaoru Yuan", "citationCount": "0", "affiliation": "Yuan, XR (Corresponding Author), Peking Univ, Beijing, Peoples R China. Chen, Siming, Fudan Univ, Sch Data Sci, Shanghai, Peoples R China. Chen, Siming; Andrienko, Natalia; Andrienko, Gennady, Fraunhofer Inst IAIS, St Augustin, Germany. Andrienko, Natalia; Andrienko, Gennady, City Univ London, London, England. Li, Jie, Tianjin Univ, Tianjin, Peoples R China. Yuan, Xiaoru, Peking Univ, Beijing, Peoples R China.", "countries": "Germany;China;England", "abstract": "In various domains, there are abundant streams or sequences of multi-item data of various kinds, e.g. streams of news and social media texts, sequences of genes and sports events, etc. Comparison is an important and general task in data analysis. For comparing data streams involving multiple items (e.g., words in texts, actors or action types in action sequences, visited places in itineraries, etc.), we propose Co-Bridges, a visual design involving connection and comparison techniques that reveal similarities and differences between two streams. Co-Bridges use river and bridge metaphors, where two sides of a river represent data streams, and bridges connect temporally or sequentially aligned segments of streams. Commonalities and differences between these segments in terms of involvement of various items are shown on the bridges. Interactive query tools support the selection of particular stream subsets for focused exploration. The visualization supports both qualitative (common and distinct items) and quantitative (stream volume, amount of item involvement) comparisons. We further propose Comparison-of-Comparisons, in which two or more Co-Bridges corresponding to different selections are juxtaposed. We test the applicability of the Co-Bridges in different domains, including social media text streams and sports event sequences. We perform an evaluation of the users' capability to understand and use Co-Bridges. The results confirm that Co-Bridges is effective for supporting pair-wise visual comparisons in a wide range of applications.", "keywords": "Visual Comparison,Pair-wise Analysis,Multi-item Data Stream,Social Media", "link": "http://dx.doi.org/10.1109/TVCG.2020.3030411", "refList": ["10.1109/tvcg.2014.2346753", "10.1109/pacificvis.2010.5429590", "10.1109/vast.2009.5333443", "10.1101/gr.2289704", "10.1177/1473871611416549", "10.1057/palgrave.ivs.9500099", "10.1109/vast.2017.8585638", "10.1109/vast.2014.7042496", "10.1109/tvcg.2017.2764459", "10.1109/tvcg.2013.221", "10.1109/vast.2011.6102439", "10.1109/tvcg.2013.213", "10.1109/tmm.2016.2614220", "10.1109/tvcg.2016.2598797", "10.1145/2207676.2208556", "10.1145/1835804.1835827", "10.1109/tvcg.2013.124", "10.2312/conf/eg2013/stars/039-063", "10.1111/cgf.13211", "10.1109/tvcg.2014.2346920", "10.1109/tvcg.2011.239", "10.1016/j.jvlc.2018.08.008", "10.1109/mcg.2018.032421661", "10.1109/tvcg.2017.2744199", "10.1109/tvcg.2019.2934535", "10.1109/tvcg.2018.2864526", "10.1007/978-0-85729-436-4\\_9", "10.1109/vast.2016.7883511", "10.1109/tvcg.2014.2346682", "10.1109/tvcg.2015.2467618", "10.1145/2566486.2567977", "10.1109/tvcg.2017.2745320", "10.1080/136588199241247", "10.1111/cgf.13401", "10.1109/tvcg.2018.2864884", "10.1109/tvcg.2012.291", "10.1109/vast.2012.6400485", "10.1109/pacificvis.2016.7465266", "10.1109/tvcg.2011.232", "10.1109/tvcg.2017.2745083", "10.1109/tvcg.2012.253", "10.1007/s12650-014-0246-x", "10.1109/tvcg.2010.20", "10.1109/tvcg.2014.2346919", "10.1109/visual.2019.8933646", "10.1007/978-0-85729-079-3"], "wos": 1, "children": [], "len": 1}, {"doi": "10.1111/cgf.13989", "year": "2020", "title": "Quantitative Comparison of Time-Dependent Treemaps", "conferenceName": "EuroVis", "authors": "Eduardo Faccin Vernier;Max Sondag;Jo{\\~{a}}o Luiz Dihl Comba;Bettina Speckmann;Alexandru Telea;Kevin Verbeek", "citationCount": "0", "affiliation": "Vernier, E (Corresponding Author), Univ Fed Rio Grande do Sul, Porto Alegre, RS, Brazil.\nVernier, E (Corresponding Author), Univ Groningen, Groningen, Netherlands.\nSondag, M.; Speckmann, B.; Verbeek, K., TU Eindhoven, Eindhoven, Netherlands.\nVernier, E.; Comba, J., Univ Fed Rio Grande do Sul, Porto Alegre, RS, Brazil.\nTelea, A., Univ Utrecht, Utrecht, Netherlands.\nVernier, E., Univ Groningen, Groningen, Netherlands.", "countries": "Netherlands;Brazil", "abstract": "Rectangular treemaps are often the method of choice to visualize large hierarchical datasets. Nowadays such datasets are available over time, hence there is a need for (a) treemaps that can handle time-dependent data, and (b) corresponding quality criteria that cover both a treemap's visual quality and its stability over time. In recent years a wide variety of (stable) treemapping algorithms has been proposed, with various advantages and limitations. We aim to provide insights to researchers and practitioners to allow them to make an informed choice when selecting a treemapping algorithm for specific applications and data. To this end, we perform an extensive quantitative evaluation of rectangular treemaps for time-dependent data. As part of this evaluation we propose a novel classification scheme for time-dependent datasets. Specifically, we observe that the performance of treemapping algorithms depends on the characteristics of the datasets used. We identify four potential representative features that characterize time-dependent hierarchical datasets and classify all datasets used in our experiments accordingly. We experimentally test the validity of this classification on more than 2000 datasets, and analyze the relative performance of 14 state-of-the-art rectangular treemapping algorithms across varying features. Finally, we visually summarize our results with respect to both visual quality and stability to aid users in making an informed choice among treemapping algorithms. All datasets, metrics, and algorithms are openly available to facilitate reuse and further comparative studies.", "keywords": "", "link": "https://doi.org/10.1111/cgf.13989", "refList": ["10.1037/0033-295x.94.2.115", "10.1016/0022-2496(73)90003-5", "10.1109/tvcg.2007.70529", "10.1109/infvis.2005.1532145", "10.1109/tvcg.2013.231", "10.1109/sibgrapi.2018.00027", "10.1561/0600000017", "10.1007/s00371-017-1373-x", "10.1109/tvcg.2017.2745140", "10.1109/tvcg.2006.200", "10.1109/tvcg.2010.79", "10.1016/j.infsof.2016.10.003", "10.1109/tvcg.2010.186", "10.1109/infvis.2001.963283", "10.1109/tvcg.2018.2865265", "10.1016/j.comgeo.2013.12.008", "10.1145/571647.571649", "10.1109/tvcg.2019.2934535", "10.1109/vissoft.2018.00018", "10.5220/0006117500880095", "10.1137/110834032", "10.1109/cvpr.1994.323794", "10.1093/sysbio/syu085", "10.1145/102377.115768", "10.1109/tvcg.2012.108", "10.1145/1056018.1056041", "10.1088/1742-6596/787/1/012007", "10.1057/ivs.2009.29", "10.1111/cgf.13164", "10.1109/iswcs.2014.6933406", "10.1016/j.cor.2013.11.015", "10.1016/j.dam.2006.08.005", "10.1007/978-3-319-57336-6\\_14", "10.1145/2827872"], "wos": 1, "children": [], "len": 1}], "len": 5}, {"doi": "10.1109/tvcg.2019.2934264", "title": "The Validity, Generalizability and Feasibility of Summative Evaluation Methods in Visual Analytics", "year": "2019", "conferenceName": "VAST", "authors": "Mosab Khayat;Morteza Karimzadeh;David S. Ebert;Arif Ghafoor", "citationCount": "1", "affiliation": "Khayat, M (Corresponding Author), Purdue Univ, W Lafayette, IN 47907 USA. Khayat, Mosab; Karimzadeh, Morteza; Ebert, David S.; Ghafoor, Arif, Purdue Univ, W Lafayette, IN 47907 USA. Karimzadeh, Morteza, Univ Colorado, Boulder, CO 80309 USA.", "countries": "USA", "abstract": "Many evaluation methods have been used to assess the usefulness of Visual Analytics (VA) solutions. These methods stem from a variety of origins with different assumptions and goals, which cause confusion about their proofing capabilities. Moreover, the lack of discussion about the evaluation processes may limit our potential to develop new evaluation methods specialized for VA. In this paper, we present an analysis of evaluation methods that have been used to summatively evaluate VA solutions. We provide a survey and taxonomy of the evaluation methods that have appeared in the VAST literature in the past two years. We then analyze these methods in terms of validity and generalizability of their findings, as well as the feasibility of using them. We propose a new metric called summative quality to compare evaluation methods according to their ability to prove usefulness, and make recommendations for selecting evaluation methods based on their summative quality in the VA domain.", "keywords": "Summative evaluation,usefulness,evaluation process,taxonomy,visual analytics", "link": "http://dx.doi.org/10.1109/TVCG.2019.2934264", "refList": ["10.1109/tvcg.2017.2744478", "10.1109/tvcg.2018.2865025", "10.1109/tvcg.2006.85", "10.1109/tvcg.2014.2346331", "10.1109/beliv.2018.8634420", "10.1109/tvcg.2017.2745181", "10.1111/cgf.13677", "10.1109/tvcg.2018.2864844", "10.1109/tvcg.2013.126", "10.1109/tvcg.2018.2864811", "10.1109/infvis.2005.1532147", "10.1177/0956797613504966", "10.1145/2669557.2669579", "10.1109/mcg.2005.102", "10.1109/visual.2003.1250426", "10.1136/bmj.39489.470347.ad", "10.1109/tvcg.2017.2744080", "10.1109/mcg.2009.53", "10.1111/j.1467-8527.2005.00307.x", "10.1109/tvcg.2010.132", "10.1109/tvcg.2018.2864886", "10.1109/tvcg.2018.2864843", "10.1109/tvcg.2018.2865028", "10.1109/tvcg.2018.2865051", "10.1109/tvcg.2018.2865044", "10.1109/tvcg.2018.2865026", "10.1007/978-3-540-71080-6\\_6", "10.1109/tvcg.2018.2865020", "10.1177/1473871611407399", "10.1109/tvcg.2018.2864504", "10.1109/tvcg.2018.2864526", "10.1109/tvcg.2005.53", "10.1109/tvcg.2018.2864905", "10.1049/sej.1991.0040", "10.1109/tvcg.2015.2513410", "10.1109/tvcg.2017.2711030", "10.1109/tvcg.2011.279", "10.1109/vast.2017.8585505", "10.1147/jrd.2010.2042914", "10.1016/s0378-7206(98)00044-5", "10.1145/2993901.2993913", "10.1109/tvcg.2018.2865041", "10.1109/tvcg.2018.2864812", "10.1109/tvcg.2017.2744758", "10.1145/1168149.1168158", "10.1109/tvcg.2017.2745279", "10.1109/tvcg.2012.213", "10.1109/tvcg.2017.2744738", "10.1109/tvcg.2017.2745083", "10.1109/tvcg.2018.2864826", "10.1145/1377966.1377974", "10.1109/apec.2009.4802646", "10.1145/1168149.1168152", "10.1016/j.jss.2008.03.059", "10.1109/vast.2017.8585484", "10.1109/tvcg.2017.2744818", "10.1109/tvcg.2017.2744358", "10.1109/tvcg.2018.2864499", "10.1109/tvcg.2018.2865042", "10.1109/tvcg.2017.2744898"], "wos": 1, "children": [{"doi": "10.1109/tvcg.2020.3030388", "title": "Visualization of Human Spine Biomechanics for Spinal Surgery", "year": "2020", "conferenceName": "SciVis", "authors": "Pepe Eulzer;Sabine Bauer;Francis Kilian;Kai Lawonn", "citationCount": "0", "affiliation": "Eulzer, P (Corresponding Author), Univ Jena, Jena, Germany. Eulzer, Pepe; Lawonn, Kai, Univ Jena, Jena, Germany. Bauer, Sabine, Univ Koblenz Landau, Koblenz, Germany. Kilian, Francis, Cath Clin Koblenz Montabaur, Dept Spine Surg, Koblenz, Germany.", "countries": "Germany", "abstract": "We propose a visualization application, designed for the exploration of human spine simulation data. Our goal is to support research in biomechanical spine simulation and advance efforts to implement simulation-backed analysis in surgical applications. Biomechanical simulation is a state-of-the-art technique for analyzing load distributions of spinal structures. Through the inclusion of patient-specific data, such simulations may facilitate personalized treatment and customized surgical interventions. Difficulties in spine modelling and simulation can be partly attributed to poor result representation, which may also be a hindrance when introducing such techniques into a clinical environment. Comparisons of measurements across multiple similar anatomical structures and the integration of temporal data make commonly available diagrams and charts insufficient for an intuitive and systematic display of results. Therefore, we facilitate methods such as multiple coordinated views, abstraction and focus and context to display simulation outcomes in a dedicated tool. $\\mathrm{By}$ linking the result data with patient-specific anatomy, we make relevant parameters tangible for clinicians. Furthermore, we introduce new concepts to show the directions of impact force vectors, which were not accessible before. We integrated our toolset into a spine segmentation and simulation pipeline and evaluated our methods with both surgeons and biomechanical researchers. When comparing our methods against standard representations that are currently in use, we found increases in accuracy and speed in data exploration tasks. $\\mathrm{in}$ a qualitative review, domain experts deemed the tool highly useful when dealing with simulation result data, which typically combines time-dependent patient movement and the resulting force distributions on spinal structures.", "keywords": "Medical visualization,bioinformatics,coordinated views,focus and context,biomechanical simulation", "link": "http://dx.doi.org/10.1109/TVCG.2020.3030388", "refList": ["10.1109/tvcg.2018.2864903", "10.1177/1473871613510429", "10.1093/ehjqcco/qcz052", "10.1109/tvcg.2007.70594", "10.1109/tvcg.2018.2865076", "10.1055/s-0039-1687862", "10.1109/visual.1990.146375", "10.1109/tvcg.2017.2744198", "10.1016/j.ijmedinf.2014.10.001", "10.1109/tvcg.2013.124", "10.1016/j.jacc", "10.1111/cgf.13167", "10.17705/1thci.00055", "10.1136/bmjqs.2009.037895", "10.1109/tvcg.2013.238", "10.1109/tvcg.2018.2865240", "10.1186/1471-2261-6-34", "10.1109/tvcg.2019.2934264", "10.1109/tvcg.2013.200", "10.1109/tvcg.2011.209", "10.1109/tvcg.2014.2346682", "10.1109/tvcg.2015.2467091", "10.1136/bmjopen-2019-033208", "10.1109/beliv.2018.8634027", "10.1109/tvcg.2012.213", "10.1109/tvcg.2015.2467191", "10.1109/tvcg.2015.2467325", "10.1145/2133806.2133821", "10.1145/1806799.1806866", "10.1108/02635570610688869", "10.1002/hbm.20701", "10.1561/1100000039", "10.1145/3025453.3025645", "10.1109/tvcg.2009.111", "10.1109/tvcg.2013.120", "10.1109/tvcg.2016.2599030"], "wos": 1, "children": [], "len": 1}], "len": 3}, {"doi": "10.1111/cgf.13673", "year": "2019", "title": "Multiple Views: different meanings and collocated words", "conferenceName": "EuroVis", "authors": "Jonathan C. Roberts;Hayder Al{-}Maneea;Peter W. S. Butcher;Robert Lew;Geraint Rees;Nirwan Sharma;Ana Frankenberg{-}Garcia", "citationCount": "1", "affiliation": "Roberts, JC (Corresponding Author), Bangor Univ, Bangor, Gwynedd, Wales.\nRoberts, J. C.; Al-maneea, H.; Butcher, P. W. S.; Sharma, N., Bangor Univ, Bangor, Gwynedd, Wales.\nAl-maneea, H., Basrah Univ, Basrah, Iraq.\nLew, R.; Rees, G., Adam Mickiewicz Univ, Poznan, Poland.\nFrankenberg-Garcia, A., Univ Surrey, Guildford, Surrey, England.", "countries": "Poland;Wales;England;Iraq", "abstract": "We report on an in-depth corpus linguistic study on multiple views' terminology and word collocation. We take a broad interpretation of these terms, and explore the meaning and diversity of their use in visualisation literature. First we explore senses of the term multiple views' (e.g., multiple views' can mean juxtaposition, many viewport projections or several alternative opinions). Second, we investigate term popularity and frequency of occurrences, investigating usage of multiple' and view' (e.g., multiple views, multiple visualisations, multiple sets). Third, we investigate word collocations and terms that have a similar sense (e.g., multiple views, side-by-side, small multiples). We built and used several corpora, including a 6-million-word corpus of all IEEE Visualisation conference articles published in IEEE Transactions on Visualisation and Computer Graphics 2012 to 2017. We draw on our substantial experience from early work in coordinated and multiple views, and with collocation analysis develop several lists of terms. This research provides insight into term use, a reference for novice and expert authors in visualisation, and contributes a taxonomy of multiple view' terms.", "keywords": "", "link": "https://doi.org/10.1111/cgf.13673", "refList": ["10.1109/tvcg.2017.2744359", "10.1109/38.31462", "10.1109/cmv.2003.1215002", "10.2307/2289444", "10.1016/j.ijhcs.2011.02.007", "10.1017/s0022112091210654", "10.1016/b978-008044531-1/50426-7", "10.1109/cmv.2003.1215001", "10.1109/tvcg.2013.134", "10.1117/12.378894", "10.1037/0096-1523.21.6.1494", "10.1057/palgrave.ivs.9500086", "10.1109/iv.2011.42", "10.1109/tvcg.2017.2744199", "10.4324/9780203810088", "10.1145/1321440.1321580", "10.1109/tvcg.2015.2467271", "10.1016/j.learninstruc.2006.03.001", "10.1145/345513.345282", "10.1007/s40607-014-0009-9", "10.1109/tvcg.2017.2743859", "10.1109/infvis.1997.636761", "10.1109/tvcg.2013.219", "10.1007/978-3-319-55627-7", "10.1109/tvcg.2009.111", "10.1109/iv.2008.21", "10.1109/infvis.2002.1173157", "10.1109/mcg.2014.82", "10.1145/3143699.3143717", "10.1109/tvcg.2012.226", "10.1145/345513.345271", "10.2478/jazcas-2018-0006", "10.1145/2556288.2556969", "10.1109/visual.1998.745282", "10.1145/1276377.1276427", "10.1109/infvis.2001.963283", "10.1007/978-1-4471-6497-5\\_1", "10.1109/visual.1994.346302", "10.1057/palgrave.ivs.9500068", "10.1109/tvcg.2006.160", "10.1109/visual.1990.146374", "10.1109/tvcg.2016.2614803", "10.1177/1473871611416549", "10.1109/tvcg.2017.2745878", "10.1109/tvcg.2006.69", "10.1109/tpami.1983.4767367", "10.1109/visual.1991.175794", "10.1109/tvcg.2017.2744159", "10.1109/tvcg.2017.2744198", "10.1109/32.328995", "10.1016/j.jeap.2018.07.003", "10.1016/j.geomorph.2012.08.021", "10.1109/tvcg.2014.2346920", "10.1109/2.917550", "10.1017/s0958344018000150", "10.1109/tvcg.2009.94", "10.1179/2051819613z.0000000003", "10.1109/vast.2008.4677370", "10.1117/12.309533", "10.1109/tvcg.2014.2346747", "10.1075/ijcl.13.4.06ray", "10.1007/s12650-015-0323-9", "10.1109/tvcg.2006.178", "10.1109/tvcg.2016.2615308", "10.2307/1269768", "10.2307/4132312", "10.1109/tvcg.2018.2864903", "10.1109/mis.2006.100", "10.1109/iv.1998.694193", "10.1007/s11192-015-1830-0", "10.1109/tvcg.2017.2744080", "10.1111/j.1467-9280.1997.tb00442.x", "10.1109/cmv.2007.20", "10.1109/infvis.2003.1249006", "10.1109/tvcg.2017.2745941", "10.1016/s1364-6613(99)01332-7", "10.1145/989863.989893", "10.1109/tse.1985.232211", "10.1109/tvcg.2017.2744184", "10.1109/infvis.2004.12", "10.1075/ijcl.17.3.04har", "10.1109/tvcg.2010.179", "10.1016/j.jss.2006.05.024", "10.1109/cmv.2003.1215005", "10.1109/tvcg.2017.2744358", "10.1145/2992154.2996365", "10.1109/tvcg.2016.2598827"], "wos": 1, "children": [{"doi": "10.1109/tvcg.2020.3030338", "title": "Composition and Configuration Patterns in Multiple-View Visualizations", "year": "2020", "conferenceName": "InfoVis", "authors": "Xi Chen;Wei Zeng 0004;Yanna Lin;Hayder Al-Maneea;Jonathan Roberts 0002;Remco Chang", "citationCount": "0", "affiliation": "Zeng, W (Corresponding Author), Chinese Acad Sci, Shenzhen Inst Adv Technol, Shenzhen, Peoples R China. Chen, Xi; Zeng, Wei; Lin, Yanna, Chinese Acad Sci, Shenzhen Inst Adv Technol, Shenzhen, Peoples R China. AI-maneea, Hayder Mahdi; Roberts, Jonathan, Bangor Univ, Bangor, Gwynedd, Wales. Chang, Remco, Tufts Univ, Medford, MA 02155 USA.", "countries": "USA;Wales;China", "abstract": "Multiple-view visualization (MV) is a layout design technique often employed to help users see a large number of data attributes and values in a single cohesive representation. Because of its generalizability, the MV design has been widely adopted by the visualization community to help users examine and interact with large, complex, and high-dimensional data. However, although ubiquitous, there has been little work to categorize and analyze MVs in order to better understand its design space. As a result, there has been little to no guideline in how to use the MV design effectively. In this paper, we present an in-depth study of how MVs are designed in practice. We focus on two fundamental measures of multiple-view patterns: composition, which quantifies what view types and how many are there; and configuration, which characterizes spatial arrangement of view layouts in the display space. We build a new dataset containing 360 images of MVs collected from IEEE VIS, EuroVis, and PacificVis publications 2011 to 2019, and make fine-grained annotations of view types and layouts for these visualization images. From this data we conduct composition and configuration analyses using quantitative metrics of term frequency and layout topology. We identify common practices around MVs, including relationship of view types, popular view layouts, and correlation between view types and layouts. We combine the findings into a MV recommendation system, providing interactive tools to explore the design space, and support example-based design.", "keywords": "Multiple views,design pattern,quantitative analysis,example-based design", "link": "http://dx.doi.org/10.1109/TVCG.2020.3030338", "refList": ["10.1109/tvcg.2018.2865235", "10.1109/tvcg.2016.2615308", "10.1145/2642918.2647398", "10.1177/1473871611416549", "10.1109/tvcg.2019.2934810", "10.1109/tvcg.2014.48", "10.1109/tvcg.2018.2864903", "10.1145/345513.345271", "10.1109/iv.1998.694193", "10.1109/tvcg.2007.70594", "10.1109/tvcg.2017.2744019", "10.1109/tvcg.2011.185", "10.1109/tvcg.2015.2467194", "10.1109/visual.1991.175815", "10.14778/2831360.2831371", "10.1109/mcg.2019.2924636", "10.1111/cgf.13673", "10.1111/cgf.12131", "10.1109/tvcg.2017.2744198", "10.1145/108360.108361", "10.1109/vl.1996.545307", "10.1109/tvcg.2017.2745140", "10.1109/cmv.2007.20", "10.1145/198366.198376", "10.1145/2508363.2508405", "10.1111/cgf.12114", "10.1109/icde.2018.00019", "10.1109/tvcg.2017.2787113", "10.1109/tvcg.2018.2865240", "10.1111/cgf.13380", "10.1111/cgf.12902", "10.1109/vast.2015.7347628", "10.2307/2288400", "10.1109/infvis.2004.12", "10.1145/102377.115768", "10.1109/tvcg.2009.179", "10.1109/2945.981851", "10.1109/tvcg.2007.70521", "10.1109/pacificvis.2012.6183556", "10.1145/2213836", "10.1109/tvcg.2013.234", "10.1109/iv.2008.87"], "wos": 1, "children": [], "len": 1}], "len": 3}], "len": 15}, "index": 654, "embedding": [1.4710628986358643, 1.1810777187347412, -1.03950035572052, -1.6313953399658203, -0.6195418834686279, 0.16650904715061188, -0.7477038502693176, 0.9505431056022644, -0.41535258293151855, 1.1170318126678467, -0.0716162770986557, 0.5694665312767029, -0.1268409788608551, 1.227454423904419, -0.4577621519565582, 2.3668642044067383, 0.9212180376052856, 4.094339370727539, -0.6218824982643127, 1.9351866245269775, -0.06630208343267441, 1.176155924797058, 0.41834375262260437, 1.8637350797653198, -2.4589109420776367, 1.2533942461013794, -0.4969606399536133, 1.2066245079040527, 1.6994966268539429, -0.7525829672813416, 0.2103341668844223, 1.2330654859542847], "projection": [-0.5430283546447754, 8.2163667678833], "size": 8, "height": 3, "width": 4}