{"data": {"doi": "10.1109/tvcg.2019.2934803", "title": "There Is No Spoon: Evaluating Performance, Space Use, and Presence with Expert Domain Users in Immersive Analytics", "year": "2019", "conferenceName": "InfoVis", "authors": "Andrea Batch;Andrew Cunningham;Maxime Cordeil;Niklas Elmqvist;Tim Dwyer;Bruce H. Thomas;Kim Marriott", "citationCount": "6", "affiliation": "Batch, A (Corresponding Author), Univ Maryland, College Pk, MD 20742 USA. Batch, Andrea; Elmqvist, Niklas, Univ Maryland, College Pk, MD 20742 USA. Cunningham, Andrew; Thomas, Bruce H., Univ South Australia Adelaide, Adelaide, SA, Australia. Cordeil, Maxime; Dwyer, Tim; Marriott, Kim, Univ Melbourne, Melbourne, Vic, Australia.", "countries": "USA;Australia", "abstract": "Immersive analytics turns the very space surrounding the user into a canvas for data analysis, supporting human cognitive abilities in myriad ways. We present the results of a design study, contextual inquiry, and longitudinal evaluation involving professional economists using a Virtual Reality (VR) system for multidimensional visualization to explore actual economic data. Results from our preregistered evaluation highlight the varied use of space depending on context (exploration vs. presentation), the organization of space to support work, and the impact of immersion on navigation and orientation in the 3D analysis space.", "keywords": "Design study,evaluation,economic analysis,immersive analytics", "link": "http://dx.doi.org/10.1109/TVCG.2019.2934803", "refList": ["10.1145/3139131.3139141", "10.1109/2.60882", "10.1007/978-3-030-01388-2\\_1", "10.1109/38.250911", "10.1145/302979.303166", "10.1073/pnas.1306779110", "10.1109/tvcg.2012.219", "10.1162/105474698565686", "10.1016/0364-0213(94)90007-8", "10.1145/642611.642650", "10.1162/pres.1992.1.4.482", "10.1007/978-3-030-01388-2", "10.1109/2.19829", "10.1111/1467-8284.00096", "10.1007/978-3-030-01388-2\\_7", "10.1109/hicss.2011.339", "10.1109/tvcg.2016.2599107", "10.1145/3173574.3173664", "10.1145/1008653.1008669", "10.1109/tvcg.2017.2743990", "10.1145/642611", "10.1145/3126594.3126613", "10.1007/978-94-007-6833-89", "10.1162/pres\\_a\\_00124", "10.1016/0004-3702(94)00017-u", "10.1109/tvcg.2014.20", "10.1145/1168149.1168158", "10.1109/visual.1995.480800", "10.1109/icsens.2015.7370446", "10.1207/s15516709cog1701\\_1", "10.1162/105474601300343603", "10.1109/tvcg.2016.2518135", "10.1109/tvcg.2012.213", "10.1016/s0097-8493(02)00113-9", "10.1162/pres.1994.3.2.130", "10.1109/tvcg.2018.2865191", "10.1109/visual.1990.146402", "10.1162/105474601300343612", "10.1145/2702123.2702406", "10.1162/pres.1992.1.1.120", "10.1145/3009939.3009955", "10.1109/glocom.2015.7417476", "10.1162/pres\\_a\\_00261"], "wos": 1, "children": [{"doi": "10.1109/tvcg.2020.3030456", "title": "Cartographic Relief Shading with Neural Networks", "year": "2020", "conferenceName": "InfoVis", "authors": "Bernhard Jenny;Magnus Heitzler;Dilpreet Singh;Marianna Farmakis-Serebryakova;Jeffery Chieh Liu;Lorenz Hurni", "citationCount": "4", "affiliation": "Jenny, B (Corresponding Author), Monash Univ, Melbourne, Vic, Australia. Jenny, Bernhard; Singh, Dilpreet; Liu, Jeffery Chieh, Monash Univ, Melbourne, Vic, Australia. Heitzler, Magnus; Farmakis-Serebryakova, Marianna; Hurni, Lorenz, Swiss Fed Inst Technol, Inst Cartog \\& Geoinformat, Zurich, Switzerland.", "countries": "Switzerland;Australia", "abstract": "Shaded relief is an effective method for visualising terrain on topographic maps, especially when the direction of illumination is adapted locally to emphasise individual terrain features. However, digital shading algorithms are unable to fully match the expressiveness of hand-crafted masterpieces, which are created through a laborious process by highly specialised cartographers. We replicate hand-drawn relief shading using U-Net neural networks. The deep neural networks are trained with manual shaded relief images of the Swiss topographic map series and terrain models of the same area. The networks generate shaded relief that closely resemble hand-drawn shaded relief art. The networks learn essential design principles from manual relief shading such as removing unnecessary terrain details, locally adjusting the illumination direction to accentuate individual terrain features, and varying brightness to emphasise larger landforms. Neural network shadings are generated from digital elevation models in a few seconds, and a study with 18 relief shading experts found that they are of high quality.", "keywords": "Relief shading,shaded relief,hillshade,neural rendering,illustrative visualisation,image-to-image translation", "link": "http://dx.doi.org/10.1109/TVCG.2020.3030456", "refList": ["10.1145/1456650.1456652", "10.1145/1145/1556262.1556270", "10.1145/345513.345271", "10.1109/tvcg.2019.2934803", "10.1145/3180658", "10.1109/tridui.2006.1618264", "10.3389/fict.2018.00015", "10.1109/vr.2018.8447558", "10.1518/hfes.45.1.160.27234", "10.1145/3290605.3300377", "10.1089/cpb.2006.9.157", "10.1007/s00779-011-0500-3", "10.1109/vl.1996.545307", "10.1109/tvcg.2019.2934415", "10.1109/5.726791", "10.1145/3290605.3300288", "10.1109/tvcg.2017.2745941", "10.1109/vr.2001.913779", "10.1145/586081.586086", "10.18637/jss.v067.i01", "10.1145/1502800.1502805", "10.1145/1165734.1165736", "10.1145/3126594.3126613", "10.1109/tvcg.2008.109", "10.1109/tvcg.2017.2744184", "10.1016/j.cola.2019.100937", "10.1109/visual.2019.8933545", "10.1145/3290605.3300555", "10.1111/cgf.13431", "10.1109/tvcg.2019.2934395", "10.1109/vr.2019.8798340", "10.1145/3025453.3026046", "10.1109/vr.2019.8797871", "10.1145/3290605.3300752", "10.1109/tvcg.2016.2520921", "10.1109/tvcg.2018.2865191", "10.1145/1970378.1970384", "10.1109/tvcg.2019.2934208", "10.18637/jss.v069.i01", "10.1162/105474698565659", "10.1145/1124772.1124775", "10.1109/vrais.1997.583043"], "wos": 1, "children": [], "len": 1}, {"doi": "10.1109/tvcg.2020.3030460", "title": "Personal Augmented Reality for Information Visualization on Large Interactive Displays", "year": "2020", "conferenceName": "InfoVis", "authors": "Patrick Reipschl\u00e4ger;Tamara Flemisch;Raimund Dachselt", "citationCount": "0", "affiliation": "Reipschlager, P (Corresponding Author), Tech Univ Dresden, Interact Media Lab, Dresden, Germany. Reipschlager, Patrick; Flemisch, Tamara; Dachselt, Raimund, Tech Univ Dresden, Interact Media Lab, Dresden, Germany. Dachselt, Raimund, Tech Univ Dresden, Ctr Tactile Internet CeTi, Dresden, Germany. Dachselt, Raimund, Tech Univ Dresden, Cluster Excellence Phys Life, Dresden, Germany.", "countries": "Germany", "abstract": "In this work we propose the combination of large interactive displays with personal head-mounted Augmented Reality (AR) for information visualization to facilitate data exploration and analysis. Even though large displays provide more display space, they are challenging with regard to perception, effective multi-user support, and managing data density and complexity. To address these issues and illustrate our proposed setup, we contribute an extensive design space comprising first, the spatial alignment of display, visualizations, and objects in AR space. Next, we discuss which parts of a visualization can be augmented. Finally, we analyze how AR can be used to display personal views in order to show additional information and to minimize the mutual disturbance of data analysts. Based on this conceptual foundation, we present a number of exemplary techniques for extending visualizations with AR and discuss their relation to our design space. We further describe how these techniques address typical visualization problems that we have identified during our literature research. To examine our concepts, we introduce a generic AR visualization framework as well as a prototype implementing several example techniques. In order to demonstrate their potential, we further present a use case walkthrough in which we analyze a movie data set. From these experiences, we conclude that the contributed techniques can be useful in exploring and understanding multivariate data. We are convinced that the extension of large displays with AR for information visualization has a great potential for data analysis and sense-making.", "keywords": "Augmented Reality,Information Visualization,InfoVis,Large Displays,Immersive Analytics,Physical Navigation,Multiple Coordinated Views", "link": "http://dx.doi.org/10.1109/TVCG.2020.3030460", "refList": ["10.1109/tvcg.2008.153", "10.1109/tvcg.2013.166", "10.1109/tvcg.2012.275", "10.1109/tvcg.2019.2934803", "10.1177/1473871611412817", "10.1109/tvcg.2017.2745958", "10.1109/tvcg.2019.2934415", "10.1109/tvcg.2009.162", "10.1109/mcg.2019.2897927", "10.1109/tvcg.2017.2744199", "10.1145/3126594.3126613", "10.1145/3173574.3173759", "10.1145/3290605.3300360", "10.1145/2858036.2858158", "10.1145/642611.642695", "10.1145/2702123.2702312", "10.1109/3dui.2014.6798833", "10.1109/tvcg.2018.2865235", "10.1111/cgf.13213", "10.1109/mcg.2014.82", "10.1145/3343055.3359718", "10.1007/978-3-030-01388-2\\_1", "10.1145/2858036.2858524", "10.1145/3173574.3173610", "10.1145/2817721.2817735", "10.1145/1166253.1166280", "10.1109/vr46266.2020.1582298687237", "10.1145/2576099", "10.1145/3173574.3173664", "10.1109/infvis.2005.1532136", "10.1080/15384047.2020.1806642", "10.1023/a:1021271517844", "10.1109/tvcg.2019.2903956", "10.1177/1473871611415997", "10.1145/2817721.2823505", "10.1145/3290605.3300521", "10.1016/s1071-5819(03)00021-1", "10.1145/2470654.2466431", "10.1109/vr.2019.8797733", "10.1177/1473871611416549", "10.1109/tvcg.2011.287", "10.2312/eurp.20191136", "10.1111/cgf.12871", "10.1145/3290605.3300288", "10.1109/3dui.2014.6798842", "10.1145/302979.303113", "10.1145/3343055.3359709", "10.1109/tvcg.2013.197", "10.1007/s11071-020-05736-x", "10.1109/vr46266.2020.00-23", "10.1109/tvcg.2016.2592906", "10.1109/mcg.2019.2898856", "10.1109/tvcg.2016.2640960", "10.1109/tvcg.2017.2745258", "10.1145/2817721.2817726", "10.1109/tvcg.2018.2865192", "10.1109/bigdata.2018.8622521", "10.1109/tvcg.2012.204", "10.1080/07370024.2019.1697697", "10.1109/vr46266.2020.1581122519414", "10.1109/vr46266.2020.00-20", "10.1109/pacificvis.2019.00010", "10.1145/3359996.3364242", "10.1145/3173574.3173593", "10.1109/ismar-adjunct.2016.0030", "10.1145/2317956.2318025", "10.1109/cmv.2007.20", "10.1080/07370020902739429", "10.1109/visual.2019.8933673", "10.1109/tvcg.2016.2598608", "10.1145/2702123.2702331", "10.1109/tvcg.2017.2745941", "10.1145/1936652.1936676", "10.1117/12.2521648", "10.1145/3009939.3009945", "10.1111/cgf.13206", "10.1109/tvcg.2013.163", "10.1109/tvcg.2017.2744184", "10.1145/2785830.2785871", "10.1109/tvcg.2012.251"], "wos": 1, "children": [], "len": 1}, {"doi": "10.1109/tvcg.2020.3030450", "title": "Shared Surfaces and Spaces: Collaborative Data Visualisation in a Co-located Immersive Environment", "year": "2020", "conferenceName": "InfoVis", "authors": "Benjamin Lee;Xiaoyun Hu;Maxime Cordeil;Arnaud Prouzeau;Bernhard Jenny;Tim Dwyer", "citationCount": "0", "affiliation": "Lee, B (Corresponding Author), Monash Univ, Clayton, Vic, Australia. Lee, Benjamin; Hu, Xiaoyun; Cordeil, Maxime; Prouzeau, Arnaud; Jenny, Bernhard; Dwyer, Tim, Monash Univ, Clayton, Vic, Australia.", "countries": "Australia", "abstract": "Immersive technologies offer new opportunities to support collaborative visual data analysis by providing each collaborator a personal, high-resolution view of a flexible shared visualisation space through a head mounted display. However, most prior studies of collaborative immersive analytics have focused on how groups interact with surface interfaces such as tabletops and wall displays. This paper reports on a study in which teams of three co-located participants are given flexible visualisation authoring tools to allow a great deal of control in how they structure their shared workspace. They do so using a prototype system we call FIESTA: the Free-roaming Immersive Environment to Support Team-based Analysis. Unlike traditional visualisation tools, FIESTA allows users to freely position authoring interfaces and visualisation artefacts anywhere in the virtual environment, either on virtual surfaces or suspended within the interaction space. Our participants solved visual analytics tasks on a multivariate data set, doing so individually and collaboratively by creating a large number of 2D and 3D visualisations. Their behaviours suggest that the usage of surfaces is coupled with the type of visualisation used, often using walls to organise 2D visualisations, but positioning 3D visualisations in the space around them. Outside of tightly-coupled collaboration, participants followed social protocols and did not interact with visualisations that did not belong to them even if outside of its owner's personal workspace.", "keywords": "Immersive analytics,collaboration,virtual reality,qualitative study,multivariate data", "link": "http://dx.doi.org/10.1109/TVCG.2020.3030450", "refList": ["10.1109/tvcg.2008.153", "10.1007/s10606-004-5062-8", "10.1145/3343055.3359718", "10.1109/pacificvis.2019.00010", "10.1109/tvcg.2019.2914677", "10.1016/0020-7373(91)90039-a", "10.1109/tvcg.2011.287", "10.1117/12.2005484", "10.1109/mmul.2009.35", "10.1109/tvcg.2019.2934803", "10.1145/3359996.3364242", "10.1109/immersive.2016.7932384", "10.1016/j.future.2008.07.015", "10.1057/palgrave.ivs.9500167", "10.1109/mcg.2019.2898941", "10.1145/3343055.3360746", "10.1007/978-3-319-45853-3\\_8", "10.1145/2576099", "10.1145/2858036.2858039", "10.1109/tvcg.2016.2599107", "10.1145/3173574.3173664", "10.1007/978-3-030-01388-2\\_2", "10.1109/vr.2019.8797978", "10.1145/3126594.3126613", "10.1109/tvcg.2016.2592906", "10.1109/mcg.2019.2898856", "10.1007/978-3-030-01388-2\\_8", "10.1023/a:1021271517844", "10.1109/bigdata.2014.7004282", "10.1109/tvcg.2019.2934395", "10.1109/ismar.2010.5643530", "10.1007/978-3-030-01388-22", "10.1145/2133806.2133821", "10.1109/3dvis.2014.7160093", "10.1145/2556288.2557058", "10.1109/vr.2019.8797845"], "wos": 1, "children": [], "len": 1}, {"doi": "10.1109/tvcg.2020.3030334", "title": "Uplift: A Tangible and Immersive Tabletop System for Casual Collaborative Visual Analytics", "year": "2020", "conferenceName": "VAST", "authors": "Barrett Ens;Sarah Goodwin;Arnaud Prouzeau;Fraser Anderson;Florence Y. Wang;Samuel Gratzl;Zac Lucarelli;Brendan Moyle;Jim Smiley;Tim Dwyer", "citationCount": "0", "affiliation": "Ens, B (Corresponding Author), Monash Univ, Clayton, Vic, Australia. Ens, Barrett; Goodwin, Sarah; Prouzeau, Arnaud; Wang, Florence Y.; Gratzl, Samuel; Lucarelli, Zac; Moyle, Brendan; Smiley, Jim; Dwyer, Tim, Monash Univ, Clayton, Vic, Australia. Anderson, Fraser, Autodesk Res, Toronto, ON, Canada.", "countries": "Canada;Australia", "abstract": "Collaborative visual analytics leverages social interaction to support data exploration and sensemaking. These processes are typically imagined as formalised, extended activities, between groups of dedicated experts, requiring expertise with sophisticated data analysis tools. However, there are many professional domains that benefit from support for short 'bursts' of data exploration between a subset of stakeholders with a diverse breadth of knowledge. Such 'casual collaborative\u2019 scenarios will require engaging features to draw users' attention, with intuitive, 'walk-up and use\u2019 interfaces. This paper presents Uplift, a novel prototype system to support 'casual collaborative visual analytics' for a campus microgrid, co-designed with local stakeholders. An elicitation workshop with key members of the building management team revealed relevant knowledge is distributed among multiple experts in their team, each using bespoke analysis tools. Uplift combines an engaging 3D model on a central tabletop display with intuitive tangible interaction, as well as augmented-reality, mid-air data visualisation, in order to support casual collaborative visual analytics for this complex domain. Evaluations with expert stakeholders from the building management and energy domains were conducted during and following our prototype development and indicate that Uplift is successful as an engaging backdrop for casual collaboration. Experts see high potential in such a system to bring together diverse knowledge holders and reveal complex interactions between structural, operational, and financial aspects of their domain. Such systems have further potential in other domains that require collaborative discussion or demonstration of models, forecasts, or cost-benefit analyses to high-level stakeholders.", "keywords": "Data visualisation,tangible and embedded interaction,augmented reality,immersive analytics", "link": "http://dx.doi.org/10.1109/TVCG.2020.3030334", "refList": ["10.1109/vr.2019.8797733", "10.1109/tvcg.2018.2865235", "10.1111/cgf.13213", "10.1109/mcg.2014.82", "10.1109/tvcg.2008.153", "10.1145/1240624.1240701", "10.1109/tvcg.2013.166", "10.1177/1473871611416549", "10.1145/3343055.3359718", "10.1109/pacificvis.2019.00010", "10.1109/tvcg.2012.275", "10.1109/vr46266.2020.00-20", "10.1109/tvcg.2011.287", "10.3788/co.20201301.0001", "10.1109/tvcg.2019.2934803", "10.1145/3173574.3173610", "10.1145/2858036.2858524", "10.1145/3359996.3364242", "10.1145/3173574.3173593", "10.1177/1473871611412817", "10.1109/tvcg.2017.2745958", "10.1111/cgf.12871", "10.1145/2817721.2817735", "10.1145/2317956.2318025", "10.1145/1166253.1166280", "10.1007/978-3-319-73207-7", "10.1109/tvcg.2019.2934415", "10.1109/cmv.2007.20", "10.1109/vr46266.2020.1582298687237", "10.1109/tvcg.2009.162", "10.1109/visual.2019.8933673", "10.1109/mcg.2019.2897927", "10.1145/2702123.2702331", "10.1145/2576099", "10.1145/3290605.3300288", "10.1145/3173574.3173664", "10.1109/infvis.2005.1532136", "10.1109/3dui.2014.6798842", "10.1145/302979.303113", "10.1145/3343055.3359709", "10.1109/tvcg.2016.2598608", "10.1109/tvcg.2017.2744199", "10.1145/1936652.1936676", "10.1117/12.2521648", "10.1080/15384047.2020.1806642", "10.1109/tvcg.2013.197", "10.1145/3009939.3009945", "10.1145/3126594.3126613", "10.1109/tvcg.2016.2592906", "10.1109/mcg.2019.2898856", "10.1111/cgf.13206", "10.1109/tvcg.2013.163", "10.1109/tvcg.2016.2640960", "10.1145/3173574.3173759", "10.1109/tvcg.2017.2744184", "10.1109/tvcg.2017.2745258", "10.1023/a:1021271517844", "10.1145/2817721.2817726", "10.1145/2858036.2858158", "10.1109/tvcg.2018.2865192", "10.1109/bigdata.2018.8622521", "10.1145/642611.642695", "10.1145/2785830.2785871", "10.1109/tvcg.2012.204", "10.1080/07370024.2019.1697697", "10.1109/tvcg.2019.2903956", "10.1109/tcyb.2020.2970556", "10.1109/tvcg.2012.251", "10.1145/2702123.2702312", "10.1177/1473871611415997", "10.1145/2817721.2823505", "10.1145/3290605.3300521", "10.2312/eurp", "10.1145/2470654.2466431"], "wos": 1, "children": [], "len": 1}], "len": 9}, "index": 963, "embedding": [1.851575493812561, 1.4278056621551514, 3.201610565185547, 4.702564716339111, -0.6602144837379456, 0.16650904715061188, -0.706787109375, 2.1824324131011963, -0.43060755729675293, -0.8515991568565369, 1.6109501123428345, 1.5490641593933105, -0.13366082310676575, 2.302902936935425, 0.9226180911064148, 1.3960328102111816, 0.5581522583961487, 0.06482167541980743, -0.6607173681259155, 2.400428056716919, -0.06630208343267441, 2.125779390335083, 0.44703999161720276, -0.1414090394973755, 1.9347596168518066, 0.08472851663827896, -0.5077023506164551, 0.30858543515205383, 2.6777374744415283, 1.7380226850509644, 1.770717740058899, 2.1370186805725098], "projection": [-3.652550458908081, 7.734662055969238], "size": 5, "height": 2, "width": 4}