{"data": {"doi": "10.1109/tvcg.2014.2346333", "title": "Low-Pass Filtered Volumetric Shadows", "year": "2014", "conferenceName": "SciVis", "authors": "Marco Ament;Filip Sadlo;Carsten Dachsbacher;Daniel Weiskopf", "citationCount": "15", "affiliation": "Ament, M (Corresponding Author), Karlsruhe Inst Technol, D-76021 Karlsruhe, Germany. Ament, Marco; Dachsbacher, Carsten, Karlsruhe Inst Technol, D-76021 Karlsruhe, Germany. Sadlo, Filip; Weiskopf, Daniel, Univ Stuttgart, Stuttgart, Germany.", "countries": "Germany", "abstract": "We present a novel and efficient method to compute volumetric soft shadows for interactive direct volume visualization to improve the perception of spatial depth. By direct control of the softness of volumetric shadows, disturbing visual patterns due to hard shadows can be avoided and users can adapt the illumination to their personal and application-specific requirements. We compute the shadowing of a point in the data set by employing spatial filtering of the optical depth over a finite area patch pointing toward each light source. Conceptually, the area patch spans a volumetric region that is sampled with shadow rays; afterward, the resulting optical depth values are convolved with a low-pass filter on the patch. In the numerical computation, however, to avoid expensive shadow ray marching, we show how to align and set up summed area tables for both directional and point light sources. Once computed, the summed area tables enable efficient evaluation of soft shadows for each point in constant time without shadow ray marching and the softness of the shadows can be controlled interactively. We integrated our method in a GPU-based volume renderer with ray casting from the camera, which offers interactive control of the transfer function, light source positions, and viewpoint, for both static and time-dependent data sets. Our results demonstrate the benefit of soft shadows for visualization to achieve user-controlled illumination with many-point lighting setups for improved perception combined with high rendering speed.", "keywords": "Direct volume rendering, volume illumination, soft shadows, filtered shadows, summed area table", "link": "http://dx.doi.org/10.1109/TVCG.2014.2346333", "refList": ["10.1145/329693.329695", "10.2312/conf/eg2012/stars/053-074", "10.1111/j.1467-8659.2009.01464.x", "10.1109/tvcg.2011.211", "10.1109/tvcg.2013.129", "10.1111/j.1467-8659.2010.01724.x", "10.1145/2492684", "10.1109/pg.2007.27", "10.1016/j.compfluid.2012.03.006", "10.1111/j.1467-8659.2009.01695.x", "10.1111/j.1467-8659.2008.01154.x", "10.1007/s00371-005-0287-1", "10.1111/j.1467-8659.2011.02063.x", "10.1109/tvcg.2012.232", "10.1109/tvcg.2011.35", "10.1109/tvcg.2009.45", "10.1109/38.135913", "10.1371/journal.pone.0038586", "10.1109/visual.2002.1183764", "10.1109/tvcg.2006.33", "10.1109/tvcg.2003.1196002", "10.1145/2448196.2448205", "10.1068/p3060", "10.1111/j.1467-8659.2005.00880.x", "10.1016/j.cag.2010.03.005", "10.1109/svv.1998.729583", "10.1145/1283900.1283908", "10.1109/tvcg.2011.161", "10.1109/visual.2003.1250394", "10.1109/tvcg.2013.172", "10.1109/tvcg.2011.198", "10.1145/360825.360839", "10.1109/2945.468400", "10.1109/tvcg.2010.116", "10.1109/pacificvis.2010.5429594"], "wos": 1, "children": [{"doi": "10.1109/tvcg.2015.2467963", "title": "Anisotropic Ambient Volume Shading", "year": "2015", "conferenceName": "SciVis", "authors": "Marco Ament;Carsten Dachsbacher", "citationCount": "10", "affiliation": "Ament, M (Corresponding Author), Karlsruhe Inst Technol, D-76021 Karlsruhe, Germany. Ament, Marco; Dachsbacher, Carsten, Karlsruhe Inst Technol, D-76021 Karlsruhe, Germany.", "countries": "Germany", "abstract": "We present a novel method to compute anisotropic shading for direct volume rendering to improve the perception of the orientation and shape of surface-like structures. We determine the scale-aware anisotropy of a shading point by analyzing its ambient region. We sample adjacent points with similar scalar values to perform a principal component analysis by computing the eigenvectors and eigenvalues of the covariance matrix. In particular, we estimate the tangent directions, which serve as the tangent frame for anisotropic bidirectional reflectance distribution functions. Moreover, we exploit the ratio of the eigenvalues to measure the magnitude of the anisotropy at each shading point. Altogether, this allows us to model a data-driven, smooth transition from isotropic to strongly anisotropic volume shading. In this way, the shape of volumetric features can be enhanced significantly by aligning specular highlights along the principal direction of anisotropy. Our algorithm is independent of the transfer function, which allows us to compute all shading parameters once and store them with the data set. We integrated our method in a GPU-based volume renderer, which offers interactive control of the transfer function, light source positions, and viewpoint. Our results demonstrate the benefit of anisotropic shading for visualization to achieve data-driven local illumination for improved perception compared to isotropic shading.", "keywords": "Direct volume rendering, volume illumination, anisotropic shading", "link": "http://dx.doi.org/10.1109/TVCG.2015.2467963", "refList": ["10.1109/visual.1996.567777", "10.2312/conf/eg2012/stars/053-074", "10.1109/tvcg.2014.2346411", "10.1109/tvcg.2010.37", "10.1109/tvcg.2013.129", "10.1145/2492684", "10.1145/965141.563893", "10.1111/j.1467-8659.2009.01695.x", "10.1109/tvcg.2012.232", "10.1109/tvcg.2011.35", "10.1109/tvcg.2009.45", "10.1109/visual.2004.5", "10.1371/journal.pone.0038586", "10.1109/tvcg.2003.1196000", "10.1109/visual.1999.809886", "10.1145/2448196.2448205", "10.1145/340916.340922", "10.1068/p3060", "10.1109/visual.1994.346331", "10.1109/visual.2003.1250414", "10.1086/144246", "10.1109/tip.2003.819861", "10.1109/svv.1998.729583", "10.1145/1283900.1283908", "10.1109/tvcg.2011.161", "10.1111/cgf.12300", "10.1167/3.5.3", "10.1109/38.511", "10.1109/tvcg.2011.198", "10.1109/tvcg.2012.267", "10.1111/j.1467-8659.2009.01477.x", "10.1117/12.429489", "10.1109/tvcg.2014.2346333", "10.1109/2945.468400", "10.1109/pacificvis.2010.5429594"], "wos": 1, "children": [{"doi": "10.1109/tvcg.2016.2599041", "title": "OSPRay - A CPU Ray Tracing Framework for Scientific Visualization", "year": "2016", "conferenceName": "SciVis", "authors": "Ingo Wald;Gregory P. Johnson;Jefferson Amstutz;Carson Brownlee;Aaron Knoll;Jim Jeffers;Johannes G\u00fcnther;Paul A. Navr\u00e1til", "citationCount": "55", "affiliation": "Wald, I (Corresponding Author), Intel Corp, Santa Clara, CA 95051 USA. Wald, I.; Johnson, G. P.; Amstutz, J.; Brownlee, C.; Jeffers, J.; Guenther, J., Intel Corp, Santa Clara, CA 95051 USA. Brownlee, C.; Navratil, P., Texas Adv Comp Ctr, Austin, TX USA. Knoll, A., Univ Utah, SCI Inst, Salt Lake City, UT 84112 USA. Knoll, A., Argonne Natl Lab, 9700 S Cass Ave, Argonne, IL 60439 USA.", "countries": "USA", "abstract": "Scientific data is continually increasing in complexity, variety and size, making efficient visualization and specifically rendering an ongoing challenge. Traditional rasterization-based visualization approaches encounter performance and quality limitations, particularly in HPC environments without dedicated rendering hardware. In this paper, we present OSPRay, a turn-key CPU ray tracing framework oriented towards production-use scientific visualization which can utilize varying SIMD widths and multiple device backends found across diverse HPC resources. This framework provides a high-quality, efficient CPU-based solution for typical visualization workloads, which has already been integrated into several prevalent visualization packages. We show that this system delivers the performance, high-level API simplicity, and modular device support needed to provide a compelling new rendering framework for implementing efficient scientific visualization workflows.", "keywords": "", "link": "http://dx.doi.org/10.1109/TVCG.2016.2599041", "refList": ["10.1111/j.1467-8659.2005.00855.x", "10.1109/tvcg.2015.2467963", "10.1016/0263-7855(96)00018-5", "10.1145/1778765.1778803", "10.1145/2019627.2019634", "10.1109/rt.2007.4342603", "10.1109/mcg.2009.130", "10.1109/pacificvis.2011.5742355", "10.1145/300523.300537", "10.1371/journal.pone.0038586", "10.1109/2945.795215", "10.1145/2601097.2601199", "10.1109/pvgs.2003.1249046", "10.1109/tvcg.2010.173"], "wos": 1, "children": [{"doi": "10.1109/tvcg.2017.2743979", "title": "Screen-Space Normal Distribution Function Caching for Consistent Multi-Resolution Rendering of Large Particle Data", "year": "2017", "conferenceName": "SciVis", "authors": "Mohamed Ibrahim;Patrick Wickenhauser;Peter Rautek;Guido Reina;Markus Hadwiger", "citationCount": "1", "affiliation": "Ibrahim, M (Corresponding Author), KAUST, Thuwal 239556900, Saudi Arabia. Ibrahim, Mohamed; Rautek, Peter; Hadwiger, Markus, KAUST, Thuwal 239556900, Saudi Arabia. Wickenhaeuser, Patrick; Reina, Guido, Univ Stuttgart, Visualizat Res Ctr VISUS, Stuttgart, Germany.", "countries": "Germany;Arabia", "abstract": "Molecular dynamics (MD) simulations are crucial to investigating important processes in physics and thermodynamics. The simulated atoms are usually visualized as hard spheres with Phong shading, where individual particles and their local density can be perceived well in close-up views. However, for large-scale simulations with 10 million particles or more, the visualization of large fields-of-view usually suffers from strong aliasing artifacts, because the mismatch between data size and output resolution leads to severe under-sampling of the geometry. Excessive super-sampling can alleviate this problem, but is prohibitively expensive. This paper presents a novel visualization method for large-scale particle data that addresses aliasing while enabling interactive high-quality rendering. We introduce the novel concept of screen-space normal distribution functions (S-NDFs) for particle data. S-NDFs represent the distribution of surface normals that map to a given pixel in screen space, which enables high-quality re-lighting without re-rendering particles. In order to facilitate interactive zooming, we cache S-NDFs in a screen-space mipmap (S-MIP). Together, these two concepts enable interactive, scale-consistent re-lighting and shading changes, as well as zooming, without having to re-sample the particle data. We show how our method facilitates the interactive exploration of real-world large-scale MD simulation data in different scenarios.", "keywords": "Multiresolution Techniques,Point-Based Data,Glyph-based Techniques,Scalability Issues,Molecular Visualization", "link": "http://dx.doi.org/10.1109/TVCG.2017.2743979", "refList": ["10.1109/tvcg.2011.81", "10.1109/tvcg.2010.215", "10.2312/spbg/spbg06/059-065", "10.1111/j.1467-8659.2009.01698.x", "10.1109/tvcg.2014.2350479", "10.1145/2508363.2508422", "10.1145/965141.563893", "10.1111/j.1467-8659.2012.03128.x", "10.1111/j.1467-8659.2011.01964.x", "10.1111/cgf.12363", "10.2312/vcbm.20151209", "10.1145/2366145.2366152", "10.1109/visual.2003.1250404", "10.1007/978-3-642-38750-0\\_1", "10.1109/tvcg.2007.70439", "10.1109/scivis.2015.7429492", "10.1145/1239451.1239479", "10.2312/egwr/egsr07/195-206", "10.1109/tvcg.2014.2346324", "10.1111/cgf.12197", "10.2312/egpgv/egpgv13/009-016", "10.1109/tvcg.2009.142", "10.1109/tvcg.2016.2599041", "10.1109/sc.2014.40", "10.1109/visual.2004.103", "10.1021/ct500169q", "10.1145/1730804.1730834"], "wos": 1, "children": [], "len": 1}, {"doi": "10.1109/tvcg.2017.2745105", "title": "CasCADe: A Novel 4D Visualization System for Virtual Construction Planning", "year": "2017", "conferenceName": "InfoVis", "authors": "Paulo Ivson;Daniel Nascimento;Waldemar Celes Filho;Simone D. J. Barbosa", "citationCount": "3", "affiliation": "Ivson, P (Corresponding Author), Pontificia Univ Catolica Rio de Janeiro, Tecgraf Inst, Rio de Janeiro, Brazil. Ivson, Paulo; Nascimento, Daniel; Celes, Waldemar, Pontificia Univ Catolica Rio de Janeiro, Tecgraf Inst, Rio de Janeiro, Brazil. Barbosa, Simone D. J., Pontificia Univ Catolica Rio de Janeiro, Informat Dept, Rio de Janeiro, Brazil.", "countries": "Brazil", "abstract": "Building Information Modeling (BIM) provides an integrated 3D environment to manage large-scale engineering projects. The Architecture, Engineering and Construction (AEC) industry explores 4D visualizations over these datasets for virtual construction planning. However, existing solutions lack adequate visual mechanisms to inspect the underlying schedule and make inconsistencies readily apparent. The goal of this paper is to apply best practices of information visualization to improve 4D analysis of construction plans. We first present a review of previous work that identifies common use cases and limitations. We then consulted with AEC professionals to specify the main design requirements for such applications. These guided the development of CasCADe, a novel 4D visualization system where task sequencing and spatio-temporal simultaneity are immediately apparent. This unique framework enables the combination of diverse analytical features to create an information-rich analysis environment. We also describe how engineering collaborators used CasCADe to review the real-world construction plans of an Oil &amp;amp; Gas process plant. The system made evident schedule uncertainties, identified work-space conflicts and helped analyze other constructability issues. The results and contributions of this paper suggest new avenues for future research in information visualization for the AEC industry.", "keywords": "Visualization in physical sciences and engineering,design studies,integrating spatial and non-spatial data visualization,task and requirements analysis", "link": "http://dx.doi.org/10.1109/TVCG.2017.2745105", "refList": ["10.1061/(asce)0733-9364(2000)126:4(251", "10.1109/tvcg.2013.126", "10.1109/tvcg.2011.127", "10.1111/j.1467-8659.2010.01725.x", "10.1145/1053427.1053439", "10.1061/(asce)0733-9364(2002)128:4(287", "10.1016/s0926-5805(98)00053-3", "10.1109/2945.981847", "10.1109/tvcg.2009.102", "10.1016/j.autcon.2009.11.004", "10.1109/iv.1999.781617", "10.1016/j.autcon.2014.03.009", "10.1109/tvcg.2007.70539", "10.1111/1467-8659.00689", "10.1109/mcg.2003.1210862", "10.1016/s0097-8493(00)00130-8", "10.1016/j.autcon.2012.08.004", "10.1061/(asce)0887-3801(2009)23:6(391", "10.1109/tii.2012.2188901", "10.1109/mcg.2003.1242376", "10.1109/tvcg.2007.70570", "10.1145/345513.345271", "10.1016/j.autcon.2010.09.016", "10.1006/ijhc.2000.0418", "10.1111/j.1467-8659.2012.03081.x", "10.1109/tvcg.2009.152", "10.1061/(asce)0733-9364(2004)130:4(598", "10.1145/199404.199409", "10.1109/tvcg.2011.144", "10.1109/iv.2004.1320137", "10.1016/j.autcon.2011.07.005", "10.1109/tvcg.2008.194", "10.1109/tvcg.2012.110", "10.1109/iv.2008.18", "10.1109/tvcg.2012.213", "10.1109/tvcg.2016.2599041", "10.1109/tvcg.2007.70515", "10.1145/2699276.2699280", "10.1179/000870403235002042", "10.1111/j.1467-9671.2010.01194.x", "10.1109/tvcg.2008.59", "10.1109/visual.1997.663876", "10.1109/tvcg.2007.70574", "10.1109/2945.466717", "10.1016/j.autcon.2006.04.001", "10.1016/j.cad.2014.02.001", "10.1109/tvcg.2004.1260759", "10.1145/1279640.1279642", "10.1016/j.autcon.2011.10.003", "10.1109/visual.1996.568118", "10.1016/j.autcon.2014.04.009", "10.1061/(asce)0733-9364(1996)122:4(337", "10.1109/vl.1996.545307", "10.1108/09699980910970860", "10.1109/visual.1995.480803", "10.1109/tvcg.2006.115", "10.1016/j.autcon.2004.06.002", "10.1016/j.autcon.2013.09.003", "10.1061/(asce)co.1943-7862.0000102", "10.1016/j.autcon.2009.11.015", "10.1109/tvcg.2009.84", "10.1145/1090122.1090154", "10.1061/9780784413616.040", "10.1145/1360612.1360700", "10.3758/bf03206757", "10.1016/j.aei.2015.01.011", "10.1016/j.autcon.2015.02.007", "10.1111/j.1538-4632.2005.00575.x", "10.1061/(asce)0887-3801(2002)16:2(124", "10.1145/882262.882299", "10.1016/j.autcon.2004.08.012", "10.1016/j.autcon.2011.12.011", "10.1016/j.compenvurbsys.2009.07.003", "10.1061/(asce)lm.1943-5630.0000127", "10.1080/0144619042000201376", "10.1109/tvcg.2005.62", "10.1109/cmv.2007.20", "10.1109/70.56661", "10.1109/2945.841119", "10.1109/tvcg.2007.70535", "10.1109/iv.2011.15", "10.1016/j.cag.2010.11.015", "10.1016/j.aei.2009.05.002", "10.1109/iv.2003.1218054", "10.1109/sibgrapi.2007.36", "10.1109/tvcg.2012.265", "10.1145/2601097.2601199", "10.1109/2945.675649", "10.1109/iv.1997.626539", "10.1016/j.autcon.2008.10.003", "10.1109/2945.468391"], "wos": 1, "children": [], "len": 1}, {"doi": "10.1109/tvcg.2018.2864841", "title": "A Declarative Grammar of Flexible Volume Visualization Pipelines", "year": "2018", "conferenceName": "SciVis", "authors": "Min Shih;Charles Rozhon;Kwan-Liu Ma", "citationCount": "1", "affiliation": "Shih, M (Corresponding Author), Univ Calif Davis, Davis, CA 95616 USA. Shih, Min; Rozhon, Charles; Ma, Kwan-Liu, Univ Calif Davis, Davis, CA 95616 USA.", "countries": "USA", "abstract": "This paper presents a declarative grammar for conveniently and effectively specifying advanced volume visualizations. Existing methods for creating volume visualizations either lack the flexibility to specify sophisticated visualizations or are difficult to use for those unfamiliar with volume rendering implementation and parameterization. Our design provides the ability to quickly create expressive visualizations without knowledge of the volume rendering implementation. It attempts to capture aspects of those difficult but powerful methods while remaining flexible and easy to use. As a proof of concept, our current implementation of the grammar allows users to combine multiple data variables in various ways and define transfer functions for diverse input data. The grammar also has the ability to describe advanced shading effects and create animations. We demonstrate the power and flexibility of our approach using multiple practical volume visualizations.", "keywords": "Volume visualization,direct volume rendering,declarative specification,multivariate/multimodal volume data,animation", "link": "http://dx.doi.org/10.1109/TVCG.2018.2864841", "refList": ["10.1109/38.31462", "10.1007/978-0-387-98141-3\\_1", "10.1109/visual.1992.235219", "10.1109/visual.2004.95", "10.1080/14685240802376389", "10.1109/tvcg.2015.2467449", "10.1109/visual.2005.1532788", "10.1109/tvcg.2011.185", "10.1145/2345156.2254079", "10.1109/scivis.2015.7429514", "10.1109/tvcg.2014.2346318", "10.1111/j.1467-8659.2011.01952.x", "10.2312/vissym/eurovis07/115-122", "10.1109/tvcg.2002.1021579", "10.1109/mcg.2009.130", "10.1109/tvcg.2015.2467091", "10.1109/tvcg.2007.70555", "10.1111/j.1467-8659.2007.01095.x", "10.1016/j.parco.2007.09.001", "10.1109/tvcg.2009.174", "10.1109/tvcg.2007.70534", "10.1109/tvcg.2016.2599041", "10.1109/tvcg.2014.2346322", "10.1109/mcg.2008.96", "10.1109/tvcg.2009.189", "10.1109/ipdps.2011.385", "10.1109/tvcg.2016.2599030"], "wos": 1, "children": [], "len": 1}, {"doi": "10.1111/cgf.13958", "year": "2020", "title": "CPU Ray Tracing of Tree-Based Adaptive Mesh Refinement Data", "conferenceName": "EuroVis", "authors": "Feng Wang;Nathan Marshak;William Usher;Carsten Burstedde;Aaron Knoll;Timo Heister;Chris R. Johnson", "citationCount": "0", "affiliation": "Wang, F (Corresponding Author), Univ Utah, SCI Inst, Salt Lake City, UT 84112 USA.\nWang, Feng; Marshak, Nathan; Usher, Will; Johnson, Chris R., Univ Utah, SCI Inst, Salt Lake City, UT 84112 USA.\nUsher, Will; Knoll, Aaron, Intel Corp, Santa Clara, CA 95051 USA.\nBurstedde, Carsten, Univ Bonn, Inst Numer Simulat, Bonn, Germany.\nHeister, Timo, Clemson Univ, Sch Math \\& Stat Sci, Clemson, SC 29631 USA.", "countries": "Germany;USA", "abstract": "Adaptive mesh refinement (AMR) techniques allow for representing a simulation's computation domain in an adaptive fashion. Although these techniques have found widespread adoption in high-performance computing simulations, visualizing their data output interactively and without cracks or artifacts remains challenging. In this paper, we present an efficient solution for direct volume rendering and hybrid implicit isosurface ray tracing of tree-based AMR (TB-AMR) data. We propose a novel reconstruction strategy, Generalized Trilinear Interpolation (GTI), to interpolate across AMR level boundaries without cracks or discontinuities in the surface normal. We employ a general sparse octree structure supporting a wide range of AMR data, and use it to accelerate volume rendering, hybrid implicit isosurface rendering and value queries. We demonstrate that our approach achieves artifact-free isosurface and volume rendering and provides higher quality output images compared to existing methods at interactive rendering rates.", "keywords": "", "link": "https://doi.org/10.1111/cgf.13958", "refList": ["10.1109/tvcg.2010.240", "10.1016/s0010-4655(99)00501-9", "10.1109/5992.774839", "10.1145/3139295.3139305", "10.2312/vissym/eurovis06/259-266", "10.1145/195826.195828", "10.1109/ldav48142.2019.8944267", "10.2312/evs.20191167", "10.1109/tvcg.2018.2864850", "10.1109/tvcg.2005.79", "10.21105/joss.01370", "10.1016/0021-9991(84)90073-1", "10.1109/visual.1998.745713", "10.1145/2601097.2601199", "10.1109/ldav.2013.6675156", "10.1109/tvcg.2009.149", "10.1007/s00371-008-0215-2", "10.1109/tvcg.2016.2599041", "10.1137/100791634", "10.1109/inpar.2012.6339601", "10.2312/vg/vg-pbg08/163-170", "10.1109/ldav.2012.6378973", "10.2312/pgv.20181091"], "wos": 1, "children": [], "len": 1}], "len": 9}, {"doi": "10.1111/cgf.12914", "year": "2016", "title": "MCFTLE: Monte Carlo Rendering of Finite-Time Lyapunov Exponent Fields", "conferenceName": "EuroVis", "authors": "Tobias G{\\\"{u}}nther;Alexander Kuhn;Holger Theisel", "citationCount": "7", "affiliation": "Gunther, T (Corresponding Author), Univ Magdeburg, Visual Comp Grp, D-39106 Magdeburg, Germany.\nGuenther, Tobias; Theisel, Holger, Univ Magdeburg, Visual Comp Grp, D-39106 Magdeburg, Germany.\nKuhn, Alexander, Zuse Inst Berlin, Berlin, Germany.", "countries": "Germany", "abstract": "Traditionally, Lagrangian fields such as finite-time Lyapunov exponents (FTLE) are precomputed on a discrete grid and are ray casted afterwards. This, however, introduces both grid discretization errors and sampling errors during ray marching. In this work, we apply a progressive, view-dependent Monte Carlo-based approach for the visualization of such Lagrangian fields in time-dependent flows. Our approach avoids grid discretization and ray marching errors completely, is consistent, and has a low memory consumption. The system provides noisy previews that converge over time to an accurate high-quality visualization. Compared to traditional approaches, the proposed system avoids explicitly predefined fieldline seeding structures, and uses a Monte Carlo sampling strategy named Woodcock tracking to distribute samples along the view ray. An acceleration of this sampling strategy requires local upper bounds for the FTLE values, which we progressively acquire during the rendering. Our approach is tailored for high-quality visualizations of complex FTLE fields and is guaranteed to faithfully represent detailed ridge surface structures as indicators for Lagrangian coherent structures (LCS). We demonstrate the effectiveness of our approach by using a set of analytic test cases and real-world numerical simulations.", "keywords": "", "link": "https://doi.org/10.1111/cgf.12914", "refList": ["10.13182/nse72-1", "10.1142/s0218127404011430", "10.1109/pacificvis.2012.6183582", "10.13182/nse68-1", "10.1109/tvcg.2014.2346319", "10.1016/j.physd.2005.10.007", "10.1016/s0167-2789(00)00142-1", "10.1111/j.1467-8659.2010.01831.x", "10.1007/s00371-005-0287-1", "10.1145/2601097.2601219", "10.1111/j.1467-8659.2012.03148.x", "10.1117/12.2083253", "10.1109/tvcg.2007.70551", "10.1109/tvcg.2007.70554", "10.1371/journal.pone.0038586", "10.1145/1409060.1409083", "10.1109/tvcg.2012.131", "10.1109/tvcg.2010.227", "10.1109/tvcg.2015.2467963", "10.1145/2661229.2661292", "10.1109/tvcg.2014.2325043", "10.1109/tvcg.2011.265", "10.1016/s0167-2789(00)00199-8", "10.1016/j.jqsrt.2013.04.001", "10.1109/tvcg.2013.128", "10.1007/978-3-540-74496-2\\_35", "10.1016/j.jocs.2014.12.002", "10.1111/cgf.12280", "10.1111/cgf.12269", "10.1109/tvcg.2012.33", "10.1145/1866158.1866199", "10.1111/cgf.12592", "10.1146/annurev-fluid-010313-141322", "10.1109/2945.468400", "10.1111/j.1467-8659.2011.01901.x"], "wos": 1, "children": [{"doi": "10.1109/tvcg.2019.2934313", "title": "Accelerated Monte Carlo Rendering of Finite-Time Lyapunov Exponents", "year": "2019", "conferenceName": "SciVis", "authors": "Irene Baeza Rojo;Markus H. Gross;Tobias G\u00fcnther", "citationCount": "0", "affiliation": "Rojo, IB (Corresponding Author), Swiss Fed Inst Technol, Comp Graph Lab, Zurich, Switzerland. Rojo, Irene Baeza; Gross, Markus; Guenther, Tobias, Swiss Fed Inst Technol, Comp Graph Lab, Zurich, Switzerland.", "countries": "Switzerland", "abstract": "Time-dependent fluid flows often contain numerous hyperbolic Lagrangian coherent structures, which act as transport barriers that guide the advection. The finite-time Lyapunov exponent is a commonly-used approximation to locate these repelling or attracting structures. Especially on large numerical simulations, the FTLE ridges can become arbitrarily sharp and very complex. Thus, the discrete sampling onto a grid for a subsequent direct volume rendering is likely to miss sharp ridges in the visualization. For this reason, an unbiased Monte Carlo-based rendering approach was recently proposed that treats the FTLE field as participating medium with single scattering. This method constructs a ground truth rendering without discretization, but it is prohibitively slow with render times in the order of days or weeks for a single image. In this paper, we accelerate the rendering process significantly, which allows us to compute video sequence of high-resolution FTLE animations in a much more reasonable time frame. For this, we follow two orthogonal approaches to improve on the rendering process: the volumetric light path integration in gradient domain and an acceleration of the transmittance estimation. We analyze the convergence and performance of the proposed method and demonstrate the approach by rendering complex FTLE fields in several 3D vector fields.", "keywords": "Scientific visualization,Monte Carlo,feature extraction,finite-time Lyapunov exponents,gradient domain,Fourier", "link": "http://dx.doi.org/10.1109/TVCG.2019.2934313", "refList": ["10.1088/1749-4699/1/1/015005", "10.1145/2661229.2661291", "10.1145/63039.63042", "10.1111/cgf.13319", "10.1145/2766997", "10.1109/pacificvis.2012.6183582", "10.1103/physrevfluids.2.090502", "10.1111/cgf.13104", "10.1145/3197517.3201363", "10.1016/j.physd.2005.10.007", "10.1145/1882261.1866199", "10.1016/s0167-2789(00)00142-1", "10.1111/j.1467-8659.2010.01831.x", "10.1007/s00371-005-0287-1", "10.1111/j.1467-8659.2012.03148.x", "10.1109/tvcg.2007.70551", "10.1109/tvcg.2007.70554", "10.1371/journal.pone.0038586", "10.1109/tvcg.2010.227", "10.1145/2661229.2661292", "10.1109/tvcg.2014.2325043", "10.1088/0022-3727/1/11/423", "10.1109/tvcg.2011.265", "10.1016/s0167-2789(00)00199-8", "10.1111/cgf.12914", "10.1016/j.jqsrt.2013.04.001", "10.1109/tvcg.2013.128", "10.1007/978-3-540-74496-2\\_35", "10.1063/1.3270044", "10.1016/j.jocs.2014.12.002", "10.1111/j.1467-8659.2008.01165.x", "10.1111/cgf.13342", "10.1111/cgf.12269", "10.1109/tvcg.2012.33", "10.1145/3072959.3073665", "10.1111/cgf.13102", "10.1145/3072959.3073601", "10.1111/cgf.12592", "10.1111/j.1467-8659.2003.00723.x", "10.1146/annurev-fluid-010313-141322", "10.1002/qj.828", "10.1111/j.1467-8659.2011.01901.x"], "wos": 1, "children": [], "len": 1}], "len": 3}, {"doi": "10.1111/cgf.12916", "year": "2016", "title": "Decoupled Shading for Real-time Heterogeneous Volume Illumination", "conferenceName": "EuroVis", "authors": "Y. Zhang;K.{-}L. Ma", "citationCount": "4", "affiliation": "Zhang, Y (Corresponding Author), Univ Calif Davis, Davis, CA 95616 USA.\nZhang, Y.; Ma, K. -L., Univ Calif Davis, Davis, CA 95616 USA.", "countries": "USA", "abstract": "Existing real-time volume rendering techniques which support global illumination are limited in modeling distinct realistic appearances for classified volume data, which is a desired capability in many fields of study for illustration and education. Directly extending the emission-absorption volume integral with heterogeneous material shading becomes unaffordable for real-time applications because the high-frequency view-dependent global lighting needs to be evaluated per sample along the volume integral. In this paper, we present a decoupled shading algorithm for multi-material volume rendering that separates global incident lighting evaluation from per-sample material shading under multiple light sources. We show how the incident lighting calculation can be optimized through a sparse volume integration method. The quality, performance and usefulness of our new multi-material volume rendering method is demonstrated through several examples.", "keywords": "Global illumination; high performance; multi-material; multiple scattering; soft shadow; volume rendering", "link": "https://doi.org/10.1111/cgf.12916", "refList": ["10.1109/tvcg.2013.17", "10.1111/j.1467-8659.2009.01464.x", "10.1145/197938.197971", "10.1109/tvcg.2013.129", "10.1145/360349.360353", "10.1145/965141.563893", "10.1111/j.1467-8659.2008.01154.x", "10.1109/tvcg.2011.35", "10.1371/journal.pone.0038586", "10.1109/tvcg.2015.2467963", "10.1111/cgf.12252", "10.1016/j.cag.2010.03.005", "10.1111/j.1467-8659.2007.01095.x", "10.1109/tvcg.2013.172", "10.1109/tvcg.2011.198", "10.1109/tvcg.2014.2346333", "10.1145/360825.360839", "10.1109/2945.468400", "10.1109/tvcg.2007.70573", "10.1109/pacificvis.2010.5429594"], "wos": 1, "children": [{"doi": "10.1109/tvcg.2017.2744438", "title": "Interactive Dynamic Volume Illumination with Refraction and Caustics", "year": "2017", "conferenceName": "SciVis", "authors": "Jens G. Magnus;Stefan Bruckner", "citationCount": "4", "affiliation": "Magnus, JG (Corresponding Author), Univ Bergen, Bergen, Norway. Magnus, Jens G.; Bruckner, Stefan, Univ Bergen, Bergen, Norway.", "countries": "Norway", "abstract": "In recent years, significant progress has been made in developing high-quality interactive methods for realistic volume illumination. However, refraction - despite being an important aspect of light propagation in participating media - has so far only received little attention. In this paper, we present a novel approach for refractive volume illumination including caustics capable of interactive frame rates. By interleaving light and viewing ray propagation, our technique avoids memory-intensive storage of illumination information and does not require any precomputation. It is fully dynamic and all parameters such as light position and transfer function can be modified interactively without a performance penalty.", "keywords": "Interactive volume rendering,illumination,refraction,shadows,caustics", "link": "http://dx.doi.org/10.1109/TVCG.2017.2744438", "refList": ["10.1111/j.1467-8659.2009.01464.x", "10.1073/pnas.1500913112", "10.1145/1268517.1268548", "10.1109/tvcg.2011.211", "10.1109/tvcg.2003.1196003", "10.1109/tvcg.2013.129", "10.1109/tvcg.2010.255", "10.1145/2492684", "10.1111/j.1467-8659.2009.01695.x", "10.1111/j.1467-8659.2008.01154.x", "10.1109/pacificvis.2015.7156382", "10.1109/mcg.2010.98", "10.1145/1360612.1360634", "10.1111/1467-8659.1020121", "10.1016/j.gmod.2006.07.003", "10.1145/1073204.1073310", "10.1109/tvcg.2009.45", "10.1177/0956797611408734", "10.2312/vissym/eurovis05/215-222", "10.1111/j.1467-8659.2004.00794.x", "10.1145/1111411.1111439", "10.1038/srep44274", "10.1145/2448196.2448205", "10.2312/egwr/egsr07/195-206", "10.1145/1944745.1944764", "10.1111/j.1467-8659.2010.01733.x", "10.1109/tvcg.2002.1021575", "10.1111/cgf.12252", "10.1109/38.55151", "10.1111/cgf.12916", "10.1109/tvcg.2011.161", "10.1145/2557605", "10.1109/tvcg.2011.198", "10.2312/egwr/egsr05/291-300", "10.1145/357290.357293", "10.1109/tvcg.2014.2346333", "10.1109/2945.468400", "10.1145/1230100.1230116"], "wos": 1, "children": [], "len": 1}], "len": 3}], "len": 19}, {"doi": "10.1109/tvcg.2016.2598430", "title": "Correlated Photon Mapping for Interactive Global Illumination of Time-Varying Volumetric Data", "year": "2016", "conferenceName": "SciVis", "authors": "Daniel J\u00f6nsson;Anders Ynnerman", "citationCount": "11", "affiliation": "Jonsson, D (Corresponding Author), Linkoping Univ, Norrkoping, Sweden. Jonsson, Daniel; Ynnerman, Anders, Linkoping Univ, Norrkoping, Sweden.", "countries": "Sweden", "abstract": "We present a method for interactive global illumination of both static and time-varying volumetric data based on reduction of the overhead associated with re-computation of photon maps. Our method uses the identification of photon traces invariant to changes of visual parameters such as the transfer function (TF), or data changes between time-steps in a 4D volume. This lets us operate on a variant subset of the entire photon distribution. The amount of computation required in the two stages of the photon mapping process, namely tracing and gathering, can thus be reduced to the subset that are affected by a data or visual parameter change. We rely on two different types of information from the original data to identify the regions that have changed. A low resolution uniform grid containing the minimum and maximum data values of the original data is derived for each time step. Similarly, for two consecutive time-steps, a low resolution grid containing the difference between the overlapping data is used. We show that this compact metadata can be combined with the transfer function to identify the regions that have changed. Each photon traverses the low-resolution grid to identify if it can be directly transferred to the next photon distribution state or if it needs to be recomputed. An efficient representation of the photon distribution is presented leading to an order of magnitude improved performance of the raycasting step. The utility of the method is demonstrated in several examples that show visual fidelity, as well as performance. The examples show that visual quality can be retained when the fraction of retraced photons is as low as 40%-50%.", "keywords": "Volume rendering;photon mapping;global illumination;participating media", "link": "http://dx.doi.org/10.1109/TVCG.2016.2598430", "refList": ["10.1111/j.1467-8659.2008.01153.x", "10.1109/tvcg.2013.17", "10.1111/j.1467-8659.2009.01464.x", "10.1109/tvcg.2011.211", "10.1007/bf01905559", "10.1109/tvcg.2003.1196003", "10.1145/2492684", "10.1109/pg.2007.27", "10.1111/j.1467-8659.2008.01154.x", "10.1109/pacificvis.2015.7156382", "10.1111/j.1467-8659.2012.02093.x", "10.1145/280814.280925", "10.1109/tvcg.2012.232", "10.1109/tvcg.2011.35", "10.1109/tvcg.2009.45", "10.1145/1330511.1330518", "10.1371/journal.pone.0038586", "10.1111/j.1467-8659.2012.03051.x", "10.1145/2448196.2448205", "10.1145/1730804.1730821", "10.1111/j.1467-8659.2011.01979.x", "10.1111/cgf.12252", "10.1109/tvcg.2007.70518", "10.1145/2451236.2451242", "10.1137/1114019", "10.1109/tip.2003.819861", "10.1109/tvcg.2011.161", "10.1109/tvcg.2011.198", "10.1109/tvcg.2014.2346333", "10.1142/s0129626411000187", "10.1109/2945.468400"], "wos": 1, "children": [], "len": 1}, {"doi": "10.1109/tvcg.2017.2744438", "title": "Interactive Dynamic Volume Illumination with Refraction and Caustics", "year": "2017", "conferenceName": "SciVis", "authors": "Jens G. Magnus;Stefan Bruckner", "citationCount": "4", "affiliation": "Magnus, JG (Corresponding Author), Univ Bergen, Bergen, Norway. Magnus, Jens G.; Bruckner, Stefan, Univ Bergen, Bergen, Norway.", "countries": "Norway", "abstract": "In recent years, significant progress has been made in developing high-quality interactive methods for realistic volume illumination. However, refraction - despite being an important aspect of light propagation in participating media - has so far only received little attention. In this paper, we present a novel approach for refractive volume illumination including caustics capable of interactive frame rates. By interleaving light and viewing ray propagation, our technique avoids memory-intensive storage of illumination information and does not require any precomputation. It is fully dynamic and all parameters such as light position and transfer function can be modified interactively without a performance penalty.", "keywords": "Interactive volume rendering,illumination,refraction,shadows,caustics", "link": "http://dx.doi.org/10.1109/TVCG.2017.2744438", "refList": ["10.1111/j.1467-8659.2009.01464.x", "10.1073/pnas.1500913112", "10.1145/1268517.1268548", "10.1109/tvcg.2011.211", "10.1109/tvcg.2003.1196003", "10.1109/tvcg.2013.129", "10.1109/tvcg.2010.255", "10.1145/2492684", "10.1111/j.1467-8659.2009.01695.x", "10.1111/j.1467-8659.2008.01154.x", "10.1109/pacificvis.2015.7156382", "10.1109/mcg.2010.98", "10.1145/1360612.1360634", "10.1111/1467-8659.1020121", "10.1016/j.gmod.2006.07.003", "10.1145/1073204.1073310", "10.1109/tvcg.2009.45", "10.1177/0956797611408734", "10.2312/vissym/eurovis05/215-222", "10.1111/j.1467-8659.2004.00794.x", "10.1145/1111411.1111439", "10.1038/srep44274", "10.1145/2448196.2448205", "10.2312/egwr/egsr07/195-206", "10.1145/1944745.1944764", "10.1111/j.1467-8659.2010.01733.x", "10.1109/tvcg.2002.1021575", "10.1111/cgf.12252", "10.1109/38.55151", "10.1111/cgf.12916", "10.1109/tvcg.2011.161", "10.1145/2557605", "10.1109/tvcg.2011.198", "10.2312/egwr/egsr05/291-300", "10.1145/357290.357293", "10.1109/tvcg.2014.2346333", "10.1109/2945.468400", "10.1145/1230100.1230116"], "wos": 1, "children": [], "len": 1}, {"doi": "10.1109/pacificvis.2015.7156383", "year": "2015", "title": "Advanced lighting for unstructured-grid data visualization", "conferenceName": "PacificVis", "authors": "Min Shih;Yubo Zhang;Kwan{-}Liu Ma", "citationCount": "2", "affiliation": "Shih, M (Corresponding Author), Univ Calif Davis, Davis, CA 95616 USA.\nShih, Min; Zhang, Yubo; Ma, Kwan-Liu, Univ Calif Davis, Davis, CA 95616 USA.", "countries": "USA", "abstract": "The benefits of using advanced illumination models in volume visualization have been demonstrated by many researchers. Interactive volume rendering incorporated with advanced lighting has been achieved with GPU acceleration for regular-grid volume data, making volume visualization even more appealing as a tool for 3D data exploration. This paper presents an interactive illumination strategy, which is specially designed and optimized for volume visualization of unstructured-grid data. The basis of the design is a partial differential equation based illumination model to simulate the light propagation, absorption, and scattering within the volumetric medium. In particular, a two-level scheme is introduced to overcome the challenges presented by unstructured grids. Test results show that the added illumination effects such as global shadowing and multiple scattering not only lead to more visually pleasing visualization, but also greatly enhance the perception of the depth information and complex spatial relationships for features of interest in the volume data. This volume visualization enhancement is introduced at a time when unstructured grids are becoming increasingly popular for a variety of scientific simulation applications.", "keywords": "", "link": "https://doi.org/10.1109/PACIFICVIS.2015.7156383", "refList": ["10.1111/j.1467-8659.2008.01153.x", "10.1109/tvcg.2012.306", "10.1109/tvcg.2003.1196003", "10.1109/tvcg.2013.129", "10.1109/visual.2000.885683", "10.1109/tvcg.2009.105", "10.1145/280814.280925", "10.1109/visual.2003.1250390", "10.1002/cpa.3160050303", "10.1109/tvcg.2012.232", "10.1109/visual.2002.1183764", "10.1109/visual.2000.885680", "10.1145/2448196.2448205", "10.1016/j.cag.2010.03.005", "10.1145/78964.78965", "10.1109/tvcg.2011.198", "10.1109/tvcg.2014.2346333", "10.1109/2945.468400", "10.1109/pacificvis.2010.5429594"], "wos": 1, "children": [], "len": 1}, {"doi": "10.1109/pacificvis.2015.7156382", "year": "2015", "title": "Efficient volume illumination with multiple light sources through selective light updates", "conferenceName": "PacificVis", "authors": "Erik Sund{\\'{e}}n;Timo Ropinski", "citationCount": "4", "affiliation": "Sunden, E (Corresponding Author), Linkoping Univ, Interact Visualizat Grp, S-58183 Linkoping, Sweden.\nSunden, Erik, Linkoping Univ, Interact Visualizat Grp, S-58183 Linkoping, Sweden.\nRopinski, Timo, Univ Ulm, Visual Comp Res Grp, D-89069 Ulm, Germany.", "countries": "Sweden;Germany", "abstract": "Incorporating volumetric illumination into rendering of volumetric data increases visual realism, which can lead to improved spatial comprehension. It is known that spatial comprehension can be further improved by incorporating multiple light sources. However, many volumetric illumination algorithms have severe drawbacks when dealing with multiple light sources. These drawbacks are mainly high performance penalties and memory usage, which can be tackled with specialized data structures or data under sampling. In contrast, in this paper we present a method which enables volumetric illumination with multiple light sources without requiring precomputation or impacting visual quality. To achieve this goal, we introduce selective light updates which minimize the required computations when light settings are changed. We will discuss and analyze the novel concepts underlying selective light updates, and demonstrate them when applied to real-world data under different light settings.", "keywords": "", "link": "https://doi.org/10.1109/PACIFICVIS.2015.7156382", "refList": ["10.1109/tvcg.2012.91", "10.1109/tvcg.2013.17", "10.1111/j.1467-8659.2009.01464.x", "10.1109/tvcg.2011.211", "10.1109/tvcg.2003.1196003", "10.1109/visual.2003.1250395", "10.1111/j.1467-8659.2009.01695.x", "10.1111/j.1467-8659.2008.01154.x", "10.1109/mcg.2010.98", "10.1109/tvcg.2012.232", "10.1109/tvcg.2011.35", "10.1109/38.135913", "10.1371/journal.pone.0038586", "10.1145/2448196.2448205", "10.1145/1730804.1730821", "10.1068/p3060", "10.1111/cgf.12252", "10.1109/visual.2003.1250394", "10.1167/3.5.3", "10.1109/tvcg.2011.198", "10.1109/tvcg.2013.172", "10.1145/2024676.2024694", "10.1109/tvcg.2014.2346333", "10.1109/2945.468400"], "wos": 1, "children": [{"doi": "10.1109/tvcg.2016.2598430", "title": "Correlated Photon Mapping for Interactive Global Illumination of Time-Varying Volumetric Data", "year": "2016", "conferenceName": "SciVis", "authors": "Daniel J\u00f6nsson;Anders Ynnerman", "citationCount": "11", "affiliation": "Jonsson, D (Corresponding Author), Linkoping Univ, Norrkoping, Sweden. Jonsson, Daniel; Ynnerman, Anders, Linkoping Univ, Norrkoping, Sweden.", "countries": "Sweden", "abstract": "We present a method for interactive global illumination of both static and time-varying volumetric data based on reduction of the overhead associated with re-computation of photon maps. Our method uses the identification of photon traces invariant to changes of visual parameters such as the transfer function (TF), or data changes between time-steps in a 4D volume. This lets us operate on a variant subset of the entire photon distribution. The amount of computation required in the two stages of the photon mapping process, namely tracing and gathering, can thus be reduced to the subset that are affected by a data or visual parameter change. We rely on two different types of information from the original data to identify the regions that have changed. A low resolution uniform grid containing the minimum and maximum data values of the original data is derived for each time step. Similarly, for two consecutive time-steps, a low resolution grid containing the difference between the overlapping data is used. We show that this compact metadata can be combined with the transfer function to identify the regions that have changed. Each photon traverses the low-resolution grid to identify if it can be directly transferred to the next photon distribution state or if it needs to be recomputed. An efficient representation of the photon distribution is presented leading to an order of magnitude improved performance of the raycasting step. The utility of the method is demonstrated in several examples that show visual fidelity, as well as performance. The examples show that visual quality can be retained when the fraction of retraced photons is as low as 40%-50%.", "keywords": "Volume rendering;photon mapping;global illumination;participating media", "link": "http://dx.doi.org/10.1109/TVCG.2016.2598430", "refList": ["10.1111/j.1467-8659.2008.01153.x", "10.1109/tvcg.2013.17", "10.1111/j.1467-8659.2009.01464.x", "10.1109/tvcg.2011.211", "10.1007/bf01905559", "10.1109/tvcg.2003.1196003", "10.1145/2492684", "10.1109/pg.2007.27", "10.1111/j.1467-8659.2008.01154.x", "10.1109/pacificvis.2015.7156382", "10.1111/j.1467-8659.2012.02093.x", "10.1145/280814.280925", "10.1109/tvcg.2012.232", "10.1109/tvcg.2011.35", "10.1109/tvcg.2009.45", "10.1145/1330511.1330518", "10.1371/journal.pone.0038586", "10.1111/j.1467-8659.2012.03051.x", "10.1145/2448196.2448205", "10.1145/1730804.1730821", "10.1111/j.1467-8659.2011.01979.x", "10.1111/cgf.12252", "10.1109/tvcg.2007.70518", "10.1145/2451236.2451242", "10.1137/1114019", "10.1109/tip.2003.819861", "10.1109/tvcg.2011.161", "10.1109/tvcg.2011.198", "10.1109/tvcg.2014.2346333", "10.1142/s0129626411000187", "10.1109/2945.468400"], "wos": 1, "children": [], "len": 1}, {"doi": "10.1109/tvcg.2017.2744438", "title": "Interactive Dynamic Volume Illumination with Refraction and Caustics", "year": "2017", "conferenceName": "SciVis", "authors": "Jens G. Magnus;Stefan Bruckner", "citationCount": "4", "affiliation": "Magnus, JG (Corresponding Author), Univ Bergen, Bergen, Norway. Magnus, Jens G.; Bruckner, Stefan, Univ Bergen, Bergen, Norway.", "countries": "Norway", "abstract": "In recent years, significant progress has been made in developing high-quality interactive methods for realistic volume illumination. However, refraction - despite being an important aspect of light propagation in participating media - has so far only received little attention. In this paper, we present a novel approach for refractive volume illumination including caustics capable of interactive frame rates. By interleaving light and viewing ray propagation, our technique avoids memory-intensive storage of illumination information and does not require any precomputation. It is fully dynamic and all parameters such as light position and transfer function can be modified interactively without a performance penalty.", "keywords": "Interactive volume rendering,illumination,refraction,shadows,caustics", "link": "http://dx.doi.org/10.1109/TVCG.2017.2744438", "refList": ["10.1111/j.1467-8659.2009.01464.x", "10.1073/pnas.1500913112", "10.1145/1268517.1268548", "10.1109/tvcg.2011.211", "10.1109/tvcg.2003.1196003", "10.1109/tvcg.2013.129", "10.1109/tvcg.2010.255", "10.1145/2492684", "10.1111/j.1467-8659.2009.01695.x", "10.1111/j.1467-8659.2008.01154.x", "10.1109/pacificvis.2015.7156382", "10.1109/mcg.2010.98", "10.1145/1360612.1360634", "10.1111/1467-8659.1020121", "10.1016/j.gmod.2006.07.003", "10.1145/1073204.1073310", "10.1109/tvcg.2009.45", "10.1177/0956797611408734", "10.2312/vissym/eurovis05/215-222", "10.1111/j.1467-8659.2004.00794.x", "10.1145/1111411.1111439", "10.1038/srep44274", "10.1145/2448196.2448205", "10.2312/egwr/egsr07/195-206", "10.1145/1944745.1944764", "10.1111/j.1467-8659.2010.01733.x", "10.1109/tvcg.2002.1021575", "10.1111/cgf.12252", "10.1109/38.55151", "10.1111/cgf.12916", "10.1109/tvcg.2011.161", "10.1145/2557605", "10.1109/tvcg.2011.198", "10.2312/egwr/egsr05/291-300", "10.1145/357290.357293", "10.1109/tvcg.2014.2346333", "10.1109/2945.468400", "10.1145/1230100.1230116"], "wos": 1, "children": [], "len": 1}], "len": 5}, {"doi": "10.1111/cgf.12916", "year": "2016", "title": "Decoupled Shading for Real-time Heterogeneous Volume Illumination", "conferenceName": "EuroVis", "authors": "Y. Zhang;K.{-}L. Ma", "citationCount": "4", "affiliation": "Zhang, Y (Corresponding Author), Univ Calif Davis, Davis, CA 95616 USA.\nZhang, Y.; Ma, K. -L., Univ Calif Davis, Davis, CA 95616 USA.", "countries": "USA", "abstract": "Existing real-time volume rendering techniques which support global illumination are limited in modeling distinct realistic appearances for classified volume data, which is a desired capability in many fields of study for illustration and education. Directly extending the emission-absorption volume integral with heterogeneous material shading becomes unaffordable for real-time applications because the high-frequency view-dependent global lighting needs to be evaluated per sample along the volume integral. In this paper, we present a decoupled shading algorithm for multi-material volume rendering that separates global incident lighting evaluation from per-sample material shading under multiple light sources. We show how the incident lighting calculation can be optimized through a sparse volume integration method. The quality, performance and usefulness of our new multi-material volume rendering method is demonstrated through several examples.", "keywords": "Global illumination; high performance; multi-material; multiple scattering; soft shadow; volume rendering", "link": "https://doi.org/10.1111/cgf.12916", "refList": ["10.1109/tvcg.2013.17", "10.1111/j.1467-8659.2009.01464.x", "10.1145/197938.197971", "10.1109/tvcg.2013.129", "10.1145/360349.360353", "10.1145/965141.563893", "10.1111/j.1467-8659.2008.01154.x", "10.1109/tvcg.2011.35", "10.1371/journal.pone.0038586", "10.1109/tvcg.2015.2467963", "10.1111/cgf.12252", "10.1016/j.cag.2010.03.005", "10.1111/j.1467-8659.2007.01095.x", "10.1109/tvcg.2013.172", "10.1109/tvcg.2011.198", "10.1109/tvcg.2014.2346333", "10.1145/360825.360839", "10.1109/2945.468400", "10.1109/tvcg.2007.70573", "10.1109/pacificvis.2010.5429594"], "wos": 1, "children": [{"doi": "10.1109/tvcg.2017.2744438", "title": "Interactive Dynamic Volume Illumination with Refraction and Caustics", "year": "2017", "conferenceName": "SciVis", "authors": "Jens G. Magnus;Stefan Bruckner", "citationCount": "4", "affiliation": "Magnus, JG (Corresponding Author), Univ Bergen, Bergen, Norway. Magnus, Jens G.; Bruckner, Stefan, Univ Bergen, Bergen, Norway.", "countries": "Norway", "abstract": "In recent years, significant progress has been made in developing high-quality interactive methods for realistic volume illumination. However, refraction - despite being an important aspect of light propagation in participating media - has so far only received little attention. In this paper, we present a novel approach for refractive volume illumination including caustics capable of interactive frame rates. By interleaving light and viewing ray propagation, our technique avoids memory-intensive storage of illumination information and does not require any precomputation. It is fully dynamic and all parameters such as light position and transfer function can be modified interactively without a performance penalty.", "keywords": "Interactive volume rendering,illumination,refraction,shadows,caustics", "link": "http://dx.doi.org/10.1109/TVCG.2017.2744438", "refList": ["10.1111/j.1467-8659.2009.01464.x", "10.1073/pnas.1500913112", "10.1145/1268517.1268548", "10.1109/tvcg.2011.211", "10.1109/tvcg.2003.1196003", "10.1109/tvcg.2013.129", "10.1109/tvcg.2010.255", "10.1145/2492684", "10.1111/j.1467-8659.2009.01695.x", "10.1111/j.1467-8659.2008.01154.x", "10.1109/pacificvis.2015.7156382", "10.1109/mcg.2010.98", "10.1145/1360612.1360634", "10.1111/1467-8659.1020121", "10.1016/j.gmod.2006.07.003", "10.1145/1073204.1073310", "10.1109/tvcg.2009.45", "10.1177/0956797611408734", "10.2312/vissym/eurovis05/215-222", "10.1111/j.1467-8659.2004.00794.x", "10.1145/1111411.1111439", "10.1038/srep44274", "10.1145/2448196.2448205", "10.2312/egwr/egsr07/195-206", "10.1145/1944745.1944764", "10.1111/j.1467-8659.2010.01733.x", "10.1109/tvcg.2002.1021575", "10.1111/cgf.12252", "10.1109/38.55151", "10.1111/cgf.12916", "10.1109/tvcg.2011.161", "10.1145/2557605", "10.1109/tvcg.2011.198", "10.2312/egwr/egsr05/291-300", "10.1145/357290.357293", "10.1109/tvcg.2014.2346333", "10.1109/2945.468400", "10.1145/1230100.1230116"], "wos": 1, "children": [], "len": 1}], "len": 3}], "len": 37}, "index": 339, "embedding": [1.5731340646743774, 1.0426191091537476, 0.6752455830574036, 1.5537002086639404, -0.6737499833106995, 0.16650904715061188, -0.7139257192611694, -0.5138809680938721, 0.13794708251953125, -0.8176287412643433, 1.6413756608963013, -0.608446478843689, 0.1447085440158844, 0.829492449760437, -0.6561029553413391, 1.6768615245819092, 0.9855421781539917, 0.07420150190591812, 0.6882043480873108, 8.315646171569824, -0.06630208343267441, -0.4288652539253235, 1.9586234092712402, 2.068991184234619, -2.5787017345428467, 2.545654058456421, -0.5483691096305847, 0.5818139314651489, 0.7918184995651245, -0.13499583303928375, 1.6703637838363647, 1.5742616653442383], "projection": [-1.4493277072906494, 6.076451301574707], "size": 19, "height": 4, "width": 6}