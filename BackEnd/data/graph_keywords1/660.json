{"data": {"doi": "10.1109/tvcg.2017.2744159", "title": "StreetVizor: Visual Exploration of Human-Scale Urban Forms Based on Street Views", "year": "2017", "conferenceName": "SciVis", "authors": "Qiaomu Shen;Wei Zeng 0004;Yu Ye;Stefan M\u00fcller Arisona;Simon Schubiger-Banz;Remo Aslak Burkhard;Huamin Qu", "citationCount": "5", "affiliation": "Zeng, W (Corresponding Author), Swiss Fed Inst Technol, Future Cities Lab, Zurich, Switzerland. Shen, Qiaomu; Qu, Huamin, Hong Kong Univ Sci \\& Technol, Hong Kong, Peoples R China. Zeng, Wei; Burkhard, Remo, Swiss Fed Inst Technol, Future Cities Lab, Zurich, Switzerland. Ye, Yu, Tongji Univ, Shanghai, Peoples R China. Arisona, Stefan Muller; Schubiger, Simon, Univ Appl Sci \\& Arts Northwestern Switzerland FHN, Basel, Switzerland.", "countries": "Switzerland;China", "abstract": "Urban forms at human-scale, i.e., urban environments that individuals can sense (e.g., sight, smell, and touch) in their daily lives, can provide unprecedented insights on a variety of applications, such as urban planning and environment auditing. The analysis of urban forms can help planners develop high-quality urban spaces through evidence-based design. However, such analysis is complex because of the involvement of spatial, multi-scale (i.e., city, region, and street), and multivariate (e.g., greenery and sky ratios) natures of urban forms. In addition, current methods either lack quantitative measurements or are limited to a small area. The primary contribution of this work is the design of StreetVizor, an interactive visual analytics system that helps planners leverage their domain knowledge in exploring human-scale urban forms based on street view images. Our system presents two-stage visual exploration: 1) an AOI Explorer for the visual comparison of spatial distributions and quantitative measurements in two areas-of-interest (AOIs) at city- and region-scales; 2) and a Street Explorer with a novel parallel coordinate plot for the exploration of the fine-grained details of the urban forms at the street-scale. We integrate visualization techniques with machine learning models to facilitate the detection of street view patterns. We illustrate the applicability of our approach with case studies on the real-world datasets of four cities, i.e., Hong Kong, Singapore, Greater London and New York City. Interviews with domain experts demonstrate the effectiveness of our system in facilitating various analytical tasks.", "keywords": "Urban forms,human scale,street view,visual analytics", "link": "http://dx.doi.org/10.1109/TVCG.2017.2744159", "refList": ["10.1111/j.1467-8659.2008.01241.x", "10.2312/conf/eg2013/stars/095-116", "10.1109/tvcg.2013.226", "10.1177/1473871611416549", "10.1109/tvcg.2016.2520920", "10.1109/cvprw.2014.121", "10.1016/j.landurbplan.2014.08.005", "10.1109/tvcg.2013.221", "10.1109/vl.1996.545307", "10.1109/tvcg.2016.2598694", "10.1109/tvcg.2007.70523", "10.1007/s11390-013-1383-8", "10.1109/tvcg.2015.2467619", "10.1109/tvcg.2013.228", "10.1109/visual.1999.809866", "10.1109/tvcg.2015.2467199", "10.1109/tvcg.2008.193", "10.1109/34.1000236", "10.1109/2945.981848", "10.1007/s00371-012-0713-0", "10.1109/tvcg.2011.181", "10.1109/tvcg.2011.176", "10.1109/tvcg.2016.2598472", "10.1109/tbdata.2016.2586447", "10.1109/tvcg.2014.2346594", "10.1145/102377.115768", "10.1109/tvcg.2013.179", "10.1109/tvcg.2008.166", "10.1109/tvcg.2014.2346265", "10.1016/j.cities.2015.03.006", "10.1016/j.amepre.2010.09.034", "10.1145/2830541", "10.1016/j.ufug.2015.06.006", "10.1111/j.1467-8659.2009.01666.x", "10.1109/tvcg.2014.2346446", "10.1109/mc.2010.170", "10.1109/tvcg.2016.2598432"], "wos": 1, "children": [{"doi": "10.1109/tvcg.2019.2934671", "title": "A Natural-language-based Visual Query Approach of Uncertain Human Trajectories", "year": "2019", "conferenceName": "VAST", "authors": "Zhaosong Huang;Ye Zhao;Wei Chen;Shengjie Gao;Kejie Yu;Weixia Xu;MingJie Tang;Minfeng Zhu;Mingliang Xu", "citationCount": "0", "affiliation": "Chen, W (Corresponding Author), Zhejiang Univ, State Key Lab CAD \\& CG, Hangzhou, Peoples R China. Xu, ML (Corresponding Author), Zhengzhou Univ, Sch Informat Engn, Zhengzhou 450000, Peoples R China. Huang, Zhaosong; Chen, Wei; Gao, Shengjie; Yu, Kejie; Xu, Weixia; Zhu, Minfeng, Zhejiang Univ, State Key Lab CAD \\& CG, Hangzhou, Peoples R China. Zhao, Ye, Kent State Univ, Dept Comp Sci, Kent, OH 44242 USA. Tang, Mingjie, Ant Financial, San Mateo, CA USA. Xu, Mingliang, Zhengzhou Univ, Sch Informat Engn, Zhengzhou 450000, Peoples R China.", "countries": "USA;China", "abstract": "Visual querying is essential for interactively exploring massive trajectory data. However, the data uncertainty imposes profound challenges to fulfill advanced analytics requirements. On the one hand, many underlying data does not contain accurate geographic coordinates, e.g., positions of a mobile phone only refer to the regions (i.e., mobile cell stations) in which it resides, instead of accurate GPS coordinates. On the other hand, domain experts and general users prefer a natural way, such as using a natural language sentence, to access and analyze massive movement data. In this paper, we propose a visual analytics approach that can extract spatial-temporal constraints from a textual sentence and support an effective query method over uncertain mobile trajectory data. It is built up on encoding massive, spatially uncertain trajectories by the semantic information of the POls and regions covered by them, and then storing the trajectory documents in text database with an effective indexing scheme. The visual interface facilitates query condition specification, situation-aware visualization, and semantic exploration of large trajectory data. Usage scenarios on real-world human mobility datasets demonstrate the effectiveness of our approach.", "keywords": "Natural-language-based Visual Query,Spatial Uncertaity,Trajectory Exploration", "link": "http://dx.doi.org/10.1109/TVCG.2019.2934671", "refList": ["10.1017/s1351324909005129", "10.1109/tvcg.2013.226", "10.1109/tvcg.2018.2864503", "10.1561/1500000019", "10.1109/icde.2010.5447829", "10.1109/tvcg.2008.172", "10.1177/1473871612457601", "10.1145/2442810.2442828", "10.1109/pacificvis.2014.50", "10.1109/vast.2014.7042486", "10.1201/9781420008609.ch3", "10.1177/1473871613480062", "10.1109/tvcg.2017.2744159", "10.1145/2629592", "10.1109/tvcg.2016.2616404", "10.1109/vl.1996.545307", "10.5311/josis.2012.4.62", "10.5220/0005716900480059", "10.1109/tvcg.2018.2865049", "10.1109/tvcg.2015.2467619", "10.1109/tvcg.2015.2467771", "10.1109/tvcg.2011.233", "10.1186/s12859-015-0564-6", "10.1111/cgf.12114", "10.1108/eb026562", "10.1002/inc3.362", "10.1109/vast.2014.7042495", "10.1145/299917.299920", "10.1162/coli.2009.35.4.35403", "10.1016/j.datak.2007.10.008", "10.13140/2.1.2393.1847", "10.1109/tits.2017.2683539", "10.1109/tbdata.2017.2667700", "10.1177/1473871617692841", "10.1109/tits.2015.2436897", "10.1109/tvcg.2013.179", "10.1145/2339530.2339561", "10.1109/vast.2008.4677356", "10.1109/access.2016.2553681", "10.1109/tvcg.2017.2758362", "10.14778/2732232.2732235", "10.1109/tits.2017.2711644", "10.1162/jmlr.2003.3.4-5.993", "10.1145/330560.330692", "10.1109/tvcg.2014.2371856", "10.1111/cgf.12778", "10.1145/2743025", "10.1109/tnn.2003.820440", "10.1109/tvcg.2016.2598885", "10.1109/tits.2016.2639320", "10.1145/1341012.1341041", "10.1109/tvcg.2016.2598416", "10.1145/2501654.2501656", "10.1109/tvcg.2016.2598432", "10.1109/tvcg.2018.2865042"], "wos": 1, "children": [], "len": 1}, {"doi": "10.1109/tvcg.2020.3030370", "title": "TaxThemis: Interactive Mining and Exploration of Suspicious Tax Evasion Groups", "year": "2020", "conferenceName": "VAST", "authors": "Yating Lin;Kamkwai Wong;Yong Wang;Rong Zhang;Bo Dong;Huamin Qu;Qinghua Zheng", "citationCount": "0", "affiliation": "Lin, YT (Corresponding Author), Xi An Jiao Tong Univ, MOEKLINNS Lab, Xian, Shaanxi, Peoples R China. Lin, Yating; Zheng, Qinghua, Xi An Jiao Tong Univ, MOEKLINNS Lab, Xian, Shaanxi, Peoples R China. Wong, Kamkwai; Wang, Yong; Zhang, Rong; Qu, Huamin, Hong Kong Univ Sci \\& Technol, Hong Kong, Peoples R China. Dong, Bo, Xi An Jiao Tong Univ, Natl Engn Lab Big Data Analyt, Xian, Shaanxi, Peoples R China.", "countries": "China", "abstract": "Tax evasion is a serious economic problem for many countries, as it can undermine the government's tax system and lead to an unfair business competition environment. Recent research has applied data analytics techniques to analyze and detect tax evasion behaviors of individual taxpayers. However, they have failed to support the analysis and exploration of the related party transaction tax evasion (RPTTE) behaviors (e.g., transfer pricing), where a group of taxpayers is involved. In this paper, we present TaxThemis, an interactive visual analytics system to help tax officers mine and explore suspicious tax evasion groups through analyzing heterogeneous tax-related data. A taxpayer network is constructed and fused with the respective trade network to detect suspicious RPTTE groups. Rich visualizations are designed to facilitate the exploration and investigation of suspicious transactions between related taxpayers with profit and topological data analysis. Specifically, we propose a calendar heatmap with a carefully-designed encoding scheme to intuitively show the evidence of transferring revenue through related party transactions. We demonstrate the usefulness and effectiveness of TaxThemis through two case studies on real-world tax-related data and interviews with domain experts.", "keywords": "Visual Analytics,Tax Network,Tax Evasion Detection,Anomaly detection,Multidimensional data", "link": "http://dx.doi.org/10.1109/TVCG.2020.3030370", "refList": ["10.1111/cgf.12886", "10.2307/2277827", "10.1109/tvcg.2010.44", "10.1109/tits.2014.2315794", "10.1109/tvcg.2019.2934670", "10.1038/s41467-019-08987-4", "10.1111/cgf.12920", "10.1109/vast.2017.8585721", "10.1080/15230406.2015.1093431", "10.1109/tvcg.2018.2843369", "10.1038/srep01001", "10.1109/tvcg.2017.2744018", "10.1109/tvcg.2017.2744159", "10.1068/b130199p", "10.1109/tvcg.2009.143", "10.1016/j.visinf.2017.01.006", "10.1109/tvcg.2019.2892483", "10.1109/pacificvis.2017.8031583", "10.1109/pacificvis48177.2020.2785", "10.2307/2686111", "10.1109/tvcg.2015.2467199", "10.1111/cgf.12114", "10.1109/tvcg.2018.2865126", "10.1111/j.1538-4632.1996.tb00936.x", "10.1109/tvcg.2019.2934619", "10.2307/2332142", "10.1007/978-3-319-10590-1\\_53", "10.1109/cvpr.2016.485", "10.1109/cvpr.2017.17", "10.2307/2986645", "10.1109/tvcg.2014.2346321", "10.1017/s0140525x16001837", "10.1109/tvcg.2016.2598541", "10.1371/journal.pone.0207377", "10.1109/tvcg.2014.2346265", "10.1007/s4095-020-0191-7", "10.3141/1644-14", "10.1109/tvcg.2017.2744158", "10.1109/cvpr.2016.90", "10.1109/tvcg.2018.2865027", "10.1109/tvcg.2017.2785807", "10.1109/tvcg.2017.2744358", "10.1111/j.1538-4632.1995.tb00338.x", "10.1080/03081068808717359", "10.1109/tvcg.2016.2598831"], "wos": 1, "children": [], "len": 1}, {"doi": "10.1111/cgf.13673", "year": "2019", "title": "Multiple Views: different meanings and collocated words", "conferenceName": "EuroVis", "authors": "Jonathan C. Roberts;Hayder Al{-}Maneea;Peter W. S. Butcher;Robert Lew;Geraint Rees;Nirwan Sharma;Ana Frankenberg{-}Garcia", "citationCount": "1", "affiliation": "Roberts, JC (Corresponding Author), Bangor Univ, Bangor, Gwynedd, Wales.\nRoberts, J. C.; Al-maneea, H.; Butcher, P. W. S.; Sharma, N., Bangor Univ, Bangor, Gwynedd, Wales.\nAl-maneea, H., Basrah Univ, Basrah, Iraq.\nLew, R.; Rees, G., Adam Mickiewicz Univ, Poznan, Poland.\nFrankenberg-Garcia, A., Univ Surrey, Guildford, Surrey, England.", "countries": "Poland;Wales;England;Iraq", "abstract": "We report on an in-depth corpus linguistic study on multiple views' terminology and word collocation. We take a broad interpretation of these terms, and explore the meaning and diversity of their use in visualisation literature. First we explore senses of the term multiple views' (e.g., multiple views' can mean juxtaposition, many viewport projections or several alternative opinions). Second, we investigate term popularity and frequency of occurrences, investigating usage of multiple' and view' (e.g., multiple views, multiple visualisations, multiple sets). Third, we investigate word collocations and terms that have a similar sense (e.g., multiple views, side-by-side, small multiples). We built and used several corpora, including a 6-million-word corpus of all IEEE Visualisation conference articles published in IEEE Transactions on Visualisation and Computer Graphics 2012 to 2017. We draw on our substantial experience from early work in coordinated and multiple views, and with collocation analysis develop several lists of terms. This research provides insight into term use, a reference for novice and expert authors in visualisation, and contributes a taxonomy of multiple view' terms.", "keywords": "", "link": "https://doi.org/10.1111/cgf.13673", "refList": ["10.1109/tvcg.2017.2744359", "10.1109/38.31462", "10.1109/cmv.2003.1215002", "10.2307/2289444", "10.1016/j.ijhcs.2011.02.007", "10.1017/s0022112091210654", "10.1016/b978-008044531-1/50426-7", "10.1109/cmv.2003.1215001", "10.1109/tvcg.2013.134", "10.1117/12.378894", "10.1037/0096-1523.21.6.1494", "10.1057/palgrave.ivs.9500086", "10.1109/iv.2011.42", "10.1109/tvcg.2017.2744199", "10.4324/9780203810088", "10.1145/1321440.1321580", "10.1109/tvcg.2015.2467271", "10.1016/j.learninstruc.2006.03.001", "10.1145/345513.345282", "10.1007/s40607-014-0009-9", "10.1109/tvcg.2017.2743859", "10.1109/infvis.1997.636761", "10.1109/tvcg.2013.219", "10.1007/978-3-319-55627-7", "10.1109/tvcg.2009.111", "10.1109/iv.2008.21", "10.1109/infvis.2002.1173157", "10.1109/mcg.2014.82", "10.1145/3143699.3143717", "10.1109/tvcg.2012.226", "10.1145/345513.345271", "10.2478/jazcas-2018-0006", "10.1145/2556288.2556969", "10.1109/visual.1998.745282", "10.1145/1276377.1276427", "10.1109/infvis.2001.963283", "10.1007/978-1-4471-6497-5\\_1", "10.1109/visual.1994.346302", "10.1057/palgrave.ivs.9500068", "10.1109/tvcg.2006.160", "10.1109/visual.1990.146374", "10.1109/tvcg.2016.2614803", "10.1177/1473871611416549", "10.1109/tvcg.2017.2745878", "10.1109/tvcg.2006.69", "10.1109/tpami.1983.4767367", "10.1109/visual.1991.175794", "10.1109/tvcg.2017.2744159", "10.1109/tvcg.2017.2744198", "10.1109/32.328995", "10.1016/j.jeap.2018.07.003", "10.1016/j.geomorph.2012.08.021", "10.1109/tvcg.2014.2346920", "10.1109/2.917550", "10.1017/s0958344018000150", "10.1109/tvcg.2009.94", "10.1179/2051819613z.0000000003", "10.1109/vast.2008.4677370", "10.1117/12.309533", "10.1109/tvcg.2014.2346747", "10.1075/ijcl.13.4.06ray", "10.1007/s12650-015-0323-9", "10.1109/tvcg.2006.178", "10.1109/tvcg.2016.2615308", "10.2307/1269768", "10.2307/4132312", "10.1109/tvcg.2018.2864903", "10.1109/mis.2006.100", "10.1109/iv.1998.694193", "10.1007/s11192-015-1830-0", "10.1109/tvcg.2017.2744080", "10.1111/j.1467-9280.1997.tb00442.x", "10.1109/cmv.2007.20", "10.1109/infvis.2003.1249006", "10.1109/tvcg.2017.2745941", "10.1016/s1364-6613(99)01332-7", "10.1145/989863.989893", "10.1109/tse.1985.232211", "10.1109/tvcg.2017.2744184", "10.1109/infvis.2004.12", "10.1075/ijcl.17.3.04har", "10.1109/tvcg.2010.179", "10.1016/j.jss.2006.05.024", "10.1109/cmv.2003.1215005", "10.1109/tvcg.2017.2744358", "10.1145/2992154.2996365", "10.1109/tvcg.2016.2598827"], "wos": 1, "children": [{"doi": "10.1109/tvcg.2020.3030338", "title": "Composition and Configuration Patterns in Multiple-View Visualizations", "year": "2020", "conferenceName": "InfoVis", "authors": "Xi Chen;Wei Zeng 0004;Yanna Lin;Hayder Al-Maneea;Jonathan Roberts 0002;Remco Chang", "citationCount": "0", "affiliation": "Zeng, W (Corresponding Author), Chinese Acad Sci, Shenzhen Inst Adv Technol, Shenzhen, Peoples R China. Chen, Xi; Zeng, Wei; Lin, Yanna, Chinese Acad Sci, Shenzhen Inst Adv Technol, Shenzhen, Peoples R China. AI-maneea, Hayder Mahdi; Roberts, Jonathan, Bangor Univ, Bangor, Gwynedd, Wales. Chang, Remco, Tufts Univ, Medford, MA 02155 USA.", "countries": "USA;Wales;China", "abstract": "Multiple-view visualization (MV) is a layout design technique often employed to help users see a large number of data attributes and values in a single cohesive representation. Because of its generalizability, the MV design has been widely adopted by the visualization community to help users examine and interact with large, complex, and high-dimensional data. However, although ubiquitous, there has been little work to categorize and analyze MVs in order to better understand its design space. As a result, there has been little to no guideline in how to use the MV design effectively. In this paper, we present an in-depth study of how MVs are designed in practice. We focus on two fundamental measures of multiple-view patterns: composition, which quantifies what view types and how many are there; and configuration, which characterizes spatial arrangement of view layouts in the display space. We build a new dataset containing 360 images of MVs collected from IEEE VIS, EuroVis, and PacificVis publications 2011 to 2019, and make fine-grained annotations of view types and layouts for these visualization images. From this data we conduct composition and configuration analyses using quantitative metrics of term frequency and layout topology. We identify common practices around MVs, including relationship of view types, popular view layouts, and correlation between view types and layouts. We combine the findings into a MV recommendation system, providing interactive tools to explore the design space, and support example-based design.", "keywords": "Multiple views,design pattern,quantitative analysis,example-based design", "link": "http://dx.doi.org/10.1109/TVCG.2020.3030338", "refList": ["10.1109/tvcg.2018.2865235", "10.1109/tvcg.2016.2615308", "10.1145/2642918.2647398", "10.1177/1473871611416549", "10.1109/tvcg.2019.2934810", "10.1109/tvcg.2014.48", "10.1109/tvcg.2018.2864903", "10.1145/345513.345271", "10.1109/iv.1998.694193", "10.1109/tvcg.2007.70594", "10.1109/tvcg.2017.2744019", "10.1109/tvcg.2011.185", "10.1109/tvcg.2015.2467194", "10.1109/visual.1991.175815", "10.14778/2831360.2831371", "10.1109/mcg.2019.2924636", "10.1111/cgf.13673", "10.1111/cgf.12131", "10.1109/tvcg.2017.2744198", "10.1145/108360.108361", "10.1109/vl.1996.545307", "10.1109/tvcg.2017.2745140", "10.1109/cmv.2007.20", "10.1145/198366.198376", "10.1145/2508363.2508405", "10.1111/cgf.12114", "10.1109/icde.2018.00019", "10.1109/tvcg.2017.2787113", "10.1109/tvcg.2018.2865240", "10.1111/cgf.13380", "10.1111/cgf.12902", "10.1109/vast.2015.7347628", "10.2307/2288400", "10.1109/infvis.2004.12", "10.1145/102377.115768", "10.1109/tvcg.2009.179", "10.1109/2945.981851", "10.1109/tvcg.2007.70521", "10.1109/pacificvis.2012.6183556", "10.1145/2213836", "10.1109/tvcg.2013.234", "10.1109/iv.2008.87"], "wos": 1, "children": [], "len": 1}], "len": 3}], "len": 9}, "index": 660, "embedding": [2.4188334941864014, 1.454913854598999, 1.0608787536621094, 1.3932995796203613, -0.6737499833106995, 0.16650904715061188, -0.7139257192611694, 0.7131867408752441, -0.4176805317401886, -0.8176287412643433, -0.06694771349430084, 2.076127767562866, -0.13027368485927582, 4.900514602661133, 2.299858808517456, 2.050960063934326, 1.4750951528549194, 0.07420150190591812, -0.6413080096244812, -1.0321691036224365, -0.06630208343267441, 0.15033428370952606, 2.0317490100860596, -0.13057257235050201, 2.0469372272491455, 0.09751410037279129, -0.5483691096305847, 1.479600191116333, 2.043325185775757, 0.46649041771888733, 1.529017448425293, 2.494605302810669], "projection": [-4.018756866455078, 7.867635250091553], "size": 5, "height": 3, "width": 3}