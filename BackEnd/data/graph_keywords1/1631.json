{"data": {"title": "Parsing and Summarizing Infographics with Synthetically Trained Icon Detection", "authors": "Spandan Madan; Zoya Bylinskii; Carolina Nobre; Matthew Tancik; Adria Recasens; Kimberli Zhong; Sami Alsheikh; Aude Oliva; Fr\ufffd\ufffddo Durand; Hanspeter Pfister", "affiliation": "Spandan Madan (Harvard University), Zoya Bylinskii (Adobe Research), Carolina Nobre (Harvard University), Matthew Tancik (University of California, Berkeley), Adria Recasens (Massachusetts Institute of Technology), Kimberli Zhong (Massachusetts Institute of Technology), Sami Alsheikh (Massachusetts Institute of Technology), Aude Oliva (Massachusetts Institute of Technology), Fredo Durand (Massachusetts Institute of Technology), Hanspeter Pfister (Harvard University)", "countries": "USA", "abstract": "Widely used in news, business, and educational media, infographics are handcrafted to effectively communicate messages about complex and often abstract topics including 'ways to conserve the environment' and 'understanding the financial crisis'. The computational understanding of infographics required for future applications like automatic captioning, summarization, search, and question-answering, will depend on being able to parse the visual and textual elements contained within. However, being composed of stylistically and semantically diverse visual and textual elements, infographics pose challenges for current A.I. systems. While automatic text extraction works reasonably well on infographics, standard object detection algorithms fail to identify the stand-alone visual elements in infographics that we refer to as 'icons'. In this paper, we propose a novel approach to train an object detector using synthetically-generated data, and show that it succeeds at generalizing to detecting icons within in-the-wild infographics. We further pair our icon detection approach with an icon classifier and a state-of-the-art text detector to demonstrate three demo applications: topic prediction, multi-modal summarization, and multi-modal search. Parsing the visual and textual elements within infographics provides us with the first steps towards automatic infographic understanding.", "doi": "parsingandsummarizin-2021", "year": 2021, "conferenceName": "PacificVis", "citationCount": 0, "keywords": "", "link": "", "refList": "", "wos": 0, "len": 1}, "index": 1631, "embedding": [-2.125394344329834, -0.2801166772842407, -1.030107021331787, -0.26406028866767883, -0.11488457024097443, 0.16650904715061188, 5.349244117736816, 1.7859841585159302, 7.809534549713135, -0.7817944884300232, 2.9005770683288574, -0.9841079115867615, 0.009662487544119358, 2.173267364501953, -0.804432213306427, -0.5232402086257935, -0.008738257922232151, 0.07072390615940094, -0.23242419958114624, 0.03240932896733284, -0.06630208343267441, 0.5226964354515076, -0.05622868984937668, -0.1390654742717743, -1.164926290512085, 2.3710732460021973, -0.5452967882156372, -0.19688554108142853, -0.5651506185531616, -2.657630681991577, 0.3318488895893097, -0.9189074635505676], "projection": [14.70795726776123, 4.395733833312988], "size": 1, "height": 1, "width": 1}