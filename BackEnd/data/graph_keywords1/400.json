{"data": {"doi": "10.1109/tvcg.2014.2346751", "title": "Visual Analytics for Comparison of Ocean Model Output with Reference Data: Detecting and Analyzing Geophysical Processes Using Clustering Ensembles", "year": "2014", "conferenceName": "VAST", "authors": "Patrick K\u00f6thur;Mike Sips;Henryk Dobslaw;Doris Dransch", "citationCount": "17", "affiliation": "Kothur, P (Corresponding Author), GFZ German Res Ctr Geosci, Potsdam, Germany. Koethur, Patrick; Sips, Mike; Dobslaw, Henryk; Dransch, Doris, GFZ German Res Ctr Geosci, Potsdam, Germany. Dransch, Doris, Humboldt Univ, Dept Geog, D-10099 Berlin, Germany.", "countries": "Germany", "abstract": "Researchers assess the quality of an ocean model by comparing its output to that of a previous model version or to observations. One objective of the comparison is to detect and to analyze differences and similarities between both data sets regarding geophysical processes, such as particular ocean currents. This task involves the analysis of thousands or hundreds of thousands of geographically referenced temporal profiles in the data. To cope with the amount of data, modelers combine aggregation of temporal profiles to single statistical values with visual comparison. Although this strategy is based on experience and a well-grounded body of expert knowledge, our discussions with domain experts have shown that it has two limitations: (1) using a single statistical measure results in a rather limited scope of the comparison and in significant loss of information, and (2) the decisions modelers have to make in the process may lead to important aspects being overlooked.", "keywords": "Ocean modeling, model assessment, geospatial time series, cluster ensembles, visual comparison, visual analytics", "link": "http://dx.doi.org/10.1109/TVCG.2014.2346751", "refList": ["10.1080/17489725.2010.532816", "10.1175/2009jtecha1374.1", "10.1109/icpr.2002.1047450", "10.1111/j.1467-8659.2009.01664.x", "10.1162/153244303321897735", "10.1126/science.1099192", "10.1109/bibm.2010.5706631", "10.1109/18.681318", "10.1016/j.patcog.2005.01.025", "10.1109/mcg.2010.100", "10.1109/tgrs.2008.918647", "10.1179/000870403235002042", "10.1029/2000gl012234", "10.1016/s1045-926x(03)00046-6", "10.1109/tvcg.2012.190", "10.1111/j.1467-8659.2012.03184.x", "10.1111/cgf.12390", "10.1007/s10618-012-0285-7", "10.1109/tvcg.2012.284", "10.1145/1283383.1283494", "10.1080/13658816.2010.510800", "10.1109/tvcg.2008.69", "10.1109/tvcg.2006.84", "10.1198/016214502760047131", "10.1109/tvcg.2008.139", "10.1109/iv.2011.12", "10.1177/1473871613481692", "10.1109/tnb.2011.2144997", "10.1007/978-0-85729-079-3"], "wos": 1, "children": [{"doi": "10.1109/tvcg.2019.2934540", "title": "Separating the Wheat from the Chaff: Comparative Visual Cues for Transparent Diagnostics of Competing Models", "year": "2019", "conferenceName": "InfoVis", "authors": "Aritra Dasgupta;Hong Wang;Nancy O'Brien;Susannah Burrows", "citationCount": "2", "affiliation": "Dasgupta, A (Corresponding Author), New Jersey Inst Technol, Newark, NJ 07102 USA. Dasgupta, Aritra, New Jersey Inst Technol, Newark, NJ 07102 USA. Wang, Hong, Arizona State Univ, Tempe, AZ 85287 USA. O'Brien, Nancy; Burrows, Susannah, Pacific Northwest Natl Lab, Richland, WA 99352 USA.", "countries": "USA", "abstract": "Experts in data and physical sciences have to regularly grapple with the problem of competing models. Be it analytical or physics-based models, a cross-cutting challenge for experts is to reliably diagnose which model outcomes appropriately predict or simulate real-world phenomena. Expert judgment involves reconciling information across many, and often, conflicting criteria that describe the quality of model outcomes. In this paper, through a design study with climate scientists, we develop a deeper understanding of the problem and solution space of model diagnostics, resulting in the following contributions: i) a problem and task characterization using which we map experts' model diagnostics goals to multi-way visual comparison tasks, ii) a design space of comparative visual cues for letting experts quickly understand the degree of disagreement among competing models and gauge the degree of stability of model outputs with respect to alternative criteria, and iii) design and evaluation of MyriadCues, an interactive visualization interface for exploring alternative hypotheses and insights about good and bad models by leveraging comparative visual cues. We present case studies and subjective feedback by experts, which validate how MyriadCues enables more transparent model diagnostic mechanisms, as compared to the state of the art.", "keywords": "Visual comparison,Visual cues,Model evaluation,Transparency,Simulation", "link": "http://dx.doi.org/10.1109/TVCG.2019.2934540", "refList": ["10.1109/tvcg.2014.2346751", "10.1109/tvcg.2009.167", "10.1145/230562.230563", "10.1109/sp.2016.42", "10.1177/1473871611416549", "10.1007/s00376-018-7300-x", "10.1109/tvcg.2011.229", "10.1111/j.1467-8659.2008.01205.x", "10.1109/tvcg.2013.122", "10.1145/22949.22950", "10.1016/j.tics.2004.11.006", "10.1175/bams-d-17-0218.1", "10.1109/mcg.2018.032421661", "10.1897/ieam\\_2004a-015.1", "10.1175/bams-d-15-00135.1", "10.1109/tvcg.2011.225", "10.1029/2000jd900719", "10.1109/tvcg.2011.279", "10.1109/tvcg.2014.2346321", "10.1111/j.1467-8349.2009.00180.x", "10.1145/3025453.3025882", "10.1111/cgf.12390", "10.1109/tvcg.2012.110", "10.1145/882262.882291", "10.1109/tvcg.2016.2598589", "10.1098/rspa.2017.0009", "10.1029/2007jd008972", "10.1109/visual.1990.146402", "10.1109/tvcg.2016.2598830", "10.1109/tvcg.2008.139", "10.1109/tvcg.2014.2346755", "10.1109/tvcg.2009.111", "10.1002/2014ms000354", "10.1111/j.1467-8659.2012.03116.x", "10.1179/000870403235002042"], "wos": 1, "children": [], "len": 1}, {"doi": "10.1109/pacificvis.2016.7465271", "year": "2016", "title": "Screen-space silhouettes for visualizing ensembles of 3D isosurfaces", "conferenceName": "PacificVis", "authors": "Ismail Demir;Johannes Kehrer;R{\\\"{u}}diger Westermann", "citationCount": "12", "affiliation": "Demir, I (Corresponding Author), Tech Univ Munich, Comp Graph \\& Visualizat Grp, D-80290 Munich, Germany.\nDemir, Ismail; Kehrer, Johannes; Westermann, Ruediger, Tech Univ Munich, Comp Graph \\& Visualizat Grp, D-80290 Munich, Germany.", "countries": "Germany", "abstract": "Visualizing sets of isosurfaces from 3D scalar ensemble fields is a difficult task due to inherent occlusion effects, yet it is often required to analyze the uncertainty represented by such an ensemble. In this paper, we present a novel visualization technique for ensembles of isosurfaces based on screen-space silhouettes. By using silhouettes, the displayed information is reduced to avoid occlusions, yet the major shape of the surfaces can be maintained. Our approach preserves spatial coherence and does not make any assumption about the underlying surface distribution. By providing additional mechanisms, i.e., picking, clustering, cutting and animation, we enable the user to explore an ensemble of surfaces interactively.", "keywords": "I.3.3 {[}Computer Graphics]: Picture/Image Generation-Display algorithms", "link": "https://doi.org/10.1109/PACIFICVIS.2016.7465271", "refList": ["10.1109/tvcg.2014.2346751", "10.1109/tvcg.2013.143", "10.1016/s0097-8493(02)00055-9", "10.1109/tvcg.2010.190", "10.1109/tvcg.2015.2467204", "10.1177/1473871611416549", "10.1109/pacificvis.2013.6596144", "10.1109/ldav.2011.6092313", "10.2481/dsj.3.153", "10.1145/345513.345271", "10.1007/s003710050111", "10.1109/icdmw.2009.55", "10.1109/tvcg.2010.247", "10.1109/tvcg.2009.155", "10.1109/tvcg.2014.2346626", "10.1111/j.1467-8659.2009.01677.x", "10.1111/j.1467-8659.2011.01944.x", "10.1109/vl.1996.545307", "10.1016/j.patrec.2009.09.011", "10.1109/tvcg.2014.2346455", "10.1109/tvcg.2010.181", "10.1016/j.cageo.2010.02.010", "10.1007/978-1-4471-6497-5\\_1", "10.1109/mcg.2003.1231171", "10.1007/s00371-010-0541-z", "10.1145/988834.988849", "10.1111/cgf.12649", "10.1109/visual.2000.885739", "10.1109/tvcg.2015.2468093", "10.1016/j.jcp.2007.02.014", "10.1109/visual.2003.1250414", "10.1109/tvcg.2012.110", "10.1109/tvcg.2014.2307892", "10.1145/37402.37422", "10.1615/int.j.uncertaintyquantification.2012003956", "10.1109/vast.2015.7347634", "10.1109/tvcg.2014.2346448", "10.1111/cgf.12099"], "wos": 1, "children": [{"doi": "10.1109/tvcg.2018.2864808", "title": "Exploring Time-Varying Multivariate Volume Data Using Matrix of Isosurface Similarity Maps", "year": "2018", "conferenceName": "SciVis", "authors": "Jun Tao 0002;Martin Imre;Chaoli Wang;Nitesh V. Chawla;Hanqi Guo;Gokhan Sever;Seung Hyun Kim", "citationCount": "3", "affiliation": "Tao, J (Corresponding Author), Univ Notre Dame, Notre Dame, IN 46556 USA. Tao, Jun; Imre, Martin; Wang, Chaoli; Chawla, Nitesh V., Univ Notre Dame, Notre Dame, IN 46556 USA. Guo, Hanqi; Sever, Gokhan, Argonne Natl Lab, Argonne, IL 60439 USA. Kim, Seung Hyun, Ohio State Univ, Columbus, OH 43210 USA.", "countries": "USA", "abstract": "We present a novel visual representation and interface named the matrix of isosurface similarity maps (MISM) for effective exploration of large time-varying multivariate volumetric data sets. MISM synthesizes three types of similarity maps (i.e., self, temporal, and variable similarity maps) to capture the essential relationships among isosurfaces of different variables and time steps. Additionally, it serves as the main visual mapping and navigation tool for examining the vast number of isosurfaces and exploring the underlying time-varying multivariate data set. We present temporal clustering, variable grouping, and interactive filtering to reduce the huge exploration space of MISM. In conjunction with the isovalue and isosurface views, MISM allows users to identify important isosurfaces or isosurface pairs and compare them over space, time, and value range. More importantly, we introduce path recommendation that suggests, animates, and compares traversal paths for effectively exploring MISM under varied criteria and at different levels-of-detail. A silhouette-based method is applied to render multiple surfaces of interest in a visually succinct manner. We demonstrate the effectiveness of our approach with case studies of several time-varying multivariate data sets and an ensemble data set, and evaluate our work with two domain experts.", "keywords": "Time-varying multivariate data visualization,isosurface,similarity map,visual interface,path recommendation", "link": "http://dx.doi.org/10.1109/TVCG.2018.2864808", "refList": ["10.1177/1473871611416549", "10.1126/science.1136800", "10.1109/tvcg.2013.133", "10.1109/mcg.2009.107", "10.1111/j.1467-8659.2010.01725.x", "10.1109/tvcg.2011.258", "10.1109/tvcg.2013.213", "10.1111/cgf.12800", "10.1109/tvcg.2009.136", "10.1109/pacificvis.2016.7465271", "10.1109/tvcg.2008.116", "10.1109/tvcg.2008.184", "10.1109/tvcg.2008.140", "10.1145/237170.237216", "10.1109/tvcg.2004.39", "10.1109/tvcg.2015.2467431", "10.1109/pacificvis.2017.8031592", "10.1109/pacificvis.2013.6596138", "10.2312/vissym/eurovis07/115-122", "10.1175/1520-0493(2002)130", "10.1109/tvcg.2006.165", "10.1109/tvcg.2011.246", "10.1109/tvcg.2012.110", "10.1109/pacificvis.2011.5742378", "10.1111/j.1467-8659.2009.01689.x", "10.2312/eggh/hpg12/033-037", "10.1145/37402.37422", "10.1109/tvcg.2012.284", "10.1109/visual.2003.1250402", "10.1109/tvcg.2006.164", "10.1109/tvcg.2012.80", "10.1109/tvcg.2008.143", "10.1109/tvcg.2011.100", "10.1016/j.physleta.2006.08.058", "10.1109/mcise.2003.1182960", "10.1109/visual.1999.809910", "10.1109/tvcg.2010.20"], "wos": 1, "children": [{"doi": "10.1109/tvcg.2019.2934255", "title": "TSR-TVD: Temporal Super-Resolution for Time-Varying Data Analysis and Visualization", "year": "2019", "conferenceName": "SciVis", "authors": "Jun Han;Chaoli Wang", "citationCount": "5", "affiliation": "Han, J (Corresponding Author), Univ Notre Dame, Dept Comp Sci \\& Engn, Notre Dame, IN 46556 USA. Han, Jun; Wang, Chaoli, Univ Notre Dame, Dept Comp Sci \\& Engn, Notre Dame, IN 46556 USA.", "countries": "USA", "abstract": "We present TSR-TVD, a novel deep learning framework that generates temporal super-resolution (TSR) of time-varying data (TVD) using adversarial learning. TSR-TVD is the first work that applies the recurrent generative network (RGN), a combination of the recurrent neural network (RNN) and generative adversarial network (GAN), to generate temporal high-resolution volume sequences from low-resolution ones. The design of TSR-TVD includes a generator and a discriminator. The generator takes a pair of volumes as input and outputs the synthesized intermediate volume sequence through forward and backward predictions. The discriminator takes the synthesized intermediate volumes as input and produces a score indicating the realness of the volumes. Our method handles multivariate data as well where the trained network from one variable is applied to generate TSR for another variable. To demonstrate the effectiveness of TSR-TVD, we show quantitative and qualitative results with several time-varying multivariate data sets and compare our method against standard linear interpolation and solutions solely based on RNN or CNN.", "keywords": "Time-varying data visualization,super-resolution,deep learning,recurrent generative network", "link": "http://dx.doi.org/10.1109/TVCG.2019.2934255", "refList": ["10.1109/iccv.2017.478", "10.1016/j.ijvsm.2017.05.001", "10.1109/cvpr.2018.00938", "10.1109/iccv.2015.123", "10.3390/e19020047", "10.1109/tvcg.2013.133", "10.1111/cgf.13620", "10.1109/visual.2003.1250413", "10.1109/cvpr.2016.278", "10.1109/tvcg.2008.184", "10.1145/3309993", "10.1109/tvcg.2008.140", "10.1109/pacificvis.2018.00018", "10.1109/icris.2018.00099", "10.1109/cvpr.2017.632", "10.1109/tvcg.2018.2816059", "10.1109/mcg.2007.129", "10.1109/tvcg.2018.2864808", "10.1109/mcg.2018.2881523", "10.1109/tvcg.2015.2467431", "10.1109/72.279181", "10.2312/vissym/eurovis07/115-122", "10.1109/tvcg.2006.165", "10.1162/neco.1997.9.8.1735", "10.1145/3197517.3201304", "10.1109/cvpr.2018.00068", "10.1109/iaeac.2015.7428667", "10.1109/tip.2003.819861", "10.1109/tvcg.2012.110", "10.1109/vds.2017.8573447", "10.1109/tvcg.2018.2796085", "10.1111/j.1467-8659.2009.01689.x", "10.1109/pacificvis.2011.5742378", "10.1109/cvpr.2018.00917", "10.1109/visual.2003.1250402", "10.1109/cvpr.2017.244", "10.1109/cvpr.2016.90", "10.1007/978-3-319-24574-4\\_28", "10.1109/tvcg.2005.38", "10.1109/visual.1999.809910", "10.1109/iccv.2015.515", "10.1007/978-3-319-46475-6\\_43"], "wos": 1, "children": [{"doi": "10.1109/tvcg.2020.3030374", "title": "VC-Net: Deep Volume-Composition Networks for Segmentation and Visualization of Highly Sparse and Noisy Image Data", "year": "2020", "conferenceName": "SciVis", "authors": "Yifan Wang;Guoli Yan;Haikuan Zhu;Sagar Buch;Ying Wang;E. Mark Haacke;Jing Hua;Zichun Zhong", "citationCount": "0", "affiliation": "Wang, YF (Corresponding Author), Wayne State Univ, Dept Comp Sci, Detroit, MI 48202 USA. Wang, Yifan; Yan, Guoli; Zhu, Haikuan; Hua, Jing; Zhong, Zichun, Wayne State Univ, Dept Comp Sci, Detroit, MI 48202 USA. Buch, Sagar; Wang, Ying; Haacke, Ewart Mark, Wayne State Univ, Dept Radiol, Detroit, MI 48201 USA.", "countries": "USA", "abstract": "The fundamental motivation of the proposed work is to present a new visualization-guided computing paradigm to combine direct 3D volume processing and volume rendered clues for effective 3D exploration. For example, extracting and visualizing microstructures in-vivo have been a long-standing challenging problem. However, due to the high sparseness and noisiness in cerebrovasculature data as well as highly complex geometry and topology variations of micro vessels, it is still extremely challenging to extract the complete 3D vessel structure and visualize it in 3D with high fidelity. In this paper, we present an end-to-end deep learning method, VC-Net, for robust extraction of 3D microvascular structure through embedding the image composition, generated by maximum intensity projection (MIP), into the 3D volumetric image learning process to enhance the overall performance. The core novelty is to automatically leverage the volume visualization technique (e.g., MIP - a volume rendering scheme for 3D volume images) to enhance the 3D data exploration at the deep learning level. The MIP embedding features can enhance the local vessel signal (through canceling out the noise) and adapt to the geometric variability and scalability of vessels, which is of great importance in microvascular tracking. A multi-stream convolutional neural network (CNN) framework is proposed to effectively learn the 3D volume and 2D MIP feature vectors, respectively, and then explore their inter-dependencies in a joint volume-composition embedding space by unprojecting the 2D feature vectors into the 3D volume embedding space. It is noted that the proposed framework can better capture the small/micro vessels and improve the vessel connectivity. To our knowledge, this is the first time that a deep learning framework is proposed to construct a joint convolutional embedding space, where the computed vessel probabilities from volume rendering based 2D projection and 3D volume can be explored and integrated synergistically. Experimental results are evaluated and compared with the traditional 3D vessel segmentation methods and the state-of-the-art in deep learning, by using extensive public and real patient (micro- )cerebrovascular image datasets. The application of this accurate segmentation and visualization of sparse and complicated 3D microvascular structure facilitated by our method demonstrates the potential in a powerful MR arteriogram and venogram diagnosis of vascular disease.", "keywords": "Deep neural network,3D cerebrovascular segmentation and visualization,maximum intensity projection (MIP),joint embedding", "link": "http://dx.doi.org/10.1109/TVCG.2020.3030374", "refList": ["10.1109/cluster.2018.00036", "10.1109/iccv.2015.123", "10.1109/tvcg.2013.133", "10.1109/cvpr.2017.19", "10.1109/tvcg.2019.2934312", "10.1007/978-3-319-46487-9\\_40", "10.1109/tvcg.2006.175", "10.1109/tvcg.2007.70523", "10.1109/tvcg.2018.2880207", "10.1145/3309993", "10.1109/pacificvis.2018.00018", "10.1109/iccv.2017.244", "10.1109/cvpr.2017.632", "10.1109/tvcg.2018.2816059", "10.1109/pacificvis.2009.4906852", "10.1109/tvcg.2018.2864808", "10.1109/mcg.2018.2881523", "10.1109/tvcg.2015.2467431", "10.1109/tpami.2015.2439281", "10.1109/pacificvis48177.2020.8737", "10.1109/cvpr.2019.00244", "10.1109/tvcg.2006.165", "10.1109/bigdata.2018.8622520", "10.1007/978-3-319-46466-4\\_29", "10.1109/visual.2019.8933759", "10.1145/3197517.3201304", "10.1109/pacificvis.2011.5742378", "10.1109/cvpr.2006.91", "10.1109/pacificvis.2011.5742369", "10.1109/tvcg.2019.2934255", "10.1109/cvpr.2016.90", "10.1007/978-3-319-24574-4\\_28", "10.1109/pacificvis.2019.00041", "10.1109/tvcg.2019.2934332", "10.1109/cvpr.2018.00916", "10.1007/978-3-319-46475-6\\_43"], "wos": 1, "children": [], "len": 1}, {"doi": "10.1109/pacificvis48177.2020.8737", "year": "2020", "title": "SSR-VFD: Spatial Super-Resolution for Vector Field Data Analysis and Visualization", "conferenceName": "PacificVis", "authors": "Li Guo;Shaojie Ye;Jun Han;Hao Zheng;Han Gao;Danny Z. Chen;Jian{-}Xun Wang;Chaoli Wang", "citationCount": "1", "affiliation": "Guo, L (Corresponding Author), Nankai Univ, Tianjin, Peoples R China.\nGuo, Li, Nankai Univ, Tianjin, Peoples R China.\nYe, Shaojie, Zhejiang Univ, Hangzhou, Zhejiang, Peoples R China.\nHan, Jun; Zheng, Hao; Gao, Han; Chen, Danny Z.; Wang, Jian-Xun; Wang, Chaoli, Univ Notre Dame, Notre Dame, IN 46556 USA.", "countries": "USA;China", "abstract": "We present SSR-VFD, a novel deep learning framework that produces coherent spatial super-resolution (SSR) of three-dimensional vector field data (VFD). SSR-VFD is the first work that advocates a machine learning approach to generate high-resolution vector fields from low-resolution ones. The core of SSR-VFD lies in the use of three separate neural nets that take the three components of a low-resolution vector field as input and jointly output a synthesized high-resolution vector field. To capture spatial coherence, we take into account magnitude and angle losses in network optimization. Our method can work in the in situ scenario where VFD are down-sampled at simulation time for storage saving and these reduced VFD are upsampled back to their original resolution during postprocessing. To demonstrate the effectiveness of SSR-VFD, we show quantitative and qualitative results with several vector field data sets of different characteristics and compare our method against volume upscaling using bicubic interpolation, and two solutions based on CNN and GAN, respectively.", "keywords": "Spatial super-resolution; vector field data; convolutional neural network; deep learning", "link": "https://doi.org/10.1109/PacificVis48177.2020.8737", "refList": ["10.1016/j.ijvsm.2017.05.001", "10.1016/j.jvs.2005.01.020", "10.1109/iccv.2015.123", "10.1111/cgf.13620", "10.1109/cvpr.2019.00831", "10.1109/cvpr.2019.00817", "10.1109/cvpr.2019.00399", "10.1109/tvcg.2019.2934312", "10.1145/3309993", "10.1109/pacificvis.2018.00018", "10.1109/tvcg.2018.2816059", "10.1109/mcg.2018.2881523", "10.1109/tpami.2015.2439281", "10.1109/bigdata.2018.8622520", "10.1145/3197517.3201304", "10.1109/tvcg.2018.2796085", "10.1109/tvcg.2019.2934255", "10.1109/cvpr.2016.90", "10.1109/pacificvis.2019.00041", "10.1111/cgf.13689"], "wos": 1, "children": [{"doi": "10.1109/tvcg.2020.3030374", "title": "VC-Net: Deep Volume-Composition Networks for Segmentation and Visualization of Highly Sparse and Noisy Image Data", "year": "2020", "conferenceName": "SciVis", "authors": "Yifan Wang;Guoli Yan;Haikuan Zhu;Sagar Buch;Ying Wang;E. Mark Haacke;Jing Hua;Zichun Zhong", "citationCount": "0", "affiliation": "Wang, YF (Corresponding Author), Wayne State Univ, Dept Comp Sci, Detroit, MI 48202 USA. Wang, Yifan; Yan, Guoli; Zhu, Haikuan; Hua, Jing; Zhong, Zichun, Wayne State Univ, Dept Comp Sci, Detroit, MI 48202 USA. Buch, Sagar; Wang, Ying; Haacke, Ewart Mark, Wayne State Univ, Dept Radiol, Detroit, MI 48201 USA.", "countries": "USA", "abstract": "The fundamental motivation of the proposed work is to present a new visualization-guided computing paradigm to combine direct 3D volume processing and volume rendered clues for effective 3D exploration. For example, extracting and visualizing microstructures in-vivo have been a long-standing challenging problem. However, due to the high sparseness and noisiness in cerebrovasculature data as well as highly complex geometry and topology variations of micro vessels, it is still extremely challenging to extract the complete 3D vessel structure and visualize it in 3D with high fidelity. In this paper, we present an end-to-end deep learning method, VC-Net, for robust extraction of 3D microvascular structure through embedding the image composition, generated by maximum intensity projection (MIP), into the 3D volumetric image learning process to enhance the overall performance. The core novelty is to automatically leverage the volume visualization technique (e.g., MIP - a volume rendering scheme for 3D volume images) to enhance the 3D data exploration at the deep learning level. The MIP embedding features can enhance the local vessel signal (through canceling out the noise) and adapt to the geometric variability and scalability of vessels, which is of great importance in microvascular tracking. A multi-stream convolutional neural network (CNN) framework is proposed to effectively learn the 3D volume and 2D MIP feature vectors, respectively, and then explore their inter-dependencies in a joint volume-composition embedding space by unprojecting the 2D feature vectors into the 3D volume embedding space. It is noted that the proposed framework can better capture the small/micro vessels and improve the vessel connectivity. To our knowledge, this is the first time that a deep learning framework is proposed to construct a joint convolutional embedding space, where the computed vessel probabilities from volume rendering based 2D projection and 3D volume can be explored and integrated synergistically. Experimental results are evaluated and compared with the traditional 3D vessel segmentation methods and the state-of-the-art in deep learning, by using extensive public and real patient (micro- )cerebrovascular image datasets. The application of this accurate segmentation and visualization of sparse and complicated 3D microvascular structure facilitated by our method demonstrates the potential in a powerful MR arteriogram and venogram diagnosis of vascular disease.", "keywords": "Deep neural network,3D cerebrovascular segmentation and visualization,maximum intensity projection (MIP),joint embedding", "link": "http://dx.doi.org/10.1109/TVCG.2020.3030374", "refList": ["10.1109/cluster.2018.00036", "10.1109/iccv.2015.123", "10.1109/tvcg.2013.133", "10.1109/cvpr.2017.19", "10.1109/tvcg.2019.2934312", "10.1007/978-3-319-46487-9\\_40", "10.1109/tvcg.2006.175", "10.1109/tvcg.2007.70523", "10.1109/tvcg.2018.2880207", "10.1145/3309993", "10.1109/pacificvis.2018.00018", "10.1109/iccv.2017.244", "10.1109/cvpr.2017.632", "10.1109/tvcg.2018.2816059", "10.1109/pacificvis.2009.4906852", "10.1109/tvcg.2018.2864808", "10.1109/mcg.2018.2881523", "10.1109/tvcg.2015.2467431", "10.1109/tpami.2015.2439281", "10.1109/pacificvis48177.2020.8737", "10.1109/cvpr.2019.00244", "10.1109/tvcg.2006.165", "10.1109/bigdata.2018.8622520", "10.1007/978-3-319-46466-4\\_29", "10.1109/visual.2019.8933759", "10.1145/3197517.3201304", "10.1109/pacificvis.2011.5742378", "10.1109/cvpr.2006.91", "10.1109/pacificvis.2011.5742369", "10.1109/tvcg.2019.2934255", "10.1109/cvpr.2016.90", "10.1007/978-3-319-24574-4\\_28", "10.1109/pacificvis.2019.00041", "10.1109/tvcg.2019.2934332", "10.1109/cvpr.2018.00916", "10.1007/978-3-319-46475-6\\_43"], "wos": 1, "children": [], "len": 1}], "len": 3}, {"doi": "10.1111/cgf.14037", "year": "2020", "title": "State of the Art in Time-Dependent Flow Topology: Interpreting Physical Meaningfulness Through Mathematical Properties", "conferenceName": "EuroVis", "authors": "Roxana Bujack;Lin Yan;Ingrid Hotz;Christoph Garth;Bei Wang", "citationCount": "0", "affiliation": "Bujack, R (Corresponding Author), Los Alamos Natl Lab, Los Alamos, NM 87545 USA.\nBujack, Roxana, Los Alamos Natl Lab, Los Alamos, NM 87545 USA.\nYan, Lin; Wang, Bei, Univ Utah, Sci Comp \\& Imaging Inst, Salt Lake City, UT 84112 USA.\nHotz, Ingrid, Linkopings Univ, Sci Visualizat Grp, Linkoping, Sweden.\nGarth, Christoph, Univ Kaiserslautern, Kaiserslautern, Germany.", "countries": "Sweden;Germany;USA", "abstract": "We present a state-of-the-art report on time-dependent flow topology. We survey representative papers in visualization and provide a taxonomy of existing approaches that generalize flow topology from time-independent to time-dependent settings. The approaches are classified based upon four categories: tracking of steady topology, reference frame adaption, pathline classification or clustering, and generalization of critical points. Our unique contributions include introducing a set of desirable mathematical properties to interpret physical meaningfulness for time-dependent flow visualization, inferring mathematical properties associated with selective research papers, and utilizing such properties for classification. The five most important properties identified in the existing literature include coincidence with the steady case, induction of a partition within the domain, Lagrangian invariance, objectivity, and Galilean invariance.", "keywords": "", "link": "https://doi.org/10.1111/cgf.14037", "refList": ["10.2514/6.1995-1715", "10.1111/cgf.12100", "10.1007/978-3-540-70823-0\\_1", "10.1111/cgf.12885", "10.1063/1.857730", "10.1109/tvcg.2019.2934312", "10.1109/tvcg.2013.92", "10.1063/1.166399", "10.1109/tvcg.2005.68.3", "10.1063/1.4971788", "10.1111/cgf.12933", "10.1145/3072959.3073684", "10.1063/1.4982720", "10.1109/tvcg.2018.2864432", "10.1017/s0022112004002526", "10.1109/tvcg.2010.93", "10.1109/pacificvis.2016.7465253", "10.1109/tvcg.2018.2864505", "10.1063/1.858828", "10.1109/tvcg.2019.2934255", "10.5194/npg-9-237-2002", "10.1063/1.4800210", "10.1007/978-3-540-88606-8\\_12", "10.1111/j.1467-8659.2011.01942.x", "10.1109/2945.928168", "10.1007/978-3-662-10388-31", "10.1016/j.physd.2013.01.013", "10.1111/cgf.12358", "10.1017/s002211209900720x", "10.1017/s0022112097008057", "10.1111/j.1467-8659.2009.01546.x", "10.1109/2.35197", "10.1111/j.1467-8659.2012.03089.x", "10.1111/cgf.13319", "10.1109/tvcg.2019.2934375.3", "10.1016/j.crme.2015.08.002.4", "10.1016/s0167-2789(00)00142-1", "10.1111/cgf.12359", "10.1103/physreve.93.063107", "10.1016/j.physd.2009.05.005", "10.1063/1.1477449", "10.1111/j.1467-8659.2009.01686.x", "10.1109/pacificvis.2011.5742374", "10.1017/jfm.2013.391", "10.1111/cgf.12121", "10.1186/1743-422x-3-15", "10.1063/1.3502450", "10.1063/1.868323", "10.1016/j.cnsns.2013.05.002", "10.1109/visual.2004.99", "10.1109/visual.2004.107", "10.1111/j.1467-8659.2009.01604.x", "10.1146/annurev-fluid-010313-141322", "10.1063/1.3690153", "10.1109/tvcg.2019.2934375", "10.1109/tvcg.2013.143", "10.1137/130940633", "10.1016/j.cag.2014.01.007", "10.1016/s0097-8493(02)00056-0", "10.1109/vl.1996.545307", "10.1109/tvcg.2011.284", "10.1109/tvcg.2011.265", "10.1017/jfm.2016.792", "10.1109/tvcg.2013.208", "10.1007/s12650-016-0348-8", "10.1023/b:elas.0000005548.36767.e7", "10.1007/978-1-4939-0419-8\\_\\_9", "10.1007/bf00849110", "10.1615/int.j.uncertaintyquantification.2012003956", "10.1017/s0022112096001802", "10.1017/s0962492902000065", "10.1109/pacificvis.2019.00041", "10.1111/j.1467-8659.2011.01901.x", "10.1109/tvcg.2008.33", "10.1016/j.physd.2005.10.007", "10.1016/s0894-1777(96)00090-8", "10.1145/2517327.2442526", "10.1109/tvcg.2017.2743938", "10.1109/tvcg.2018.2816059", "10.1109/tvcg.2019.2934242", "10.2514/6.1995-1715.4", "10.1111/cgf.12109", "10.1109/tvcg.2011.269", "10.1109/visual.1990.146359", "10.1111/j.1467-8659.2003.00723.x", "10.5194/npg-18-977-2011", "10.1109/visual.1998.745296", "10.1109/tvcg.2007.70557", "10.1109/tvcg.2014.2312012"], "wos": 1, "children": [], "len": 1}], "len": 9}, {"doi": "10.1109/tvcg.2020.3030374", "title": "VC-Net: Deep Volume-Composition Networks for Segmentation and Visualization of Highly Sparse and Noisy Image Data", "year": "2020", "conferenceName": "SciVis", "authors": "Yifan Wang;Guoli Yan;Haikuan Zhu;Sagar Buch;Ying Wang;E. Mark Haacke;Jing Hua;Zichun Zhong", "citationCount": "0", "affiliation": "Wang, YF (Corresponding Author), Wayne State Univ, Dept Comp Sci, Detroit, MI 48202 USA. Wang, Yifan; Yan, Guoli; Zhu, Haikuan; Hua, Jing; Zhong, Zichun, Wayne State Univ, Dept Comp Sci, Detroit, MI 48202 USA. Buch, Sagar; Wang, Ying; Haacke, Ewart Mark, Wayne State Univ, Dept Radiol, Detroit, MI 48201 USA.", "countries": "USA", "abstract": "The fundamental motivation of the proposed work is to present a new visualization-guided computing paradigm to combine direct 3D volume processing and volume rendered clues for effective 3D exploration. For example, extracting and visualizing microstructures in-vivo have been a long-standing challenging problem. However, due to the high sparseness and noisiness in cerebrovasculature data as well as highly complex geometry and topology variations of micro vessels, it is still extremely challenging to extract the complete 3D vessel structure and visualize it in 3D with high fidelity. In this paper, we present an end-to-end deep learning method, VC-Net, for robust extraction of 3D microvascular structure through embedding the image composition, generated by maximum intensity projection (MIP), into the 3D volumetric image learning process to enhance the overall performance. The core novelty is to automatically leverage the volume visualization technique (e.g., MIP - a volume rendering scheme for 3D volume images) to enhance the 3D data exploration at the deep learning level. The MIP embedding features can enhance the local vessel signal (through canceling out the noise) and adapt to the geometric variability and scalability of vessels, which is of great importance in microvascular tracking. A multi-stream convolutional neural network (CNN) framework is proposed to effectively learn the 3D volume and 2D MIP feature vectors, respectively, and then explore their inter-dependencies in a joint volume-composition embedding space by unprojecting the 2D feature vectors into the 3D volume embedding space. It is noted that the proposed framework can better capture the small/micro vessels and improve the vessel connectivity. To our knowledge, this is the first time that a deep learning framework is proposed to construct a joint convolutional embedding space, where the computed vessel probabilities from volume rendering based 2D projection and 3D volume can be explored and integrated synergistically. Experimental results are evaluated and compared with the traditional 3D vessel segmentation methods and the state-of-the-art in deep learning, by using extensive public and real patient (micro- )cerebrovascular image datasets. The application of this accurate segmentation and visualization of sparse and complicated 3D microvascular structure facilitated by our method demonstrates the potential in a powerful MR arteriogram and venogram diagnosis of vascular disease.", "keywords": "Deep neural network,3D cerebrovascular segmentation and visualization,maximum intensity projection (MIP),joint embedding", "link": "http://dx.doi.org/10.1109/TVCG.2020.3030374", "refList": ["10.1109/cluster.2018.00036", "10.1109/iccv.2015.123", "10.1109/tvcg.2013.133", "10.1109/cvpr.2017.19", "10.1109/tvcg.2019.2934312", "10.1007/978-3-319-46487-9\\_40", "10.1109/tvcg.2006.175", "10.1109/tvcg.2007.70523", "10.1109/tvcg.2018.2880207", "10.1145/3309993", "10.1109/pacificvis.2018.00018", "10.1109/iccv.2017.244", "10.1109/cvpr.2017.632", "10.1109/tvcg.2018.2816059", "10.1109/pacificvis.2009.4906852", "10.1109/tvcg.2018.2864808", "10.1109/mcg.2018.2881523", "10.1109/tvcg.2015.2467431", "10.1109/tpami.2015.2439281", "10.1109/pacificvis48177.2020.8737", "10.1109/cvpr.2019.00244", "10.1109/tvcg.2006.165", "10.1109/bigdata.2018.8622520", "10.1007/978-3-319-46466-4\\_29", "10.1109/visual.2019.8933759", "10.1145/3197517.3201304", "10.1109/pacificvis.2011.5742378", "10.1109/cvpr.2006.91", "10.1109/pacificvis.2011.5742369", "10.1109/tvcg.2019.2934255", "10.1109/cvpr.2016.90", "10.1007/978-3-319-24574-4\\_28", "10.1109/pacificvis.2019.00041", "10.1109/tvcg.2019.2934332", "10.1109/cvpr.2018.00916", "10.1007/978-3-319-46475-6\\_43"], "wos": 1, "children": [], "len": 1}], "len": 13}, {"doi": "10.1109/tvcg.2018.2864815", "title": "An Interactive Framework for Visualization of Weather Forecast Ensembles", "year": "2018", "conferenceName": "SciVis", "authors": "Bo Ma 0002;Alireza Entezari", "citationCount": "1", "affiliation": "Ma, B (Corresponding Author), Univ Florida, Gainesville, FL 32611 USA. Ma, Bo; Entezari, Alireza, Univ Florida, Gainesville, FL 32611 USA.", "countries": "USA", "abstract": "Numerical Weather Prediction (NWP) ensembles are commonly used to assess the uncertainty and confidence in weather forecasts. Spaghetti plots are conventional tools for meteorologists to directly examine the uncertainty exhibited by ensembles, where they simultaneously visualize isocontours of all ensemble members. To avoid visual clutter in practical usages, one needs to select a small number of informative isovalues for visual analysis. Moreover, due to the complex topology and variation of ensemble isocontours, it is often a challenging task to interpret the spaghetti plot for even a single isovalue in large ensembles. In this paper, we propose an interactive framework for uncertainty visualization of weather forecast ensembles that significantly improves and expands the utility of spaghetti plots in ensemble analysis. Complementary to state-of-the-art methods, our approach provides a complete framework for visual exploration of ensemble isocontours, including isovalue selection, interactive isocontour variability exploration, and interactive sub-region selection and re-analysis. Our framework is built upon the high-density clustering paradigm, where the mode structure of the density function is represented as a hierarchy of nested subsets of the data. We generalize the high-density clustering for isocontours and propose a bandwidth selection method for estimating the density function of ensemble isocontours. We present novel visualizations based on high-density clustering results, called the mode plot and the simplified spaghetti plot. The proposed mode plot visually encodes the structure provided by the high-density clustering result and summarizes the distribution of ensemble isocontours. It also enables the selection of subsets of interesting isocontours, which are interactively highlighted in a linked spaghetti plot for providing spatial context. To provide an interpretable overview of the positional variability of isocontours, our system allows for selection of informative isovalues from the simplified spaghetti plot. Due to the spatial variability of ensemble isocontours, the system allows for interactive selection and focus on sub-regions for local uncertainty and clustering re-analysis. We examine a number of ensemble datasets to establish the utility of our approach and discuss its advantages over state-of-the-art visual analysis tools for ensemble data.", "keywords": "Spaghetti plots,ensemble visualization,uncertainty visualization,high-density clustering,ensemble forecasting", "link": "http://dx.doi.org/10.1109/TVCG.2018.2864815", "refList": ["10.1109/tvcg.2013.143", "10.1109/tvcg.2014.2346332", "10.1109/tvcg.2015.2467204", "10.1109/tvcg.2017.2745178", "10.1111/cgf.12100", "10.1109/pacificvis.2016.7465251", "10.1080/01621459.2016.1228536", "10.1109/34.400568", "10.1111/cgf.12898", "10.1109/icdmw.2009.55", "10.1109/tvcg.2013.2297914", "10.18637/jss.v021.i07", "10.1109/tvcg.2015.2467754", "10.1109/tvcg.2010.247", "10.1109/tvcg.2015.2467958", "10.1109/tvcg.2016.2598868", "10.1111/j.1467-8659.2011.01944.x", "10.1007/978-1-4471-2804-5\\_6", "10.1109/tvcg.2010.181", "10.1109/pacificvis.2016.7465271", "10.1109/mcg.2014.52", "10.1145/3002151.3002165", "10.1111/j.1467-8659.2009.01697.x", "10.1007/978-1-4471-6497-5\\_1", "10.1007/s11222-013-9400-x", "10.1109/tvcg.2017.2776935", "10.1016/j.cag.2017.01.006", "10.1109/tvcg.2013.208", "10.1109/tvcg.2015.2468093", "10.1146/annurev-statistics-031017-100045", "10.1109/tvcg.2014.2307892", "10.1111/j.1467-8659.2009.01689.x", "10.1145/37402.37422", "10.1109/tvcg.2015.2507592", "10.1118/1.596225", "10.5194/gmd-8-2329-2015", "10.1109/tvcg.2014.2346448", "10.1111/j.1467-8659.2011.01942.x", "10.1109/pacificvis.2016.7465272", "10.1109/tvcg.2016.2598830", "10.1109/tvcg.2016.2637333", "10.1109/tvcg.2016.2598869"], "wos": 1, "children": [{"doi": "10.1109/tvcg.2020.3030466", "title": "Uncertainty in Continuous Scatterplots, Continuous Parallel Coordinates, and Fibers", "year": "2020", "conferenceName": "SciVis", "authors": "Boyan Zheng;Filip Sadlo", "citationCount": "0", "affiliation": "Zheng, BY (Corresponding Author), Heidelberg Univ, Heidelberg, Germany. Zheng, Boyan; Sadlo, Filip, Heidelberg Univ, Heidelberg, Germany.", "countries": "Germany", "abstract": "In this paper, we introduce uncertainty to continuous scatterplots and continuous parallel coordinates. We derive respective models, validate them with sampling-based brute-force schemes, and present acceleration strategies for their computation. At the same time, we show that our approach lends itself as well for introducing uncertainty into the definition of fibers in bivariate data. Finally, we demonstrate the properties and the utility of our approach using specifically designed synthetic cases and simulated data.", "keywords": "Multivariate data,uncertainty visualization,uncertain continuous scatterplots,uncertain continuous parallel coordinates,uncertain fibers", "link": "http://dx.doi.org/10.1109/TVCG.2020.3030466", "refList": ["10.1109/tvcg.2018.2865193", "10.1109/tvcg.2013.143", "10.1109/tvcg.2015.2467204", "10.1109/pacificvis.2013.6596144", "10.1109/tvcg.2017.2745178", "10.1109/tmm.2016.2614227", "10.1109/scivis.2015.7429488", "10.1111/cgf.12100", "10.1109/pacificvis.2016.7465251", "10.1111/cgf.12898", "10.1109/tvcg.2015.2410278", "10.1109/icdmw.2009.55", "10.1109/tvcg.2015.2467754", "10.1109/tvcg.2010.247", "10.1109/tvcg.2019.2934312", "10.1111/cgf.13397", "10.1109/tvcg.2016.2598868", "10.1111/j.1467-8659.2011.01944.x", "10.1109/tvcg.2015.2507569", "10.1109/tvcg.2013.92", "10.1145/1268517.1268563", "10.1109/tvcg.2014.2346455", "10.1109/tvcg.2010.181", "10.1109/tvcg.2018.2853721", "10.1109/tvcg.2008.140", "10.1007/s12650-015-0341-7", "10.1109/mcg.2014.52", "10.1109/tvcg.2018.2864815", "10.1111/j.1467-8659.2012.03095.x", "10.1109/tvcg.2013.138", "10.1109/tvcg.2019.2934242", "10.3390/e20070540", "10.1016/j.jcp.2007.02.014", "10.1111/cgf.13999", "10.1109/tvcg.2017.2779501", "10.1111/cgf.12390", "10.1109/tvcg.2014.2307892", "10.1111/cgf.13531", "10.1109/tvcg.2013.152", "10.1038/nature14956", "10.1007/978-3-540-88606-8\\_4", "10.1109/mcg.2005.71", "10.1111/j.1467-8659.2011.01942.x", "10.1109/tvcg.2019.2934800", "10.1109/tvcg.2016.2598830", "10.1109/cvpr.2005.188", "10.1109/tvcg.2011.261", "10.1111/cgf.13731", "10.1109/tvcg.2017.2754480"], "wos": 1, "children": [], "len": 1}, {"doi": "10.1111/cgf.13706", "year": "2019", "title": "Analysis of Decadal Climate Predictions with User-guided Hierarchical Ensemble Clustering", "conferenceName": "EuroVis", "authors": "Christopher P. Kappe;Michael B{\\\"{o}}ttinger;Heike Leitte", "citationCount": "0", "affiliation": "Kappe, CP (Corresponding Author), TU Kaiserslautern, Dept Comp Sci, Kaiserslautern, Germany.\nKappe, C. P.; Leitte, H., TU Kaiserslautern, Dept Comp Sci, Kaiserslautern, Germany.\nBoettinger, M., Deutsch Klimarechenzentrum DKRZ, Hamburg, Germany.", "countries": "Germany", "abstract": "In order to gain probabilistic results, ensemble simulation techniques are increasingly applied in the weather and climate sciences (as well as in various other scientific disciplines). In many cases, however, only mean results or other abstracted quantities such as percentiles are used for further analyses and dissemination of the data. In this work, we aim at a more detailed visualization of the temporal development of the whole ensemble that takes the variability of all single members into account. We propose a visual analytics tool that allows an effective analysis process based on a hierarchical clustering of the time-dependent scalar fields. The system includes a flow chart that shows the ensemble members' cluster affiliation over time, reflecting the whole cluster hierarchy. The latter one can be dynamically explored using a visualization derived from a dendrogram. As an aid in linking the different views, we have developed an adaptive coloring scheme that takes into account cluster similarity and the containment relationships. Finally, standard visualizations of the involved field data (cluster means, ground truth data, etc.) are also incorporated. We include results of our work on real-world datasets to showcase the utility of our approach.", "keywords": "", "link": "https://doi.org/10.1111/cgf.13706", "refList": ["10.1109/tvcg.2010.223", "10.1109/pacificvis.2016.7465251", "10.1109/icdmw.2009.55", "10.1109/tvcg.2016.2598868", "10.1109/tvcg.2015.2507569", "10.1145/3025453.3025912", "10.1109/tvcg.2018.2864815", "10.1109/tvcg.2013.162", "10.1109/tvcg.2014.2346277", "10.1109/tvcg.2011.239", "10.1109/2945.981848", "10.1109/tvcg.2014.2388208", "10.1175/bams-d-15-00184.1", "10.1109/tvcg.2008.166", "10.5194/gmd-10-571-2017", "10.1109/tvcg.2015.2507592", "10.1175/1520-0442(1996)009", "10.1111/cgf.13164", "10.1109/tvcg.2016.2598830", "10.1109/tkde.2014.2373384", "10.1109/tvcg.2014.2346433"], "wos": 1, "children": [], "len": 1}], "len": 5}, {"doi": "10.1109/pacificvis.2018.00037", "year": "2018", "title": "A Comparative 3D Visualization Tool for Observation of Mode Water", "conferenceName": "PacificVis", "authors": "Midori Yano;Takayuki Itoh;Yuusuke Tanaka;Daisuke Matsuoka;Fumiaki Araki", "citationCount": "3", "affiliation": "Yano, M (Corresponding Author), Ochanomizu Univ, Tokyo, Japan.\nYano, Midori; Itoh, Takayuki, Ochanomizu Univ, Tokyo, Japan.\nTanaka, Yuusuke; Matsuoka, Daisuke; Araki, Fumiaki, Japan Agcy Marine Earth Sci \\& Technol, Tokyo, Japan.", "countries": "Japan", "abstract": "Mode water forms a 3D region of seawater mass, which has similar physical characteristics values. Research and observation of mode water have a long history in physical oceanography because analysis of mode water brings the understanding of various natural phenomena. There have been various definitions of mode water, and comparison of mode water regions extracted with such various definitions is an important issue in this field. This paper presents our study on comparative 3D visualization tool for the comparison of mode water regions. We extract pairs of outer boundaries of mode water regions as isosurfaces and calculate dissimilarity values between the pairs. The tool visualizes the multi-dimensional vectors of the dissimilarity values by Parallel Coordinate Plots (PCP) and provides a user interface to specify particular pairs of mode water regions so that we can comparatively visualize the shapes of the regions. This paper introduces our experiment on a comparison of mode water regions between an observation and a simulation datasets using the presented tool.", "keywords": "Comparative visualization; Scientific visualization; Volume dataset; Ocean data; Mode water; 3D shape similarity; PCP; Isosurface", "link": "https://doi.org/10.1109/PacificVis.2018.00037", "refList": ["10.1002/2014jc009861", "10.1016/0011-7471(69)90034-5", "10.1109/2945.506226", "10.1175/2011jpo4513.1", "10.1175/2010jpo4261.1", "10.1109/pacificvis.2016.7465271", "10.1016/j.dsr.2014.10.009", "10.1109/smi.2004.1314504", "10.1002/2015gl067495", "10.1109/pacificvis.2016.7465272", "10.1111/1467-8659.00669", "10.1007/s10872-015-0300-x", "10.1023/a:1025507725222", "10.1175/2010jcli3435.1"], "wos": 1, "children": [{"doi": "10.1111/cgf.13731", "year": "2019", "title": "The State of the Art in Visual Analysis Approaches for Ocean and Atmospheric Datasets", "conferenceName": "EuroVis", "authors": "Shehzad Afzal;Mohamad Mazen Hittawe;Sohaib Ghani;Tahira Jamil;Omar M. Knio;Markus Hadwiger;Kevin I.{-}J. Ho", "citationCount": "0", "affiliation": "Afzal, S (Corresponding Author), King Abdullah Univ Sci \\& Technol, Thuwal, Saudi Arabia.\nAfzal, S.; Hittawe, M. M.; Ghani, S.; Jamil, T.; Knio, O.; Hadwiger, M.; Hoteit, I, King Abdullah Univ Sci \\& Technol, Thuwal, Saudi Arabia.", "countries": "Arabia", "abstract": "The analysis of ocean and atmospheric datasets offers a unique set of challenges to scientists working in different application areas. These challenges include dealing with extremely large volumes of multidimensional data, supporting interactive visual analysis, ensembles exploration and visualization, exploring model sensitivities to inputs, mesoscale ocean features analysis, predictive analytics, heterogeneity and complexity of observational data, representing uncertainty, and many more. Researchers across disciplines collaborate to address such challenges, which led to significant research and development advances in ocean and atmospheric sciences, and also in several relevant areas such as visualization and visual analytics, big data analytics, machine learning and statistics. In this report, we perform an extensive survey of research advances in the visual analysis of ocean and atmospheric datasets. First, we survey the task requirements by conducting interviews with researchers, domain experts, and end users working with these datasets on a spectrum of analytics problems in the domain of ocean and atmospheric sciences. We then discuss existing models and frameworks related to data analysis, sense-making, and knowledge discovery for visual analytics applications. We categorize the techniques, systems, and tools presented in the literature based on the taxonomies of task requirements, interaction methods, visualization techniques, machine learning and statistical methods, evaluation methods, data types, data dimensions and size, spatial scale and application areas. We then evaluate the task requirements identified based on our interviews with domain experts in the context of categorized research based on our taxonomies, and existing models and frameworks of visual analytics to determine the extent to which they fulfill these task requirements, and identify the gaps in current research. In the last part of this report, we summarize the trends, challenges, and opportunities for future research in this area. (see http://www.acm.org/about/class/class/2012) )", "keywords": "", "link": "https://doi.org/10.1111/cgf.13731", "refList": ["10.1111/cgf.12898", "10.1109/icdmw.2009.55", "10.1109/tvcg.2013.144", "10.1109/tvcg.2015.2467754", "10.1109/tvcg.2015.2507569", "10.1109/tvcg.2014.2346455", "10.1111/cgf.12901", "10.1109/tvcg.2008.184", "10.1109/mc.2013.119", "10.1111/j.1467-8659.2009.01697.x", "10.1109/tvcg.2009.200", "10.1111/cgf.12649", "10.1109/2945.981847", "10.1109/tvcg.2014.2346481", "10.1109/tvcg.2012.190", "10.1109/mis.2006.75", "10.1109/iv.2015.13", "10.1111/cgf.12135", "10.1109/vast.2009.5332586", "10.1109/pacificvis.2011.5742369", "10.1109/tvcg.2008.131", "10.1109/tvcg.2013.131", "10.1109/tvcg.2010.82", "10.1109/pacificvis.2015.7156374", "10.1111/cgf.12886", "10.1109/tvcg.2016.2598869", "10.1109/vast.2012.6400553", "10.1109/pacificvis.2013.6596144", "10.1109/tvcg.2017.2745178", "10.1109/tvcg.2015.2410278", "10.1111/cgf.12931", "10.1109/tvcg.2009.155", "10.1109/pacificvis.2015.7156366", "10.1109/mcg.2015.121", "10.1007/978-1-4471-2804-5\\_6", "10.1109/ldav.2015.7348068", "10.1007/978-1-4471-6497-5\\_1", "10.1109/pacificvis.2009.4906852", "10.1111/cgf.12646", "10.1109/tvcg.2016.2607204", "10.1109/tvcg.2011.162", "10.1177/1473871612465214", "10.1109/mcg.2017.3621228", "10.1109/tvcg.2012.110", "10.1109/sc.2014.40", "10.5194/gmd-8-2329-2015", "10.1109/tvcg.2012.80", "10.1109/tvcg.2014.2346448", "10.1109/ldav.2012.6378978", "10.1007/s10915-011-9501-7", "10.1109/tvcg.2016.2598830", "10.1109/tvcg.2007.70515", "10.1109/vast.2011.6102460", "10.1109/pacificvis.2017.8031584", "10.1109/tvcg.2016.2637904", "10.1175/2009jtecha1374.1", "10.1109/tvcg.2015.2467591", "10.1109/tvcg.2015.2467204", "10.1109/tvcg.2008.59", "10.1109/tvcg.2013.143", "10.1109/tvcg.2008.119", "10.1109/tvcg.2015.2467411", "10.1109/icdmw.2009.91", "10.1109/tvcg.2016.2598868", "10.1109/tvcg.2017.2661309", "10.1109/vl.1996.545307", "10.1109/tvcg.2007.70523", "10.1109/tvcg.2008.140", "10.1109/icra.2012.6224689", "10.1109/tvcg.2010.80", "10.1167/tvst.7.1.16", "10.1109/pacificvis.2018.00037", "10.1111/cgf.13210", "10.1109/tvcg.2017.2698041", "10.1109/iv.2010.51", "10.1109/tvcg.2016.2640960", "10.1109/tvcg.2010.170", "10.1103/physrevd.71.077102", "10.5194/npg-22-545-2015", "10.1109/tvcg.2014.2307892", "10.1111/cgf.12650", "10.1109/iv.2009.38", "10.2312/pe.envirvis.envirvis13.053-057", "10.1145/3122948.3122952", "10.1109/ldav.2014.7013208", "10.1038/nature14956", "10.1109/vast.2015.7347671", "10.1109/vast.2015.7347634", "10.1109/tvcg.2014.2346755", "10.1177/1473871613481692", "10.1109/ldav.2017.8231849", "10.1109/tvcg.2017.2773071", "10.1109/iv.2011.79", "10.1109/tvcg.2013.10", "10.1109/tvcg.2008.157", "10.1111/j.1467-8659.2009.01664.x", "10.1109/pacificvis.2016.7465251", "10.1109/vast.2014.7042489", "10.1109/mis.2006.100", "10.1109/tvcg.2010.247", "10.1109/tvcg.2016.2534560", "10.1109/tvcg.2010.181", "10.1109/tvcg.2018.2864817", "10.1109/vast.2015.7347635", "10.1109/tvcg.2018.2864901", "10.1109/hicss.2016.183", "10.1109/iv.2010.32", "10.1111/j.1467-8659.2011.01948.x", "10.1109/tvcg.2017.2743989", "10.1109/pacificvis.2016.7465272", "10.1109/tvcg.2008.69", "10.1109/tvcg.2008.139", "10.1109/iv.2011.12", "10.1111/cgf.12520"], "wos": 1, "children": [{"doi": "10.1109/tvcg.2020.3030466", "title": "Uncertainty in Continuous Scatterplots, Continuous Parallel Coordinates, and Fibers", "year": "2020", "conferenceName": "SciVis", "authors": "Boyan Zheng;Filip Sadlo", "citationCount": "0", "affiliation": "Zheng, BY (Corresponding Author), Heidelberg Univ, Heidelberg, Germany. Zheng, Boyan; Sadlo, Filip, Heidelberg Univ, Heidelberg, Germany.", "countries": "Germany", "abstract": "In this paper, we introduce uncertainty to continuous scatterplots and continuous parallel coordinates. We derive respective models, validate them with sampling-based brute-force schemes, and present acceleration strategies for their computation. At the same time, we show that our approach lends itself as well for introducing uncertainty into the definition of fibers in bivariate data. Finally, we demonstrate the properties and the utility of our approach using specifically designed synthetic cases and simulated data.", "keywords": "Multivariate data,uncertainty visualization,uncertain continuous scatterplots,uncertain continuous parallel coordinates,uncertain fibers", "link": "http://dx.doi.org/10.1109/TVCG.2020.3030466", "refList": ["10.1109/tvcg.2018.2865193", "10.1109/tvcg.2013.143", "10.1109/tvcg.2015.2467204", "10.1109/pacificvis.2013.6596144", "10.1109/tvcg.2017.2745178", "10.1109/tmm.2016.2614227", "10.1109/scivis.2015.7429488", "10.1111/cgf.12100", "10.1109/pacificvis.2016.7465251", "10.1111/cgf.12898", "10.1109/tvcg.2015.2410278", "10.1109/icdmw.2009.55", "10.1109/tvcg.2015.2467754", "10.1109/tvcg.2010.247", "10.1109/tvcg.2019.2934312", "10.1111/cgf.13397", "10.1109/tvcg.2016.2598868", "10.1111/j.1467-8659.2011.01944.x", "10.1109/tvcg.2015.2507569", "10.1109/tvcg.2013.92", "10.1145/1268517.1268563", "10.1109/tvcg.2014.2346455", "10.1109/tvcg.2010.181", "10.1109/tvcg.2018.2853721", "10.1109/tvcg.2008.140", "10.1007/s12650-015-0341-7", "10.1109/mcg.2014.52", "10.1109/tvcg.2018.2864815", "10.1111/j.1467-8659.2012.03095.x", "10.1109/tvcg.2013.138", "10.1109/tvcg.2019.2934242", "10.3390/e20070540", "10.1016/j.jcp.2007.02.014", "10.1111/cgf.13999", "10.1109/tvcg.2017.2779501", "10.1111/cgf.12390", "10.1109/tvcg.2014.2307892", "10.1111/cgf.13531", "10.1109/tvcg.2013.152", "10.1038/nature14956", "10.1007/978-3-540-88606-8\\_4", "10.1109/mcg.2005.71", "10.1111/j.1467-8659.2011.01942.x", "10.1109/tvcg.2019.2934800", "10.1109/tvcg.2016.2598830", "10.1109/cvpr.2005.188", "10.1109/tvcg.2011.261", "10.1111/cgf.13731", "10.1109/tvcg.2017.2754480"], "wos": 1, "children": [], "len": 1}], "len": 3}], "len": 5}], "len": 27}], "len": 31}, "index": 400, "embedding": [0.17663425207138062, 1.1116995811462402, -1.0662840604782104, -2.350348949432373, -0.5331024527549744, 0.16650904715061188, -0.7643030881881714, 1.0125840902328491, -0.07887148857116699, 0.6472355723381042, 0.21850332617759705, 0.8461326956748962, 1.282434105873108, 0.4129897356033325, -0.7975054383277893, 0.8446729183197021, 1.045634388923645, 0.06589167565107346, -0.3568231463432312, 0.9295654892921448, -0.06630208343267441, 0.0059216925874352455, -0.7117334604263306, 1.3105075359344482, -2.343374252319336, 0.9120747447013855, -0.5536867380142212, 1.0555408000946045, 1.6982771158218384, -1.8664532899856567, 0.2968538701534271, 0.6886342167854309], "projection": [0.3242887258529663, 8.213874816894531], "size": 16, "height": 6, "width": 5}