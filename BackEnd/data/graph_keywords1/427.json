{"data": {"doi": "10.1109/tvcg.2015.2467031", "title": "Visualizing Tensor Normal Distributions at Multiple Levels of Detail", "year": "2015", "conferenceName": "SciVis", "authors": "Amin Abbasloo;Vitalis Wiens;Max Hermann;Thomas Schultz", "citationCount": "10", "affiliation": "Abbasloo, A (Corresponding Author), Univ Bonn, Bonn, Germany. Abbasloo, Amin; Wiens, Vitalis; Hermann, Max; Schultz, Thomas, Univ Bonn, Bonn, Germany.", "countries": "Germany", "abstract": "Despite the widely recognized importance of symmetric second order tensor fields in medicine and engineering, the visualization of data uncertainty in tensor fields is still in its infancy. A recently proposed tensorial normal distribution, involving a fourth order covariance tensor, provides a mathematical description of how different aspects of the tensor field, such as trace, anisotropy, or orientation, vary and covary at each point. However, this wealth of information is far too rich for a human analyst to take in at a single glance, and no suitable visualization tools are available. We propose a novel approach that facilitates visual analysis of tensor covariance at multiple levels of detail. We start with a visual abstraction that uses slice views and direct volume rendering to indicate large-scale changes in the covariance structure, and locations with high overall variance. We then provide tools for interactive exploration, making it possible to drill down into different types of variability, such as in shape or orientation. Finally, we allow the analyst to focus on specific locations of the field, and provide tensor glyph animations and overlays that intuitively depict confidence intervals at those points. Our system is demonstrated by investigating the effects of measurement noise on diffusion tensor MRI, and by analyzing two ensembles of stress tensor fields from solid mechanics.", "keywords": "Uncertainty visualization, tensor visualization, direct volume rendering, interaction, glyph based visualization", "link": "http://dx.doi.org/10.1109/TVCG.2015.2467031", "refList": ["10.1111/j.1467-8659.2011.01933.x", "10.1002/mrm.20965", "10.1002/mrm.20484", "10.1109/tmi.2003.815059", "10.1016/j.media.2013.10.009", "10.1109/tmi.2007.907277", "10.1002/mrm.10331", "10.1109/tvcg.2010.247", "10.1109/tvcg.2009.184", "10.1109/tmi.2011.2111422", "10.1111/j.1467-8659.2011.01944.x", "10.1109/vl.1996.545307", "10.1002/1522-2594(200010)44:4", "10.1016/j.nicl.2014.07.001", "10.1016/j.jmr.2011.09.022", "10.1109/tvcg.2006.181", "10.1007/978-1-84882-299-3\\_14", "10.1109/tvcg.2007.70602", "10.1080/14786440109462720", "10.1111/j.1467-8659.2012.03231.x", "10.1007/3-540-31272-2\\_7", "10.1007/978-3-642-23629-7\\_18", "10.1007/978-1-4471-6497-5\\_1", "10.1016/j.sigpro.2006.02.050", "10.1037/h0071325", "10.1109/mcg.2003.1231171", "10.1111/j.1467-8659.2012.03095.x", "10.1109/pacificvis.2012.6183591", "10.1126/science.290.5500.2319", "10.1109/tvcg.2002.1021579", "10.1007/978-1-84882-299-3\\_1", "10.1161/01.str.30.2.393", "10.1007/s00371-012-0733-9", "10.1109/tvcg.2006.134", "10.1111/j.1467-8659.2009.01675.x", "10.1002/1531-8249(199902)45:2", "10.1002/mrm.10491", "10.1016/j.neuroimage.2006.07.001", "10.1109/tvcg.2008.128", "10.1016/j.neuroimage.2013.05.057", "10.1016/s1053-8119(03)00044-2", "10.1111/j.1467-8659.2012.03097.x", "10.1002/mrm.20318", "10.1109/pacificvis.2014.51", "10.1109/tvcg.2010.199", "10.1111/j.1467-8659.2009.01604.x", "10.1016/j.neuroimage.2009.10.071", "10.1126/science.1215280", "10.1109/2945.856994", "10.1111/j.1467-8659.2011.01942.x", "10.1111/cgf.12099", "10.1109/tvcg.2009.170"], "wos": 1, "children": [{"doi": "10.1111/cgf.13692", "year": "2019", "title": "Towards Glyphs for Uncertain Symmetric Second-Order Tensors", "conferenceName": "EuroVis", "authors": "Tim Gerrits;Christian R{\\\"{o}}ssl;Holger Theisel", "citationCount": "0", "affiliation": "Gerrits, T (Corresponding Author), Univ Magdeburg, Magdeburg, Germany.\nGerrits, Tim; Roessl, Christian; Theisel, Holger, Univ Magdeburg, Magdeburg, Germany.", "countries": "Germany", "abstract": "Measured data often incorporates some amount of uncertainty, which is generally modeled as a distribution of possible samples. In this paper, we consider second-order symmetric tensors with uncertainty. In the 3D case, this means the tensor data consists of 6 coefficients - uncertainty, however, is encoded by 21 coefficients assuming a multivariate Gaussian distribution as model. The high dimension makes the direct visualization of tensor data with uncertainty a difficult problem, which was until now unsolved. The contribution of this paper consists in the design of glyphs for uncertain second-order symmetric tensors in 2D and 3D. The construction consists of a standard glyph for the mean tensor that is augmented by a scalar field that represents uncertainty. We show that this scalar field and therefore the displayed glyph encode the uncertainty comprehensively, i.e., there exists a bijective map between the glyph and the parameters of the distribution. Our approach can extend several classes of existing glyphs for symmetric tensors to additionally encode uncertainty and therefore provides a possible foundation for further uncertain tensor glyph design. For demonstration, we choose the well-known superquadric glyphs, and we show that the uncertainty visualization satisfies all their design constraints.", "keywords": "", "link": "https://doi.org/10.1111/cgf.13692", "refList": ["10.1007/978-1-4471-2804-5\\_6", "10.1109/tvcg.2016.2598998", "10.1111/cgf.12357", "10.1109/tvcg.2014.2346455", "10.1109/tvcg.2010.199", "10.1109/tmi.2003.815059", "10.1109/tvcg.2015.2467435", "10.1111/cgf.13173", "10.1002/mrm.10331", "10.1111/cgf.12099", "10.1111/cgf.12890", "10.1109/tvcg.2015.2467031", "10.1016/j.sigpro.2006.02.050", "10.1007/978-1-4471-6497-5\\_1", "10.2312/vissym/vissym04/147-154", "10.1109/pacificvis.2012.6183591"], "wos": 1, "children": [], "len": 1}, {"doi": "10.1111/cgf.12934", "year": "2016", "title": "State of the Art in Transfer Functions for Direct Volume Rendering", "conferenceName": "EuroVis", "authors": "Patric Ljung;Jens H. Kr{\\\"{u}}ger;M. Eduard Gr{\\\"{o}}ller;Markus Hadwiger;Charles D. Hansen;Anders Ynnerman", "citationCount": "33", "affiliation": "Ljung, P (Corresponding Author), Linkoping Univ, S-58183 Linkoping, Sweden.\nLjung, Patric; Ynnerman, Anders, Linkoping Univ, S-58183 Linkoping, Sweden.\nKrueger, Jens, Univ Duisburg Essen, CoViDAG, Essen, Germany.\nKrueger, Jens; Hansen, Charles D., Univ Utah, Sci Comp \\& Imaging Inst, Salt Lake City, UT 84112 USA.\nGroeller, Eduard, TU Wien, Vienna, Austria.\nGroeller, Eduard, Univ Bergen, N-5020 Bergen, Norway.\nHadwiger, Markus, King Abdullah Univ Sci \\& Technol, Thuwal, Saudi Arabia.", "countries": "USA;Arabia;Germany;Austria;Sweden;Norway", "abstract": "A central topic in scientific visualization is the transfer function (TF) for volume rendering. The TF serves a fundamental role in translating scalar and multivariate data into color and opacity to express and reveal the relevant features present in the data studied. Beyond this core functionality, TFs also serve as a tool for encoding and utilizing domain knowledge and as an expression for visual design of material appearances. TFs also enable interactive volumetric exploration of complex data. The purpose of this state-of-the-art report (STAR) is to provide an overview of research into the various aspects of TFs, which lead to interpretation of the underlying data through the use of meaningful visual representations. The STAR classifies TF research into the following aspects: dimensionality, derived attributes, aggregated attributes, rendering aspects, automation, and user interfaces. The STAR concludes with some interesting research challenges that form the basis of an agenda for the development of next generation TF tools and methodologies.", "keywords": "", "link": "https://doi.org/10.1111/cgf.12934", "refList": ["10.1109/tvcg.2008.198", "10.2312/vissym/vissym04/017-024.8", "10.2312/vissym/vissym02/115-124", "10.1109/tvcg.2011.97", "10.1109/visual.2003.1250413", "10.1109/tvcg.2015.2467031", "10.1109/tvcg.2009.120", "10.1109/pccga.2004.1348348", "10.1111/j.1467-8659.2011.01944.x", "10.1109/tvcg.2008.170", "10.1109/svv.1998.729588", "10.1111/cgf.12365", "10.1109/tvcg.2009.115", "10.1371/journal.pone.0038586", "10.1109/tvcg.2010.195", "10.1109/tvcg.2006.148", "10.1111/cgf.12623", "10.1109/visual.2003.1250386", "10.1109/sccg.2001.945360", "10.1109/ldav.2014.7013202", "10.1109/pacificvis.2014.24", "10.1109/visual.1999.809932", "10.1109/38.865879", "10.1109/tvcg.2011.261", "10.1109/pacificvis.2009.4906854", "10.1109/tvcg.2008.162", "10.2312/vg/vg-pbg08/041-048", "10.2312/vg/vg06/001-008", "10.1109/tvcg.2014.2346411", "10.1109/2945.998670", "10.2312/vissym/eurovis05/263-270", "10.2312/conf/eg2012/stars/075-094", "10.1016/j.cag.2012.02.007", "10.1109/tvcg.2015.2467294", "10.1109/tvcg.2014.2346351", "10.1109/tvcg.2008.25", "10.2312/vissym/eurovis07/115-122", "10.1109/visual.1999.809886", "10.1111/cgf.12624", "10.1109/tvcg.2008.169", "10.1109/tvcg.2002.1021579", "10.1109/tvcg.2007.1051", "10.1109/tvcg.2010.239", "10.1111/cgf.12371", "10.1109/tvcg.2007.70518", "10.1109/tvcg.2014.2346324", "10.1109/visual.1998.745319", "10.1109/jbhi.2013.2263227", "10.1109/tvcg.2012.80", "10.1109/tvcg.2006.100", "10.1007/s10915-011-9501-7", "10.1109/pacificvis.2013.6596129", "10.1109/pacificvis.2010.5429615", "10.1109/tvcg.2006.124", "10.1145/1375714.1375729", "10.1109/visual.2004.48", "10.1109/ldav.2011.6092313", "10.1109/38.920623", "10.2312/vissym/eurovis05/069-076", "10.1109/2945.646238", "10.1016/j.gmod.2003.08.002", "10.1109/tvcg.2010.35", "10.1109/svv.1998.729580", "10.1109/visual.1995.480803", "10.2312/vissym/eurovis06/251-258", "10.2312/vissym/eurovis06/227-234", "10.1109/tvcg.2015.2467431", "10.2312/vissym/vissym04/017-024", "10.1109/tvcg.2006.39", "10.1016/j.cmpb.2007.03.008", "10.1109/pacificvis.2011.5742368", "10.1109/tvcg.2007.47", "10.1111/j.1467-8659.2007.01095.x", "10.1109/tvcg.2010.170", "10.2312/vcbm/vcbm08/101-108", "10.2312/vissym/eurovis06/243-250", "10.1109/visual.2000.885678", "10.2312/vg/vg07/001-008", "10.1109/tvcg.2009.185", "10.1016/j.cag.2008.08.006", "10.1109/icma.2007.4303986", "10.1109/tvcg.2005.38", "10.1109/tvcg.2006.96", "10.1111/j.1467-8659.2009.01474.x", "10.1109/tvcg.2009.189", "10.2312/vissym/eurovis07/131-138", "10.1109/pccga.2002.1167880", "10.1111/j.1467-8659.2012.03123.x", "10.2312/vissym/eurovis05/271-278", "10.1109/tvcg.2009.25", "10.1111/j.1467-8659.2008.01216.x", "10.1109/tvcg.2012.231", "10.1109/tvcg.2011.258", "10.1111/j.1467-8659.2005.00855.x", "10.1109/visual.1996.568113", "10.1109/tvcg.2005.62", "10.1109/tvcg.2011.23", "10.1109/tvcg.2014.2359462", "10.1109/icics.2009.5397587", "10.1109/2945.942694", "10.1109/pacificvis.2009.4906857", "10.1109/tvcg.2007.70591", "10.1109/pacificvis.2010.5429624", "10.1109/visual.2003.1250414", "10.2312/vg/vg05/137-145", "10.1109/tvcg.2012.105", "10.1111/j.1467-8659.2012.03122.x", "10.1109/38.511", "10.1109/2945.856994", "10.1109/tvcg.2006.72", "10.1109/2945.468400", "10.2312/vg/vg10/077-083", "10.1057/ivs.2010.6"], "wos": 1, "children": [{"doi": "10.1109/tvcg.2017.2744078", "title": "An Intelligent System Approach for Probabilistic Volume Rendering Using Hierarchical 3D Convolutional Sparse Coding", "year": "2017", "conferenceName": "SciVis", "authors": "Tran Minh Quan;Junyoung Choi;Haejin Jeong;Won-Ki Jeong", "citationCount": "4", "affiliation": "Ulsan Nat'l Inst. of Science and Technology (UNIST);Ulsan Nat'l Inst. of Science and Technology (UNIST);Ulsan Nat'l Inst. of Science and Technology (UNIST);Ulsan Nat'l Inst. of Science and Technology (UNIST)", "countries": "Ulsan Nat'l Inst. of Science and Technology (UNIST)", "abstract": "In this paper, we propose a novel machine learning-based voxel classification method for highly-accurate volume rendering. Unlike conventional voxel classification methods that incorporate intensity-based features, the proposed method employs dictionary based features learned directly from the input data using hierarchical multi-scale 3D convolutional sparse coding, a novel extension of the state-of-the-art learning-based sparse feature representation method. The proposed approach automatically generates high-dimensional feature vectors in up to 75 dimensions, which are then fed into an intelligent system built on a random forest classifier for accurately classifying voxels from only a handful of selection scribbles made directly on the input data by the user. We apply the probabilistic transfer function to further customize and refine the rendered result. The proposed method is more intuitive to use and more robust to noise in comparison with conventional intensity-based classification methods. We evaluate the proposed method using several synthetic and real-world volume datasets, and demonstrate the methods usability through a user study.", "keywords": "Volume Rendering,Machine Learning,Hierarchically Convolutional Sparse Coding", "link": "http://dx.doi.org/10.1109/TVCG.2017.2744078", "refList": ["10.1207/s15327051hci0701\\_3", "10.1109/tvcg.2008.162", "10.1109/cvpr.2013.57", "10.1109/cvpr.2015.7299149", "10.1109/isbi.2015.7164109", "10.1109/38.920623", "10.1109/tvcg.2009.25", "10.1109/tvcg.2012.231", "10.1109/cvpr.2010.5539957", "10.1007/978-3-319-46726-9\\_56", "10.1109/tsp.2006.881199", "10.1109/cvpr.2006.142", "10.1109/svv.1998.729588", "10.1109/cvpr.2014.394", "10.1111/cgf.12623", "10.1109/icassp.2014.6854992", "10.1111/cgf.12624", "10.1109/tvcg.2002.1021579", "10.1145/54852.378484", "10.1111/cgf.12934", "10.4135/9781412961288.n154", "10.1109/tip.2015.2495260", "10.1109/tvcg.2012.105", "10.1145/3065386", "10.1109/38.511", "10.1109/tvcg.2005.38", "10.1007/978-3-319-12643-2\\_31", "10.1145/360825.360839", "10.2307/1932409", "10.1109/pacificvis.2013.6596129", "10.1109/tvcg.2011.261", "10.1023/a:1010933404324"], "wos": 1, "children": [{"doi": "10.1109/pacificvis.2019.00041", "year": "2019", "title": "DNN-VolVis: Interactive Volume Visualization Supported by Deep Neural Network", "conferenceName": "PacificVis", "authors": "Fan Hong;Can Liu;Xiaoru Yuan", "citationCount": "2", "affiliation": "Yuan, XR (Corresponding Author), Peking Univ, Minist Educ, Key Lab Machine Percept, Beijing, Peoples R China.\nYuan, XR (Corresponding Author), Peking Univ, Sch EECS, Beijing, Peoples R China.\nYuan, XR (Corresponding Author), Peking Univ, Beijing Engn Technol Res Ctr Virtual Simulat \\& Vi, Beijing, Peoples R China.\nHong, Fan; Liu, Can; Yuan, Xiaoru, Peking Univ, Minist Educ, Key Lab Machine Percept, Beijing, Peoples R China.\nHong, Fan; Liu, Can; Yuan, Xiaoru, Peking Univ, Sch EECS, Beijing, Peoples R China.\nYuan, Xiaoru, Peking Univ, Beijing Engn Technol Res Ctr Virtual Simulat \\& Vi, Beijing, Peoples R China.", "countries": "China", "abstract": "In this work, we propose a novel approach of volume visualization without explicit traditional rendering pipeline. In our proposed method, volumetric images can be interactively `reversed' given the volumetric data and a static volume rendered image under the desired rendering effect. Our pipeline enables 3D-navigation on it for exploring the given volumetric data without explicit transfer function. In our approach, deep neural networks, combined usage of Generative Adversarial Networks (GANs) and Convolutional Neural Networks (CNN) are employed to synthesize high-resolution and perceptually authentic images directly, inheriting the desired transfer function and viewing parameter implicitly given by the input images respectively.", "keywords": "Deep learning; volume rendering; transfer function; generative adversarial network; machine learning", "link": "https://doi.org/10.1109/PacificVis.2019.00041", "refList": ["10.1109/iccv.2017.629", "10.1109/tvcg.2008.162", "10.2312/vissym/eurovis05/271-278", "10.1109/38.920623", "10.1109/tvcg.2009.25", "10.1109/tvcg.2017.2744078", "10.1109/visual.2003.1250413", "10.1109/cvpr.2017.19", "10.1109/tvcg.2010.35", "10.1109/cvpr.2015.7298594", "10.1109/visual.1996.568113", "10.1109/5.726791", "10.1109/svv.1998.729588", "10.1109/iccv.2017.244", "10.1109/cvpr.2017.632", "10.1109/83.535842", "10.1016/0893-6080(91)90009-t", "10.1109/tvcg.2006.148", "10.2312/vissym/eurovis07/115-122", "10.1038/323533a0", "10.1109/tvcg.2002.1021579", "10.1109/tvcg.2007.1051", "10.1145/1830483.1830503", "10.1109/cvpr.2016.90", "10.1109/tvcg.2012.80", "10.1007/978-3-319-24574-4\\_28", "10.1109/tvcg.2005.38", "10.1109/tvcg.2009.189", "10.1109/pacificvis.2013.6596129", "10.1109/visual.1999.809932", "10.1007/978-3-319-46493-0\\_47", "10.1109/tvcg.2011.261", "10.1109/pccga.2002.1167880"], "wos": 1, "children": [{"doi": "10.1109/tvcg.2020.3030374", "title": "VC-Net: Deep Volume-Composition Networks for Segmentation and Visualization of Highly Sparse and Noisy Image Data", "year": "2020", "conferenceName": "SciVis", "authors": "Yifan Wang;Guoli Yan;Haikuan Zhu;Sagar Buch;Ying Wang;E. Mark Haacke;Jing Hua;Zichun Zhong", "citationCount": "0", "affiliation": "Wang, YF (Corresponding Author), Wayne State Univ, Dept Comp Sci, Detroit, MI 48202 USA. Wang, Yifan; Yan, Guoli; Zhu, Haikuan; Hua, Jing; Zhong, Zichun, Wayne State Univ, Dept Comp Sci, Detroit, MI 48202 USA. Buch, Sagar; Wang, Ying; Haacke, Ewart Mark, Wayne State Univ, Dept Radiol, Detroit, MI 48201 USA.", "countries": "USA", "abstract": "The fundamental motivation of the proposed work is to present a new visualization-guided computing paradigm to combine direct 3D volume processing and volume rendered clues for effective 3D exploration. For example, extracting and visualizing microstructures in-vivo have been a long-standing challenging problem. However, due to the high sparseness and noisiness in cerebrovasculature data as well as highly complex geometry and topology variations of micro vessels, it is still extremely challenging to extract the complete 3D vessel structure and visualize it in 3D with high fidelity. In this paper, we present an end-to-end deep learning method, VC-Net, for robust extraction of 3D microvascular structure through embedding the image composition, generated by maximum intensity projection (MIP), into the 3D volumetric image learning process to enhance the overall performance. The core novelty is to automatically leverage the volume visualization technique (e.g., MIP - a volume rendering scheme for 3D volume images) to enhance the 3D data exploration at the deep learning level. The MIP embedding features can enhance the local vessel signal (through canceling out the noise) and adapt to the geometric variability and scalability of vessels, which is of great importance in microvascular tracking. A multi-stream convolutional neural network (CNN) framework is proposed to effectively learn the 3D volume and 2D MIP feature vectors, respectively, and then explore their inter-dependencies in a joint volume-composition embedding space by unprojecting the 2D feature vectors into the 3D volume embedding space. It is noted that the proposed framework can better capture the small/micro vessels and improve the vessel connectivity. To our knowledge, this is the first time that a deep learning framework is proposed to construct a joint convolutional embedding space, where the computed vessel probabilities from volume rendering based 2D projection and 3D volume can be explored and integrated synergistically. Experimental results are evaluated and compared with the traditional 3D vessel segmentation methods and the state-of-the-art in deep learning, by using extensive public and real patient (micro- )cerebrovascular image datasets. The application of this accurate segmentation and visualization of sparse and complicated 3D microvascular structure facilitated by our method demonstrates the potential in a powerful MR arteriogram and venogram diagnosis of vascular disease.", "keywords": "Deep neural network,3D cerebrovascular segmentation and visualization,maximum intensity projection (MIP),joint embedding", "link": "http://dx.doi.org/10.1109/TVCG.2020.3030374", "refList": ["10.1109/cluster.2018.00036", "10.1109/iccv.2015.123", "10.1109/tvcg.2013.133", "10.1109/cvpr.2017.19", "10.1109/tvcg.2019.2934312", "10.1007/978-3-319-46487-9\\_40", "10.1109/tvcg.2006.175", "10.1109/tvcg.2007.70523", "10.1109/tvcg.2018.2880207", "10.1145/3309993", "10.1109/pacificvis.2018.00018", "10.1109/iccv.2017.244", "10.1109/cvpr.2017.632", "10.1109/tvcg.2018.2816059", "10.1109/pacificvis.2009.4906852", "10.1109/tvcg.2018.2864808", "10.1109/mcg.2018.2881523", "10.1109/tvcg.2015.2467431", "10.1109/tpami.2015.2439281", "10.1109/pacificvis48177.2020.8737", "10.1109/cvpr.2019.00244", "10.1109/tvcg.2006.165", "10.1109/bigdata.2018.8622520", "10.1007/978-3-319-46466-4\\_29", "10.1109/visual.2019.8933759", "10.1145/3197517.3201304", "10.1109/pacificvis.2011.5742378", "10.1109/cvpr.2006.91", "10.1109/pacificvis.2011.5742369", "10.1109/tvcg.2019.2934255", "10.1109/cvpr.2016.90", "10.1007/978-3-319-24574-4\\_28", "10.1109/pacificvis.2019.00041", "10.1109/tvcg.2019.2934332", "10.1109/cvpr.2018.00916", "10.1007/978-3-319-46475-6\\_43"], "wos": 1, "children": [], "len": 1}, {"doi": "10.1109/pacificvis48177.2020.8737", "year": "2020", "title": "SSR-VFD: Spatial Super-Resolution for Vector Field Data Analysis and Visualization", "conferenceName": "PacificVis", "authors": "Li Guo;Shaojie Ye;Jun Han;Hao Zheng;Han Gao;Danny Z. Chen;Jian{-}Xun Wang;Chaoli Wang", "citationCount": "1", "affiliation": "Guo, L (Corresponding Author), Nankai Univ, Tianjin, Peoples R China.\nGuo, Li, Nankai Univ, Tianjin, Peoples R China.\nYe, Shaojie, Zhejiang Univ, Hangzhou, Zhejiang, Peoples R China.\nHan, Jun; Zheng, Hao; Gao, Han; Chen, Danny Z.; Wang, Jian-Xun; Wang, Chaoli, Univ Notre Dame, Notre Dame, IN 46556 USA.", "countries": "USA;China", "abstract": "We present SSR-VFD, a novel deep learning framework that produces coherent spatial super-resolution (SSR) of three-dimensional vector field data (VFD). SSR-VFD is the first work that advocates a machine learning approach to generate high-resolution vector fields from low-resolution ones. The core of SSR-VFD lies in the use of three separate neural nets that take the three components of a low-resolution vector field as input and jointly output a synthesized high-resolution vector field. To capture spatial coherence, we take into account magnitude and angle losses in network optimization. Our method can work in the in situ scenario where VFD are down-sampled at simulation time for storage saving and these reduced VFD are upsampled back to their original resolution during postprocessing. To demonstrate the effectiveness of SSR-VFD, we show quantitative and qualitative results with several vector field data sets of different characteristics and compare our method against volume upscaling using bicubic interpolation, and two solutions based on CNN and GAN, respectively.", "keywords": "Spatial super-resolution; vector field data; convolutional neural network; deep learning", "link": "https://doi.org/10.1109/PacificVis48177.2020.8737", "refList": ["10.1016/j.ijvsm.2017.05.001", "10.1016/j.jvs.2005.01.020", "10.1109/iccv.2015.123", "10.1111/cgf.13620", "10.1109/cvpr.2019.00831", "10.1109/cvpr.2019.00817", "10.1109/cvpr.2019.00399", "10.1109/tvcg.2019.2934312", "10.1145/3309993", "10.1109/pacificvis.2018.00018", "10.1109/tvcg.2018.2816059", "10.1109/mcg.2018.2881523", "10.1109/tpami.2015.2439281", "10.1109/bigdata.2018.8622520", "10.1145/3197517.3201304", "10.1109/tvcg.2018.2796085", "10.1109/tvcg.2019.2934255", "10.1109/cvpr.2016.90", "10.1109/pacificvis.2019.00041", "10.1111/cgf.13689"], "wos": 1, "children": [{"doi": "10.1109/tvcg.2020.3030374", "title": "VC-Net: Deep Volume-Composition Networks for Segmentation and Visualization of Highly Sparse and Noisy Image Data", "year": "2020", "conferenceName": "SciVis", "authors": "Yifan Wang;Guoli Yan;Haikuan Zhu;Sagar Buch;Ying Wang;E. Mark Haacke;Jing Hua;Zichun Zhong", "citationCount": "0", "affiliation": "Wang, YF (Corresponding Author), Wayne State Univ, Dept Comp Sci, Detroit, MI 48202 USA. Wang, Yifan; Yan, Guoli; Zhu, Haikuan; Hua, Jing; Zhong, Zichun, Wayne State Univ, Dept Comp Sci, Detroit, MI 48202 USA. Buch, Sagar; Wang, Ying; Haacke, Ewart Mark, Wayne State Univ, Dept Radiol, Detroit, MI 48201 USA.", "countries": "USA", "abstract": "The fundamental motivation of the proposed work is to present a new visualization-guided computing paradigm to combine direct 3D volume processing and volume rendered clues for effective 3D exploration. For example, extracting and visualizing microstructures in-vivo have been a long-standing challenging problem. However, due to the high sparseness and noisiness in cerebrovasculature data as well as highly complex geometry and topology variations of micro vessels, it is still extremely challenging to extract the complete 3D vessel structure and visualize it in 3D with high fidelity. In this paper, we present an end-to-end deep learning method, VC-Net, for robust extraction of 3D microvascular structure through embedding the image composition, generated by maximum intensity projection (MIP), into the 3D volumetric image learning process to enhance the overall performance. The core novelty is to automatically leverage the volume visualization technique (e.g., MIP - a volume rendering scheme for 3D volume images) to enhance the 3D data exploration at the deep learning level. The MIP embedding features can enhance the local vessel signal (through canceling out the noise) and adapt to the geometric variability and scalability of vessels, which is of great importance in microvascular tracking. A multi-stream convolutional neural network (CNN) framework is proposed to effectively learn the 3D volume and 2D MIP feature vectors, respectively, and then explore their inter-dependencies in a joint volume-composition embedding space by unprojecting the 2D feature vectors into the 3D volume embedding space. It is noted that the proposed framework can better capture the small/micro vessels and improve the vessel connectivity. To our knowledge, this is the first time that a deep learning framework is proposed to construct a joint convolutional embedding space, where the computed vessel probabilities from volume rendering based 2D projection and 3D volume can be explored and integrated synergistically. Experimental results are evaluated and compared with the traditional 3D vessel segmentation methods and the state-of-the-art in deep learning, by using extensive public and real patient (micro- )cerebrovascular image datasets. The application of this accurate segmentation and visualization of sparse and complicated 3D microvascular structure facilitated by our method demonstrates the potential in a powerful MR arteriogram and venogram diagnosis of vascular disease.", "keywords": "Deep neural network,3D cerebrovascular segmentation and visualization,maximum intensity projection (MIP),joint embedding", "link": "http://dx.doi.org/10.1109/TVCG.2020.3030374", "refList": ["10.1109/cluster.2018.00036", "10.1109/iccv.2015.123", "10.1109/tvcg.2013.133", "10.1109/cvpr.2017.19", "10.1109/tvcg.2019.2934312", "10.1007/978-3-319-46487-9\\_40", "10.1109/tvcg.2006.175", "10.1109/tvcg.2007.70523", "10.1109/tvcg.2018.2880207", "10.1145/3309993", "10.1109/pacificvis.2018.00018", "10.1109/iccv.2017.244", "10.1109/cvpr.2017.632", "10.1109/tvcg.2018.2816059", "10.1109/pacificvis.2009.4906852", "10.1109/tvcg.2018.2864808", "10.1109/mcg.2018.2881523", "10.1109/tvcg.2015.2467431", "10.1109/tpami.2015.2439281", "10.1109/pacificvis48177.2020.8737", "10.1109/cvpr.2019.00244", "10.1109/tvcg.2006.165", "10.1109/bigdata.2018.8622520", "10.1007/978-3-319-46466-4\\_29", "10.1109/visual.2019.8933759", "10.1145/3197517.3201304", "10.1109/pacificvis.2011.5742378", "10.1109/cvpr.2006.91", "10.1109/pacificvis.2011.5742369", "10.1109/tvcg.2019.2934255", "10.1109/cvpr.2016.90", "10.1007/978-3-319-24574-4\\_28", "10.1109/pacificvis.2019.00041", "10.1109/tvcg.2019.2934332", "10.1109/cvpr.2018.00916", "10.1007/978-3-319-46475-6\\_43"], "wos": 1, "children": [], "len": 1}], "len": 3}, {"doi": "10.1111/cgf.14037", "year": "2020", "title": "State of the Art in Time-Dependent Flow Topology: Interpreting Physical Meaningfulness Through Mathematical Properties", "conferenceName": "EuroVis", "authors": "Roxana Bujack;Lin Yan;Ingrid Hotz;Christoph Garth;Bei Wang", "citationCount": "0", "affiliation": "Bujack, R (Corresponding Author), Los Alamos Natl Lab, Los Alamos, NM 87545 USA.\nBujack, Roxana, Los Alamos Natl Lab, Los Alamos, NM 87545 USA.\nYan, Lin; Wang, Bei, Univ Utah, Sci Comp \\& Imaging Inst, Salt Lake City, UT 84112 USA.\nHotz, Ingrid, Linkopings Univ, Sci Visualizat Grp, Linkoping, Sweden.\nGarth, Christoph, Univ Kaiserslautern, Kaiserslautern, Germany.", "countries": "Sweden;Germany;USA", "abstract": "We present a state-of-the-art report on time-dependent flow topology. We survey representative papers in visualization and provide a taxonomy of existing approaches that generalize flow topology from time-independent to time-dependent settings. The approaches are classified based upon four categories: tracking of steady topology, reference frame adaption, pathline classification or clustering, and generalization of critical points. Our unique contributions include introducing a set of desirable mathematical properties to interpret physical meaningfulness for time-dependent flow visualization, inferring mathematical properties associated with selective research papers, and utilizing such properties for classification. The five most important properties identified in the existing literature include coincidence with the steady case, induction of a partition within the domain, Lagrangian invariance, objectivity, and Galilean invariance.", "keywords": "", "link": "https://doi.org/10.1111/cgf.14037", "refList": ["10.2514/6.1995-1715", "10.1111/cgf.12100", "10.1007/978-3-540-70823-0\\_1", "10.1111/cgf.12885", "10.1063/1.857730", "10.1109/tvcg.2019.2934312", "10.1109/tvcg.2013.92", "10.1063/1.166399", "10.1109/tvcg.2005.68.3", "10.1063/1.4971788", "10.1111/cgf.12933", "10.1145/3072959.3073684", "10.1063/1.4982720", "10.1109/tvcg.2018.2864432", "10.1017/s0022112004002526", "10.1109/tvcg.2010.93", "10.1109/pacificvis.2016.7465253", "10.1109/tvcg.2018.2864505", "10.1063/1.858828", "10.1109/tvcg.2019.2934255", "10.5194/npg-9-237-2002", "10.1063/1.4800210", "10.1007/978-3-540-88606-8\\_12", "10.1111/j.1467-8659.2011.01942.x", "10.1109/2945.928168", "10.1007/978-3-662-10388-31", "10.1016/j.physd.2013.01.013", "10.1111/cgf.12358", "10.1017/s002211209900720x", "10.1017/s0022112097008057", "10.1111/j.1467-8659.2009.01546.x", "10.1109/2.35197", "10.1111/j.1467-8659.2012.03089.x", "10.1111/cgf.13319", "10.1109/tvcg.2019.2934375.3", "10.1016/j.crme.2015.08.002.4", "10.1016/s0167-2789(00)00142-1", "10.1111/cgf.12359", "10.1103/physreve.93.063107", "10.1016/j.physd.2009.05.005", "10.1063/1.1477449", "10.1111/j.1467-8659.2009.01686.x", "10.1109/pacificvis.2011.5742374", "10.1017/jfm.2013.391", "10.1111/cgf.12121", "10.1186/1743-422x-3-15", "10.1063/1.3502450", "10.1063/1.868323", "10.1016/j.cnsns.2013.05.002", "10.1109/visual.2004.99", "10.1109/visual.2004.107", "10.1111/j.1467-8659.2009.01604.x", "10.1146/annurev-fluid-010313-141322", "10.1063/1.3690153", "10.1109/tvcg.2019.2934375", "10.1109/tvcg.2013.143", "10.1137/130940633", "10.1016/j.cag.2014.01.007", "10.1016/s0097-8493(02)00056-0", "10.1109/vl.1996.545307", "10.1109/tvcg.2011.284", "10.1109/tvcg.2011.265", "10.1017/jfm.2016.792", "10.1109/tvcg.2013.208", "10.1007/s12650-016-0348-8", "10.1023/b:elas.0000005548.36767.e7", "10.1007/978-1-4939-0419-8\\_\\_9", "10.1007/bf00849110", "10.1615/int.j.uncertaintyquantification.2012003956", "10.1017/s0022112096001802", "10.1017/s0962492902000065", "10.1109/pacificvis.2019.00041", "10.1111/j.1467-8659.2011.01901.x", "10.1109/tvcg.2008.33", "10.1016/j.physd.2005.10.007", "10.1016/s0894-1777(96)00090-8", "10.1145/2517327.2442526", "10.1109/tvcg.2017.2743938", "10.1109/tvcg.2018.2816059", "10.1109/tvcg.2019.2934242", "10.2514/6.1995-1715.4", "10.1111/cgf.12109", "10.1109/tvcg.2011.269", "10.1109/visual.1990.146359", "10.1111/j.1467-8659.2003.00723.x", "10.5194/npg-18-977-2011", "10.1109/visual.1998.745296", "10.1109/tvcg.2007.70557", "10.1109/tvcg.2014.2312012"], "wos": 1, "children": [], "len": 1}], "len": 9}], "len": 11}, {"doi": "10.1109/tvcg.2018.2864816", "title": "Interactive Visualization of 3D Histopathology in Native Resolution", "year": "2018", "conferenceName": "SciVis", "authors": "Martin Falk;Anders Ynnerman;Darren Treanor;Claes Lundstr\u00f6m", "citationCount": "1", "affiliation": "Falk, M (Corresponding Author), Linkoping Univ, Dept Sci \\& Technol, Linkoping, Sweden. Falk, Martin; Ynnerman, Anders, Linkoping Univ, Dept Sci \\& Technol, Linkoping, Sweden. Treanor, Darren, Leeds Teaching Hosp NHS Trust, Leeds, W Yorkshire, England. Treanor, Darren; Lundstrom, Claes, Linkoping Univ, Ctr Med Image Sci \\& Visualizat CMIV, Linkoping, Sweden. Lundstrom, Claes, Sectra AB, Linkoping, Sweden.", "countries": "Sweden;England", "abstract": "We present a visualization application that enables effective interactive visual analysis of large-scale 3D histopathology, that is, high-resolution 3D microscopy data of human tissue. Clinical work flows and research based on pathology have, until now, largely been dominated by 2D imaging. As we will show in the paper, studying volumetric histology data will open up novel and useful opportunities for both research and clinical practice. Our starting point is the current lack of appropriate visualization tools in histopathology, which has been a limiting factor in the uptake of digital pathology. Visualization of 3D histology data does pose difficult challenges in several aspects. The full-color datasets are dense and large in scale, on the order of 100,000 \u00d7 100,000 \u00d7 100 voxels. This entails serious demands on both rendering performance and user experience design. Despite this, our developed application supports interactive study of 3D histology datasets at native resolution. Our application is based on tailoring and tuning of existing methods, system integration work, as well as a careful study of domain specific demands emanating from a close participatory design process with domain experts as team members. Results from a user evaluation employing the tool demonstrate a strong agreement among the 14 participating pathologists that 3D histopathology will be a valuable and enabling tool for their work.", "keywords": "Histology,Pathology,Volume Rendering,Expert Evaluation", "link": "http://dx.doi.org/10.1109/TVCG.2018.2864816", "refList": ["10.4103/2153-3539.129452", "10.2312/vissym/vissym02/115-124", "10.1371/journal.pone.0126817", "10.1093/ajcp/138.suppl1.288", "10.1109/tvcg.2009.150", "10.4103/2153-3539.151890", "10.1109/mcg.2010.26", "10.1109/tbme.2014.2303294", "10.1109/tvcg.2012.240", "10.1111/cgf.12605", "10.1007/s00371-008-0261-9", "10.1109/tvcg.2002.1021579", "10.1016/j.mri.2012.05.001", "10.1109/pacificvis.2017.8031591", "10.1111/his.12629", "10.2312/vissym/vissym00/137-146", "10.4103/2153-3539.151894", "10.1186/s12859-017-1934-z", "10.1117/12.813756", "10.1145/2834117", "10.1111/his.13452", "10.1111/cgf.12934", "10.1001/jama.2017.14585", "10.1016/j.ajpath.2012.01.033", "10.1109/visual.2002.1183757", "10.4103/2153-3539.114206", "10.17629/www.diagnosticpathology.eu-2016-2:232", "10.1109/mcg.2013.55", "10.1073/pnas.1710742114", "10.1117/12.529137", "10.2312/vg/vg-pbg08/163-170", "10.4103/2153-3539.119005"], "wos": 1, "children": [], "len": 1}, {"doi": "10.1111/cgf.13183", "year": "2017", "title": "Visual Analysis of Confocal Raman Spectroscopy Data using Cascaded Transfer Function Design", "conferenceName": "EuroVis", "authors": "Christoph M. Schikora;Markus Plack;Rainer Bornemann;Peter Haring Bol{\\'{\\i}}var;Andreas Kolb", "citationCount": "0", "affiliation": "Schikora, CM (Corresponding Author), Univ Siegen, Comp Graph \\& Multimedia Syst, Siegen, Germany.\nSchikora, Christoph M.; Plack, Markus; Kolb, Andreas, Univ Siegen, Comp Graph \\& Multimedia Syst, Siegen, Germany.\nBornemann, Rainer; Bolivar, Peter Haring, Univ Siegen, High Frequency \\& Quantum Elect, Siegen, Germany.", "countries": "Germany", "abstract": "2D Confocal Raman Microscopy (CRM) data consist of high dimensional per-pixel spectral data of 1000 bands and allows for complex spectral and spatial-spectral analysis tasks, i.e., in material discrimination, material thickness, and spatial material distributions. Currently, simple integral methods are commonly applied as visual analysis solutions to CRM data which exhibit restricted discrimination power in various regards. In this paper we present a novel approach for the visual analysis of 2D multispectral CRM data using multi-variate visualization techniques. Due to the large amount of data and the demand of an explorative approach without a-priori restriction, our system allows for arbitrary interactive (de)selection of varaibles w/o limitation and an unrestricted online definition/construction of new, combined properties. Our approach integrates CRM specific quantitative measures and handles material-related features for mixed materials in a quantitative manner. Technically, we realize the online definition/construction of new, combined properties as semi-automatic, cascaded, 1D and 2D multidimensional transfer functions (MD-TFs). By interactively incorporating new (raw or derived) properties, the dimensionality of the MD-TF space grows during the exploration procedure and is virtually unlimited. The final visualization is achieved by an enhanced color mixing step which improves saturation and contrast.", "keywords": "", "link": "https://doi.org/10.1111/cgf.13183", "refList": ["10.1016/j.sab.2006.12.002", "10.1021/nl061702a", "10.1007/978-3-642-12522-5\\_4", "10.1016/j.carbon.2016.01.001", "10.1137/040616024", "10.1016/j.cag.2012.02.007", "10.1111/cgf.12365", "10.2312/vissym/eur0vis05/117-123", "10.1007/s11664-009-0803-6", "10.1109/mcse.2012.27", "10.1109/tvcg.2002.1021579", "10.1007/978-3-540-85567-5\\_50", "10.1109/pacificvis.2010.5429612", "10.1109/tgrs.2010.2051553", "10.1109/tvcg.2007.70591", "10.1021/ac034173t", "10.1366/000370210792434350", "10.1111/cgf.12934", "10.1109/tvcg.2012.110", "10.1109/tvcg.2012.105", "10.1109/tvcg.2006.164", "10.1109/tvcg.2009.199", "10.1109/visual.2003.1250412", "10.1109/igarss.2011.6049397", "10.1007/978-3-642-12522-5", "10.1109/pacificvis.2013.6596129", "10.1039/c4an01061b", "10.1109/tvcg.2011.261"], "wos": 1, "children": [], "len": 1}], "len": 17}, {"doi": "10.1111/cgf.13173", "year": "2017", "title": "Overview + Detail Visualization for Ensembles of Diffusion Tensors", "conferenceName": "EuroVis", "authors": "Changgong Zhang;Matthan W. A. Caan;Thomas H{\\\"{o}}llt;Elmar Eisemann;Anna Vilanova", "citationCount": "5", "affiliation": "Zhang, C (Corresponding Author), Delft Univ Technol, Comp Graph \\& Visualizat, Delft, Netherlands.\nZhang, C.; Hollt, T.; Eisemann, E.; Vilanova, A., Delft Univ Technol, Comp Graph \\& Visualizat, Delft, Netherlands.\nCaan, M. W. A., Univ Amsterdam, Acad Med Ctr, Brain Imaging Ctr, Amsterdam, Netherlands.\nHollt, T., Leiden Univ, Computat Biol Ctr, Med Ctr, Leiden, Netherlands.", "countries": "Netherlands", "abstract": "A Diffusion Tensor Imaging (DTI) group study consists of a collection of volumetric diffusion tensor datasets (i.e., an ensemble) acquired from a group of subjects. The multivariate nature of the diffusion tensor imposes challenges on the analysis and the visualization. These challenges are commonly tackled by reducing the diffusion tensors to scalar-valued quantities that can be analyzed with common statistical tools. However, reducing tensors to scalars poses the risk of losing intrinsic information about the tensor. Visualization of tensor ensemble data without loss of information is still a largely unsolved problem. In this work, we propose an overview + detail visualization to facilitate the tensor ensemble exploration. We define an ensemble representative tensor and variations in terms of the three intrinsic tensor properties (i.e., scale, shape, and orientation) separately. The ensemble summary information is visually encoded into the newly designed aggregate tensor glyph which, in a spatial layout, functions as the overview. The aggregate tensor glyph guides the analyst to interesting areas that would need further detailed inspection. The detail views reveal the original information that is lost during aggregation. It helps the analyst to further understand the sources of variation and formulate hypotheses. To illustrate the applicability of our prototype, we compare with most relevant previous work through a user study and we present a case study on the analysis of a brain diffusion tensor dataset ensemble from healthy volunteers.", "keywords": "", "link": "https://doi.org/10.1111/cgf.13173", "refList": ["10.1109/tvcg.2013.143", "10.1111/j.2044-8317.1972.tb00491.x", "10.1109/tvcg.2015.2467204", "10.1109/tvcg.2015.2467435", "10.1109/tmi.2003.815059", "10.1109/mcg.2007.323435", "10.1109/tmi.2007.907277", "10.1002/mrm.1910360612", "10.1109/icdmw.2009.55", "10.1111/cgf.12890", "10.1109/tvcg.2015.2467031", "10.1002/mrm.20741", "10.1002/mrm.20931", "10.1109/tvcg.2010.247", "10.1111/j.1467-8659.2009.01677.x", "10.1109/pacificvis.2009.4906851", "10.1111/j.1467-8659.2011.01944.x", "10.1109/tvcg.2013.92", "10.1109/vl.1996.545307", "10.1109/tvcg.2014.2346455", "10.1109/tvcg.2010.181", "10.1016/j.jmr.2011.09.022", "10.2312/envirvis.20161099", "10.1145/1980462.1980470", "10.1007/978-1-4471-6497-5\\_1", "10.1016/j.sigpro.2006.02.050", "10.2312/conf/eg2013/stars/039-063", "10.2312/vissym/vissym04/147-154", "10.1111/cgf.12935", "10.1006/nimg.2002.1148", "10.1109/pacificvis.2012.6183591", "10.1016/j.neuroimage.2010.12.008", "10.1016/j.neuroimage.2010.11.029", "10.1016/s0006-3495(94)80775-1", "10.1109/tvcg.2011.203", "10.1111/j.1467-8659.2009.01675.x", "10.1109/pacificvis.2011.5742374", "10.1016/j.neuroimage.2006.07.021", "10.1109/tvcg.2014.2307892", "10.1109/tvcg.2010.199", "10.1002/mrm.22365", "10.1002/(sici)1522-2594(199909)42:3", "10.1109/vast.2015.7347634", "10.1016/j.neuroimage.2011.11.094", "10.1109/tvcg.2014.2346325", "10.1109/mcg.2005.71", "10.1111/j.1467-8659.2011.01942.x", "10.1007/978-3-642-33418-4\\_61", "10.1002/mrm.21229", "10.1016/j.media.2006.06.004", "10.1109/tvcg.2016.2598826"], "wos": 1, "children": [{"doi": "10.1109/tvcg.2018.2864825", "title": "EnsembleLens: Ensemble-based Visual Exploration of Anomaly Detection Algorithms with Multidimensional Data", "year": "2018", "conferenceName": "VAST", "authors": "Ke Xu;Meng Xia;Xing Mu;Yun Wang 0012;Nan Cao", "citationCount": "3", "affiliation": "Cao, N (Corresponding Author), Tongji Univ, IDVx Lab, Shanghai, Peoples R China. Xu, Ke; Xia, Meng; Mu, Xing; Wang, Yun, Hong Kong Univ Sci \\& Technol, Hong Kong, Peoples R China. Cao, Nan, Tongji Univ, IDVx Lab, Shanghai, Peoples R China.", "countries": "China", "abstract": "The results of anomaly detection are sensitive to the choice of detection algorithms as they are specialized for different properties of data, especially for multidimensional data. Thus, it is vital to select the algorithm appropriately. To systematically select the algorithms, ensemble analysis techniques have been developed to support the assembly and comparison of heterogeneous algorithms. However, challenges remain due to the absence of the ground truth, interpretation, or evaluation of these anomaly detectors. In this paper, we present a visual analytics system named EnsembleLens that evaluates anomaly detection algorithms based on the ensemble analysis process. The system visualizes the ensemble processes and results by a set of novel visual designs and multiple coordinated contextual views to meet the requirements of correlation analysis, assessment and reasoning of anomaly detection algorithms. We also introduce an interactive analysis workflow that dynamically produces contextualized and interpretable data summaries that allow further refinements of exploration results based on user feedback. We demonstrate the effectiveness of EnsembleLens through a quantitative evaluation, three case studies with real-world data and interviews with two domain experts.", "keywords": "Algorithm Evaluation,Ensemble Analysis,Anomaly Detection,Visual Analysis,Multidimensional Data", "link": "http://dx.doi.org/10.1109/TVCG.2018.2864825", "refList": ["10.1109/icde.2011.5767916", "10.1007/978-1-4615-0953-0\\_4", "10.1109/tvcg.2017.2745178", "10.1016/j.inffus.2005.01.008", "10.1109/tvcg.2013.265", "10.1111/cgf.12898", "10.1109/tvcg.2015.2410278", "10.1371/journal.pone.0152173", "10.1145/1772690.1772749", "10.1109/tvcg.2017.2744419", "10.1109/icdmw.2009.55", "10.1023/b:aire.0000045502.10941.a9", "10.14778/1920841.1921021", "10.1007/s10462-009-9124-7", "10.1023/b:dami.0000023676.72185.7c", "10.1145/2890508", "10.2307/1412159", "10.1109/tvcg.2010.181", "10.1109/scivis.2015.7429487", "10.1109/wsc.2007.4419664", "10.1137/1.9781611972818.2", "10.1177/1473871616686635", "10.1002/sam.11161", "10.1109/mcg.2014.52", "10.1007/s007780050006", "10.1007/3-540-45014-9\\_1", "10.1109/icpr.2004.1334558", "10.1007/s10618-012-0300-z", "10.1109/intellisys.2015.7361141", "10.1007/978-3-642-12026-8\\_29", "10.1109/icdm.2008.17", "10.1109/pacificvis.2012.6183572", "10.1109/tvcg.2014.2346922", "10.1109/tpami.2005.237", "10.1007/s10115-007-0093-3", "10.1007/978-3-319-14142-8\\_8", "10.1109/cec.2002.1004386", "10.1016/s0167-7152(98)00006-6", "10.1137/1.9781611972825.90", "10.1145/956750.956758", "10.1111/1467-842x.00110", "10.1145/2830544.2830549", "10.1109/tvcg.2015.2468093", "10.1109/34.58871", "10.1145/1081870.1081891", "10.1111/cgf.12390", "10.1002/sam.v1:3", "10.2307/2332226", "10.1145/2481244.2481252", "10.1111/cgf.13173", "10.1109/tvcg.2014.2346448", "10.1007/978-4-431-68057-4\\_3", "10.1145/3097983.3098154", "10.1109/tvcg.2016.2598830", "10.1007/bf02289565", "10.1145/1541880.1541882", "10.1145/1961189.1961199"], "wos": 1, "children": [{"doi": "10.1109/tvcg.2020.3030368", "title": "Implicit Multidimensional Projection of Local Subspaces", "year": "2020", "conferenceName": "InfoVis", "authors": "Rongzheng Bian;Yumeng Xue;Liang Zhou;Jian Zhang 0070;Baoquan Chen;Daniel Weiskopf;Yunhai Wang", "citationCount": "1", "affiliation": "Wang, YH (Corresponding Author), Shandong Univ, Qingdao, Peoples R China. Zhou, L (Corresponding Author), Univ Utah, Salt Lake City, UT 84112 USA. Bian, Rongzheng; Xue, Yumeng; Wang, Yunhai, Shandong Univ, Qingdao, Peoples R China. Chen, Baoquan, Peking Univ, Beijing, Peoples R China. Zhang, Jian, Chinese Acad Sci, CNIC, Beijing, Peoples R China. Zhou, Liang, Univ Utah, Salt Lake City, UT 84112 USA. Weiskopf, Daniel, Univ Stuttgart, Stuttgart, Germany.", "countries": "USA;Germany;China", "abstract": "We propose a visualization method to understand the effect of multidimensional projection on local subspaces, using implicit function differentiation. Here, we understand the local subspace as the multidimensional local neighborhood of data points. Existing methods focus on the projection of multidimensional data points, and the neighborhood information is ignored. Our method is able to analyze the shape and directional information of the local subspace to gain more insights into the global structure of the data through the perception of local structures. Local subspaces are fitted by multidimensional ellipses that are spanned by basis vectors. An accurate and efficient vector transformation method is proposed based on analytical differentiation of multidimensional projections formulated as implicit functions. The results are visualized as glyphs and analyzed using a full set of specifically-designed interactions supported in our efficient web-based visualization tool. The usefulness of our method is demonstrated using various multi- and high-dimensional benchmark datasets. Our implicit differentiation vector transformation is evaluated through numerical comparisons; the overall method is evaluated through exploration examples and use cases.", "keywords": "High-dimensional data visualization,dimensionality reduction,local linear subspaces,user interaction", "link": "http://dx.doi.org/10.1109/TVCG.2020.3030368", "refList": ["10.3844/jcssp.2018.613.622", "10.1016/j.aci.2018.08.003", "10.3390/info9030065", "10.1016/j.visinf.2018.09.003", "10.1371/journal.pone.0118432", "10.1016/s0893-6080(05)80023-1", "10.1109/tvcg.2020.2986996", "10.1109/icst.2012.56", "10.1007/s10844-013-0250-y", "10.1109/tbdata.2018", "10.1145/1125451.1125659", "10.1109/tvcg.2013.125", "10.1177/1473871611412817", "10.1145/3290605.3300911", "10.1111/cgf.14034", "10.1007/s13721-013-0034-x", "10.1016/j.procs.2017.05.216", "10.1016/j.ins.2009.08.025", "10.1109/tvcg.2013.124", "10.1109/tvcg.2018.2864499", "10.1109/tvcg.2018.2864475", "10.1080/10447318.2020.1741118", "10.1016/j.imu.2019.100203", "10.1109/tvcg.2018.2865240", "10.1186/s12864-019-6413-7", "10.1109/tvcg.2015.2467551", "10.1002/widm.1249", "10.1007/978-3-319-66429-3\\_29", "10.1109/tvcg.2014.2346481", "10.1109/tvcg.2018.2864825", "10.1177/1473871620904671", "10.1109/tvcg.2019.2934267", "10.1136/bmjopen-2016-012799", "10.1109/smartgridcomm.2017.8340682", "10.1007/s10664-015-9401-9", "10.1145/1143844.1143874", "10.1111/cgf.12389", "10.1109/tvcg.2018.2872577", "10.1007/978-981-13-5802-9\\_20", "10.1016/j.ipm.2009.03.002", "10.5220/0006431602160222", "10.1109/mcg.2015.50", "10.1109/tvcg.2014.2346574", "10.1007/bf02289565", "10.1109/tvcg.2017.2744378", "10.1016/j.patrec.2008.08.010", "10.1023/a:1010933404324", "10.9735/2229-3981"], "wos": 1, "children": [], "len": 1}, {"doi": "10.1111/cgf.13683", "year": "2019", "title": "Oui! Outlier Interpretation on Multi-dimensional Data via Visual Analytics", "conferenceName": "EuroVis", "authors": "Xun Zhao;Weiwei Cui;Yanhong Wu;Haidong Zhang;Huamin Qu;Dongmei Zhang", "citationCount": "1", "affiliation": "Zhao, X (Corresponding Author), Hong Kong Univ Sci \\& Technol, Hong Kong, Peoples R China.\nZhao, Xun; Qui, Huamin, Hong Kong Univ Sci \\& Technol, Hong Kong, Peoples R China.\nZhao, Xun; Cui, Weiwei; Zhang, Haidong; Zhang, Dongmei, Microsoft Res Asia, Beijing, Peoples R China.\nWu, Yanhong, Visa Res, Palo Alto, CA USA.", "countries": "USA;China", "abstract": "Outliers, the data instances that do not conform with normal patterns in a dataset, are widely studied in various domains, such as cybersecurity, social analysis, and public health. By detecting and analyzing outliers, users can either gain insights into abnormal patterns or purge the data of errors. However, different domains usually have different considerations with respect to outliers. Understanding the defining characteristics of outliers is essential for users to select and filter appropriate outliers based on their domain requirements. Unfortunately, most existing work focuses on the efficiency and accuracy of outlier detection, neglecting the importance of outlier interpretation. To address these issues, we propose Oui, a visual analytic system that helps users understand, interpret, and select the outliers detected by various algorithms. We also present a usage scenario on a real dataset and a qualitative user study to demonstrate the effectiveness and usefulness of our system.", "keywords": "", "link": "https://doi.org/10.1111/cgf.13683", "refList": ["10.1007/978-3-642-40994-3\\_20", "10.1016/j.actpsy.2012.04.004", "10.1162/089976600300015565", "10.1371/journal.pone.0152173", "10.1007/s10462-004-4304-y", "10.1080/10618600.1996.10474696", "10.1109/iciea.2017.8282889", "10.1145/2858036.2858529", "10.1002/sam.11161", "10.1137/1.9781611972818.2", "10.1177/1473871616686635", "10.1145/2939672.2939778", "10.2307/2685478", "10.1145/335191.335437", "10.1007/bf01898350", "10.1007/978-3-642-21329-8\\_4", "10.1109/icdm.2008.17", "10.1109/tvcg.2011.201", "10.1109/tvcg.2014.2346248", "10.1109/tvcg.2018.2864825", "10.1145/2594473.2594476", "10.1109/tvcg.2017.2711030", "10.1145/335191.335388", "10.1109/tvcg.2015.2467196", "10.1214/aos/1013203451", "10.1016/s0004-3702(98)00082-4", "10.1007/978-3-642-04898-2\\_455", "10.1109/titb.2006.880553", "10.1007/978-3-319-91476-3\\_3", "10.1145/1401890.1401946", "10.1145/3097983.3098154", "10.1145/1541880.1541882", "10.1109/tvcg.2017.2744378", "10.1023/a:1010933404324"], "wos": 1, "children": [{"doi": "10.1109/tvcg.2020.3030443", "title": "CAVA: A Visual Analytics System for Exploratory Columnar Data Augmentation Using Knowledge Graphs", "year": "2020", "conferenceName": "VAST", "authors": "Dylan Cashman;Shenyu Xu;Subhajit Das;Florian Heimerl;Cong Liu;Shah Rukh Humayoun;Michael Gleicher;Alex Endert;Remco Chang", "citationCount": "0", "affiliation": "Cashman, D (Corresponding Author), Tufts Univ, Medford, MA 02155 USA. Cashman, Dylan; Liu, Cong; Chang, Remco, Tufts Univ, Medford, MA 02155 USA. Xu, Shenyu; Das, Subhajit; Endert, Alex, Georgia Tech, Atlanta, GA USA. Heimerl, Florian; Gleicher, Michael, Univ Wisconsin, Madison, WI 53706 USA. Humayoun, Shah Rukh, San Francisco State Univ, San Francisco, CA 94132 USA.", "countries": "USA", "abstract": "Most visual analytics systems assume that all foraging for data happens before the analytics process; once analysis begins, the set of data attributes considered is fixed. Such separation of data construction from analysis precludes iteration that can enable foraging informed by the needs that arise in-situ during the analysis. The separation of the foraging loop from the data analysis tasks can limit the pace and scope of analysis. In this paper, we present CAVA, a system that integrates data curation and data augmentation with the traditional data exploration and analysis tasks, enabling information foraging in-situ during analysis. Identifying attributes to add to the dataset is difficult because it requires human knowledge to determine which available attributes will be helpful for the ensuing analytical tasks. CAVA crawls knowledge graphs to provide users with a a broad set of attributes drawn from external data to choose from. Users can then specify complex operations on knowledge graphs to construct additional attributes. CAVA shows how visual analytics can help users forage for attributes by letting users visually explore the set of available data, and by serving as an interface for query construction. It also provides visualizations of the knowledge graph itself to help users understand complex joins such as multi-hop aggregations. We assess the ability of our system to enable users to perform complex data combinations without programming in a user study over two datasets. We then demonstrate the generalizability of CAVA through two additional usage scenarios. The results of the evaluation confirm that CAVA is effective in helping the user perform data foraging that leads to improved analysis outcomes, and offer evidence in support of integrating data augmentation as a part of the visual analytics pipeline.", "keywords": "Visual Analytics,Information Foraging,Data Augmentation", "link": "http://dx.doi.org/10.1109/TVCG.2020.3030443", "refList": ["10.1057/palgrave.ivs.9500122", "10.1109/tvcg.2016.2598867", "10.1111/cgf.13708", "10.1109/tvcg.2019.2934799", "10.1109/tvcg.2019.2934541", "10.1109/tvcg.2013.65", "10.1109/tvcg.2018.2875702", "10.1109/iv.2004.1320207", "10.1068/p260471", "10.1145/1778765.1778816", "10.1109/tvcg.2018.2808489", "10.1109/tvcg.2018.2864912", "10.1016/j.apgeog.2015.12.006", "10.1111/j.1467-8659.2011.01960.x", "10.1109/tvcg.2018.2864843", "10.1109/pacificvis.2010.5429604", "10.1109/tvcg.2014.2346898", "10.1109/5.726791", "10.1177/1475090214540874", "10.1109/icde.2016.7498287", "10.1145/1556262.1556289", "10.1109/tvcg.2007.70535", "10.1109/vast.2012.6400489", "10.1145/1056808.1056914", "10.1016/j.neucom.2014.09.063", "10.1145/7529.8927", "10.1109/tvcg.2016.2598495", "10.1109/tvcg.2016.2607204", "10.1109/vast47406.2019.8986943", "10.3758/bf03205986", "10.1109/infvis.2005.1532142", "10.1145/1150402.1150479", "10.1109/tvcg.2017.2674978", "10.1109/tvcg.2019.2945960", "10.1109/tvcg.2017.2744098", "10.1109/tvcg.2017.2674999", "10.1109/tvcg.2011.279", "10.1109/tvcg.2014.2346594", "10.1109/tvcg.2017.2744184", "10.1111/cgf.12876", "10.1007/s4095-020-0191-7", "10.1007/s11390-015-1535-0", "10.1111/cgf.12640", "10.1109/tvcg.2016.2598667", "10.1111/cgf.13683", "10.1109/tvcg.2013.153", "10.1109/tvcg.2019.2934208", "10.1109/tvcg.2019.2934655", "10.1111/cgf.12655", "10.1007/s11023-010-9221-z", "10.1109/vast.2012.6400487", "10.1145/2702123.2702585", "10.1007/bf00310175", "10.1109/tvcg.2017.2744378", "10.1103/physreve.64.061907", "10.1109/ldav.2017.8231848", "10.1109/tvcg.2016.2598831"], "wos": 1, "children": [], "len": 1}, {"doi": "10.1109/tvcg.2020.3030432", "title": "Evaluation of Sampling Methods for Scatterplots", "year": "2020", "conferenceName": "VAST", "authors": "Jun Yuan;Shouxing Xiang;Jiazhi Xia;Lingyun Yu;Shixia Liu", "citationCount": "0", "affiliation": "Liu, SX (Corresponding Author), Tsinghua Univ, BNRist, Beijing, Peoples R China. Yuan, Jun; Xiang, Shouxing; Liu, Shixia, Tsinghua Univ, BNRist, Beijing, Peoples R China. Xia, Jiazhi, Cent South Univ, Changsha, Peoples R China. Yu, Lingyun, Xian Jiaotong Liverpool Univ, Suzhou, Peoples R China.", "countries": "China", "abstract": "Given a scatterplot with tens of thousands of points or even more, a natural question is which sampling method should be used to create a small but \u201cgood\u201d scatterplot for a better abstraction. We present the results of a user study that investigates the influence of different sampling strategies on multi-class scatterplots. The main goal of this study is to understand the capability of sampling methods in preserving the density, outliers, and overall shape of a scatterplot. To this end, we comprehensively review the literature and select seven typical sampling strategies as well as eight representative datasets. We then design four experiments to understand the performance of different strategies in maintaining: 1) region density; 2) class density; 3) outliers; and 4) overall shape in the sampling results. The results show that: 1) random sampling is preferred for preserving region density; 2) blue noise sampling and random sampling have comparable performance with the three multi-class sampling strategies in preserving class density; 3) outlier biased density based sampling, recursive subdivision based sampling, and blue noise sampling perform the best in keeping outliers; and 4) blue noise sampling outperforms the others in maintaining the overall shape of a scatterplot.", "keywords": "Scatterplot,data sampling,empirical evaluation", "link": "http://dx.doi.org/10.1109/TVCG.2020.3030432", "refList": ["10.1057/palgrave.ivs.9500122", "10.1109/tvcg.2016.2598867", "10.1109/tvcg.2015.2467591", "10.1111/cgf.13708", "10.1109/tvcg.2019.2934799", "10.1109/tvcg.2019.2934541", "10.1109/tvcg.2013.65", "10.1109/iv.2004.1320207", "10.1068/p260471", "10.1145/1778765.1778816", "10.1109/tvcg.2018.2808489", "10.1109/tvcg.2018.2864912", "10.1016/j.apgeog.2015.12.006", "10.1111/j.1467-8659.2011.01960.x", "10.1109/tvcg.2018.2864843", "10.1109/pacificvis.2010.5429604", "10.1109/tvcg.2014.2346898", "10.1109/5.726791", "10.1177/1475090214540874", "10.1145/1556262.1556289", "10.1109/tvcg.2007.70535", "10.1109/vast.2012.6400489", "10.1145/1056808.1056914", "10.1016/j.neucom.2014.09.063", "10.1145/7529.8927", "10.1109/tvcg.2016.2607204", "10.1109/vast47406.2019.8986943", "10.3758/bf03205986", "10.1109/infvis.2005.1532142", "10.1145/1150402.1150479", "10.1109/tvcg.2017.2674978", "10.1109/tvcg.2017.2744098", "10.1109/tvcg.2017.2674999", "10.1109/tvcg.2011.279", "10.1109/tvcg.2014.2346594", "10.1109/tvcg.2017.2744184", "10.1111/cgf.12876", "10.1109/1011101.2019.2945960", "10.1007/s4095-020-0191-7", "10.1007/s11390-015-1535-0", "10.1111/cgf.12640", "10.1109/tvcg.2016.2598667", "10.1111/cgf.13683", "10.1109/tvcg.2013.153", "10.1109/tvcg.2019.2934208", "10.1109/tvcg.2019.2934655", "10.1111/cgf.12655", "10.1007/s11023-010-9221-z", "10.1109/vast.2012.6400487", "10.1145/2702123.2702585", "10.1007/bf00310175", "10.1109/tvcg.2017.2744378", "10.1103/physreve.64.061907", "10.1109/ldav.2017.8231848", "10.1109/tvcg.2016.2598831"], "wos": 1, "children": [], "len": 1}, {"doi": "10.1111/cgf.14034", "year": "2020", "title": "The State of the Art in Enhancing Trust in Machine Learning Models with the Use of Visualizations", "conferenceName": "EuroVis", "authors": "Angelos Chatzimparmpas;Rafael Messias Martins;Ilir Jusufi;Kostiantyn Kucher;Fabrice Rossi;Andreas Kerren", "citationCount": "2", "affiliation": "Chatzimparmpas, A (Corresponding Author), Linnaeus Univ, Dept Comp Sci \\& Media Technol, Vaxjo, Sweden.\nChatzimparmpas, A.; Martins, R. M.; Jusufi, I.; Kucher, K.; Kerren, A., Linnaeus Univ, Dept Comp Sci \\& Media Technol, Vaxjo, Sweden.\nRossi, F., PSL Univ, Univ Paris Dauphine, Ceremade, Paris, France.", "countries": "Sweden;France", "abstract": "Machine learning (ML) models are nowadays used in complex applications in various domains, such as medicine, bioinformatics, and other sciences. Due to their black box nature, however, it may sometimes be hard to understand and trust the results they provide. This has increased the demand for reliable visualization tools related to enhancing trust in ML models, which has become a prominent topic of research in the visualization community over the past decades. To provide an overview and present the frontiers of current research on the topic, we present a State-of-the-Art Report (STAR) on enhancing trust in ML models with the use of interactive visualization. We define and describe the background of the topic, introduce a categorization for visualization techniques that aim to accomplish this goal, and discuss insights and opportunities for future research directions. Among our contributions is a categorization of trust against different facets of interactive ML, expanded and improved from previous research. Our results are investigated from different analytical perspectives: (a) providing a statistical overview, (b) summarizing key findings, (c) performing topic analyses, and (d) exploring the data sets used in the individual papers, all with the support of an interactive web-based survey browser. We intend this survey to be beneficial for visualization researchers whose interests involve making ML models more trustworthy, as well as researchers and practitioners from other disciplines in their search for effective visualization techniques suitable for solving their tasks with confidence and conveying meaning to their data.", "keywords": "trustworthy machine learning; visualization; interpretable machine learning; explainable machine learning", "link": "https://doi.org/10.1111/cgf.14034", "refList": ["10.1109/mcg.2018.2878902", "10.1109/tvcg.2008.153", "10.2312/mlvis.20181130", "10.1109/tvcg.2016.2598828", "10.1145/3290605.3300911", "10.1145/2993901.2993909", "10.2312/mlvis.20191158", "10.1109/tvcg.2016.2598446", "10.1111/j.1467-8659.2009.01475.x", "10.1145/3290605.3300809", "10.1109/pacificvis.2018.00031", "10.1055/s-0029-1216348", "10.1007/978-3-319-90403-0\\_13", "10.1109/tvcg.2017.2745085", "10.1111/j.1467-8659.2011.01938.x", "10.1007/978-3-319-54024-5\\_6", "10.1016/s0167-9473(01)00065-2", "10.1111/cgf.12895", "10.2312/eurovisshort.20141152.17", "10.2312/eurova.20151098.22", "10.1111/cgf.13667", "10.3115/1072228.1072378", "10.1109/tbdata.2018.2877350.16", "10.1109/lars.2009.5418323.25", "10.1109/tvcg.2017.2744878", "10.1016/j.combustflame.2005.09.018", "10.1016/j.cag.2014.01.006", "10.1109/tvcg.2016.2570755", "10.2312/mlvis.20191158.1,19", "10.1518/hfes.46.1.50.30392", "10.1145/3301275.3302280", "10.1145/3351095.3372834.1", "10.1016/s0377-2217(01)00264-8", "10.1111/cgf.13424", "10.1007/978-3-319-23485-4\\_53", "10.1007/978-94-007-0753-5\\_3623", "10.1109/tvcg.2013.101", "10.1111/cgf.12884", "10.1111/j.1467-8659.2010.01835.x", "10.1021/ci9901338", "10.4230/lipics.itcs:2017", "10.1109/mis.2013.24", "10.1109/tvcg.2014.2346482", "10.1109/tvcg.2018.2865230", "10.1073/pnas.1807180116", "10.1109/dsaa.2018.00018", "10.1109/tvcg.2009.153", "10.3115/1219840.1219855", "10.1109/tvcg.2018.2864812", "10.1109/tvcg.2018.2872577", "10.2312/trvis.20191183", "10.1109/cvpr:2004.383", "10.1109/vast.2008.4677350", "10.1145/302979.303001", "10.1109/tvcg.2018.2864499", "10.1111/cgf.13672", "10.1109/tvcg.2014.2346626", "10.23915/distill.00010.18", "10.1109/tvcg.2017.2744805", "10.2312/mlvis:20191160.18", "10.23915/distill:00016", "10.1109/pacificvis.2016.7465260", "10.1111/cgf.13683", "10.23915/distill.00016.19", "10.1145/32906053.300803.22", "10.1109/tvcg.2014.2346574", "10.1177/1473871615600010", "10.1109/tvcg.2016.2598831", "10.1145/3230623", "10.1109/visual.2019.8933744", "10.1145/2993901.2993915", "10.1016/j.visinf.2017.01.006", "10.1145/2993901.2993914", "10.1109/tvcg.2014.2346984", "10.1109/5.726791", "10.23915/distill.00010", "10.1109/tvcg.2018.2864825", "10.2307/2394164", "10.1109/tvcg.2017.2744458", "10.1145/2993901.2993917.28", "10.1111/cgf.13711", "10.1109/tvcg.2016.2598664", "10.2307/2530428", "10.1109/icdar.1997.620583", "10.1109/tvcg.2017.2744718", "10.1111/cgf.13425", "10.1109/tvcg.2019.2903943", "10.1145/1518701.1518895", "10.1109/tvcg.2018.2864838", "10.1145/62038.62043", "10.1111/j.1467-8659.2011.01920.x", "10.1145/3025171.3025208", "10.1145/355112.355124", "10.1109/vast.2010.5652398", "10.1109/tvcg.2014.2346578", "10.1145/3173574.3174209", "10.4178/epih/e2014008", "10.1109/beliv.2018.8634201.25,28", "10.1016/j.eswa.2007.12.020", "10.1111/cgf:13406", "10.1109/mcg.2011.103", "10.1631/fitee.1700808", "10.1109/tvcg.2017.2745158", "10.1073/pnas.0307752101", "10.1109/tvcg.2018.2816223", "10.1109/tvcg.2017.2745141", "10.1145/32232.32234", "10.1109/tvcg.2019.2934267", "10.1109/tvcg.2018.2864477", "10.1145/3132169", "10.2312/eurova.20151100.19", "10.1145/3172944.3172964", "10.1145/2601248.2601268", "10.1109/isai-nlp.2018.8693002.1", "10.1111/cgf.13404", "10.1007/s100320200071", "10.2312/trvis.20191183.16", "10.1111/cgf.12755", "10.1145/2702123.2702509", "10.1145/1401890.1402008.25", "10.1109/tvcg.2012.65", "10.1177/1473871617733996", "10.2312/trvis.20191187.7", "10.21236/ada273556", "10.1109/vast.2010.5652450", "10.1111/j.1467-8659.2011.01940.x", "10.1177/875647939000600106", "10.1109/tvcg.2017.2711030", "10.1016/j.immuni.2016.04.014", "10.1109/tvcg.2019.2934209", "10.1016/0095-0696(78)90006-2", "10.1016/j.jclinepi.2015.04.014", "10.1016/j.ress.2013.02.013", "10.1111/cgf.12640", "10.1145/1015330.1015388.25", "10.1111/j.1467-8659.2009.01468.x", "10.1145/1541880.1541882", "10.1109/vast.2011.6102453", "10.1016/s0008-8846(98)00165-3", "10.2312/trvis.20191186.7", "10.1007/s13748-013-0040-3", "10.1109/tvcg.2015.2467757", "10.1109/tbdata.2018.2877350", "10.1109/vast.2017.8585613", "10.1080/10556789208805504", "10.1109/vast.2012.6400484", "10.1145/3025171.3025181", "10.1007/978-3-319-90403-0\\_12", "10.1109/mcg.2019.2922592", "10.1021/ci000392t", "10.1109/vast.2007.4389000", "10.1111/cgf.13406.16", "10.1111/cgf.13684", "10.2312/eurovisshort.20161166.17", "10.2312/evs:20191168", "10.1145/3041021.3055135", "10.1145/3301275.3302265", "10.1613/jair.4135", "10.1109/tvcg.2018.2864500", "10.1109/tvcg.2017.2744158", "10.1109/ssci.2015.33", "10.1111/cgf.13453", "10.2312/pe/eurovast/eurova11/049-052", "10.1145/3025171.3025181.13", "10.1145/371920.372094", "10.1109/tvcg.2017.2744938", "10.1111/j.1467-8659.2012.03108.x", "10.1109/tvcg.2019.2934251", "10.1145/3290605.3300809.18", "10.1109/ldav.2016.7874305", "10.1109/vast.2016.7883514", "10.1109/iccv.2015.425", "10.1145/3301275.3302324", "10.1109/tnnls.2013.2292894", "10.1109/tvcg.2018.2865044", "10.1109/tvcg.2013.157", "10.1371/journal.pcbi.0020161", "10.1186/s12916-019-1426-2", "10.1109/10.867928", "10.1111/cgf.13217", "10.1109/mcg.2019.2919033", "10.1145/2993901.2993910", "10.1109/tvcg.2017.2744738", "10.2307/258792", "10.1111/cgf.12655", "10.1016/j.dss.2014.03.001", "10.1109/tvcg.2019.2904069", "10.1111/cgf.13205", "10.1002/mds.22340", "10.1109/tvcg.2019.2934595", "10.1287/inte.2018.0957", "10.1109/cvpr.2007.382974", "10.1109/tvcg.2012.280", "10.1145/2678025.2701399.13", "10.2312/mlvis.20181130.13", "10.2312/eurova.20181106.16", "10.1109/tvcg.2018.2864475", "10.2312/mlvis.20191160.18,22", "10.1007/978-1-4612-4026-6.25", "10.1109/cvpr.2006.42", "10.1145/3172944.3172950", "10.1109/cvpr.2004.383.25", "10.1109/tvcg.2019.2934812", "10.1609/aimag.v35i4.2513", "10.2312/trvis.20191185.7", "10.1111/j.1467-8659.2009.01684.x", "10.1371/journal.pone.0129126", "10.1111/cgf.13092", "10.1162/coli\\_a\\_00237", "10.1109/tvcg.2017.2744818", "10.1109/vast.2011.6102448", "10.1109/tvcg.2009.111", "10.1109/tvcg.2019.2934619", "10.1016/s0377-2217(01)00264-8.25", "10.1111/cgf.12639", "10.1109/access.2019.2919343", "10.1186/s12874-019-0681-4", "10.1109/pacificvis.2015.7156366", "10.1109/pacificvis.2018.00029", "10.1109/tvcg.2019.2934261", "10.1080/13506280444000102.http://www.uvt.nl/ticc", "10.1109/vast.2018.8802509", "10.1111/cgf.13212", "10.1145/3200489", "10.1111/cgf.13176", "10.1177/1473871620904671", "10.1007/978-3-319-10590-1\\_53", "10.1111/j.1467-8659.2012.03126.x", "10.1111/cgf.13172", "10.1145/3025171.3025208.6,21", "10.1111/cgf.12366", "10.1109/tvcg.2019.2934659", "10.1109/cvprw.2009.5206848", "10.1016/j.media.2014.11.010", "10.1109/tvcg.2017.2744683", "10.1109/tvcg.2019.2934262", "10.1016/j.neucom.2006.11.018", "10.1177/1473871615571951", "10.1371/journal.pcbi.0020161.25", "10.1177/1473871611415994", "10.2312/trvis20191187", "10.2312/eurova", "10.1145/2858036.2858529", "10.1145/2207676.2207738", "10.1007/s11042-009-0417-2", "10.1145/3301275.3302317", "10.1038/s41746-019-0148-3", "10.1145/3351095.3372834", "10.1080/10691898.2011.11889627", "10.1109/tvcg.2018.2864504", "10.1109/vast.2017.8585720", "10.1109/mcg.2018.053491732", "10.1007/s10994-010-5207-6", "10.1109/tvcg.2019.2934433", "10.1016/j.cag.2017.05.005", "10.1109/tvcg.2012.279", "10.1145/3231622.3231641.19,20", "10.1145/1562849.1562851", "10.1007/11564126\\_", "10.1109/tvcg.2018.2846735", "10.3115/1225403.1225421", "10.1109/vast.2012.6400486", "10.2312/eurova.20191116.22", "10.1109/tvcg.2007.70443", "10.1080/027868291009242", "10.2312/eurova.20151100", "10.1145/2939502.2939503.19", "10.1016/j.cag.2014.02.004", "10.1145/2939672.2939778", "10.1109/vast.2010.5652484", "10.1111/cgf.12641", "10.1145/3301275.3302289", "10.1109/visual.2019.8933619", "10.1109/tvcg.2017.2672987", "10.1109/vast.2016.7883517.20", "10.1109/igarss.2017.8127684", "10.1016/j.jcae.2010.04.002", "10.1109/vast.2010.5652885", "10.1016/j.visinf.2019.03.002", "10.1007/s00371-018-1500-3", "10.1109/mcg.2018.042731661", "10.1109/34.598228", "10.1109/tvcg.2018.2865027", "10.1016/j.neucom.2017.01.105", "10.1111/cgf.12389", "10.1109/tvcg.2019.2934591", "10.1109/vast.2010.5652392.16", "10.1111/cgf.13416", "10.1080/02701367.1992.10608764", "10.1109/vast.2017.8585721", "10.1109/tvcg.2018.2843369", "10.1109/sbes.2010.27", "10.1109/vast.2015.7347637", "10.1145/1401890.1402008", "10.1016/j.bpj.2010.04.064", "10.1109/tvcg.2013.125", "10.1109/isai-nlp.2018.8693002", "10.1371/journal.pone.0160127", "10.1145/2856767.2856779", "10.1145/2678025.2701399", "10.1109/vast.2011.6102451", "10.1109/mcg.2010.18", "10.1021/ci4000213", "10.1109/vast.2012.6400492", "10.1007/11564126-49.25", "10.2312/eurova.20171114", "10.1109/vast.2010.5652443", "10.1145/3134599", "10.2312/pe/eurovast/eurovast10/013-018.19", "10.1109/tvcg.2019.2903946", "10.1109/tvcg.2015.2467717", "10.1177/1473871612460526", "10.1016/j.cag.2018.09.018", "10.1109/tvcg.2016.2598838", "10.1145/3172944.3172964.14", "10.1109/vast.2009.5333428", "10.1109/vast.2014.7042480", "10.2312/pe/eurovast/eurovast10/013-018", "10.1177/0962280215588241", "10.1145/2993901.2993917", "10.1109/cvpr.2008:4587581", "10.1109/tvcg.2015.2467551", "10.1016/j.visinf.2018.09.001", "10.1126/science.290.5500.2319", "10.2312/eurova.20151107", "10.1109/visual.2019.8933695", "10.13140/2.1.2393.1847", "10.1197/jamia.m1929", "10.1109/cvpr.2008.4587581.25", "10.1145/1518701.1518895.16", "10.1109/vds.2017.8573444", "10.2312/trvis:20191185", "10.1145/3359786", "10.13140/2.1.1341.1520", "10.2312/pe/eurovast/eurova11/049-052.17", "10.1109/tvcg.2014.2346660", "10.1145/3185517", "10.1109/adprl.2011.5967372", "10.1109/tvcg.2015.2467591", "10.1111/j.1751-9004.2009.00232.x", "10.1136/qshc.2004.010033", "10.1109/vast.2012.6400493", "10.1109/tvcg.2019.2934266", "10.1145/2971763.2971775", "10.1111/cgf.13730", "10.1109/vast.2012.6400488", "10.1111/cgf.13210", "10.1109/tvcg.2019.2934631", "10.1145/3172944.3172965", "10.1057/ivs.2010.2", "10.1109/tvcg.2017.2745258", "10.1016/j.jbusres.2019.07.039", "10.1162/jmlr.2003.3.4-5.993", "10.1109/pacificvis.2019.00044", "10.2312/pe/eurovast/eurova12/037-041", "10.1109/tvcg.2019.2934629", "10.1177/0018720814547570", "10.1145/3292500.3330908", "10.1111/j.1467-8659.2009.01467.x", "10.2312/eurova.20151098", "10.1177/1473871617713337", "10.1109/lars:2009.5418323", "10.1109/vast.2011.6102437", "10.1111/cgf.12878", "10.1561/1500000001", "10.1145/3025171.3025222", "10.1007/s11704-016-6028-y", "10.1016/j.procs.2017.05.216", "10.1109/cvpr.2007.382974.25", "10.1080/10447318.2020.1741118", "10.1109/vast.2012.6400489", "10.1145/3025171.3025172", "10.1109/tvcg.2017.2744098", "10.1109/tvcg.2005.66", "10.1016/j.dss.2009.05.016", "10.1007/978-1-4612-4026-6", "10.2312/evs.20191168.16,20,28", "10.2312/pe/eurovast/eurova12/037-041.17", "10.1145/3290605.3300803", "10.1145/1015330.1015388", "10.1111/cgf.13197", "10.1016/b978-1-55860-377-6.50048-7", "10.1111/cgf.13681", "10.1109/tvcg.2017.2744378", "10.1109/tvcg.2017.2744358", "10.1109/vast.2008.4677352"], "wos": 1, "children": [{"doi": "10.1109/tvcg.2020.3030368", "title": "Implicit Multidimensional Projection of Local Subspaces", "year": "2020", "conferenceName": "InfoVis", "authors": "Rongzheng Bian;Yumeng Xue;Liang Zhou;Jian Zhang 0070;Baoquan Chen;Daniel Weiskopf;Yunhai Wang", "citationCount": "1", "affiliation": "Wang, YH (Corresponding Author), Shandong Univ, Qingdao, Peoples R China. Zhou, L (Corresponding Author), Univ Utah, Salt Lake City, UT 84112 USA. Bian, Rongzheng; Xue, Yumeng; Wang, Yunhai, Shandong Univ, Qingdao, Peoples R China. Chen, Baoquan, Peking Univ, Beijing, Peoples R China. Zhang, Jian, Chinese Acad Sci, CNIC, Beijing, Peoples R China. Zhou, Liang, Univ Utah, Salt Lake City, UT 84112 USA. Weiskopf, Daniel, Univ Stuttgart, Stuttgart, Germany.", "countries": "USA;Germany;China", "abstract": "We propose a visualization method to understand the effect of multidimensional projection on local subspaces, using implicit function differentiation. Here, we understand the local subspace as the multidimensional local neighborhood of data points. Existing methods focus on the projection of multidimensional data points, and the neighborhood information is ignored. Our method is able to analyze the shape and directional information of the local subspace to gain more insights into the global structure of the data through the perception of local structures. Local subspaces are fitted by multidimensional ellipses that are spanned by basis vectors. An accurate and efficient vector transformation method is proposed based on analytical differentiation of multidimensional projections formulated as implicit functions. The results are visualized as glyphs and analyzed using a full set of specifically-designed interactions supported in our efficient web-based visualization tool. The usefulness of our method is demonstrated using various multi- and high-dimensional benchmark datasets. Our implicit differentiation vector transformation is evaluated through numerical comparisons; the overall method is evaluated through exploration examples and use cases.", "keywords": "High-dimensional data visualization,dimensionality reduction,local linear subspaces,user interaction", "link": "http://dx.doi.org/10.1109/TVCG.2020.3030368", "refList": ["10.3844/jcssp.2018.613.622", "10.1016/j.aci.2018.08.003", "10.3390/info9030065", "10.1016/j.visinf.2018.09.003", "10.1371/journal.pone.0118432", "10.1016/s0893-6080(05)80023-1", "10.1109/tvcg.2020.2986996", "10.1109/icst.2012.56", "10.1007/s10844-013-0250-y", "10.1109/tbdata.2018", "10.1145/1125451.1125659", "10.1109/tvcg.2013.125", "10.1177/1473871611412817", "10.1145/3290605.3300911", "10.1111/cgf.14034", "10.1007/s13721-013-0034-x", "10.1016/j.procs.2017.05.216", "10.1016/j.ins.2009.08.025", "10.1109/tvcg.2013.124", "10.1109/tvcg.2018.2864499", "10.1109/tvcg.2018.2864475", "10.1080/10447318.2020.1741118", "10.1016/j.imu.2019.100203", "10.1109/tvcg.2018.2865240", "10.1186/s12864-019-6413-7", "10.1109/tvcg.2015.2467551", "10.1002/widm.1249", "10.1007/978-3-319-66429-3\\_29", "10.1109/tvcg.2014.2346481", "10.1109/tvcg.2018.2864825", "10.1177/1473871620904671", "10.1109/tvcg.2019.2934267", "10.1136/bmjopen-2016-012799", "10.1109/smartgridcomm.2017.8340682", "10.1007/s10664-015-9401-9", "10.1145/1143844.1143874", "10.1111/cgf.12389", "10.1109/tvcg.2018.2872577", "10.1007/978-981-13-5802-9\\_20", "10.1016/j.ipm.2009.03.002", "10.5220/0006431602160222", "10.1109/mcg.2015.50", "10.1109/tvcg.2014.2346574", "10.1007/bf02289565", "10.1109/tvcg.2017.2744378", "10.1016/j.patrec.2008.08.010", "10.1023/a:1010933404324", "10.9735/2229-3981"], "wos": 1, "children": [], "len": 1}, {"doi": "10.1109/tvcg.2020.3030465", "title": "Visual Causality Analysis of Event Sequence Data", "year": "2020", "conferenceName": "VAST", "authors": "Zhuochen Jin;Shunan Guo;Nan Chen;Daniel Weiskopf;David Gotz;Nan Cao", "citationCount": "0", "affiliation": "Cao, N (Corresponding Author), Tongji Univ, IDVx Lab, Shanghai, Peoples R China. Jin, Zhuochen; Guo, Shunan; Chen, Nan; Cao, Nan, Tongji Univ, IDVx Lab, Shanghai, Peoples R China. Weiskopf, Daniel, Univ Stuttgart, Stuttgart, Germany. Gotz, David, Univ N Carolina, Chapel Hill, NC 27515 USA.", "countries": "USA;Germany;China", "abstract": "Causality is crucial to understanding the mechanisms behind complex systems and making decisions that lead to intended outcomes. Event sequence data is widely collected from many real-world processes, such as electronic health records, web clickstreams, and financial transactions, which transmit a great deal of information reflecting the causal relations among event types. Unfortunately, recovering causalities from observational event sequences is challenging, as the heterogeneous and high-dimensional event variables are often connected to rather complex underlying event excitation mechanisms that are hard to infer from limited observations. Many existing automated causal analysis techniques suffer from poor explainability and fail to include an adequate amount of human knowledge. In this paper, we introduce a visual analytics method for recovering causalities in event sequence data. We extend the Granger causality analysis algorithm on Hawkes processes to incorporate user feedback into causal model refinement. The visualization system includes an interactive causal analysis framework that supports bottom-up causal exploration, iterative causal verification and refinement, and causal comparison through a set of novel visualizations and interactions. We report two forms of evaluation: a quantitative evaluation of the model improvements resulting from the user-feedback mechanism, and a qualitative evaluation through case studies in different application domains to demonstrate the usefulness of the system.", "keywords": "Event sequence data,causality analysis,visual analytics", "link": "http://dx.doi.org/10.1109/TVCG.2020.3030465", "refList": ["10.5555/1642718", "10.1109/tvcg.2018.2865022", "10.5555/2074094.2074151", "10.1109/tvcg.2016.2618797", "10.1073/pnas.1320645111", "10.1109/tvcg.2017.2744843", "10.1109/iv.2017.69", "10.1109/tvcg.2019.2934399", "10.1145/3172944.3173007", "10.5555/1795555", "10.1109/mcg.2005.102", "10.1145/381641.381653", "10.1162/153244301753344614", "10.1111/cgf.14034", "10.1111/cgf.13198", "10.1017/cbo9780511519857", "10.1007/s10462-016-9475-9", "10.1075/ssol.2.2.07bor", "10.1007/978-1-4614-3223-4\\_3", "10.1109/infvis.2003.1249025", "10.1007/978-94-007-6094-313", "10.1145/2858036.2858387", "10.1109/tvcg.2007.70528", "10.1109/tvcg.2017.2674958", "10.1147/sj.454.0801", "10.1109/tvcg.2013.119", "10.1145/3173574.3173711", "10.1016/j.erss.2017.06.034", "10.1109/visual.2019.8933695", "10.1007/s11665-016-2173-6", "10.1016/0377-0427(87)90125-7", "10.2307/3601125", "10.1016/b978-0-444-88738-2.50018-x", "10.1109/mcg.2006.70", "10.1109/tvcg.2018.2865145", "10.1017/s1351324997001502", "10.1109/tvcg.2010.179", "10.1214/aos/1176344552", "10.1109/mcg.2009.22", "10.1007/978-3-319-26633-6\\_13", "10.1080/10447318.2014.905422", "10.1016/j.visinf.2019.03.004", "10.1057/palgrave.ivs.9500074", "10.1007/978-1-4614-3223-4"], "wos": 1, "children": [], "len": 1}], "len": 5}], "len": 11}, {"doi": "10.1111/cgf.14034", "year": "2020", "title": "The State of the Art in Enhancing Trust in Machine Learning Models with the Use of Visualizations", "conferenceName": "EuroVis", "authors": "Angelos Chatzimparmpas;Rafael Messias Martins;Ilir Jusufi;Kostiantyn Kucher;Fabrice Rossi;Andreas Kerren", "citationCount": "2", "affiliation": "Chatzimparmpas, A (Corresponding Author), Linnaeus Univ, Dept Comp Sci \\& Media Technol, Vaxjo, Sweden.\nChatzimparmpas, A.; Martins, R. M.; Jusufi, I.; Kucher, K.; Kerren, A., Linnaeus Univ, Dept Comp Sci \\& Media Technol, Vaxjo, Sweden.\nRossi, F., PSL Univ, Univ Paris Dauphine, Ceremade, Paris, France.", "countries": "Sweden;France", "abstract": "Machine learning (ML) models are nowadays used in complex applications in various domains, such as medicine, bioinformatics, and other sciences. Due to their black box nature, however, it may sometimes be hard to understand and trust the results they provide. This has increased the demand for reliable visualization tools related to enhancing trust in ML models, which has become a prominent topic of research in the visualization community over the past decades. To provide an overview and present the frontiers of current research on the topic, we present a State-of-the-Art Report (STAR) on enhancing trust in ML models with the use of interactive visualization. We define and describe the background of the topic, introduce a categorization for visualization techniques that aim to accomplish this goal, and discuss insights and opportunities for future research directions. Among our contributions is a categorization of trust against different facets of interactive ML, expanded and improved from previous research. Our results are investigated from different analytical perspectives: (a) providing a statistical overview, (b) summarizing key findings, (c) performing topic analyses, and (d) exploring the data sets used in the individual papers, all with the support of an interactive web-based survey browser. We intend this survey to be beneficial for visualization researchers whose interests involve making ML models more trustworthy, as well as researchers and practitioners from other disciplines in their search for effective visualization techniques suitable for solving their tasks with confidence and conveying meaning to their data.", "keywords": "trustworthy machine learning; visualization; interpretable machine learning; explainable machine learning", "link": "https://doi.org/10.1111/cgf.14034", "refList": ["10.1109/mcg.2018.2878902", "10.1109/tvcg.2008.153", "10.2312/mlvis.20181130", "10.1109/tvcg.2016.2598828", "10.1145/3290605.3300911", "10.1145/2993901.2993909", "10.2312/mlvis.20191158", "10.1109/tvcg.2016.2598446", "10.1111/j.1467-8659.2009.01475.x", "10.1145/3290605.3300809", "10.1109/pacificvis.2018.00031", "10.1055/s-0029-1216348", "10.1007/978-3-319-90403-0\\_13", "10.1109/tvcg.2017.2745085", "10.1111/j.1467-8659.2011.01938.x", "10.1007/978-3-319-54024-5\\_6", "10.1016/s0167-9473(01)00065-2", "10.1111/cgf.12895", "10.2312/eurovisshort.20141152.17", "10.2312/eurova.20151098.22", "10.1111/cgf.13667", "10.3115/1072228.1072378", "10.1109/tbdata.2018.2877350.16", "10.1109/lars.2009.5418323.25", "10.1109/tvcg.2017.2744878", "10.1016/j.combustflame.2005.09.018", "10.1016/j.cag.2014.01.006", "10.1109/tvcg.2016.2570755", "10.2312/mlvis.20191158.1,19", "10.1518/hfes.46.1.50.30392", "10.1145/3301275.3302280", "10.1145/3351095.3372834.1", "10.1016/s0377-2217(01)00264-8", "10.1111/cgf.13424", "10.1007/978-3-319-23485-4\\_53", "10.1007/978-94-007-0753-5\\_3623", "10.1109/tvcg.2013.101", "10.1111/cgf.12884", "10.1111/j.1467-8659.2010.01835.x", "10.1021/ci9901338", "10.4230/lipics.itcs:2017", "10.1109/mis.2013.24", "10.1109/tvcg.2014.2346482", "10.1109/tvcg.2018.2865230", "10.1073/pnas.1807180116", "10.1109/dsaa.2018.00018", "10.1109/tvcg.2009.153", "10.3115/1219840.1219855", "10.1109/tvcg.2018.2864812", "10.1109/tvcg.2018.2872577", "10.2312/trvis.20191183", "10.1109/cvpr:2004.383", "10.1109/vast.2008.4677350", "10.1145/302979.303001", "10.1109/tvcg.2018.2864499", "10.1111/cgf.13672", "10.1109/tvcg.2014.2346626", "10.23915/distill.00010.18", "10.1109/tvcg.2017.2744805", "10.2312/mlvis:20191160.18", "10.23915/distill:00016", "10.1109/pacificvis.2016.7465260", "10.1111/cgf.13683", "10.23915/distill.00016.19", "10.1145/32906053.300803.22", "10.1109/tvcg.2014.2346574", "10.1177/1473871615600010", "10.1109/tvcg.2016.2598831", "10.1145/3230623", "10.1109/visual.2019.8933744", "10.1145/2993901.2993915", "10.1016/j.visinf.2017.01.006", "10.1145/2993901.2993914", "10.1109/tvcg.2014.2346984", "10.1109/5.726791", "10.23915/distill.00010", "10.1109/tvcg.2018.2864825", "10.2307/2394164", "10.1109/tvcg.2017.2744458", "10.1145/2993901.2993917.28", "10.1111/cgf.13711", "10.1109/tvcg.2016.2598664", "10.2307/2530428", "10.1109/icdar.1997.620583", "10.1109/tvcg.2017.2744718", "10.1111/cgf.13425", "10.1109/tvcg.2019.2903943", "10.1145/1518701.1518895", "10.1109/tvcg.2018.2864838", "10.1145/62038.62043", "10.1111/j.1467-8659.2011.01920.x", "10.1145/3025171.3025208", "10.1145/355112.355124", "10.1109/vast.2010.5652398", "10.1109/tvcg.2014.2346578", "10.1145/3173574.3174209", "10.4178/epih/e2014008", "10.1109/beliv.2018.8634201.25,28", "10.1016/j.eswa.2007.12.020", "10.1111/cgf:13406", "10.1109/mcg.2011.103", "10.1631/fitee.1700808", "10.1109/tvcg.2017.2745158", "10.1073/pnas.0307752101", "10.1109/tvcg.2018.2816223", "10.1109/tvcg.2017.2745141", "10.1145/32232.32234", "10.1109/tvcg.2019.2934267", "10.1109/tvcg.2018.2864477", "10.1145/3132169", "10.2312/eurova.20151100.19", "10.1145/3172944.3172964", "10.1145/2601248.2601268", "10.1109/isai-nlp.2018.8693002.1", "10.1111/cgf.13404", "10.1007/s100320200071", "10.2312/trvis.20191183.16", "10.1111/cgf.12755", "10.1145/2702123.2702509", "10.1145/1401890.1402008.25", "10.1109/tvcg.2012.65", "10.1177/1473871617733996", "10.2312/trvis.20191187.7", "10.21236/ada273556", "10.1109/vast.2010.5652450", "10.1111/j.1467-8659.2011.01940.x", "10.1177/875647939000600106", "10.1109/tvcg.2017.2711030", "10.1016/j.immuni.2016.04.014", "10.1109/tvcg.2019.2934209", "10.1016/0095-0696(78)90006-2", "10.1016/j.jclinepi.2015.04.014", "10.1016/j.ress.2013.02.013", "10.1111/cgf.12640", "10.1145/1015330.1015388.25", "10.1111/j.1467-8659.2009.01468.x", "10.1145/1541880.1541882", "10.1109/vast.2011.6102453", "10.1016/s0008-8846(98)00165-3", "10.2312/trvis.20191186.7", "10.1007/s13748-013-0040-3", "10.1109/tvcg.2015.2467757", "10.1109/tbdata.2018.2877350", "10.1109/vast.2017.8585613", "10.1080/10556789208805504", "10.1109/vast.2012.6400484", "10.1145/3025171.3025181", "10.1007/978-3-319-90403-0\\_12", "10.1109/mcg.2019.2922592", "10.1021/ci000392t", "10.1109/vast.2007.4389000", "10.1111/cgf.13406.16", "10.1111/cgf.13684", "10.2312/eurovisshort.20161166.17", "10.2312/evs:20191168", "10.1145/3041021.3055135", "10.1145/3301275.3302265", "10.1613/jair.4135", "10.1109/tvcg.2018.2864500", "10.1109/tvcg.2017.2744158", "10.1109/ssci.2015.33", "10.1111/cgf.13453", "10.2312/pe/eurovast/eurova11/049-052", "10.1145/3025171.3025181.13", "10.1145/371920.372094", "10.1109/tvcg.2017.2744938", "10.1111/j.1467-8659.2012.03108.x", "10.1109/tvcg.2019.2934251", "10.1145/3290605.3300809.18", "10.1109/ldav.2016.7874305", "10.1109/vast.2016.7883514", "10.1109/iccv.2015.425", "10.1145/3301275.3302324", "10.1109/tnnls.2013.2292894", "10.1109/tvcg.2018.2865044", "10.1109/tvcg.2013.157", "10.1371/journal.pcbi.0020161", "10.1186/s12916-019-1426-2", "10.1109/10.867928", "10.1111/cgf.13217", "10.1109/mcg.2019.2919033", "10.1145/2993901.2993910", "10.1109/tvcg.2017.2744738", "10.2307/258792", "10.1111/cgf.12655", "10.1016/j.dss.2014.03.001", "10.1109/tvcg.2019.2904069", "10.1111/cgf.13205", "10.1002/mds.22340", "10.1109/tvcg.2019.2934595", "10.1287/inte.2018.0957", "10.1109/cvpr.2007.382974", "10.1109/tvcg.2012.280", "10.1145/2678025.2701399.13", "10.2312/mlvis.20181130.13", "10.2312/eurova.20181106.16", "10.1109/tvcg.2018.2864475", "10.2312/mlvis.20191160.18,22", "10.1007/978-1-4612-4026-6.25", "10.1109/cvpr.2006.42", "10.1145/3172944.3172950", "10.1109/cvpr.2004.383.25", "10.1109/tvcg.2019.2934812", "10.1609/aimag.v35i4.2513", "10.2312/trvis.20191185.7", "10.1111/j.1467-8659.2009.01684.x", "10.1371/journal.pone.0129126", "10.1111/cgf.13092", "10.1162/coli\\_a\\_00237", "10.1109/tvcg.2017.2744818", "10.1109/vast.2011.6102448", "10.1109/tvcg.2009.111", "10.1109/tvcg.2019.2934619", "10.1016/s0377-2217(01)00264-8.25", "10.1111/cgf.12639", "10.1109/access.2019.2919343", "10.1186/s12874-019-0681-4", "10.1109/pacificvis.2015.7156366", "10.1109/pacificvis.2018.00029", "10.1109/tvcg.2019.2934261", "10.1080/13506280444000102.http://www.uvt.nl/ticc", "10.1109/vast.2018.8802509", "10.1111/cgf.13212", "10.1145/3200489", "10.1111/cgf.13176", "10.1177/1473871620904671", "10.1007/978-3-319-10590-1\\_53", "10.1111/j.1467-8659.2012.03126.x", "10.1111/cgf.13172", "10.1145/3025171.3025208.6,21", "10.1111/cgf.12366", "10.1109/tvcg.2019.2934659", "10.1109/cvprw.2009.5206848", "10.1016/j.media.2014.11.010", "10.1109/tvcg.2017.2744683", "10.1109/tvcg.2019.2934262", "10.1016/j.neucom.2006.11.018", "10.1177/1473871615571951", "10.1371/journal.pcbi.0020161.25", "10.1177/1473871611415994", "10.2312/trvis20191187", "10.2312/eurova", "10.1145/2858036.2858529", "10.1145/2207676.2207738", "10.1007/s11042-009-0417-2", "10.1145/3301275.3302317", "10.1038/s41746-019-0148-3", "10.1145/3351095.3372834", "10.1080/10691898.2011.11889627", "10.1109/tvcg.2018.2864504", "10.1109/vast.2017.8585720", "10.1109/mcg.2018.053491732", "10.1007/s10994-010-5207-6", "10.1109/tvcg.2019.2934433", "10.1016/j.cag.2017.05.005", "10.1109/tvcg.2012.279", "10.1145/3231622.3231641.19,20", "10.1145/1562849.1562851", "10.1007/11564126\\_", "10.1109/tvcg.2018.2846735", "10.3115/1225403.1225421", "10.1109/vast.2012.6400486", "10.2312/eurova.20191116.22", "10.1109/tvcg.2007.70443", "10.1080/027868291009242", "10.2312/eurova.20151100", "10.1145/2939502.2939503.19", "10.1016/j.cag.2014.02.004", "10.1145/2939672.2939778", "10.1109/vast.2010.5652484", "10.1111/cgf.12641", "10.1145/3301275.3302289", "10.1109/visual.2019.8933619", "10.1109/tvcg.2017.2672987", "10.1109/vast.2016.7883517.20", "10.1109/igarss.2017.8127684", "10.1016/j.jcae.2010.04.002", "10.1109/vast.2010.5652885", "10.1016/j.visinf.2019.03.002", "10.1007/s00371-018-1500-3", "10.1109/mcg.2018.042731661", "10.1109/34.598228", "10.1109/tvcg.2018.2865027", "10.1016/j.neucom.2017.01.105", "10.1111/cgf.12389", "10.1109/tvcg.2019.2934591", "10.1109/vast.2010.5652392.16", "10.1111/cgf.13416", "10.1080/02701367.1992.10608764", "10.1109/vast.2017.8585721", "10.1109/tvcg.2018.2843369", "10.1109/sbes.2010.27", "10.1109/vast.2015.7347637", "10.1145/1401890.1402008", "10.1016/j.bpj.2010.04.064", "10.1109/tvcg.2013.125", "10.1109/isai-nlp.2018.8693002", "10.1371/journal.pone.0160127", "10.1145/2856767.2856779", "10.1145/2678025.2701399", "10.1109/vast.2011.6102451", "10.1109/mcg.2010.18", "10.1021/ci4000213", "10.1109/vast.2012.6400492", "10.1007/11564126-49.25", "10.2312/eurova.20171114", "10.1109/vast.2010.5652443", "10.1145/3134599", "10.2312/pe/eurovast/eurovast10/013-018.19", "10.1109/tvcg.2019.2903946", "10.1109/tvcg.2015.2467717", "10.1177/1473871612460526", "10.1016/j.cag.2018.09.018", "10.1109/tvcg.2016.2598838", "10.1145/3172944.3172964.14", "10.1109/vast.2009.5333428", "10.1109/vast.2014.7042480", "10.2312/pe/eurovast/eurovast10/013-018", "10.1177/0962280215588241", "10.1145/2993901.2993917", "10.1109/cvpr.2008:4587581", "10.1109/tvcg.2015.2467551", "10.1016/j.visinf.2018.09.001", "10.1126/science.290.5500.2319", "10.2312/eurova.20151107", "10.1109/visual.2019.8933695", "10.13140/2.1.2393.1847", "10.1197/jamia.m1929", "10.1109/cvpr.2008.4587581.25", "10.1145/1518701.1518895.16", "10.1109/vds.2017.8573444", "10.2312/trvis:20191185", "10.1145/3359786", "10.13140/2.1.1341.1520", "10.2312/pe/eurovast/eurova11/049-052.17", "10.1109/tvcg.2014.2346660", "10.1145/3185517", "10.1109/adprl.2011.5967372", "10.1109/tvcg.2015.2467591", "10.1111/j.1751-9004.2009.00232.x", "10.1136/qshc.2004.010033", "10.1109/vast.2012.6400493", "10.1109/tvcg.2019.2934266", "10.1145/2971763.2971775", "10.1111/cgf.13730", "10.1109/vast.2012.6400488", "10.1111/cgf.13210", "10.1109/tvcg.2019.2934631", "10.1145/3172944.3172965", "10.1057/ivs.2010.2", "10.1109/tvcg.2017.2745258", "10.1016/j.jbusres.2019.07.039", "10.1162/jmlr.2003.3.4-5.993", "10.1109/pacificvis.2019.00044", "10.2312/pe/eurovast/eurova12/037-041", "10.1109/tvcg.2019.2934629", "10.1177/0018720814547570", "10.1145/3292500.3330908", "10.1111/j.1467-8659.2009.01467.x", "10.2312/eurova.20151098", "10.1177/1473871617713337", "10.1109/lars:2009.5418323", "10.1109/vast.2011.6102437", "10.1111/cgf.12878", "10.1561/1500000001", "10.1145/3025171.3025222", "10.1007/s11704-016-6028-y", "10.1016/j.procs.2017.05.216", "10.1109/cvpr.2007.382974.25", "10.1080/10447318.2020.1741118", "10.1109/vast.2012.6400489", "10.1145/3025171.3025172", "10.1109/tvcg.2017.2744098", "10.1109/tvcg.2005.66", "10.1016/j.dss.2009.05.016", "10.1007/978-1-4612-4026-6", "10.2312/evs.20191168.16,20,28", "10.2312/pe/eurovast/eurova12/037-041.17", "10.1145/3290605.3300803", "10.1145/1015330.1015388", "10.1111/cgf.13197", "10.1016/b978-1-55860-377-6.50048-7", "10.1111/cgf.13681", "10.1109/tvcg.2017.2744378", "10.1109/tvcg.2017.2744358", "10.1109/vast.2008.4677352"], "wos": 1, "children": [{"doi": "10.1109/tvcg.2020.3030368", "title": "Implicit Multidimensional Projection of Local Subspaces", "year": "2020", "conferenceName": "InfoVis", "authors": "Rongzheng Bian;Yumeng Xue;Liang Zhou;Jian Zhang 0070;Baoquan Chen;Daniel Weiskopf;Yunhai Wang", "citationCount": "1", "affiliation": "Wang, YH (Corresponding Author), Shandong Univ, Qingdao, Peoples R China. Zhou, L (Corresponding Author), Univ Utah, Salt Lake City, UT 84112 USA. Bian, Rongzheng; Xue, Yumeng; Wang, Yunhai, Shandong Univ, Qingdao, Peoples R China. Chen, Baoquan, Peking Univ, Beijing, Peoples R China. Zhang, Jian, Chinese Acad Sci, CNIC, Beijing, Peoples R China. Zhou, Liang, Univ Utah, Salt Lake City, UT 84112 USA. Weiskopf, Daniel, Univ Stuttgart, Stuttgart, Germany.", "countries": "USA;Germany;China", "abstract": "We propose a visualization method to understand the effect of multidimensional projection on local subspaces, using implicit function differentiation. Here, we understand the local subspace as the multidimensional local neighborhood of data points. Existing methods focus on the projection of multidimensional data points, and the neighborhood information is ignored. Our method is able to analyze the shape and directional information of the local subspace to gain more insights into the global structure of the data through the perception of local structures. Local subspaces are fitted by multidimensional ellipses that are spanned by basis vectors. An accurate and efficient vector transformation method is proposed based on analytical differentiation of multidimensional projections formulated as implicit functions. The results are visualized as glyphs and analyzed using a full set of specifically-designed interactions supported in our efficient web-based visualization tool. The usefulness of our method is demonstrated using various multi- and high-dimensional benchmark datasets. Our implicit differentiation vector transformation is evaluated through numerical comparisons; the overall method is evaluated through exploration examples and use cases.", "keywords": "High-dimensional data visualization,dimensionality reduction,local linear subspaces,user interaction", "link": "http://dx.doi.org/10.1109/TVCG.2020.3030368", "refList": ["10.3844/jcssp.2018.613.622", "10.1016/j.aci.2018.08.003", "10.3390/info9030065", "10.1016/j.visinf.2018.09.003", "10.1371/journal.pone.0118432", "10.1016/s0893-6080(05)80023-1", "10.1109/tvcg.2020.2986996", "10.1109/icst.2012.56", "10.1007/s10844-013-0250-y", "10.1109/tbdata.2018", "10.1145/1125451.1125659", "10.1109/tvcg.2013.125", "10.1177/1473871611412817", "10.1145/3290605.3300911", "10.1111/cgf.14034", "10.1007/s13721-013-0034-x", "10.1016/j.procs.2017.05.216", "10.1016/j.ins.2009.08.025", "10.1109/tvcg.2013.124", "10.1109/tvcg.2018.2864499", "10.1109/tvcg.2018.2864475", "10.1080/10447318.2020.1741118", "10.1016/j.imu.2019.100203", "10.1109/tvcg.2018.2865240", "10.1186/s12864-019-6413-7", "10.1109/tvcg.2015.2467551", "10.1002/widm.1249", "10.1007/978-3-319-66429-3\\_29", "10.1109/tvcg.2014.2346481", "10.1109/tvcg.2018.2864825", "10.1177/1473871620904671", "10.1109/tvcg.2019.2934267", "10.1136/bmjopen-2016-012799", "10.1109/smartgridcomm.2017.8340682", "10.1007/s10664-015-9401-9", "10.1145/1143844.1143874", "10.1111/cgf.12389", "10.1109/tvcg.2018.2872577", "10.1007/978-981-13-5802-9\\_20", "10.1016/j.ipm.2009.03.002", "10.5220/0006431602160222", "10.1109/mcg.2015.50", "10.1109/tvcg.2014.2346574", "10.1007/bf02289565", "10.1109/tvcg.2017.2744378", "10.1016/j.patrec.2008.08.010", "10.1023/a:1010933404324", "10.9735/2229-3981"], "wos": 1, "children": [], "len": 1}, {"doi": "10.1109/tvcg.2020.3030465", "title": "Visual Causality Analysis of Event Sequence Data", "year": "2020", "conferenceName": "VAST", "authors": "Zhuochen Jin;Shunan Guo;Nan Chen;Daniel Weiskopf;David Gotz;Nan Cao", "citationCount": "0", "affiliation": "Cao, N (Corresponding Author), Tongji Univ, IDVx Lab, Shanghai, Peoples R China. Jin, Zhuochen; Guo, Shunan; Chen, Nan; Cao, Nan, Tongji Univ, IDVx Lab, Shanghai, Peoples R China. Weiskopf, Daniel, Univ Stuttgart, Stuttgart, Germany. Gotz, David, Univ N Carolina, Chapel Hill, NC 27515 USA.", "countries": "USA;Germany;China", "abstract": "Causality is crucial to understanding the mechanisms behind complex systems and making decisions that lead to intended outcomes. Event sequence data is widely collected from many real-world processes, such as electronic health records, web clickstreams, and financial transactions, which transmit a great deal of information reflecting the causal relations among event types. Unfortunately, recovering causalities from observational event sequences is challenging, as the heterogeneous and high-dimensional event variables are often connected to rather complex underlying event excitation mechanisms that are hard to infer from limited observations. Many existing automated causal analysis techniques suffer from poor explainability and fail to include an adequate amount of human knowledge. In this paper, we introduce a visual analytics method for recovering causalities in event sequence data. We extend the Granger causality analysis algorithm on Hawkes processes to incorporate user feedback into causal model refinement. The visualization system includes an interactive causal analysis framework that supports bottom-up causal exploration, iterative causal verification and refinement, and causal comparison through a set of novel visualizations and interactions. We report two forms of evaluation: a quantitative evaluation of the model improvements resulting from the user-feedback mechanism, and a qualitative evaluation through case studies in different application domains to demonstrate the usefulness of the system.", "keywords": "Event sequence data,causality analysis,visual analytics", "link": "http://dx.doi.org/10.1109/TVCG.2020.3030465", "refList": ["10.5555/1642718", "10.1109/tvcg.2018.2865022", "10.5555/2074094.2074151", "10.1109/tvcg.2016.2618797", "10.1073/pnas.1320645111", "10.1109/tvcg.2017.2744843", "10.1109/iv.2017.69", "10.1109/tvcg.2019.2934399", "10.1145/3172944.3173007", "10.5555/1795555", "10.1109/mcg.2005.102", "10.1145/381641.381653", "10.1162/153244301753344614", "10.1111/cgf.14034", "10.1111/cgf.13198", "10.1017/cbo9780511519857", "10.1007/s10462-016-9475-9", "10.1075/ssol.2.2.07bor", "10.1007/978-1-4614-3223-4\\_3", "10.1109/infvis.2003.1249025", "10.1007/978-94-007-6094-313", "10.1145/2858036.2858387", "10.1109/tvcg.2007.70528", "10.1109/tvcg.2017.2674958", "10.1147/sj.454.0801", "10.1109/tvcg.2013.119", "10.1145/3173574.3173711", "10.1016/j.erss.2017.06.034", "10.1109/visual.2019.8933695", "10.1007/s11665-016-2173-6", "10.1016/0377-0427(87)90125-7", "10.2307/3601125", "10.1016/b978-0-444-88738-2.50018-x", "10.1109/mcg.2006.70", "10.1109/tvcg.2018.2865145", "10.1017/s1351324997001502", "10.1109/tvcg.2010.179", "10.1214/aos/1176344552", "10.1109/mcg.2009.22", "10.1007/978-3-319-26633-6\\_13", "10.1080/10447318.2014.905422", "10.1016/j.visinf.2019.03.004", "10.1057/palgrave.ivs.9500074", "10.1007/978-1-4614-3223-4"], "wos": 1, "children": [], "len": 1}], "len": 5}], "len": 21}, {"doi": "10.1111/cgf.13397", "year": "2018", "title": "Representative Consensus from Limited-Size Ensembles", "conferenceName": "EuroVis", "authors": "Mahsa Mirzargar;Ross T. Whitaker", "citationCount": "0", "affiliation": "Mirzargar, M (Corresponding Author), Univ Miami, Dept Comp Sci, Coral Gables, FL 33124 USA.\nMirzargar, Mahsa, Univ Miami, Dept Comp Sci, Coral Gables, FL 33124 USA.\nWhitaker, Ross T., Univ Utah, Sch Comp, Salt Lake City, UT USA.\nWhitaker, Ross T., Univ Utah, SCI Inst, Salt Lake City, UT USA.", "countries": "USA", "abstract": "Characterizing the uncertainty and extracting reliable visual information from ensemble data have been persistent challenges in various disciplines, specifically in simulation sciences. Many ensemble analysis and visualization techniques take a probabilistic approach to this problem with the assumption that the ensemble size is large enough to extract reliable statistical or probabilistic summaries. However, many real-life ensembles are rather limited in size, with only a handful of members, due to various restrictions such as storage, computational power, or sampling limitations. As a result, probabilistic inference is subject to imprecision and can potentially result in untrustworthy information in the presence of a limited sample-size ensemble. In this case, a more reliable approach is to fuse the information present in an ensemble with a limited number of members with minimal assumptions. In this paper, we propose a technique to construct a representative consensus that is particularly suited for ensembles of a relatively small size. The proposed technique casts the problem as an ordering problem in which at each point in the domain, the ensemble members are ranked based on the local neighborhood. This local approach allows us to provide shape and irregularity sensitivity. The local order statistics will then be fused to construct a global consensus using a Bayesian approach to ensure spatial coherency of the local information. We demonstrate the utility of the proposed technique using a synthetic and two real-life examples.", "keywords": "", "link": "https://doi.org/10.1111/cgf.13397", "refList": ["10.1109/tvcg.2016.2598919", "10.1198/jasa.2009.0108", "10.1109/tvcg.2015.2467591", "10.1109/tvcg.2015.2467204", "10.1016/0031-3203(93)90135-j", "10.1109/tvcg.2013.143", "10.1186/s12859-016-1445-3", "10.1111/cgf.12898", "10.1109/tvcg.2016.2598868", "10.1016/j.media.2015.06.012", "10.1109/tvcg.2014.2346455", "10.1109/scivis.2015.7429487", "10.1109/vizsec.2015.7312766", "10.2307/2333244", "10.1109/34.969114", "10.1145/3002151.3002165.3", "10.1214/aos/1176347507", "10.1109/tvcg.2015.2424872", "10.1007/s11634-014-0166-6", "10.1109/tvcg.2016.2607204", "10.1109/tpami.1984.4767596", "10.1109/tpami.2004.60", "10.1198/jcgs.2011.09224", "10.1007/978-3-319-10443-0\\_3", "10.1111/cgf.13204", "10.1080/10618600.2016.1209115", "10.1109/iccv.2001.937655", "10.1111/j.1467-8659.2012.03097.x", "10.1109/vast.2015.7347634", "10.1111/cgf.13173", "10.1111/j.1467-8659.2011.01942.x", "10.1109/tvcg.2016.2637333", "10.1111/cgf.12653", "10.1109/tmi.2004.828354", "10.1109/tvcg.2016.2598869", "10.1111/j.1467-8659.2012.03096.x"], "wos": 1, "children": [{"doi": "10.1109/tvcg.2020.3030466", "title": "Uncertainty in Continuous Scatterplots, Continuous Parallel Coordinates, and Fibers", "year": "2020", "conferenceName": "SciVis", "authors": "Boyan Zheng;Filip Sadlo", "citationCount": "0", "affiliation": "Zheng, BY (Corresponding Author), Heidelberg Univ, Heidelberg, Germany. Zheng, Boyan; Sadlo, Filip, Heidelberg Univ, Heidelberg, Germany.", "countries": "Germany", "abstract": "In this paper, we introduce uncertainty to continuous scatterplots and continuous parallel coordinates. We derive respective models, validate them with sampling-based brute-force schemes, and present acceleration strategies for their computation. At the same time, we show that our approach lends itself as well for introducing uncertainty into the definition of fibers in bivariate data. Finally, we demonstrate the properties and the utility of our approach using specifically designed synthetic cases and simulated data.", "keywords": "Multivariate data,uncertainty visualization,uncertain continuous scatterplots,uncertain continuous parallel coordinates,uncertain fibers", "link": "http://dx.doi.org/10.1109/TVCG.2020.3030466", "refList": ["10.1109/tvcg.2018.2865193", "10.1109/tvcg.2013.143", "10.1109/tvcg.2015.2467204", "10.1109/pacificvis.2013.6596144", "10.1109/tvcg.2017.2745178", "10.1109/tmm.2016.2614227", "10.1109/scivis.2015.7429488", "10.1111/cgf.12100", "10.1109/pacificvis.2016.7465251", "10.1111/cgf.12898", "10.1109/tvcg.2015.2410278", "10.1109/icdmw.2009.55", "10.1109/tvcg.2015.2467754", "10.1109/tvcg.2010.247", "10.1109/tvcg.2019.2934312", "10.1111/cgf.13397", "10.1109/tvcg.2016.2598868", "10.1111/j.1467-8659.2011.01944.x", "10.1109/tvcg.2015.2507569", "10.1109/tvcg.2013.92", "10.1145/1268517.1268563", "10.1109/tvcg.2014.2346455", "10.1109/tvcg.2010.181", "10.1109/tvcg.2018.2853721", "10.1109/tvcg.2008.140", "10.1007/s12650-015-0341-7", "10.1109/mcg.2014.52", "10.1109/tvcg.2018.2864815", "10.1111/j.1467-8659.2012.03095.x", "10.1109/tvcg.2013.138", "10.1109/tvcg.2019.2934242", "10.3390/e20070540", "10.1016/j.jcp.2007.02.014", "10.1111/cgf.13999", "10.1109/tvcg.2017.2779501", "10.1111/cgf.12390", "10.1109/tvcg.2014.2307892", "10.1111/cgf.13531", "10.1109/tvcg.2013.152", "10.1038/nature14956", "10.1007/978-3-540-88606-8\\_4", "10.1109/mcg.2005.71", "10.1111/j.1467-8659.2011.01942.x", "10.1109/tvcg.2019.2934800", "10.1109/tvcg.2016.2598830", "10.1109/cvpr.2005.188", "10.1109/tvcg.2011.261", "10.1111/cgf.13731", "10.1109/tvcg.2017.2754480"], "wos": 1, "children": [], "len": 1}], "len": 3}, {"doi": "10.1111/cgf.13692", "year": "2019", "title": "Towards Glyphs for Uncertain Symmetric Second-Order Tensors", "conferenceName": "EuroVis", "authors": "Tim Gerrits;Christian R{\\\"{o}}ssl;Holger Theisel", "citationCount": "0", "affiliation": "Gerrits, T (Corresponding Author), Univ Magdeburg, Magdeburg, Germany.\nGerrits, Tim; Roessl, Christian; Theisel, Holger, Univ Magdeburg, Magdeburg, Germany.", "countries": "Germany", "abstract": "Measured data often incorporates some amount of uncertainty, which is generally modeled as a distribution of possible samples. In this paper, we consider second-order symmetric tensors with uncertainty. In the 3D case, this means the tensor data consists of 6 coefficients - uncertainty, however, is encoded by 21 coefficients assuming a multivariate Gaussian distribution as model. The high dimension makes the direct visualization of tensor data with uncertainty a difficult problem, which was until now unsolved. The contribution of this paper consists in the design of glyphs for uncertain second-order symmetric tensors in 2D and 3D. The construction consists of a standard glyph for the mean tensor that is augmented by a scalar field that represents uncertainty. We show that this scalar field and therefore the displayed glyph encode the uncertainty comprehensively, i.e., there exists a bijective map between the glyph and the parameters of the distribution. Our approach can extend several classes of existing glyphs for symmetric tensors to additionally encode uncertainty and therefore provides a possible foundation for further uncertain tensor glyph design. For demonstration, we choose the well-known superquadric glyphs, and we show that the uncertainty visualization satisfies all their design constraints.", "keywords": "", "link": "https://doi.org/10.1111/cgf.13692", "refList": ["10.1007/978-1-4471-2804-5\\_6", "10.1109/tvcg.2016.2598998", "10.1111/cgf.12357", "10.1109/tvcg.2014.2346455", "10.1109/tvcg.2010.199", "10.1109/tmi.2003.815059", "10.1109/tvcg.2015.2467435", "10.1111/cgf.13173", "10.1002/mrm.10331", "10.1111/cgf.12099", "10.1111/cgf.12890", "10.1109/tvcg.2015.2467031", "10.1016/j.sigpro.2006.02.050", "10.1007/978-1-4471-6497-5\\_1", "10.2312/vissym/vissym04/147-154", "10.1109/pacificvis.2012.6183591"], "wos": 1, "children": [], "len": 1}], "len": 29}], "len": 51}, "index": 427, "embedding": [0.8911964297294617, 1.0408719778060913, -1.060706377029419, -2.308903217315674, 0.42677661776542664, 0.16650904715061188, -0.700136661529541, 2.932107925415039, 3.243083953857422, 1.2440516948699951, 1.8164873123168945, 1.5759506225585938, 4.3015851974487305, 1.9109492301940918, -0.678647518157959, -0.5592858791351318, 1.7136516571044922, 0.08175134658813477, 0.7351514101028442, 2.199002742767334, -0.06630208343267441, -0.6501080393791199, -1.2873778343200684, 1.7538480758666992, -2.570812940597534, 2.674466371536255, -0.5500518083572388, 0.36380839347839355, 2.0088064670562744, -2.2119052410125732, 1.0353662967681885, 0.6549897193908691], "projection": [1.470414638519287, 8.979490280151367], "size": 26, "height": 6, "width": 8}