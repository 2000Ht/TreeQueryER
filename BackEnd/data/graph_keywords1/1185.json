{"data": {"doi": "10.1109/vast.2016.7883519", "title": "The semantics of sketch: Flexibility in visual query systems for time series data", "year": "2016", "conferenceName": "VAST", "authors": "Michael Correll;Michael Gleicher", "citationCount": "12", "affiliation": "Correll, M (Corresponding Author), Univ Washington, Seattle, WA 98195 USA. Correll, Michael, Univ Washington, Seattle, WA 98195 USA. Gleicher, Michael, Univ Wisconsin, Madison, WI USA.", "countries": "USA", "abstract": "Sketching allows analysts to specify complex and free-form patterns of interest. Visual query systems can make use of sketches to locate these patterns of interest in large datasets. However, sketching is ambiguous: the same drawing could represent a multitude of potential queries. In this work, we investigate these ambiguities as they apply to visual query systems for time series data. We define a class of \u201cinvariants\u201d - the properties of a time series that the analyst wishes to ignore when performing a sketch-based query. We present the results of a crowd-sourced study, showing that these invariants are key components of how people rate the strength of match between sketch and target. We adapt a number of algorithms for time series matching to support invariants in sketches. Lastly, we present a web-deployed prototype sketch-based visual query system that relies on these invariants. We apply the prototype to data from finance, the digital humanities, and political science.", "keywords": "", "link": "http://dx.doi.org/10.1109/VAST.2016.7883519", "refList": ["10.1080/0144929x.2010.511264", "10.1145/2207676.2208294", "10.1145/1056808.1057017", "10.1111/cgf.12106", "10.1109/tvcg.2014.2346452", "10.1109/2.910894", "10.1109/tvcg.2014.2346455", "10.1145/2678025.2701379", "10.1109/icde.1996.492204", "10.1145/634067.634292", "10.1016/0031-3203(81)90009-1", "10.1109/infvis.2005.1532144", "10.1109/edssc.2007.4450237", "10.1057/palgrave.ivs.9500061", "10.2307/1578475", "10.1109/tvcg.2013.191", "10.1109/icde.1999.754915", "10.1109/tvcg.2012.204", "10.1109/2.410146", "10.1109/tvcg.2010.162", "10.1016/s0734-189x(88)80033-1", "10.1109/icpr.1992.201616", "10.1117/12.587537", "10.1137/1.9781611972818.60"], "wos": 1, "children": [{"doi": "10.1109/tvcg.2018.2864907", "title": "Looks Good To Me: Visualizations As Sanity Checks", "year": "2018", "conferenceName": "InfoVis", "authors": "Michael Correll;Mingwei Li;Gordon L. Kindlmann;Carlos Scheidegger", "citationCount": "6", "affiliation": "Correll, M (Corresponding Author), Tableau Res, Seattle, WA 98103 USA. Correll, Michael, Tableau Res, Seattle, WA 98103 USA. Li, Mingwei; Scheidegger, Carlos, Univ Arizona, Tucson, AZ 85721 USA. Kindlmann, Gordon, Univ Chicago, Chicago, IL 60637 USA.", "countries": "USA", "abstract": "Famous examples such as Anscombe's Quartet highlight that one of the core benefits of visualizations is allowing people to discover visual patterns that might otherwise be hidden by summary statistics. This visual inspection is particularly important in exploratory data analysis, where analysts can use visualizations such as histograms and dot plots to identify data quality issues. Yet, these visualizations are driven by parameters such as histogram bin size or mark opacity that have a great deal of impact on the final visual appearance of the chart, but are rarely optimized to make important features visible. In this paper, we show that data flaws have varying impact on the visual features of visualizations, and that the adversarial or merely uncritical setting of design parameters of visualizations can obscure the visual signatures of these flaws. Drawing on the framework of Algebraic Visualization Design, we present the results of a crowdsourced study showing that common visualization types can appear to reasonably summarize distributional data while hiding large and important flaws such as missing data and extraneous modes. We make use of these results to propose additional best practices for visualizations of distributions for data quality tasks.", "keywords": "Graphical perception,data quality,univariate visualizations", "link": "http://dx.doi.org/10.1109/TVCG.2018.2864907", "refList": ["10.1109/tvcg.2017.2744359", "10.1109/tvcg.2014.2346979", "10.1109/tvcg.2012.230", "10.1016/j.jesp.2017.01.006", "10.1145/3025453.3025870", "10.1145/2254556.2254659", "10.1109/tvcg.2011.185", "10.1023/a:1021564703268", "10.1111/j.1467-8659.2009.01677.x", "10.1080/00045608.2011.577364", "10.1145/3025453.3025912", "10.1007/bf01025868", "10.1002/wics.35", "10.1111/j.1539-6924.1987.tb00488.x", "10.2307/2686111", "10.2307/2685478", "10.1109/tvcg.2016.2598862", "10.1145/2470654.2466443", "10.1109/tvcg.2017.2674978", "10.2307/2288400", "10.1109/tvcg.2016.2598618", "10.1145/2858036.2858155", "10.1109/tvcg.2015.2469125", "10.1109/tvcg.2014.2346978", "10.1037/1082-989x.10.4.389", "10.2307/2291420", "10.2307/2682899", "10.1214/088342304000000297", "10.1109/tvcg.2014.2346298", "10.1109/tvcg.2010.161", "10.1109/tvcg.2015.2467191", "10.1109/tvcg.2014.2346325", "10.2307/2289526", "10.1145/2702123.2702585", "10.1109/tvcg.2016.2599030", "10.1109/vast.2016.7883519"], "wos": 1, "children": [{"doi": "10.1109/tvcg.2019.2934796", "title": "Improving the Robustness of Scagnostics", "year": "2019", "conferenceName": "InfoVis", "authors": "Yunhai Wang;Zeyu Wang 0005;Tingting Liu;Michael Correll;Zhanglin Cheng;Oliver Deussen;Michael Sedlmair", "citationCount": "1", "affiliation": "Wang, YH (Corresponding Author), Shandong Univ, Jinan, Peoples R China. Wang, Yunhai; Wang, Zeyu; Liu, Tingting, Shandong Univ, Jinan, Peoples R China. Wang, Zeyu; Cheng, Zhanglin; Deussen, Oliver, SIAT, Shenzhen VisuCA Key Lab, Shenzhen, Peoples R China. Correll, Michael, Tableau Res, Seattle, WA USA. Deussen, Oliver, Konstanz Univ, Constance, Germany. Sedlmair, Michael, Univ Stuttgart, VISUS, Stuttgart, Germany.", "countries": "USA;Germany;China", "abstract": "In this paper, we examine the robustness of scagnostics through a series of theoretical and empirical studies. First, we investigate the sensitivity of scagnostics by employing perturbing operations on more than 60M synthetic and real-world scatterplots. We found that two scagnostic measures, Outlying and Clumpy, are overly sensitive to data binning. To understand how these measures align with human judgments of visual features, we conducted a study with 24 participants, which reveals that i) humans are not sensitive to small perturbations of the data that cause large changes in both measures, and ii) the perception of clumpiness heavily depends on per-cluster topologies and structures. Motivated by these results, we propose Robust Scagnostics (RScag) by combining adaptive binning with a hierarchy-based form of scagnostics. An analysis shows that RScag improves on the robustness of original scagnostics, aligns better with human judgments, and is equally fast as the traditional scagnostic measures.", "keywords": "Scagnostics,scatterplots,sensitivity analysis,Robust Scagnostics", "link": "http://dx.doi.org/10.1109/TVCG.2019.2934796", "refList": ["10.1057/palgrave.ivs.9500122", "10.1109/tvcg.2014.2346979", "10.1111/j.1467-8659.2009.01467.x", "10.1109/vast.2008.4677368", "10.2307/2289444", "10.1109/tvcg.2011.229", "10.1109/iv.2004.1320207", "10.1109/vast.2009.5332628", "10.1111/insr.12095\\_11", "10.1109/tvcg.2010.184", "10.1109/tvcg.2015.2467323", "10.1109/vast.2010.5652460", "10.1111/j.1467-8659.2012.03069.x", "10.1145/1842993.1843002", "10.1198/106186008x320465", "10.1109/pacificvis.2016.7465244", "10.1109/tvcg.2013.20", "10.1111/cgf.12641", "10.1109/tvcg.2012.128", "10.1109/tvcg.2015.2467671", "10.1057/palgrave.ivs.9500091", "10.1007/978-1-4612-4400-4", "10.1111/cgf.13176", "10.1002/0470870958", "10.1109/tvcg.2018.2864907", "10.1111/j.1467-8659.2012.03125.x", "10.1109/vast.2012.6400490", "10.1109/infvis.2005.1532142", "10.1109/vast.2010.5652433", "10.1109/vast.2009.5332611", "10.1201/9781315140919", "10.1145/2858036.2858155", "10.1109/ldav.2013.6675164", "10.1515/itit-2014-1070", "10.1111/cgf.13684", "10.1109/tpami.1979.4766909", "10.2307/2289936", "10.1109/pacificvis.2014.42", "10.1109/tvcg.2016.2598467", "10.1109/tvcg.2013.153", "10.1111/cgf.13446", "10.1109/tvcg.2006.94", "10.1109/tvcg.2014.2346572", "10.1111/cgf.12632", "10.1109/tvcg.2017.2744339"], "wos": 1, "children": [], "len": 1}, {"doi": "10.1109/tvcg.2020.3030363", "title": "Improving the Usability of Virtual Reality Neuron Tracing with Topological Elements", "year": "2020", "conferenceName": "SciVis", "authors": "Torin McDonald;William Usher;Nathan Morrical;Attila Gyulassy;Steve Petruzza;Frederick Federer;Alessandra Angelucci;Valerio Pascucci", "citationCount": "0", "affiliation": "McDonald, T (Corresponding Author), Univ Utah, SCI Inst, Salt Lake City, UT 84112 USA. McDonald, Torin; Usher, Will; Morrical, Nate; Gyulassy, Attila; Petruzza, Steve; Pascucci, Valerio, Univ Utah, SCI Inst, Salt Lake City, UT 84112 USA. Petruzza, Steve, Utah State Univ, Logan, UT 84322 USA. Federer, Frederick; Angelucci, Alessandra, Univ Utah, Moran Ese Inst, Salt Lake City, UT 84112 USA.", "countries": "USA", "abstract": "Researchers in the field of connectomics are working to reconstruct a map of neural connections in the brain in order to understand at a fundamental level how the brain processes information. Constructing this wiring diagram is done by tracing neurons through high-resolution image stacks acquired with fluorescence microscopy imaging techniques. While a large number of automatic tracing algorithms have been proposed, these frequently rely on local features in the data and fail on noisy data or ambiguous cases, requiring time-consuming manual correction. As a result, manual and semi-automatic tracing methods remain the state-of-the-art for creating accurate neuron reconstructions. We propose a new semi-automatic method that uses topological features to guide users in tracing neurons and integrate this method within a virtual reality (VR) framework previously used for manual tracing. Our approach augments both visualization and interaction with topological elements, allowing rapid understanding and tracing of complex morphologies. In our pilot study, neuroscientists demonstrated a strong preference for using our tool over prior approaches, reported less fatigue during tracing, and commended the ability to better understand possible paths and alternatives. Quantitative evaluation of the traces reveals that users' tracing speed increased, while retaining similar accuracy compared to a fully manual approach.", "keywords": "Virtual Reality,Morse-Smale Complex,Semi-automatic Neuron Tracing", "link": "http://dx.doi.org/10.1109/TVCG.2020.3030363", "refList": ["10.1038/nmeth.2869", "10.18637/jss.v028.c01", "10.1177/1473871611416549", "10.1016/j.celrep.2020.107523", "10.1602/neurorx.1.2.182", "10.1038/nprot.2014.191", "10.1136/jnnp-2011-300403", "10.1126/sciadv.aax5851", "10.2312/pe.vmv.vmv13.105-112", "10.1038/s43018-020-0031-9", "10.1109/tvcg.2013.213", "10.1093/jnci/92.8.613", "10.1109/52.329404", "10.1109/tvcg.2017.2785271", "10.1007/s11548-013-0820-z", "10.1109/tvcg.2019.2934547", "10.1002/cjp2.113", "10.1080/2162402x.2018.1507600", "10.1109/tvcg.2013.124", "10.1016/s0140-6736(14)60958-2", "10.1038/s41467-017-01689-9", "10.1016/j.cell.2018.07.010", "10.1007/978-3-319-24523-2", "10.1038/nrg3832", "10.2352/j.imagingsci.technol.2017.61.6.060404", "10.1109/tvcg.2018.2864907", "10.1111/cgf.13413", "10.1007/978-3-319-67979-2\\_4", "10.1145/2836034.2836040", "10.1038/nmeth.2563", "10.1016/0377-0427(87)90125-7", "10.1016/j.immuni.2016.04.014", "10.1002/cyto.a.22702", "10.12688/wellcomeopenres.15191.1", "10.1109/2945.981851", "10.1038/s43018-020-0026-6", "10.5281/zenodo", "10.1109/tvcg.2019.2931299", "10.1109/annes.1995.499469", "10.1145/2133806.2133821", "10.1002/hbm.20701", "10.1109/tvcg.2013.161", "10.1007/978-3-319-24523-210", "10.1126/scitranslmed.3004330", "10.1038/nmeth.4391", "10.1559/152304003100010929", "10.1126/science.280.5363.585", "10.1007/978-3-319-24523-2\\_10", "10.1109/tvcg.2016.2598587", "10.1038/s41597-019-0258-4"], "wos": 1, "children": [], "len": 1}, {"doi": "10.1109/tvcg.2020.3030426", "title": "Introducing Layers of Meaning (LoM): A Framework to Reduce Semantic Distance of Visualization In Humanistic Research", "year": "2020", "conferenceName": "InfoVis", "authors": "Houda Lamqaddam;Andrew Vande Moere;Vero Vanden Abeele;Koenraad Brosens;Katrien Verbert", "citationCount": "0", "affiliation": "Lamqaddam, H (Corresponding Author), Katholieke Univ Leuven, Leuven, Belgium. Lamqaddam, Houda; Vande Moere, Andrew; Vanden Abeele, Vero; Brosens, Koenraad; Verbert, Katrien, Katholieke Univ Leuven, Leuven, Belgium.", "countries": "Belgium", "abstract": "Information visualization (infovis) is a powerful tool for exploring rich datasets. Within humanistic research, rich qualitative data and domain culture make traditional infovis approaches appear reductive and disconnected, leading to low adoption. In this paper, we use a multi-step approach to scrutinize the relationship between infovis and the humanities and suggest new directions for it. We first look into infovis from the humanistic perspective by exploring the humanistic literature around infovis. We validate and expand those findings though a co-design workshop with humanist and infovis experts. Then, we translate our findings into guidelines for designers and conduct a design critique exercise to explore their effect on the perception of humanist researchers. Based on these steps, we introduce Layers of Meaning, a framework to reduce the semantic distance between humanist researchers and visualizations of their research material, by grounding infovis tools in time and space, physicality, terminology, nuance, and provenance.", "keywords": "Infovis,Humanities,Digital Humanities", "link": "http://dx.doi.org/10.1109/TVCG.2020.3030426", "refList": ["10.1177/1473871611416549", "10.1109/tvcg.2014.2346979", "10.1016/j.jesp.2013.03.013", "10.1109/tvcg.2018.2864909", "10.1145/2858036.2858465", "10.1145/1553374.1553527", "10.1037/1076-898x.14.1.36", "10.1109/tvcg.2011.185", "10.2200/s00371ed1v01y201107aim013", "10.1145/3025453.3025912", "10.3758/s13423-018-1525-7", "10.1109/tvcg.2017.2743898", "10.1037/a0029146", "10.1109/infvis.2005.1532136", "10.1109/tvcg.2015.2467671", "10.1109/tvcg.2018.2864907", "10.3758/s13423-016-1174-7", "10.1136/bmj.312.7047.1654", "10.2307/2288400", "10.1085/jgp.7.2.235", "10.3758/s13423-017-1323-7", "10.1109/tvcg.2018.2810918", "10.1080/13803390500205718", "10.1016/s0364-0213(87)80026-5", "10.1109/tvcg.2018.2864884", "10.2307/1419876", "10.1109/tvcg.2010.161", "10.5281/zenodo", "10.1109/tvcg.2005.63", "10.1177/001872089203400503", "10.1126/science.220.4598.671", "10.2307/2289447", "10.1006/jesp.1996.0009", "10.1007/s10898-012-9951-y", "10.3758/s13423-017-1343-3", "10.1109/tvcg.2007.70515", "10.21105/joss.01686", "10.18637/jss.v080.i01", "10.1111/j.1467-8659.2009.01694.x", "10.1145/2702123.2702608"], "wos": 1, "children": [], "len": 1}, {"doi": "10.1109/tvcg.2020.3030365", "title": "Modeling the Influence of Visual Density on Cluster Perception in Scatterplots Using Topology", "year": "2020", "conferenceName": "InfoVis", "authors": "Ghulam Jilani Quadri;Paul Rosen", "citationCount": "0", "affiliation": "Quadri, GJ (Corresponding Author), Univ S Florida, Tampa, FL 33620 USA. Quadri, Ghulam Jilani; Rosen, Paul, Univ S Florida, Tampa, FL 33620 USA.", "countries": "USA", "abstract": "Scatterplots are used for a variety of visual analytics tasks, including cluster identification, and the visual encodings used on a scatterplot play a deciding role on the level of visual separation of clusters. For visualization designers, optimizing the visual encodings is crucial to maximizing the clarity of data. This requires accurately modeling human perception of cluster separation, which remains challenging. We present a multi-stage user study focusing on four factors-distribution size of clusters, number of points, size of points, and opacity of points-that influence cluster identification in scatterplots. From these parameters, we have constructed two models, a distance-based model, and a density-based model, using the merge tree data structure from Topological Data Analysis. Our analysis demonstrates that these factors play an important role in the number of clusters perceived, and it verifies that the distance-based and density-based models can reasonably estimate the number of clusters a user observes. Finally, we demonstrate how these models can be used to optimize visual encodings on real-world data.", "keywords": "Scatterplot,clustering,perception,empirical evaluation,visual encoding,crowdsourcing,topological data analysis", "link": "http://dx.doi.org/10.1109/TVCG.2020.3030365", "refList": ["10.1109/tvcg.2017.2744359", "10.1145/1778765", "10.1109/tvcg.2019.2934799", "10.1111/cgf.12889", "10.1109/tvcg.2011.127", "10.1111/cgf.13444", "10.1145/1964897.1964910", "10.1167/8.7.6", "10.1145/3173574.3173991", "10.1145/1556262.1556289", "10.1145/1056808.1056914", "10.2307/2288400", "10.1109/tvcg.2014.2346594", "10.1109/iv.2002.1028760", "10.1177/001316447303300111", "10.1007/bf02289823", "10.1109/tvcg.2017.2744339", "10.1111/j.1467-8659.2009.01694.x", "10.1109/tvcg.2014.2346979", "10.1090/mbk/069", "10.1109/tvcg.2013.65", "10.1109/mcg.2012.37", "10.1109/pacificvis.2010.5429604", "10.1002/acp.2350050106", "10.1109/infvis.2005.1532136", "10.1177/1473871612465214", "10.1109/tvcg.2017.2674978", "10.1002/jhbs.20078", "10.1007/978-3-642-35142-6\\_14", "10.1007/978-3-319-71507-0", "10.1109/mcg.201.7.6", "10.3758/bf03193961", "10.1364/josa.49.000280", "10.1145/3025453.3025905", "10.1109/tvcg.201.9.2934541", "10.1109/tvcg.2018.2829750", "10.1177/1473871615606187", "10.1111/cgf.13408", "10.1109/pacificvis.2016.7465252", "10.1109/pacificvis.2016.7465244", "10.1109/inevis.2005.1532142", "10.1111/cgf.13414", "10.1111/j.1467-8659.2012.03125.x", "10.1167/16.5.11", "10.1109/infvis.2005.1532142", "10.1145/2858036.2858155", "10.1038/nmeth1210-941", "10.1177/1473871616638892", "10.1109/tcbb.2014.2306840", "10.1111/cgf.13684", "10.1177/0301006615602599", "10.1214/aoms/1177731915", "10.1145/2702123.2702585", "10.1109/tvcg.2013.183", "10.1109/tvcg.2014.2346572", "10.1109/tvcg.2018.2875702", "10.1109/tvcg.2017.2754480", "10.1109/vast.2014.7042493", "10.1057/palgrave.ivs.9500122", "10.1109/tvcg.2014.2330617", "10.1109/tvcg.2019.2934541", "10.1068/p030033", "10.1140/epjds/s13688-017-0109-5", "10.1201/b17511", "10.1016/s0925-7721(02)00093-7", "10.1109/pacificvis.2012.6183557", "10.1109/tvcg.2014.2346983", "10.1109/5.726791", "10.1080/01621459.1926.10502165", "10.1109/tvcg.2007.70535", "10.1109/tvcg.2018.2864907", "10.1111/cgf.12109", "10.1109/tvcg.2017.2744184", "10.1146/annurev-statistics-031017-100045", "10.1111/cgf.13409", "10.1145/3002151.3002162", "10.1016/s0378-4371(98)00494-4", "10.3138/y308-2422-8615-1233", "10.1111/cgf.12632", "10.1145/3290605.3300771"], "wos": 1, "children": [], "len": 1}, {"doi": "10.1109/tvcg.2020.3030336", "title": "Visual cohort comparison for spatial single-cell omics-data", "year": "2020", "conferenceName": "VAST", "authors": "Antonios Somarakis;Marieke E. Ijsselsteijn;Sietse J. Luk;Boyd Kenkhuis;Noel F. C. C. de Miranda;Boudewijn P. F. Lelieveldt;Thomas H\u00f6llt", "citationCount": "0", "affiliation": "Hollt, T (Corresponding Author), Delft Univ Technol, Comp Graph \\& Visualizat Grp, Delft, Netherlands. Hollt, T (Corresponding Author), Leiden Univ, Med Ctr, Leiden Computat Biol Ctr, Leiden, Netherlands. Somarakis, Antonios; Lelieveldt, Boudewijn P. F., Leiden Univ, Med Ctr, Dept Radiol, Div Image Proc, Leiden, Netherlands. Ijsselsteijn, Marieke E.; de Miranda, Noel F. C. C., Leiden Univ, Med Ctr, Dept Pathol, Immunogen Grp, Leiden, Netherlands. Luk, Sietse J., Leiden Univ, Med Ctr, Hematol Dept, Leiden, Netherlands. Kenkhuis, Boyd, Leiden Univ, Med Ctr, Human Genet Dept, Leiden, Netherlands. Hollt, Thomas, Delft Univ Technol, Comp Graph \\& Visualizat Grp, Delft, Netherlands. Hollt, Thomas, Leiden Univ, Med Ctr, Leiden Computat Biol Ctr, Leiden, Netherlands.", "countries": "Netherlands", "abstract": "Spatially-resolved omics-data enable researchers to precisely distinguish cell types in tissue and explore their spatial interactions, enabling deep understanding of tissue functionality. To understand what causes or deteriorates a disease and identify related biomarkers, clinical researchers regularly perform large-scale cohort studies, requiring the comparison of such data at cellular level. In such studies, with little a-priori knowledge of what to expect in the data, explorative data analysis is a necessity. Here, we present an interactive visual analysis workflow for the comparison of cohorts of spatially-resolved omics-data. Our workflow allows the comparative analysis of two cohorts based on multiple levels-of-detail, from simple abundance of contained cell types over complex co-localization patterns to individual comparison of complete tissue images. As a result, the workflow enables the identification of cohort-differentiating features, as well as outlier samples at any stage of the workflow. During the development of the workflow, we continuously consulted with domain experts. To show the effectiveness of the workflow, we conducted multiple case studies with domain experts from different application areas and with different data modalities.", "keywords": "Visual analytics,Imaging Mass Cytometry,Vectra,spatially-resolved data,single-cell omics-data,Visual comparison", "link": "http://dx.doi.org/10.1109/TVCG.2020.3030336", "refList": ["10.1038/nmeth.2869", "10.18637/jss.v028.c01", "10.1177/1473871611416549", "10.1016/j.celrep.2020.107523", "10.1602/neurorx.1.2.182", "10.1038/nprot.2014.191", "10.1136/jnnp-2011-300403", "10.1126/sciadv.aax5851", "10.2312/pe.vmv.vmv13.105-112", "10.1038/s43018-020-0031-9", "10.1109/tvcg.2013.213", "10.1093/jnci/92.8.613", "10.1109/52.329404", "10.1109/tvcg.2017.2785271", "10.1007/s11548-013-0820-z", "10.1109/tvcg.2019.2934547", "10.1002/cjp2.113", "10.1080/2162402x.2018.1507600", "10.1109/tvcg.2013.124", "10.1016/s0140-6736(14)60958-2", "10.1038/s41467-017-01689-9", "10.1016/j.cell.2018.07.010", "10.1007/978-3-319-24523-2", "10.1038/nrg3832", "10.2352/j.imagingsci.technol.2017.61.6.060404", "10.1109/tvcg.2018.2864907", "10.1111/cgf.13413", "10.1007/978-3-319-67979-2\\_4", "10.1145/2836034.2836040", "10.1038/nmeth.2563", "10.1101/2020.03.27.001834", "10.1016/0377-0427(87)90125-7", "10.1016/j.immuni.2016.04.014", "10.1002/cyto.a.22702", "10.12688/wellcomeopenres.15191.1", "10.1109/2945.981851", "10.1038/s43018-020-0026-6", "10.1038/s41586-019-1876-x", "10.1109/tvcg.2019.2931299", "10.1109/annes.1995.499469", "10.1145/2133806.2133821", "10.1109/tvcg.2013.161", "10.1007/978-3-319-24523-210", "10.1126/scitranslmed.3004330", "10.1038/nmeth.4391", "10.1111/cgf.14002", "10.1559/152304003100010929", "10.1126/science.280.5363.585", "10.1007/978-3-319-24523-2\\_10", "10.1109/tvcg.2016.2598587", "10.1038/s41597-019-0258-4"], "wos": 1, "children": [], "len": 1}, {"doi": "10.1111/cgf.13698", "year": "2019", "title": "Visual-Interactive Preprocessing of Multivariate Time Series Data", "conferenceName": "EuroVis", "authors": "J{\\\"{u}}rgen Bernard;Marco Hutter;Heiko Reinemuth;Hendrik Pfeifer;Christian Bors;J{\\\"{o}}rn Kohlhammer", "citationCount": "2", "affiliation": "Bernard, J (Corresponding Author), Tech Univ Darmstadt, Darmstadt, Germany.\nBernard, Juergen; Hutter, Marco; Reinemuth, Heiko; Pfeifer, Hendrik, Tech Univ Darmstadt, Darmstadt, Germany.\nBors, Christian, TU Wien, Vienna, Austria.\nKohlhammer, Joern, Fraunhofer IGD, Darmstadt, Germany.", "countries": "Germany;Austria", "abstract": "Pre-processing is a prerequisite to conduct effective and efficient downstream data analysis. Pre-processing pipelines often require multiple routines to address data quality challenges and to bring the data into a usable form. For both the construction and the refinement of pre-processing pipelines, human-in-the-loop approaches are highly beneficial. This particularly applies to multivariate time series, a complex data type with multiple values developing over time. Due to the high specificity of this domain, it has not been subject to in-depth research in visual analytics. We present a visual-interactive approach for preprocessing multivariate time series data with the following aspects. Our approach supports analysts to carry out six core analysis tasks related to pre-processing of multivariate time series. To support these tasks, we identify requirements to baseline toolkits that may help practitioners in their choice. We characterize the space of visualization designs for uncertainty-aware pre-processing and justify our decisions. Two usage scenarios demonstrate applicability of our approach, design choices, and uncertainty visualizations for the six analysis tasks. This work is one step towards strengthening the visual analytics support for data pre-processing in general and for uncertainty-aware pre-processing of multivariate time series in particular.", "keywords": "", "link": "https://doi.org/10.1111/cgf.13698", "refList": ["10.1016/j.engappai.2010.09.007", "10.1109/tvcg.2015.2467591", "10.1111/cgf.13190", "10.1177/1473871611416549", "10.1007/3-7908-1701-5\\_9", "10.1109/icdmw.2009.55", "10.3758/s13423-012-0247-5", "10.1109/pacificvis.2010.5429596", "10.1177/1473871611415994", "10.1117/12.2080001", "10.1145/2379776.2379788", "10.1145/3105971.3105984", "10.1016/j.patcog.2005.01.025", "10.1594/pangaea.150017", "10.1109/tvcg.2013.178", "10.1109/tvcg.2018.2859973", "10.1109/tvcg.2011.195", "10.1145/1126004.1126005", "10.1145/1656274.1656278", "10.1594/pangaea.804156", "10.1594/pangaea.787726", "10.1109/tvcg.2018.2865077", "10.1007/978-1-4471-6497-5\\_1", "10.2312/eurova.20151104", "10.1109/tvcg.2012.285", "10.1023/a:1024988512476", "10.1109/tvcg.2010.225", "10.1109/vast.2015.7347672", "10.1007/s00799-014-0134-y", "10.1109/tvcg.2016.2598495", "10.1109/tvcg.2018.2864907", "10.1007/s40430-018-1079-7", "10.1007/978-3-642-32498-7\\_5", "10.1111/cgf.13237", "10.1109/vast.2009.5332611", "10.1109/tvcg.2015.2467752", "10.1016/j.cviu.2006.08.002", "10.1109/tvcg.2014.2346321", "10.1145/1014052.1014104", "10.1007/978-3-540-71949-6", "10.2312/sca/sca10/001-010", "10.1145/3025453.3025738", "10.2312/eurova.20181112", "10.1109/pacificvis.2018.00034", "10.1007/978-0-85729-079-3\\_8", "10.1109/tvcg.2017.2779501", "10.1109/tvcg.2008.166", "10.1007/s10618-012-0285-7", "10.1109/tvcg.2013.222", "10.1109/tvcg.2018.2864889", "10.1109/tvcg.2016.2598592", "10.1109/vast.2010.5652530", "10.1145/2723372.2731081", "10.1109/tvcg.2018.2864914", "10.1109/infvis.2000.885098", "10.1016/j.neucom.2017.01.105", "10.2352/issn.2470-1173.2017.1.vda-387", "10.1109/tvcg.2015.2467851", "10.1109/tvcg.2016.2598468", "10.1109/tvcg.2016.2603178"], "wos": 1, "children": [{"doi": "10.1109/tvcg.2020.3030364", "title": "Supporting the Problem-Solving Loop: Designing Highly Interactive Optimisation Systems", "year": "2020", "conferenceName": "VAST", "authors": "Jie Liu;Tim Dwyer;Guido Tack;Samuel Gratzl;Kim Marriott", "citationCount": "0", "affiliation": "Liu, J (Corresponding Author), Monash Univ, Clayton, Vic, Australia. Liu, Jie; Dwyer, Tim; Tack, Guido; Gratzl, Samuel; Marriott, Kim, Monash Univ, Clayton, Vic, Australia.", "countries": "Australia", "abstract": "Efficient optimisation algorithms have become important tools for finding high-quality solutions to hard, real-world problems such as production scheduling, timetabling, or vehicle routing. These algorithms are typically \u201cblack boxes\u201d that work on mathematical models of the problem to solve. However, many problems are difficult to fully specify, and require a \u201chuman in the loop\u201d who collaborates with the algorithm by refining the model and guiding the search to produce acceptable solutions. Recently, the Problem-Solving Loop was introduced as a high-level model of such interactive optimisation. Here, we present and evaluate nine recommendations for the design of interactive visualisation tools supporting the Problem-Solving Loop. They range from the choice of visual representation for solutions and constraints to the use of a solution gallery to support exploration of alternate solutions. We first examined the applicability of the recommendations by investigating how well they had been supported in previous interactive optimisation tools. We then evaluated the recommendations in the context of the vehicle routing problem with time windows (VRPTW). To do so we built a sophisticated interactive visual system for solving VRPTW that was informed by the recommendations. Ten participants then used this system to solve a variety of routing problems. We report on participant comments and interaction patterns with the tool. These showed the tool was regarded as highly usable and the results generally supported the usefulness of the underlying recommendations.", "keywords": "Interactive optimisation,Interface design,Usability,Interactive systems and tools,Vehicle routing", "link": "http://dx.doi.org/10.1109/TVCG.2020.3030364", "refList": ["10.1176/appi.ajp.2018.18070881", "10.1006/obhd.1997.2679", "10.1109/vlhcc.2018.8506576", "10.1177/0956797611417632", "10.1177/0956797619830649", "10.1177/0049124115610347", "10.1177/1948550618775108", "10.1145/3313831.3376533", "10.1511/2014.111.460", "10.1145/2858036.2858465", "10.1145/3173574.3173606", "10.1177/1745691616658637", "10.1038/483531a", "10.1145/3173574.3174053", "10.1037/pspp0000186", "10.1016/j.jclinepi.2015.05.029", "10.1126/science.aac4716", "10.1145/985692.985782", "10.1080/02699931.2018.1524747", "10.1073/pnas.1402786111", "10.1145/3290605.3300295", "10.1111/cgf.13698", "10.1145/3290605.3300709", "10.2307/2686111", "10.1214/17-ba1091", "10.1145/1449715.1449732", "10.2139/ssrn.2694998", "10.1145/3313831.3376777", "10.1177/2515245917747646", "10.1145/3290605.3300754", "10.1145/3025453.3025626", "10.1109/tvcg.2014.2346321", "10.1037/gpr0000123", "10.2139/ssrn.2535453", "10.1145/3025453.3025738", "10.1038/533452a", "10.1177/1948550617714584", "10.1007/s11222-013-9416-2", "10.3389/fpsyg.2016.01832", "10.1038/s41562-018-0506-1", "10.1007/s11222-016-9696-4", "10.1177/1367006918763132", "10.1109/tsmc.1981.4308636", "10.1038/nrd3439-c1", "10.1177/0956797617723726", "10.1111/j.1467-8659.2012.03116.x", "10.1146/annurev-psych-122216-011836", "10.1145/3290605.3300432"], "wos": 1, "children": [], "len": 1}], "len": 3}, {"doi": "10.1111/cgf.14002", "year": "2020", "title": "v-plots: Designing Hybrid Charts for the Comparative Analysis of Data Distributions", "conferenceName": "EuroVis", "authors": "Michael Blumenschein;Luka J. Debbeler;Nadine C. Lages;Britta Renner;Daniel A. Keim;Mennatallah El{-}Assady", "citationCount": "0", "affiliation": "Blumenschein, M (Corresponding Author), Univ Konstanz, Constance, Germany.\nBlumenschein, Michael; Debbeler, Luka J.; Lages, Nadine C.; Renner, Britta; Keim, Daniel A.; El-Assady, Mennatallah, Univ Konstanz, Constance, Germany.", "countries": "Germany", "abstract": "Comparing data distributions is a core focus in descriptive statistics, and part of most data analysis processes across disciplines. In particular, comparing distributions entails numerous tasks, ranging from identifying global distribution properties, comparing aggregated statistics (e.g., mean values), to the local inspection of single cases. While various specialized visualizations have been proposed (e.g., box plots, histograms, or violin plots), they are not usually designed to support more than a few tasks, unless they are combined. In this paper, we present the v-plot designer; a technique for authoring custom hybrid charts, combining mirrored bar charts, difference encodings, and violin-style plots. v-plots are customizable and enable the simultaneous comparison of data distributions on global, local, and aggregation levels. Our system design is grounded in an expert survey that compares and evaluates 20 common visualization techniques to derive guidelines for the task-driven selection of appropriate visualizations. This knowledge externalization step allowed us to develop a guiding wizard that can tailor v-plots to individual tasks and particular distribution properties. Finally, we confirm the usefulness of our system design and the userguiding process by measuring the fitness for purpose and applicability in a second study with four domain and statistic experts.", "keywords": "", "link": "https://doi.org/10.1111/cgf.14002", "refList": ["10.2307/2683468", "10.1186/1475-2891-12-1", "10.18637/jss.v028.c01", "10.1109/tvcg.2018.2865158", "10.1007/s00267-011-9692-6", "10.1177/1473871611416549", "10.1016/s0043-1354(98)00138-9", "10.1186/1471-2458-12-556", "10.1201/9781351072304", "10.1002/2014wr016367", "10.1201/9781315140919.2", "10.1111/cgf.12634", "10.1109/tvcg.2017.2744018", "10.1111/j.1467-8659.2009.01677.x", "10.1029/2007gl031764", "10.1145/3025453.3025912", "10.1109/tvcg.2018.2859973", "10.1016/j.scitotenv.2018.06.190", "10.1111/j.1752-1688.2011.00540.x", "10.1201/9781351072304.5", "10.1002/9781118575574", "10.2312/conf/eg2013/stars/039-063", "10.2307/2685478", "10.1109/tvcg.2018.2865240", "10.1177/0013916513515239", "10.1145/3125571.3125585", "10.1109/tvcg.2018.2864907", "10.1201/9781315140919", "10.1109/tvcg.2015.2467752", "10.1111/cgf.12391", "10.1109/tvcg.2015.2467091", "10.1109/tvcg.2018.2864884", "10.1016/j.jhydrol.2005.06.008", "10.2307/2682899", "10.2307/2685133", "10.1001/archpediatrics.2011.83", "10.1109/tvcg.2014.2346298", "10.1016/j.scitotenv.2009.06.031", "10.1109/tvcg.2015.2467191", "10.1016/b978-0-12-079050-0.50020-5", "10.1016/j.csda.2007.11.008", "10.1017/s1368980015003559", "10.1145/2669557.2669572", "10.1016/j.appet.2017.03.039"], "wos": 1, "children": [{"doi": "10.1109/tvcg.2020.3030336", "title": "Visual cohort comparison for spatial single-cell omics-data", "year": "2020", "conferenceName": "VAST", "authors": "Antonios Somarakis;Marieke E. Ijsselsteijn;Sietse J. Luk;Boyd Kenkhuis;Noel F. C. C. de Miranda;Boudewijn P. F. Lelieveldt;Thomas H\u00f6llt", "citationCount": "0", "affiliation": "Hollt, T (Corresponding Author), Delft Univ Technol, Comp Graph \\& Visualizat Grp, Delft, Netherlands. Hollt, T (Corresponding Author), Leiden Univ, Med Ctr, Leiden Computat Biol Ctr, Leiden, Netherlands. Somarakis, Antonios; Lelieveldt, Boudewijn P. F., Leiden Univ, Med Ctr, Dept Radiol, Div Image Proc, Leiden, Netherlands. Ijsselsteijn, Marieke E.; de Miranda, Noel F. C. C., Leiden Univ, Med Ctr, Dept Pathol, Immunogen Grp, Leiden, Netherlands. Luk, Sietse J., Leiden Univ, Med Ctr, Hematol Dept, Leiden, Netherlands. Kenkhuis, Boyd, Leiden Univ, Med Ctr, Human Genet Dept, Leiden, Netherlands. Hollt, Thomas, Delft Univ Technol, Comp Graph \\& Visualizat Grp, Delft, Netherlands. Hollt, Thomas, Leiden Univ, Med Ctr, Leiden Computat Biol Ctr, Leiden, Netherlands.", "countries": "Netherlands", "abstract": "Spatially-resolved omics-data enable researchers to precisely distinguish cell types in tissue and explore their spatial interactions, enabling deep understanding of tissue functionality. To understand what causes or deteriorates a disease and identify related biomarkers, clinical researchers regularly perform large-scale cohort studies, requiring the comparison of such data at cellular level. In such studies, with little a-priori knowledge of what to expect in the data, explorative data analysis is a necessity. Here, we present an interactive visual analysis workflow for the comparison of cohorts of spatially-resolved omics-data. Our workflow allows the comparative analysis of two cohorts based on multiple levels-of-detail, from simple abundance of contained cell types over complex co-localization patterns to individual comparison of complete tissue images. As a result, the workflow enables the identification of cohort-differentiating features, as well as outlier samples at any stage of the workflow. During the development of the workflow, we continuously consulted with domain experts. To show the effectiveness of the workflow, we conducted multiple case studies with domain experts from different application areas and with different data modalities.", "keywords": "Visual analytics,Imaging Mass Cytometry,Vectra,spatially-resolved data,single-cell omics-data,Visual comparison", "link": "http://dx.doi.org/10.1109/TVCG.2020.3030336", "refList": ["10.1038/nmeth.2869", "10.18637/jss.v028.c01", "10.1177/1473871611416549", "10.1016/j.celrep.2020.107523", "10.1602/neurorx.1.2.182", "10.1038/nprot.2014.191", "10.1136/jnnp-2011-300403", "10.1126/sciadv.aax5851", "10.2312/pe.vmv.vmv13.105-112", "10.1038/s43018-020-0031-9", "10.1109/tvcg.2013.213", "10.1093/jnci/92.8.613", "10.1109/52.329404", "10.1109/tvcg.2017.2785271", "10.1007/s11548-013-0820-z", "10.1109/tvcg.2019.2934547", "10.1002/cjp2.113", "10.1080/2162402x.2018.1507600", "10.1109/tvcg.2013.124", "10.1016/s0140-6736(14)60958-2", "10.1038/s41467-017-01689-9", "10.1016/j.cell.2018.07.010", "10.1007/978-3-319-24523-2", "10.1038/nrg3832", "10.2352/j.imagingsci.technol.2017.61.6.060404", "10.1109/tvcg.2018.2864907", "10.1111/cgf.13413", "10.1007/978-3-319-67979-2\\_4", "10.1145/2836034.2836040", "10.1038/nmeth.2563", "10.1101/2020.03.27.001834", "10.1016/0377-0427(87)90125-7", "10.1016/j.immuni.2016.04.014", "10.1002/cyto.a.22702", "10.12688/wellcomeopenres.15191.1", "10.1109/2945.981851", "10.1038/s43018-020-0026-6", "10.1038/s41586-019-1876-x", "10.1109/tvcg.2019.2931299", "10.1109/annes.1995.499469", "10.1145/2133806.2133821", "10.1109/tvcg.2013.161", "10.1007/978-3-319-24523-210", "10.1126/scitranslmed.3004330", "10.1038/nmeth.4391", "10.1111/cgf.14002", "10.1559/152304003100010929", "10.1126/science.280.5363.585", "10.1007/978-3-319-24523-2\\_10", "10.1109/tvcg.2016.2598587", "10.1038/s41597-019-0258-4"], "wos": 1, "children": [], "len": 1}], "len": 3}], "len": 19}, {"doi": "10.1109/tvcg.2018.2865077", "title": "Comparing Similarity Perception in Time Series Visualizations", "year": "2018", "conferenceName": "InfoVis", "authors": "Anna Gogolou;Theophanis Tsandilas;Themis Palpanas;Anastasia Bezerianos", "citationCount": "12", "affiliation": "Gogolouis, A (Corresponding Author), Univ Paris Sud, INRIA, Orsay, France. Gogolouis, A (Corresponding Author), Univ Paris Saclay, Paris, France. Gogolouis, Anna; Tsandilas, Theophanis, Univ Paris Sud, INRIA, Orsay, France. Gogolouis, Anna; Tsandilas, Theophanis; Bezerianos, Anastasia, Univ Paris Saclay, Paris, France. Tsandilas, Theophanis, CNRS, Paris, France. Palpanas, Themis, Univ Paris 05, Paris, France. Bezerianos, Anastasia, Univ Paris Sud, Orsay, France. Bezerianos, Anastasia, INRIA, CNRS, Paris, France.", "countries": "France", "abstract": "A common challenge faced by many domain experts working with time series data is how to identify and compare similar patterns. This operation is fundamental in high-level tasks, such as detecting recurring phenomena or creating clusters of similar temporal sequences. While automatic measures exist to compute time series similarity, human intervention is often required to visually inspect these automatically generated results. The visualization literature has examined similarity perception and its relation to automatic similarity measures for line charts, but has not yet considered if alternative visual representations, such as horizon graphs and colorfields, alter this perception. Motivated by how neuroscientists evaluate epileptiform patterns, we conducted two experiments that study how these three visualization techniques affect similarity perception in EEG signals. We seek to understand if the time series results returned from automatic similarity measures are perceived in a similar manner, irrespective of the visualization technique; and if what people perceive as similar with each visualization aligns with different automatic measures and their similarity constraints. Our findings indicate that horizon graphs align with similarity measures that allow local variations in temporal position or speed (i.e., dynamic time warping) more than the two other techniques. On the other hand, horizon graphs do not align with measures that are insensitive to amplitude and y-offset scaling (i.e., measures based on z-normalization), but the inverse seems to be the case for line charts and colorfields. Overall, our work indicates that the choice of visualization affects what temporal patterns we consider as similar, i.e., the notion of similarity in time series is not visualization independent.", "keywords": "Time series,similarity perception,automatic similarity search,line charts,horizon graphs,colorfields,evaluation", "link": "http://dx.doi.org/10.1109/TVCG.2018.2865077", "refList": ["10.1016/j.engappai.2010.09.007", "10.1109/tvcg.2012.196", "10.1016/j.cag.2007.01.032", "10.1192/bjp.125.4.341", "10.1145/1056808.1057017", "10.1111/epi.13108", "10.1016/j.neulet.2011.03.070", "10.1109/pacificvis.2018.00023", "10.1109/mcg.2012.37", "10.1109/vast.2007.4389007", "10.14778/2824032.2824099", "10.1109/vast.2016.7883518", "10.1145/2470654.2466441", "10.1007/978-0-85729-079-3\\_1", "10.1145/2678025.2701379", "10.1109/tvcg.2011.195", "10.1145/2207676.2208556", "10.1145/3182168", "10.1145/634067.634292", "10.1177/001316448104100307", "10.1093/gerona/glq232", "10.1109/infvis.2005.1532144", "10.1111/j.1535-7511.2006.00145.x", "10.1145/2470654.2466443", "10.1007/s00778-016-0442-5", "10.1097/ede.0b013e3181e5b06a", "10.1016/j.compbiomed.2008.04.010", "10.1016/j.brainresbull.2015.04.007", "10.1109/edssc.2007.4450237", "10.1057/palgrave.ivs.9500061", "10.2307/2289144", "10.1109/tvcg.2008.166", "10.1641/0006-3568(2001)051{[}0341:lndats]2.0.co", "2", "10.1145/2814710.2814719", "10.1109/infvis.2001.963273", "10.1109/tvcg.2011.232", "10.1109/wsc.2003.1261490", "10.1109/tvcg.2010.162", "10.1016/j.jneumeth.2016.02.025", "10.1145/1385569.1385666", "10.1145/2339530.2339576", "10.1007/978-3-319-26633-6\\_13", "10.1001/archneurol.2009.137", "10.1109/infvis.1999.801851", "10.1007/s10618-013-0312-3", "10.1109/vast.2016.7883519", "10.1145/1133265.1133348"], "wos": 1, "children": [{"doi": "10.1109/tvcg.2019.2934784", "title": "A Comparison of Radial and Linear Charts for Visualizing Daily Patterns", "year": "2019", "conferenceName": "InfoVis", "authors": "Manuela Waldner;Alexandra Diehl;Denis Gracanin;Rainer Splechtna;Claudio Delrieux;Kresimir Matkovic", "citationCount": "0", "affiliation": "Waldner, M (Corresponding Author), TU Wien, Vienna, Austria. Waldner, Manuela, TU Wien, Vienna, Austria. Diehl, Alexandra, Univ Zurich, Zurich, Switzerland. Gracanin, Denis, Virginia Tech, Blacksburg, VA USA. Splechtna, Rainer; Matkovic, Kresimir, VRVis Res Ctr, Vienna, Austria. Delrieux, Claudio, Univ Nacl Sur, Elect \\& Comp Eng Dept, Bahia Blanca, Buenos Aires, Argentina.", "countries": "Argentina;Switzerland;USA;Austria", "abstract": "Radial charts are generally considered less effective than linear charts. Perhaps the only exception is in visualizing periodical time-dependent data, which is believed to be naturally supported by the radial layout. It has been demonstrated that the drawbacks of radial charts outweigh the benefits of this natural mapping. Visualization of daily patterns, as a special case, has not been systematically evaluated using radial charts. In contrast to yearly or weekly recurrent trends, the analysis of daily patterns on a radial chart may benefit from our trained skill on reading radial clocks that are ubiquitous in our culture. In a crowd-sourced experiment with 92 non-expert users, we evaluated the accuracy, efficiency, and subjective ratings of radial and linear charts for visualizing daily traffic accident patterns. We systematically compared juxtaposed 12-hours variants and single 24-hours variants for both layouts in four low-level tasks and one high-level interpretation task. Our results show that over all tasks, the most elementary 24-hours linear bar chart is most accurate and efficient and is also preferred by the users. This provides strong evidence for the use of linear layouts \u2013 even for visualizing periodical daily patterns.", "keywords": "Radial charts,time series series data,daily patterns,crowd-sourced experiment", "link": "http://dx.doi.org/10.1109/TVCG.2019.2934784", "refList": ["10.1109/infvis.2000.885091", "10.1109/tvcg.2018.2865158", "10.1177/1473871611406623", "10.1111/cgf.13444", "10.1038/scientificamerican0384-128", "10.1109/tvcg.2018.2865234", "10.1109/tvcg.2015.2467771", "10.1109/tvcg.2018.2865077", "10.1109/tvcg.2013.184", "10.1109/tvcg.2014.2346320", "10.1145/2858036.2858300", "10.1109/tvcg.2017.2674958", "10.1109/iv.2013.12", "10.1145/2470654.2466443", "10.1007/s10763-012-9362-z", "10.1207/s15427625tcq1402\\_3", "10.2307/2288400", "10.1136/jnnp.64.5.588", "10.1109/tvcg.2014.2346426", "10.1109/infvis.1998.729557", "10.1007/bf03217308", "10.1145/506443.506505", "10.1109/infvis.2001.963273", "10.1111/j.1467-8659.2011.01947.x", "10.1109/tvcg.2013.234", "10.1109/38.974517", "10.2312/pe/eurovisshort/eurovisshort2012/097-101", "10.1145/1743546.1743567", "10.1109/tvcg.2010.162", "10.2307/2289447", "10.1145/2110192.2110202", "10.1109/tvcg.2009.23", "10.3102/10769986030004353", "10.1109/tvcg.2010.209"], "wos": 1, "children": [], "len": 1}, {"doi": "10.1109/tvcg.2019.2934655", "title": "Visual Analytics for Electromagnetic Situation Awareness in Radio Monitoring and Management", "year": "2019", "conferenceName": "VAST", "authors": "Ying Zhao;Xiaobo Luo;Xiaoru Lin;Hairong Wang;Xiaoyan Kui;Fangfang Zhou;Jinsong Wang;Yi Chen 0007;Wei Chen", "citationCount": "3", "affiliation": "Kui, XY; Zhou, FF (Corresponding Author), Cent S Univ, Sch Comp Sci \\& Engn, Changsha, Hunan, Peoples R China. Zhao, Ying; Luo, Xiaobo; Lin, Xiaoru; Kui, Xiaoyan; Zhou, Fangfang, Cent S Univ, Sch Comp Sci \\& Engn, Changsha, Hunan, Peoples R China. Wang, Hairong, Cent S Univ, Sch Automat, Changsha, Hunan, Peoples R China. Wang, Jinsong, Southwest Elect \\& Telecom Engn Inst, Shanghai, Peoples R China. Chen, Yi, Beijing Technol \\& Business Univ, Beijing Key Lab Big Data Technol Food Safety, Beijing, Peoples R China. Chen, Wei, Zhejiang Univ, Key Lab CAD \\& CG, Hangzhou, Zhejiang, Peoples R China.", "countries": "China", "abstract": "Traditional radio monitoring and management largely depend on radio spectrum data analysis, which requires considerable domain experience and heavy cognition effort and frequently results in incorrect signal judgment and incomprehensive situation awareness. Faced with increasingly complicated electromagnetic environments, radio supervisors urgently need additional data sources and advanced analytical technologies to enhance their situation awareness ability. This paper introduces a visual analytics approach for electromagnetic situation awareness. Guided by a detailed scenario and requirement analysis, we first propose a signal clustering method to process radio signal data and a situation assessment model to obtain qualitative and quantitative descriptions of the electromagnetic situations. We then design a two-module interface with a set of visualization views and interactions to help radio supervisors perceive and understand the electromagnetic situations by a joint analysis of radio signal data and radio spectrum data. Evaluations on real-world data sets and an interview with actual users demonstrate the effectiveness of our prototype system. Finally, we discuss the limitations of the proposed approach and provide future work directions.", "keywords": "Radio monitoring and management,radio signal data,radio spectrum data,situation awareness,visual analytics", "link": "http://dx.doi.org/10.1109/TVCG.2019.2934655", "refList": ["10.1016/j.newast.2010.07.009", "10.1109/tvcg.2017.2744459", "10.1109/tvcg.2018.2864503", "10.1145/1029208.1029219", "10.1109/pacificvis.2014.54", "10.1109/tvcg.2018.2829750", "10.1016/j.jvlc.2017.11.004", "10.1109/tcyb.2015.2448236", "10.1016/j.patrec.2017.11.011", "10.1109/tvcg.2015.2505305", "10.1109/vast.2014.7042528", "10.1007/s12650-018-0530-2", "10.1109/tvcg.2018.2816203", "10.1109/tmm.2016.2614220", "10.1109/tvcg.2017.2745180", "10.1109/mcg.2018.2879067", "10.1109/tvcg.2018.2859973", "10.1109/tvcg.2016.2598460", "10.1109/infvis.2005.1532134", "10.1109/tvcg.2018.2851227", "10.1155/2012/920671", "10.1109/vast.2014.7042479", "10.1109/tvcg.2013.228", "10.1109/tvcg.2018.2865077", "10.1016/j.csda.2005.10.001", "10.1109/tvcg.2018.2865028", "10.1109/tvcg.2011.239", "10.1145/3173574.3174237", "10.1007/s13042-016-0603-2", "10.1109/tvcg.2018.2865020", "10.1017/s1041610219000024", "10.1109/2945.981848", "10.1109/tvcg.2010.193", "10.1109/tvcg.2018.2802520", "10.1145/3200766", "10.1109/wcncw.2015.7122557", "10.1145/3006299.3006312", "10.1109/icsssm.2007.4280175", "10.1126/science.1242072", "10.1109/tvcg.2017.2744098", "10.1109/tvcg.2015.2467196", "10.1109/tvcg.2016.2598619", "10.1109/tvcg.2016.2598664", "10.1109/tvcg.2013.196", "10.1109/comst.2016.2631080", "10.1109/tvcg.2018.2865029", "10.1007/s10816-016-9307-x", "10.1109/tvcg.2008.166", "10.1109/tvcg.2017.2758362", "10.1109/vizsec.2005.1532072", "10.1518/001872095779049543", "10.1109/tvcg.2007.70415", "10.1016/j.ins.2018.01.013", "10.1109/tvcg.2014.2346911", "10.1109/mim.2013.6616284", "10.1109/jsyst.2014.2358997", "10.1111/cgf.12910", "10.1109/isi.2009.5137305", "10.1109/tvcg.2011.179", "10.1007/s11277-015-2631-8", "10.1111/cgf.12396", "10.1109/tvcg.2013.2297933", "10.1109/tvcg.2014.2346926", "10.1109/tvcg.2014.2346913", "10.1109/pacificvis.2018.00030", "10.1109/tvcg.2014.2346433", "10.1109/tvcg.2016.2614803"], "wos": 1, "children": [{"doi": "10.1109/tvcg.2020.3030443", "title": "CAVA: A Visual Analytics System for Exploratory Columnar Data Augmentation Using Knowledge Graphs", "year": "2020", "conferenceName": "VAST", "authors": "Dylan Cashman;Shenyu Xu;Subhajit Das;Florian Heimerl;Cong Liu;Shah Rukh Humayoun;Michael Gleicher;Alex Endert;Remco Chang", "citationCount": "0", "affiliation": "Cashman, D (Corresponding Author), Tufts Univ, Medford, MA 02155 USA. Cashman, Dylan; Liu, Cong; Chang, Remco, Tufts Univ, Medford, MA 02155 USA. Xu, Shenyu; Das, Subhajit; Endert, Alex, Georgia Tech, Atlanta, GA USA. Heimerl, Florian; Gleicher, Michael, Univ Wisconsin, Madison, WI 53706 USA. Humayoun, Shah Rukh, San Francisco State Univ, San Francisco, CA 94132 USA.", "countries": "USA", "abstract": "Most visual analytics systems assume that all foraging for data happens before the analytics process; once analysis begins, the set of data attributes considered is fixed. Such separation of data construction from analysis precludes iteration that can enable foraging informed by the needs that arise in-situ during the analysis. The separation of the foraging loop from the data analysis tasks can limit the pace and scope of analysis. In this paper, we present CAVA, a system that integrates data curation and data augmentation with the traditional data exploration and analysis tasks, enabling information foraging in-situ during analysis. Identifying attributes to add to the dataset is difficult because it requires human knowledge to determine which available attributes will be helpful for the ensuing analytical tasks. CAVA crawls knowledge graphs to provide users with a a broad set of attributes drawn from external data to choose from. Users can then specify complex operations on knowledge graphs to construct additional attributes. CAVA shows how visual analytics can help users forage for attributes by letting users visually explore the set of available data, and by serving as an interface for query construction. It also provides visualizations of the knowledge graph itself to help users understand complex joins such as multi-hop aggregations. We assess the ability of our system to enable users to perform complex data combinations without programming in a user study over two datasets. We then demonstrate the generalizability of CAVA through two additional usage scenarios. The results of the evaluation confirm that CAVA is effective in helping the user perform data foraging that leads to improved analysis outcomes, and offer evidence in support of integrating data augmentation as a part of the visual analytics pipeline.", "keywords": "Visual Analytics,Information Foraging,Data Augmentation", "link": "http://dx.doi.org/10.1109/TVCG.2020.3030443", "refList": ["10.1057/palgrave.ivs.9500122", "10.1109/tvcg.2016.2598867", "10.1111/cgf.13708", "10.1109/tvcg.2019.2934799", "10.1109/tvcg.2019.2934541", "10.1109/tvcg.2013.65", "10.1109/tvcg.2018.2875702", "10.1109/iv.2004.1320207", "10.1068/p260471", "10.1145/1778765.1778816", "10.1109/tvcg.2018.2808489", "10.1109/tvcg.2018.2864912", "10.1016/j.apgeog.2015.12.006", "10.1111/j.1467-8659.2011.01960.x", "10.1109/tvcg.2018.2864843", "10.1109/pacificvis.2010.5429604", "10.1109/tvcg.2014.2346898", "10.1109/5.726791", "10.1177/1475090214540874", "10.1109/icde.2016.7498287", "10.1145/1556262.1556289", "10.1109/tvcg.2007.70535", "10.1109/vast.2012.6400489", "10.1145/1056808.1056914", "10.1016/j.neucom.2014.09.063", "10.1145/7529.8927", "10.1109/tvcg.2016.2598495", "10.1109/tvcg.2016.2607204", "10.1109/vast47406.2019.8986943", "10.3758/bf03205986", "10.1109/infvis.2005.1532142", "10.1145/1150402.1150479", "10.1109/tvcg.2017.2674978", "10.1109/tvcg.2019.2945960", "10.1109/tvcg.2017.2744098", "10.1109/tvcg.2017.2674999", "10.1109/tvcg.2011.279", "10.1109/tvcg.2014.2346594", "10.1109/tvcg.2017.2744184", "10.1111/cgf.12876", "10.1007/s4095-020-0191-7", "10.1007/s11390-015-1535-0", "10.1111/cgf.12640", "10.1109/tvcg.2016.2598667", "10.1111/cgf.13683", "10.1109/tvcg.2013.153", "10.1109/tvcg.2019.2934208", "10.1109/tvcg.2019.2934655", "10.1111/cgf.12655", "10.1007/s11023-010-9221-z", "10.1109/vast.2012.6400487", "10.1145/2702123.2702585", "10.1007/bf00310175", "10.1109/tvcg.2017.2744378", "10.1103/physreve.64.061907", "10.1109/ldav.2017.8231848", "10.1109/tvcg.2016.2598831"], "wos": 1, "children": [], "len": 1}, {"doi": "10.1109/tvcg.2020.3030432", "title": "Evaluation of Sampling Methods for Scatterplots", "year": "2020", "conferenceName": "VAST", "authors": "Jun Yuan;Shouxing Xiang;Jiazhi Xia;Lingyun Yu;Shixia Liu", "citationCount": "0", "affiliation": "Liu, SX (Corresponding Author), Tsinghua Univ, BNRist, Beijing, Peoples R China. Yuan, Jun; Xiang, Shouxing; Liu, Shixia, Tsinghua Univ, BNRist, Beijing, Peoples R China. Xia, Jiazhi, Cent South Univ, Changsha, Peoples R China. Yu, Lingyun, Xian Jiaotong Liverpool Univ, Suzhou, Peoples R China.", "countries": "China", "abstract": "Given a scatterplot with tens of thousands of points or even more, a natural question is which sampling method should be used to create a small but \u201cgood\u201d scatterplot for a better abstraction. We present the results of a user study that investigates the influence of different sampling strategies on multi-class scatterplots. The main goal of this study is to understand the capability of sampling methods in preserving the density, outliers, and overall shape of a scatterplot. To this end, we comprehensively review the literature and select seven typical sampling strategies as well as eight representative datasets. We then design four experiments to understand the performance of different strategies in maintaining: 1) region density; 2) class density; 3) outliers; and 4) overall shape in the sampling results. The results show that: 1) random sampling is preferred for preserving region density; 2) blue noise sampling and random sampling have comparable performance with the three multi-class sampling strategies in preserving class density; 3) outlier biased density based sampling, recursive subdivision based sampling, and blue noise sampling perform the best in keeping outliers; and 4) blue noise sampling outperforms the others in maintaining the overall shape of a scatterplot.", "keywords": "Scatterplot,data sampling,empirical evaluation", "link": "http://dx.doi.org/10.1109/TVCG.2020.3030432", "refList": ["10.1057/palgrave.ivs.9500122", "10.1109/tvcg.2016.2598867", "10.1109/tvcg.2015.2467591", "10.1111/cgf.13708", "10.1109/tvcg.2019.2934799", "10.1109/tvcg.2019.2934541", "10.1109/tvcg.2013.65", "10.1109/iv.2004.1320207", "10.1068/p260471", "10.1145/1778765.1778816", "10.1109/tvcg.2018.2808489", "10.1109/tvcg.2018.2864912", "10.1016/j.apgeog.2015.12.006", "10.1111/j.1467-8659.2011.01960.x", "10.1109/tvcg.2018.2864843", "10.1109/pacificvis.2010.5429604", "10.1109/tvcg.2014.2346898", "10.1109/5.726791", "10.1177/1475090214540874", "10.1145/1556262.1556289", "10.1109/tvcg.2007.70535", "10.1109/vast.2012.6400489", "10.1145/1056808.1056914", "10.1016/j.neucom.2014.09.063", "10.1145/7529.8927", "10.1109/tvcg.2016.2607204", "10.1109/vast47406.2019.8986943", "10.3758/bf03205986", "10.1109/infvis.2005.1532142", "10.1145/1150402.1150479", "10.1109/tvcg.2017.2674978", "10.1109/tvcg.2017.2744098", "10.1109/tvcg.2017.2674999", "10.1109/tvcg.2011.279", "10.1109/tvcg.2014.2346594", "10.1109/tvcg.2017.2744184", "10.1111/cgf.12876", "10.1109/1011101.2019.2945960", "10.1007/s4095-020-0191-7", "10.1007/s11390-015-1535-0", "10.1111/cgf.12640", "10.1109/tvcg.2016.2598667", "10.1111/cgf.13683", "10.1109/tvcg.2013.153", "10.1109/tvcg.2019.2934208", "10.1109/tvcg.2019.2934655", "10.1111/cgf.12655", "10.1007/s11023-010-9221-z", "10.1109/vast.2012.6400487", "10.1145/2702123.2702585", "10.1007/bf00310175", "10.1109/tvcg.2017.2744378", "10.1103/physreve.64.061907", "10.1109/ldav.2017.8231848", "10.1109/tvcg.2016.2598831"], "wos": 1, "children": [], "len": 1}], "len": 5}, {"doi": "10.1109/tvcg.2020.3030421", "title": "LineSmooth: An Analytical Framework for Evaluating the Effectiveness of Smoothing Techniques on Line Charts", "year": "2020", "conferenceName": "VAST", "authors": "Paul Rosen;Ghulam Jilani Quadri", "citationCount": "0", "affiliation": "Rosen, P (Corresponding Author), Univ S Florida, Tampa, FL 33620 USA. Rosen, Paul; Quadri, Ghulam Jilani, Univ S Florida, Tampa, FL 33620 USA.", "countries": "USA", "abstract": "We present a comprehensive framework for evaluating line chart smoothing methods under a variety of visual analytics tasks. Line charts are commonly used to visualize a series of data samples. When the number of samples is large, or the data are noisy, smoothing can be applied to make the signal more apparent. However, there are a wide variety of smoothing techniques available, and the effectiveness of each depends upon both nature of the data and the visual analytics task at hand. To date, the visualization community lacks a summary work for analyzing and classifying the various smoothing methods available. In this paper, we establish a framework, based on 8 measures of the line smoothing effectiveness tied to 8 low-level visual analytics tasks. We then analyze 12 methods coming from 4 commonly used classes of line chart smoothing-rank filters, convolutional filters, frequency domain filters, and subsampling. The results show that while no method is ideal for all situations, certain methods, such as Gaussian filters and TOPOLOGY-based subsampling, perform well in general. Other methods, such as low-pass CUTOFF filters and Douglas-peucker subsampling, perform well for specific visual analytics tasks. Almost as importantly, our framework demonstrates that several methods, including the commonly used UNIFORM subsampling, produce low-quality results, and should, therefore, be avoided, if possible.", "keywords": "Line chart,data smoothing,time-series", "link": "http://dx.doi.org/10.1109/TVCG.2020.3030421", "refList": ["10.1109/tvcg.2017.2744359", "10.1109/tip.2007.902329", "10.1109/tvcg.2014.2346979", "10.1090/mbk/069", "10.1002/acp.2350030302", "10.1109/tvcg.2018.2829750", "10.1080/03610927708827533", "10.1109/tvcg.2017.2653106", "10.3138/fm57-6770-u75u-7727", "10.2466/pms.104.3.707-721", "10.1016/s0146-664x(72", "10.1002/0471691852", "10.1093/ptj/74.8.768", "10.1016/j.rse.2015.12.023", "10.1145/2207676.2208556", "10.1109/tvcg.2018.2865264", "10.1109/tvcg.2018.2865077", "10.3758/bf03201236", "10.1145/3064175", "10.1145/2858036.2858300", "10.1109/infvis.2005.1532136", "10.1109/infvis.2005.1532144", "10.1021/ac60214a047", "10.1109/tvcg.2015.2467671", "10.1007/s11634-011-0102-y", "10.1109/tvcg.2017.2787113", "10.1002/cta.4490080205", "10.2312/evs.20201053", "10.1109/ncvpripg.2011.34", "10.1145/3025453.3025922", "10.1016/s0146-664x(72)80017-0", "10.1109/tvcg.2018.2864884", "10.1016/0734-189x(83)90054-3", "10.1109/tvcg.2013.234", "10.1109/tvcg.2016.2598592", "10.1109/tvcg.2010.162", "10.1109/jrproc.1949.232969", "10.1119/1.14057", "10.2307/2003354", "10.2312/evs", "10.1109/tvcg.2018.2864914", "10.1109/34.211471", "10.1145/2702123.2702608"], "wos": 1, "children": [], "len": 1}, {"doi": "10.1109/tvcg.2020.3030352", "title": "StackGenVis: Alignment of Data, Algorithms, and Models for Stacking Ensemble Learning Using Performance Metrics", "year": "2020", "conferenceName": "VAST", "authors": "Angelos Chatzimparmpas;Rafael Messias Martins;Kostiantyn Kucher;Andreas Kerren", "citationCount": "0", "affiliation": "Chatzimparmpas, A (Corresponding Author), Linnaeus Univ, Vaxjo, Sweden. Chatzimparmpas, Angelos; Martins, Rafael M.; Kucher, Kostiantyn; Kerren, Andreas, Linnaeus Univ, Vaxjo, Sweden.", "countries": "Sweden", "abstract": "In machine learning (ML), ensemble methods-such as bagging, boosting, and stacking-are widely-established approaches that regularly achieve top-notch predictive performance. Stacking (also called \u201cstacked generalization\u201d) is an ensemble method that combines heterogeneous base models, arranged in at least one layer, and then employs another metamodel to summarize the predictions of those models. Although it may be a highly-effective approach for increasing the predictive performance of ML, generating a stack of models from scratch can be a cumbersome trial-and-error process. This challenge stems from the enormous space of available solutions, with different sets of data instances and features that could be used for training, several algorithms to choose from, and instantiations of these algorithms using diverse parameters (i.e., models) that perform differently according to various metrics. In this work, we present a knowledge generation model, which supports ensemble learning with the use of visualization, and a visual analytics system for stacked generalization. Our system, StackGenVis, assists users in dynamically adapting performance metrics, managing data instances, selecting the most important features for a given data set, choosing a set of top-performant and diverse algorithms, and measuring the predictive performance. In consequence, our proposed tool helps users to decide between distinct models and to reduce the complexity of the resulting stack by removing overpromising and underperforming models. The applicability and effectiveness of StackGenVis are demonstrated with two use cases: a real-world healthcare data set and a collection of data related to sentiment/stance detection in texts. Finally, the tool has been evaluated through interviews with three ML experts.", "keywords": "Stacking,stacked generalization,ensemble learning,visual analytics,visualization", "link": "http://dx.doi.org/10.1109/TVCG.2020.3030352", "refList": ["10.1109/tvcg.2017.2744359", "10.1109/tip.2007.902329", "10.1109/tvcg.2014.2346979", "10.1090/mbk/069", "10.1002/acp.2350030302", "10.1109/tvcg.2018.2829750", "10.1080/03610927708827533", "10.1109/tvcg.2017.2653106", "10.3138/fm57-6770-u75u-7727", "10.2466/pms.104.3.707-721", "10.1002/0471691852", "10.1093/ptj/74.8.768", "10.1016/j.rse.2015.12.023", "10.1145/2207676.2208556", "10.1109/tvcg.2018.2865264", "10.1109/tvcg.2018.2865077", "10.3758/bf03201236", "10.1145/2858036.2858300", "10.1109/infvis.2005.1532136", "10.1109/infvis.2005.1532144", "10.1021/ac60214a047", "10.1109/tvcg.2015.2467671", "10.1007/s11634-011-0102-y", "10.1109/tvcg.2017.2787113", "10.1002/cta.4490080205", "10.2312/evs.20201053", "10.1109/ncvpripg.2011.34", "10.1145/3025453.3025922", "10.1109/tvcg.2018.2864884", "10.1016/0734-189x(83)90054-3", "10.1109/tvcg.2013.234", "10.1109/tvcg.2016.2598592", "10.1109/tvcg.2010.162", "10.1109/jrproc.1949.232969", "10.1119/1.14057", "10.2307/2003354", "10.2312/evs", "10.1109/34.211471", "10.1145/2702123.2702608"], "wos": 1, "children": [], "len": 1}, {"doi": "10.1111/cgf.13698", "year": "2019", "title": "Visual-Interactive Preprocessing of Multivariate Time Series Data", "conferenceName": "EuroVis", "authors": "J{\\\"{u}}rgen Bernard;Marco Hutter;Heiko Reinemuth;Hendrik Pfeifer;Christian Bors;J{\\\"{o}}rn Kohlhammer", "citationCount": "2", "affiliation": "Bernard, J (Corresponding Author), Tech Univ Darmstadt, Darmstadt, Germany.\nBernard, Juergen; Hutter, Marco; Reinemuth, Heiko; Pfeifer, Hendrik, Tech Univ Darmstadt, Darmstadt, Germany.\nBors, Christian, TU Wien, Vienna, Austria.\nKohlhammer, Joern, Fraunhofer IGD, Darmstadt, Germany.", "countries": "Germany;Austria", "abstract": "Pre-processing is a prerequisite to conduct effective and efficient downstream data analysis. Pre-processing pipelines often require multiple routines to address data quality challenges and to bring the data into a usable form. For both the construction and the refinement of pre-processing pipelines, human-in-the-loop approaches are highly beneficial. This particularly applies to multivariate time series, a complex data type with multiple values developing over time. Due to the high specificity of this domain, it has not been subject to in-depth research in visual analytics. We present a visual-interactive approach for preprocessing multivariate time series data with the following aspects. Our approach supports analysts to carry out six core analysis tasks related to pre-processing of multivariate time series. To support these tasks, we identify requirements to baseline toolkits that may help practitioners in their choice. We characterize the space of visualization designs for uncertainty-aware pre-processing and justify our decisions. Two usage scenarios demonstrate applicability of our approach, design choices, and uncertainty visualizations for the six analysis tasks. This work is one step towards strengthening the visual analytics support for data pre-processing in general and for uncertainty-aware pre-processing of multivariate time series in particular.", "keywords": "", "link": "https://doi.org/10.1111/cgf.13698", "refList": ["10.1016/j.engappai.2010.09.007", "10.1109/tvcg.2015.2467591", "10.1111/cgf.13190", "10.1177/1473871611416549", "10.1007/3-7908-1701-5\\_9", "10.1109/icdmw.2009.55", "10.3758/s13423-012-0247-5", "10.1109/pacificvis.2010.5429596", "10.1177/1473871611415994", "10.1117/12.2080001", "10.1145/2379776.2379788", "10.1145/3105971.3105984", "10.1016/j.patcog.2005.01.025", "10.1594/pangaea.150017", "10.1109/tvcg.2013.178", "10.1109/tvcg.2018.2859973", "10.1109/tvcg.2011.195", "10.1145/1126004.1126005", "10.1145/1656274.1656278", "10.1594/pangaea.804156", "10.1594/pangaea.787726", "10.1109/tvcg.2018.2865077", "10.1007/978-1-4471-6497-5\\_1", "10.2312/eurova.20151104", "10.1109/tvcg.2012.285", "10.1023/a:1024988512476", "10.1109/tvcg.2010.225", "10.1109/vast.2015.7347672", "10.1007/s00799-014-0134-y", "10.1109/tvcg.2016.2598495", "10.1109/tvcg.2018.2864907", "10.1007/s40430-018-1079-7", "10.1007/978-3-642-32498-7\\_5", "10.1111/cgf.13237", "10.1109/vast.2009.5332611", "10.1109/tvcg.2015.2467752", "10.1016/j.cviu.2006.08.002", "10.1109/tvcg.2014.2346321", "10.1145/1014052.1014104", "10.1007/978-3-540-71949-6", "10.2312/sca/sca10/001-010", "10.1145/3025453.3025738", "10.2312/eurova.20181112", "10.1109/pacificvis.2018.00034", "10.1007/978-0-85729-079-3\\_8", "10.1109/tvcg.2017.2779501", "10.1109/tvcg.2008.166", "10.1007/s10618-012-0285-7", "10.1109/tvcg.2013.222", "10.1109/tvcg.2018.2864889", "10.1109/tvcg.2016.2598592", "10.1109/vast.2010.5652530", "10.1145/2723372.2731081", "10.1109/tvcg.2018.2864914", "10.1109/infvis.2000.885098", "10.1016/j.neucom.2017.01.105", "10.2352/issn.2470-1173.2017.1.vda-387", "10.1109/tvcg.2015.2467851", "10.1109/tvcg.2016.2598468", "10.1109/tvcg.2016.2603178"], "wos": 1, "children": [{"doi": "10.1109/tvcg.2020.3030364", "title": "Supporting the Problem-Solving Loop: Designing Highly Interactive Optimisation Systems", "year": "2020", "conferenceName": "VAST", "authors": "Jie Liu;Tim Dwyer;Guido Tack;Samuel Gratzl;Kim Marriott", "citationCount": "0", "affiliation": "Liu, J (Corresponding Author), Monash Univ, Clayton, Vic, Australia. Liu, Jie; Dwyer, Tim; Tack, Guido; Gratzl, Samuel; Marriott, Kim, Monash Univ, Clayton, Vic, Australia.", "countries": "Australia", "abstract": "Efficient optimisation algorithms have become important tools for finding high-quality solutions to hard, real-world problems such as production scheduling, timetabling, or vehicle routing. These algorithms are typically \u201cblack boxes\u201d that work on mathematical models of the problem to solve. However, many problems are difficult to fully specify, and require a \u201chuman in the loop\u201d who collaborates with the algorithm by refining the model and guiding the search to produce acceptable solutions. Recently, the Problem-Solving Loop was introduced as a high-level model of such interactive optimisation. Here, we present and evaluate nine recommendations for the design of interactive visualisation tools supporting the Problem-Solving Loop. They range from the choice of visual representation for solutions and constraints to the use of a solution gallery to support exploration of alternate solutions. We first examined the applicability of the recommendations by investigating how well they had been supported in previous interactive optimisation tools. We then evaluated the recommendations in the context of the vehicle routing problem with time windows (VRPTW). To do so we built a sophisticated interactive visual system for solving VRPTW that was informed by the recommendations. Ten participants then used this system to solve a variety of routing problems. We report on participant comments and interaction patterns with the tool. These showed the tool was regarded as highly usable and the results generally supported the usefulness of the underlying recommendations.", "keywords": "Interactive optimisation,Interface design,Usability,Interactive systems and tools,Vehicle routing", "link": "http://dx.doi.org/10.1109/TVCG.2020.3030364", "refList": ["10.1176/appi.ajp.2018.18070881", "10.1006/obhd.1997.2679", "10.1109/vlhcc.2018.8506576", "10.1177/0956797611417632", "10.1177/0956797619830649", "10.1177/0049124115610347", "10.1177/1948550618775108", "10.1145/3313831.3376533", "10.1511/2014.111.460", "10.1145/2858036.2858465", "10.1145/3173574.3173606", "10.1177/1745691616658637", "10.1038/483531a", "10.1145/3173574.3174053", "10.1037/pspp0000186", "10.1016/j.jclinepi.2015.05.029", "10.1126/science.aac4716", "10.1145/985692.985782", "10.1080/02699931.2018.1524747", "10.1073/pnas.1402786111", "10.1145/3290605.3300295", "10.1111/cgf.13698", "10.1145/3290605.3300709", "10.2307/2686111", "10.1214/17-ba1091", "10.1145/1449715.1449732", "10.2139/ssrn.2694998", "10.1145/3313831.3376777", "10.1177/2515245917747646", "10.1145/3290605.3300754", "10.1145/3025453.3025626", "10.1109/tvcg.2014.2346321", "10.1037/gpr0000123", "10.2139/ssrn.2535453", "10.1145/3025453.3025738", "10.1038/533452a", "10.1177/1948550617714584", "10.1007/s11222-013-9416-2", "10.3389/fpsyg.2016.01832", "10.1038/s41562-018-0506-1", "10.1007/s11222-016-9696-4", "10.1177/1367006918763132", "10.1109/tsmc.1981.4308636", "10.1038/nrd3439-c1", "10.1177/0956797617723726", "10.1111/j.1467-8659.2012.03116.x", "10.1146/annurev-psych-122216-011836", "10.1145/3290605.3300432"], "wos": 1, "children": [], "len": 1}], "len": 3}], "len": 17}, {"doi": "10.1109/tvcg.2019.2934666", "title": "You can't always sketch what you want: Understanding Sensemaking in Visual Query Systems", "year": "2019", "conferenceName": "VAST", "authors": "Doris Jung Lin Lee;John Lee 0005;Tarique Siddiqui;Jaewoo Kim;Karrie Karahalios;Aditya G. Parameswaran", "citationCount": "0", "affiliation": "Lee, DJL (Corresponding Author), Univ Calif Berkeley, Berkeley, CA 94720 USA. Lee, Doris Jung-Lin; Parameswaran, Aditya, Univ Calif Berkeley, Berkeley, CA 94720 USA. Lee, John; Siddiqui, Tarique; Kim, Jaewoo; Karahalios, Karrie, Univ Illinois, Urbana, IL 61801 USA.", "countries": "USA", "abstract": "Visual query systems (VQSs) empower users to interactively search for line charts with desired visual patterns, typically specified using intuitive sketch-based interfaces. Despite decades of past work on VQSs, these efforts have not translated to adoption in practice, possibly because VQSs are largely evaluated in unrealistic lab-based settings. To remedy this gap in adoption, we collaborated with experts from three diverse domains\u2014astronomy, genetics, and material science\u2014via a year-long user-centered design process to develop a VQS that supports their workflow and analytical needs, and evaluate how VQSs can be used in practice. Our study results reveal that ad-hoc sketch-only querying is not as commonly used as prior work suggests, since analysts are often unable to precisely express their patterns of interest. In addition, we characterize three essential sensemaking processes supported by our enhanced VQS. We discover that participants employ all three processes, but in different proportions, depending on the analytical needs in each domain. Our findings suggest that all three sensemaking processes must be integrated in order to make future VQSs useful for a wide range of analytical inquiries.", "keywords": "Visual analytics,exploratory analysis,visual queries", "link": "http://dx.doi.org/10.1109/TVCG.2019.2934666", "refList": ["10.1145/937549.937550", "10.1145/1056808.1057017", "10.1145/800045.801579", "10.1145/2818048.2819988", "10.1145/2940299.2940303", "10.1109/52.329404", "10.1145/2678025.2701379", "10.1145/2207676.2207738", "10.1145/3301275.3302307", "10.1145/634067.634292", "10.1145/3173574.3173962", "10.1109/infvis.2005.1532136", "10.1109/vast.2008.4677353", "10.1038/s41598-017-06110-5", "10.1007/s41061-018-0188-1", "10.1109/tvcg.2017.2743990", "10.1109/tvcg.2011.279", "10.1145/259963.260531", "10.1145/1377966.1377971", "10.1177/1473871616638546", "10.1057/palgrave.ivs.9500061", "10.1145/1168149.1168158", "10.1007/3-540-45650-338", "10.1145/2818048.2819967", "10.1145/2133416.2146416", "10.1109/mcg.2006.70", "10.1093/nar/gkw446", "10.1109/tvcg.2012.213", "10.1145/1377966.1377974", "10.3847/1538-4365/aab4f5", "10.1145/989863.989880", "10.1109/vast.2016.7883519"], "wos": 1, "children": [], "len": 1}, {"doi": "10.1111/cgf.13971", "year": "2020", "title": "Peax : Interactive Visual Pattern Search in Sequential Data Using Unsupervised Deep Representation Learning", "conferenceName": "EuroVis", "authors": "Fritz Lekschas;Brant Peterson;Daniel Haehn;Eric Ma;Nils Gehlenborg;Hanspeter Pfister", "citationCount": "0", "affiliation": "Lekschas, F (Corresponding Author), Harvard Sch Engn \\& Appl Sci, Cambridge, MA 02138 USA.\nLekschas, Fritz; Haehn, Daniel; Pfister, Hanspeter, Harvard Sch Engn \\& Appl Sci, Cambridge, MA 02138 USA.\nPeterson, Brant; Ma, Eric, Novartis Inst BioMed Res, Cambridge, MA USA.\nGehlenborg, Nils, Harvard Med Sch, Boston, MA 02115 USA.\nHaehn, Daniel, Univ Massachusetts, Boston, MA 02125 USA.", "countries": "USA", "abstract": "We present PEAX, a novel feature-based technique for interactive visual pattern search in sequential data, like time series or data mapped to a genome sequence. Visually searching for patterns by similarity is often challenging because of the large search space, the visual complexity of patterns, and the user's perception of similarity. For example, in genomics, researchers try to link patterns in multivariate sequential data to cellular or pathogenic processes, but a lack of ground truth and high variance makes automatic pattern detection unreliable. We have developed a convolutional autoencoder for unsupervised representation learning of regions in sequential data that can capture more visual details of complex patterns compared to existing similarity measures. Using this learned representation as features of the sequential data, our accompanying visual query system enables interactive feedback-driven adjustments of the pattern search to adapt to the users' perceived similarity. Using an active learning sampling strategy, PEAX collects user-generated binary relevance feedback. This feedback is used to train a model for binary classification, to ultimately find other regions that exhibit patterns similar to the search target. We demonstrate PEAX's features through a case study in genomics and report on a user study with eight domain experts to assess the usability and usefulness of PEAX. Moreover, we evaluate the effectiveness of the learned feature representation for visual similarity search in two additional user studies. We find that our models retrieve significantly more similar patterns than other commonly used techniques.", "keywords": "", "link": "https://doi.org/10.1111/cgf.13971", "refList": ["10.1007/s10618-015-0418-x", "10.1038/nrg.2015.17", "10.1145/1056808.1057017", "10.1145/312624.312676", "10.1145/1882471.1882478", "10.1126/science.1181369", "10.1109/tkde.2014.2316504", "10.1109/mcse.2007.53", "10.1016/b978-155860915-0/50039-1", "10.1093/nar/gky753", "10.1007/pl00011669", "10.1016/j.cell.2008.03.029", "10.1109/vast.2014.7042480", "10.1016/j.neucom.2018.03.067", "10.1145/2678025.2701379", "10.1109/isbi.2017.7950530", "10.5281/zenodo.2609763", "10.1145/634067.634292", "10.1007/s10618-007-0064-z", "10.1126/science.1222794", "10.1016/j.cell.2007.05.009", "10.1098/rsif.2013.0048", "10.1146/annurev-genom-082509-141651", "10.1007/s10618-012-0250-5", "10.1101/gr.4074106", "10.1057/palgrave.ivs.9500061", "10.1007/978-3-642-21735-7\\_7", "10.1101/gr.136127.111", "10.1109/bigcom.2017.13", "10.1038/nmeth.4325", "10.1037/a0032397", "10.1186/s12864-017-4226-0", "10.1038/nature11247", "10.1038/nature23884", "10.1186/s13059-018-1486-1", "10.1109/tpami.2013.50", "10.1117/12.587537", "10.1038/srep26094", "10.1038/nbt1010-1045", "10.1109/vast.2016.7883519"], "wos": 1, "children": [], "len": 1}, {"doi": "10.1111/cgf.14035", "year": "2020", "title": "Survey on the Analysis of User Interactions and Visualization Provenance", "conferenceName": "EuroVis", "authors": "Kai Xu;Alvitta Ottley;Conny Walchshofer;Marc Streit;Remco Chang;John E. Wenskovitch", "citationCount": "0", "affiliation": "Xu, K (Corresponding Author), Middlesex Univ, London, England.\nXu, Kai, Middlesex Univ, London, England.\nOttley, Alvitta, Washington Univ, St Louis, MO 63110 USA.\nWalchshofer, Conny; Streit, Marc, Johannes Kepler Univ Linz, Linz, Austria.\nChang, Remco, Tufts Univ, Medford, MA 02155 USA.\nWenskovitch, John, Virginia Tech, Blacksburg, VA USA.", "countries": "USA;England;Austria", "abstract": "There is fast-growing literature on provenance-related research, covering aspects such as its theoretical framework, use cases, and techniques for capturing, visualizing, and analyzing provenance data. As a result, there is an increasing need to identify and taxonomize the existing scholarship. Such an organization of the research landscape will provide a complete picture of the current state of inquiry and identify knowledge gaps or possible avenues for further investigation. In this STAR, we aim to produce a comprehensive survey of work in the data visualization and visual analytics field that focus on the analysis of user interaction and provenance data. We structure our survey around three primary questions: (1) WHY analyze provenance data, (2) WHAT provenance data to encode and how to encode it, and (3) HOW to analyze provenance data. A concluding discussion provides evidence-based guidelines and highlights concrete opportunities for future development in this emerging area. The survey and papers discussed can be explored online interactively at https://provenance-survey.caleydo.org.", "keywords": "", "link": "https://doi.org/10.1111/cgf.14035", "refList": ["10.1145/3186266", "10.1145/3185524", "10.1109/tvcg.2014.2346575", "10.1109/tvcg.2016.2598471", "10.1109/tvcg.2016.2598446", "10.1145/2856767.2856779", "10.1109/tvcg.2017.2745278", "10.1109/tvcg.2015.2467871", "10.1109/tvcg.2019.2934668", "10.1145/3301275.3302307", "10.1145/2207676.2208293", "10.1111/cgf.13402", "10.1111/cgf.12895", "10.1145/1084805.1084812", "10.1145/2983923", "10.1007/978-1-4419-5874-7\\_12", "10.1109/mcg.2010.18", "10.1109/tvcg.2015.2467153", "10.1109/tvcg.2013.211", "10.1145/3172944.3172964", "10.1145/3290605.3300360", "10.1109/tvcg.2009.199", "10.1109/vast.2016.7883515", "10.1145/2207676.2208412", "10.1145/1979742.1979570", "10.1145/2207676.2208565", "10.1109/tvcg.2017.2745078", "10.1109/tvcg.2013.226", "10.1145/3301275.3302270", "10.1145/2882903.2882919", "10.1109/tvcg.2013.132", "10.1007/978-1-4614-3223-4\\_6", "10.1007/978-1-4899-7993-3\\_80747-1", "10.1145/2449396.2449439", "10.4230/dagrep.8.11.35", "10.1111/cgf.13424", "10.1109/tvcg.2015.2467613", "10.1109/mcse.2007.106", "10.1109/vast.2014.7042486", "10.1145/3126594.3126653", "10.1145/2591510", "10.1109/vast.2017.8585665", "10.1109/tvcg.2017.2744684", "10.1109/vast.2009.5333564", "10.1111/cgf.12631", "10.1145/2702123.2702262", "10.1111/cgf.13717", "10.2312/evs.20191181", "10.1111/cgf.12925", "10.1145/2702123.2702590", "10.1109/tvcg.2015.2467551", "10.1145/3025171.3025187", "10.1145/3316416.3316418", "10.1109/tvcg.2015.2468078", "10.1109/mcg.2014.73", "10.1109/tvcg.2017.2744479", "10.1109/tvcg.2018.2859969", "10.1109/tvcg.2014.2346321", "10.1109/tvcg.2007.70589", "10.1007/s13218-012-0167-6", "10.1111/cgf.13670", "10.1145/2807442.2807478", "10.1111/cgf.13715", "10.1109/tvcg.2012.23", "10.1109/tvcg.2017.2745279", "10.1109/tvcg.2013.164", "10.1109/vast.2008.4677365", "10.1145/3301275.3302291", "10.1109/tvcg.2012.260", "10.1109/tvcg.2010.177", "10.1109/tvcg.2018.2865024", "10.1109/mcg.2015.51", "10.1145/2240236.2240260", "10.1109/tvcg.2016.2599030.2", "10.1109/tvcg.2007.70515", "10.1109/tvcg.2012.175", "10.1109/mcg.2019.2941856", "10.1109/tvcg.2008.137", "10.1016/j.visinf.2018.09.003", "10.4304/jmm.9.5.635-643", "10.1109/tvcg.2017.2744843", "10.1111/cgf.13405", "10.1145/2633043", "10.1109/tvcg.2009.129", "10.1109/tvcg.2019.2934609", "10.1111/cgf.12924", "10.1145/2702123.2702376", "10.1109/vast.2017.8585669", "10.1145/1502650.1502695", "10.1111/cgf.13730", "10.1109/tvcg.2013.124", "10.1109/tvcg.2017.2744805", "10.1109/mcg.2009.49", "10.1109/vast.2015.7347625", "10.1145/3009973", "10.1145/2470654.2470723", "10.1109/vast.2016.7883520", "10.1109/vast.2014.7042492", "10.1145/2984511.2984588", "10.1111/cgf.12391", "10.1561/1900000006", "10.1007/s00778-017-0486-1", "10.1109/vast.2009.5333020", "10.1145/1926385.1926423", "10.1145/1057977.1057978", "10.1145/3290605.3300892", "10.1111/j.1467-8659.2011.01928.x", "10.1109/tvcg.2013.188", "10.1109/tvcg.2015.2467191", "10.1109/iccicct.2014.6993023", "10.1145/3290605.3300874", "10.1145/2557500.2557524", "10.1109/mcg.2015.91", "10.1109/vast.2012.6400494", "10.1109/tvcg.2013.220", "10.1109/mcg.2019.2945378", "10.1109/vast.2012.6400486", "10.1109/tvcg.2018.2865158", "10.1109/tvcg.2016.2598839", "10.1145/1142473.1142574", "10.1177/1555343416672782", "10.1109/vast.2011.6102449", "10.1111/cgf.12090", "10.1109/vast.2016.7883518", "10.1111/cgf.13678", "10.1109/mcg.2009.53", "10.1109/tvcg.2014.2346250", "10.1109/tvcg.2016.2598797", "10.1111/cgf.13400", "10.1109/tvcg.2014.2346573", "10.1080/01431160600746456", "10.1145/2642918.2647378", "10.1109/mcg.2019.2945720", "10.1145/2207676.2207741", "10.1145/3025171.3025189", "10.1145/634067.634292", "10.1109/tvcg.2015.2467611", "10.1109/tit.1982.1056489", "10.1109/tvcg.2018.2865117", "10.1109/vast.2009.5333023", "10.1145/3332165.3347866", "10.1109/mcg.2019.2933419", "10.1145/3184900", "10.1109/tvcg.2012.273", "10.1109/vast.2010.5652885", "10.1109/vast.2015.7347627", "10.1145/3290605.3300803", "10.1109/tvcg.2012.258", "10.1109/mcg.2009.87", "10.1109/tvcg.2019.2934556", "10.1145/1869397.1869399", "10.1109/mcg.2015.50", "10.1145/3172944.3172979", "10.1111/cgf.13208", "10.1111/cgf.12619", "10.1145/3290605.3300358", "10.1109/vast.2008.4677352", "10.1109/tvcg.2016.2598468", "10.1109/vast.2016.7883519", "10.1109/mcse.2008.79"], "wos": 1, "children": [], "len": 1}], "len": 45}, "index": 1185, "embedding": [1.5491793155670166, 2.328674554824829, -1.0662840604782104, -2.350348949432373, -0.26877492666244507, 0.16650904715061188, -0.7643030881881714, -0.9931802153587341, 0.6868146657943726, -0.9009531736373901, 1.099535346031189, 1.573786973953247, 1.073819875717163, 1.0642783641815186, 1.4143037796020508, 3.0381555557250977, 3.916816473007202, 0.06589167565107346, 1.4764549732208252, 3.6614601612091064, -0.06630208343267441, -0.6124352812767029, 1.811478853225708, 3.1794803142547607, -2.343374252319336, 1.1750550270080566, -0.5536867380142212, 3.430879592895508, 1.1354130506515503, -1.4448509216308594, 2.6199285984039307, 2.0816330909729004], "projection": [0.39476191997528076, 9.19567584991455], "size": 23, "height": 4, "width": 12}