{"data": {"doi": "10.1109/tvcg.2018.2864839", "title": "Time-Dependent Flow seen through Approximate Observer Killing Fields", "year": "2018", "conferenceName": "SciVis", "authors": "Markus Hadwiger;Matej Mlejnek;Thomas Theu\u00dfl;Peter Rautek", "citationCount": "5", "affiliation": "Hadwiger, M (Corresponding Author), KAUST, Visual Comp Ctr, Thuwal 239556900, Saudi Arabia. Hadwiger, Markus; Mlejnek, Matej; Rautek, Peter, KAUST, Visual Comp Ctr, Thuwal 239556900, Saudi Arabia. Theussl, Thomas, KAUST, Core Labs, Thuwal 239556900, Saudi Arabia.", "countries": "Arabia", "abstract": "Flow fields are usually visualized relative to a global observer, i.e., a single frame of reference. However, often no global frame can depict all flow features equally well. Likewise, objective criteria for detecting features such as vortices often use either a global reference frame, or compute a separate frame for each point in space and time. We propose the first general framework that enables choosing a smooth trade-off between these two extremes. Using global optimization to minimize specific differential geometric properties, we compute a time-dependent observer velocity field that describes the motion of a continuous field of observers adapted to the input flow. This requires developing the novel notion of an observed time derivative. While individual observers are restricted to rigid motions, overall we compute an approximate Killing field, corresponding to almost-rigid motion. This enables continuous transitions between different observers. Instead of focusing only on flow features, we furthermore develop a novel general notion of visualizing how all observers jointly perceive the input field. This in fact requires introducing the concept of an observation time, with respect to which a visualization is computed. We develop the corresponding notions of observed stream, path, streak, and time lines. For efficiency, these characteristic curves can be computed using standard approaches, by first transforming the input field accordingly. Finally, we prove that the input flow perceived by the observer field is objective. This makes derived flow features, such as vortices, objective as well.", "keywords": "Flow visualization,observer frames of reference,Killing vector fields,infinitesimal isometries,Lie derivatives,objectivity", "link": "http://dx.doi.org/10.1109/TVCG.2018.2864839", "refList": ["10.1111/cgf.12358", "10.1111/j.1467-8659.2012.03063.x", "10.1109/embc.2013.6610171", "10.1111/cgf.13319", "10.1145/1239451.1239515", "10.1109/visual.1997.663898", "10.1017/jfm.2016.151", "10.1145/2723158", "10.1111/j.1467-8659.2010.01779.x", "10.1109/visual.1999.809896", "10.1111/cgf.12174", "10.1109/tvcg.2015.2467200", "10.1145/3072959.3073684", "10.1109/tvcg.2008.163", "10.1145/1276377.1276457", "10.1109/tvcg.2002.1021575", "10.1017/s0022112004002526", "10.1109/pacificvis.2016.7465253", "10.1109/tvcg.2010.198", "10.1111/j.1467-8659.2011.02028.x", "10.1145/1073204.1073323", "10.1111/cgf.12427", "10.1109/tvcg.2007.70545", "10.1109/tvcg.2012.316", "10.1017/s0022112095000462", "10.1109/tvcg.2007.70557", "10.1109/tvcg.2014.2312012"], "wos": 1, "children": [{"doi": "10.1109/tvcg.2019.2934375", "title": "Vector Field Topology of Time-Dependent Flows in a Steady Reference Frame", "year": "2019", "conferenceName": "SciVis", "authors": "Irene Baeza Rojo;Tobias G\u00fcnther", "citationCount": "2", "affiliation": "Rojo, IB (Corresponding Author), Swiss Fed Inst Technol, Comp Graph Lab, Zurich, Switzerland. Rojo, Irene Baeza; Guenther, Tobias, Swiss Fed Inst Technol, Comp Graph Lab, Zurich, Switzerland.", "countries": "Switzerland", "abstract": "The topological analysis of unsteady vector fields remains to this day one of the largest challenges in flow visualization. We build up on recent work on vortex extraction to define a time-dependent vector field topology for 2D and 3D flows. In our work, we split the vector field into two components: a vector field in which the flow becomes steady, and the remaining ambient flow that describes the motion of topological elements (such as sinks, sources and saddles) and feature curves (vortex corelines and bifurcation lines). To this end, we expand on recent local optimization approaches by modeling spatially-varying deformations through displacement transformations from continuum mechanics. We compare and discuss the relationships with existing local and integration-based topology extraction methods, showing for instance that separatrices seeded from saddles in the optimal frame align with the integration-based streakline vector field topology. In contrast to the streakline-based approach, our method gives a complete picture of the topology for every time slice, including the steps near the temporal domain boundaries. With our work it now becomes possible to extract topological information even when only few time slices are available. We demonstrate the method in several analytical and numerically-simulated flows and discuss practical aspects, limitations and opportunities for future work.", "keywords": "Scientific visualization,unsteady flow,vector field topology,reference frame optimization", "link": "http://dx.doi.org/10.1109/TVCG.2019.2934375", "refList": ["10.1016/0377-0257(79)87004-4", "10.1111/cgf.12358", "10.1111/j.1467-8659.2009.01546.x", "10.1109/2.35197", "10.1002/qj.2947", "10.1007/978-3-540-70823-0\\_1", "10.1111/cgf.13319", "10.1016/j.physd.2010.11.010", "10.1109/pacificvis.2012.6183582", "10.1017/jfm.2016.151", "10.1109/38.79452", "10.1111/j.1467-8659.2011.01901.x", "10.1016/j.physd.2005.10.007", "10.1109/tvcg.2018.2864813", "10.1109/visual.1999.809896", "10.1146/annurev.fluid.23.1.601", "10.1109/tvcg.2015.2467200", "10.1109/tvcg.2007.1036", "10.1109/tvcg.2018.2864839", "10.1109/2945.694953", "10.1109/tvcg.2012.131", "10.1111/cgf.12933", "10.1111/j.1467-8659.2009.01686.x", "10.1145/3072959.3073684", "10.1109/visual.2000.885716", "10.1016/s0167-2789(00)00199-8", "10.1063/1.166479", "10.1109/visual.1991.175773", "10.1016/0960-0779(94)90137-6", "10.1109/tvcg.2007.70557", "10.1017/s0022112004002526", "10.1109/tvcg.2010.93", "10.1109/pacificvis.2016.7465253", "10.1111/j.1467-8659.2011.01925.x", "10.1109/visual.2004.99", "10.1007/bf00849110", "10.1109/visual.1999.809907", "10.1007/bf00198434", "10.1109/tvcg.2007.70545", "10.1146/annurev-fluid-010313-141322", "10.1109/visual.1998.745296", "10.1109/2945.928168", "10.1007/s00791-011-0152-x", "10.2312/vissym/vissymo4/183-192"], "wos": 1, "children": [{"doi": "10.1111/cgf.14037", "year": "2020", "title": "State of the Art in Time-Dependent Flow Topology: Interpreting Physical Meaningfulness Through Mathematical Properties", "conferenceName": "EuroVis", "authors": "Roxana Bujack;Lin Yan;Ingrid Hotz;Christoph Garth;Bei Wang", "citationCount": "0", "affiliation": "Bujack, R (Corresponding Author), Los Alamos Natl Lab, Los Alamos, NM 87545 USA.\nBujack, Roxana, Los Alamos Natl Lab, Los Alamos, NM 87545 USA.\nYan, Lin; Wang, Bei, Univ Utah, Sci Comp \\& Imaging Inst, Salt Lake City, UT 84112 USA.\nHotz, Ingrid, Linkopings Univ, Sci Visualizat Grp, Linkoping, Sweden.\nGarth, Christoph, Univ Kaiserslautern, Kaiserslautern, Germany.", "countries": "Sweden;Germany;USA", "abstract": "We present a state-of-the-art report on time-dependent flow topology. We survey representative papers in visualization and provide a taxonomy of existing approaches that generalize flow topology from time-independent to time-dependent settings. The approaches are classified based upon four categories: tracking of steady topology, reference frame adaption, pathline classification or clustering, and generalization of critical points. Our unique contributions include introducing a set of desirable mathematical properties to interpret physical meaningfulness for time-dependent flow visualization, inferring mathematical properties associated with selective research papers, and utilizing such properties for classification. The five most important properties identified in the existing literature include coincidence with the steady case, induction of a partition within the domain, Lagrangian invariance, objectivity, and Galilean invariance.", "keywords": "", "link": "https://doi.org/10.1111/cgf.14037", "refList": ["10.2514/6.1995-1715", "10.1111/cgf.12100", "10.1007/978-3-540-70823-0\\_1", "10.1111/cgf.12885", "10.1063/1.857730", "10.1109/tvcg.2019.2934312", "10.1109/tvcg.2013.92", "10.1063/1.166399", "10.1109/tvcg.2005.68.3", "10.1063/1.4971788", "10.1111/cgf.12933", "10.1145/3072959.3073684", "10.1063/1.4982720", "10.1109/tvcg.2018.2864432", "10.1017/s0022112004002526", "10.1109/tvcg.2010.93", "10.1109/pacificvis.2016.7465253", "10.1109/tvcg.2018.2864505", "10.1063/1.858828", "10.1109/tvcg.2019.2934255", "10.5194/npg-9-237-2002", "10.1063/1.4800210", "10.1007/978-3-540-88606-8\\_12", "10.1111/j.1467-8659.2011.01942.x", "10.1109/2945.928168", "10.1007/978-3-662-10388-31", "10.1016/j.physd.2013.01.013", "10.1111/cgf.12358", "10.1017/s002211209900720x", "10.1017/s0022112097008057", "10.1111/j.1467-8659.2009.01546.x", "10.1109/2.35197", "10.1111/j.1467-8659.2012.03089.x", "10.1111/cgf.13319", "10.1109/tvcg.2019.2934375.3", "10.1016/j.crme.2015.08.002.4", "10.1016/s0167-2789(00)00142-1", "10.1111/cgf.12359", "10.1103/physreve.93.063107", "10.1016/j.physd.2009.05.005", "10.1063/1.1477449", "10.1111/j.1467-8659.2009.01686.x", "10.1109/pacificvis.2011.5742374", "10.1017/jfm.2013.391", "10.1111/cgf.12121", "10.1186/1743-422x-3-15", "10.1063/1.3502450", "10.1063/1.868323", "10.1016/j.cnsns.2013.05.002", "10.1109/visual.2004.99", "10.1109/visual.2004.107", "10.1111/j.1467-8659.2009.01604.x", "10.1146/annurev-fluid-010313-141322", "10.1063/1.3690153", "10.1109/tvcg.2019.2934375", "10.1109/tvcg.2013.143", "10.1137/130940633", "10.1016/j.cag.2014.01.007", "10.1016/s0097-8493(02)00056-0", "10.1109/vl.1996.545307", "10.1109/tvcg.2011.284", "10.1109/tvcg.2011.265", "10.1017/jfm.2016.792", "10.1109/tvcg.2013.208", "10.1007/s12650-016-0348-8", "10.1023/b:elas.0000005548.36767.e7", "10.1007/978-1-4939-0419-8\\_\\_9", "10.1007/bf00849110", "10.1615/int.j.uncertaintyquantification.2012003956", "10.1017/s0022112096001802", "10.1017/s0962492902000065", "10.1109/pacificvis.2019.00041", "10.1111/j.1467-8659.2011.01901.x", "10.1109/tvcg.2008.33", "10.1016/j.physd.2005.10.007", "10.1016/s0894-1777(96)00090-8", "10.1145/2517327.2442526", "10.1109/tvcg.2017.2743938", "10.1109/tvcg.2018.2816059", "10.1109/tvcg.2019.2934242", "10.2514/6.1995-1715.4", "10.1111/cgf.12109", "10.1109/tvcg.2011.269", "10.1109/visual.1990.146359", "10.1111/j.1467-8659.2003.00723.x", "10.5194/npg-18-977-2011", "10.1109/visual.1998.745296", "10.1109/tvcg.2007.70557", "10.1109/tvcg.2014.2312012"], "wos": 1, "children": [], "len": 1}, {"doi": "10.1111/cgf.13982", "year": "2020", "title": "Extraction of Distinguished Hyperbolic Trajectories for 2D Time-Dependent Vector Field Topology", "conferenceName": "EuroVis", "authors": "Lutz Hofmann;Filip Sadlo", "citationCount": "0", "affiliation": "Hofmann, L (Corresponding Author), Heidelberg Univ, Heidelberg, Germany.\nHofmann, Lutz; Sadlo, Filip, Heidelberg Univ, Heidelberg, Germany.", "countries": "Germany", "abstract": "This paper does two main contributions to 2D time-dependent vector field topology. First, we present a technique for robust, accurate, and efficient extraction of distinguished hyperbolic trajectories (DHT), the generative structures of 2D time-dependent vector field topology. It is based on refinement of initial candidate curves. In contrast to previous approaches, it is robust because the refinement converges for reasonably close initial candidates, it is accurate due to its adaptive scheme, and it is efficient due to its high convergence speed. Second, we provide a detailed evaluation and discussion of previous approaches for the extraction of DHTs and time-dependent vector field topology in general. We demonstrate the utility of our approach using analytical flows, as well as data from computational fluid dynamics.", "keywords": "", "link": "https://doi.org/10.1111/cgf.13982", "refList": ["10.1063/1.3579597", "10.1109/2.35197", "10.1111/j.1467-8659.2012.03063.x", "10.1007/978-3-540-70823-0\\_2", "10.1111/cgf.12885", "10.5194/npg-11-17-2004", "10.1016/j.physd.2005.10.007", "10.1109/visual.1998.745297", "10.1109/tvcg.2018.2868760", "10.1109/tvcg.2007.70551", "10.1109/tvcg.2017.2743938", "10.1109/visual.1999.809896", "10.1109/tvcg.2007.70554", "10.1109/tvcg.2015.2467200", "10.1016/j.physd.2009.05.005", "10.1007/978-3-540-88606-8\\_2", "10.1109/tvcg.2012.131", "10.1007/978-3-540-88606-8\\_1", "10.1145/3072959.3073684", "10.1142/s0218127403007321", "10.1016/s0167-2789(00)00199-8", "10.1063/1.166479", "10.1007/s003329900057", "10.1109/tvcg.2010.198", "10.1109/visual.2004.99", "10.1109/visual.2003.1250376", "10.1109/tvcg.2007.70545", "10.5194/npg-9-237-2002", "10.5194/npg-17-1-2010", "10.1109/tvcg.2007.70557", "10.1109/tvcg.2019.2934375"], "wos": 1, "children": [], "len": 1}], "len": 5}, {"doi": "10.1111/cgf.13689", "year": "2019", "title": "Robust Reference Frame Extraction from Unsteady 2D Vector Fields with Convolutional Neural Networks", "conferenceName": "EuroVis", "authors": "Byungsoo Kim;Tobias G{\\\"{u}}nther", "citationCount": "3", "affiliation": "Kim, B (Corresponding Author), Swiss Fed Inst Technol, Dept Comp Sci, Zurich, Switzerland.\nKim, Byungsoo; Guenther, Tobias, Swiss Fed Inst Technol, Dept Comp Sci, Zurich, Switzerland.", "countries": "Switzerland", "abstract": "Robust feature extraction is an integral part of scientific visualization. In unsteady vector field analysis, researchers recently directed their attention towards the computation of near-steady reference frames for vortex extraction, which is a numerically challenging endeavor. In this paper, we utilize a convolutional neural network to combine two steps of the visualization pipeline in an end-to-end manner: the filtering and the feature extraction. We use neural networks for the extraction of a steady reference frame for a given unsteady 2D vector field. By conditioning the neural network to noisy inputs and resampling artifacts, we obtain numerically stabler results than existing optimization-based approaches. Supervised deep learning typically requires a large amount of training data. Thus, our second contribution is the creation of a vector field benchmark data set, which is generally useful for any local deep learning-based feature extraction. Based on Vatistas velocity profile, we formulate a parametric vector field mixture model that we parameterize based on numerically-computed example vector fields in near-steady reference frames. Given the parametric model, we can efficiently synthesize thousands of vector fields that serve as input to our deep learning architecture. The proposed network is evaluated on an unseen numerical fluid flow simulation.", "keywords": "", "link": "https://doi.org/10.1111/cgf.13689", "refList": ["10.1016/0377-0257(79)87004-4", "10.1111/cgf.12358", "10.1109/tvcg.2018.2864828", "10.1016/0167-2789(91)90088-q", "10.1007/978-3-540-70823-0\\_9", "10.1016/b978-012387582-2/50040-x", "10.1111/cgf.13405", "10.1111/cgf.13319", "10.1109/tvcg.2018.2843369", "10.1007/bf00538235", "10.23940/ijpe.18.03", "10.1017/jfm.2016.151", "10.1109/visual.1999.809896", "10.1146/annurev.fluid.23.1.601", "10.1109/tvcg.2007.1036", "10.1109/tvcg.2018.2864839", "10.1007/978-3-319-54024-5\\_6", "10.1109/tvcg.2013.189", "10.1145/3072959.3073684", "10.1109/tvcg.2015.2467203", "10.2514/2.957", "10.1016/0960-0779(94)90137-6", "10.1109/visual.1991.175773", "10.1109/visual.1996.568137", "10.1017/s0022112004002526", "10.1109/pacificvis.2016.7465253", "10.1007/bf00849110", "10.1007/bf00198434", "10.1109/tvcg.2007.70545", "10.3390/informatics4030027", "10.1137/140983665", "10.1016/0011-7471(70)90059-8", "10.1017/s0022112095000462", "10.1145/1183287.1183290"], "wos": 1, "children": [{"doi": "10.1109/tvcg.2020.3028947", "title": "A Fluid Flow Data Set for Machine Learning and its Application to Neural Flow Map Interpolation", "year": "2020", "conferenceName": "SciVis", "authors": "Jakob Jakob;Markus H. Gross;Tobias G\u00fcnther", "citationCount": "0", "affiliation": "Jakob, J (Corresponding Author), Swiss Fed Inst Technol, Zurich, Switzerland. Jakob, Jakob; Gross, Markus; Guenther, Tobias, Swiss Fed Inst Technol, Zurich, Switzerland.", "countries": "Switzerland", "abstract": "In recent years, deep learning has opened countless research opportunities across many different disciplines. At present, visualization is mainly applied to explore and explain neural networks. Its counterpart-the application of deep learning to visualization problems-requires us to share data more openly in order to enable more scientists to engage in data-driven research. In this paper, we construct a large fluid flow data set and apply it to a deep learning problem in scientific visualization. Parameterized by the Reynolds number, the data set contains a wide spectrum of laminar and turbulent fluid flow regimes. The full data set was simulated on a high-performance compute cluster and contains 8000 time-dependent 2D vector fields, accumulating to more than 16 TB in size. Using our public fluid data set, we trained deep convolutional neural networks in order to set a benchmark for an improved post-hoc Lagrangian fluid flow analysis. In in-situ settings, flow maps are exported and interpolated in order to assess the transport characteristics of time-dependent fluids. Using deep learning, we improve the accuracy of flow map interpolations, allowing a more precise flow analysis at a reduced memory IO footprint.", "keywords": "Scientific visualization,deep learning,flow maps", "link": "http://dx.doi.org/10.1109/TVCG.2020.3028947", "refList": ["10.1007/978-3-319-10593-2\\_25", "10.1145/3355089.3356560", "10.1109/access.2019.2903582", "10.1111/cgf.13405", "10.1109/tmm.2019.2919431", "10.1017/jfm.2016.151", "10.1016/j.physd.2005.10.007", "10.1007/978-3-030-00533-7\\_36", "10.3390/rs11161921", "10.1007/978-3-030-48457-6\\_1", "10.1145/3309993", "10.1109/pacificvis.2018.00018", "10.1109/tvcg.2007.70554", "10.1109/mcg.2018.2881523", "10.1109/cvpr.2016.207", "10.1145/1073204.1073264", "10.1145/3072959.3073643", "10.1109/tpami.2015.2439281", "10.2312/pgv", "10.4208/cicp.oa-2018-0035", "10.1109/cvpr.2017.693", "10.1109/tvcg.2013.128", "10.1109/igarss.2018.8519261", "10.1063/1.3270044", "10.2312/pgv.20191115", "10.1145/3197517.3201304", "10.1145/3065386", "10.1145/1360612.1360649", "10.1109/mcse.2015.103", "10.1145/3355089.3356575", "10.1109/mcg.2018.2881502", "10.1029/2019jd032121", "10.3390/informatics4030027", "10.1109/access.2019.2931781", "10.1007/s12650-018-0523-1", "10.1109/tvcg.2019.2934332", "10.1146/annurev.fluid.32.1.165", "10.1007/978-3-319-46475-6\\_43", "10.1126/science.1127647", "10.1007/978-3-319-46475-6\\_25", "10.1111/cgf.13689"], "wos": 1, "children": [], "len": 1}, {"doi": "10.1109/pacificvis48177.2020.8737", "year": "2020", "title": "SSR-VFD: Spatial Super-Resolution for Vector Field Data Analysis and Visualization", "conferenceName": "PacificVis", "authors": "Li Guo;Shaojie Ye;Jun Han;Hao Zheng;Han Gao;Danny Z. Chen;Jian{-}Xun Wang;Chaoli Wang", "citationCount": "1", "affiliation": "Guo, L (Corresponding Author), Nankai Univ, Tianjin, Peoples R China.\nGuo, Li, Nankai Univ, Tianjin, Peoples R China.\nYe, Shaojie, Zhejiang Univ, Hangzhou, Zhejiang, Peoples R China.\nHan, Jun; Zheng, Hao; Gao, Han; Chen, Danny Z.; Wang, Jian-Xun; Wang, Chaoli, Univ Notre Dame, Notre Dame, IN 46556 USA.", "countries": "USA;China", "abstract": "We present SSR-VFD, a novel deep learning framework that produces coherent spatial super-resolution (SSR) of three-dimensional vector field data (VFD). SSR-VFD is the first work that advocates a machine learning approach to generate high-resolution vector fields from low-resolution ones. The core of SSR-VFD lies in the use of three separate neural nets that take the three components of a low-resolution vector field as input and jointly output a synthesized high-resolution vector field. To capture spatial coherence, we take into account magnitude and angle losses in network optimization. Our method can work in the in situ scenario where VFD are down-sampled at simulation time for storage saving and these reduced VFD are upsampled back to their original resolution during postprocessing. To demonstrate the effectiveness of SSR-VFD, we show quantitative and qualitative results with several vector field data sets of different characteristics and compare our method against volume upscaling using bicubic interpolation, and two solutions based on CNN and GAN, respectively.", "keywords": "Spatial super-resolution; vector field data; convolutional neural network; deep learning", "link": "https://doi.org/10.1109/PacificVis48177.2020.8737", "refList": ["10.1016/j.ijvsm.2017.05.001", "10.1016/j.jvs.2005.01.020", "10.1109/iccv.2015.123", "10.1111/cgf.13620", "10.1109/cvpr.2019.00831", "10.1109/cvpr.2019.00817", "10.1109/cvpr.2019.00399", "10.1109/tvcg.2019.2934312", "10.1145/3309993", "10.1109/pacificvis.2018.00018", "10.1109/tvcg.2018.2816059", "10.1109/mcg.2018.2881523", "10.1109/tpami.2015.2439281", "10.1109/bigdata.2018.8622520", "10.1145/3197517.3201304", "10.1109/tvcg.2018.2796085", "10.1109/tvcg.2019.2934255", "10.1109/cvpr.2016.90", "10.1109/pacificvis.2019.00041", "10.1111/cgf.13689"], "wos": 1, "children": [{"doi": "10.1109/tvcg.2020.3030374", "title": "VC-Net: Deep Volume-Composition Networks for Segmentation and Visualization of Highly Sparse and Noisy Image Data", "year": "2020", "conferenceName": "SciVis", "authors": "Yifan Wang;Guoli Yan;Haikuan Zhu;Sagar Buch;Ying Wang;E. Mark Haacke;Jing Hua;Zichun Zhong", "citationCount": "0", "affiliation": "Wang, YF (Corresponding Author), Wayne State Univ, Dept Comp Sci, Detroit, MI 48202 USA. Wang, Yifan; Yan, Guoli; Zhu, Haikuan; Hua, Jing; Zhong, Zichun, Wayne State Univ, Dept Comp Sci, Detroit, MI 48202 USA. Buch, Sagar; Wang, Ying; Haacke, Ewart Mark, Wayne State Univ, Dept Radiol, Detroit, MI 48201 USA.", "countries": "USA", "abstract": "The fundamental motivation of the proposed work is to present a new visualization-guided computing paradigm to combine direct 3D volume processing and volume rendered clues for effective 3D exploration. For example, extracting and visualizing microstructures in-vivo have been a long-standing challenging problem. However, due to the high sparseness and noisiness in cerebrovasculature data as well as highly complex geometry and topology variations of micro vessels, it is still extremely challenging to extract the complete 3D vessel structure and visualize it in 3D with high fidelity. In this paper, we present an end-to-end deep learning method, VC-Net, for robust extraction of 3D microvascular structure through embedding the image composition, generated by maximum intensity projection (MIP), into the 3D volumetric image learning process to enhance the overall performance. The core novelty is to automatically leverage the volume visualization technique (e.g., MIP - a volume rendering scheme for 3D volume images) to enhance the 3D data exploration at the deep learning level. The MIP embedding features can enhance the local vessel signal (through canceling out the noise) and adapt to the geometric variability and scalability of vessels, which is of great importance in microvascular tracking. A multi-stream convolutional neural network (CNN) framework is proposed to effectively learn the 3D volume and 2D MIP feature vectors, respectively, and then explore their inter-dependencies in a joint volume-composition embedding space by unprojecting the 2D feature vectors into the 3D volume embedding space. It is noted that the proposed framework can better capture the small/micro vessels and improve the vessel connectivity. To our knowledge, this is the first time that a deep learning framework is proposed to construct a joint convolutional embedding space, where the computed vessel probabilities from volume rendering based 2D projection and 3D volume can be explored and integrated synergistically. Experimental results are evaluated and compared with the traditional 3D vessel segmentation methods and the state-of-the-art in deep learning, by using extensive public and real patient (micro- )cerebrovascular image datasets. The application of this accurate segmentation and visualization of sparse and complicated 3D microvascular structure facilitated by our method demonstrates the potential in a powerful MR arteriogram and venogram diagnosis of vascular disease.", "keywords": "Deep neural network,3D cerebrovascular segmentation and visualization,maximum intensity projection (MIP),joint embedding", "link": "http://dx.doi.org/10.1109/TVCG.2020.3030374", "refList": ["10.1109/cluster.2018.00036", "10.1109/iccv.2015.123", "10.1109/tvcg.2013.133", "10.1109/cvpr.2017.19", "10.1109/tvcg.2019.2934312", "10.1007/978-3-319-46487-9\\_40", "10.1109/tvcg.2006.175", "10.1109/tvcg.2007.70523", "10.1109/tvcg.2018.2880207", "10.1145/3309993", "10.1109/pacificvis.2018.00018", "10.1109/iccv.2017.244", "10.1109/cvpr.2017.632", "10.1109/tvcg.2018.2816059", "10.1109/pacificvis.2009.4906852", "10.1109/tvcg.2018.2864808", "10.1109/mcg.2018.2881523", "10.1109/tvcg.2015.2467431", "10.1109/tpami.2015.2439281", "10.1109/pacificvis48177.2020.8737", "10.1109/cvpr.2019.00244", "10.1109/tvcg.2006.165", "10.1109/bigdata.2018.8622520", "10.1007/978-3-319-46466-4\\_29", "10.1109/visual.2019.8933759", "10.1145/3197517.3201304", "10.1109/pacificvis.2011.5742378", "10.1109/cvpr.2006.91", "10.1109/pacificvis.2011.5742369", "10.1109/tvcg.2019.2934255", "10.1109/cvpr.2016.90", "10.1007/978-3-319-24574-4\\_28", "10.1109/pacificvis.2019.00041", "10.1109/tvcg.2019.2934332", "10.1109/cvpr.2018.00916", "10.1007/978-3-319-46475-6\\_43"], "wos": 1, "children": [], "len": 1}], "len": 3}], "len": 7}], "len": 15}, "index": 767, "embedding": [-0.7324632406234741, 1.147998332977295, -1.030107021331787, -2.273205041885376, -0.4476333558559418, 0.16650904715061188, -0.7323254346847534, 1.1301124095916748, 1.633212924003601, -0.8419216275215149, 1.6755367517471313, 0.3709472417831421, 2.8320932388305664, 1.2660754919052124, -0.41252821683883667, -0.12652544677257538, 1.19234037399292, 0.07072390615940094, 0.769432008266449, 2.089280605316162, -0.06630208343267441, -0.5897487998008728, -0.6228023171424866, 1.030440330505371, -2.405334949493408, 1.1065772771835327, -0.5452967882156372, 0.8599357008934021, 1.3552147150039673, -2.657630681991577, 1.0324138402938843, 0.519530713558197], "projection": [0.9551910758018494, 8.243728637695312], "size": 8, "height": 4, "width": 4}