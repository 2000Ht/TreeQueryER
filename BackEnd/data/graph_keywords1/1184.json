{"data": {"doi": "10.1109/vast.2016.7883518", "title": "Shape Grammar Extraction for Efficient Query-by-Sketch Pattern Matching in Long Time Series", "year": "2016", "conferenceName": "VAST", "authors": "Prithiviraj K. Muthumanickam;Katerina Vrotsou;Matthew Cooper;Jimmy Johansson", "citationCount": "2", "affiliation": "Muthumanickam, PK (Corresponding Author), Linkoping Univ, Linkoping, Sweden. Muthumanickam, Prithiviraj K.; Vrotsou, Katerina; Cooper, Matthew; Johansson, Jimmy, Linkoping Univ, Linkoping, Sweden.", "countries": "Sweden", "abstract": "Long time-series, involving thousands or even millions of time steps, are common in many application domains but remain very difficult to explore interactively. Often the analytical task in such data is to identify specific patterns, but this is a very complex and computationally difficult problem and so focusing the search in order to only identify interesting patterns is a common solution. We propose an efficient method for exploring user-sketched patterns, incorporating the domain expert's knowledge, in time series data through a shape grammar based approach. The shape grammar is extracted from the time series by considering the data as a combination of basic elementary shapes positioned across different amplitudes. We represent these basic shapes using a ratio value, perform binning on ratio values and apply a symbolic approximation. Our proposed method for pattern matching is amplitude-, scale- and translation-invariant and, since the pattern search and pattern constraint relaxation happen at the symbolic level, is very efficient permitting its use in a real-time/online system. We demonstrate the effectiveness of our method in a case study on stock market data although it is applicable to any numeric time series data.", "keywords": "", "link": "http://dx.doi.org/10.1109/VAST.2016.7883518", "refList": ["10.1016/j.engappai.2010.09.007", "10.1007/978-3-642-32695-0", "10.1007/978-3-662-44845-8\\_37", "10.1007/978-3-642-41398-8\\_24", "10.1145/1056808.1057017", "10.1016/j.engappai.2008.01.005", "10.1145/274946.274955", "10.1145/882082.882086", "10.1145/312624.312676", "10.3138/fm57-6770-u75u-7727", "10.1109/ism.2007.15", "10.1007/pl00011669", "10.1145/2379776.2379788", "10.1145/2678025.2701379", "10.1109/tvcg.2008.184", "10.1109/iv.2008.80", "10.1613/jair.374", "10.1109/icde.1996.492204", "10.1145/634067.634292", "10.1007/978-3-642-34654-5\\_10", "10.1109/tvcg.2009.200", "10.1016/j.neucom.2014.01.045", "10.1177/1473871611430769", "10.1109/tvcg.2010.137", "10.1109/iccwamtip.2014.7073350", "10.1016/j.knosys.2012.12.011", "10.1057/palgrave.ivs.9500061", "10.1109/ride.1998.658288", "10.1007/3-540-45650-338", "10.1109/biovis.2012.6378590", "10.1109/icde.1999.754915", "10.1145/1385569.1385666", "10.1145/1083784.1083789", "10.1145/363347.363387", "10.1117/12.587537", "10.1109/vast.2010.5652530"], "wos": 1, "children": [{"doi": "10.1109/tvcg.2018.2865077", "title": "Comparing Similarity Perception in Time Series Visualizations", "year": "2018", "conferenceName": "InfoVis", "authors": "Anna Gogolou;Theophanis Tsandilas;Themis Palpanas;Anastasia Bezerianos", "citationCount": "12", "affiliation": "Gogolouis, A (Corresponding Author), Univ Paris Sud, INRIA, Orsay, France. Gogolouis, A (Corresponding Author), Univ Paris Saclay, Paris, France. Gogolouis, Anna; Tsandilas, Theophanis, Univ Paris Sud, INRIA, Orsay, France. Gogolouis, Anna; Tsandilas, Theophanis; Bezerianos, Anastasia, Univ Paris Saclay, Paris, France. Tsandilas, Theophanis, CNRS, Paris, France. Palpanas, Themis, Univ Paris 05, Paris, France. Bezerianos, Anastasia, Univ Paris Sud, Orsay, France. Bezerianos, Anastasia, INRIA, CNRS, Paris, France.", "countries": "France", "abstract": "A common challenge faced by many domain experts working with time series data is how to identify and compare similar patterns. This operation is fundamental in high-level tasks, such as detecting recurring phenomena or creating clusters of similar temporal sequences. While automatic measures exist to compute time series similarity, human intervention is often required to visually inspect these automatically generated results. The visualization literature has examined similarity perception and its relation to automatic similarity measures for line charts, but has not yet considered if alternative visual representations, such as horizon graphs and colorfields, alter this perception. Motivated by how neuroscientists evaluate epileptiform patterns, we conducted two experiments that study how these three visualization techniques affect similarity perception in EEG signals. We seek to understand if the time series results returned from automatic similarity measures are perceived in a similar manner, irrespective of the visualization technique; and if what people perceive as similar with each visualization aligns with different automatic measures and their similarity constraints. Our findings indicate that horizon graphs align with similarity measures that allow local variations in temporal position or speed (i.e., dynamic time warping) more than the two other techniques. On the other hand, horizon graphs do not align with measures that are insensitive to amplitude and y-offset scaling (i.e., measures based on z-normalization), but the inverse seems to be the case for line charts and colorfields. Overall, our work indicates that the choice of visualization affects what temporal patterns we consider as similar, i.e., the notion of similarity in time series is not visualization independent.", "keywords": "Time series,similarity perception,automatic similarity search,line charts,horizon graphs,colorfields,evaluation", "link": "http://dx.doi.org/10.1109/TVCG.2018.2865077", "refList": ["10.1016/j.engappai.2010.09.007", "10.1109/tvcg.2012.196", "10.1016/j.cag.2007.01.032", "10.1192/bjp.125.4.341", "10.1145/1056808.1057017", "10.1111/epi.13108", "10.1016/j.neulet.2011.03.070", "10.1109/pacificvis.2018.00023", "10.1109/mcg.2012.37", "10.1109/vast.2007.4389007", "10.14778/2824032.2824099", "10.1109/vast.2016.7883518", "10.1145/2470654.2466441", "10.1007/978-0-85729-079-3\\_1", "10.1145/2678025.2701379", "10.1109/tvcg.2011.195", "10.1145/2207676.2208556", "10.1145/3182168", "10.1145/634067.634292", "10.1177/001316448104100307", "10.1093/gerona/glq232", "10.1109/infvis.2005.1532144", "10.1111/j.1535-7511.2006.00145.x", "10.1145/2470654.2466443", "10.1007/s00778-016-0442-5", "10.1097/ede.0b013e3181e5b06a", "10.1016/j.compbiomed.2008.04.010", "10.1016/j.brainresbull.2015.04.007", "10.1109/edssc.2007.4450237", "10.1057/palgrave.ivs.9500061", "10.2307/2289144", "10.1109/tvcg.2008.166", "10.1641/0006-3568(2001)051{[}0341:lndats]2.0.co", "2", "10.1145/2814710.2814719", "10.1109/infvis.2001.963273", "10.1109/tvcg.2011.232", "10.1109/wsc.2003.1261490", "10.1109/tvcg.2010.162", "10.1016/j.jneumeth.2016.02.025", "10.1145/1385569.1385666", "10.1145/2339530.2339576", "10.1007/978-3-319-26633-6\\_13", "10.1001/archneurol.2009.137", "10.1109/infvis.1999.801851", "10.1007/s10618-013-0312-3", "10.1109/vast.2016.7883519", "10.1145/1133265.1133348"], "wos": 1, "children": [{"doi": "10.1109/tvcg.2019.2934784", "title": "A Comparison of Radial and Linear Charts for Visualizing Daily Patterns", "year": "2019", "conferenceName": "InfoVis", "authors": "Manuela Waldner;Alexandra Diehl;Denis Gracanin;Rainer Splechtna;Claudio Delrieux;Kresimir Matkovic", "citationCount": "0", "affiliation": "Waldner, M (Corresponding Author), TU Wien, Vienna, Austria. Waldner, Manuela, TU Wien, Vienna, Austria. Diehl, Alexandra, Univ Zurich, Zurich, Switzerland. Gracanin, Denis, Virginia Tech, Blacksburg, VA USA. Splechtna, Rainer; Matkovic, Kresimir, VRVis Res Ctr, Vienna, Austria. Delrieux, Claudio, Univ Nacl Sur, Elect \\& Comp Eng Dept, Bahia Blanca, Buenos Aires, Argentina.", "countries": "Argentina;Switzerland;USA;Austria", "abstract": "Radial charts are generally considered less effective than linear charts. Perhaps the only exception is in visualizing periodical time-dependent data, which is believed to be naturally supported by the radial layout. It has been demonstrated that the drawbacks of radial charts outweigh the benefits of this natural mapping. Visualization of daily patterns, as a special case, has not been systematically evaluated using radial charts. In contrast to yearly or weekly recurrent trends, the analysis of daily patterns on a radial chart may benefit from our trained skill on reading radial clocks that are ubiquitous in our culture. In a crowd-sourced experiment with 92 non-expert users, we evaluated the accuracy, efficiency, and subjective ratings of radial and linear charts for visualizing daily traffic accident patterns. We systematically compared juxtaposed 12-hours variants and single 24-hours variants for both layouts in four low-level tasks and one high-level interpretation task. Our results show that over all tasks, the most elementary 24-hours linear bar chart is most accurate and efficient and is also preferred by the users. This provides strong evidence for the use of linear layouts \u2013 even for visualizing periodical daily patterns.", "keywords": "Radial charts,time series series data,daily patterns,crowd-sourced experiment", "link": "http://dx.doi.org/10.1109/TVCG.2019.2934784", "refList": ["10.1109/infvis.2000.885091", "10.1109/tvcg.2018.2865158", "10.1177/1473871611406623", "10.1111/cgf.13444", "10.1038/scientificamerican0384-128", "10.1109/tvcg.2018.2865234", "10.1109/tvcg.2015.2467771", "10.1109/tvcg.2018.2865077", "10.1109/tvcg.2013.184", "10.1109/tvcg.2014.2346320", "10.1145/2858036.2858300", "10.1109/tvcg.2017.2674958", "10.1109/iv.2013.12", "10.1145/2470654.2466443", "10.1007/s10763-012-9362-z", "10.1207/s15427625tcq1402\\_3", "10.2307/2288400", "10.1136/jnnp.64.5.588", "10.1109/tvcg.2014.2346426", "10.1109/infvis.1998.729557", "10.1007/bf03217308", "10.1145/506443.506505", "10.1109/infvis.2001.963273", "10.1111/j.1467-8659.2011.01947.x", "10.1109/tvcg.2013.234", "10.1109/38.974517", "10.2312/pe/eurovisshort/eurovisshort2012/097-101", "10.1145/1743546.1743567", "10.1109/tvcg.2010.162", "10.2307/2289447", "10.1145/2110192.2110202", "10.1109/tvcg.2009.23", "10.3102/10769986030004353", "10.1109/tvcg.2010.209"], "wos": 1, "children": [], "len": 1}, {"doi": "10.1109/tvcg.2019.2934655", "title": "Visual Analytics for Electromagnetic Situation Awareness in Radio Monitoring and Management", "year": "2019", "conferenceName": "VAST", "authors": "Ying Zhao;Xiaobo Luo;Xiaoru Lin;Hairong Wang;Xiaoyan Kui;Fangfang Zhou;Jinsong Wang;Yi Chen 0007;Wei Chen", "citationCount": "3", "affiliation": "Kui, XY; Zhou, FF (Corresponding Author), Cent S Univ, Sch Comp Sci \\& Engn, Changsha, Hunan, Peoples R China. Zhao, Ying; Luo, Xiaobo; Lin, Xiaoru; Kui, Xiaoyan; Zhou, Fangfang, Cent S Univ, Sch Comp Sci \\& Engn, Changsha, Hunan, Peoples R China. Wang, Hairong, Cent S Univ, Sch Automat, Changsha, Hunan, Peoples R China. Wang, Jinsong, Southwest Elect \\& Telecom Engn Inst, Shanghai, Peoples R China. Chen, Yi, Beijing Technol \\& Business Univ, Beijing Key Lab Big Data Technol Food Safety, Beijing, Peoples R China. Chen, Wei, Zhejiang Univ, Key Lab CAD \\& CG, Hangzhou, Zhejiang, Peoples R China.", "countries": "China", "abstract": "Traditional radio monitoring and management largely depend on radio spectrum data analysis, which requires considerable domain experience and heavy cognition effort and frequently results in incorrect signal judgment and incomprehensive situation awareness. Faced with increasingly complicated electromagnetic environments, radio supervisors urgently need additional data sources and advanced analytical technologies to enhance their situation awareness ability. This paper introduces a visual analytics approach for electromagnetic situation awareness. Guided by a detailed scenario and requirement analysis, we first propose a signal clustering method to process radio signal data and a situation assessment model to obtain qualitative and quantitative descriptions of the electromagnetic situations. We then design a two-module interface with a set of visualization views and interactions to help radio supervisors perceive and understand the electromagnetic situations by a joint analysis of radio signal data and radio spectrum data. Evaluations on real-world data sets and an interview with actual users demonstrate the effectiveness of our prototype system. Finally, we discuss the limitations of the proposed approach and provide future work directions.", "keywords": "Radio monitoring and management,radio signal data,radio spectrum data,situation awareness,visual analytics", "link": "http://dx.doi.org/10.1109/TVCG.2019.2934655", "refList": ["10.1016/j.newast.2010.07.009", "10.1109/tvcg.2017.2744459", "10.1109/tvcg.2018.2864503", "10.1145/1029208.1029219", "10.1109/pacificvis.2014.54", "10.1109/tvcg.2018.2829750", "10.1016/j.jvlc.2017.11.004", "10.1109/tcyb.2015.2448236", "10.1016/j.patrec.2017.11.011", "10.1109/tvcg.2015.2505305", "10.1109/vast.2014.7042528", "10.1007/s12650-018-0530-2", "10.1109/tvcg.2018.2816203", "10.1109/tmm.2016.2614220", "10.1109/tvcg.2017.2745180", "10.1109/mcg.2018.2879067", "10.1109/tvcg.2018.2859973", "10.1109/tvcg.2016.2598460", "10.1109/infvis.2005.1532134", "10.1109/tvcg.2018.2851227", "10.1155/2012/920671", "10.1109/vast.2014.7042479", "10.1109/tvcg.2013.228", "10.1109/tvcg.2018.2865077", "10.1016/j.csda.2005.10.001", "10.1109/tvcg.2018.2865028", "10.1109/tvcg.2011.239", "10.1145/3173574.3174237", "10.1007/s13042-016-0603-2", "10.1109/tvcg.2018.2865020", "10.1017/s1041610219000024", "10.1109/2945.981848", "10.1109/tvcg.2010.193", "10.1109/tvcg.2018.2802520", "10.1145/3200766", "10.1109/wcncw.2015.7122557", "10.1145/3006299.3006312", "10.1109/icsssm.2007.4280175", "10.1126/science.1242072", "10.1109/tvcg.2017.2744098", "10.1109/tvcg.2015.2467196", "10.1109/tvcg.2016.2598619", "10.1109/tvcg.2016.2598664", "10.1109/tvcg.2013.196", "10.1109/comst.2016.2631080", "10.1109/tvcg.2018.2865029", "10.1007/s10816-016-9307-x", "10.1109/tvcg.2008.166", "10.1109/tvcg.2017.2758362", "10.1109/vizsec.2005.1532072", "10.1518/001872095779049543", "10.1109/tvcg.2007.70415", "10.1016/j.ins.2018.01.013", "10.1109/tvcg.2014.2346911", "10.1109/mim.2013.6616284", "10.1109/jsyst.2014.2358997", "10.1111/cgf.12910", "10.1109/isi.2009.5137305", "10.1109/tvcg.2011.179", "10.1007/s11277-015-2631-8", "10.1111/cgf.12396", "10.1109/tvcg.2013.2297933", "10.1109/tvcg.2014.2346926", "10.1109/tvcg.2014.2346913", "10.1109/pacificvis.2018.00030", "10.1109/tvcg.2014.2346433", "10.1109/tvcg.2016.2614803"], "wos": 1, "children": [{"doi": "10.1109/tvcg.2020.3030443", "title": "CAVA: A Visual Analytics System for Exploratory Columnar Data Augmentation Using Knowledge Graphs", "year": "2020", "conferenceName": "VAST", "authors": "Dylan Cashman;Shenyu Xu;Subhajit Das;Florian Heimerl;Cong Liu;Shah Rukh Humayoun;Michael Gleicher;Alex Endert;Remco Chang", "citationCount": "0", "affiliation": "Cashman, D (Corresponding Author), Tufts Univ, Medford, MA 02155 USA. Cashman, Dylan; Liu, Cong; Chang, Remco, Tufts Univ, Medford, MA 02155 USA. Xu, Shenyu; Das, Subhajit; Endert, Alex, Georgia Tech, Atlanta, GA USA. Heimerl, Florian; Gleicher, Michael, Univ Wisconsin, Madison, WI 53706 USA. Humayoun, Shah Rukh, San Francisco State Univ, San Francisco, CA 94132 USA.", "countries": "USA", "abstract": "Most visual analytics systems assume that all foraging for data happens before the analytics process; once analysis begins, the set of data attributes considered is fixed. Such separation of data construction from analysis precludes iteration that can enable foraging informed by the needs that arise in-situ during the analysis. The separation of the foraging loop from the data analysis tasks can limit the pace and scope of analysis. In this paper, we present CAVA, a system that integrates data curation and data augmentation with the traditional data exploration and analysis tasks, enabling information foraging in-situ during analysis. Identifying attributes to add to the dataset is difficult because it requires human knowledge to determine which available attributes will be helpful for the ensuing analytical tasks. CAVA crawls knowledge graphs to provide users with a a broad set of attributes drawn from external data to choose from. Users can then specify complex operations on knowledge graphs to construct additional attributes. CAVA shows how visual analytics can help users forage for attributes by letting users visually explore the set of available data, and by serving as an interface for query construction. It also provides visualizations of the knowledge graph itself to help users understand complex joins such as multi-hop aggregations. We assess the ability of our system to enable users to perform complex data combinations without programming in a user study over two datasets. We then demonstrate the generalizability of CAVA through two additional usage scenarios. The results of the evaluation confirm that CAVA is effective in helping the user perform data foraging that leads to improved analysis outcomes, and offer evidence in support of integrating data augmentation as a part of the visual analytics pipeline.", "keywords": "Visual Analytics,Information Foraging,Data Augmentation", "link": "http://dx.doi.org/10.1109/TVCG.2020.3030443", "refList": ["10.1057/palgrave.ivs.9500122", "10.1109/tvcg.2016.2598867", "10.1111/cgf.13708", "10.1109/tvcg.2019.2934799", "10.1109/tvcg.2019.2934541", "10.1109/tvcg.2013.65", "10.1109/tvcg.2018.2875702", "10.1109/iv.2004.1320207", "10.1068/p260471", "10.1145/1778765.1778816", "10.1109/tvcg.2018.2808489", "10.1109/tvcg.2018.2864912", "10.1016/j.apgeog.2015.12.006", "10.1111/j.1467-8659.2011.01960.x", "10.1109/tvcg.2018.2864843", "10.1109/pacificvis.2010.5429604", "10.1109/tvcg.2014.2346898", "10.1109/5.726791", "10.1177/1475090214540874", "10.1109/icde.2016.7498287", "10.1145/1556262.1556289", "10.1109/tvcg.2007.70535", "10.1109/vast.2012.6400489", "10.1145/1056808.1056914", "10.1016/j.neucom.2014.09.063", "10.1145/7529.8927", "10.1109/tvcg.2016.2598495", "10.1109/tvcg.2016.2607204", "10.1109/vast47406.2019.8986943", "10.3758/bf03205986", "10.1109/infvis.2005.1532142", "10.1145/1150402.1150479", "10.1109/tvcg.2017.2674978", "10.1109/tvcg.2019.2945960", "10.1109/tvcg.2017.2744098", "10.1109/tvcg.2017.2674999", "10.1109/tvcg.2011.279", "10.1109/tvcg.2014.2346594", "10.1109/tvcg.2017.2744184", "10.1111/cgf.12876", "10.1007/s4095-020-0191-7", "10.1007/s11390-015-1535-0", "10.1111/cgf.12640", "10.1109/tvcg.2016.2598667", "10.1111/cgf.13683", "10.1109/tvcg.2013.153", "10.1109/tvcg.2019.2934208", "10.1109/tvcg.2019.2934655", "10.1111/cgf.12655", "10.1007/s11023-010-9221-z", "10.1109/vast.2012.6400487", "10.1145/2702123.2702585", "10.1007/bf00310175", "10.1109/tvcg.2017.2744378", "10.1103/physreve.64.061907", "10.1109/ldav.2017.8231848", "10.1109/tvcg.2016.2598831"], "wos": 1, "children": [], "len": 1}, {"doi": "10.1109/tvcg.2020.3030432", "title": "Evaluation of Sampling Methods for Scatterplots", "year": "2020", "conferenceName": "VAST", "authors": "Jun Yuan;Shouxing Xiang;Jiazhi Xia;Lingyun Yu;Shixia Liu", "citationCount": "0", "affiliation": "Liu, SX (Corresponding Author), Tsinghua Univ, BNRist, Beijing, Peoples R China. Yuan, Jun; Xiang, Shouxing; Liu, Shixia, Tsinghua Univ, BNRist, Beijing, Peoples R China. Xia, Jiazhi, Cent South Univ, Changsha, Peoples R China. Yu, Lingyun, Xian Jiaotong Liverpool Univ, Suzhou, Peoples R China.", "countries": "China", "abstract": "Given a scatterplot with tens of thousands of points or even more, a natural question is which sampling method should be used to create a small but \u201cgood\u201d scatterplot for a better abstraction. We present the results of a user study that investigates the influence of different sampling strategies on multi-class scatterplots. The main goal of this study is to understand the capability of sampling methods in preserving the density, outliers, and overall shape of a scatterplot. To this end, we comprehensively review the literature and select seven typical sampling strategies as well as eight representative datasets. We then design four experiments to understand the performance of different strategies in maintaining: 1) region density; 2) class density; 3) outliers; and 4) overall shape in the sampling results. The results show that: 1) random sampling is preferred for preserving region density; 2) blue noise sampling and random sampling have comparable performance with the three multi-class sampling strategies in preserving class density; 3) outlier biased density based sampling, recursive subdivision based sampling, and blue noise sampling perform the best in keeping outliers; and 4) blue noise sampling outperforms the others in maintaining the overall shape of a scatterplot.", "keywords": "Scatterplot,data sampling,empirical evaluation", "link": "http://dx.doi.org/10.1109/TVCG.2020.3030432", "refList": ["10.1057/palgrave.ivs.9500122", "10.1109/tvcg.2016.2598867", "10.1109/tvcg.2015.2467591", "10.1111/cgf.13708", "10.1109/tvcg.2019.2934799", "10.1109/tvcg.2019.2934541", "10.1109/tvcg.2013.65", "10.1109/iv.2004.1320207", "10.1068/p260471", "10.1145/1778765.1778816", "10.1109/tvcg.2018.2808489", "10.1109/tvcg.2018.2864912", "10.1016/j.apgeog.2015.12.006", "10.1111/j.1467-8659.2011.01960.x", "10.1109/tvcg.2018.2864843", "10.1109/pacificvis.2010.5429604", "10.1109/tvcg.2014.2346898", "10.1109/5.726791", "10.1177/1475090214540874", "10.1145/1556262.1556289", "10.1109/tvcg.2007.70535", "10.1109/vast.2012.6400489", "10.1145/1056808.1056914", "10.1016/j.neucom.2014.09.063", "10.1145/7529.8927", "10.1109/tvcg.2016.2607204", "10.1109/vast47406.2019.8986943", "10.3758/bf03205986", "10.1109/infvis.2005.1532142", "10.1145/1150402.1150479", "10.1109/tvcg.2017.2674978", "10.1109/tvcg.2017.2744098", "10.1109/tvcg.2017.2674999", "10.1109/tvcg.2011.279", "10.1109/tvcg.2014.2346594", "10.1109/tvcg.2017.2744184", "10.1111/cgf.12876", "10.1109/1011101.2019.2945960", "10.1007/s4095-020-0191-7", "10.1007/s11390-015-1535-0", "10.1111/cgf.12640", "10.1109/tvcg.2016.2598667", "10.1111/cgf.13683", "10.1109/tvcg.2013.153", "10.1109/tvcg.2019.2934208", "10.1109/tvcg.2019.2934655", "10.1111/cgf.12655", "10.1007/s11023-010-9221-z", "10.1109/vast.2012.6400487", "10.1145/2702123.2702585", "10.1007/bf00310175", "10.1109/tvcg.2017.2744378", "10.1103/physreve.64.061907", "10.1109/ldav.2017.8231848", "10.1109/tvcg.2016.2598831"], "wos": 1, "children": [], "len": 1}], "len": 5}, {"doi": "10.1109/tvcg.2020.3030421", "title": "LineSmooth: An Analytical Framework for Evaluating the Effectiveness of Smoothing Techniques on Line Charts", "year": "2020", "conferenceName": "VAST", "authors": "Paul Rosen;Ghulam Jilani Quadri", "citationCount": "0", "affiliation": "Rosen, P (Corresponding Author), Univ S Florida, Tampa, FL 33620 USA. Rosen, Paul; Quadri, Ghulam Jilani, Univ S Florida, Tampa, FL 33620 USA.", "countries": "USA", "abstract": "We present a comprehensive framework for evaluating line chart smoothing methods under a variety of visual analytics tasks. Line charts are commonly used to visualize a series of data samples. When the number of samples is large, or the data are noisy, smoothing can be applied to make the signal more apparent. However, there are a wide variety of smoothing techniques available, and the effectiveness of each depends upon both nature of the data and the visual analytics task at hand. To date, the visualization community lacks a summary work for analyzing and classifying the various smoothing methods available. In this paper, we establish a framework, based on 8 measures of the line smoothing effectiveness tied to 8 low-level visual analytics tasks. We then analyze 12 methods coming from 4 commonly used classes of line chart smoothing-rank filters, convolutional filters, frequency domain filters, and subsampling. The results show that while no method is ideal for all situations, certain methods, such as Gaussian filters and TOPOLOGY-based subsampling, perform well in general. Other methods, such as low-pass CUTOFF filters and Douglas-peucker subsampling, perform well for specific visual analytics tasks. Almost as importantly, our framework demonstrates that several methods, including the commonly used UNIFORM subsampling, produce low-quality results, and should, therefore, be avoided, if possible.", "keywords": "Line chart,data smoothing,time-series", "link": "http://dx.doi.org/10.1109/TVCG.2020.3030421", "refList": ["10.1109/tvcg.2017.2744359", "10.1109/tip.2007.902329", "10.1109/tvcg.2014.2346979", "10.1090/mbk/069", "10.1002/acp.2350030302", "10.1109/tvcg.2018.2829750", "10.1080/03610927708827533", "10.1109/tvcg.2017.2653106", "10.3138/fm57-6770-u75u-7727", "10.2466/pms.104.3.707-721", "10.1016/s0146-664x(72", "10.1002/0471691852", "10.1093/ptj/74.8.768", "10.1016/j.rse.2015.12.023", "10.1145/2207676.2208556", "10.1109/tvcg.2018.2865264", "10.1109/tvcg.2018.2865077", "10.3758/bf03201236", "10.1145/3064175", "10.1145/2858036.2858300", "10.1109/infvis.2005.1532136", "10.1109/infvis.2005.1532144", "10.1021/ac60214a047", "10.1109/tvcg.2015.2467671", "10.1007/s11634-011-0102-y", "10.1109/tvcg.2017.2787113", "10.1002/cta.4490080205", "10.2312/evs.20201053", "10.1109/ncvpripg.2011.34", "10.1145/3025453.3025922", "10.1016/s0146-664x(72)80017-0", "10.1109/tvcg.2018.2864884", "10.1016/0734-189x(83)90054-3", "10.1109/tvcg.2013.234", "10.1109/tvcg.2016.2598592", "10.1109/tvcg.2010.162", "10.1109/jrproc.1949.232969", "10.1119/1.14057", "10.2307/2003354", "10.2312/evs", "10.1109/tvcg.2018.2864914", "10.1109/34.211471", "10.1145/2702123.2702608"], "wos": 1, "children": [], "len": 1}, {"doi": "10.1109/tvcg.2020.3030352", "title": "StackGenVis: Alignment of Data, Algorithms, and Models for Stacking Ensemble Learning Using Performance Metrics", "year": "2020", "conferenceName": "VAST", "authors": "Angelos Chatzimparmpas;Rafael Messias Martins;Kostiantyn Kucher;Andreas Kerren", "citationCount": "0", "affiliation": "Chatzimparmpas, A (Corresponding Author), Linnaeus Univ, Vaxjo, Sweden. Chatzimparmpas, Angelos; Martins, Rafael M.; Kucher, Kostiantyn; Kerren, Andreas, Linnaeus Univ, Vaxjo, Sweden.", "countries": "Sweden", "abstract": "In machine learning (ML), ensemble methods-such as bagging, boosting, and stacking-are widely-established approaches that regularly achieve top-notch predictive performance. Stacking (also called \u201cstacked generalization\u201d) is an ensemble method that combines heterogeneous base models, arranged in at least one layer, and then employs another metamodel to summarize the predictions of those models. Although it may be a highly-effective approach for increasing the predictive performance of ML, generating a stack of models from scratch can be a cumbersome trial-and-error process. This challenge stems from the enormous space of available solutions, with different sets of data instances and features that could be used for training, several algorithms to choose from, and instantiations of these algorithms using diverse parameters (i.e., models) that perform differently according to various metrics. In this work, we present a knowledge generation model, which supports ensemble learning with the use of visualization, and a visual analytics system for stacked generalization. Our system, StackGenVis, assists users in dynamically adapting performance metrics, managing data instances, selecting the most important features for a given data set, choosing a set of top-performant and diverse algorithms, and measuring the predictive performance. In consequence, our proposed tool helps users to decide between distinct models and to reduce the complexity of the resulting stack by removing overpromising and underperforming models. The applicability and effectiveness of StackGenVis are demonstrated with two use cases: a real-world healthcare data set and a collection of data related to sentiment/stance detection in texts. Finally, the tool has been evaluated through interviews with three ML experts.", "keywords": "Stacking,stacked generalization,ensemble learning,visual analytics,visualization", "link": "http://dx.doi.org/10.1109/TVCG.2020.3030352", "refList": ["10.1109/tvcg.2017.2744359", "10.1109/tip.2007.902329", "10.1109/tvcg.2014.2346979", "10.1090/mbk/069", "10.1002/acp.2350030302", "10.1109/tvcg.2018.2829750", "10.1080/03610927708827533", "10.1109/tvcg.2017.2653106", "10.3138/fm57-6770-u75u-7727", "10.2466/pms.104.3.707-721", "10.1002/0471691852", "10.1093/ptj/74.8.768", "10.1016/j.rse.2015.12.023", "10.1145/2207676.2208556", "10.1109/tvcg.2018.2865264", "10.1109/tvcg.2018.2865077", "10.3758/bf03201236", "10.1145/2858036.2858300", "10.1109/infvis.2005.1532136", "10.1109/infvis.2005.1532144", "10.1021/ac60214a047", "10.1109/tvcg.2015.2467671", "10.1007/s11634-011-0102-y", "10.1109/tvcg.2017.2787113", "10.1002/cta.4490080205", "10.2312/evs.20201053", "10.1109/ncvpripg.2011.34", "10.1145/3025453.3025922", "10.1109/tvcg.2018.2864884", "10.1016/0734-189x(83)90054-3", "10.1109/tvcg.2013.234", "10.1109/tvcg.2016.2598592", "10.1109/tvcg.2010.162", "10.1109/jrproc.1949.232969", "10.1119/1.14057", "10.2307/2003354", "10.2312/evs", "10.1109/34.211471", "10.1145/2702123.2702608"], "wos": 1, "children": [], "len": 1}, {"doi": "10.1111/cgf.13698", "year": "2019", "title": "Visual-Interactive Preprocessing of Multivariate Time Series Data", "conferenceName": "EuroVis", "authors": "J{\\\"{u}}rgen Bernard;Marco Hutter;Heiko Reinemuth;Hendrik Pfeifer;Christian Bors;J{\\\"{o}}rn Kohlhammer", "citationCount": "2", "affiliation": "Bernard, J (Corresponding Author), Tech Univ Darmstadt, Darmstadt, Germany.\nBernard, Juergen; Hutter, Marco; Reinemuth, Heiko; Pfeifer, Hendrik, Tech Univ Darmstadt, Darmstadt, Germany.\nBors, Christian, TU Wien, Vienna, Austria.\nKohlhammer, Joern, Fraunhofer IGD, Darmstadt, Germany.", "countries": "Germany;Austria", "abstract": "Pre-processing is a prerequisite to conduct effective and efficient downstream data analysis. Pre-processing pipelines often require multiple routines to address data quality challenges and to bring the data into a usable form. For both the construction and the refinement of pre-processing pipelines, human-in-the-loop approaches are highly beneficial. This particularly applies to multivariate time series, a complex data type with multiple values developing over time. Due to the high specificity of this domain, it has not been subject to in-depth research in visual analytics. We present a visual-interactive approach for preprocessing multivariate time series data with the following aspects. Our approach supports analysts to carry out six core analysis tasks related to pre-processing of multivariate time series. To support these tasks, we identify requirements to baseline toolkits that may help practitioners in their choice. We characterize the space of visualization designs for uncertainty-aware pre-processing and justify our decisions. Two usage scenarios demonstrate applicability of our approach, design choices, and uncertainty visualizations for the six analysis tasks. This work is one step towards strengthening the visual analytics support for data pre-processing in general and for uncertainty-aware pre-processing of multivariate time series in particular.", "keywords": "", "link": "https://doi.org/10.1111/cgf.13698", "refList": ["10.1016/j.engappai.2010.09.007", "10.1109/tvcg.2015.2467591", "10.1111/cgf.13190", "10.1177/1473871611416549", "10.1007/3-7908-1701-5\\_9", "10.1109/icdmw.2009.55", "10.3758/s13423-012-0247-5", "10.1109/pacificvis.2010.5429596", "10.1177/1473871611415994", "10.1117/12.2080001", "10.1145/2379776.2379788", "10.1145/3105971.3105984", "10.1016/j.patcog.2005.01.025", "10.1594/pangaea.150017", "10.1109/tvcg.2013.178", "10.1109/tvcg.2018.2859973", "10.1109/tvcg.2011.195", "10.1145/1126004.1126005", "10.1145/1656274.1656278", "10.1594/pangaea.804156", "10.1594/pangaea.787726", "10.1109/tvcg.2018.2865077", "10.1007/978-1-4471-6497-5\\_1", "10.2312/eurova.20151104", "10.1109/tvcg.2012.285", "10.1023/a:1024988512476", "10.1109/tvcg.2010.225", "10.1109/vast.2015.7347672", "10.1007/s00799-014-0134-y", "10.1109/tvcg.2016.2598495", "10.1109/tvcg.2018.2864907", "10.1007/s40430-018-1079-7", "10.1007/978-3-642-32498-7\\_5", "10.1111/cgf.13237", "10.1109/vast.2009.5332611", "10.1109/tvcg.2015.2467752", "10.1016/j.cviu.2006.08.002", "10.1109/tvcg.2014.2346321", "10.1145/1014052.1014104", "10.1007/978-3-540-71949-6", "10.2312/sca/sca10/001-010", "10.1145/3025453.3025738", "10.2312/eurova.20181112", "10.1109/pacificvis.2018.00034", "10.1007/978-0-85729-079-3\\_8", "10.1109/tvcg.2017.2779501", "10.1109/tvcg.2008.166", "10.1007/s10618-012-0285-7", "10.1109/tvcg.2013.222", "10.1109/tvcg.2018.2864889", "10.1109/tvcg.2016.2598592", "10.1109/vast.2010.5652530", "10.1145/2723372.2731081", "10.1109/tvcg.2018.2864914", "10.1109/infvis.2000.885098", "10.1016/j.neucom.2017.01.105", "10.2352/issn.2470-1173.2017.1.vda-387", "10.1109/tvcg.2015.2467851", "10.1109/tvcg.2016.2598468", "10.1109/tvcg.2016.2603178"], "wos": 1, "children": [{"doi": "10.1109/tvcg.2020.3030364", "title": "Supporting the Problem-Solving Loop: Designing Highly Interactive Optimisation Systems", "year": "2020", "conferenceName": "VAST", "authors": "Jie Liu;Tim Dwyer;Guido Tack;Samuel Gratzl;Kim Marriott", "citationCount": "0", "affiliation": "Liu, J (Corresponding Author), Monash Univ, Clayton, Vic, Australia. Liu, Jie; Dwyer, Tim; Tack, Guido; Gratzl, Samuel; Marriott, Kim, Monash Univ, Clayton, Vic, Australia.", "countries": "Australia", "abstract": "Efficient optimisation algorithms have become important tools for finding high-quality solutions to hard, real-world problems such as production scheduling, timetabling, or vehicle routing. These algorithms are typically \u201cblack boxes\u201d that work on mathematical models of the problem to solve. However, many problems are difficult to fully specify, and require a \u201chuman in the loop\u201d who collaborates with the algorithm by refining the model and guiding the search to produce acceptable solutions. Recently, the Problem-Solving Loop was introduced as a high-level model of such interactive optimisation. Here, we present and evaluate nine recommendations for the design of interactive visualisation tools supporting the Problem-Solving Loop. They range from the choice of visual representation for solutions and constraints to the use of a solution gallery to support exploration of alternate solutions. We first examined the applicability of the recommendations by investigating how well they had been supported in previous interactive optimisation tools. We then evaluated the recommendations in the context of the vehicle routing problem with time windows (VRPTW). To do so we built a sophisticated interactive visual system for solving VRPTW that was informed by the recommendations. Ten participants then used this system to solve a variety of routing problems. We report on participant comments and interaction patterns with the tool. These showed the tool was regarded as highly usable and the results generally supported the usefulness of the underlying recommendations.", "keywords": "Interactive optimisation,Interface design,Usability,Interactive systems and tools,Vehicle routing", "link": "http://dx.doi.org/10.1109/TVCG.2020.3030364", "refList": ["10.1176/appi.ajp.2018.18070881", "10.1006/obhd.1997.2679", "10.1109/vlhcc.2018.8506576", "10.1177/0956797611417632", "10.1177/0956797619830649", "10.1177/0049124115610347", "10.1177/1948550618775108", "10.1145/3313831.3376533", "10.1511/2014.111.460", "10.1145/2858036.2858465", "10.1145/3173574.3173606", "10.1177/1745691616658637", "10.1038/483531a", "10.1145/3173574.3174053", "10.1037/pspp0000186", "10.1016/j.jclinepi.2015.05.029", "10.1126/science.aac4716", "10.1145/985692.985782", "10.1080/02699931.2018.1524747", "10.1073/pnas.1402786111", "10.1145/3290605.3300295", "10.1111/cgf.13698", "10.1145/3290605.3300709", "10.2307/2686111", "10.1214/17-ba1091", "10.1145/1449715.1449732", "10.2139/ssrn.2694998", "10.1145/3313831.3376777", "10.1177/2515245917747646", "10.1145/3290605.3300754", "10.1145/3025453.3025626", "10.1109/tvcg.2014.2346321", "10.1037/gpr0000123", "10.2139/ssrn.2535453", "10.1145/3025453.3025738", "10.1038/533452a", "10.1177/1948550617714584", "10.1007/s11222-013-9416-2", "10.3389/fpsyg.2016.01832", "10.1038/s41562-018-0506-1", "10.1007/s11222-016-9696-4", "10.1177/1367006918763132", "10.1109/tsmc.1981.4308636", "10.1038/nrd3439-c1", "10.1177/0956797617723726", "10.1111/j.1467-8659.2012.03116.x", "10.1146/annurev-psych-122216-011836", "10.1145/3290605.3300432"], "wos": 1, "children": [], "len": 1}], "len": 3}], "len": 17}, {"doi": "10.1111/cgf.14035", "year": "2020", "title": "Survey on the Analysis of User Interactions and Visualization Provenance", "conferenceName": "EuroVis", "authors": "Kai Xu;Alvitta Ottley;Conny Walchshofer;Marc Streit;Remco Chang;John E. Wenskovitch", "citationCount": "0", "affiliation": "Xu, K (Corresponding Author), Middlesex Univ, London, England.\nXu, Kai, Middlesex Univ, London, England.\nOttley, Alvitta, Washington Univ, St Louis, MO 63110 USA.\nWalchshofer, Conny; Streit, Marc, Johannes Kepler Univ Linz, Linz, Austria.\nChang, Remco, Tufts Univ, Medford, MA 02155 USA.\nWenskovitch, John, Virginia Tech, Blacksburg, VA USA.", "countries": "USA;England;Austria", "abstract": "There is fast-growing literature on provenance-related research, covering aspects such as its theoretical framework, use cases, and techniques for capturing, visualizing, and analyzing provenance data. As a result, there is an increasing need to identify and taxonomize the existing scholarship. Such an organization of the research landscape will provide a complete picture of the current state of inquiry and identify knowledge gaps or possible avenues for further investigation. In this STAR, we aim to produce a comprehensive survey of work in the data visualization and visual analytics field that focus on the analysis of user interaction and provenance data. We structure our survey around three primary questions: (1) WHY analyze provenance data, (2) WHAT provenance data to encode and how to encode it, and (3) HOW to analyze provenance data. A concluding discussion provides evidence-based guidelines and highlights concrete opportunities for future development in this emerging area. The survey and papers discussed can be explored online interactively at https://provenance-survey.caleydo.org.", "keywords": "", "link": "https://doi.org/10.1111/cgf.14035", "refList": ["10.1145/3186266", "10.1145/3185524", "10.1109/tvcg.2014.2346575", "10.1109/tvcg.2016.2598471", "10.1109/tvcg.2016.2598446", "10.1145/2856767.2856779", "10.1109/tvcg.2017.2745278", "10.1109/tvcg.2015.2467871", "10.1109/tvcg.2019.2934668", "10.1145/3301275.3302307", "10.1145/2207676.2208293", "10.1111/cgf.13402", "10.1111/cgf.12895", "10.1145/1084805.1084812", "10.1145/2983923", "10.1007/978-1-4419-5874-7\\_12", "10.1109/mcg.2010.18", "10.1109/tvcg.2015.2467153", "10.1109/tvcg.2013.211", "10.1145/3172944.3172964", "10.1145/3290605.3300360", "10.1109/tvcg.2009.199", "10.1109/vast.2016.7883515", "10.1145/2207676.2208412", "10.1145/1979742.1979570", "10.1145/2207676.2208565", "10.1109/tvcg.2017.2745078", "10.1109/tvcg.2013.226", "10.1145/3301275.3302270", "10.1145/2882903.2882919", "10.1109/tvcg.2013.132", "10.1007/978-1-4614-3223-4\\_6", "10.1007/978-1-4899-7993-3\\_80747-1", "10.1145/2449396.2449439", "10.4230/dagrep.8.11.35", "10.1111/cgf.13424", "10.1109/tvcg.2015.2467613", "10.1109/mcse.2007.106", "10.1109/vast.2014.7042486", "10.1145/3126594.3126653", "10.1145/2591510", "10.1109/vast.2017.8585665", "10.1109/tvcg.2017.2744684", "10.1109/vast.2009.5333564", "10.1111/cgf.12631", "10.1145/2702123.2702262", "10.1111/cgf.13717", "10.2312/evs.20191181", "10.1111/cgf.12925", "10.1145/2702123.2702590", "10.1109/tvcg.2015.2467551", "10.1145/3025171.3025187", "10.1145/3316416.3316418", "10.1109/tvcg.2015.2468078", "10.1109/mcg.2014.73", "10.1109/tvcg.2017.2744479", "10.1109/tvcg.2018.2859969", "10.1109/tvcg.2014.2346321", "10.1109/tvcg.2007.70589", "10.1007/s13218-012-0167-6", "10.1111/cgf.13670", "10.1145/2807442.2807478", "10.1111/cgf.13715", "10.1109/tvcg.2012.23", "10.1109/tvcg.2017.2745279", "10.1109/tvcg.2013.164", "10.1109/vast.2008.4677365", "10.1145/3301275.3302291", "10.1109/tvcg.2012.260", "10.1109/tvcg.2010.177", "10.1109/tvcg.2018.2865024", "10.1109/mcg.2015.51", "10.1145/2240236.2240260", "10.1109/tvcg.2016.2599030.2", "10.1109/tvcg.2007.70515", "10.1109/tvcg.2012.175", "10.1109/mcg.2019.2941856", "10.1109/tvcg.2008.137", "10.1016/j.visinf.2018.09.003", "10.4304/jmm.9.5.635-643", "10.1109/tvcg.2017.2744843", "10.1111/cgf.13405", "10.1145/2633043", "10.1109/tvcg.2009.129", "10.1109/tvcg.2019.2934609", "10.1111/cgf.12924", "10.1145/2702123.2702376", "10.1109/vast.2017.8585669", "10.1145/1502650.1502695", "10.1111/cgf.13730", "10.1109/tvcg.2013.124", "10.1109/tvcg.2017.2744805", "10.1109/mcg.2009.49", "10.1109/vast.2015.7347625", "10.1145/3009973", "10.1145/2470654.2470723", "10.1109/vast.2016.7883520", "10.1109/vast.2014.7042492", "10.1145/2984511.2984588", "10.1111/cgf.12391", "10.1561/1900000006", "10.1007/s00778-017-0486-1", "10.1109/vast.2009.5333020", "10.1145/1926385.1926423", "10.1145/1057977.1057978", "10.1145/3290605.3300892", "10.1111/j.1467-8659.2011.01928.x", "10.1109/tvcg.2013.188", "10.1109/tvcg.2015.2467191", "10.1109/iccicct.2014.6993023", "10.1145/3290605.3300874", "10.1145/2557500.2557524", "10.1109/mcg.2015.91", "10.1109/vast.2012.6400494", "10.1109/tvcg.2013.220", "10.1109/mcg.2019.2945378", "10.1109/vast.2012.6400486", "10.1109/tvcg.2018.2865158", "10.1109/tvcg.2016.2598839", "10.1145/1142473.1142574", "10.1177/1555343416672782", "10.1109/vast.2011.6102449", "10.1111/cgf.12090", "10.1109/vast.2016.7883518", "10.1111/cgf.13678", "10.1109/mcg.2009.53", "10.1109/tvcg.2014.2346250", "10.1109/tvcg.2016.2598797", "10.1111/cgf.13400", "10.1109/tvcg.2014.2346573", "10.1080/01431160600746456", "10.1145/2642918.2647378", "10.1109/mcg.2019.2945720", "10.1145/2207676.2207741", "10.1145/3025171.3025189", "10.1145/634067.634292", "10.1109/tvcg.2015.2467611", "10.1109/tit.1982.1056489", "10.1109/tvcg.2018.2865117", "10.1109/vast.2009.5333023", "10.1145/3332165.3347866", "10.1109/mcg.2019.2933419", "10.1145/3184900", "10.1109/tvcg.2012.273", "10.1109/vast.2010.5652885", "10.1109/vast.2015.7347627", "10.1145/3290605.3300803", "10.1109/tvcg.2012.258", "10.1109/mcg.2009.87", "10.1109/tvcg.2019.2934556", "10.1145/1869397.1869399", "10.1109/mcg.2015.50", "10.1145/3172944.3172979", "10.1111/cgf.13208", "10.1111/cgf.12619", "10.1145/3290605.3300358", "10.1109/vast.2008.4677352", "10.1109/tvcg.2016.2598468", "10.1109/vast.2016.7883519", "10.1109/mcse.2008.79"], "wos": 1, "children": [], "len": 1}], "len": 21}, "index": 1184, "embedding": [0.6843297481536865, 0.5182435512542725, 0.8291565179824829, -1.7713910341262817, 0.29908648133277893, 0.16650904715061188, -0.7643030881881714, -0.9931802153587341, 0.26751384139060974, -0.9009531736373901, 2.3724241256713867, -0.5380550026893616, 0.07677968591451645, -0.7758724689483643, -0.8119193315505981, 0.10955015569925308, 0.7556531429290771, 0.06589167565107346, 1.0615683794021606, 1.406270980834961, -0.06630208343267441, -0.6124352812767029, 0.5523620247840881, -0.15392345190048218, -2.343374252319336, 0.05785536766052246, -0.2640359699726105, 0.7702187299728394, 0.3244888484477997, -0.8449201583862305, 0.9426021575927734, 0.2919069230556488], "projection": [-0.18009723722934723, 4.529698371887207], "size": 11, "height": 4, "width": 5}