{"data": {"doi": "10.1109/pacificvis48177.2020.1043", "year": "2020", "title": "AutoCaption: An Approach to Generate Natural Language Description from Visualization Automatically", "conferenceName": "PacificVis", "authors": "Can Liu;Liwenhan Xie;Yun Han;Datong Wei;Xiaoru Yuan", "citationCount": "0", "affiliation": "Yuan, XR (Corresponding Author), Peking Univ, Minist Educ, Key Lab Machine Percept, Beijing, Peoples R China.\nYuan, XR (Corresponding Author), Peking Univ, Sch EECS, Beijing, Peoples R China.\nYuan, XR (Corresponding Author), Peking Univ, Natl Engn Lab Big Data Anal \\& Applicat, Beijing, Peoples R China.\nLiu, Can; Xie, Liwenhan; Han, Yun; Wei, Datong; Yuan, Xiaoru, Peking Univ, Minist Educ, Key Lab Machine Percept, Beijing, Peoples R China.\nLiu, Can; Xie, Liwenhan; Han, Yun; Wei, Datong; Yuan, Xiaoru, Peking Univ, Sch EECS, Beijing, Peoples R China.\nYuan, Xiaoru, Peking Univ, Natl Engn Lab Big Data Anal \\& Applicat, Beijing, Peoples R China.", "countries": "China", "abstract": "In this paper, we propose a novel approach to generate captions for visualization charts automatically. In the proposed method, visual marks and visual channels, together with the associated text information in the original charts, are first extracted and identified with a multilayer perceptron classifier. Meanwhile, data information can also be retrieved by parsing visual marks with extracted mapping relationships. Then a 1-D convolutional residual network is employed to analyze the relationship between visual elements, and recognize significant features of the visualization charts, with both data and visual information as input. In the final step, the full description of the visual charts can be generated through a template-based approach. The generated captions can effectively cover the main visual features of the visual charts and support major feature types in commons charts. We further demonstrate the effectiveness of our approach through several cases.", "keywords": "", "link": "https://doi.org/10.1109/PacificVis48177.2020.1043", "refList": ["10.1145/1414471.1414525", "10.1111/cgf.13193", "10.1109/tvcg.2018.2865145", "10.1109/is.2002.1044219", "10.1145/2470654.2481374", "10.1080/13614568.2010.534186", "10.1017/s1351324997001502", "10.1145/3035918.3035922", "10.1109/cvpr.2016.90", "10.1145/2047196.2047247", "10.1007/s11257-006-9002-9", "10.1109/cvpr.2015.7298935", "10.1145/1148170.1148270", "10.1109/72.279181", "10.1109/icsmc.2011.6084067"], "wos": 1, "children": [], "len": 1}, "index": 260, "embedding": [-1.9954558610916138, -0.2517378628253937, -1.060706377029419, -0.32634517550468445, -0.17045269906520844, 0.16650904715061188, 5.380379676818848, 1.5225602388381958, 6.754868507385254, -0.5890102982521057, 2.0914499759674072, -0.920688271522522, 0.1905195266008377, 2.199202299118042, -0.678647518157959, -0.5592858791351318, -0.05316852033138275, 0.08175134658813477, -0.2071121335029602, 0.36516061425209045, -0.06630208343267441, 0.5449568629264832, -0.15046541392803192, -0.12925946712493896, -1.3074088096618652, 2.6810619831085205, -0.5500518083572388, -0.16255053877830505, -0.5349987745285034, -2.490147590637207, 0.27202510833740234, -0.905439555644989], "projection": [17.81463623046875, 3.554631233215332], "size": 1, "height": 1, "width": 1}