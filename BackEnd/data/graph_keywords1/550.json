{"data": {"doi": "10.1109/tvcg.2016.2598472", "title": "Blockwise Human Brain Network Visual Comparison Using NodeTrix Representation", "year": "2016", "conferenceName": "VAST", "authors": "Xinsong Yang;Lei Shi 0002;Madelaine Daianu;Hanghang Tong;Qingsong Liu;Paul M. Thompson", "citationCount": "16", "affiliation": "Shi, L (Corresponding Author), Chinese Acad Sci, SKLCS, Inst Software, Beijing 100864, Peoples R China. Yang, Xinsong; Shi, Lei; Liu, Qingsong, Chinese Acad Sci, SKLCS, Inst Software, Beijing 100864, Peoples R China. Yang, Xinsong, Beijing Univ Posts \\& Telecommun, Beijing 100864, Peoples R China. Daianu, Madelaine; Thompson, Paul, Univ Southern Calif, Mark \\& Mary Stevens Inst Neuroimaging \\& Informat, Imaging Genet Ctr, Los Angeles, CA USA. Tong, Hanghang, Arizona State Univ, Sch Comp, Informat \\& Decis Syst Engn, Tempe, AZ 85287 USA.", "countries": "USA;China", "abstract": "Visually comparing human brain networks from multiple population groups serves as an important task in the field of brain connectomics. The commonly used brain network representation, consisting of nodes and edges, may not be able to reveal the most compelling network differences when the reconstructed networks are dense and homogeneous. In this paper, we leveraged the block information on the Region Of Interest (ROI) based brain networks and studied the problem of blockwise brain network visual comparison. An integrated visual analytics framework was proposed. In the first stage, a two-level ROI block hierarchy was detected by optimizing the anatomical structure and the predictive comparison performance simultaneously. In the second stage, the NodeTrix representation was adopted and customized to visualize the brain network with block information. We conducted controlled user experiments and case studies to evaluate our proposed solution. Results indicated that our visual analytics method outperformed the commonly used node-link graph and adjacency matrix design in the blockwise network comparison tasks. We have shown compelling findings from two real-world brain network data sets, which are consistent with the prior connectomics studies.", "keywords": "Brain Network;Visual Comparison;Hybrid Representation", "link": "http://dx.doi.org/10.1109/TVCG.2016.2598472", "refList": ["10.1109/tvcg.2007.70582", "10.1177/1473871611416549", "10.1016/j.neuroimage.2014.04.048", "10.1007/s00371-013-0892-3", "10.1016/0006-8993(87)91107-3", "10.1523/jneurosci.4184-08.2009", "10.3389/fpsyg.2014.00761", "10.1109/isbi.2015.7163904", "10.1109/tvcg.2014.2346312", "10.1016/j.neuroimage.2013.04.111", "10.1523/jneurosci.2177-05.2005", "10.1016/j.biopsych.2011.01.032", "10.1109/tvcg.2015.2440252", "10.2312/vcbm/vcbm12/009-016", "10.1111/j.1749-6632.2010.05888.x", "10.1002/hbm.22830", "10.1001/archpsyc.60.6.585", "10.1109/tvcg.2015.2403323", "10.1089/brain.2012.0137", "10.1093/brain/88.3.585", "10.1080/10618600.2012.681250", "10.1109/tvcg.2010.244", "10.1145/2556288.2557010", "10.1016/j.dcn.2013.03.003", "10.1016/j.neuroimage.2013.05.013", "10.1126/scitranslmed.3001344", "10.1523/jneurosci.3941-09.2010", "10.1111/j.2517-6161.1996.tb02080.x", "10.1145/2470654.2470724", "10.1016/j.neuroimage.2005.03.026", "10.1002/cne.20768", "10.1016/j.neuroimage.2006.01.021", "10.1093/cercor/11.1.1", "10.1111/j.1467-8659.2009.01450.x", "10.2307/2300300"], "wos": 1, "children": [{"doi": "10.1109/tvcg.2017.2744159", "title": "StreetVizor: Visual Exploration of Human-Scale Urban Forms Based on Street Views", "year": "2017", "conferenceName": "SciVis", "authors": "Qiaomu Shen;Wei Zeng 0004;Yu Ye;Stefan M\u00fcller Arisona;Simon Schubiger-Banz;Remo Aslak Burkhard;Huamin Qu", "citationCount": "5", "affiliation": "Zeng, W (Corresponding Author), Swiss Fed Inst Technol, Future Cities Lab, Zurich, Switzerland. Shen, Qiaomu; Qu, Huamin, Hong Kong Univ Sci \\& Technol, Hong Kong, Peoples R China. Zeng, Wei; Burkhard, Remo, Swiss Fed Inst Technol, Future Cities Lab, Zurich, Switzerland. Ye, Yu, Tongji Univ, Shanghai, Peoples R China. Arisona, Stefan Muller; Schubiger, Simon, Univ Appl Sci \\& Arts Northwestern Switzerland FHN, Basel, Switzerland.", "countries": "Switzerland;China", "abstract": "Urban forms at human-scale, i.e., urban environments that individuals can sense (e.g., sight, smell, and touch) in their daily lives, can provide unprecedented insights on a variety of applications, such as urban planning and environment auditing. The analysis of urban forms can help planners develop high-quality urban spaces through evidence-based design. However, such analysis is complex because of the involvement of spatial, multi-scale (i.e., city, region, and street), and multivariate (e.g., greenery and sky ratios) natures of urban forms. In addition, current methods either lack quantitative measurements or are limited to a small area. The primary contribution of this work is the design of StreetVizor, an interactive visual analytics system that helps planners leverage their domain knowledge in exploring human-scale urban forms based on street view images. Our system presents two-stage visual exploration: 1) an AOI Explorer for the visual comparison of spatial distributions and quantitative measurements in two areas-of-interest (AOIs) at city- and region-scales; 2) and a Street Explorer with a novel parallel coordinate plot for the exploration of the fine-grained details of the urban forms at the street-scale. We integrate visualization techniques with machine learning models to facilitate the detection of street view patterns. We illustrate the applicability of our approach with case studies on the real-world datasets of four cities, i.e., Hong Kong, Singapore, Greater London and New York City. Interviews with domain experts demonstrate the effectiveness of our system in facilitating various analytical tasks.", "keywords": "Urban forms,human scale,street view,visual analytics", "link": "http://dx.doi.org/10.1109/TVCG.2017.2744159", "refList": ["10.1111/j.1467-8659.2008.01241.x", "10.2312/conf/eg2013/stars/095-116", "10.1109/tvcg.2013.226", "10.1177/1473871611416549", "10.1109/tvcg.2016.2520920", "10.1109/cvprw.2014.121", "10.1016/j.landurbplan.2014.08.005", "10.1109/tvcg.2013.221", "10.1109/vl.1996.545307", "10.1109/tvcg.2016.2598694", "10.1109/tvcg.2007.70523", "10.1007/s11390-013-1383-8", "10.1109/tvcg.2015.2467619", "10.1109/tvcg.2013.228", "10.1109/visual.1999.809866", "10.1109/tvcg.2015.2467199", "10.1109/tvcg.2008.193", "10.1109/34.1000236", "10.1109/2945.981848", "10.1007/s00371-012-0713-0", "10.1109/tvcg.2011.181", "10.1109/tvcg.2011.176", "10.1109/tvcg.2016.2598472", "10.1109/tbdata.2016.2586447", "10.1109/tvcg.2014.2346594", "10.1145/102377.115768", "10.1109/tvcg.2013.179", "10.1109/tvcg.2008.166", "10.1109/tvcg.2014.2346265", "10.1016/j.cities.2015.03.006", "10.1016/j.amepre.2010.09.034", "10.1145/2830541", "10.1016/j.ufug.2015.06.006", "10.1111/j.1467-8659.2009.01666.x", "10.1109/tvcg.2014.2346446", "10.1109/mc.2010.170", "10.1109/tvcg.2016.2598432"], "wos": 1, "children": [{"doi": "10.1109/tvcg.2019.2934671", "title": "A Natural-language-based Visual Query Approach of Uncertain Human Trajectories", "year": "2019", "conferenceName": "VAST", "authors": "Zhaosong Huang;Ye Zhao;Wei Chen;Shengjie Gao;Kejie Yu;Weixia Xu;MingJie Tang;Minfeng Zhu;Mingliang Xu", "citationCount": "0", "affiliation": "Chen, W (Corresponding Author), Zhejiang Univ, State Key Lab CAD \\& CG, Hangzhou, Peoples R China. Xu, ML (Corresponding Author), Zhengzhou Univ, Sch Informat Engn, Zhengzhou 450000, Peoples R China. Huang, Zhaosong; Chen, Wei; Gao, Shengjie; Yu, Kejie; Xu, Weixia; Zhu, Minfeng, Zhejiang Univ, State Key Lab CAD \\& CG, Hangzhou, Peoples R China. Zhao, Ye, Kent State Univ, Dept Comp Sci, Kent, OH 44242 USA. Tang, Mingjie, Ant Financial, San Mateo, CA USA. Xu, Mingliang, Zhengzhou Univ, Sch Informat Engn, Zhengzhou 450000, Peoples R China.", "countries": "USA;China", "abstract": "Visual querying is essential for interactively exploring massive trajectory data. However, the data uncertainty imposes profound challenges to fulfill advanced analytics requirements. On the one hand, many underlying data does not contain accurate geographic coordinates, e.g., positions of a mobile phone only refer to the regions (i.e., mobile cell stations) in which it resides, instead of accurate GPS coordinates. On the other hand, domain experts and general users prefer a natural way, such as using a natural language sentence, to access and analyze massive movement data. In this paper, we propose a visual analytics approach that can extract spatial-temporal constraints from a textual sentence and support an effective query method over uncertain mobile trajectory data. It is built up on encoding massive, spatially uncertain trajectories by the semantic information of the POls and regions covered by them, and then storing the trajectory documents in text database with an effective indexing scheme. The visual interface facilitates query condition specification, situation-aware visualization, and semantic exploration of large trajectory data. Usage scenarios on real-world human mobility datasets demonstrate the effectiveness of our approach.", "keywords": "Natural-language-based Visual Query,Spatial Uncertaity,Trajectory Exploration", "link": "http://dx.doi.org/10.1109/TVCG.2019.2934671", "refList": ["10.1017/s1351324909005129", "10.1109/tvcg.2013.226", "10.1109/tvcg.2018.2864503", "10.1561/1500000019", "10.1109/icde.2010.5447829", "10.1109/tvcg.2008.172", "10.1177/1473871612457601", "10.1145/2442810.2442828", "10.1109/pacificvis.2014.50", "10.1109/vast.2014.7042486", "10.1201/9781420008609.ch3", "10.1177/1473871613480062", "10.1109/tvcg.2017.2744159", "10.1145/2629592", "10.1109/tvcg.2016.2616404", "10.1109/vl.1996.545307", "10.5311/josis.2012.4.62", "10.5220/0005716900480059", "10.1109/tvcg.2018.2865049", "10.1109/tvcg.2015.2467619", "10.1109/tvcg.2015.2467771", "10.1109/tvcg.2011.233", "10.1186/s12859-015-0564-6", "10.1111/cgf.12114", "10.1108/eb026562", "10.1002/inc3.362", "10.1109/vast.2014.7042495", "10.1145/299917.299920", "10.1162/coli.2009.35.4.35403", "10.1016/j.datak.2007.10.008", "10.13140/2.1.2393.1847", "10.1109/tits.2017.2683539", "10.1109/tbdata.2017.2667700", "10.1177/1473871617692841", "10.1109/tits.2015.2436897", "10.1109/tvcg.2013.179", "10.1145/2339530.2339561", "10.1109/vast.2008.4677356", "10.1109/access.2016.2553681", "10.1109/tvcg.2017.2758362", "10.14778/2732232.2732235", "10.1109/tits.2017.2711644", "10.1162/jmlr.2003.3.4-5.993", "10.1145/330560.330692", "10.1109/tvcg.2014.2371856", "10.1111/cgf.12778", "10.1145/2743025", "10.1109/tnn.2003.820440", "10.1109/tvcg.2016.2598885", "10.1109/tits.2016.2639320", "10.1145/1341012.1341041", "10.1109/tvcg.2016.2598416", "10.1145/2501654.2501656", "10.1109/tvcg.2016.2598432", "10.1109/tvcg.2018.2865042"], "wos": 1, "children": [], "len": 1}, {"doi": "10.1109/tvcg.2020.3030370", "title": "TaxThemis: Interactive Mining and Exploration of Suspicious Tax Evasion Groups", "year": "2020", "conferenceName": "VAST", "authors": "Yating Lin;Kamkwai Wong;Yong Wang;Rong Zhang;Bo Dong;Huamin Qu;Qinghua Zheng", "citationCount": "0", "affiliation": "Lin, YT (Corresponding Author), Xi An Jiao Tong Univ, MOEKLINNS Lab, Xian, Shaanxi, Peoples R China. Lin, Yating; Zheng, Qinghua, Xi An Jiao Tong Univ, MOEKLINNS Lab, Xian, Shaanxi, Peoples R China. Wong, Kamkwai; Wang, Yong; Zhang, Rong; Qu, Huamin, Hong Kong Univ Sci \\& Technol, Hong Kong, Peoples R China. Dong, Bo, Xi An Jiao Tong Univ, Natl Engn Lab Big Data Analyt, Xian, Shaanxi, Peoples R China.", "countries": "China", "abstract": "Tax evasion is a serious economic problem for many countries, as it can undermine the government's tax system and lead to an unfair business competition environment. Recent research has applied data analytics techniques to analyze and detect tax evasion behaviors of individual taxpayers. However, they have failed to support the analysis and exploration of the related party transaction tax evasion (RPTTE) behaviors (e.g., transfer pricing), where a group of taxpayers is involved. In this paper, we present TaxThemis, an interactive visual analytics system to help tax officers mine and explore suspicious tax evasion groups through analyzing heterogeneous tax-related data. A taxpayer network is constructed and fused with the respective trade network to detect suspicious RPTTE groups. Rich visualizations are designed to facilitate the exploration and investigation of suspicious transactions between related taxpayers with profit and topological data analysis. Specifically, we propose a calendar heatmap with a carefully-designed encoding scheme to intuitively show the evidence of transferring revenue through related party transactions. We demonstrate the usefulness and effectiveness of TaxThemis through two case studies on real-world tax-related data and interviews with domain experts.", "keywords": "Visual Analytics,Tax Network,Tax Evasion Detection,Anomaly detection,Multidimensional data", "link": "http://dx.doi.org/10.1109/TVCG.2020.3030370", "refList": ["10.1111/cgf.12886", "10.2307/2277827", "10.1109/tvcg.2010.44", "10.1109/tits.2014.2315794", "10.1109/tvcg.2019.2934670", "10.1038/s41467-019-08987-4", "10.1111/cgf.12920", "10.1109/vast.2017.8585721", "10.1080/15230406.2015.1093431", "10.1109/tvcg.2018.2843369", "10.1038/srep01001", "10.1109/tvcg.2017.2744018", "10.1109/tvcg.2017.2744159", "10.1068/b130199p", "10.1109/tvcg.2009.143", "10.1016/j.visinf.2017.01.006", "10.1109/tvcg.2019.2892483", "10.1109/pacificvis.2017.8031583", "10.1109/pacificvis48177.2020.2785", "10.2307/2686111", "10.1109/tvcg.2015.2467199", "10.1111/cgf.12114", "10.1109/tvcg.2018.2865126", "10.1111/j.1538-4632.1996.tb00936.x", "10.1109/tvcg.2019.2934619", "10.2307/2332142", "10.1007/978-3-319-10590-1\\_53", "10.1109/cvpr.2016.485", "10.1109/cvpr.2017.17", "10.2307/2986645", "10.1109/tvcg.2014.2346321", "10.1017/s0140525x16001837", "10.1109/tvcg.2016.2598541", "10.1371/journal.pone.0207377", "10.1109/tvcg.2014.2346265", "10.1007/s4095-020-0191-7", "10.3141/1644-14", "10.1109/tvcg.2017.2744158", "10.1109/cvpr.2016.90", "10.1109/tvcg.2018.2865027", "10.1109/tvcg.2017.2785807", "10.1109/tvcg.2017.2744358", "10.1111/j.1538-4632.1995.tb00338.x", "10.1080/03081068808717359", "10.1109/tvcg.2016.2598831"], "wos": 1, "children": [], "len": 1}, {"doi": "10.1111/cgf.13673", "year": "2019", "title": "Multiple Views: different meanings and collocated words", "conferenceName": "EuroVis", "authors": "Jonathan C. Roberts;Hayder Al{-}Maneea;Peter W. S. Butcher;Robert Lew;Geraint Rees;Nirwan Sharma;Ana Frankenberg{-}Garcia", "citationCount": "1", "affiliation": "Roberts, JC (Corresponding Author), Bangor Univ, Bangor, Gwynedd, Wales.\nRoberts, J. C.; Al-maneea, H.; Butcher, P. W. S.; Sharma, N., Bangor Univ, Bangor, Gwynedd, Wales.\nAl-maneea, H., Basrah Univ, Basrah, Iraq.\nLew, R.; Rees, G., Adam Mickiewicz Univ, Poznan, Poland.\nFrankenberg-Garcia, A., Univ Surrey, Guildford, Surrey, England.", "countries": "Poland;Wales;England;Iraq", "abstract": "We report on an in-depth corpus linguistic study on multiple views' terminology and word collocation. We take a broad interpretation of these terms, and explore the meaning and diversity of their use in visualisation literature. First we explore senses of the term multiple views' (e.g., multiple views' can mean juxtaposition, many viewport projections or several alternative opinions). Second, we investigate term popularity and frequency of occurrences, investigating usage of multiple' and view' (e.g., multiple views, multiple visualisations, multiple sets). Third, we investigate word collocations and terms that have a similar sense (e.g., multiple views, side-by-side, small multiples). We built and used several corpora, including a 6-million-word corpus of all IEEE Visualisation conference articles published in IEEE Transactions on Visualisation and Computer Graphics 2012 to 2017. We draw on our substantial experience from early work in coordinated and multiple views, and with collocation analysis develop several lists of terms. This research provides insight into term use, a reference for novice and expert authors in visualisation, and contributes a taxonomy of multiple view' terms.", "keywords": "", "link": "https://doi.org/10.1111/cgf.13673", "refList": ["10.1109/tvcg.2017.2744359", "10.1109/38.31462", "10.1109/cmv.2003.1215002", "10.2307/2289444", "10.1016/j.ijhcs.2011.02.007", "10.1017/s0022112091210654", "10.1016/b978-008044531-1/50426-7", "10.1109/cmv.2003.1215001", "10.1109/tvcg.2013.134", "10.1117/12.378894", "10.1037/0096-1523.21.6.1494", "10.1057/palgrave.ivs.9500086", "10.1109/iv.2011.42", "10.1109/tvcg.2017.2744199", "10.4324/9780203810088", "10.1145/1321440.1321580", "10.1109/tvcg.2015.2467271", "10.1016/j.learninstruc.2006.03.001", "10.1145/345513.345282", "10.1007/s40607-014-0009-9", "10.1109/tvcg.2017.2743859", "10.1109/infvis.1997.636761", "10.1109/tvcg.2013.219", "10.1007/978-3-319-55627-7", "10.1109/tvcg.2009.111", "10.1109/iv.2008.21", "10.1109/infvis.2002.1173157", "10.1109/mcg.2014.82", "10.1145/3143699.3143717", "10.1109/tvcg.2012.226", "10.1145/345513.345271", "10.2478/jazcas-2018-0006", "10.1145/2556288.2556969", "10.1109/visual.1998.745282", "10.1145/1276377.1276427", "10.1109/infvis.2001.963283", "10.1007/978-1-4471-6497-5\\_1", "10.1109/visual.1994.346302", "10.1057/palgrave.ivs.9500068", "10.1109/tvcg.2006.160", "10.1109/visual.1990.146374", "10.1109/tvcg.2016.2614803", "10.1177/1473871611416549", "10.1109/tvcg.2017.2745878", "10.1109/tvcg.2006.69", "10.1109/tpami.1983.4767367", "10.1109/visual.1991.175794", "10.1109/tvcg.2017.2744159", "10.1109/tvcg.2017.2744198", "10.1109/32.328995", "10.1016/j.jeap.2018.07.003", "10.1016/j.geomorph.2012.08.021", "10.1109/tvcg.2014.2346920", "10.1109/2.917550", "10.1017/s0958344018000150", "10.1109/tvcg.2009.94", "10.1179/2051819613z.0000000003", "10.1109/vast.2008.4677370", "10.1117/12.309533", "10.1109/tvcg.2014.2346747", "10.1075/ijcl.13.4.06ray", "10.1007/s12650-015-0323-9", "10.1109/tvcg.2006.178", "10.1109/tvcg.2016.2615308", "10.2307/1269768", "10.2307/4132312", "10.1109/tvcg.2018.2864903", "10.1109/mis.2006.100", "10.1109/iv.1998.694193", "10.1007/s11192-015-1830-0", "10.1109/tvcg.2017.2744080", "10.1111/j.1467-9280.1997.tb00442.x", "10.1109/cmv.2007.20", "10.1109/infvis.2003.1249006", "10.1109/tvcg.2017.2745941", "10.1016/s1364-6613(99)01332-7", "10.1145/989863.989893", "10.1109/tse.1985.232211", "10.1109/tvcg.2017.2744184", "10.1109/infvis.2004.12", "10.1075/ijcl.17.3.04har", "10.1109/tvcg.2010.179", "10.1016/j.jss.2006.05.024", "10.1109/cmv.2003.1215005", "10.1109/tvcg.2017.2744358", "10.1145/2992154.2996365", "10.1109/tvcg.2016.2598827"], "wos": 1, "children": [{"doi": "10.1109/tvcg.2020.3030338", "title": "Composition and Configuration Patterns in Multiple-View Visualizations", "year": "2020", "conferenceName": "InfoVis", "authors": "Xi Chen;Wei Zeng 0004;Yanna Lin;Hayder Al-Maneea;Jonathan Roberts 0002;Remco Chang", "citationCount": "0", "affiliation": "Zeng, W (Corresponding Author), Chinese Acad Sci, Shenzhen Inst Adv Technol, Shenzhen, Peoples R China. Chen, Xi; Zeng, Wei; Lin, Yanna, Chinese Acad Sci, Shenzhen Inst Adv Technol, Shenzhen, Peoples R China. AI-maneea, Hayder Mahdi; Roberts, Jonathan, Bangor Univ, Bangor, Gwynedd, Wales. Chang, Remco, Tufts Univ, Medford, MA 02155 USA.", "countries": "USA;Wales;China", "abstract": "Multiple-view visualization (MV) is a layout design technique often employed to help users see a large number of data attributes and values in a single cohesive representation. Because of its generalizability, the MV design has been widely adopted by the visualization community to help users examine and interact with large, complex, and high-dimensional data. However, although ubiquitous, there has been little work to categorize and analyze MVs in order to better understand its design space. As a result, there has been little to no guideline in how to use the MV design effectively. In this paper, we present an in-depth study of how MVs are designed in practice. We focus on two fundamental measures of multiple-view patterns: composition, which quantifies what view types and how many are there; and configuration, which characterizes spatial arrangement of view layouts in the display space. We build a new dataset containing 360 images of MVs collected from IEEE VIS, EuroVis, and PacificVis publications 2011 to 2019, and make fine-grained annotations of view types and layouts for these visualization images. From this data we conduct composition and configuration analyses using quantitative metrics of term frequency and layout topology. We identify common practices around MVs, including relationship of view types, popular view layouts, and correlation between view types and layouts. We combine the findings into a MV recommendation system, providing interactive tools to explore the design space, and support example-based design.", "keywords": "Multiple views,design pattern,quantitative analysis,example-based design", "link": "http://dx.doi.org/10.1109/TVCG.2020.3030338", "refList": ["10.1109/tvcg.2018.2865235", "10.1109/tvcg.2016.2615308", "10.1145/2642918.2647398", "10.1177/1473871611416549", "10.1109/tvcg.2019.2934810", "10.1109/tvcg.2014.48", "10.1109/tvcg.2018.2864903", "10.1145/345513.345271", "10.1109/iv.1998.694193", "10.1109/tvcg.2007.70594", "10.1109/tvcg.2017.2744019", "10.1109/tvcg.2011.185", "10.1109/tvcg.2015.2467194", "10.1109/visual.1991.175815", "10.14778/2831360.2831371", "10.1109/mcg.2019.2924636", "10.1111/cgf.13673", "10.1111/cgf.12131", "10.1109/tvcg.2017.2744198", "10.1145/108360.108361", "10.1109/vl.1996.545307", "10.1109/tvcg.2017.2745140", "10.1109/cmv.2007.20", "10.1145/198366.198376", "10.1145/2508363.2508405", "10.1111/cgf.12114", "10.1109/icde.2018.00019", "10.1109/tvcg.2017.2787113", "10.1109/tvcg.2018.2865240", "10.1111/cgf.13380", "10.1111/cgf.12902", "10.1109/vast.2015.7347628", "10.2307/2288400", "10.1109/infvis.2004.12", "10.1145/102377.115768", "10.1109/tvcg.2009.179", "10.1109/2945.981851", "10.1109/tvcg.2007.70521", "10.1109/pacificvis.2012.6183556", "10.1145/2213836", "10.1109/tvcg.2013.234", "10.1109/iv.2008.87"], "wos": 1, "children": [], "len": 1}], "len": 3}], "len": 9}, {"doi": "10.1109/tvcg.2017.2744278", "title": "Abstractocyte: A Visual Tool for Exploring Nanoscale Astroglial Cells", "year": "2017", "conferenceName": "SciVis", "authors": "Haneen Mohammed;Ali K. Al-Awami;Johanna Beyer;Corrado Cal\u00ec;Pierre J. Magistretti;Hanspeter Pfister;Markus Hadwiger", "citationCount": "4", "affiliation": "Mohammed, H (Corresponding Author), KAUST, Thuwal 239556900, Saudi Arabia. Mohammed, Haneen; Al-Awami, Ali K.; Cali, Corrado; Magistretti, Pierre; Hadwiger, Markus, KAUST, Thuwal 239556900, Saudi Arabia. Beyer, Johanna; Pfister, Hanspeter, Harvard Univ, John A Paulson Sch Engn \\& Appl Sci, Cambridge, MA 02138 USA.", "countries": "USA;Arabia", "abstract": "This paper presents Abstractocyte, a system for the visual analysis of astrocytes and their relation to neurons, in nanoscale volumes of brain tissue. Astrocytes are glial cells, i.e., non-neuronal cells that support neurons and the nervous system. The study of astrocytes has immense potential for understanding brain function. However, their complex and widely-branching structure requires high-resolution electron microscopy imaging and makes visualization and analysis challenging. Furthermore, the structure and function of astrocytes is very different from neurons, and therefore requires the development of new visualization and analysis tools. With Abstractocyte, biologists can explore the morphology of astrocytes using various visual abstraction levels, while simultaneously analyzing neighboring neurons and their connectivity. We define a novel, conceptual 2D abstraction space for jointly visualizing astrocytes and neurons. Neuroscientists can choose a specific joint visualization as a point in this space. Interactively moving this point allows them to smoothly transition between different abstraction levels in an intuitive manner. In contrast to simply switching between different visualizations, this preserves the visual context and correlations throughout the transition. Users can smoothly navigate from concrete, highly-detailed 3D views to simplified and abstracted 2D views. In addition to investigating astrocytes, neurons, and their relationships, we enable the interactive analysis of the distribution of glycogen, which is of high importance to neuroscientists. We describe the design of Abstractocyte, and present three case studies in which neuroscientists have successfully used our system to assess astrocytic coverage of synapses, glycogen distribution in relation to synapses, and astrocytic-mitochondria coverage.", "keywords": "Connectomics,Neuroscience,Data Abstraction,Interactive 3D Visualization", "link": "http://dx.doi.org/10.1109/TVCG.2017.2744278", "refList": ["10.1371/journal.pone.0038011", "10.1109/tvcg.2008.153", "10.1007/s12021-014-9242-5", "10.1109/tvcg.2014.2346312", "10.1109/tvcg.2011.82", "10.1109/tvcg.2009.121", "10.1016/j.neuroimage.2012.02.075", "10.1016/j.neuroimage.2013.04.111", "10.1145/2702123.2702129", "10.1007/3-540-58950-3", "10.1109/isbi.2011.5872394", "10.1109/isbi.2011.5872397", "10.1016/j.gmod.2015.05.001", "10.1111/j.1365-2818.2010.03402.x", "10.1002/cne.23852", "10.1111/j.1365-2818.20.10.03402.x", "10.1109/tvcg.2002.1021579", "10.1109/tvcg.2016.2598472", "10.1002/spe.4380211102", "10.1002/cne.21974", "10.1007/978-3-319-27857-5\\_1", "10.1109/tvcg.2013.142", "10.1109/tvcg.2007.70539", "10.1126/science.1209168", "10.1109/tvcg.2015.2467441", "10.1145/2254556.2254653", "10.1109/biovis.2013.6664349"], "wos": 1, "children": [{"doi": "10.1109/tvcg.2019.2934402", "title": "CerebroVis: Designing an Abstract yet Spatially Contextualized Cerebral Artery Network Visualization", "year": "2019", "conferenceName": "InfoVis", "authors": "Aditeya Pandey;Harsh Shukla;Geoffrey S. Young;Lei Qin;Amir A. Zamani;Liangge Hsu;Raymond Huang;Cody Dunne;Michelle Borkin", "citationCount": "1", "affiliation": "Pandey, A (Corresponding Author), Northeastern Univ, Boston, MA 02115 USA. Pandey, Aditeya; Shukla, Harsh; Dunne, Cody; Borkin, Michelle A., Northeastern Univ, Boston, MA 02115 USA. Young, Geoffrey S.; Zamani, Amir A.; Hsu, Liangge; Huang, Raymond, Brigham \\& Womens Hosp, Boston, MA 02115 USA. Qin, Lei, Dana Farber Canc Inst, Boston, MA 02115 USA.", "countries": "USA", "abstract": "Blood circulation in the human brain is supplied through a network of cerebral arteries. If a clinician suspects a patient has a stroke or other cerebrovascular condition, they order imaging tests. Neuroradiologists visually search the resulting scans for abnormalities. Their visual search tasks correspond to the abstract network analysis tasks of browsing and path following. To assist neuroradiologists in identifying cerebral artery abnormalities, we designed CerebroVis, a novel abstract\u2014yet spatially contextualized\u2014cerebral artery network visualization. In this design study, we contribute a novel framing and definition of the cerebral artery system in terms of network theory and characterize neuroradiologist domain goals as abstract visualization and network analysis tasks. Through an iterative, user-centered design process we developed an abstract network layout technique which incorporates cerebral artery spatial context. The abstract visualization enables increased domain task performance over 3D geometry representations, while including spatial context helps preserve the user's mental map of the underlying geometry. We provide open source implementations of our network layout technique and prototype cerebral artery visualization tool. We demonstrate the robustness of our technique by successfully laying out 61 open source brain scans. We evaluate the effectiveness of our layout through a mixed methods study with three neuroradiologists. In a formative controlled experiment our study participants used CerebroVis and a conventional 3D visualization to examine real cerebral artery imaging data to identify a simulated intracranial artery stenosis. Participants were more accurate at identifying stenoses using CerebroVis (absolute risk difference 13%). A free copy of this paper, the evaluation stimuli and data, and source code are available at osf.io/e5sxt.", "keywords": "Network Visualization,Spatial Context,Abstract Design,Flow Network,Medical Imaging,Cerebral Arteries", "link": "http://dx.doi.org/10.1109/TVCG.2019.2934402", "refList": ["10.1109/tvcg.2007.70582", "10.1093/bib/bbr069", "10.1145/323233.323254", "10.1109/tvcg.2008.165", "10.1145/234535.234538", "10.1109/tvcg.2008.117", "10.3174/ajnr.a1234", "10.1145/1360612.1360699", "10.1109/tse.1981.234519", "10.1007/3-540-63938-1\\_67", "10.1109/tvcg.2014.2346312", "10.1161/01.str.14.5.756", "10.1016/b978-008044531-1/50426-7", "10.1109/tvcg.2011.185", "10.1016/j.pharmthera.2013.01.016", "10.1109/tvcg.2013.231", "10.3102/0013189x033007014", "10.1186/1471-2105-10-375", "10.1111/j.1467-8659.2008.01205.x", "10.1109/mcg.2011.103", "10.1109/wvl.1989.77035", "10.3174/ajnr.a0689", "10.1109/isre.1993.324822", "10.1007/978-3-319-27261-0\\_50", "10.1109/tvcg.2010.79", "10.1111/1467-9884.00149", "10.1007/978-3-540-70904-6\\_19", "10.1109/tvcg.2011.192", "10.1109/tvcg.2013.124", "10.1145/774833.774859", "10.1007/s10851-013-0473-0", "10.1002/(sici)1097-024x(199612)26:121415::aid-spe693.3.co", "2-g", "10.1109/tvcg.2011.193", "10.3141/2392-06", "10.1109/42.41482", "10.1007/978-3-642-21608-4.7", "10.1109/tvcg.2016.2598472", "10.1155/2015/450341", "10.1002/spe.4380211102", "10.1145/1168149.1168168", "10.1093/neuros/nyx325", "10.1117/12.2079420", "10.1098/rstb.2005.1637", "10.1016/j.neuroimage.2013.05.089", "10.1145/2470654.2470724", "10.1111/j.1365-2125.2011.04061.x", "10.1148/rg.263055186", "10.1109/tvcg.2012.213", "10.2471/blt.16.181636", "10.1023/a:1009771921595", "10.1109/tsmc.1981.4308636", "10.1109/tvcg.2014.2346276", "10.1145/1201775.882291", "10.1109/tvcg.2017.2744278", "10.1109/tvcg.2009.111", "10.1214/11-ejs612", "10.1147/jrd.2015.2411412", "10.1161/01.str.0000041999.64363.b2"], "wos": 1, "children": [], "len": 1}, {"doi": "10.1109/tvcg.2019.2934334", "title": "Scale Trotter: Illustrative Visual Travels Across Negative Scales", "year": "2019", "conferenceName": "SciVis", "authors": "Sarkis Halladjian;Haichao Miao;David Kouril;M. Eduard Gr\u00f6ller;Ivan Viola;Tobias Isenberg", "citationCount": "1", "affiliation": "Halladjian, S (Corresponding Author), INRIA, Paris, France. Halladjian, S (Corresponding Author), Univ Paris Saclay, St Aubin, France. Halladjian, Sarkis; Isenberg, Tobias, INRIA, Paris, France. Halladjian, Sarkis, Univ Paris Saclay, St Aubin, France. Miao, Haichao; Kouril, David; Groller, M. Eduard, TU Wien, Vienna, Austria. Groller, M. Eduard, VRVis Res Ctr, Vienna, Austria. Viola, Ivan, King Abdullah Univ Sci \\& Technol, Thuwal, Saudi Arabia.", "countries": "Arabia;France;Austria", "abstract": "We present ScaleTrotter, a conceptual framework for an interactive, multi-scale visualization of biological mesoscale data and, specifically, genome data. ScaleTrotter allows viewers to smoothly transition from the nucleus of a cell to the atomistic composition of the DNA, while bridging several orders of magnitude in scale. The challenges in creating an interactive visualization of genome data are fundamentally different in several ways from those in other domains like astronomy that require a multi-scale representation as well. First, genome data has intertwined scale levels\u2014the DNA is an extremely long, connected molecule that manifests itself at all scale levels. Second, elements of the DNA do not disappear as one zooms out\u2014instead the scale levels at which they are observed group these elements differently. Third, we have detailed information and thus geometry for the entire dataset and for all scale levels, posing a challenge for interactive visual exploration. Finally, the conceptual scale levels for genome data are close in scale space, requiring us to find ways to visually embed a smaller scale into a coarser one. We address these challenges by creating a new multi-scale visualization concept. We use a scale-dependent camera model that controls the visual embedding of the scales into their respective parents, the rendering of a subset of the scale hierarchy, and the location, size, and scope of the view. In traversing the scales, ScaleTrotter is roaming between 2D and 3D visual representations that are depicted in integrated visuals. We discuss, specifically, how this form of multi-scale visualization follows from the specific characteristics of the genome data and describe its implementation. Finally, we discuss the implications of our work to the general illustrative depiction of multi-scale data.", "keywords": "Multi-scale visualization,scale transition,abstraction,human genome,DNA,Hi-C data", "link": "http://dx.doi.org/10.1109/TVCG.2019.2934334", "refList": ["10.1126/science.291.5507.1177", "10.1038/nrneph.2010.55", "10.1016/j.jmb.2018.06.009", "10.1109/tvcg.2017.2744518", "10.1109/tvcg.2017.2743958", "10.1111/j.1467-8659.2012.03128.x", "10.1145/1507149.1507186", "10.1111/j.1467-8659.2012.03082.x", "10.1109/tvcg.2007.2", "10.1145/2024156.2024165", "10.1201/b17511", "10.1038/srep20802", "10.1145/1239451.1239482", "10.1109/mcg.2005.34", "10.1111/cgf.13429", "10.1186/1471-2105-11-444", "10.1109/tvcg.2015.2403323", "10.2312/vcbm.20151209", "10.1109/ldav.2016.7874310", "10.3791/1869", "10.1109/tvcg.2017.2747545", "10.1109/tvcg.2017.2743981", "10.1111/cgf.12892", "10.1126/science.aag0025", "10.1101/gr.213611.116", "10.2312/eurovisshort.20171146", "10.1109/mcg.2008.63", "10.1111/cgf.12349", "10.1017/s0890060411000230", "10.1109/tvcg.2007.70591", "10.1109/infvis.2004.12", "10.1111/cgf.13202", "10.2312/vissym/eurovis05/303-310", "10.1111/cgf.13072", "10.1016/j.jmb.2018.09.004", "10.1111/j.1467-8659.2011.01917.x", "10.1111/cgf.12197", "10.2312/eurovisstar.20151112", "10.1086/344286", "10.1093/nar/gks586", "10.2312/ega.20101005", "10.1186/s13059-018-1486-1", "10.1109/visual.2004.103", "10.1111/j.1467-8659.2009.01692.x", "10.1109/tvcg.2017.2744278", "10.1109/tvcg.2012.159", "10.1109/tvcg.2018.2864507", "10.1038/nrm1225", "10.1109/tvcg.2016.2598866"], "wos": 1, "children": [{"doi": "10.1109/tvcg.2020.3030415", "title": "Modeling in the Time of COVID-19: Statistical and Rule-based Mesoscale Models", "year": "2020", "conferenceName": "SciVis", "authors": "Ngan Nguyen;Ondrej Strnad;Tobias Klein;Deng Luo;Ruwayda Alharbi;Peter Wonka;Martina Maritan;Peter Mindek;Ludovic Autin;David S. Goodsell;Ivan Viola", "citationCount": "0", "affiliation": "Nguyen, N (Corresponding Author), King Abdullah Univ Sci \\& Technol KAUST, Thuwal, Saudi Arabia. Nguyen, Ngan; Strnad, Ondrej; Luo, Deng; Alharbi, Ruwayda; Wonka, Peter; Viola, Ivan, King Abdullah Univ Sci \\& Technol KAUST, Thuwal, Saudi Arabia. Klein, Tobias; Mindek, Peter, TU Wien, Vienna, Austria. Klein, Tobias; Mindek, Peter, Nanographics GmbH, Vienna, Austria. Maritan, Martina; Autin, Ludovic; Goodsell, David S., Scripps Res Inst, La Jolla, CA 92037 USA.", "countries": "USA;Arabia;Austria", "abstract": "We present a new technique for the rapid modeling and construction of scientifically accurate mesoscale biological models. The resulting 3D models are based on a few 2D microscopy scans and the latest knowledge available about the biological entity, represented as a set of geometric relationships. Our new visual-programming technique is based on statistical and rule-based modeling approaches that are rapid to author, fast to construct, and easy to revise. From a few 2D microscopy scans, we determine the statistical properties of various structural aspects, such as the outer membrane shape, the spatial properties, and the distribution characteristics of the macromolecular elements on the membrane. This information is utilized in the construction of the 3D model. Once all the imaging evidence is incorporated into the model, additional information can be incorporated by interactively defining the rules that spatially characterize the rest of the biological entity, such as mutual interactions among macromolecules, and their distances and orientations relative to other structures. These rules are defined through an intuitive 3D interactive visualization as a visual-programming feedback loop. We demonstrate the applicability of our approach on a use case of the modeling procedure of the SARS-CoV-2 virion ultrastructure. This atomistic model, which we present here, can steer biological research to new promising directions in our efforts to fight the spread of the virus.", "keywords": "molecular visualization,mesoscale modeling", "link": "http://dx.doi.org/10.1109/TVCG.2020.3030415", "refList": ["10.1145/2187836.2187957", "10.1109/tvcg.2009.157", "10.1099/0022-1317-39-3-545", "10.1007/978-3-319-73915-1\\_31", "10.1109/tvcg.2013.158", "10.1016/j.cag.2013.01.010", "10.1109/vast.2009.5333893", "10.1038/s41594-020-0468-7", "10.1145/174462.156635", "10.1038/nmeth.f.301", "10.1038/s41586-020-2008-3", "10.1016/j.jsb.2010.11.021", "10.7554/elife.57309", "10.1109/tvcg.2017.2744518", "10.1007/s00371-017-1397-2", "10.1109/tvcg.2017.2744258", "10.1111/cgf.13373", "10.1016/0022-5193(68)90079-9", "10.1111/j.1467-8659.2012.03128.x", "10.1145/2897824.2925951", "10.1007/978-3-319-28661-7\\_5", "10.1128/jvi.00645-06", "10.1016/bs.aivir.2016.08.005", "10.1007/978-3-319-50106-2\\_29", "10.1007/978-3-319-50106-2\\_30", "10.1107/s0907444910007493", "10.1093/gigascience/giz064", "10.1007/s11540-006-9010-5", "10.1111/cgf.13640", "10.1109/tvcg.2006.115", "10.1145/3130800.3130804", "10.1016/j.bbamem.2018.02.017", "10.1111/cgf.13816", "10.1021/acs.jctc.9b00453", "10.1016/j.jmgm.2016.07.008", "10.1126/science.abc6952", "10.1007/978-3-319-27261-0\\_16", "10.1007/978-3-319-73915-1\\_29", "10.1146/annurev.bb.06.060177.001055", "10.1002/(sici)1097-0282(199603)38:3", "10.1109/tvcg.2019.2934334", "10.1145/357306.357310", "10.1111/j.1467-8659.2009.01612.x", "10.3238/arztebl.2011.0087", "10.1093/bioinformatics/bty272", "10.1007/978-3-319-07121-35", "10.1107/s0021889883010985", "10.1101/2020.03.25.008904", "10.1126/science.abb9983", "10.1002/jcc.21861", "10.1111/cgf.12197", "10.1145/3197517.3201393", "10.1016/j.tibs.2020.02.010", "10.1007/s13238-016-0352-8", "10.1101/2020.06.26.173476", "10.1145/882262.882291", "10.1109/mcg.2018.2877076", "10.1093/nar/gkh468", "10.1038/nsb1203-980", "10.1007/978-3-319-07121-3\\_5", "10.1093/nar/gky427", "10.1111/cgf.12370", "10.1109/38.310720", "10.1038/nmeth.3204", "10.1109/tvcg.2016.2603178"], "wos": 1, "children": [], "len": 1}], "len": 3}, {"doi": "10.1111/cgf.13429", "year": "2018", "title": "DimSUM: Dimension and Scale Unifying Map for Visual Abstraction of DNA Origami Structures", "conferenceName": "EuroVis", "authors": "Haichao Miao;Elisa De Llano;Tobias Isenberg;M. Eduard Gr{\\\"{o}}ller;Ivan Barisic;Ivan Viola", "citationCount": "6", "affiliation": "Miao, H (Corresponding Author), TU Wien, Vienna, Austria.\nMiao, H (Corresponding Author), Austrian Inst Technol, Seibersdorf, Austria.\nMiao, H.; Groeller, M. E.; Viola, I., TU Wien, Vienna, Austria.\nMiao, H.; De Llano, E.; Barisic, I., Austrian Inst Technol, Seibersdorf, Austria.\nIsenberg, T., Inria, Paris, France.\nIsenberg, T., Univ Paris Saclay, Paris, France.\nGroeller, M. E., VRVis Res Ctr, Graz, Austria.", "countries": "France;Austria", "abstract": "We present a novel visualization concept for DNA origami structures that integrates a multitude of representations into a Dimension and Scale Unifying Map (DimSUM). This novel abstraction map provides means to analyze, smoothly transition between, and interact with many visual representations of the DNA origami structures in an effective way that was not possible before. DNA origami structures are nanoscale objects, which are challenging to model in silico. In our holistic approach we seamlessly combine three-dimensional realistic shape models, two-dimensional diagrammatic representations, and ordered alignments in one-dimensional arrangements, with semantic transitions across many scales. To navigate through this large, two-dimensional abstraction map we highlight locations that users frequently visit for certain tasks and datasets. Particularly interesting viewpoints can be explicitly saved to optimize the workflow. We have developed DimSUM together with domain scientists specialized in DNA nanotechnology. In the paper we discuss our design decisions for both the visualization and the interaction techniques. We demonstrate two practical use cases in which our approach increases the specialists' understanding and improves their effectiveness in the analysis. Finally, we discuss the implications of our concept for the use of controlled abstraction in visualization in general.", "keywords": "", "link": "https://doi.org/10.1111/cgf.13429", "refList": ["10.1146/annurev.biophys.32.110601.141800", "10.2307/1269768", "10.1016/j.comgeo.2004.11.002", "10.1006/ijhc.2002.1017", "10.1109/visual.1991.175794", "10.1006/ijhc.1017", "10.1016/0022-5193(82)90002-9", "10.1109/cmv.2007.20", "10.1111/j.1467-8659.2012.03081.x", "10.1109/tvcg.2017.2747545", "10.1093/nar/gkg680", "10.2312/vcbm.20151209", "10.1111/j.1467-8659.2012.03085.x", "10.1109/tvcg.2017.2743981", "10.1179/1743277412y.0000000007", "10.1109/tvcg.2009.141", "10.1109/tvcg.2007.70578", "10.1038/171737a0", "10.1126/science.aaf4388", "10.1111/cgf.12349", "10.1007/978-3-540-33037-0\\_10", "10.1093/nar/gks596", "10.1093/nar/gkp436", "10.1111/j.1467-8659.2011.01917.x", "10.1038/nature04586", "10.1038/nature14586", "10.1038/nmeth.1570", "10.1109/tvcg.2017.2744278", "10.1007/978-3-540-33037-010"], "wos": 1, "children": [{"doi": "10.1109/tvcg.2019.2934334", "title": "Scale Trotter: Illustrative Visual Travels Across Negative Scales", "year": "2019", "conferenceName": "SciVis", "authors": "Sarkis Halladjian;Haichao Miao;David Kouril;M. Eduard Gr\u00f6ller;Ivan Viola;Tobias Isenberg", "citationCount": "1", "affiliation": "Halladjian, S (Corresponding Author), INRIA, Paris, France. Halladjian, S (Corresponding Author), Univ Paris Saclay, St Aubin, France. Halladjian, Sarkis; Isenberg, Tobias, INRIA, Paris, France. Halladjian, Sarkis, Univ Paris Saclay, St Aubin, France. Miao, Haichao; Kouril, David; Groller, M. Eduard, TU Wien, Vienna, Austria. Groller, M. Eduard, VRVis Res Ctr, Vienna, Austria. Viola, Ivan, King Abdullah Univ Sci \\& Technol, Thuwal, Saudi Arabia.", "countries": "Arabia;France;Austria", "abstract": "We present ScaleTrotter, a conceptual framework for an interactive, multi-scale visualization of biological mesoscale data and, specifically, genome data. ScaleTrotter allows viewers to smoothly transition from the nucleus of a cell to the atomistic composition of the DNA, while bridging several orders of magnitude in scale. The challenges in creating an interactive visualization of genome data are fundamentally different in several ways from those in other domains like astronomy that require a multi-scale representation as well. First, genome data has intertwined scale levels\u2014the DNA is an extremely long, connected molecule that manifests itself at all scale levels. Second, elements of the DNA do not disappear as one zooms out\u2014instead the scale levels at which they are observed group these elements differently. Third, we have detailed information and thus geometry for the entire dataset and for all scale levels, posing a challenge for interactive visual exploration. Finally, the conceptual scale levels for genome data are close in scale space, requiring us to find ways to visually embed a smaller scale into a coarser one. We address these challenges by creating a new multi-scale visualization concept. We use a scale-dependent camera model that controls the visual embedding of the scales into their respective parents, the rendering of a subset of the scale hierarchy, and the location, size, and scope of the view. In traversing the scales, ScaleTrotter is roaming between 2D and 3D visual representations that are depicted in integrated visuals. We discuss, specifically, how this form of multi-scale visualization follows from the specific characteristics of the genome data and describe its implementation. Finally, we discuss the implications of our work to the general illustrative depiction of multi-scale data.", "keywords": "Multi-scale visualization,scale transition,abstraction,human genome,DNA,Hi-C data", "link": "http://dx.doi.org/10.1109/TVCG.2019.2934334", "refList": ["10.1126/science.291.5507.1177", "10.1038/nrneph.2010.55", "10.1016/j.jmb.2018.06.009", "10.1109/tvcg.2017.2744518", "10.1109/tvcg.2017.2743958", "10.1111/j.1467-8659.2012.03128.x", "10.1145/1507149.1507186", "10.1111/j.1467-8659.2012.03082.x", "10.1109/tvcg.2007.2", "10.1145/2024156.2024165", "10.1201/b17511", "10.1038/srep20802", "10.1145/1239451.1239482", "10.1109/mcg.2005.34", "10.1111/cgf.13429", "10.1186/1471-2105-11-444", "10.1109/tvcg.2015.2403323", "10.2312/vcbm.20151209", "10.1109/ldav.2016.7874310", "10.3791/1869", "10.1109/tvcg.2017.2747545", "10.1109/tvcg.2017.2743981", "10.1111/cgf.12892", "10.1126/science.aag0025", "10.1101/gr.213611.116", "10.2312/eurovisshort.20171146", "10.1109/mcg.2008.63", "10.1111/cgf.12349", "10.1017/s0890060411000230", "10.1109/tvcg.2007.70591", "10.1109/infvis.2004.12", "10.1111/cgf.13202", "10.2312/vissym/eurovis05/303-310", "10.1111/cgf.13072", "10.1016/j.jmb.2018.09.004", "10.1111/j.1467-8659.2011.01917.x", "10.1111/cgf.12197", "10.2312/eurovisstar.20151112", "10.1086/344286", "10.1093/nar/gks586", "10.2312/ega.20101005", "10.1186/s13059-018-1486-1", "10.1109/visual.2004.103", "10.1111/j.1467-8659.2009.01692.x", "10.1109/tvcg.2017.2744278", "10.1109/tvcg.2012.159", "10.1109/tvcg.2018.2864507", "10.1038/nrm1225", "10.1109/tvcg.2016.2598866"], "wos": 1, "children": [{"doi": "10.1109/tvcg.2020.3030415", "title": "Modeling in the Time of COVID-19: Statistical and Rule-based Mesoscale Models", "year": "2020", "conferenceName": "SciVis", "authors": "Ngan Nguyen;Ondrej Strnad;Tobias Klein;Deng Luo;Ruwayda Alharbi;Peter Wonka;Martina Maritan;Peter Mindek;Ludovic Autin;David S. Goodsell;Ivan Viola", "citationCount": "0", "affiliation": "Nguyen, N (Corresponding Author), King Abdullah Univ Sci \\& Technol KAUST, Thuwal, Saudi Arabia. Nguyen, Ngan; Strnad, Ondrej; Luo, Deng; Alharbi, Ruwayda; Wonka, Peter; Viola, Ivan, King Abdullah Univ Sci \\& Technol KAUST, Thuwal, Saudi Arabia. Klein, Tobias; Mindek, Peter, TU Wien, Vienna, Austria. Klein, Tobias; Mindek, Peter, Nanographics GmbH, Vienna, Austria. Maritan, Martina; Autin, Ludovic; Goodsell, David S., Scripps Res Inst, La Jolla, CA 92037 USA.", "countries": "USA;Arabia;Austria", "abstract": "We present a new technique for the rapid modeling and construction of scientifically accurate mesoscale biological models. The resulting 3D models are based on a few 2D microscopy scans and the latest knowledge available about the biological entity, represented as a set of geometric relationships. Our new visual-programming technique is based on statistical and rule-based modeling approaches that are rapid to author, fast to construct, and easy to revise. From a few 2D microscopy scans, we determine the statistical properties of various structural aspects, such as the outer membrane shape, the spatial properties, and the distribution characteristics of the macromolecular elements on the membrane. This information is utilized in the construction of the 3D model. Once all the imaging evidence is incorporated into the model, additional information can be incorporated by interactively defining the rules that spatially characterize the rest of the biological entity, such as mutual interactions among macromolecules, and their distances and orientations relative to other structures. These rules are defined through an intuitive 3D interactive visualization as a visual-programming feedback loop. We demonstrate the applicability of our approach on a use case of the modeling procedure of the SARS-CoV-2 virion ultrastructure. This atomistic model, which we present here, can steer biological research to new promising directions in our efforts to fight the spread of the virus.", "keywords": "molecular visualization,mesoscale modeling", "link": "http://dx.doi.org/10.1109/TVCG.2020.3030415", "refList": ["10.1145/2187836.2187957", "10.1109/tvcg.2009.157", "10.1099/0022-1317-39-3-545", "10.1007/978-3-319-73915-1\\_31", "10.1109/tvcg.2013.158", "10.1016/j.cag.2013.01.010", "10.1109/vast.2009.5333893", "10.1038/s41594-020-0468-7", "10.1145/174462.156635", "10.1038/nmeth.f.301", "10.1038/s41586-020-2008-3", "10.1016/j.jsb.2010.11.021", "10.7554/elife.57309", "10.1109/tvcg.2017.2744518", "10.1007/s00371-017-1397-2", "10.1109/tvcg.2017.2744258", "10.1111/cgf.13373", "10.1016/0022-5193(68)90079-9", "10.1111/j.1467-8659.2012.03128.x", "10.1145/2897824.2925951", "10.1007/978-3-319-28661-7\\_5", "10.1128/jvi.00645-06", "10.1016/bs.aivir.2016.08.005", "10.1007/978-3-319-50106-2\\_29", "10.1007/978-3-319-50106-2\\_30", "10.1107/s0907444910007493", "10.1093/gigascience/giz064", "10.1007/s11540-006-9010-5", "10.1111/cgf.13640", "10.1109/tvcg.2006.115", "10.1145/3130800.3130804", "10.1016/j.bbamem.2018.02.017", "10.1111/cgf.13816", "10.1021/acs.jctc.9b00453", "10.1016/j.jmgm.2016.07.008", "10.1126/science.abc6952", "10.1007/978-3-319-27261-0\\_16", "10.1007/978-3-319-73915-1\\_29", "10.1146/annurev.bb.06.060177.001055", "10.1002/(sici)1097-0282(199603)38:3", "10.1109/tvcg.2019.2934334", "10.1145/357306.357310", "10.1111/j.1467-8659.2009.01612.x", "10.3238/arztebl.2011.0087", "10.1093/bioinformatics/bty272", "10.1007/978-3-319-07121-35", "10.1107/s0021889883010985", "10.1101/2020.03.25.008904", "10.1126/science.abb9983", "10.1002/jcc.21861", "10.1111/cgf.12197", "10.1145/3197517.3201393", "10.1016/j.tibs.2020.02.010", "10.1007/s13238-016-0352-8", "10.1101/2020.06.26.173476", "10.1145/882262.882291", "10.1109/mcg.2018.2877076", "10.1093/nar/gkh468", "10.1038/nsb1203-980", "10.1007/978-3-319-07121-3\\_5", "10.1093/nar/gky427", "10.1111/cgf.12370", "10.1109/38.310720", "10.1038/nmeth.3204", "10.1109/tvcg.2016.2603178"], "wos": 1, "children": [], "len": 1}], "len": 3}], "len": 5}, {"doi": "10.1111/cgf.13700", "year": "2019", "title": "Interactive Volumetric Visual Analysis of Glycogen-derived Energy Absorption in Nanometric Brain Structures", "conferenceName": "EuroVis", "authors": "Marco Agus;Corrado Cal{\\`{\\i}};Ali K. Al{-}Awami;Enrico Gobbetti;Pierre J. Magistretti;Markus Hadwiger", "citationCount": "3", "affiliation": "Agus, M (Corresponding Author), KAUST, Thuwal, Saudi Arabia.\nAgus, M (Corresponding Author), VCC, Thuwal, Saudi Arabia.\nAgus, M (Corresponding Author), Ctr Adv Studies Res \\& Dev Sardinia CRS4, Visual Comp Grp, Cagliari, Italy.\nAgus, M.; Cali, C.; Al-Awami, A.; Magistretti, P.; Hadwiger, M., KAUST, Thuwal, Saudi Arabia.\nAgus, M.; Al-Awami, A.; Hadwiger, M., VCC, Thuwal, Saudi Arabia.\nCali, C.; Magistretti, P., BESE, Thuwal, Saudi Arabia.\nAgus, M.; Gobbetti, E., Ctr Adv Studies Res \\& Dev Sardinia CRS4, Visual Comp Grp, Cagliari, Italy.\nAl-Awami, A., Saudi Aramco \\& EXPEC Comp Ctr, Dharhan, Saudi Arabia.", "countries": "Italy;Arabia", "abstract": "Digital acquisition and processing techniques are changing the way neuroscience investigation is carried out. Emerging applications range from statistical analysis on image stacks to complex connectomics visual analysis tools targeted to develop and test hypotheses of brain development and activity. In this work, we focus on neuroenergetics, a field where neuroscientists analyze nanoscale brain morphology and relate energy consumption to glucose storage in form of glycogen granules. In order to facilitate the understanding of neuroenergetic mechanisms, we propose a novel customized pipeline for the visual analysis of nanometric-level reconstructions based on electron microscopy image data. Our framework supports analysis tasks by combining i) a scalable volume visualization architecture able to selectively render image stacks and corresponding labelled data, ii) a method for highlighting distance-based energy absorption probabilities in form of glow maps, and iii) a hybrid connectivitybased and absorption-based interactive layout representation able to support queries for selective analysis of areas of interest and potential activity within the segmented datasets. This working pipeline is currently used in a variety of studies in the neuroenergetics domain. Here, we discuss a test case in which the framework was successfully used by domain scientists for the analysis of aging effects on glycogen metabolism, extracting knowledge from a series of nanoscale brain stacks of rodents somatosensory cortex.", "keywords": "", "link": "https://doi.org/10.1111/cgf.13700", "refList": ["10.1371/journal.pone.0038011", "10.1016/j.coisb.2017.07.011", "10.1145/234535.234538", "10.1109/tvcg.2018.2864847", "10.2312/conf/eg2012/stars/053-074", "10.3389/fnins.2018.00664", "10.1109/tpami.2018.2835450", "10.1109/tvcg.2014.2346312", "10.1109/tvcg.2009.121", "10.1002/glia.23020", "10.1117/1.jbo.18.5.050902", "10.1111/cgf.12927", "10.1038/nn.3837", "10.1109/isbi.2011.5872394", "10.3868/j.issn.2096-0689.2017.04.004", "10.1111/cgf.12792", "10.1016/j.neuroscience.2012.09.077", "10.1109/tvcg.2012.240", "10.1523/jneurosci.4825-12.2013", "10.1002/cne.23852", "10.2312/vcbm.20151213", "10.1111/cgf.12605", "10.1016/j.cag.2018.04.007", "10.1038/s41592-018-0049-4", "10.1007/s00371-015-1151-6", "10.1109/tvcg.2018.2864852", "10.1109/ic3d.2016.7823463", "10.3389/fncel.2019.00082", "10.1111/boc.201600024", "10.2312/vg/vg10/053-060", "10.1109/tvcg.2013.142", "10.1371/journal.pone.0198131", "10.1111/cgf.12280", "10.1038/nature22356", "10.1109/tvcg.2015.2467441", "10.1016/j.neuron.2015.03.035", "10.2312/vcbm.20161276", "10.1016/j.neuroscience.2007.07.014", "10.1109/tvcg.2017.2744238", "10.1002/glia.23250", "10.3389/fncel.2018.00308", "10.1016/j.cell.2018.06.019", "10.1109/tvcg.2017.2744278", "10.1109/biovis.2013.6664349", "10.1179/000870403235002042"], "wos": 1, "children": [], "len": 1}], "len": 15}, {"doi": "10.1109/tvcg.2018.2864852", "title": "Visualization of Neuronal Structures in Wide-Field Microscopy Brain Images", "year": "2018", "conferenceName": "SciVis", "authors": "Saeed Boorboor;Shreeraj Jadhav;Mala Ananth;David Talmage;Lorna Role;Arie E. Kaufman", "citationCount": "1", "affiliation": "Boorboor, S (Corresponding Author), SUNY Stony Brook, Dept Comp Sci, Stony Brook, NY 11794 USA. Boorboor, Saeed; Jadhav, Shreeraj; Kaufman, Arie, SUNY Stony Brook, Dept Comp Sci, Stony Brook, NY 11794 USA. Ananth, Mala; Talmage, David; Role, Lorna, SUNY Stony Brook, Dept Neurobiol \\& Behav, Stony Brook, NY 11794 USA.", "countries": "USA", "abstract": "Wide-field microscopes are commonly used in neurobiology for experimental studies of brain samples. Available visualization tools are limited to electron, two-photon, and confocal microscopy datasets, and current volume rendering techniques do not yield effective results when used with wide-field data. We present a workflow for the visualization of neuronal structures in wide-field microscopy images of brain samples. We introduce a novel gradient-based distance transform that overcomes the out-of-focus blur caused by the inherent design of wide-field microscopes. This is followed by the extraction of the 3D structure of neurites using a multi-scale curvilinear filter and cell-bodies using a Hessian-based enhancement filter. The response from these filters is then applied as an opacity map to the raw data. Based on the visualization challenges faced by domain experts, our workflow provides multiple rendering modes to enable qualitative analysis of neuronal structures, which includes separation of cell-bodies from neurites and an intensity-based classification of the structures. Additionally, we evaluate our visualization results against both a standard image processing deconvolution technique and a confocal microscopy image of the same specimen. We show that our method is significantly faster and requires less computational resources, while producing high quality visualizations. We deploy our workflow in an immersive gigapixel facility as a paradigm for the processing and visualization of large, high-resolution, wide-field microscopy brain datasets.", "keywords": "Wide-field microscopy,volume visualization,neuron visualization,neuroscience", "link": "http://dx.doi.org/10.1109/TVCG.2018.2864852", "refList": ["10.1109/titb.2002.1006304", "10.1111/j.1467-8659.2008.01220.x", "10.1007/s12021-011-9116-z", "10.1007/s12021-011-9120-3", "10.1007/978-0-387-45524-2\\_23", "10.1086/111605", "10.1109/tvcg.2007.70433", "10.1007/978-3-642-10520-3\\_9", "10.1109/tvcg.2014.2346312", "10.1109/tvcg.2011.82", "10.1109/mcg.2010.56", "10.1007/s12021-016-9302-0", "10.1109/tvcg.2012.42", "10.1016/j.neuron.2015.06.036", "10.1038/nbt.1612", "10.1109/tpami.2011.148", "10.1002/cyto.a.20022", "10.1007/s12021-011-9122-1", "10.1109/tvcg.2009.118", "10.1109/msp.2006.1628876", "10.1371/journal.pcbi.0010042", "10.1007/bfb0056195", "10.1016/j.ymeth.2016.12.015", "10.1016/j.compbiomed.2014.07.007", "10.1364/josa.62.000055", "10.1007/s12021-011-9121-2", "10.1098/rspa.1959.0200", "10.1007/s12021-016-9310-0", "10.1109/tvcg.2016.2598472", "10.1073/pnas.93.4.1591", "10.1111/j.1460-9568.2011.07671.x", "10.1109/tvcg.2013.142", "10.1109/cvpr.2013.283", "10.1109/vr.2017.7892342", "10.1109/tvcg.2012.203", "10.1109/tvcg.2008.30", "10.1007/s12021-014-9253-2", "10.1007/978-1-4471-6497-5\\_21", "10.1109/mcg.2014.80", "10.1111/j.1365-2818.2005.01466.x", "10.1007/s12021-011-9110-5", "10.1109/tvcg.2017.2744079", "10.1093/bioinformatics/btt170", "10.1007/s12021-010-9095-5", "10.1109/34.56205"], "wos": 1, "children": [{"doi": "10.1111/cgf.13700", "year": "2019", "title": "Interactive Volumetric Visual Analysis of Glycogen-derived Energy Absorption in Nanometric Brain Structures", "conferenceName": "EuroVis", "authors": "Marco Agus;Corrado Cal{\\`{\\i}};Ali K. Al{-}Awami;Enrico Gobbetti;Pierre J. Magistretti;Markus Hadwiger", "citationCount": "3", "affiliation": "Agus, M (Corresponding Author), KAUST, Thuwal, Saudi Arabia.\nAgus, M (Corresponding Author), VCC, Thuwal, Saudi Arabia.\nAgus, M (Corresponding Author), Ctr Adv Studies Res \\& Dev Sardinia CRS4, Visual Comp Grp, Cagliari, Italy.\nAgus, M.; Cali, C.; Al-Awami, A.; Magistretti, P.; Hadwiger, M., KAUST, Thuwal, Saudi Arabia.\nAgus, M.; Al-Awami, A.; Hadwiger, M., VCC, Thuwal, Saudi Arabia.\nCali, C.; Magistretti, P., BESE, Thuwal, Saudi Arabia.\nAgus, M.; Gobbetti, E., Ctr Adv Studies Res \\& Dev Sardinia CRS4, Visual Comp Grp, Cagliari, Italy.\nAl-Awami, A., Saudi Aramco \\& EXPEC Comp Ctr, Dharhan, Saudi Arabia.", "countries": "Italy;Arabia", "abstract": "Digital acquisition and processing techniques are changing the way neuroscience investigation is carried out. Emerging applications range from statistical analysis on image stacks to complex connectomics visual analysis tools targeted to develop and test hypotheses of brain development and activity. In this work, we focus on neuroenergetics, a field where neuroscientists analyze nanoscale brain morphology and relate energy consumption to glucose storage in form of glycogen granules. In order to facilitate the understanding of neuroenergetic mechanisms, we propose a novel customized pipeline for the visual analysis of nanometric-level reconstructions based on electron microscopy image data. Our framework supports analysis tasks by combining i) a scalable volume visualization architecture able to selectively render image stacks and corresponding labelled data, ii) a method for highlighting distance-based energy absorption probabilities in form of glow maps, and iii) a hybrid connectivitybased and absorption-based interactive layout representation able to support queries for selective analysis of areas of interest and potential activity within the segmented datasets. This working pipeline is currently used in a variety of studies in the neuroenergetics domain. Here, we discuss a test case in which the framework was successfully used by domain scientists for the analysis of aging effects on glycogen metabolism, extracting knowledge from a series of nanoscale brain stacks of rodents somatosensory cortex.", "keywords": "", "link": "https://doi.org/10.1111/cgf.13700", "refList": ["10.1371/journal.pone.0038011", "10.1016/j.coisb.2017.07.011", "10.1145/234535.234538", "10.1109/tvcg.2018.2864847", "10.2312/conf/eg2012/stars/053-074", "10.3389/fnins.2018.00664", "10.1109/tpami.2018.2835450", "10.1109/tvcg.2014.2346312", "10.1109/tvcg.2009.121", "10.1002/glia.23020", "10.1117/1.jbo.18.5.050902", "10.1111/cgf.12927", "10.1038/nn.3837", "10.1109/isbi.2011.5872394", "10.3868/j.issn.2096-0689.2017.04.004", "10.1111/cgf.12792", "10.1016/j.neuroscience.2012.09.077", "10.1109/tvcg.2012.240", "10.1523/jneurosci.4825-12.2013", "10.1002/cne.23852", "10.2312/vcbm.20151213", "10.1111/cgf.12605", "10.1016/j.cag.2018.04.007", "10.1038/s41592-018-0049-4", "10.1007/s00371-015-1151-6", "10.1109/tvcg.2018.2864852", "10.1109/ic3d.2016.7823463", "10.3389/fncel.2019.00082", "10.1111/boc.201600024", "10.2312/vg/vg10/053-060", "10.1109/tvcg.2013.142", "10.1371/journal.pone.0198131", "10.1111/cgf.12280", "10.1038/nature22356", "10.1109/tvcg.2015.2467441", "10.1016/j.neuron.2015.03.035", "10.2312/vcbm.20161276", "10.1016/j.neuroscience.2007.07.014", "10.1109/tvcg.2017.2744238", "10.1002/glia.23250", "10.3389/fncel.2018.00308", "10.1016/j.cell.2018.06.019", "10.1109/tvcg.2017.2744278", "10.1109/biovis.2013.6664349", "10.1179/000870403235002042"], "wos": 1, "children": [], "len": 1}], "len": 3}, {"doi": "10.1109/tvcg.2019.2934402", "title": "CerebroVis: Designing an Abstract yet Spatially Contextualized Cerebral Artery Network Visualization", "year": "2019", "conferenceName": "InfoVis", "authors": "Aditeya Pandey;Harsh Shukla;Geoffrey S. Young;Lei Qin;Amir A. Zamani;Liangge Hsu;Raymond Huang;Cody Dunne;Michelle Borkin", "citationCount": "1", "affiliation": "Pandey, A (Corresponding Author), Northeastern Univ, Boston, MA 02115 USA. Pandey, Aditeya; Shukla, Harsh; Dunne, Cody; Borkin, Michelle A., Northeastern Univ, Boston, MA 02115 USA. Young, Geoffrey S.; Zamani, Amir A.; Hsu, Liangge; Huang, Raymond, Brigham \\& Womens Hosp, Boston, MA 02115 USA. Qin, Lei, Dana Farber Canc Inst, Boston, MA 02115 USA.", "countries": "USA", "abstract": "Blood circulation in the human brain is supplied through a network of cerebral arteries. If a clinician suspects a patient has a stroke or other cerebrovascular condition, they order imaging tests. Neuroradiologists visually search the resulting scans for abnormalities. Their visual search tasks correspond to the abstract network analysis tasks of browsing and path following. To assist neuroradiologists in identifying cerebral artery abnormalities, we designed CerebroVis, a novel abstract\u2014yet spatially contextualized\u2014cerebral artery network visualization. In this design study, we contribute a novel framing and definition of the cerebral artery system in terms of network theory and characterize neuroradiologist domain goals as abstract visualization and network analysis tasks. Through an iterative, user-centered design process we developed an abstract network layout technique which incorporates cerebral artery spatial context. The abstract visualization enables increased domain task performance over 3D geometry representations, while including spatial context helps preserve the user's mental map of the underlying geometry. We provide open source implementations of our network layout technique and prototype cerebral artery visualization tool. We demonstrate the robustness of our technique by successfully laying out 61 open source brain scans. We evaluate the effectiveness of our layout through a mixed methods study with three neuroradiologists. In a formative controlled experiment our study participants used CerebroVis and a conventional 3D visualization to examine real cerebral artery imaging data to identify a simulated intracranial artery stenosis. Participants were more accurate at identifying stenoses using CerebroVis (absolute risk difference 13%). A free copy of this paper, the evaluation stimuli and data, and source code are available at osf.io/e5sxt.", "keywords": "Network Visualization,Spatial Context,Abstract Design,Flow Network,Medical Imaging,Cerebral Arteries", "link": "http://dx.doi.org/10.1109/TVCG.2019.2934402", "refList": ["10.1109/tvcg.2007.70582", "10.1093/bib/bbr069", "10.1145/323233.323254", "10.1109/tvcg.2008.165", "10.1145/234535.234538", "10.1109/tvcg.2008.117", "10.3174/ajnr.a1234", "10.1145/1360612.1360699", "10.1109/tse.1981.234519", "10.1007/3-540-63938-1\\_67", "10.1109/tvcg.2014.2346312", "10.1161/01.str.14.5.756", "10.1016/b978-008044531-1/50426-7", "10.1109/tvcg.2011.185", "10.1016/j.pharmthera.2013.01.016", "10.1109/tvcg.2013.231", "10.3102/0013189x033007014", "10.1186/1471-2105-10-375", "10.1111/j.1467-8659.2008.01205.x", "10.1109/mcg.2011.103", "10.1109/wvl.1989.77035", "10.3174/ajnr.a0689", "10.1109/isre.1993.324822", "10.1007/978-3-319-27261-0\\_50", "10.1109/tvcg.2010.79", "10.1111/1467-9884.00149", "10.1007/978-3-540-70904-6\\_19", "10.1109/tvcg.2011.192", "10.1109/tvcg.2013.124", "10.1145/774833.774859", "10.1007/s10851-013-0473-0", "10.1002/(sici)1097-024x(199612)26:121415::aid-spe693.3.co", "2-g", "10.1109/tvcg.2011.193", "10.3141/2392-06", "10.1109/42.41482", "10.1007/978-3-642-21608-4.7", "10.1109/tvcg.2016.2598472", "10.1155/2015/450341", "10.1002/spe.4380211102", "10.1145/1168149.1168168", "10.1093/neuros/nyx325", "10.1117/12.2079420", "10.1098/rstb.2005.1637", "10.1016/j.neuroimage.2013.05.089", "10.1145/2470654.2470724", "10.1111/j.1365-2125.2011.04061.x", "10.1148/rg.263055186", "10.1109/tvcg.2012.213", "10.2471/blt.16.181636", "10.1023/a:1009771921595", "10.1109/tsmc.1981.4308636", "10.1109/tvcg.2014.2346276", "10.1145/1201775.882291", "10.1109/tvcg.2017.2744278", "10.1109/tvcg.2009.111", "10.1214/11-ejs612", "10.1147/jrd.2015.2411412", "10.1161/01.str.0000041999.64363.b2"], "wos": 1, "children": [], "len": 1}, {"doi": "10.1109/pacificvis.2019.00013", "year": "2019", "title": "Challenges for Brain Data Analysis in VR Environments", "conferenceName": "PacificVis", "authors": "Sabrina Jaeger;Karsten Klein;Lucas Joos;Johannes Zagermann;Michael de Ridder;Jinman Kim;Jean Yee Hwa Yang;Ulrike Pfeil;Harald Reiterer;Falk Schreiber", "citationCount": "1", "affiliation": "Jaeger, S (Corresponding Author), Univ Konstanz, Constance, Germany.\nJaeger, Sabrina; Klein, Karsten; Joos, Lucas; Zagermann, Johannes; Pfeil, Ulrike; Reiterer, Harald; Schreiber, Falk, Univ Konstanz, Constance, Germany.\nde Ridder, Michael; Kim, Jinman; Yang, Jean, Univ Sydney, Sydney, NSW, Australia.", "countries": "Germany;Australia", "abstract": "Analysing and understanding brain function and disorder is the main focus of neuroscience. Due to the high complexity of the brain, directionality of the signal and changing activity over time, visual exploration and data analysis are difficult. For this reason, a vast amount of research challenges are still unsolved. We explored different challenges of the visual analysis of brain data and the design of corresponding immersive environments in collaboration with experts from the biomedical domain. We built a prototype of an immersive virtual reality environment to explore the design space and to investigate how brain data analysis can be supported by a variety of design choices. Our environment can be used to study the effect of different visualisations and combinations of brain data representation, as for example network layouts, anatomical mapping or time series. As a long-term goal, we aim to aid neuro-scientists in a better understanding of brain function and disorder.", "keywords": "Human-centered computing; Visualization; Visualization application domains; Visual Analytics; Human-centered computing; Visualization; Visualization design and evaluation methods Applied computing; Life and medical sciences; Computational biology; Biological networks", "link": "https://doi.org/10.1109/PacificVis.2019.00013", "refList": ["10.1098/rstb.2013.0521", "10.1016/j.neuroimage.2017.04.014", "10.1111/cgf.12791", "10.1016/j.neuroimage.2013.04.111", "10.1109/tmi.2017.2721640", "10.1371/journal.pone.0068910", "10.1007/s41109-018-0096-x", "10.3389/fnins.2014.00015", "10.1007/978-3-319-73207-7", "10.1016/j.jneumeth.2013.08.005", "10.3389/fncom.2016.00066", "10.1155/2017/8362741", "10.1016/j.neuroimage.2009.10.003", "10.1109/pacificvis.2014.48", "10.1109/wevr.2017.7957707", "10.1038/nrn2575", "10.1109/tvcg.2016.2598472", "10.1371/journal.pone.0053199", "10.1016/j.euroneuro.2010.03.008", "10.1111/cgf.13072", "10.1145/2470654.2470724", "10.1111/cgf.12615", "10.1016/j.neuroimage.2012.01.107", "10.1109/tvcg.2008.21", "10.1109/biovis.2013.6664348", "10.1186/s40708-018-0083-0", "10.1057/palgrave.ivs.9500092", "10.1016/j.neuroimage.2015.11.055", "10.12688/f1000research.6838.1", "10.1016/j.neuroimage.2016.11.006"], "wos": 1, "children": [], "len": 1}, {"doi": "10.1109/pacificvis.2017.8031601", "year": "2017", "title": "A visual analytics system for brain functional connectivity comparison across individuals, groups, and time points", "conferenceName": "PacificVis", "authors": "Takanori Fujiwara;Jia{-}Kai Chou;Andrew M. McCullough;Charan Ranganath;Kwan{-}Liu Ma", "citationCount": "1", "affiliation": "Fujiwara, T (Corresponding Author), Univ Calif Davis, Davis, CA 95616 USA.\nFujiwara, Takanori; Chou, Jia-Kai; McCullough, Andrew M.; Ranganath, Charan; Ma, Kwan-Liu, Univ Calif Davis, Davis, CA 95616 USA.", "countries": "USA", "abstract": "Neuroscientists study brain functional connectivity in order to obtain a deeper understanding of how the brain functions. Current studies are mainly based on analyzing the averaged brain connectivity of a group (or groups) due to the high complexity of the collected data in terms of dimensionality, variability, and volume. While it is more desirable for the researchers to explore the potential variability between individual subjects or groups, a data analysis solution meeting this need is absent. In this paper, we present the design and capabilities of such a visual analytics system, which enables neuroscientists to visually compare the differences of brain networks between individual subjects as well as group averages, to explore a large dataset and examine sub-groups of participants that may not have been expected a priori to be of interest, to review detailed information as needed, and to manipulate the data and views to fit their analytical needs with easy interactions. We demonstrate the utility and strengths of this system with case studies using a representative functional connectivity dataset.", "keywords": "I.3.8 {[}Computer Graphics]: Applications", "link": "https://doi.org/10.1109/PACIFICVIS.2017.8031601", "refList": ["10.1109/tvcg.2007.70582", "10.1016/j.jneumeth.2010.11.015", "10.1016/j.neucom.2006.11.018", "10.1007/978-3-642-10520-3\\_9", "10.1016/j.neuroimage.2013.04.111", "10.1016/j.neuron.2014.10.015", "10.1016/j.neuroimage.2013.05.079", "10.1371/journal.pone.0068910", "10.1111/j.1467-8659.2010.01835.x", "10.1016/j.neuroimage.2009.10.003", "10.1523/jneurosci.1324-15.2015", "10.1016/j.tics.2016.03.014", "10.1371/journal.pone.0138297", "10.1002/hbm.23150", "10.1371/journal.pone.0040709", "10.1016/j.tins.2013.03.001", "10.1109/tvcg.2016.2598472", "10.1057/ivs.2010.2", "10.1145/2470654.2470724", "10.1111/cgf.12615", "10.1007/978-1-4471-6497-5\\_21", "10.1109/tvcg.2013.114", "10.1371/journal.pone.0113838", "10.1088/1742-5468/2008/10/p10008", "10.3389/fninf.2011.00003", "10.1109/icdm.2015.135", "10.1109/tvcg.2015.2467851", "10.1016/j.jneumeth.2015.02.021"], "wos": 1, "children": [{"doi": "10.1109/tvcg.2020.3028889", "title": "A Visual Analytics Framework for Reviewing Multivariate Time-Series Data with Dimensionality Reduction", "year": "2020", "conferenceName": "VAST", "authors": "Takanori Fujiwara;Shilpika;Naohisa Sakamoto;Jorji Nonaka;Keiji Yamamoto;Kwan-Liu Ma", "citationCount": "0", "affiliation": "Fujiwara, T (Corresponding Author), Univ Calif Davis, Davis, CA 95616 USA. Fujiwara, Takanori; Shilpika; Ma, Kwan-Liu, Univ Calif Davis, Davis, CA 95616 USA. Sakamoto, Naohisa, Kobe Univ, Kobe, Hyogo, Japan. Nonaka, Jorji; Yamamoto, Keiji, RIKEN R CCS, Kobe, Hyogo, Japan.", "countries": "Japan;USA", "abstract": "Data-driven problem solving in many real-world applications involves analysis of time-dependent multivariate data, for which dimensionality reduction (DR) methods are often used to uncover the intrinsic structure and features of the data. However, DR is usually applied to a subset of data that is either single-time-point multivariate or univariate time-series, resulting in the need to manually examine and correlate the DR results out of different data subsets. When the number of dimensions is large either in terms of the number of time points or attributes, this manual task becomes too tedious and infeasible. In this paper, we present MulTiDR, a new DR framework that enables processing of time-dependent multivariate data as a whole to provide a comprehensive overview of the data. With the framework, we employ DR in two steps. When treating the instances, time points, and attributes of the data as a 3D array, the first DR step reduces the three axes of the array to two, and the second DR step visualizes the data in a lower-dimensional space. In addition, by coupling with a contrastive learning method and interactive visualizations, our framework enhances analysts' ability to interpret DR results. We demonstrate the effectiveness of our framework with four case studies using real-world datasets.", "keywords": "Multivariate time-series,tensor,data cube,dimensionality reduction,interpretability,visual analytics", "link": "http://dx.doi.org/10.1109/TVCG.2020.3028889", "refList": ["10.1016/j.neucom.2008.12.017", "10.1109/tvcg.2015.2467591", "10.1007/bf02289464", "10.1109/tvcg.2015.2468111", "10.1177/1350650119867242", "10.1109/pacificvis48177.2020.9280", "10.1109/tvcg.2017.2744419", "10.1109/tvcg.2011.185", "10.1109/bigdata.2015.7363807", "10.1145/2669557.2669559", "10.1016/j.patcog.2011.01.004", "10.1080/13506280444000102.http://www.uvt.nl/ticc", "10.1186/1475-925x-14-s2-s6", "10.1007/s12650-018-0530-2", "10.1109/tkde.2018.2878247", "10.1016/j.visinf.2018.04.010", "10.1002/1099-128x(200005/06)14:3", "10.1371/journal.pone.0107878", "10.1109/pacificvis.2017.8031601", "10.1016/j.jbi.2019.103291", "10.1109/daac49578.2019.00008", "10.1109/allerton.2019.8919886", "10.1007/978-3-319-13105-4\\_14", "10.4258/hir.2016.22.3.156", "10.1109/tvcg.2015.2467553", "10.1145/2245276.2245469", "10.1007/bf02294485", "10.1109/tvcg.2015.2468078", "10.1109/tvcg.2016.2598470", "10.1137/07070111x", "10.1109/tvcg.2019.2934433", "10.1109/tvcg.2016.2640960", "10.1007/bf02310791", "10.1109/tvcg.2016.2534558", "10.1109/access.2016.2529723", "10.1109/tvcg.2016.2598664", "10.2312/eurovisshort.20161164", "10.1109/tvcg.2018.2865018", "10.1111/cgf.12804", "10.1109/tvcg.2018.2846735", "10.1016/j.comnet.2017.06.013", "10.1146/annurev-statistics-041715-033624", "10.1109/pacificvis.2018.00026", "10.1109/tvcg.2015.2467851"], "wos": 1, "children": [], "len": 1}], "len": 3}, {"doi": "10.1111/cgf.13712", "year": "2019", "title": "Route-Aware Edge Bundling for Visualizing Origin-Destination Trails in Urban Traffic", "conferenceName": "EuroVis", "authors": "Wei Zeng;Q. Shen;Y. Jiang;A. Telea", "citationCount": "1", "affiliation": "Shen, Q (Corresponding Author), Hong Kong Univ Sci \\& Technol, Hong Kong, Peoples R China.\nZeng, W., Chinese Acad Sci, Shenzhen Inst Adv Technol, Shenzhen, Peoples R China.\nShen, Q.; Jiang, Y., Hong Kong Univ Sci \\& Technol, Hong Kong, Peoples R China.\nTelea, A., Univ Groningen, Groningen, Netherlands.", "countries": "China;Netherlands", "abstract": "Origin-destination (OD) trails describe movements across space. Typical visualizations thereof use either straight lines or plot the actual trajectories. To reduce clutter inherent to visualizing large OD datasets, bundling methods can be used. Yet, bundling OD trails in urban traffic data remains challenging. Two specific reasons hereof are the constraints implied by the underlying road network and the difficulty of finding good bundling settings. To cope with these issues, we propose a new approach called Route Aware Edge Bundling (RAEB). To handle road constraints, we first generate a hierarchical model of the road-and-trajectory data. Next, we derive optimal bundling parameters, including kernel size and number of iterations, for a user-selected level of detail of this model, thereby allowing users to explicitly trade off simplification vs accuracy. We demonstrate the added value of RAEB compared to state-of-the-art trail bundling methods on both synthetic and real-world traffic data for tasks that include the preservation of road network topology and the support of multiscale exploration.", "keywords": "", "link": "https://doi.org/10.1111/cgf.13712", "refList": ["10.1109/tvcg.2008.135", "10.1145/2833165.2833168", "10.1111/cgf.13213", "10.1109/mcg.2011.88", "10.1109/tvcg.2013.226", "10.1109/tvcg.2010.44", "10.1145/1653771.1653820", "10.1109/tvcg.2015.2468111", "10.1109/tst.2013.6509098", "10.1111/j.1467-8659.2009.01440.x", "10.1111/cgf.12922", "10.1109/tvcg.2018.2816219", "10.1109/vast.2014.7042486", "10.1198/tas.2009.0033", "10.1111/cgf.12132", "10.1111/j.1467-8659.2009.01700.x", "10.1016/j.trc.2007.05.002", "10.1007/978-3-540-72680-7\\_22", "10.1109/tvcg.2011.233", "10.1109/tvcg.2014.2346271", "10.1109/tvcg.2016.2515611", "10.1109/infvis.2005.1532150", "10.1109/tvcg.2016.2598472", "10.1109/tvcg.2006.147", "10.1109/tvcg.2016.2598958", "10.1109/tits.2017.2683539", "10.1109/tits.2015.2436897", "10.1111/j.1467-8659.2012.03079.x", "10.1109/tvcg.2017.2744338", "10.1109/pacificvis.2017.8031594", "10.1179/000870410x12658023467367", "10.1057/palgrave.ivs.9500182", "10.1109/tvcg.2011.104", "10.1109/tvcg.2011.190", "10.1109/tvcg.2013.114", "10.1111/cgf.12778", "10.1109/tvcg.2015.2467112", "10.1111/cgf.12107", "10.1109/iv.2010.53", "10.1109/42.563664", "10.1109/tvcg.2017.2666146", "10.1145/2530531", "10.1111/j.1467-8659.2009.01450.x", "10.4028/www.scientific.net/kem.342-343.593", "10.1109/tvcg.2011.202", "10.1038/srep00612"], "wos": 1, "children": [{"doi": "10.1109/tvcg.2020.3030410", "title": "Revisiting the Modifiable Areal Unit Problem in Deep Traffic Prediction with Visual Analytics", "year": "2020", "conferenceName": "VAST", "authors": "Wei Zeng 0002;Chengqiao Lin;Juncong Lin;Jincheng Jiang;Jiazhi Xia;Cagatay Turkay;Wei Chen", "citationCount": "0", "affiliation": "Lin, JC (Corresponding Author), Xiamen Univ, Xiamen, Peoples R China. Zeng, Wei; Jiang, Jincheng, Chinese Acad Sci, Shenzhen Inst Adv Technol, Shenzhen, Peoples R China. Lin, Chengqiao; Lin, Juncong, Xiamen Univ, Xiamen, Peoples R China. Xia, Jiazhi, Cent South Univ, Changsha, Peoples R China. Turkay, Cagatay, Univ Warwick, Coventry, W Midlands, England. Chen, Wei, Zhejiang Univ, State Key Lab CAD \\& CG, Hangzhou, Zhejiang, Peoples R China.", "countries": "China;England", "abstract": "Deep learning methods are being increasingly used for urban traffic prediction where spatiotemporal traffic data is aggregated into sequentially organized matrices that are then fed into convolution-based residual neural networks. However, the widely known modifiable areal unit problem within such aggregation processes can lead to perturbations in the network inputs. This issue can significantly destabilize the feature embeddings and the predictions - rendering deep networks much less useful for the experts. This paper approaches this challenge by leveraging unit visualization techniques that enable the investigation of many-to-many relationships between dynamically varied multi-scalar aggregations of urban traffic data and neural network predictions. Through regular exchanges with a domain expert, we design and develop a visual analytics solution that integrates 1) a Bivariate Map equipped with an advanced bivariate colormap to simultaneously depict input traffic and prediction errors across space, 2) a Moran's I Scatterplot that provides local indicators of spatial association analysis, and 3) a Multi-scale Attribution View that arranges non-linear dot plots in a tree layout to promote model analysis and comparison across scales. We evaluate our approach through a series of case studies involving a real-world dataset of Shenzhen taxi trips, and through interviews with domain experts. We observe that geographical scale variations have important impact on prediction performances, and interactive visual exploration of dynamically varying inputs and outputs benefit experts in the development of deep traffic prediction models.", "keywords": "MAUP,traffic prediction,deep learning,model diagnostic,visual analytics", "link": "http://dx.doi.org/10.1109/TVCG.2020.3030410", "refList": ["10.1038/srep26377", "10.1109/mcg.2011.88", "10.1080/13658816.2015.1119279", "10.1109/tvcg.2013.226", "10.1109/pacificvis.2011.5742387", "10.1038/s41467-017-01882-w", "10.1109/tvcg.2019.2934670", "10.1111/j.1467-8659.2009.01440.x", "10.1111/cgf.13712", "10.1016/j.compenvurbsys.2008.09.006", "10.1109/pacificvis.2014.50", "10.1109/tvcg.2018.2816219", "10.1109/tvcg.2016.2535234", "10.1109/tvcg.2014.2346893", "10.3390/ijgi8080344", "10.1109/tvcg.2013.246", "10.1007/s10940-005-9003-6", "10.1016/j.compenvurbsys.2008.05.001", "10.1007/s10661-019-7831-3", "10.1111/j.1538-4632.2007.00699.x", "10.1016/j.aap.2016.08.015", "10.1080/13658816.2018.1541177", "10.1109/pacificvis.2012.6183572", "10.1109/tvcg.2011.181", "10.1137/090759069", "10.1109/pacificvis.2011.5742390", "10.1214/10-aos799", "10.1109/tits.2017.2683539", "10.1109/tits.2015.2436897", "10.3390/ijerph16071150", "10.1109/tvcg.2009.145", "10.1109/tvcg.2012.265", "10.1080/10106049.2017.1404140", "10.3390/ijgi8020063", "10.3390/info6020134", "10.1080/13658816.2014.955027", "10.1109/tits.2016.2639320", "10.2307/143141", "10.1109/tvcg.2016.2598432"], "wos": 1, "children": [], "len": 1}, {"doi": "10.1109/tvcg.2020.3030469", "title": "Topology Density Map for Urban Data Visualization and Analysis", "year": "2020", "conferenceName": "VAST", "authors": "Zezheng Feng;Haotian Li;Wei Zeng 0004;Shuang-Hua Yang;Huamin Qu", "citationCount": "0", "affiliation": "Zeng, W (Corresponding Author), Chinese Acad Sci, Shenzhen Inst Adv Technol, Shenzhen, Peoples R China. Feng, Zezheng; Li, Haotian; Qu, Huamin, Hong Kong Univ Sci \\& Technol, Hong Kong, Peoples R China. Zeng, Wei, Chinese Acad Sci, Shenzhen Inst Adv Technol, Shenzhen, Peoples R China. Yang, Shuang-Hua, Southern Univ Sci \\& Technol, Shenzhen, Peoples R China.", "countries": "China", "abstract": "Density map is an effective visualization technique for depicting the scalar field distribution in 2D space. Conventional methods for constructing density maps are mainly based on Euclidean distance, limiting their applicability in urban analysis that shall consider road network and urban traffic. In this work, we propose a new method named Topology Density Map, targeting for accurate and intuitive density maps in the context of urban environment. Based on the various constraints of road connections and traffic conditions, the method first constructs a directed acyclic graph (DAG) that propagates nonlinear scalar fields along 1D road networks. Next, the method extends the scalar fields to a 2D space by identifying key intersecting points in the DAG and calculating the scalar fields for every point, yielding a weighted Voronoi diagram like effect of space division. Two case studies demonstrate that the Topology Density Map supplies accurate information to users and provides an intuitive visualization for decision making. An interview with domain experts demonstrates the feasibility, usability, and effectiveness of our method.", "keywords": "Density map,network topology,urban data", "link": "http://dx.doi.org/10.1109/TVCG.2020.3030469", "refList": ["10.1109/vast.2009.5332584", "10.1109/tvcg.2013.193", "10.1080/03081060.2013.844903", "10.1109/tvcg.2018.2864503", "10.1145/2702123.2702419", "10.1109/tvcg.2019.2934670", "10.1109/tits.2015.2496783", "10.1177/1473871615581216", "10.3141/1617-02", "10.1145/2024156.2024169", "10.1111/cgf.13712", "10.1016/j.ejor.2007.02.005", "10.1109/tvcg.2014.2346893", "10.1007/11871842\\_29", "10.1109/vast.2010.5652478", "10.1016/j.visinf.2019.10.002", "10.1109/tvcg.2016.2616404", "10.1109/vl.1996.545307", "10.1145/2629592", "10.1155/2018/2696037", "10.1061/(asce)0733-947x(1998)124:4(368", "10.3141/1899-21", "10.1023/a:1026123329433", "10.1109/mcg.2010.79", "10.1057/palgrave.ivs.9500174", "10.1109/tcyb.2019.2963681", "10.1109/tvcg.2015.2467554", "10.1111/cgf.12114", "10.1145/2814575", "10.1016/j.jcps.2014.08.002", "10.1109/2945.981847", "10.1080/03052150210909", "10.1109/tciaig.2012.2186810", "10.1109/tits.2017.2683539", "10.1109/iv.2004.1320137", "10.1016/0377-2217(80)90126-5", "10.1109/tvcg.2016.2640960", "10.1109/tvcg.2015.2467196", "10.1145/3097983.3098056", "10.1007/s11432-018-9801-4", "10.1109/vast.2014.7042490", "10.1061/(asce)0733-947x(2006)132:2(122", "10.1016/j.tra.2008.03.011", "10.1109/tits.2014.2298892", "10.1016/j.trb.2005.12.003", "10.1007/bf01840357", "10.1109/vast.2011.6102454", "10.1109/tvcg.2013.145", "10.1007/bf02289588", "10.1109/pacificvis.2014.56", "10.1109/mcg.2018.053491730", "10.1109/tvcg.2009.111", "10.1057/palgrave.ivs.9500184", "10.1109/tvcg.2013.173", "10.1109/tvcg.2016.2598432", "10.1007/978-0-85729-079-3"], "wos": 1, "children": [], "len": 1}], "len": 5}], "len": 45}, "index": 550, "embedding": [1.3831311464309692, 1.6906355619430542, -1.0434188842773438, -2.387450695037842, -0.5725212693214417, 0.16650904715061188, -0.713410496711731, 2.6847083568573, 1.1615749597549438, 2.041576623916626, 0.3876485824584961, 0.8361964821815491, -0.15996834635734558, -1.1581534147262573, -0.8862755298614502, 2.674309730529785, 3.000711679458618, 3.2889633178710938, -0.6726681590080261, 0.8425988554954529, -0.06630208343267441, 0.7191255688667297, 0.3204265534877777, 3.828256130218506, -2.424682378768921, 2.188636064529419, -0.5581337213516235, 1.6465795040130615, 2.0343589782714844, 1.153329610824585, 0.16192574799060822, 1.745561122894287], "projection": [-0.40539973974227905, 8.38874340057373], "size": 23, "height": 5, "width": 11}