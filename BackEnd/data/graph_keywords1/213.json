{"data": {"doi": "10.1109/pacificvis.2018.00035", "year": "2018", "title": "An Automatic Deformation Approach for Occlusion Free Egocentric Data Exploration", "conferenceName": "PacificVis", "authors": "Cheng Li;Joachim Moortgat;Han{-}Wei Shen", "citationCount": "1", "affiliation": "Li, C (Corresponding Author), Ohio State Univ, Columbus, OH 43210 USA.\nLi, Cheng; Moortgat, Joachim; Shen, Han-Wei, Ohio State Univ, Columbus, OH 43210 USA.", "countries": "USA", "abstract": "Occlusion management is an important task for three dimension data exploration. For egocentric data exploration, the occlusion problems, caused by the camera being too close to opaque data elements, have not been well addressed by previous studies. In this paper, we propose an automatic approach to resolve these problems and provide an occlusion free egocentric data exploration. Our system utilizes a state transition model to monitor both the camera and the data, and manages the initiation, duration, and termination of deformation with animation. Our method can be applied to multiple types of scientific datasets, including volumetric data, polygon mesh data, and particle data. We demonstrate our method with different exploration tasks, including camera navigation, isovalue adjustment, transfer function adjustment, and time varying exploration. We have collaborated with a domain expert and received positive feedback.", "keywords": "Data Deformation; Occlusion Management; Data Exploration; Egocentric Visualization", "link": "https://doi.org/10.1109/PacificVis.2018.00035", "refList": ["10.1145/989863.989871", "10.1109/tvcg.2008.59", "10.1111/j.1467-8659.2008.01332.x", "10.1109/tvcg.2016.2599049", "10.1109/pacificvis.2014.14", "10.1109/tvcg.2007.70433", "10.1007/s10596-015-9501-z", "10.1109/38.610209", "10.1109/tvcg.2003.1207447", "10.1111/j.1467-8659.2008.01181.x", "10.1109/tvcg.2012.42", "10.1109/tvcg.2016.2599217", "10.1002/fld.3764", "10.1109/pacificvis.2013.6596123", "10.1109/tvcg.2006.140", "10.1109/tvcg.2012.143", "10.1109/tvcg.2007.70565", "10.1109/scivis.2015.7429485", "10.1109/pacificvis.2017.8031579", "10.1109/tvcg.2006.167", "10.1145/505008.505039", "10.1109/tvcg.2006.144", "10.1016/j.cag.2010.01.007", "10.1109/tvcg.2015.2502583", "10.1109/tvcg.2011.283", "10.1109/38.595268", "10.1109/tvcg.2016.2518338", "10.1109/tvcg.2014.20", "10.1145/1980462.1980487", "10.1111/cgf.12466", "10.2312/compaesth/compaesth05/209-216", "10.1109/tvcg.2010.127", "10.1016/j.advwatres.2016.01.002", "10.2312/vg/vg06/009-016", "10.1109/tvcg.2009.144", "10.1145/1462055.1462056"], "wos": 1, "children": [{"doi": "10.1109/pacificvis.2019.00011", "year": "2019", "title": "Object-in-Hand Feature Displacement with Physically-Based Deformation", "conferenceName": "PacificVis", "authors": "Cheng Li;Han{-}Wei Shen", "citationCount": "1", "affiliation": "Li, C (Corresponding Author), Ohio State Univ, Columbus, OH 43210 USA.\nLi, Cheng; Shen, Han-Wei, Ohio State Univ, Columbus, OH 43210 USA.", "countries": "USA", "abstract": "Data deformation has been widely used in visualization to obtain an improved view that better helps the comprehension of the data. It has been a consistent pursuit to conduct interactive deformation by operations that are natural to users. In this paper, we propose a deformation system following the object-in-hand metaphor. We utilize a touchscreen to directly manipulate the shape of the data by using fingers. Users can drag data features and move them along with the fingers. Users can also press their fingers to hold other parts of the data fixed during the deformation, or perform cutting on the data using a finger. The deformation is executed using a physically-based mesh, which is constructed to incorporate data properties to make the deformation authentic as well as informative. By manipulating data features as if handling an object in hand, we can successfully achieve less occluded view of the data, or improved feature layout for better view comparison. We present case studies on various types of scientific datasets, including particle data, volumetric data, and streamlines.", "keywords": "Deformation; Physically-Based; Touchscreen", "link": "https://doi.org/10.1109/PacificVis.2019.00011", "refList": ["10.5132/eec.2016.01.01", "10.1109/visual.2003.1250400", "10.1109/tvcg.2008.59", "10.1109/tvcg.2015.2467202", "10.1145/2076354.2076390", "10.1109/tvcg.2013.100", "10.1109/tvcg.2016.2599049", "10.1109/visual.1996.567609", "10.1145/2992154.2996779", "10.1109/tvcg.2016.2599217", "10.1145/2766890", "10.1109/pacificvis.2018.00035", "10.1007/978-3-319-45853-3\\_6", "10.1109/tvcg.2006.140", "10.1111/cgf.12166", "10.1109/tvcg.2007.70565", "10.1109/pccga.2001.962877", "10.1109/pacificvis.2017.8031579", "10.1109/tvcg.2006.144", "10.3897/mycokeys.36.25986", "10.1016/j.cag.2010.01.007", "10.1109/tvcg.2007.48", "10.1111/j.1467-8659.2012.03115.x", "10.1109/tvcg.2015.2502583", "10.1109/tvcg.2011.283", "10.1109/tvcg.2012.70", "10.1145/3025453.3025890", "10.1111/j.1467-8659.2007.01102.x", "10.1145/2993148.2993152", "10.1145/1980462.1980487", "10.3171/jns.1999.90.4.0780", "10.1109/tvcg.2008.132", "10.2312/vg/vg06/009-016", "10.1109/tvcg.2010.34", "10.20380/gi2009.16", "10.1145/3025453.3025863", "10.1109/tvcg.2011.224", "10.1109/tvcg.2010.157"], "wos": 1, "children": [], "len": 1}], "len": 3}, "index": 213, "embedding": [0.03282519802451134, 0.12287422269582748, -0.26896652579307556, -0.2803858518600464, -0.6602144837379456, 0.16650904715061188, 1.323461890220642, 1.769588589668274, -0.43060755729675293, -0.4893345236778259, -0.3494327962398529, -0.4939935505390167, -0.13366082310676575, 0.03531654179096222, 0.2635997533798218, 0.7899951934814453, -0.19170187413692474, 0.06482167541980743, -0.6607173681259155, -0.02444150298833847, -0.06630208343267441, 1.5747287273406982, -0.756497859954834, -0.1414090394973755, -1.1731687784194946, 0.08472851663827896, -0.5077023506164551, -0.17138656973838806, 0.4527268707752228, 1.0025320053100586, -0.4819026589393616, 0.19074806571006775], "projection": [-4.84066915512085, 5.651198387145996], "size": 2, "height": 2, "width": 1}