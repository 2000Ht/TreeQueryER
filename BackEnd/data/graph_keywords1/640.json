{"data": {"doi": "10.1109/tvcg.2017.2743978", "title": "The Good, the Bad, and the Ugly: A Theoretical Framework for the Assessment of Continuous Colormaps", "year": "2017", "conferenceName": "SciVis", "authors": "Roxana Bujack;Terece L. Turton;Francesca Samsel;Colin Ware;David H. Rogers;James P. Ahrens", "citationCount": "11", "affiliation": "Bujack, R (Corresponding Author), Los Alamos Natl Lab, Los Alamos, NM 87545 USA. Bujack, Roxana; Rogers, David H.; Ahrens, James, Los Alamos Natl Lab, Los Alamos, NM 87545 USA. Turton, Terece L.; Sannsel, Francesca, Univ Texas Austin, Austin, TX 78712 USA. Ware, Colin, Univ New Hampshire, Durham, NH 03824 USA.", "countries": "USA", "abstract": "A myriad of design rules for what constitutes a \u201cgood\u201d colormap can be found in the literature. Some common rules include order, uniformity, and high discriminative power. However, the meaning of many of these terms is often ambiguous or open to interpretation. At times, different authors may use the same term to describe different concepts or the same rule is described by varying nomenclature. These ambiguities stand in the way of collaborative work, the design of experiments to assess the characteristics of colormaps, and automated colormap generation. In this paper, we review current and historical guidelines for colormap design. We propose a specified taxonomy and provide unambiguous mathematical definitions for the most common design rules.", "keywords": "colormap,survey,taxonomy,order,uniformity,discriminative power,smoothness,monotonicity,linearity,speed", "link": "http://dx.doi.org/10.1109/TVCG.2017.2743978", "refList": ["10.1109/tvcg.2015.2489649", "10.1016/s0734-189x(83)80046-2", "10.1002/(sici)1098-1098(199622)7:2", "10.1002/col.10051", "10.1109/tvcg.2016.2599106", "10.1109/visual.2001.964510", "10.1109/mcg.2007.323435", "10.2312/eurovisshort.20141163", "10.2307/2683294", "10.1109/visual.2002.1183788", "10.1016/0146-664x(81)90006-x", "10.1007/978-3-642-10520-3\\_9", "10.2312/eurovisshort.20151135", "10.1364/josaa.23.002077", "10.1109/38.135886", "10.1016/j.csda.2008.11.033", "10.1037/0278-7393.14.4.579", "10.1037/1076-898x.5.4.393", "10.1109/6.736450", "10.1109/mcg.2004.1297012", "10.1016/s0146-664x(79)80040-4", "10.1109/visual.1990.146372", "10.1109/mcg.2011.55", "10.1145/22949.22950", "10.1117/12.384882", "10.1109/mcg.1986.276688", "10.2312/eurorv3.20171107", "10.1016/b978-012387582-2/50038-1", "10.1002/col.1049", "10.1111/j.1467-8659.2011.01938.x", "10.1109/t-c.1969.222678", "10.5670/oceanog.2016.66", "10.2307/2684111", "10.1364/josa.32.000247", "10.1002/col.20227", "10.1111/cgf.12633", "10.1117/12.849111", "10.1109/38.7760", "10.1109/tvcg.2016.2599214", "10.1109/ldav.2013.6675161", "10.1111/cgf.12127", "10.1109/iv.2008.24", "10.1016/j.cag.2010.11.015", "10.1007/bf00275798", "10.1109/tns.1982.4332189", "10.1088/0959-5309/46/3/317", "10.1109/tvcg.2014.2346978", "10.2307/2683729", "10.1016/j.visres.2010.09.012", "10.1016/j.cag.2016.06.004", "10.1029/2004e0400002", "10.1111/cgf.12379", "10.1002/col.20710", "10.2312/envirvis.20171105", "10.1111/j.1467-8659.2008.01203.x", "10.1145/2207676.2208547", "10.1109/visual.1990.146383"], "wos": 1, "children": [{"doi": "10.1109/vast.2018.8802486", "title": "SMARTexplore: Simplifying High-Dimensional Data Analysis through a Table-Based Visual Analytics Approach", "year": "2018", "conferenceName": "VAST", "authors": "Michael Blumenschein;Michael Behrisch;Stefanie Schmid;Simon Butscher;Deborah Wahl;Karoline Villinger;Britta Renner;Harald Reiterer;Daniel A. Keim", "citationCount": "0", "affiliation": "Blumenschein, M (Corresponding Author), Univ Konstanz, Constance, Germany. Blumenschein, Michael; Schmid, Stefanie; Butscher, Simon; Wahl, Deborah R.; Villinger, Karoline; Renner, Britta; Reiterer, Harald; Keim, Daniel A., Univ Konstanz, Constance, Germany. Behrisch, Michael, Harvard Univ, Cambridge, MA 02138 USA.", "countries": "Germany;USA", "abstract": "We present SMARTEXPLORE, a novel visual analytics technique that simplifies the identification and understanding of clusters, correlations, and complex patterns in high-dimensional data. The analysis is integrated into an interactive table-based visualization that maintains a consistent and familiar representation throughout the analysis. The visualization is tightly coupled with pattern matching, subspace analysis, reordering, and layout algorithms. To increase the analyst's trust in the revealed patterns, SMARTEXPLORE automatically selects and computes statistical measures based on dimension and data properties. While existing approaches to analyzing high-dimensional data (e.g., planar projections and Parallel coordinates) have proven effective, they typically have steep learning curves for non-visualization experts. Our evaluation, based on three expert case studies, confirms that non-visualization experts successfully reveal patterns in high-dimensional data when using SMARTEXPLORE.", "keywords": "High-dimensional data,visual exploration,pattern-driven analysis,tabular visualization,subspace,aggregation", "link": "http://dx.doi.org/10.1109/VAST.2018.8802486", "refList": ["10.1177/1473871612460526", "10.1109/tvcg.2015.2489649", "10.1111/j.1467-8659.2008.01241.x", "10.1007/978-3-319-25087-8\\_29", "10.1007/b98835", "10.13140/rg.2.2.16570.90567", "10.1109/tvcg.2014.2346260", "10.1109/vast.2009.5332628", "10.2307/2528823", "10.1109/tvcg.2010.184", "10.1145/1133265.1133318", "10.1057/palgrave.ivs.9500072", "10.1111/j.1467-8659.2012.03110.x", "10.1145/1007730.1007731", "10.1057/palgrave.ivs.9500086", "10.1111/cgf.12935", "10.1109/tvcg.2014.2346279", "10.1007/bf01898350", "10.1109/tvcg.2013.173", "10.1109/tvcg.2017.2672987", "10.1109/tvcg.2014.2346248", "10.1109/infvis.2004.46", "10.1109/vast.2010.5652433", "10.1109/vast.2009.5332611", "10.1109/tvcg.2015.2467553", "10.1109/tvcg.2015.2468078", "10.1109/tvcg.2017.2744098", "10.1109/tvcg.2013.150", "10.1109/tvcg.2016.2640960", "10.1111/cgf.12630", "10.1007/978-1-4757-1904-8", "10.1109/tvcg.2011.188", "10.1109/tvcg.2010.138", "10.1109/tvcg.2017.2745078", "10.1109/tvcg.2017.2743978", "10.1111/cgf.12879", "10.1109/iv.2008.33", "10.1111/cgf.13446", "10.1007/s00371-018-1483-0", "10.1109/infvis.1998.729559", "10.1145/2669557.2669572", "10.1111/j.1467-8659.2008.01239.x"], "wos": 1, "children": [], "len": 1}, {"doi": "10.1109/tvcg.2018.2865147", "title": "Mapping Color to Meaning in Colormap Data Visualizations", "year": "2018", "conferenceName": "InfoVis", "authors": "Karen B. Schloss;Connor Gramazio;Allison T. Silverman;Madeline L. Parker;Audrey S. Wang", "citationCount": "4", "affiliation": "Schloss, KB (Corresponding Author), Univ Wisconsin, Dept Psychol, 1202 W Johnson St, Madison, WI 53706 USA. Schloss, KB (Corresponding Author), Univ Wisconsin, Wisconsin Inst Discovery, Madison, WI 53706 USA. Schloss, Karen B.; Parker, Madeline L., Univ Wisconsin, Dept Psychol, 1202 W Johnson St, Madison, WI 53706 USA. Schloss, Karen B.; Parker, Madeline L., Univ Wisconsin, Wisconsin Inst Discovery, Madison, WI 53706 USA. Gramazio, Connor C., Brown Univ, Dept Comp Sci, Providence, RI 02912 USA. Silverman, Allison T., Brown Univ, Sch Publ Hlth, Providence, RI 02912 USA. Wang, Audrey S., CALTECH, Dept Appl \\& Computat Math, Pasadena, CA 91125 USA.", "countries": "USA", "abstract": "To interpret data visualizations, people must determine how visual features map onto concepts. For example, to interpret colormaps, people must determine how dimensions of color (e.g., lightness, hue) map onto quantities of a given measure (e.g., brain activity, correlation magnitude). This process is easier when the encoded mappings in the visualization match people's predictions of how visual features will map onto concepts, their inferred mappings. To harness this principle in visualization design, it is necessary to understand what factors determine people's inferred mappings. In this study, we investigated how inferred color-quantity mappings for colormap data visualizations were influenced by the background color. Prior literature presents seemingly conflicting accounts of how the background color affects inferred color-quantity mappings. The present results help resolve those conflicts, demonstrating that sometimes the background has an effect and sometimes it does not, depending on whether the colormap appears to vary in opacity. When there is no apparent variation in opacity, participants infer that darker colors map to larger quantities (dark-is-more bias). As apparent variation in opacity increases, participants become biased toward inferring that more opaque colors map to larger quantities (opaque-is-more bias). These biases work together on light backgrounds and conflict on dark backgrounds. Under such conflicts, the opaque-is-more bias can negate, or even supersede the dark-is-more bias. The results suggest that if a design goal is to produce colormaps that match people's inferred mappings and are robust to changes in background color, it is beneficial to use colormaps that will not appear to vary in opacity on any background color, and to encode larger quantities in darker colors.", "keywords": "Visual Reasoning,Visual Communication,Colormaps,Color Perception,Visual Encoding,Visual Design", "link": "http://dx.doi.org/10.1109/TVCG.2018.2865147", "refList": ["10.1109/tvcg.2015.2489649", "10.1109/tvcg.2017.2744359", "10.1111/j.1756-8765.2010.01113.x", "10.1109/tvcg.2016.2598918", "10.1007/978-3-642-10520-3\\_9", "10.1016/b978-0-08-042415-6.50014-4", "10.1016/0010-0285(92)90004-l", "10.1006/ijhc.2002.1017", "10.1559/152304090783805663", "10.1037/1076-898x.5.4.393", "10.1126/scitranslmed.aah6904", "10.1179/000870409x12488753453372", "10.1109/6.736450", "10.1037//0033-295x.109.3.492", "10.1006/ijhc.1017", "10.1117/12.384882", "10.3758/bf03201236", "10.1179/000870403235002042", "10.1559/152304097782439231", "10.1109/38.7760", "10.1016/j.neuroimage.2015.04.026", "10.1111/cgf.12127", "10.1109/tvcg.2007.70583", "10.1016/j.cag.2010.11.015", "10.1109/tvcg.2017.2743978", "10.3758/bf03203917", "10.1186/s41235-018-0090-y", "10.1145/3406601.3406602", "10.1016/j.neuroimage.2013.01.068", "10.1109/tvcg.2010.162", "10.1559/152304089783813918", "10.1177/1073858409355817", "10.1016/j.visres.2004.02.009"], "wos": 1, "children": [{"doi": "10.1109/tvcg.2019.2934284", "title": "Color Crafting: Automating the Construction of Designer Quality Color Ramps", "year": "2019", "conferenceName": "InfoVis", "authors": "Stephen Smart;Keke Wu;Danielle Albers Szafir", "citationCount": "3", "affiliation": "Smart, S (Corresponding Author), Univ Colorado, Boulder, CO 80309 USA. Smart, Stephen; Wu, Keke; Szafir, Danielle Albers, Univ Colorado, Boulder, CO 80309 USA.", "countries": "USA", "abstract": "Visualizations often encode numeric data using sequential and diverging color ramps. Effective ramps use colors that are sufficiently discriminable, align well with the data, and are aesthetically pleasing. Designers rely on years of experience to create high-quality color ramps. However, it is challenging for novice visualization developers that lack this experience to craft effective ramps as most guidelines for constructing ramps are loosely defined qualitative heuristics that are often difficult to apply. Our goal is to enable visualization developers to readily create effective color encodings using a single seed color. We do this using an algorithmic approach that models designer practices by analyzing patterns in the structure of designer-crafted color ramps. We construct these models from a corpus of 222 expert-designed color ramps, and use the results to automatically generate ramps that mimic designer practices. We evaluate our approach through an empirical study comparing the outputs of our approach with designer-crafted color ramps. Our models produce ramps that support accurate and aesthetically pleasing visualizations at least as well as designer ramps and that outperform conventional mathematical approaches.", "keywords": "Visualization,Aesthetics in Visualization,Color Perception,Visual Design,Design Mining", "link": "http://dx.doi.org/10.1109/TVCG.2019.2934284", "refList": ["10.1145/3009924", "10.1109/tvcg.2015.2489649", "10.1109/tvcg.2017.2744359", "10.1002/(sici)1098-1098(199622)7:2", "10.1016/s0734-189x(83)80046-2", "10.1109/tvcg.2016.2599106", "10.1364/josaa.29.000313", "10.1109/tvcg.2016.2598918", "10.2307/2683294", "10.1109/tvcg.2017.2653106", "10.1016/j.ijhcs.2010.05.006", "10.1016/0146-664x(81)90006-x", "10.1007/978-3-642-10520-3\\_9", "10.1109/38.135886", "10.1146/annurev-psych-120710-100504", "10.1016/j.csda.2008.11.033", "10.1145/2461912.2461988", "10.1016/j.cub.2007.06.022", "10.1016/s0146-664x(79)80040-4", "10.1109/mcg.2004.1297012", "10.1109/iv.2009.94", "10.1109/tpami.2010.184", "10.3758/s13414-010-0027-0", "10.1145/22949.22950", "10.1109/visual.1995.480803", "10.1109/tvcg.2014.2346277", "10.2307/2684111", "10.1109/tvcg.2018.2865240", "10.1111/cgf.12633", "10.1109/38.7760", "10.1016/j.jspi.2015.04.007", "10.1109/iv.2008.24", "10.1145/2939502.2939506", "10.1111/cgf.12127", "10.1016/j.cag.2010.11.015", "10.1145/3025453.3026041", "10.1109/tvcg.2012.315", "10.2307/2288400", "10.1511/2005.5.436", "10.1016/s0097-8493(96)00072-6", "10.1109/mcg.2018.011461525", "10.1145/2470654.2466420", "10.1109/tvcg.2012.279", "10.1109/tvcg.2014.2346978", "10.1109/tvcg.2017.2743978", "10.1145/3406601.3406602", "10.1117/12.2084548", "10.1109/tvcg.2018.2865147", "10.1109/tvcg.2015.2467191", "10.1111/cgf.13446", "10.1109/tvcg.2017.2744320", "10.1111/j.1467-8659.2008.01203.x", "10.1145/2702613.2702975", "10.1007/978-3-319-26633-6\\_13", "10.1145/2207676.2208547", "10.1109/tvcg.2008.174", "10.1179/000870403235002042"], "wos": 1, "children": [{"doi": "10.1109/tvcg.2020.3028891", "title": "A Structured Review of Data Management Technology for Interactive Visualization and Analysis", "year": "2020", "conferenceName": "InfoVis", "authors": "Leilani Battle;Carlos Scheidegger", "citationCount": "0", "affiliation": "Battle, L (Corresponding Author), Univ Maryland, Dept Comp Sci, College Pk, MD 20742 USA. Battle, Leilani, Univ Maryland, Dept Comp Sci, College Pk, MD 20742 USA. Scheidegger, Carlos, Univ Arizona, Dept Comp Sci, HDC Lab, Tucson, AZ 85721 USA.", "countries": "USA", "abstract": "In the last two decades, interactive visualization and analysis have become a central tool in data-driven decision making. Concurrently to the contributions in data visualization, research in data management has produced technology that directly benefits interactive analysis. Here, we contribute a systematic review of 30 years of work in this adjacent field, and highlight techniques and principles we believe to be underappreciated in visualization work. We structure our review along two axes. First, we use task taxonomies from the visualization literature to structure the space of interactions in usual systems. Second, we created a categorization of data management work that strikes a balance between specificity and generality. Concretely, we contribute a characterization of 131 research papers along these two axes. We find that five notions in data management venues fit interactive visualization systems well: materialized views, approximate query processing, user modeling and query prediction, muiti-query optimization, lineage techniques, and indexing techniques. In addition, we find a preponderance of work in materialized views and approximate query processing, most targeting a limited subset of the interaction tasks in the taxonomy we used. This suggests natural avenues of future research both in visualization and data management. Our categorization both changes how we visualization researchers design and build our systems, and highlights where future work is necessary.", "keywords": "", "link": "http://dx.doi.org/10.1109/TVCG.2020.3028891", "refList": ["10.1109/tvcg.2012.233", "10.1016/s0022-5371(74)80015-0", "10.1109/tvcg.2017.2744359", "10.1037/0096-3445.136.4.623", "10.1109/tvcg.2015.2467732", "10.1109/tvcg.2012.196", "10.1037/a0029856", "10.1109/tvcg.2014.2346979", "10.1037/h0030300", "10.1109/tvcg.2016.2598918", "10.1109/beliv.2018.8634420", "10.1109/tvcg.2018.2864909", "10.1111/cgf.13079", "10.3389/fpsyg.2012.00355", "10.1145/2858036.2858465", "10.1080/01621459.1989.10478821", "10.1037/0278-7393.24.3.732", "10.1109/tvcg.2011.127", "10.1145/2858036.2858063", "10.4249/scholarpedia.3325", "10.4324/9781410611949", "10.1111/cgf.13444", "10.1145/2993901.2993909", "10.1037/0033-295x.96.2.267", "10.1006/ijhc.1017", "10.1086/405615", "10.1109/tvcg.2019.2934801", "10.1038/17953", "10.1037/xhp0000314", "10.1109/tvcg.2019.2934400", "10.1145/2470654.2470723", "10.1037/0096-1523.16.2.332", "10.1167/16.5.11", "10.3758/s13423-016-1174-7", "10.3758/bf03207704", "10.1146/annurev.psych.55.090902.141415", "10.2307/2288400", "10.3758/bf03204258", "10.1109/tvcg.2011.279", "10.1109/vissoft.2014.36", "10.3758/s13423-011-0055-3", "10.1145/3025453.3025922", "10.1109/tvcg.2019.2934284", "10.3758/bf03210498", "10.3758/bf03200774", "10.2307/1419876", "10.1038/s41562-017-0058", "10.1109/tvcg.2010.237", "10.1109/pacificvis.2012.6183556", "10.1109/infvis.1997.636792", "10.1093/acprof:oso/9780198523192.003.0005", "10.1073/pnas.1117465109", "10.1109/tvcg.2013.234", "10.1038/nn.3655", "10.1111/cgf.12379", "10.1146/annurev-psych-010416-044232", "10.1111/cgf.13695", "10.1037/0033-295x.107.3.500", "10.1109/tvcg.2013.183", "10.1146/annurev.psych.53.100901.135125", "10.1037//0022-3514.79.6.995", "10.1559/152304003100010929", "10.1109/tvcg.2018.2865147", "10.1037/0096-1523.18.3.849", "10.1111/j.1467-8659.2009.01694.x", "10.1145/3290605.3300771"], "wos": 1, "children": [], "len": 1}], "len": 3}, {"doi": "10.1109/tvcg.2019.2934536", "title": "Estimating Color-Concept Associations from Image Statistics", "year": "2019", "conferenceName": "InfoVis", "authors": "Ragini Rathore;Zachary Leggon;Laurent Lessard;Karen B. Schloss", "citationCount": "1", "affiliation": "Rathore, R (Corresponding Author), Univ Wisconsin, Comp Sci, Madison, WI 53706 USA. Rathore, R (Corresponding Author), Univ Wisconsin, WID, Madison, WI 53706 USA. Rathore, Ragini, Univ Wisconsin, Comp Sci, Madison, WI 53706 USA. Rathore, Ragini; Leggon, Zachary; Lessard, Laurent; Schloss, Karen B., Univ Wisconsin, WID, Madison, WI 53706 USA. Leggon, Zachary, Univ Wisconsin, Biol, Madison, WI 53706 USA. Lessard, Laurent, Univ Wisconsin, Elect \\& Comp Engn, Madison, WI 53706 USA. Schloss, Karen B., Univ Wisconsin, Psychol, Madison, WI 53706 USA.", "countries": "USA", "abstract": "To interpret the meanings of colors in visualizations of categorical information, people must determine how distinct colors correspond to different concepts. This process is easier when assignments between colors and concepts in visualizations match people's expectations, making color palettes semantically interpretable. Efforts have been underway to optimize color palette design for semantic interpretablity, but this requires having good estimates of human color-concept associations. Obtaining these data from humans is costly, which motivates the need for automated methods. We developed and evaluated a new method for automatically estimating color-concept associations in a way that strongly correlates with human ratings. Building on prior studies using Google Images, our approach operates directly on Google Image search results without the need for humans in the loop. Specifically, we evaluated several methods for extracting raw pixel content of the images in order to best estimate color-concept associations obtained from human ratings. The most effective method extracted colors using a combination of cylindrical sectors and color categories in color space. We demonstrate that our approach can accurately estimate average human color-concept associations for different fruits using only a small set of images. The approach also generalizes moderately well to more complicated recycling-related concepts of objects that can appear in any color.", "keywords": "Visual Reasoning,Visual Communication,Visual Encoding,Color Perception,Color Cognition,Color Categories", "link": "http://dx.doi.org/10.1109/TVCG.2019.2934536", "refList": ["10.1145/3009924", "10.1023/b:bttj.0000047600.45421.6d", "10.1525/ae.1974.1.1.02a00030", "10.1109/tvcg.2017.2744359", "10.1109/tvcg.2016.2598918", "10.1146/annurev-vision-091517-034231", "10.1109/tvcg.2015.2467471", "10.1037/xge0000076", "10.1016/b978-0-08-042415-6.50014-4", "10.1146/annurev-psych-120710-100504", "10.1073/pnas.0906172107", "10.1109/visual.1996.568118", "10.1163/156856808784532662", "10.1073/pnas.1532837100", "10.1016/j.cogpsych.2004.10.001", "10.7717/peerj.453", "10.1037/met0000159", "10.1073/pnas.1619666114", "10.1080/00221309.1962.9711531", "10.1002/col.20010", "10.1037/xlm0000357", "10.1073/pnas.1513298113", "10.1016/0010-0285(73)90017-0", "10.1111/cgf.12127", "10.1007/bf00133570", "10.1145/3025453.3026041", "10.1037/xge0000560", "10.3758/bf03207619", "10.1371/journal.pone.0149538", "10.1186/s41235-018-0090-y", "10.1525/aa.1984.86.1.02a00050", "10.1016/j.apergo.2018.08.010", "10.1073/pnas.0701644104", "10.1109/cvpr.2015.7298965", "10.1002/col.21756", "10.1145/2207676.2208547", "10.1023/a:1008036829907", "10.1109/tvcg.2018.2865147"], "wos": 1, "children": [{"doi": "10.1109/tvcg.2020.3030439", "title": "Rainbows Revisited: Modeling Effective Colormap Design for Graphical Inference", "year": "2020", "conferenceName": "InfoVis", "authors": "Khairi Reda;Danielle Albers Szafir", "citationCount": "0", "affiliation": "Reda, K (Corresponding Author), Indiana Univ Purdue Univ, Indianapolis, IN 46202 USA. Reda, Khairi, Indiana Univ Purdue Univ, Indianapolis, IN 46202 USA. Szafir, Danielle Albers, Univ Colorado, Boulder, CO 80309 USA.", "countries": "USA", "abstract": "Color mapping is a foundational technique for visualizing scalar data. Prior literature offers guidelines for effective colormap design, such as emphasizing luminance variation while limiting changes in hue. However, empirical studies of color are largely focused on perceptual tasks. This narrow focus inhibits our understanding of how generalizable these guidelines are, particularly to tasks like visual inference that require synthesis and judgement across multiple percepts. Furthermore, the emphasis on traditional ramp designs (e.g., sequential or diverging) may sideline other key metrics or design strategies. We study how a cognitive metric-color name variation-impacts people's ability to make model-based judgments. In two graphical inference experiments, participants saw a series of color-coded scalar fields sampled from different models and assessed the relationships between these models. Contrary to conventional guidelines, participants were more accurate when viewing colormaps that cross a variety of uniquely nameable colors. We modeled participants' performance using this metric and found that it provides a better fit to the experimental data than do existing design principles. Our findings indicate cognitive advantages for colorful maps like rainbow, which exhibit high color categorization, despite their traditionally undesirable perceptual properties. We also found no evidence that color categorization would lead observers to infer false data features. Our results provide empirically grounded metrics for predicting a colormap's performance and suggest alternative guidelines for designing new quantitative colormaps to support inference. The data and materials for this paper are available at: https://osf.io/tck2r/", "keywords": "Color,perception,graphical inference,scalar data", "link": "http://dx.doi.org/10.1109/TVCG.2020.3030439", "refList": ["10.1109/tvcg.2012.233", "10.1109/tvcg.2017.2744359", "10.1111/j.1756-8765.2010.01113.x", "10.1109/tvcg.2016.2598918", "10.1109/tvcg.2015.2467471", "10.1016/b978-0-08-042415-6.50014-4", "10.1146/annurev-psych-120710-100504", "10.1080/13875868.2015.1137577", "10.1109/visual.1996.568118", "10.1006/ijhc.1017", "10.1109/tvcg.2014.2346983", "10.3758/bf03201236", "10.2307/2981473", "10.1037/0033-2909.114.3.510", "10.1111/cgf.12127", "10.1002/nav.3800020109", "10.1145/3025453.3026041", "10.1111/j.1756-8765.2011.01150.x", "10.1016/0010-0285(80)90005-5", "10.1207/s15516709cog1003\\_2", "10.1109/tvcg.2019.2934536", "10.1186/s41235-018-0090-y", "10.1023/a:1013180410169", "10.1038/s41562-017-0058", "10.20982/tqmp.01.1.p042", "10.1137/0105003", "10.1559/152304089783813918", "10.1109/tvcg.2018.2865147", "10.1179/000870403235002042", "10.1179/caj.1968.5.1.54"], "wos": 1, "children": [], "len": 1}, {"doi": "10.1109/tvcg.2020.3030434", "title": "Semantic Discriminability for Visual Communication", "year": "2020", "conferenceName": "InfoVis", "authors": "Karen B. Schloss;Zachary Leggon;Laurent Lessard", "citationCount": "0", "affiliation": "Schloss, KB (Corresponding Author), Univ Wisconsin, Psychol, Madison, WI 53706 USA. Schloss, KB (Corresponding Author), Univ Wisconsin, Wisconsin Inst Discovery, Madison, WI 53706 USA. Schloss, Karen B., Univ Wisconsin, Psychol, Madison, WI 53706 USA. Schloss, Karen B.; Leggon, Zachary, Univ Wisconsin, Wisconsin Inst Discovery, Madison, WI 53706 USA. Leggon, Zachary, Univ Wisconsin, Biol, Madison, WI USA. Lessard, Laurent, Northeastern Univ, Mech \\& Ind Engn, Boston, MA 02115 USA.", "countries": "USA", "abstract": "To interpret information visualizations, observers must determine how visual features map onto concepts. First and foremost, this ability depends on perceptual discriminability; observers must be able to see the difference between different colors for those colors to communicate different meanings. However, the ability to interpret visualizations also depends on semantic discriminability, the degree to which observers can infer a unique mapping between visual features and concepts, based on the visual features and concepts alone (i.e., without help from verbal cues such as legends or labels). Previous evidence suggested that observers were better at interpreting encoding systems that maximized semantic discriminability (maximizing association strength between assigned colors and concepts while minimizing association strength between unassigned colors and concepts), compared to a system that only maximized color-concept association strength. However, increasing semantic discriminability also resulted in increased perceptual distance, so it is unclear which factor was responsible for improved performance. In the present study, we conducted two experiments that tested for independent effects of semantic distance and perceptual distance on semantic discriminability of bar graph data visualizations. Perceptual distance was large enough to ensure colors were more than just noticeably different. We found that increasing semantic distance improved performance, independent of variation in perceptual distance, and when these two factors were uncorrelated, responses were dominated by semantic distance. These results have implications for navigating trade-offs in color palette design optimization for visual communication.", "keywords": "Visual Reasoning,Information Visualization,Visual Communication,Visual Encoding,Color Perception,Color Cognition", "link": "http://dx.doi.org/10.1109/TVCG.2020.3030434", "refList": ["10.1109/tvcg.2012.233", "10.1109/tvcg.2017.2744359", "10.1109/tvcg.2016.2598918", "10.1109/tvcg.2015.2467471", "10.1016/b978-0-08-042415-6.50014-4", "10.1146/annurev-psych-120710-100504", "10.1080/13875868.2015.1137577", "10.1109/visual.1996.568118", "10.1006/ijhc.1017", "10.1109/tvcg.2014.2346983", "10.1145/2254556.2254572", "10.3758/bf03201236", "10.2307/2981473", "10.1037/0033-2909.114.3.510", "10.1111/cgf.12127", "10.1002/nav.3800020109", "10.1145/3025453.3026041", "10.1111/j.1756-8765.2011.01150.x", "10.1016/0010-0285(80)90005-5", "10.1207/s15516709cog1003\\_2", "10.1109/tvcg.2019.2934536", "10.1186/s41235-018-0090-y", "10.1023/a:1013180410169", "10.1038/s41562-017-0058", "10.20982/tqmp.01.1.p042", "10.1137/0105003", "10.1559/152304089783813918", "10.1109/tvcg.2018.2865147", "10.1179/000870403235002042", "10.1179/caj.1968.5.1.54"], "wos": 1, "children": [], "len": 1}], "len": 5}, {"doi": "10.1109/tvcg.2020.3028891", "title": "A Structured Review of Data Management Technology for Interactive Visualization and Analysis", "year": "2020", "conferenceName": "InfoVis", "authors": "Leilani Battle;Carlos Scheidegger", "citationCount": "0", "affiliation": "Battle, L (Corresponding Author), Univ Maryland, Dept Comp Sci, College Pk, MD 20742 USA. Battle, Leilani, Univ Maryland, Dept Comp Sci, College Pk, MD 20742 USA. Scheidegger, Carlos, Univ Arizona, Dept Comp Sci, HDC Lab, Tucson, AZ 85721 USA.", "countries": "USA", "abstract": "In the last two decades, interactive visualization and analysis have become a central tool in data-driven decision making. Concurrently to the contributions in data visualization, research in data management has produced technology that directly benefits interactive analysis. Here, we contribute a systematic review of 30 years of work in this adjacent field, and highlight techniques and principles we believe to be underappreciated in visualization work. We structure our review along two axes. First, we use task taxonomies from the visualization literature to structure the space of interactions in usual systems. Second, we created a categorization of data management work that strikes a balance between specificity and generality. Concretely, we contribute a characterization of 131 research papers along these two axes. We find that five notions in data management venues fit interactive visualization systems well: materialized views, approximate query processing, user modeling and query prediction, muiti-query optimization, lineage techniques, and indexing techniques. In addition, we find a preponderance of work in materialized views and approximate query processing, most targeting a limited subset of the interaction tasks in the taxonomy we used. This suggests natural avenues of future research both in visualization and data management. Our categorization both changes how we visualization researchers design and build our systems, and highlights where future work is necessary.", "keywords": "", "link": "http://dx.doi.org/10.1109/TVCG.2020.3028891", "refList": ["10.1109/tvcg.2012.233", "10.1016/s0022-5371(74)80015-0", "10.1109/tvcg.2017.2744359", "10.1037/0096-3445.136.4.623", "10.1109/tvcg.2015.2467732", "10.1109/tvcg.2012.196", "10.1037/a0029856", "10.1109/tvcg.2014.2346979", "10.1037/h0030300", "10.1109/tvcg.2016.2598918", "10.1109/beliv.2018.8634420", "10.1109/tvcg.2018.2864909", "10.1111/cgf.13079", "10.3389/fpsyg.2012.00355", "10.1145/2858036.2858465", "10.1080/01621459.1989.10478821", "10.1037/0278-7393.24.3.732", "10.1109/tvcg.2011.127", "10.1145/2858036.2858063", "10.4249/scholarpedia.3325", "10.4324/9781410611949", "10.1111/cgf.13444", "10.1145/2993901.2993909", "10.1037/0033-295x.96.2.267", "10.1006/ijhc.1017", "10.1086/405615", "10.1109/tvcg.2019.2934801", "10.1038/17953", "10.1037/xhp0000314", "10.1109/tvcg.2019.2934400", "10.1145/2470654.2470723", "10.1037/0096-1523.16.2.332", "10.1167/16.5.11", "10.3758/s13423-016-1174-7", "10.3758/bf03207704", "10.1146/annurev.psych.55.090902.141415", "10.2307/2288400", "10.3758/bf03204258", "10.1109/tvcg.2011.279", "10.1109/vissoft.2014.36", "10.3758/s13423-011-0055-3", "10.1145/3025453.3025922", "10.1109/tvcg.2019.2934284", "10.3758/bf03210498", "10.3758/bf03200774", "10.2307/1419876", "10.1038/s41562-017-0058", "10.1109/tvcg.2010.237", "10.1109/pacificvis.2012.6183556", "10.1109/infvis.1997.636792", "10.1093/acprof:oso/9780198523192.003.0005", "10.1073/pnas.1117465109", "10.1109/tvcg.2013.234", "10.1038/nn.3655", "10.1111/cgf.12379", "10.1146/annurev-psych-010416-044232", "10.1111/cgf.13695", "10.1037/0033-295x.107.3.500", "10.1109/tvcg.2013.183", "10.1146/annurev.psych.53.100901.135125", "10.1037//0022-3514.79.6.995", "10.1559/152304003100010929", "10.1109/tvcg.2018.2865147", "10.1037/0096-1523.18.3.849", "10.1111/j.1467-8659.2009.01694.x", "10.1145/3290605.3300771"], "wos": 1, "children": [], "len": 1}, {"doi": "10.1109/tvcg.2020.3030439", "title": "Rainbows Revisited: Modeling Effective Colormap Design for Graphical Inference", "year": "2020", "conferenceName": "InfoVis", "authors": "Khairi Reda;Danielle Albers Szafir", "citationCount": "0", "affiliation": "Reda, K (Corresponding Author), Indiana Univ Purdue Univ, Indianapolis, IN 46202 USA. Reda, Khairi, Indiana Univ Purdue Univ, Indianapolis, IN 46202 USA. Szafir, Danielle Albers, Univ Colorado, Boulder, CO 80309 USA.", "countries": "USA", "abstract": "Color mapping is a foundational technique for visualizing scalar data. Prior literature offers guidelines for effective colormap design, such as emphasizing luminance variation while limiting changes in hue. However, empirical studies of color are largely focused on perceptual tasks. This narrow focus inhibits our understanding of how generalizable these guidelines are, particularly to tasks like visual inference that require synthesis and judgement across multiple percepts. Furthermore, the emphasis on traditional ramp designs (e.g., sequential or diverging) may sideline other key metrics or design strategies. We study how a cognitive metric-color name variation-impacts people's ability to make model-based judgments. In two graphical inference experiments, participants saw a series of color-coded scalar fields sampled from different models and assessed the relationships between these models. Contrary to conventional guidelines, participants were more accurate when viewing colormaps that cross a variety of uniquely nameable colors. We modeled participants' performance using this metric and found that it provides a better fit to the experimental data than do existing design principles. Our findings indicate cognitive advantages for colorful maps like rainbow, which exhibit high color categorization, despite their traditionally undesirable perceptual properties. We also found no evidence that color categorization would lead observers to infer false data features. Our results provide empirically grounded metrics for predicting a colormap's performance and suggest alternative guidelines for designing new quantitative colormaps to support inference. The data and materials for this paper are available at: https://osf.io/tck2r/", "keywords": "Color,perception,graphical inference,scalar data", "link": "http://dx.doi.org/10.1109/TVCG.2020.3030439", "refList": ["10.1109/tvcg.2012.233", "10.1109/tvcg.2017.2744359", "10.1111/j.1756-8765.2010.01113.x", "10.1109/tvcg.2016.2598918", "10.1109/tvcg.2015.2467471", "10.1016/b978-0-08-042415-6.50014-4", "10.1146/annurev-psych-120710-100504", "10.1080/13875868.2015.1137577", "10.1109/visual.1996.568118", "10.1006/ijhc.1017", "10.1109/tvcg.2014.2346983", "10.3758/bf03201236", "10.2307/2981473", "10.1037/0033-2909.114.3.510", "10.1111/cgf.12127", "10.1002/nav.3800020109", "10.1145/3025453.3026041", "10.1111/j.1756-8765.2011.01150.x", "10.1016/0010-0285(80)90005-5", "10.1207/s15516709cog1003\\_2", "10.1109/tvcg.2019.2934536", "10.1186/s41235-018-0090-y", "10.1023/a:1013180410169", "10.1038/s41562-017-0058", "10.20982/tqmp.01.1.p042", "10.1137/0105003", "10.1559/152304089783813918", "10.1109/tvcg.2018.2865147", "10.1179/000870403235002042", "10.1179/caj.1968.5.1.54"], "wos": 1, "children": [], "len": 1}, {"doi": "10.1109/tvcg.2020.3030434", "title": "Semantic Discriminability for Visual Communication", "year": "2020", "conferenceName": "InfoVis", "authors": "Karen B. Schloss;Zachary Leggon;Laurent Lessard", "citationCount": "0", "affiliation": "Schloss, KB (Corresponding Author), Univ Wisconsin, Psychol, Madison, WI 53706 USA. Schloss, KB (Corresponding Author), Univ Wisconsin, Wisconsin Inst Discovery, Madison, WI 53706 USA. Schloss, Karen B., Univ Wisconsin, Psychol, Madison, WI 53706 USA. Schloss, Karen B.; Leggon, Zachary, Univ Wisconsin, Wisconsin Inst Discovery, Madison, WI 53706 USA. Leggon, Zachary, Univ Wisconsin, Biol, Madison, WI USA. Lessard, Laurent, Northeastern Univ, Mech \\& Ind Engn, Boston, MA 02115 USA.", "countries": "USA", "abstract": "To interpret information visualizations, observers must determine how visual features map onto concepts. First and foremost, this ability depends on perceptual discriminability; observers must be able to see the difference between different colors for those colors to communicate different meanings. However, the ability to interpret visualizations also depends on semantic discriminability, the degree to which observers can infer a unique mapping between visual features and concepts, based on the visual features and concepts alone (i.e., without help from verbal cues such as legends or labels). Previous evidence suggested that observers were better at interpreting encoding systems that maximized semantic discriminability (maximizing association strength between assigned colors and concepts while minimizing association strength between unassigned colors and concepts), compared to a system that only maximized color-concept association strength. However, increasing semantic discriminability also resulted in increased perceptual distance, so it is unclear which factor was responsible for improved performance. In the present study, we conducted two experiments that tested for independent effects of semantic distance and perceptual distance on semantic discriminability of bar graph data visualizations. Perceptual distance was large enough to ensure colors were more than just noticeably different. We found that increasing semantic distance improved performance, independent of variation in perceptual distance, and when these two factors were uncorrelated, responses were dominated by semantic distance. These results have implications for navigating trade-offs in color palette design optimization for visual communication.", "keywords": "Visual Reasoning,Information Visualization,Visual Communication,Visual Encoding,Color Perception,Color Cognition", "link": "http://dx.doi.org/10.1109/TVCG.2020.3030434", "refList": ["10.1109/tvcg.2012.233", "10.1109/tvcg.2017.2744359", "10.1109/tvcg.2016.2598918", "10.1109/tvcg.2015.2467471", "10.1016/b978-0-08-042415-6.50014-4", "10.1146/annurev-psych-120710-100504", "10.1080/13875868.2015.1137577", "10.1109/visual.1996.568118", "10.1006/ijhc.1017", "10.1109/tvcg.2014.2346983", "10.1145/2254556.2254572", "10.3758/bf03201236", "10.2307/2981473", "10.1037/0033-2909.114.3.510", "10.1111/cgf.12127", "10.1002/nav.3800020109", "10.1145/3025453.3026041", "10.1111/j.1756-8765.2011.01150.x", "10.1016/0010-0285(80)90005-5", "10.1207/s15516709cog1003\\_2", "10.1109/tvcg.2019.2934536", "10.1186/s41235-018-0090-y", "10.1023/a:1013180410169", "10.1038/s41562-017-0058", "10.20982/tqmp.01.1.p042", "10.1137/0105003", "10.1559/152304089783813918", "10.1109/tvcg.2018.2865147", "10.1179/000870403235002042", "10.1179/caj.1968.5.1.54"], "wos": 1, "children": [], "len": 1}], "len": 17}, {"doi": "10.1109/tvcg.2019.2934260", "title": "Artifact-Based Rendering: Harnessing Natural and Traditional Visual Media for More Expressive and Engaging 3D Visualizations", "year": "2019", "conferenceName": "SciVis", "authors": "Seth Johnson;Francesca Samsel;Greg Abram;Daniel Olson;Andrew J. Solis;Bridger Herman;Phillip J. Wolfram;Christophe Lenglet;Daniel F. Keefe", "citationCount": "1", "affiliation": "Johnson, S (Corresponding Author), Univ Minnesota, Minneapolis, MN 55455 USA. Johnson, Seth; Olson, Daniel; Herman, Bridger; Lenglet, Christophe; Keefe, Daniel F., Univ Minnesota, Minneapolis, MN 55455 USA. Samsel, Francesca; Abram, Gregory, Univ Texas Austin, Austin, TX 78712 USA. Wolfram, Phillip J., Los Alamos Natl Lab, Fluid Dynam \\& Solid Mech Theoret Div, Los Alamos, NM USA.", "countries": "USA", "abstract": "We introduce Artifact-Based Rendering (ABR), a framework of tools, algorithms, and processes that makes it possible to produce real, data-driven 3D scientific visualizations with a visual language derived entirely from colors, lines, textures, and forms created using traditional physical media or found in nature. A theory and process for ABR is presented to address three current needs: (i) designing better visualizations by making it possible for non-programmers to rapidly design and critique many alternative data-to-visual mappings; (ii) expanding the visual vocabulary used in scientific visualizations to depict increasingly complex multivariate data; (iii) bringing a more engaging, natural, and human-relatable handcrafted aesthetic to data visualization. New tools and algorithms to support ABR include front-end applets for constructing artifact-based colormaps, optimizing 3D scanned meshes for use in data visualization, and synthesizing textures from artifacts. These are complemented by an interactive rendering engine with custom algorithms and interfaces that demonstrate multiple new visual styles for depicting point, line, surface, and volume data. A within-the-research-team design study provides early evidence of the shift in visualization design processes that ABR is believed to enable when compared to traditional scientific visualization systems. Qualitative user feedback on applications to climate science and brain imaging support the utility of ABR for scientific discovery and public communication.", "keywords": "Visualization Design,Art and Visualization,Data Physicalization,Multivariate Visualization", "link": "http://dx.doi.org/10.1109/TVCG.2019.2934260", "refList": ["10.1109/tvcg.2015.2489649", "10.1016/s0967-0645(01)00108-4", "10.1145/2702123.2702558", "10.1145/344779.345012", "10.1109/visual.1999.809905", "10.1109/visual.2001.964510", "10.1057/palgrave.ivs.9500025", "10.1109/38.988741", "10.1007/978-3-642-10520-3\\_9", "10.1038/srep38927", "10.17226/24988", "10.1109/visual.1998.745294", "10.1109/mcg.2016.66", "10.2307/1578648", "10.1145/882262.882342", "10.1117/12.384882", "10.1109/mcg.2005.34", "10.1109/tvcg.2008.31", "10.2312/sbm/sbm10/049-056", "10.1145/2556288.2557144", "10.2312/vissym/vissym04/147-154", "10.1016/j.cag.2011.01.011", "10.1109/mcg.2000.888001", "10.1145/200972.200974", "10.1145/1323688.1323689", "10.1175/jpo-d-14-0260.1", "10.1109/tvcg.2016.2549018", "10.1145/1620993.1621006", "10.2307/2684568", "10.1016/j.ocemod.2014.12.004", "10.1109/toh.2011.54", "10.1145/2702123.2702180", "10.1109/2945.773807", "10.1109/tvcg.2015.2467153", "10.1109/tvcg.2017.2743978", "10.1109/tvcg.2013.191", "10.1109/tvcg.2003.1260745", "10.1093/iwc/iww015", "10.1109/visual.2002.1183824", "10.1145/2702613.2702659", "10.1175/jcli-d-12-00566.1", "10.1145/2702613.2702975", "10.1016/j.ocemod.2013.04.010", "10.1002/2015jg003017", "10.1007/978-3-319-28588-7\\_5", "10.1109/tvcg.2011.261", "10.1109/mcg.2017.38", "10.1145/2393347.2393384"], "wos": 1, "children": [], "len": 1}, {"doi": "10.1109/tvcg.2019.2934284", "title": "Color Crafting: Automating the Construction of Designer Quality Color Ramps", "year": "2019", "conferenceName": "InfoVis", "authors": "Stephen Smart;Keke Wu;Danielle Albers Szafir", "citationCount": "3", "affiliation": "Smart, S (Corresponding Author), Univ Colorado, Boulder, CO 80309 USA. Smart, Stephen; Wu, Keke; Szafir, Danielle Albers, Univ Colorado, Boulder, CO 80309 USA.", "countries": "USA", "abstract": "Visualizations often encode numeric data using sequential and diverging color ramps. Effective ramps use colors that are sufficiently discriminable, align well with the data, and are aesthetically pleasing. Designers rely on years of experience to create high-quality color ramps. However, it is challenging for novice visualization developers that lack this experience to craft effective ramps as most guidelines for constructing ramps are loosely defined qualitative heuristics that are often difficult to apply. Our goal is to enable visualization developers to readily create effective color encodings using a single seed color. We do this using an algorithmic approach that models designer practices by analyzing patterns in the structure of designer-crafted color ramps. We construct these models from a corpus of 222 expert-designed color ramps, and use the results to automatically generate ramps that mimic designer practices. We evaluate our approach through an empirical study comparing the outputs of our approach with designer-crafted color ramps. Our models produce ramps that support accurate and aesthetically pleasing visualizations at least as well as designer ramps and that outperform conventional mathematical approaches.", "keywords": "Visualization,Aesthetics in Visualization,Color Perception,Visual Design,Design Mining", "link": "http://dx.doi.org/10.1109/TVCG.2019.2934284", "refList": ["10.1145/3009924", "10.1109/tvcg.2015.2489649", "10.1109/tvcg.2017.2744359", "10.1002/(sici)1098-1098(199622)7:2", "10.1016/s0734-189x(83)80046-2", "10.1109/tvcg.2016.2599106", "10.1364/josaa.29.000313", "10.1109/tvcg.2016.2598918", "10.2307/2683294", "10.1109/tvcg.2017.2653106", "10.1016/j.ijhcs.2010.05.006", "10.1016/0146-664x(81)90006-x", "10.1007/978-3-642-10520-3\\_9", "10.1109/38.135886", "10.1146/annurev-psych-120710-100504", "10.1016/j.csda.2008.11.033", "10.1145/2461912.2461988", "10.1016/j.cub.2007.06.022", "10.1016/s0146-664x(79)80040-4", "10.1109/mcg.2004.1297012", "10.1109/iv.2009.94", "10.1109/tpami.2010.184", "10.3758/s13414-010-0027-0", "10.1145/22949.22950", "10.1109/visual.1995.480803", "10.1109/tvcg.2014.2346277", "10.2307/2684111", "10.1109/tvcg.2018.2865240", "10.1111/cgf.12633", "10.1109/38.7760", "10.1016/j.jspi.2015.04.007", "10.1109/iv.2008.24", "10.1145/2939502.2939506", "10.1111/cgf.12127", "10.1016/j.cag.2010.11.015", "10.1145/3025453.3026041", "10.1109/tvcg.2012.315", "10.2307/2288400", "10.1511/2005.5.436", "10.1016/s0097-8493(96)00072-6", "10.1109/mcg.2018.011461525", "10.1145/2470654.2466420", "10.1109/tvcg.2012.279", "10.1109/tvcg.2014.2346978", "10.1109/tvcg.2017.2743978", "10.1145/3406601.3406602", "10.1117/12.2084548", "10.1109/tvcg.2018.2865147", "10.1109/tvcg.2015.2467191", "10.1111/cgf.13446", "10.1109/tvcg.2017.2744320", "10.1111/j.1467-8659.2008.01203.x", "10.1145/2702613.2702975", "10.1007/978-3-319-26633-6\\_13", "10.1145/2207676.2208547", "10.1109/tvcg.2008.174", "10.1179/000870403235002042"], "wos": 1, "children": [{"doi": "10.1109/tvcg.2020.3028891", "title": "A Structured Review of Data Management Technology for Interactive Visualization and Analysis", "year": "2020", "conferenceName": "InfoVis", "authors": "Leilani Battle;Carlos Scheidegger", "citationCount": "0", "affiliation": "Battle, L (Corresponding Author), Univ Maryland, Dept Comp Sci, College Pk, MD 20742 USA. Battle, Leilani, Univ Maryland, Dept Comp Sci, College Pk, MD 20742 USA. Scheidegger, Carlos, Univ Arizona, Dept Comp Sci, HDC Lab, Tucson, AZ 85721 USA.", "countries": "USA", "abstract": "In the last two decades, interactive visualization and analysis have become a central tool in data-driven decision making. Concurrently to the contributions in data visualization, research in data management has produced technology that directly benefits interactive analysis. Here, we contribute a systematic review of 30 years of work in this adjacent field, and highlight techniques and principles we believe to be underappreciated in visualization work. We structure our review along two axes. First, we use task taxonomies from the visualization literature to structure the space of interactions in usual systems. Second, we created a categorization of data management work that strikes a balance between specificity and generality. Concretely, we contribute a characterization of 131 research papers along these two axes. We find that five notions in data management venues fit interactive visualization systems well: materialized views, approximate query processing, user modeling and query prediction, muiti-query optimization, lineage techniques, and indexing techniques. In addition, we find a preponderance of work in materialized views and approximate query processing, most targeting a limited subset of the interaction tasks in the taxonomy we used. This suggests natural avenues of future research both in visualization and data management. Our categorization both changes how we visualization researchers design and build our systems, and highlights where future work is necessary.", "keywords": "", "link": "http://dx.doi.org/10.1109/TVCG.2020.3028891", "refList": ["10.1109/tvcg.2012.233", "10.1016/s0022-5371(74)80015-0", "10.1109/tvcg.2017.2744359", "10.1037/0096-3445.136.4.623", "10.1109/tvcg.2015.2467732", "10.1109/tvcg.2012.196", "10.1037/a0029856", "10.1109/tvcg.2014.2346979", "10.1037/h0030300", "10.1109/tvcg.2016.2598918", "10.1109/beliv.2018.8634420", "10.1109/tvcg.2018.2864909", "10.1111/cgf.13079", "10.3389/fpsyg.2012.00355", "10.1145/2858036.2858465", "10.1080/01621459.1989.10478821", "10.1037/0278-7393.24.3.732", "10.1109/tvcg.2011.127", "10.1145/2858036.2858063", "10.4249/scholarpedia.3325", "10.4324/9781410611949", "10.1111/cgf.13444", "10.1145/2993901.2993909", "10.1037/0033-295x.96.2.267", "10.1006/ijhc.1017", "10.1086/405615", "10.1109/tvcg.2019.2934801", "10.1038/17953", "10.1037/xhp0000314", "10.1109/tvcg.2019.2934400", "10.1145/2470654.2470723", "10.1037/0096-1523.16.2.332", "10.1167/16.5.11", "10.3758/s13423-016-1174-7", "10.3758/bf03207704", "10.1146/annurev.psych.55.090902.141415", "10.2307/2288400", "10.3758/bf03204258", "10.1109/tvcg.2011.279", "10.1109/vissoft.2014.36", "10.3758/s13423-011-0055-3", "10.1145/3025453.3025922", "10.1109/tvcg.2019.2934284", "10.3758/bf03210498", "10.3758/bf03200774", "10.2307/1419876", "10.1038/s41562-017-0058", "10.1109/tvcg.2010.237", "10.1109/pacificvis.2012.6183556", "10.1109/infvis.1997.636792", "10.1093/acprof:oso/9780198523192.003.0005", "10.1073/pnas.1117465109", "10.1109/tvcg.2013.234", "10.1038/nn.3655", "10.1111/cgf.12379", "10.1146/annurev-psych-010416-044232", "10.1111/cgf.13695", "10.1037/0033-295x.107.3.500", "10.1109/tvcg.2013.183", "10.1146/annurev.psych.53.100901.135125", "10.1037//0022-3514.79.6.995", "10.1559/152304003100010929", "10.1109/tvcg.2018.2865147", "10.1037/0096-1523.18.3.849", "10.1111/j.1467-8659.2009.01694.x", "10.1145/3290605.3300771"], "wos": 1, "children": [], "len": 1}], "len": 3}, {"doi": "10.1109/tvcg.2020.3028955", "title": "A Testing Environment for Continuous Colormaps", "year": "2020", "conferenceName": "SciVis", "authors": "Pascal Nardini;Min Chen;Roxana Bujack;Michael B\u00f6ttinger;Gerik Scheuermann", "citationCount": "0", "affiliation": "Nardini, P (Corresponding Author), Univ Leipzig, Inst Comp Sci, Leipzig, Germany. Nardini, P.; Scheuermann, G., Univ Leipzig, Inst Comp Sci, Leipzig, Germany. Chen, M., Univ Oxford, Dept Engn Sci, Oxford, England. Bujack, R., Los Alamos Natl Lab, Data Sci Scale Team, Los Alamos, NM USA. Boettinger, M., German Climate Comp Ctr DKRZ, Hamburg, Germany.", "countries": "Germany;USA;England", "abstract": "Many computer science disciplines (e.g., combinatorial optimization, natural language processing, and information retrieval) use standard or established test suites for evaluating algorithms. In visualization, similar approaches have been adopted in some areas (e.g., volume visualization), while user testimonies and empirical studies have been the dominant means of evaluation in most other areas, such as designing colormaps. In this paper, we propose to establish a test suite for evaluating the design of colormaps. With such a suite, the users can observe the effects when different continuous colormaps are applied to planar scalar fields that may exhibit various characteristic features, such as jumps, local extrema, ridge or valley lines, different distributions of scalar values, different gradients, different signal frequencies, different levels of noise, and so on. The suite also includes an expansible collection of real-world data sets including the most popular data for colormap testing in the visualization literature. The test suite has been integrated into a web-based application for creating continuous colormaps (https://ccctool.com/), facilitating close inter-operation between design and evaluation processes. This new facility complements traditional evaluation methods such as user testimonies and empirical studies.", "keywords": "Testing Environment,Color Perception,Scalar Analysis", "link": "http://dx.doi.org/10.1109/TVCG.2020.3028955", "refList": ["10.1109/tvcg.2015.2489649", "10.1016/s0734-189x(83)80046-2", "10.1109/visual.2001.964510", "10.1109/mcg.2007.323435", "10.1016/b978-012387582-2/50040-x", "10.1109/visual.2002.1183788", "10.1016/0146-664x(81)90006-x", "10.1007/978-3-642-10520-3\\_9", "10.2312/eurovisshort.20151135", "10.1016/b978-0-08-042415-6.50014-4", "10.1109/38.135886", "10.1016/j.csda.2008.11.033", "10.1117/12.172680", "10.1109/6.736450", "10.1016/j.physd.2005.10.007", "10.1016/s0146-664x(79)80040-4", "10.1109/mcg.2011.55", "10.1109/mcg.1986.276688", "10.1109/visual.1995.480803", "10.1117/12.384882", "10.1145/3205455", "10.1214/aoms/1177706645", "10.1117/12.135996", "10.1016/b978-012387582-2/50038-1", "10.1002/col.1049", "10.2307/2684111", "10.1111/cgf.12933", "10.1109/38.7760", "10.1117/12.387169", "10.1109/tvcg.2016.2599214", "10.1109/ldav.2013.6675161", "10.1109/iv.2008.24", "10.1016/j.cag.2010.11.015", "10.1109/tvcg.2008.118", "10.1109/visual.1994.346331", "10.1109/tns.1982.4332189", "10.2151/jmsj.2020-021", "10.1109/tvcg.2017.2743978", "10.1057/978-1-137-55503-8\\_2", "10.1029/2004e0400002", "10.1111/cgf.12379", "10.1023/a:1008293323270", "10.2312/envirvis.20171105", "10.1109/tvcg.2019.2961674", "10.1145/2702613.2702975", "10.1007/s10915-011-9501-7"], "wos": 1, "children": [], "len": 1}, {"doi": "10.1109/tvcg.2020.3030422", "title": "Truth or Square: Aspect Ratio Biases Recall of Position Encodings", "year": "2020", "conferenceName": "InfoVis", "authors": "Cristina R. Ceja;Caitlyn M. McColeman;Cindy Xiong;Steven Franconeri", "citationCount": "1", "affiliation": "Ceja, CR (Corresponding Author), Northwestern Univ, Evanston, IL 60208 USA. Ceja, Cristina R.; McColeman, Caitlyn M.; Xiong, Cindy; Franconeri, Steven L., Northwestern Univ, Evanston, IL 60208 USA. Xiong, Cindy, Univ Massachusetts, Amherst, MA 01003 USA.", "countries": "USA", "abstract": "Bar charts are among the most frequently used visualizations, in part because their position encoding leads them to convey data values precisely. Yet reproductions of single bars or groups of bars within a graph can be biased. Curiously, some previous work found that this bias resulted in an overestimation of reproduced data values, while other work found an underestimation. Across three empirical studies, we offer an explanation for these conflicting findings: this discrepancy is a consequence of the differing aspect ratios of the tested bar marks. Viewers are biased to remember a bar mark as being more similar to a prototypical square, leading to an overestimation of bars with a wide aspect ratio, and an underestimation of bars with a tall aspect ratio. Experiments 1 and 2 showed that the aspect ratio of the bar marks indeed influenced the direction of this bias. Experiment 3 confirmed that this pattern of misestimation bias was present for reproductions from memory, suggesting that this bias may arise when comparing values across sequential displays or views. We describe additional visualization designs that might be prone to this bias beyond bar charts (e.g., Mekko charts and treemaps), and speculate that other visual channels might hold similar biases toward prototypical values.", "keywords": "Memory biases,position estimation,bar charts,aspect ratio,area", "link": "http://dx.doi.org/10.1109/TVCG.2020.3030422", "refList": ["10.1109/tvcg.2015.2489649", "10.1016/s0734-189x(83)80046-2", "10.1109/visual.2001.964510", "10.1109/mcg.2007.323435", "10.1016/b978-012387582-2/50040-x", "10.1109/visual.2002.1183788", "10.1016/0146-664x(81)90006-x", "10.1007/978-3-642-10520-3\\_9", "10.2312/eurovisshort.20151135", "10.1016/b978-0-08-042415-6.50014-4", "10.1016/j.csda.2008.11.033", "10.1117/12.172680", "10.1109/6.736450", "10.1016/j.physd.2005.10.007", "10.1016/s0146-664x(79)80040-4", "10.1109/mcg.2011.55", "10.1117/12.384882", "10.1214/aoms/1177706645", "10.1145/3205455", "10.1016/b978-012387582-2/50038-1", "10.1002/col.1049", "10.2307/2684111", "10.1109/38.7760", "10.1109/tvcg.2016.2599214", "10.1109/ldav.2013.6675161", "10.1109/iv.2008.24", "10.1016/j.cag.2010.11.015", "10.1109/tvcg.2008.118", "10.1109/visual.1994.346331", "10.2151/jmsj.2020-021", "10.1109/tvcg.2017.2743978", "10.1057/978-1-137-55503-8\\_2", "10.1029/2004e0400002", "10.1111/cgf.12379", "10.1023/a:1008293323270", "10.1109/tvcg.2019.2961674", "10.1145/2702613.2702975"], "wos": 1, "children": [], "len": 1}], "len": 31}, "index": 640, "embedding": [1.4735857248306274, 1.2568621635437012, -1.060706377029419, -0.4705043137073517, -0.6745967864990234, 0.16650904715061188, -0.700136661529541, 2.3672232627868652, -0.43282294273376465, 2.330605983734131, -0.06899998337030411, 0.4726206362247467, -0.13324885070323944, 0.19532056152820587, -0.678647518157959, 2.4994945526123047, 0.00874093547463417, 5.667067527770996, -0.650787889957428, 3.1455774307250977, -0.06630208343267441, 3.662851095199585, 0.05630001425743103, 2.7012410163879395, -0.9675361514091492, 1.825495958328247, -0.5500518083572388, 0.7695070505142212, 2.3772647380828857, 0.19186176359653473, -0.15037801861763, 1.6178605556488037], "projection": [-0.41596511006355286, 10.48652172088623], "size": 16, "height": 4, "width": 6}