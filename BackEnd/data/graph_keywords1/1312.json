{"data": {"doi": "10.1111/cgf.12654", "year": "2015", "title": "Feature-Driven Visual Analytics of Chaotic Parameter-Dependent Movement", "conferenceName": "EuroVis", "authors": "Martin Luboschik;Martin Rohlig;Arne T. Bittig;Natalia V. Andrienko;Heidrun Schumann;Christian Tominski", "citationCount": "2", "affiliation": "Luboschik, M (Corresponding Author), Univ Rostock, Inst Comp Sci, D-18055 Rostock, Germany.\nLuboschik, M.; Roehlig, M.; Bittig, A. T.; Schumann, H.; Tominski, C., Univ Rostock, Inst Comp Sci, D-18055 Rostock, Germany.\nAndrienko, N., Fraunhofer IAIS Bonn, Bonn, Germany.\nAndrienko, N., City Univ London, London, England.", "countries": "Germany;England", "abstract": "Analyzing movements in their spatial and temporal context is a complex task. We are additionally interested in understanding the movements' dependency on parameters that govern the processes behind the movement. We propose a visual analytics approach combining analytic, visual, and interactive means to deal with the added complexity. The key idea is to perform an analytical extraction of features that capture distinct movement characteristics. Different parameter configurations and extracted features are then visualized in a compact fashion to facilitate an overview of the data. Interaction enables the user to access details about features, to compare features, and to relate features back to the original movement. We instantiate our approach with a repository of more than twenty accepted and novel features to help analysts in gaining insight into simulations of chaotic behavior of thousands of entities over thousands of data points. Domain experts applied our solution successfully to study dynamic groups in such movements in relation to thousands of parameter configurations.", "keywords": "", "link": "https://doi.org/10.1111/cgf.12654", "refList": ["10.1109/tvcg.2011.248", "10.1109/tvcg.2013.61", "10.1007/978-3-642-37583-5", "10.1080/13658816.2010.511223.4", "10.1111/j.1467-8659.2009.01440.x", "10.1109/tcbb.2013.40", "10.1109/tvcg.2013.144", "10.1109/tvcg.2013.193.2", "10.1111/cgf.12369", "10.1109/tvcg.2010.190.2", "10.1109/tvcg.2007.70583.6", "10.1109/mcg.2014.52", "10.1145/2037509.2037533", "10.1038/nrm1838", "10.1007/pl00013399", "10.1111/j.1467-8659.2011.01940.x", "10.1109/tvcg.2014.2346321", "10.1016/j.tcb.2009.01.003", "10.2312/pe/eurovast/eurova11/041-044", "10.1057/palgrave.ivs.9500183", "10.1109/tvcg.2014.2346744.3", "10.3138/carto.46.4.239", "10.1073/pnas.0906885107", "10.1016/j.cag.2013.09.004.2,8", "10.1128/mcb.26.1.313-323.2006", "10.1177/1473871613477851", "10.1111/j.1467-8659.2009.01684.x", "10.1111/j.1467-8659.2011.01920.x", "10.1109/tvcg.2004.39", "10.1179/000870403235002042"], "wos": 1, "children": [{"doi": "10.1109/tvcg.2018.2865049", "title": "MotionRugs: Visualizing Collective Trends in Space and Time", "year": "2018", "conferenceName": "VAST", "authors": "Juri Buchm\u00fcller;Dominik J\u00e4ckle;Eren Cakmak;Ulrik Brandes;Daniel A. Keim", "citationCount": "4", "affiliation": "Buchmuller, J (Corresponding Author), Univ Konstanz, Constance, Germany. Buchmueller, Jun; Jaeckie, Dominik; Cakmak, Eren; Keim, Daniel A., Univ Konstanz, Constance, Germany. Brandes, Ulrik, Swiss Fed Inst Technol, Zurich, Switzerland.", "countries": "Germany;Switzerland", "abstract": "Understanding the movement patterns of collectives, such as flocks of birds or fish swarms, is an interesting open research question. The collectives are driven by mutual objectives or react to individual direction changes and external influence factors and stimuli. The challenge in visualizing collective movement data is to show space and time of hundreds of movements at the same time to enable the detection of spatiotemporal patterns. In this paper, we propose MotionRugs, a novel space efficient technique for visualizing moving groups of entities. Building upon established space-partitioning strategies, our approach reduces the spatial dimensions in each time step to a one-dimensional ordered representation of the individual entities. By design, MotionRugs provides an overlap-free, compact overview of the development of group movements over time and thus, enables analysts to visually identify and explore group-specific temporal patterns. We demonstrate the usefulness of our approach in the field of fish swarm analysis and report on initial feedback of domain experts from the field of collective behavior.", "keywords": "Spatio-Temporal Visualization,Spatial Abstraction,Spatial Index Structures,Collective Movement", "link": "http://dx.doi.org/10.1109/TVCG.2018.2865049", "refList": ["10.1007/978-0-387-39940-9\\_1131", "10.1109/tvcg.2013.193", "10.1109/pacificvis.2014.57", "10.1109/tvcg.2015.2417572", "10.1007/bf01199431", "10.1111/j.1467-8659.2009.01440.x", "10.1109/tvcg.2011.226", "10.1145/1376616.1376618", "10.1177/1473871612457601", "10.1109/tvcg.2010.75", "10.1109/tvcg.2013.263", "10.1109/vast.2009.5332593", "10.1145/130881.130882", "10.1080/13658816.2016.1199806", "10.1109/tvcg.2013.192", "10.1109/tvcg.2006.193", "10.5220/0005716900480059", "10.1007/bf00288933", "10.1111/cgf.12654", "10.1080/13658816.2015.1081205", "10.1109/icdm.2003.1250978", "10.1145/361002.361007", "10.1109/pacificvis.2014.48", "10.1109/iv.2008.24", "10.1016/s1045-926x(03)00046-6", "10.1145/1520340.1520516", "10.3138/carto.42.4.349", "10.1007/s10844-006-9952-8", "10.1109/tvcg.2008.125", "10.1109/vast.2014.7042477", "10.1109/tvcg.2009.145", "10.1109/tvcg.2012.265", "10.1179/000870410x12658023467367", "10.2307/2332226", "10.1109/tvcg.2010.78", "10.1016/0146-664x(82)90128-9", "10.1177/1473871613477851", "10.1145/93597.98742", "10.1111/cgf.12653", "10.1145/93597.98741", "10.1179/000870403235002042"], "wos": 1, "children": [{"doi": "10.1109/tvcg.2019.2934671", "title": "A Natural-language-based Visual Query Approach of Uncertain Human Trajectories", "year": "2019", "conferenceName": "VAST", "authors": "Zhaosong Huang;Ye Zhao;Wei Chen;Shengjie Gao;Kejie Yu;Weixia Xu;MingJie Tang;Minfeng Zhu;Mingliang Xu", "citationCount": "0", "affiliation": "Chen, W (Corresponding Author), Zhejiang Univ, State Key Lab CAD \\& CG, Hangzhou, Peoples R China. Xu, ML (Corresponding Author), Zhengzhou Univ, Sch Informat Engn, Zhengzhou 450000, Peoples R China. Huang, Zhaosong; Chen, Wei; Gao, Shengjie; Yu, Kejie; Xu, Weixia; Zhu, Minfeng, Zhejiang Univ, State Key Lab CAD \\& CG, Hangzhou, Peoples R China. Zhao, Ye, Kent State Univ, Dept Comp Sci, Kent, OH 44242 USA. Tang, Mingjie, Ant Financial, San Mateo, CA USA. Xu, Mingliang, Zhengzhou Univ, Sch Informat Engn, Zhengzhou 450000, Peoples R China.", "countries": "USA;China", "abstract": "Visual querying is essential for interactively exploring massive trajectory data. However, the data uncertainty imposes profound challenges to fulfill advanced analytics requirements. On the one hand, many underlying data does not contain accurate geographic coordinates, e.g., positions of a mobile phone only refer to the regions (i.e., mobile cell stations) in which it resides, instead of accurate GPS coordinates. On the other hand, domain experts and general users prefer a natural way, such as using a natural language sentence, to access and analyze massive movement data. In this paper, we propose a visual analytics approach that can extract spatial-temporal constraints from a textual sentence and support an effective query method over uncertain mobile trajectory data. It is built up on encoding massive, spatially uncertain trajectories by the semantic information of the POls and regions covered by them, and then storing the trajectory documents in text database with an effective indexing scheme. The visual interface facilitates query condition specification, situation-aware visualization, and semantic exploration of large trajectory data. Usage scenarios on real-world human mobility datasets demonstrate the effectiveness of our approach.", "keywords": "Natural-language-based Visual Query,Spatial Uncertaity,Trajectory Exploration", "link": "http://dx.doi.org/10.1109/TVCG.2019.2934671", "refList": ["10.1017/s1351324909005129", "10.1109/tvcg.2013.226", "10.1109/tvcg.2018.2864503", "10.1561/1500000019", "10.1109/icde.2010.5447829", "10.1109/tvcg.2008.172", "10.1177/1473871612457601", "10.1145/2442810.2442828", "10.1109/pacificvis.2014.50", "10.1109/vast.2014.7042486", "10.1201/9781420008609.ch3", "10.1177/1473871613480062", "10.1109/tvcg.2017.2744159", "10.1145/2629592", "10.1109/tvcg.2016.2616404", "10.1109/vl.1996.545307", "10.5311/josis.2012.4.62", "10.5220/0005716900480059", "10.1109/tvcg.2018.2865049", "10.1109/tvcg.2015.2467619", "10.1109/tvcg.2015.2467771", "10.1109/tvcg.2011.233", "10.1186/s12859-015-0564-6", "10.1111/cgf.12114", "10.1108/eb026562", "10.1002/inc3.362", "10.1109/vast.2014.7042495", "10.1145/299917.299920", "10.1162/coli.2009.35.4.35403", "10.1016/j.datak.2007.10.008", "10.13140/2.1.2393.1847", "10.1109/tits.2017.2683539", "10.1109/tbdata.2017.2667700", "10.1177/1473871617692841", "10.1109/tits.2015.2436897", "10.1109/tvcg.2013.179", "10.1145/2339530.2339561", "10.1109/vast.2008.4677356", "10.1109/access.2016.2553681", "10.1109/tvcg.2017.2758362", "10.14778/2732232.2732235", "10.1109/tits.2017.2711644", "10.1162/jmlr.2003.3.4-5.993", "10.1145/330560.330692", "10.1109/tvcg.2014.2371856", "10.1111/cgf.12778", "10.1145/2743025", "10.1109/tnn.2003.820440", "10.1109/tvcg.2016.2598885", "10.1109/tits.2016.2639320", "10.1145/1341012.1341041", "10.1109/tvcg.2016.2598416", "10.1145/2501654.2501656", "10.1109/tvcg.2016.2598432", "10.1109/tvcg.2018.2865042"], "wos": 1, "children": [], "len": 1}, {"doi": "10.1109/tvcg.2019.2934258", "title": "Scale-Space Splatting: Reforming Spacetime for Cross-Scale Exploration of Integral Measures in Molecular Dynamics", "year": "2019", "conferenceName": "SciVis", "authors": "Juraj P\u00e1lenik;Jan Byska;Stefan Bruckner;Helwig Hauser", "citationCount": "0", "affiliation": "Palenik, J (Corresponding Author), Univ Bergen, Bergen, Norway. Palenik, Juraj; Byska, Jan; Bruckner, Stefan; Hauser, Helwig, Univ Bergen, Bergen, Norway. Byska, Jan, Masaryk Univ, Brno, Czech Republic.", "countries": "Republic;Norway", "abstract": "Understanding large amounts of spatiotemporal data from particle-based simulations, such as molecular dynamics, often relies on the computation and analysis of aggregate measures. These, however, by virtue of aggregation, hide structural information about the space/time localization of the studied phenomena. This leads to degenerate cases where the measures fail to capture distinct behaviour. In order to drill into these aggregate values, we propose a multi-scale visual exploration technique. Our novel representation, based on partial domain aggregation, enables the construction of a continuous scale-space for discrete datasets and the simultaneous exploration of scales in both space and time. We link these two scale-spaces in a scale-space space-time cube and model linked views as orthogonal slices through this cube, thus enabling the rapid identification of spatio-temporal patterns at multiple scales. To demonstrate the effectiveness of our approach, we showcase an advanced exploration of a protein-ligand simulation.", "keywords": "Scale space,time-series,scientific simulation,multi-scale analysis,space-time cube,molecular dynamics", "link": "http://dx.doi.org/10.1109/TVCG.2019.2934258", "refList": ["10.1111/cgf.13445", "10.1109/tvcg.2012.191", "10.1201/b14876", "10.1145/827051.827056", "10.1080/07391102.2005.10531229", "10.1021/acs.jcim.7b00070", "10.1007/978-3-8348-9190-729", "10.1111/cgf.13427", "10.1109/tvcg.2018.2864851", "10.1111/cgf.12612", "10.1109/tvcg.2015.2467434", "10.1016/0021-9991(82)90025-0", "10.1111/cgf.13177", "10.1007/978-1-4757-6465-9", "10.1145/1044588.1044615", "10.2307/2669996", "10.1109/tvcg.2018.2865049", "10.1007/978-3-540-70823-0\\_3", "10.1111/cgf.13640", "10.1109/tvcg.2010.253", "10.1109/tvcg.2009.177", "10.1016/j.csda.2018.03.014", "10.1109/tvcg.2009.200", "10.1109/visual.2003.1250353", "10.2312/eurovisshort.20171146", "10.1109/tvcg.2010.148", "10.1002/9780470316849", "10.1109/visual.1993.398859", "10.1007/978-1-4612-4026-6", "10.1016/j.jmb.2018.09.004", "10.1111/cgf.13415", "10.2312/molva.20181102", "10.1371/journal.pcbi.1002708", "10.1007/s10851-010-0242-2", "10.1016/0263-7855(96)00018-5", "10.1109/visual.2003.1250402", "10.1007/bf01936872", "10.1002/wics.79", "10.1111/j.1467-8659.2009.01684.x", "10.1109/tvcg.2018.2864510", "10.1111/cgf.12804", "10.1117/12.904668", "10.1002/jcc.20289", "10.1088/0965-0393/18/1/015012", "10.1109/34.56205", "10.1111/j.1435-5597.1970.tb01464.x", "10.1007/978-0-85729-079-3", "10.1007/s11263-005-1838-7"], "wos": 1, "children": [], "len": 1}, {"doi": "10.1109/pacificvis.2019.00045", "year": "2019", "title": "Space-Time Slicing: Visualizing Object Detector Performance in Driving Video Sequences", "conferenceName": "PacificVis", "authors": "Teng{-}Yok Lee;Kent Wittenburg", "citationCount": "0", "affiliation": "Lee, TY (Corresponding Author), Mitsubishi Elect Res Labs, Cambridge, MA 02139 USA.\nLee, Teng-Yok; Wittenburg, Kent, Mitsubishi Elect Res Labs, Cambridge, MA 02139 USA.", "countries": "USA", "abstract": "Development of object detectors for video in applications such as autonomous driving requires an iterative training process with data that initially requires human labeling. Later stages of development require tuning a large set of parameters that may not have labeled data available. For each training iteration and parameter selection decision, insight is needed into object detector performance. This work presents a visualization method called Space-Time Slicing to assist a human developer in the development of object detectors for driving applications without requiring labeled data. Space-Time Slicing reveals patterns in the detection data that can suggest the presence of false positives and false negatives. It may be used to set such parameters as image pixel size in data preprocessing and confidence thresholds for object classifiers by comparing performance across different conditions.", "keywords": "", "link": "https://doi.org/10.1109/PacificVis.2019.00045", "refList": ["10.1109/tvcg.2011.208", "10.1145/1778765.1778825", "10.1145/1141911.1141967", "10.1145/1276377.1276504", "10.1109/tvcg.2018.2865049", "10.1145/354384.354535", "10.1111/j.1467-8659.2012.03118.x", "10.1109/tvcg.2016.2598828", "10.1111/j.1467-8659.2012.03158.x", "10.1109/tvcg.2008.40", "10.1007/s11263-009-0275-4", "10.1109/visual.2003.1250401", "10.1109/pacificvis.2010.5429602"], "wos": 1, "children": [], "len": 1}], "len": 7}, {"doi": "10.1109/pacificvis.2017.8031583", "year": "2017", "title": "MobiSeg: Interactive region segmentation using heterogeneous mobility data", "conferenceName": "PacificVis", "authors": "Wenchao Wu;Yixian Zheng;Nan Cao;Haipeng Zeng;Bing Ni;Huamin Qu;Lionel M. Ni", "citationCount": "13", "affiliation": "Wu, WC (Corresponding Author), Hong Kong Univ Sci \\& Technol, Hong Kong, Hong Kong, Peoples R China.\nWu, Wenchao; Zheng, Yixian; Zeng, Haipeng; Ni, Bing; Qu, Huamin, Hong Kong Univ Sci \\& Technol, Hong Kong, Hong Kong, Peoples R China.\nCao, Nan, Tongji Univ, Shanghai, Peoples R China.\nNi, Lionel M., Univ Macau, Taipa, Macao, Peoples R China.", "countries": "China", "abstract": "With the acceleration of urbanization and modern civilization, more and more complex regions are formed in urban area. Although understanding these regions could provide huge insights to facilitate valuable applications for urban planning and business intelligence, few methods have been developed to effectively capture the rapid transformation of urban regions. In recent years, the widely applied location-acquisition technologies offer a more effective way to capture the dynamics of a city through analyzing people's movement activities based on mobility data. However, several challenges exist, including data sparsity and difficulties in result understanding and validation. To tackle these challenges, in this paper, we propose MobiSeg, an interactive visual analytics system, which supports the exploration of people's movement activities to segment the urban area into regions sharing similar activity patterns. A joint analysis is conducted on three types of heterogeneous mobility data (i.e., taxi trajectories, metro passenger RFID card data, and telco data), which can complement each other and provide a full picture of people's activities in a region. In addition, advanced analytical algorithms (e.g., non-negative matrix factorization (NMF) based method to capture latent activity patterns, as well as metric learning to calibrate and supervise the underlying analysis) and novel visualization designs are integrated into our system to provide a comprehensive solution to region segmentation in urban areas. We demonstrate the effectiveness of our system via case studies with real-world datasets and qualitative interviews with domain experts.", "keywords": "", "link": "https://doi.org/10.1109/PACIFICVIS.2017.8031583", "refList": ["10.1109/tvcg.2013.226", "10.1109/tvcg.2010.44", "10.1561/2200000019", "10.1109/tvcg.2015.2468111", "10.1109/tits.2012.2209201", "10.2307/621647", "10.1109/tkde.2014.2345405", "10.1109/tvcg.2015.2467194", "10.1109/pacificvis.2011.5742386", "10.1080/01431160512331316838", "10.1007/s10980-005-5238-8", "10.1145/2629592", "10.1109/tvcg.2015.2467619", "10.1109/tvcg.2015.2467592", "10.1109/tvcg.2013.228", "10.1111/cgf.12654", "10.1109/tvcg.2014.2346271", "10.1109/percomw.2011.5766912", "10.1111/cgf.12114", "10.1007/978-3-662-44848-9\\_32", "10.1109/infvis.2005.1532144", "10.1109/vast.2015.7347630", "10.1017/s0026749x10000314", "10.1137/s0036144599352836", "10.1145/860435.860485", "10.1109/tvcg.2013.168", "10.1109/tbdata.2016.2586447", "10.1109/vast.2014.7042490", "10.1109/tvcg.2012.265", "10.1109/vast.2011.6102455", "10.1162/jmlr.2003.3.4-5.993", "10.1016/j.landurbplan.2009.05.001", "10.1109/tvcg.2015.2440259", "10.1111/cgf.12107"], "wos": 1, "children": [{"doi": "10.1109/tvcg.2020.3030370", "title": "TaxThemis: Interactive Mining and Exploration of Suspicious Tax Evasion Groups", "year": "2020", "conferenceName": "VAST", "authors": "Yating Lin;Kamkwai Wong;Yong Wang;Rong Zhang;Bo Dong;Huamin Qu;Qinghua Zheng", "citationCount": "0", "affiliation": "Lin, YT (Corresponding Author), Xi An Jiao Tong Univ, MOEKLINNS Lab, Xian, Shaanxi, Peoples R China. Lin, Yating; Zheng, Qinghua, Xi An Jiao Tong Univ, MOEKLINNS Lab, Xian, Shaanxi, Peoples R China. Wong, Kamkwai; Wang, Yong; Zhang, Rong; Qu, Huamin, Hong Kong Univ Sci \\& Technol, Hong Kong, Peoples R China. Dong, Bo, Xi An Jiao Tong Univ, Natl Engn Lab Big Data Analyt, Xian, Shaanxi, Peoples R China.", "countries": "China", "abstract": "Tax evasion is a serious economic problem for many countries, as it can undermine the government's tax system and lead to an unfair business competition environment. Recent research has applied data analytics techniques to analyze and detect tax evasion behaviors of individual taxpayers. However, they have failed to support the analysis and exploration of the related party transaction tax evasion (RPTTE) behaviors (e.g., transfer pricing), where a group of taxpayers is involved. In this paper, we present TaxThemis, an interactive visual analytics system to help tax officers mine and explore suspicious tax evasion groups through analyzing heterogeneous tax-related data. A taxpayer network is constructed and fused with the respective trade network to detect suspicious RPTTE groups. Rich visualizations are designed to facilitate the exploration and investigation of suspicious transactions between related taxpayers with profit and topological data analysis. Specifically, we propose a calendar heatmap with a carefully-designed encoding scheme to intuitively show the evidence of transferring revenue through related party transactions. We demonstrate the usefulness and effectiveness of TaxThemis through two case studies on real-world tax-related data and interviews with domain experts.", "keywords": "Visual Analytics,Tax Network,Tax Evasion Detection,Anomaly detection,Multidimensional data", "link": "http://dx.doi.org/10.1109/TVCG.2020.3030370", "refList": ["10.1111/cgf.12886", "10.2307/2277827", "10.1109/tvcg.2010.44", "10.1109/tits.2014.2315794", "10.1109/tvcg.2019.2934670", "10.1038/s41467-019-08987-4", "10.1111/cgf.12920", "10.1109/vast.2017.8585721", "10.1080/15230406.2015.1093431", "10.1109/tvcg.2018.2843369", "10.1038/srep01001", "10.1109/tvcg.2017.2744018", "10.1109/tvcg.2017.2744159", "10.1068/b130199p", "10.1109/tvcg.2009.143", "10.1016/j.visinf.2017.01.006", "10.1109/tvcg.2019.2892483", "10.1109/pacificvis.2017.8031583", "10.1109/pacificvis48177.2020.2785", "10.2307/2686111", "10.1109/tvcg.2015.2467199", "10.1111/cgf.12114", "10.1109/tvcg.2018.2865126", "10.1111/j.1538-4632.1996.tb00936.x", "10.1109/tvcg.2019.2934619", "10.2307/2332142", "10.1007/978-3-319-10590-1\\_53", "10.1109/cvpr.2016.485", "10.1109/cvpr.2017.17", "10.2307/2986645", "10.1109/tvcg.2014.2346321", "10.1017/s0140525x16001837", "10.1109/tvcg.2016.2598541", "10.1371/journal.pone.0207377", "10.1109/tvcg.2014.2346265", "10.1007/s4095-020-0191-7", "10.3141/1644-14", "10.1109/tvcg.2017.2744158", "10.1109/cvpr.2016.90", "10.1109/tvcg.2018.2865027", "10.1109/tvcg.2017.2785807", "10.1109/tvcg.2017.2744358", "10.1111/j.1538-4632.1995.tb00338.x", "10.1080/03081068808717359", "10.1109/tvcg.2016.2598831"], "wos": 1, "children": [], "len": 1}, {"doi": "10.1109/pacificvis.2019.00027", "year": "2019", "title": "Visual Analytics of Taxi Trajectory Data via Topical Sub-trajectories", "conferenceName": "PacificVis", "authors": "Sichen Jin;Yubo Tao;Yuyu;Yuyu Yan;Jin Xu", "citationCount": "1", "affiliation": "Tao, YB (Corresponding Author), Zhejiang Univ, State Key Lab CAD\\&CG, Hangzhou, Zhejiang, Peoples R China.\nJin, Sichen; Tao, Yubo; Yan, Yuyu; Xu, Jin; Lin, Hai, Zhejiang Univ, State Key Lab CAD\\&CG, Hangzhou, Zhejiang, Peoples R China.", "countries": "China", "abstract": "GPS-based taxi trajectories contain valuable knowledge about movement behaviors for transportation and urban planning. Topic modeling is an effective tool to extract semantic information from taxi trajectories. However, previous methods generally ignore the direction of trajectories. In this paper, we employ the bigram topic model instead of traditional topic models to analyze textualized trajectories to take into account the direction information of trajectories. We further propose a modified Apriori algorithm to extract frequent sub-trajectories and use them to represent each topic as topical sub-trajectories. Finally, we design a visual analytics system with several linked views to facilitate users to interactively explore topics, sub-trajectories, and trips. We demonstrate the effectiveness of our system via case studies with Chengdu taxi trajectory data.", "keywords": "Human-centered computing; Visualization; Visualization application domains; Visual analytics", "link": "https://doi.org/10.1109/PacificVis.2019.00027", "refList": ["10.1145/2629592", "10.1007/s12650-018-0481-7", "10.1109/tvcg.2010.44", "10.1145/1143844.1143967", "10.3109/15569527.2010.547541", "10.1109/pacificvis.2017.8031583", "10.18653/v1/p17-2084", "10.1109/tits.2015.2436897", "10.1177/1473871612457601", "10.1109/69.250074", "10.1109/pacificvis.2014.50", "10.1109/tvcg.2016.2598416", "10.1109/mdm.2013.23", "10.1109/vast.2011.6102455"], "wos": 1, "children": [], "len": 1}], "len": 5}], "len": 15}, "index": 1312, "embedding": [0.6941138505935669, 1.353419542312622, -1.0254276990890503, -1.576537847518921, -0.6602144837379456, 0.16650904715061188, -0.706787109375, 0.2705710232257843, -0.43060755729675293, -0.1406116783618927, -0.7135432362556458, 0.6104868054389954, -0.13366082310676575, 2.39353346824646, 2.129962205886841, 2.5422165393829346, 1.1178303956985474, 2.4738881587982178, -0.6408212184906006, 0.8286682367324829, -0.06630208343267441, 0.9736945033073425, 1.094307541847229, 1.4425936937332153, -1.8903611898422241, 0.9228232502937317, -0.5077023506164551, 1.7681801319122314, 0.93824702501297, -0.1385568529367447, 1.0318728685379028, 1.8398653268814087], "projection": [-0.7048174738883972, 9.717617988586426], "size": 8, "height": 3, "width": 5}