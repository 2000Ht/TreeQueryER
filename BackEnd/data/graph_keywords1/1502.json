{"data": {"doi": "10.1111/cgf.13686", "year": "2019", "title": "Visualizing for the Non-Visual: Enabling the Visually Impaired to Use Visualization", "conferenceName": "EuroVis", "authors": "Jinho Choi;Sanghun Jung;Deok Gun Park;Jaegul Choo;Niklas Elmqvist", "citationCount": "2", "affiliation": "Choi, JO (Corresponding Author), Korea Univ, Seoul, South Korea.\nChoi, Jinho; Jung, Sanghun; Cho, Jaegul, Korea Univ, Seoul, South Korea.\nPark, Deok Gun, Univ Texas Arlington, Arlington, TX 76019 USA.\nElmqvist, Niklas, Univ Maryland, College Pk, MD 20742 USA.", "countries": "USA;Korea", "abstract": "The majority of visualizations on the web are still stored as raster images, making them inaccessible to visually impaired users. We propose a deep-neural-network-based approach that automatically recognizes key elements in a visualization, including a visualization type, graphical elements, labels, legends, and most importantly, the original data conveyed in the visualization. We leverage such extracted information to provide visually impaired people with the reading of the extracted information. Based on interviews with visually impaired users, we built a Google Chrome extension designed to work with screen reader software to automatically decode charts on a webpage using our pipeline. We compared the performance of the back-end algorithm with existing methods and evaluated the utility using qualitative feedback from visually impaired users.", "keywords": "", "link": "https://doi.org/10.1111/cgf.13686", "refList": ["10.1109/tpami.2016.2646371", "10.1109/msp.2007.914730", "10.1109/icip.2000.899506", "10.1145/3025453.3025957", "10.1145/2047196.2047247", "10.1145/3173574.3174168", "10.1145/2858036.2858435", "10.1007/978-3-319-47997-2", "10.1109/cvpr.2015.7298594", "10.1006/ijhc.1996.0048", "10.1145/2702123.2702484", "10.1145/3173574.3173772", "10.1007/s11263-015-0816-y", "10.1145/354324.354335", "10.1145/1866029.1866074", "10.1145/2815833.2816956", "10.1109/cvpr.2017.690", "10.1145/2736277.2741660", "10.1111/cgf.13193", "10.1007/978-1-84628-867-8", "10.1145/3056540.3064955", "10.1145/1352782.1352786", "10.1145/2702123.2702180", "10.1177/1473871613513228", "10.1109/cvpr.2016.254", "10.1007/978-3-319-71249-9\\_9", "10.1145/3058555.3058564", "10.1145/2533682.2533683", "10.1109/tvcg.2017.2744320", "10.1109/cvpr.2016.90", "10.1145/2538862.2538975", "10.1109/icip.2012.6467497", "10.1109/mmul.1999.809241"], "wos": 1, "children": [{"doi": "10.1109/tvcg.2020.3030351", "title": "Chartem: Reviving Chart Images with Data Embedding", "year": "2020", "conferenceName": "InfoVis", "authors": "Jiayun Fu;Bin Zhu;Weiwei Cui;Song Ge;Yun Wang 0012;Haidong Zhang;He Huang;Yuanyuan Tang;Dongmei Zhang;Xiaojing Ma 0002", "citationCount": "0", "affiliation": "Fu, JY (Corresponding Author), Huazhong Univ Sci \\& Technol, Natl Engn Res Ctr Big Data Tech \\& Syst, Big Data Sec Eng Res Ctr, Sch Cyber Sci \\& Technol, Wuhan, Peoples R China. Fu, Jiayun; Tang, Yuanyuan; Ma, Xiaojing, Huazhong Univ Sci \\& Technol, Natl Engn Res Ctr Big Data Tech \\& Syst, Big Data Sec Eng Res Ctr, Sch Cyber Sci \\& Technol, Wuhan, Peoples R China. Zhu, Bin; Cui, Weiwei; Ge, Song; Wang, Yun; Zhang, Haidong; Huang, He; Zhang, Dongmei, Microsoft Res Asia, Beijing, Peoples R China.", "countries": "China", "abstract": "In practice, charts are widely stored as bitmap images. Although easily consumed by humans, they are not convenient for other uses. For example, changing the chart style or type or a data value in a chart image practically requires creating a completely new chart, which is often a time-consuming and error-prone process. To assist these tasks, many approaches have been proposed to automatically extract information from chart images with computer vision and machine learning techniques. Although they have achieved promising preliminary results, there are still a lot of challenges to overcome in terms of robustness and accuracy. In this paper, we propose a novel alternative approach called Chartem to address this issue directly from the root. Specifically, we design a data-embedding schema to encode a significant amount of information into the background of a chart image without interfering human perception of the chart. The embedded information, when extracted from the image, can enable a variety of visualization applications to reuse or repurpose chart images. To evaluate the effectiveness of Chartem, we conduct a user study and performance experiments on Chartem embedding and extraction algorithms. We further present several prototype applications to demonstrate the utility of Chartem.", "keywords": "Chart embedding,background embedding,data embedding,chart image,chart reuse", "link": "http://dx.doi.org/10.1109/TVCG.2020.3030351", "refList": ["10.1300/j104v40n03\\_02", "10.1109/icpr.2006.479", "10.1109/tvcg.2015.2467732", "10.1109/cvpr.2014.81", "10.3390/fi10060054", "10.1109/tpami.2016.2577031", "10.1145/2858036.2858435", "10.1109/tvcg.2011.185", "10.2352/issn.2470-1173.2016.8.mwsf-078", "10.1109/lsp.2017.2745572", "10.1109/ares.2008.72", "10.1145/2896818", "10.1007/s12650-018-0530-2", "10.1002/j.1538-7305.1948.tb00917.x", "10.1109/ipta.2010.5586786", "10.1109/cvpr.2019.00766", "10.1109/tvcg.2018.2865138", "10.1137/0108018", "10.1111/cgf.13193", "10.1145/2307636.2307645", "10.1145/3152823", "10.1007/978-3-642-21551-3\\_13", "10.1111/cgf.13686", "10.1007/s10479-005-5724-z", "10.1038/540330a", "10.1109/cvpr.2019.00161", "10.1007/s00521-014-1702-1", "10.1006/jcss.2002.1827", "10.1016/j.jvlc.2018.08.005", "10.1109/cvpr.2018.00068", "10.1109/tip.2003.819861", "10.1007/978-3-642-16435-4\\_13", "10.1109/tvcg.2013.234", "10.1109/lsp.2006.870357", "10.1109/tvcg.2016.2525771", "10.1109/tvcg.2017.2744320", "10.1109/cvpr.2016.90", "10.1007/978-3-319-24574-4\\_28", "10.1016/s0019-9958(60)90287-4", "10.1109/wifs.2012.6412655", "10.1016/j.visinf.2018.04.011", "10.1109/tvcg.2019.2934431", "10.1117/12.337436"], "wos": 1, "children": [], "len": 1}, {"doi": "10.1109/tvcg.2020.3030423", "title": "MobileVisFixer: Tailoring Web Visualizations for Mobile Phones Leveraging an Explainable Reinforcement Learning Framework", "year": "2020", "conferenceName": "InfoVis", "authors": "Aoyu Wu;Wai Tong;Tim Dwyer;Bongshin Lee;Petra Isenberg;Huamin Qu", "citationCount": "0", "affiliation": "Wu, AY (Corresponding Author), Hong Kong Univ Sci \\& Technol, Hong Kong, Peoples R China. Wu, Aoyu; Tong, Wai; Qu, Huamin, Hong Kong Univ Sci \\& Technol, Hong Kong, Peoples R China. Dwyer, Tim, Monash Univ, Clayton, Vic, Australia. Lee, Bongshin, Microsoft Res, Redmond, WA USA. Isenberg, Petra, INRIA, Le Chesnay Rocquencourt, France.", "countries": "USA;China;France;Australia", "abstract": "We contribute MobileVisFixer, a new method to make visualizations more mobile-friendly. Although mobile devices have become the primary means of accessing information on the web, many existing visualizations are not optimized for small screens and can lead to a frustrating user experience. Currently, practitioners and researchers have to engage in a tedious and time-consuming process to ensure that their designs scale to screens of different sizes, and existing toolkits and libraries provide little support in diagnosing and repairing issues. To address this challenge, MobileVisFixer automates a mobile-friendly visualization re-design process with a novel reinforcement learning framework. To inform the design of MobileVisFixer, we first collected and analyzed SVG-based visualizations on the web, and identified five common mobile-friendly issues. MobileVisFixer addresses four of these issues on single-view Cartesian visualizations with linear or discrete scales by a Markov Decision Process model that is both generalizable across various visualizations and fully explainable. MobileVisFixer deconstructs charts into declarative formats, and uses a greedy heuristic based on Policy Gradient methods to find solutions to this difficult, multi-criteria optimization problem in reasonable time. In addition, MobileVisFixer can be easily extended with the incorporation of optimization algorithms for data visualizations. Quantitative evaluation on two real-world datasets demonstrates the effectiveness and generalizability of our method.", "keywords": "Mobile visualization,Responsive visualization,Machine learning for visualizations,Reinforcement learning", "link": "http://dx.doi.org/10.1109/TVCG.2020.3030423", "refList": ["10.1109/mcg.2014.82", "10.1109/tvcg.2018.2865158", "10.1109/tvcg.2012.196", "10.1145/3092703.3092726", "10.1109/pimrc.2015.7343276", "10.1109/tvcg.2014.48", "10.1145/3025453.3025957", "10.1145/2047196.2047247", "10.1145/3173574.3174168", "10.1109/icst.2019.00027", "10.1109/tvcg.2007.70594", "10.1145/3197517.3201311", "10.1145/3126594.3126653", "10.1109/mcg.2019.2924636", "10.1145/3180155.3180262", "10.1109/tvcg.2017.2659744", "10.1145/3123266.3123274", "10.1109/tvcg.2019.2934538", "10.1109/cvpr.2018.00592", "10.1109/tvcg.2018.2865138", "10.1109/tsmcc.2012.2218595", "10.1109/tvcg.2018.2865240", "10.1111/cgf.13193", "10.1145/2775441.2775478", "10.1145/3313831.3376777", "10.1109/mc.2006.109", "10.1111/cgf.13686", "10.1109/tvcg.2015.2467091", "10.4230/dagrep.9.7.78", "10.1007/978-3-319-71249-9\\_9", "10.1007/s00778-019-00588-3", "10.1109/ase.2015.31", "10.1007/bf02124742", "10.1109/tvcg.2019.2934397", "10.1109/adprl.2007.368196", "10.1109/mcg.2020.2968244", "10.1145/3092703.3092712", "10.1109/tvcg.2017.2744320", "10.1023/a:1017992615625", "10.1145/2642918", "10.1145/2858036.2858558", "10.1145/3290605.3300358", "10.1109/tvcg.2019.2934431", "10.1109/tvcg.2016.2599030"], "wos": 1, "children": [], "len": 1}, {"doi": "10.1109/tvcg.2020.3030406", "title": "Palettailor: Discriminable Colorization for Categorical Data", "year": "2020", "conferenceName": "InfoVis", "authors": "Kecheng Lu;Mi Feng;Xin Chen;Michael Sedlmair;Oliver Deussen;Dani Lischinski;Zhanglin Cheng;Yunhai Wang", "citationCount": "0", "affiliation": "Wang, YH (Corresponding Author), Shandong Univ, Jinan, Peoples R China. Cheng, ZL (Corresponding Author), SIAT, Shenzhen VesuCA Key Lab, Shenzhen, Peoples R China. Lu, Kecheng; Chen, Xin; Wang, Yunhai, Shandong Univ, Jinan, Peoples R China. Feng, Mi, Twitter Inc, San Francisco, CA USA. Lu, Kecheng; Deussen, Oliver; Cheng, Zhanglin, SIAT, Shenzhen VesuCA Key Lab, Shenzhen, Peoples R China. Sedlmair, Michael, Univ Stuttgart, VISUS, Stuttgart, Germany. Deussen, Oliver, Konstanz Univ, Constance, Germany. Lischinski, Dani, Hebrew Univ Jerusalem, Jerusalem, Israel.", "countries": "USA;Israel;Germany;China", "abstract": "We present an integrated approach for creating and assigning color palettes to different visualizations such as multi-class scatterplots, line, and bar charts. While other methods separate the creation of colors from their assignment, our approach takes data characteristics into account to produce color palettes, which are then assigned in a way that fosters better visual discrimination of classes. To do so, we use a customized optimization based on simulated annealing to maximize the combination of three carefully designed color scoring functions: point distinctness, name difference, and color discrimination. We compare our approach to state-of-the-art palettes with a controlled user study for scatterplots and line charts, furthermore we performed a case study. Our results show that Palettailor, as a fully-automated approach, generates color palettes with a higher discrimination quality than existing approaches. The efficiency of our optimization allows us also to incorporate user modifications into the color selection process.", "keywords": "Color Palette,Discriminability,Multi-Class Scatterplot,Line Chart,Bar Chart", "link": "http://dx.doi.org/10.1109/TVCG.2020.3030406", "refList": ["10.1109/mcg.2014.82", "10.1109/tvcg.2018.2865158", "10.1109/tvcg.2012.196", "10.1145/3092703.3092726", "10.1109/tvcg.2014.48", "10.1145/3025453.3025957", "10.1145/2047196.2047247", "10.1145/3173574.3174168", "10.1109/icst.2019.00027", "10.1109/tvcg.2007.70594", "10.1145/3197517.3201311", "10.1145/3126594.3126653", "10.1109/mcg.2019.2924636", "10.1145/3180155.3180262", "10.1109/tvcg.2017.2659744", "10.1145/3123266.3123274", "10.1109/tvcg.2018.2865234", "10.1109/tvcg.2019.2934538", "10.1109/cvpr.2018.00592", "10.1145/2815833.2816956", "10.1109/tvcg.2018.2865138", "10.1109/tsmcc.2012.2218595", "10.1109/tvcg.2018.2865240", "10.1111/cgf.13193", "10.1145/2775441.2775478", "10.1145/3313831.3376777", "10.1109/mc.2006.109", "10.1111/cgf.13686", "10.1109/tvcg.2015.2467091", "10.4230/dagrep.9.7.78", "10.1007/978-3-319-71249-9\\_9", "10.1007/s00778-019-00588-3", "10.1109/ase.2015.31", "10.1007/bf02124742", "10.1145/3025453.3025768", "10.1109/tvcg.2019.2934397", "10.1109/adprl.2007.368196", "10.1109/mcg.2020.2968244", "10.1145/3092703.3092712", "10.1109/tvcg.2017.2744320", "10.1023/a:1017992615625", "10.1145/2642918", "10.1145/2858036.2858558", "10.1145/3290605.3300358", "10.1109/tvcg.2019.2934431", "10.1109/tvcg.2016.2599030"], "wos": 1, "children": [], "len": 1}, {"doi": "10.1109/tvcg.2020.3030366", "title": "VisConnect: Distributed Event Synchronization for Collaborative Visualization", "year": "2020", "conferenceName": "InfoVis", "authors": "Michail Schwab;David Saffo;Yixuan Zhang;Shash Sinha;Cristina Nita-Rotaru;James Tompkin;Cody Dunne;Michelle Borkin", "citationCount": "0", "affiliation": "Schwab, M (Corresponding Author), Northeastern Univ, Boston, MA 02115 USA. Schwab, Michail; Saffo, David; Zhang, Yixuan; Nita-Rotaru, Cristina; Dunne, Cody; Borkin, Michelle A., Northeastern Univ, Boston, MA 02115 USA. Zhang, Yixuan, Georgia Inst Technol, Atlanta, GA 30332 USA. Sinha, Shash; Tompkin, James, Brown Univ, Providence, RI 02912 USA.", "countries": "USA", "abstract": "Tools and interfaces are increasingly expected to be synchronous and distributed to accommodate remote collaboration. Yet, adoption of these techniques for data visualization is low partly because development is difficult: existing collaboration software systems either do not support simultaneous interaction or require expensive redevelopment of existing visualizations. We contribute VisConnect: a web-based synchronous distributed collaborative visualization system that supports most web-based SVG data visualizations, balances system safety with responsiveness, and supports simultaneous interaction from many collaborators. VisConnect works with existing visualization implementations with little-to-no code changes by synchronizing low-level JavaScript events across clients such that visualization updates proceed transparently across clients. This is accomplished via a peer-to-peer system that establishes consensus among clients on the per-element sequence of events, and uses a lock service to grant access over elements to clients. We contribute collaborative extensions of traditional visualization interaction techniques, such as drag, brush, and lasso, and discuss different strategies for collaborative visualization interactions. To demonstrate the utility of VisConnect, we present novel examples of collaborative visualizations in the healthcare domain, remote collaboration with annotation, and show in an education case study for e-learning with 22 participants that students found the ability to remotely collaborate on class activities helpful and enjoyable for understanding concepts. A free copy of this paper and source code are available on OSF at osf.io/ut7e6 and at visconnect.us.", "keywords": "Collaborative visualization,distributed visualization,toolkit", "link": "http://dx.doi.org/10.1109/TVCG.2020.3030366", "refList": ["10.1109/tip.2004.840686", "10.1109/tcsvt.2003.815962", "10.1109/49.668976", "10.1109/sfcs.2002.1181950", "10.1109/tip.2006.875238", "10.1109/icip.1997.638586", "10.1109/tvcg.2017.2744320", "10.1109/icip.1994.413536", "10.1111/cgf.13686", "10.1109/icip.1996.560421", "10.1145/2047196.2047247", "10.1016/s0165-1684(98)00014-0", "10.1109/cvpr.2019.00161", "10.1007/978-3-319-46478-7\\_41", "10.1109/dspws.1996.555454", "10.1109/5.687830", "10.1137/0108018"], "wos": 1, "children": [], "len": 1}], "len": 9}, "index": 1502, "embedding": [2.1652138233184814, 1.2701889276504517, 2.711852550506592, 3.467528820037842, -0.6415178775787354, 0.16650904715061188, -0.39109519124031067, 3.3919496536254883, -0.4787178039550781, -0.9009531736373901, 1.9636598825454712, 1.2820183038711548, -0.15792734920978546, 2.2916488647460938, 1.8657312393188477, 1.5319335460662842, 0.12976349890232086, 0.06589167565107346, -0.7424624562263489, 1.2685117721557617, -0.06630208343267441, 3.4228851795196533, 0.07565158605575562, -0.15392345190048218, 1.6696738004684448, 0.05785536766052246, -0.5536867380142212, -0.007418991066515446, 2.3880317211151123, 3.4315145015716553, 1.376431941986084, 1.9447137117385864], "projection": [-3.6603357791900635, 7.637202739715576], "size": 5, "height": 2, "width": 4}